Created new wandb run! c56hhvw3
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59981
Policy Entropy: 4.49928
Value Function Loss: nan
Mean KL Divergence: 0.00016
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.87236
Value Function Update Magnitude: 0.76360
Collected Steps per Second: 10,523.25066
Overall Steps per Second: 7,019.88659
Timestep Collection Time: 4.75157
Timestep Consumption Time: 2.37133
PPO Batch Consumption Time: 0.31978
Total Iteration Time: 7.12291
Cumulative Model Updates: 3
Cumulative Timesteps: 50,002
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.37620
Policy Entropy: 4.49451
Value Function Loss: 0.72995
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02250
Policy Update Magnitude: 1.08042
Value Function Update Magnitude: 1.10328
Collected Steps per Second: 10,285.04044
Overall Steps per Second: 6,540.97423
Timestep Collection Time: 4.86551
Timestep Consumption Time: 2.78503
PPO Batch Consumption Time: 0.25256
Total Iteration Time: 7.65054
Cumulative Model Updates: 9
Cumulative Timesteps: 100,044
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 100044...
Checkpoint 100044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.18739
Policy Entropy: 4.49148
Value Function Loss: 0.51998
Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.01634
Policy Update Magnitude: 0.84588
Value Function Update Magnitude: 0.95724
Collected Steps per Second: 11,240.92333
Overall Steps per Second: 6,752.96831
Timestep Collection Time: 4.44981
Timestep Consumption Time: 2.95730
PPO Batch Consumption Time: 0.26241
Total Iteration Time: 7.40711
Cumulative Model Updates: 15
Cumulative Timesteps: 150,064
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.80408
Policy Entropy: 4.48922
Value Function Loss: 0.14295
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.01854
Policy Update Magnitude: 0.98836
Value Function Update Magnitude: 1.21340
Collected Steps per Second: 10,672.28571
Overall Steps per Second: 5,896.03282
Timestep Collection Time: 4.68597
Timestep Consumption Time: 3.79601
PPO Batch Consumption Time: 0.24934
Total Iteration Time: 8.48197
Cumulative Model Updates: 24
Cumulative Timesteps: 200,074
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 200074...
Checkpoint 200074 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -1.59350
Policy Entropy: 4.48771
Value Function Loss: 0.14684
Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02265
Policy Update Magnitude: 0.90112
Value Function Update Magnitude: 1.05782
Collected Steps per Second: 10,778.46853
Overall Steps per Second: 6,013.30566
Timestep Collection Time: 4.64073
Timestep Consumption Time: 3.67749
PPO Batch Consumption Time: 0.25012
Total Iteration Time: 8.31822
Cumulative Model Updates: 33
Cumulative Timesteps: 250,094
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.81070
Policy Entropy: 4.48415
Value Function Loss: 0.18160
Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.96600
Value Function Update Magnitude: 0.80162
Collected Steps per Second: 10,957.68684
Overall Steps per Second: 6,062.68390
Timestep Collection Time: 4.56447
Timestep Consumption Time: 3.68534
PPO Batch Consumption Time: 0.24995
Total Iteration Time: 8.24981
Cumulative Model Updates: 42
Cumulative Timesteps: 300,110
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 300110...
Checkpoint 300110 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.60627
Policy Entropy: 4.48356
Value Function Loss: 0.22537
Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 1.04279
Value Function Update Magnitude: 0.75176
Collected Steps per Second: 11,672.66904
Overall Steps per Second: 6,285.53906
Timestep Collection Time: 4.28916
Timestep Consumption Time: 3.67610
PPO Batch Consumption Time: 0.26127
Total Iteration Time: 7.96527
Cumulative Model Updates: 51
Cumulative Timesteps: 350,176
Timesteps Collected: 50,066
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.85676
Policy Entropy: 4.47961
Value Function Loss: 0.29416
Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.03224
Policy Update Magnitude: 1.13847
Value Function Update Magnitude: 0.64133
Collected Steps per Second: 12,126.39686
Overall Steps per Second: 6,485.99373
Timestep Collection Time: 4.12423
Timestep Consumption Time: 3.58654
PPO Batch Consumption Time: 0.25231
Total Iteration Time: 7.71077
Cumulative Model Updates: 60
Cumulative Timesteps: 400,188
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 400188...
Checkpoint 400188 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.25491
Policy Entropy: 4.47557
Value Function Loss: 0.30589
Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.03624
Policy Update Magnitude: 1.21211
Value Function Update Magnitude: 0.59150
Collected Steps per Second: 11,727.75462
Overall Steps per Second: 6,458.15839
Timestep Collection Time: 4.26339
Timestep Consumption Time: 3.47875
PPO Batch Consumption Time: 0.24398
Total Iteration Time: 7.74215
Cumulative Model Updates: 69
Cumulative Timesteps: 450,188
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.96921
Policy Entropy: 4.47385
Value Function Loss: 0.31704
Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.03654
Policy Update Magnitude: 1.24967
Value Function Update Magnitude: 0.73933
Collected Steps per Second: 11,304.76806
Overall Steps per Second: 6,388.55335
Timestep Collection Time: 4.42822
Timestep Consumption Time: 3.40767
PPO Batch Consumption Time: 0.24331
Total Iteration Time: 7.83589
Cumulative Model Updates: 78
Cumulative Timesteps: 500,248
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 500248...
Checkpoint 500248 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.41898
Policy Entropy: 4.46943
Value Function Loss: 0.35843
Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.04160
Policy Update Magnitude: 1.29613
Value Function Update Magnitude: 0.64071
Collected Steps per Second: 11,637.46219
Overall Steps per Second: 6,335.91786
Timestep Collection Time: 4.29973
Timestep Consumption Time: 3.59778
PPO Batch Consumption Time: 0.24822
Total Iteration Time: 7.89751
Cumulative Model Updates: 87
Cumulative Timesteps: 550,286
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15907
Policy Entropy: 4.46665
Value Function Loss: 0.38140
Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.03634
Policy Update Magnitude: 1.31733
Value Function Update Magnitude: 0.55728
Collected Steps per Second: 12,193.81934
Overall Steps per Second: 6,507.52028
Timestep Collection Time: 4.10339
Timestep Consumption Time: 3.58556
PPO Batch Consumption Time: 0.25487
Total Iteration Time: 7.68895
Cumulative Model Updates: 96
Cumulative Timesteps: 600,322
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 600322...
Checkpoint 600322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.31664
Policy Entropy: 4.46134
Value Function Loss: 0.42173
Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.04296
Policy Update Magnitude: 1.33811
Value Function Update Magnitude: 0.54389
Collected Steps per Second: 12,104.34916
Overall Steps per Second: 6,516.00519
Timestep Collection Time: 4.13091
Timestep Consumption Time: 3.54281
PPO Batch Consumption Time: 0.24651
Total Iteration Time: 7.67372
Cumulative Model Updates: 105
Cumulative Timesteps: 650,324
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.15135
Policy Entropy: 4.46041
Value Function Loss: 0.44104
Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.04720
Policy Update Magnitude: 1.32584
Value Function Update Magnitude: 0.57863
Collected Steps per Second: 11,560.37502
Overall Steps per Second: 6,361.52323
Timestep Collection Time: 4.32858
Timestep Consumption Time: 3.53746
PPO Batch Consumption Time: 0.24358
Total Iteration Time: 7.86604
Cumulative Model Updates: 114
Cumulative Timesteps: 700,364
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 700364...
Checkpoint 700364 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.50652
Policy Entropy: 4.45543
Value Function Loss: 0.47137
Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05027
Policy Update Magnitude: 1.32999
Value Function Update Magnitude: 0.59077
Collected Steps per Second: 11,482.52863
Overall Steps per Second: 6,423.12520
Timestep Collection Time: 4.35810
Timestep Consumption Time: 3.43281
PPO Batch Consumption Time: 0.24414
Total Iteration Time: 7.79091
Cumulative Model Updates: 123
Cumulative Timesteps: 750,406
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.13285
Policy Entropy: 4.45098
Value Function Loss: 0.50118
Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05371
Policy Update Magnitude: 1.34420
Value Function Update Magnitude: 0.63422
Collected Steps per Second: 12,126.51064
Overall Steps per Second: 6,518.90576
Timestep Collection Time: 4.12831
Timestep Consumption Time: 3.55120
PPO Batch Consumption Time: 0.24480
Total Iteration Time: 7.67951
Cumulative Model Updates: 132
Cumulative Timesteps: 800,468
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
Saving checkpoint 800468...
Checkpoint 800468 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.33009
Policy Entropy: 4.44560
Value Function Loss: 0.50709
Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05536
Policy Update Magnitude: 1.35655
Value Function Update Magnitude: 0.66601
Collected Steps per Second: 12,257.60130
Overall Steps per Second: 6,556.82820
Timestep Collection Time: 4.08188
Timestep Consumption Time: 3.54895
PPO Batch Consumption Time: 0.25251
Total Iteration Time: 7.63082
Cumulative Model Updates: 141
Cumulative Timesteps: 850,502
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.69681
Policy Entropy: 4.44272
Value Function Loss: 0.52985
Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.05803
Policy Update Magnitude: 1.31427
Value Function Update Magnitude: 0.70316
Collected Steps per Second: 11,658.07992
Overall Steps per Second: 6,507.52656
Timestep Collection Time: 4.29162
Timestep Consumption Time: 3.39671
PPO Batch Consumption Time: 0.24346
Total Iteration Time: 7.68833
Cumulative Model Updates: 150
Cumulative Timesteps: 900,534
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 900534...
Checkpoint 900534 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.73954
Policy Entropy: 4.43840
Value Function Loss: 0.54229
Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.05909
Policy Update Magnitude: 1.28463
Value Function Update Magnitude: 0.65608
Collected Steps per Second: 11,344.03455
Overall Steps per Second: 6,267.50522
Timestep Collection Time: 4.41025
Timestep Consumption Time: 3.57219
PPO Batch Consumption Time: 0.24590
Total Iteration Time: 7.98244
Cumulative Model Updates: 159
Cumulative Timesteps: 950,564
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -1.15531
Policy Entropy: 4.43696
Value Function Loss: 0.58473
Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05404
Policy Update Magnitude: 1.29471
Value Function Update Magnitude: 0.69476
Collected Steps per Second: 11,896.80057
Overall Steps per Second: 6,388.13046
Timestep Collection Time: 4.20634
Timestep Consumption Time: 3.62725
PPO Batch Consumption Time: 0.25283
Total Iteration Time: 7.83359
Cumulative Model Updates: 168
Cumulative Timesteps: 1,000,606
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1000606...
Checkpoint 1000606 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.23328
Policy Entropy: 4.43518
Value Function Loss: 0.61540
Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05502
Policy Update Magnitude: 1.31172
Value Function Update Magnitude: 0.70731
Collected Steps per Second: 12,466.29757
Overall Steps per Second: 6,540.15710
Timestep Collection Time: 4.01113
Timestep Consumption Time: 3.63455
PPO Batch Consumption Time: 0.25730
Total Iteration Time: 7.64569
Cumulative Model Updates: 177
Cumulative Timesteps: 1,050,610
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.81667
Policy Entropy: 4.42897
Value Function Loss: 0.63911
Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05942
Policy Update Magnitude: 1.31715
Value Function Update Magnitude: 0.70433
Collected Steps per Second: 12,040.83774
Overall Steps per Second: 6,538.21057
Timestep Collection Time: 4.15403
Timestep Consumption Time: 3.49608
PPO Batch Consumption Time: 0.24432
Total Iteration Time: 7.65011
Cumulative Model Updates: 186
Cumulative Timesteps: 1,100,628
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1100628...
Checkpoint 1100628 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93308
Policy Entropy: 4.42616
Value Function Loss: 0.64455
Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06357
Policy Update Magnitude: 1.28756
Value Function Update Magnitude: 0.66980
Collected Steps per Second: 11,233.53017
Overall Steps per Second: 6,368.10506
Timestep Collection Time: 4.45381
Timestep Consumption Time: 3.40285
PPO Batch Consumption Time: 0.24436
Total Iteration Time: 7.85665
Cumulative Model Updates: 195
Cumulative Timesteps: 1,150,660
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.98503
Policy Entropy: 4.42155
Value Function Loss: 0.65276
Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06902
Policy Update Magnitude: 1.26411
Value Function Update Magnitude: 0.68421
Collected Steps per Second: 11,446.23976
Overall Steps per Second: 6,317.83223
Timestep Collection Time: 4.37244
Timestep Consumption Time: 3.54926
PPO Batch Consumption Time: 0.24404
Total Iteration Time: 7.92170
Cumulative Model Updates: 204
Cumulative Timesteps: 1,200,708
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1200708...
Checkpoint 1200708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.72302
Policy Entropy: 4.41702
Value Function Loss: 0.65703
Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06571
Policy Update Magnitude: 1.23781
Value Function Update Magnitude: 0.69082
Collected Steps per Second: 12,177.27282
Overall Steps per Second: 6,536.44617
Timestep Collection Time: 4.10897
Timestep Consumption Time: 3.54596
PPO Batch Consumption Time: 0.24503
Total Iteration Time: 7.65492
Cumulative Model Updates: 213
Cumulative Timesteps: 1,250,744
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.86845
Policy Entropy: 4.41244
Value Function Loss: 0.67513
Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07128
Policy Update Magnitude: 1.22222
Value Function Update Magnitude: 0.74940
Collected Steps per Second: 12,525.44403
Overall Steps per Second: 6,627.71109
Timestep Collection Time: 3.99411
Timestep Consumption Time: 3.55420
PPO Batch Consumption Time: 0.24646
Total Iteration Time: 7.54831
Cumulative Model Updates: 222
Cumulative Timesteps: 1,300,772
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1300772...
Checkpoint 1300772 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.22730
Policy Entropy: 4.40935
Value Function Loss: 0.69121
Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07846
Policy Update Magnitude: 1.20599
Value Function Update Magnitude: 0.73169
Collected Steps per Second: 11,512.56417
Overall Steps per Second: 6,362.23689
Timestep Collection Time: 4.34447
Timestep Consumption Time: 3.51692
PPO Batch Consumption Time: 0.24469
Total Iteration Time: 7.86139
Cumulative Model Updates: 231
Cumulative Timesteps: 1,350,788
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07584
Policy Entropy: 4.40797
Value Function Loss: 0.76672
Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 1.17761
Value Function Update Magnitude: 0.75579
Collected Steps per Second: 11,242.54314
Overall Steps per Second: 6,368.39159
Timestep Collection Time: 4.44810
Timestep Consumption Time: 3.40443
PPO Batch Consumption Time: 0.24389
Total Iteration Time: 7.85253
Cumulative Model Updates: 240
Cumulative Timesteps: 1,400,796
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1400796...
Checkpoint 1400796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15575
Policy Entropy: 4.40177
Value Function Loss: 0.74294
Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 1.17389
Value Function Update Magnitude: 0.67819
Collected Steps per Second: 12,182.49031
Overall Steps per Second: 6,376.26042
Timestep Collection Time: 4.10458
Timestep Consumption Time: 3.73763
PPO Batch Consumption Time: 0.25520
Total Iteration Time: 7.84221
Cumulative Model Updates: 249
Cumulative Timesteps: 1,450,800
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.50909
Policy Entropy: 4.39806
Value Function Loss: 0.73780
Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 1.14828
Value Function Update Magnitude: 0.69391
Collected Steps per Second: 12,141.02446
Overall Steps per Second: 6,467.93332
Timestep Collection Time: 4.12140
Timestep Consumption Time: 3.61492
PPO Batch Consumption Time: 0.25636
Total Iteration Time: 7.73632
Cumulative Model Updates: 258
Cumulative Timesteps: 1,500,838
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1500838...
Checkpoint 1500838 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61374
Policy Entropy: 4.39233
Value Function Loss: 0.74298
Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.08174
Policy Update Magnitude: 1.13489
Value Function Update Magnitude: 0.73471
Collected Steps per Second: 11,769.65084
Overall Steps per Second: 6,427.48814
Timestep Collection Time: 4.24889
Timestep Consumption Time: 3.53144
PPO Batch Consumption Time: 0.25560
Total Iteration Time: 7.78033
Cumulative Model Updates: 267
Cumulative Timesteps: 1,550,846
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.89586
Policy Entropy: 4.38447
Value Function Loss: 0.74367
Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 1.13110
Value Function Update Magnitude: 0.70230
Collected Steps per Second: 12,104.28621
Overall Steps per Second: 6,523.40236
Timestep Collection Time: 4.13424
Timestep Consumption Time: 3.53691
PPO Batch Consumption Time: 0.24647
Total Iteration Time: 7.67115
Cumulative Model Updates: 276
Cumulative Timesteps: 1,600,888
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1600888...
Checkpoint 1600888 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68791
Policy Entropy: 4.38217
Value Function Loss: 0.74787
Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 1.08494
Value Function Update Magnitude: 0.65514
Collected Steps per Second: 10,449.93029
Overall Steps per Second: 5,989.78143
Timestep Collection Time: 4.78491
Timestep Consumption Time: 3.56297
PPO Batch Consumption Time: 0.25079
Total Iteration Time: 8.34788
Cumulative Model Updates: 285
Cumulative Timesteps: 1,650,890
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.18405
Policy Entropy: 4.37392
Value Function Loss: 0.76434
Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 1.07580
Value Function Update Magnitude: 0.65857
Collected Steps per Second: 12,370.86216
Overall Steps per Second: 6,616.61979
Timestep Collection Time: 4.04386
Timestep Consumption Time: 3.51680
PPO Batch Consumption Time: 0.24366
Total Iteration Time: 7.56066
Cumulative Model Updates: 294
Cumulative Timesteps: 1,700,916
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1700916...
Checkpoint 1700916 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52209
Policy Entropy: 4.37579
Value Function Loss: 0.77376
Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 1.05319
Value Function Update Magnitude: 0.71296
Collected Steps per Second: 11,655.54565
Overall Steps per Second: 6,422.10946
Timestep Collection Time: 4.29100
Timestep Consumption Time: 3.49678
PPO Batch Consumption Time: 0.24409
Total Iteration Time: 7.78778
Cumulative Model Updates: 303
Cumulative Timesteps: 1,750,930
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.48276
Policy Entropy: 4.36930
Value Function Loss: 0.78518
Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09353
Policy Update Magnitude: 1.03531
Value Function Update Magnitude: 0.61184
Collected Steps per Second: 11,932.17302
Overall Steps per Second: 6,475.61045
Timestep Collection Time: 4.19303
Timestep Consumption Time: 3.53319
PPO Batch Consumption Time: 0.25305
Total Iteration Time: 7.72622
Cumulative Model Updates: 312
Cumulative Timesteps: 1,800,962
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1800962...
Checkpoint 1800962 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45679
Policy Entropy: 4.36407
Value Function Loss: 0.79547
Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 1.05844
Value Function Update Magnitude: 0.66361
Collected Steps per Second: 11,396.81002
Overall Steps per Second: 6,265.25719
Timestep Collection Time: 4.38930
Timestep Consumption Time: 3.59505
PPO Batch Consumption Time: 0.25209
Total Iteration Time: 7.98435
Cumulative Model Updates: 321
Cumulative Timesteps: 1,850,986
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.97697
Policy Entropy: 4.35612
Value Function Loss: 0.79299
Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 1.03998
Value Function Update Magnitude: 0.61607
Collected Steps per Second: 11,685.81104
Overall Steps per Second: 6,369.39066
Timestep Collection Time: 4.28092
Timestep Consumption Time: 3.57321
PPO Batch Consumption Time: 0.24901
Total Iteration Time: 7.85413
Cumulative Model Updates: 330
Cumulative Timesteps: 1,901,012
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1901012...
Checkpoint 1901012 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89595
Policy Entropy: 4.35216
Value Function Loss: 0.80673
Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 1.01790
Value Function Update Magnitude: 0.59293
Collected Steps per Second: 11,939.40480
Overall Steps per Second: 6,404.66907
Timestep Collection Time: 4.18848
Timestep Consumption Time: 3.61957
PPO Batch Consumption Time: 0.24845
Total Iteration Time: 7.80805
Cumulative Model Updates: 339
Cumulative Timesteps: 1,951,020
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.31096
Policy Entropy: 4.34862
Value Function Loss: 0.79976
Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 1.01631
Value Function Update Magnitude: 0.64002
Collected Steps per Second: 11,717.29684
Overall Steps per Second: 6,387.59691
Timestep Collection Time: 4.26737
Timestep Consumption Time: 3.56062
PPO Batch Consumption Time: 0.24822
Total Iteration Time: 7.82798
Cumulative Model Updates: 348
Cumulative Timesteps: 2,001,022
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 2001022...
Checkpoint 2001022 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.98407
Policy Entropy: 4.34828
Value Function Loss: 0.83313
Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.95279
Value Function Update Magnitude: 0.72956
Collected Steps per Second: 11,768.54185
Overall Steps per Second: 6,453.33048
Timestep Collection Time: 4.25048
Timestep Consumption Time: 3.50086
PPO Batch Consumption Time: 0.24900
Total Iteration Time: 7.75135
Cumulative Model Updates: 357
Cumulative Timesteps: 2,051,044
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.14161
Policy Entropy: 4.33786
Value Function Loss: 0.83846
Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.97414
Value Function Update Magnitude: 0.73291
Collected Steps per Second: 11,871.82887
Overall Steps per Second: 6,425.35872
Timestep Collection Time: 4.21317
Timestep Consumption Time: 3.57130
PPO Batch Consumption Time: 0.24827
Total Iteration Time: 7.78447
Cumulative Model Updates: 366
Cumulative Timesteps: 2,101,062
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 2101062...
Checkpoint 2101062 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32217
Policy Entropy: 4.33566
Value Function Loss: 0.83395
Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.95363
Value Function Update Magnitude: 0.63949
Collected Steps per Second: 11,730.39587
Overall Steps per Second: 6,341.92348
Timestep Collection Time: 4.26516
Timestep Consumption Time: 3.62393
PPO Batch Consumption Time: 0.25376
Total Iteration Time: 7.88909
Cumulative Model Updates: 375
Cumulative Timesteps: 2,151,094
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.39514
Policy Entropy: 4.32921
Value Function Loss: 0.85726
Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.96794
Value Function Update Magnitude: 0.64389
Collected Steps per Second: 12,140.32432
Overall Steps per Second: 6,471.92003
Timestep Collection Time: 4.11966
Timestep Consumption Time: 3.60819
PPO Batch Consumption Time: 0.24894
Total Iteration Time: 7.72785
Cumulative Model Updates: 384
Cumulative Timesteps: 2,201,108
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 2201108...
Checkpoint 2201108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.47909
Policy Entropy: 4.32018
Value Function Loss: 0.88056
Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.98976
Value Function Update Magnitude: 0.73739
Collected Steps per Second: 11,918.83728
Overall Steps per Second: 6,423.36887
Timestep Collection Time: 4.19789
Timestep Consumption Time: 3.59148
PPO Batch Consumption Time: 0.24828
Total Iteration Time: 7.78937
Cumulative Model Updates: 393
Cumulative Timesteps: 2,251,142
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56900
Policy Entropy: 4.31552
Value Function Loss: 0.91366
Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.97618
Value Function Update Magnitude: 0.72939
Collected Steps per Second: 11,927.78331
Overall Steps per Second: 6,555.17176
Timestep Collection Time: 4.19206
Timestep Consumption Time: 3.43581
PPO Batch Consumption Time: 0.24851
Total Iteration Time: 7.62787
Cumulative Model Updates: 402
Cumulative Timesteps: 2,301,144
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 2301144...
Checkpoint 2301144 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64876
Policy Entropy: 4.32262
Value Function Loss: 0.91653
Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.21915
Policy Update Magnitude: 0.86512
Value Function Update Magnitude: 0.74363
Collected Steps per Second: 11,853.94500
Overall Steps per Second: 6,408.47081
Timestep Collection Time: 4.21834
Timestep Consumption Time: 3.58445
PPO Batch Consumption Time: 0.25048
Total Iteration Time: 7.80280
Cumulative Model Updates: 411
Cumulative Timesteps: 2,351,148
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.84788
Policy Entropy: 4.31099
Value Function Loss: 0.96755
Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.79457
Value Function Update Magnitude: 0.57404
Collected Steps per Second: 11,142.22880
Overall Steps per Second: 6,277.83378
Timestep Collection Time: 4.48959
Timestep Consumption Time: 3.47877
PPO Batch Consumption Time: 0.24465
Total Iteration Time: 7.96835
Cumulative Model Updates: 420
Cumulative Timesteps: 2,401,172
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 2401172...
Checkpoint 2401172 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75887
Policy Entropy: 4.31264
Value Function Loss: 0.96831
Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.82273
Value Function Update Magnitude: 0.50801
Collected Steps per Second: 11,890.90756
Overall Steps per Second: 6,435.35385
Timestep Collection Time: 4.20523
Timestep Consumption Time: 3.56497
PPO Batch Consumption Time: 0.24670
Total Iteration Time: 7.77020
Cumulative Model Updates: 429
Cumulative Timesteps: 2,451,176
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.99974
Policy Entropy: 4.30098
Value Function Loss: 1.01817
Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.11122
Policy Update Magnitude: 0.84750
Value Function Update Magnitude: 0.60711
Collected Steps per Second: 12,086.17452
Overall Steps per Second: 6,427.30756
Timestep Collection Time: 4.13696
Timestep Consumption Time: 3.64235
PPO Batch Consumption Time: 0.25323
Total Iteration Time: 7.77931
Cumulative Model Updates: 438
Cumulative Timesteps: 2,501,176
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 2501176...
Checkpoint 2501176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38642
Policy Entropy: 4.29140
Value Function Loss: 1.06039
Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.85647
Value Function Update Magnitude: 0.66969
Collected Steps per Second: 11,373.84590
Overall Steps per Second: 6,366.88037
Timestep Collection Time: 4.39640
Timestep Consumption Time: 3.45737
PPO Batch Consumption Time: 0.24576
Total Iteration Time: 7.85377
Cumulative Model Updates: 447
Cumulative Timesteps: 2,551,180
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.64632
Policy Entropy: 4.27738
Value Function Loss: 1.04612
Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.88575
Value Function Update Magnitude: 0.48231
Collected Steps per Second: 11,966.37128
Overall Steps per Second: 6,502.78646
Timestep Collection Time: 4.17971
Timestep Consumption Time: 3.51176
PPO Batch Consumption Time: 0.24462
Total Iteration Time: 7.69147
Cumulative Model Updates: 456
Cumulative Timesteps: 2,601,196
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 2601196...
Checkpoint 2601196 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.63017
Policy Entropy: 4.26948
Value Function Loss: 0.95886
Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.89421
Value Function Update Magnitude: 0.51935
Collected Steps per Second: 11,585.85442
Overall Steps per Second: 6,425.07818
Timestep Collection Time: 4.31716
Timestep Consumption Time: 3.46765
PPO Batch Consumption Time: 0.24303
Total Iteration Time: 7.78481
Cumulative Model Updates: 465
Cumulative Timesteps: 2,651,214
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.86209
Policy Entropy: 4.26013
Value Function Loss: 0.94106
Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.87227
Value Function Update Magnitude: 0.56475
Collected Steps per Second: 12,000.94940
Overall Steps per Second: 6,568.66475
Timestep Collection Time: 4.16684
Timestep Consumption Time: 3.44597
PPO Batch Consumption Time: 0.24822
Total Iteration Time: 7.61281
Cumulative Model Updates: 474
Cumulative Timesteps: 2,701,220
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 2701220...
Checkpoint 2701220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.00376
Policy Entropy: 4.25423
Value Function Loss: 0.92127
Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.85520
Value Function Update Magnitude: 0.57546
Collected Steps per Second: 11,589.71518
Overall Steps per Second: 6,359.96057
Timestep Collection Time: 4.31452
Timestep Consumption Time: 3.54780
PPO Batch Consumption Time: 0.24675
Total Iteration Time: 7.86231
Cumulative Model Updates: 483
Cumulative Timesteps: 2,751,224
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.95324
Policy Entropy: 4.24494
Value Function Loss: 0.92346
Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.85353
Value Function Update Magnitude: 0.65956
Collected Steps per Second: 12,300.37954
Overall Steps per Second: 6,669.19858
Timestep Collection Time: 4.06589
Timestep Consumption Time: 3.43306
PPO Batch Consumption Time: 0.24519
Total Iteration Time: 7.49895
Cumulative Model Updates: 492
Cumulative Timesteps: 2,801,236
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 2801236...
Checkpoint 2801236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.59999
Policy Entropy: 4.23058
Value Function Loss: 0.92343
Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.86845
Value Function Update Magnitude: 0.63393
Collected Steps per Second: 12,236.77130
Overall Steps per Second: 6,544.84931
Timestep Collection Time: 4.08899
Timestep Consumption Time: 3.55611
PPO Batch Consumption Time: 0.24510
Total Iteration Time: 7.64510
Cumulative Model Updates: 501
Cumulative Timesteps: 2,851,272
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.92841
Policy Entropy: 4.22355
Value Function Loss: 0.93999
Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.15622
Policy Update Magnitude: 0.83254
Value Function Update Magnitude: 0.64289
Collected Steps per Second: 12,335.50858
Overall Steps per Second: 6,626.00010
Timestep Collection Time: 4.05739
Timestep Consumption Time: 3.49618
PPO Batch Consumption Time: 0.24416
Total Iteration Time: 7.55358
Cumulative Model Updates: 510
Cumulative Timesteps: 2,901,322
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 2901322...
Checkpoint 2901322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51790
Policy Entropy: 4.22118
Value Function Loss: 0.92726
Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.16335
Policy Update Magnitude: 0.79227
Value Function Update Magnitude: 0.71081
Collected Steps per Second: 12,127.37379
Overall Steps per Second: 6,643.28036
Timestep Collection Time: 4.12521
Timestep Consumption Time: 3.40540
PPO Batch Consumption Time: 0.24351
Total Iteration Time: 7.53062
Cumulative Model Updates: 519
Cumulative Timesteps: 2,951,350
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.81591
Policy Entropy: 4.21212
Value Function Loss: 0.96566
Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.77490
Value Function Update Magnitude: 0.58474
Collected Steps per Second: 12,351.42667
Overall Steps per Second: 6,632.53035
Timestep Collection Time: 4.05103
Timestep Consumption Time: 3.49300
PPO Batch Consumption Time: 0.24346
Total Iteration Time: 7.54403
Cumulative Model Updates: 528
Cumulative Timesteps: 3,001,386
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 3001386...
Checkpoint 3001386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.34013
Policy Entropy: 4.20745
Value Function Loss: 0.91680
Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.75894
Value Function Update Magnitude: 0.48931
Collected Steps per Second: 12,319.56260
Overall Steps per Second: 6,647.58808
Timestep Collection Time: 4.05988
Timestep Consumption Time: 3.46405
PPO Batch Consumption Time: 0.24234
Total Iteration Time: 7.52393
Cumulative Model Updates: 537
Cumulative Timesteps: 3,051,402
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.94037
Policy Entropy: 4.19976
Value Function Loss: 0.98911
Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.75780
Value Function Update Magnitude: 0.53673
Collected Steps per Second: 12,608.41577
Overall Steps per Second: 6,590.40121
Timestep Collection Time: 3.96910
Timestep Consumption Time: 3.62437
PPO Batch Consumption Time: 0.25195
Total Iteration Time: 7.59347
Cumulative Model Updates: 546
Cumulative Timesteps: 3,101,446
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 3101446...
Checkpoint 3101446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.50919
Policy Entropy: 4.18786
Value Function Loss: 0.97768
Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.77586
Value Function Update Magnitude: 0.48581
Collected Steps per Second: 12,153.12884
Overall Steps per Second: 6,568.71434
Timestep Collection Time: 4.11548
Timestep Consumption Time: 3.49879
PPO Batch Consumption Time: 0.24325
Total Iteration Time: 7.61428
Cumulative Model Updates: 555
Cumulative Timesteps: 3,151,462
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.46979
Policy Entropy: 4.17820
Value Function Loss: 0.97316
Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11594
Policy Update Magnitude: 0.78939
Value Function Update Magnitude: 0.62351
Collected Steps per Second: 12,048.16289
Overall Steps per Second: 6,621.68532
Timestep Collection Time: 4.15233
Timestep Consumption Time: 3.40284
PPO Batch Consumption Time: 0.24282
Total Iteration Time: 7.55518
Cumulative Model Updates: 564
Cumulative Timesteps: 3,201,490
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 3201490...
Checkpoint 3201490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.86601
Policy Entropy: 4.16959
Value Function Loss: 0.98705
Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.77661
Value Function Update Magnitude: 0.66346
Collected Steps per Second: 12,119.33878
Overall Steps per Second: 6,566.82840
Timestep Collection Time: 4.12679
Timestep Consumption Time: 3.48936
PPO Batch Consumption Time: 0.24309
Total Iteration Time: 7.61616
Cumulative Model Updates: 573
Cumulative Timesteps: 3,251,504
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.44147
Policy Entropy: 4.16120
Value Function Loss: 0.96481
Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.74435
Value Function Update Magnitude: 0.53295
Collected Steps per Second: 12,174.83497
Overall Steps per Second: 6,630.20992
Timestep Collection Time: 4.10897
Timestep Consumption Time: 3.43619
PPO Batch Consumption Time: 0.24309
Total Iteration Time: 7.54516
Cumulative Model Updates: 582
Cumulative Timesteps: 3,301,530
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 3301530...
Checkpoint 3301530 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.58109
Policy Entropy: 4.15474
Value Function Loss: 0.95947
Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.71350
Value Function Update Magnitude: 0.49340
Collected Steps per Second: 12,327.53536
Overall Steps per Second: 6,633.27980
Timestep Collection Time: 4.05645
Timestep Consumption Time: 3.48221
PPO Batch Consumption Time: 0.24314
Total Iteration Time: 7.53865
Cumulative Model Updates: 591
Cumulative Timesteps: 3,351,536
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.60328
Policy Entropy: 4.13988
Value Function Loss: 0.96848
Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.72619
Value Function Update Magnitude: 0.67089
Collected Steps per Second: 12,189.01972
Overall Steps per Second: 6,490.55164
Timestep Collection Time: 4.10386
Timestep Consumption Time: 3.60304
PPO Batch Consumption Time: 0.25061
Total Iteration Time: 7.70690
Cumulative Model Updates: 600
Cumulative Timesteps: 3,401,558
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 3401558...
Checkpoint 3401558 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.40630
Policy Entropy: 4.13309
Value Function Loss: 0.93281
Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.11514
Policy Update Magnitude: 0.72026
Value Function Update Magnitude: 0.56520
Collected Steps per Second: 12,136.23014
Overall Steps per Second: 6,585.15094
Timestep Collection Time: 4.12006
Timestep Consumption Time: 3.47308
PPO Batch Consumption Time: 0.24378
Total Iteration Time: 7.59314
Cumulative Model Updates: 609
Cumulative Timesteps: 3,451,560
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.28810
Policy Entropy: 4.12464
Value Function Loss: 0.99588
Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10590
Policy Update Magnitude: 0.73726
Value Function Update Magnitude: 0.51642
Collected Steps per Second: 12,640.17425
Overall Steps per Second: 6,711.56423
Timestep Collection Time: 3.95643
Timestep Consumption Time: 3.49489
PPO Batch Consumption Time: 0.24340
Total Iteration Time: 7.45132
Cumulative Model Updates: 618
Cumulative Timesteps: 3,501,570
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 3501570...
Checkpoint 3501570 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.39353
Policy Entropy: 4.11918
Value Function Loss: 1.04023
Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.73038
Value Function Update Magnitude: 0.52858
Collected Steps per Second: 11,541.26175
Overall Steps per Second: 6,346.19982
Timestep Collection Time: 4.33332
Timestep Consumption Time: 3.54730
PPO Batch Consumption Time: 0.24486
Total Iteration Time: 7.88062
Cumulative Model Updates: 627
Cumulative Timesteps: 3,551,582
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.59869
Policy Entropy: 4.11105
Value Function Loss: 1.02796
Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.75258
Value Function Update Magnitude: 0.50080
Collected Steps per Second: 12,006.42788
Overall Steps per Second: 6,605.03569
Timestep Collection Time: 4.16560
Timestep Consumption Time: 3.40650
PPO Batch Consumption Time: 0.24307
Total Iteration Time: 7.57210
Cumulative Model Updates: 636
Cumulative Timesteps: 3,601,596
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 3601596...
Checkpoint 3601596 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.50181
Policy Entropy: 4.10229
Value Function Loss: 1.00592
Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.75732
Value Function Update Magnitude: 0.58158
Collected Steps per Second: 11,799.77663
Overall Steps per Second: 6,444.82001
Timestep Collection Time: 4.23889
Timestep Consumption Time: 3.52207
PPO Batch Consumption Time: 0.24562
Total Iteration Time: 7.76096
Cumulative Model Updates: 645
Cumulative Timesteps: 3,651,614
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.95852
Policy Entropy: 4.09334
Value Function Loss: 0.99256
Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.75350
Value Function Update Magnitude: 0.65073
Collected Steps per Second: 12,134.72519
Overall Steps per Second: 6,420.25062
Timestep Collection Time: 4.12189
Timestep Consumption Time: 3.66877
PPO Batch Consumption Time: 0.25703
Total Iteration Time: 7.79066
Cumulative Model Updates: 654
Cumulative Timesteps: 3,701,632
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 3701632...
Checkpoint 3701632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.18305
Policy Entropy: 4.08683
Value Function Loss: 1.04285
Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.77954
Value Function Update Magnitude: 0.49403
Collected Steps per Second: 11,783.31200
Overall Steps per Second: 6,436.43773
Timestep Collection Time: 4.24516
Timestep Consumption Time: 3.52653
PPO Batch Consumption Time: 0.24792
Total Iteration Time: 7.77169
Cumulative Model Updates: 663
Cumulative Timesteps: 3,751,654
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.06391
Policy Entropy: 4.07594
Value Function Loss: 1.10202
Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.78396
Value Function Update Magnitude: 0.46251
Collected Steps per Second: 12,200.94008
Overall Steps per Second: 6,583.41846
Timestep Collection Time: 4.09821
Timestep Consumption Time: 3.49693
PPO Batch Consumption Time: 0.24307
Total Iteration Time: 7.59514
Cumulative Model Updates: 672
Cumulative Timesteps: 3,801,656
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 3801656...
Checkpoint 3801656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.26851
Policy Entropy: 4.05893
Value Function Loss: 1.20115
Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.77105
Value Function Update Magnitude: 0.42735
Collected Steps per Second: 11,404.75855
Overall Steps per Second: 6,330.94653
Timestep Collection Time: 4.38413
Timestep Consumption Time: 3.51358
PPO Batch Consumption Time: 0.24450
Total Iteration Time: 7.89771
Cumulative Model Updates: 681
Cumulative Timesteps: 3,851,656
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.26115
Policy Entropy: 4.04970
Value Function Loss: 1.17373
Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.17095
Policy Update Magnitude: 0.73451
Value Function Update Magnitude: 0.38879
Collected Steps per Second: 11,764.90016
Overall Steps per Second: 6,392.17375
Timestep Collection Time: 4.25112
Timestep Consumption Time: 3.57314
PPO Batch Consumption Time: 0.24879
Total Iteration Time: 7.82426
Cumulative Model Updates: 690
Cumulative Timesteps: 3,901,670
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 3901670...
Checkpoint 3901670 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.97107
Policy Entropy: 4.04131
Value Function Loss: 1.15162
Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.17971
Policy Update Magnitude: 0.69487
Value Function Update Magnitude: 0.37369
Collected Steps per Second: 11,798.24251
Overall Steps per Second: 6,489.58011
Timestep Collection Time: 4.24063
Timestep Consumption Time: 3.46896
PPO Batch Consumption Time: 0.24284
Total Iteration Time: 7.70959
Cumulative Model Updates: 699
Cumulative Timesteps: 3,951,702
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.65481
Policy Entropy: 4.03360
Value Function Loss: 1.09933
Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.67605
Value Function Update Magnitude: 0.36212
Collected Steps per Second: 11,908.43621
Overall Steps per Second: 6,510.55026
Timestep Collection Time: 4.19904
Timestep Consumption Time: 3.48142
PPO Batch Consumption Time: 0.25118
Total Iteration Time: 7.68046
Cumulative Model Updates: 708
Cumulative Timesteps: 4,001,706
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 4001706...
Checkpoint 4001706 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.94130
Policy Entropy: 4.02304
Value Function Loss: 1.11949
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.68110
Value Function Update Magnitude: 0.43370
Collected Steps per Second: 12,292.24831
Overall Steps per Second: 6,601.87808
Timestep Collection Time: 4.07037
Timestep Consumption Time: 3.50838
PPO Batch Consumption Time: 0.24358
Total Iteration Time: 7.57875
Cumulative Model Updates: 717
Cumulative Timesteps: 4,051,740
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56795
Policy Entropy: 4.02093
Value Function Loss: 1.12553
Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.68860
Value Function Update Magnitude: 0.42535
Collected Steps per Second: 12,369.28124
Overall Steps per Second: 6,665.37368
Timestep Collection Time: 4.04340
Timestep Consumption Time: 3.46015
PPO Batch Consumption Time: 0.24380
Total Iteration Time: 7.50356
Cumulative Model Updates: 726
Cumulative Timesteps: 4,101,754
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 4101754...
Checkpoint 4101754 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.44036
Policy Entropy: 4.00698
Value Function Loss: 1.12292
Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.71058
Value Function Update Magnitude: 0.43249
Collected Steps per Second: 12,293.79440
Overall Steps per Second: 6,570.08903
Timestep Collection Time: 4.06791
Timestep Consumption Time: 3.54386
PPO Batch Consumption Time: 0.24386
Total Iteration Time: 7.61177
Cumulative Model Updates: 735
Cumulative Timesteps: 4,151,764
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.82012
Policy Entropy: 3.99520
Value Function Loss: 1.11971
Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.71852
Value Function Update Magnitude: 0.44239
Collected Steps per Second: 12,313.53337
Overall Steps per Second: 6,581.84707
Timestep Collection Time: 4.06122
Timestep Consumption Time: 3.53664
PPO Batch Consumption Time: 0.24366
Total Iteration Time: 7.59787
Cumulative Model Updates: 744
Cumulative Timesteps: 4,201,772
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 4201772...
Checkpoint 4201772 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.82668
Policy Entropy: 3.98744
Value Function Loss: 1.15650
Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.72397
Value Function Update Magnitude: 0.48368
Collected Steps per Second: 12,258.37052
Overall Steps per Second: 6,696.57952
Timestep Collection Time: 4.08113
Timestep Consumption Time: 3.38955
PPO Batch Consumption Time: 0.24376
Total Iteration Time: 7.47068
Cumulative Model Updates: 753
Cumulative Timesteps: 4,251,800
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.29615
Policy Entropy: 3.98975
Value Function Loss: 1.03757
Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.71956
Value Function Update Magnitude: 0.43377
Collected Steps per Second: 12,312.01757
Overall Steps per Second: 6,540.88917
Timestep Collection Time: 4.06286
Timestep Consumption Time: 3.58472
PPO Batch Consumption Time: 0.25122
Total Iteration Time: 7.64758
Cumulative Model Updates: 762
Cumulative Timesteps: 4,301,822
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 4301822...
Checkpoint 4301822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.94268
Policy Entropy: 3.99570
Value Function Loss: 0.64206
Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.70142
Value Function Update Magnitude: 0.41670
Collected Steps per Second: 12,071.16334
Overall Steps per Second: 6,566.04128
Timestep Collection Time: 4.14359
Timestep Consumption Time: 3.47409
PPO Batch Consumption Time: 0.24571
Total Iteration Time: 7.61768
Cumulative Model Updates: 771
Cumulative Timesteps: 4,351,840
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.88977
Policy Entropy: 3.99865
Value Function Loss: 0.50590
Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.66032
Value Function Update Magnitude: 0.53131
Collected Steps per Second: 11,721.38243
Overall Steps per Second: 6,306.51096
Timestep Collection Time: 4.26605
Timestep Consumption Time: 3.66290
PPO Batch Consumption Time: 0.24880
Total Iteration Time: 7.92895
Cumulative Model Updates: 780
Cumulative Timesteps: 4,401,844
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 4401844...
Checkpoint 4401844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.43959
Policy Entropy: 4.00777
Value Function Loss: 0.46080
Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12257
Policy Update Magnitude: 0.61772
Value Function Update Magnitude: 0.50819
Collected Steps per Second: 10,807.02545
Overall Steps per Second: 6,151.32387
Timestep Collection Time: 4.63236
Timestep Consumption Time: 3.50605
PPO Batch Consumption Time: 0.24391
Total Iteration Time: 8.13841
Cumulative Model Updates: 789
Cumulative Timesteps: 4,451,906
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.03207
Policy Entropy: 4.01112
Value Function Loss: 0.42510
Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.57198
Value Function Update Magnitude: 0.42743
Collected Steps per Second: 11,917.90488
Overall Steps per Second: 6,449.28793
Timestep Collection Time: 4.19570
Timestep Consumption Time: 3.55771
PPO Batch Consumption Time: 0.25115
Total Iteration Time: 7.75341
Cumulative Model Updates: 798
Cumulative Timesteps: 4,501,910
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 4501910...
Checkpoint 4501910 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.44569
Policy Entropy: 4.01612
Value Function Loss: 0.44203
Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.54093
Value Function Update Magnitude: 0.38420
Collected Steps per Second: 12,395.18602
Overall Steps per Second: 6,586.56646
Timestep Collection Time: 4.03415
Timestep Consumption Time: 3.55767
PPO Batch Consumption Time: 0.24795
Total Iteration Time: 7.59182
Cumulative Model Updates: 807
Cumulative Timesteps: 4,551,914
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.09441
Policy Entropy: 4.01375
Value Function Loss: 0.35720
Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.50830
Value Function Update Magnitude: 0.29288
Collected Steps per Second: 11,707.68036
Overall Steps per Second: 6,311.24494
Timestep Collection Time: 4.27429
Timestep Consumption Time: 3.65473
PPO Batch Consumption Time: 0.24828
Total Iteration Time: 7.92902
Cumulative Model Updates: 816
Cumulative Timesteps: 4,601,956
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 4601956...
Checkpoint 4601956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.70957
Policy Entropy: 4.01403
Value Function Loss: 0.27470
Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.47698
Value Function Update Magnitude: 0.26671
Collected Steps per Second: 11,844.78417
Overall Steps per Second: 6,547.67312
Timestep Collection Time: 4.22329
Timestep Consumption Time: 3.41667
PPO Batch Consumption Time: 0.24289
Total Iteration Time: 7.63997
Cumulative Model Updates: 825
Cumulative Timesteps: 4,651,980
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.48430
Policy Entropy: 4.02401
Value Function Loss: 0.24986
Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.45365
Value Function Update Magnitude: 0.46797
Collected Steps per Second: 12,287.62196
Overall Steps per Second: 6,595.23538
Timestep Collection Time: 4.06962
Timestep Consumption Time: 3.51252
PPO Batch Consumption Time: 0.24296
Total Iteration Time: 7.58214
Cumulative Model Updates: 834
Cumulative Timesteps: 4,701,986
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 4701986...
Checkpoint 4701986 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.18386
Policy Entropy: 4.02654
Value Function Loss: 0.23127
Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.42982
Value Function Update Magnitude: 0.47394
Collected Steps per Second: 12,055.92513
Overall Steps per Second: 6,564.21583
Timestep Collection Time: 4.14983
Timestep Consumption Time: 3.47180
PPO Batch Consumption Time: 0.24318
Total Iteration Time: 7.62163
Cumulative Model Updates: 843
Cumulative Timesteps: 4,752,016
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.41363
Policy Entropy: 4.03325
Value Function Loss: 0.20074
Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06717
Policy Update Magnitude: 0.41528
Value Function Update Magnitude: 0.56149
Collected Steps per Second: 12,678.26947
Overall Steps per Second: 6,711.05447
Timestep Collection Time: 3.94470
Timestep Consumption Time: 3.50748
PPO Batch Consumption Time: 0.24341
Total Iteration Time: 7.45218
Cumulative Model Updates: 852
Cumulative Timesteps: 4,802,028
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 4802028...
Checkpoint 4802028 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.09768
Policy Entropy: 4.03499
Value Function Loss: 0.19940
Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07231
Policy Update Magnitude: 0.40540
Value Function Update Magnitude: 0.64417
Collected Steps per Second: 12,366.71026
Overall Steps per Second: 6,590.32967
Timestep Collection Time: 4.04554
Timestep Consumption Time: 3.54589
PPO Batch Consumption Time: 0.24336
Total Iteration Time: 7.59143
Cumulative Model Updates: 861
Cumulative Timesteps: 4,852,058
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.73727
Policy Entropy: 4.03238
Value Function Loss: 0.20628
Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.39686
Value Function Update Magnitude: 0.50700
Collected Steps per Second: 12,227.43738
Overall Steps per Second: 6,599.85990
Timestep Collection Time: 4.09096
Timestep Consumption Time: 3.48829
PPO Batch Consumption Time: 0.24577
Total Iteration Time: 7.57925
Cumulative Model Updates: 870
Cumulative Timesteps: 4,902,080
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 4902080...
Checkpoint 4902080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.55014
Policy Entropy: 4.02964
Value Function Loss: 0.19526
Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06880
Policy Update Magnitude: 0.40495
Value Function Update Magnitude: 0.42453
Collected Steps per Second: 12,002.04547
Overall Steps per Second: 6,510.46607
Timestep Collection Time: 4.16746
Timestep Consumption Time: 3.51525
PPO Batch Consumption Time: 0.24413
Total Iteration Time: 7.68271
Cumulative Model Updates: 879
Cumulative Timesteps: 4,952,098
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57399
Policy Entropy: 4.02467
Value Function Loss: 0.19769
Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06786
Policy Update Magnitude: 0.40280
Value Function Update Magnitude: 0.44891
Collected Steps per Second: 12,298.02328
Overall Steps per Second: 6,634.39592
Timestep Collection Time: 4.06602
Timestep Consumption Time: 3.47106
PPO Batch Consumption Time: 0.24284
Total Iteration Time: 7.53708
Cumulative Model Updates: 888
Cumulative Timesteps: 5,002,102
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 5002102...
Checkpoint 5002102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.26006
Policy Entropy: 4.02379
Value Function Loss: 0.19714
Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06782
Policy Update Magnitude: 0.40238
Value Function Update Magnitude: 0.51611
Collected Steps per Second: 12,492.90278
Overall Steps per Second: 6,628.15233
Timestep Collection Time: 4.00227
Timestep Consumption Time: 3.54131
PPO Batch Consumption Time: 0.24316
Total Iteration Time: 7.54358
Cumulative Model Updates: 897
Cumulative Timesteps: 5,052,102
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46046
Policy Entropy: 4.02768
Value Function Loss: 0.19753
Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06262
Policy Update Magnitude: 0.41320
Value Function Update Magnitude: 0.51382
Collected Steps per Second: 12,266.95105
Overall Steps per Second: 6,606.57714
Timestep Collection Time: 4.07616
Timestep Consumption Time: 3.49236
PPO Batch Consumption Time: 0.24282
Total Iteration Time: 7.56852
Cumulative Model Updates: 906
Cumulative Timesteps: 5,102,104
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 5102104...
Checkpoint 5102104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.49121
Policy Entropy: 4.02164
Value Function Loss: 0.20973
Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06272
Policy Update Magnitude: 0.41805
Value Function Update Magnitude: 0.41861
Collected Steps per Second: 11,948.43225
Overall Steps per Second: 6,561.33822
Timestep Collection Time: 4.18482
Timestep Consumption Time: 3.43588
PPO Batch Consumption Time: 0.24375
Total Iteration Time: 7.62070
Cumulative Model Updates: 915
Cumulative Timesteps: 5,152,106
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.84641
Policy Entropy: 4.02248
Value Function Loss: 0.19458
Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06139
Policy Update Magnitude: 0.42804
Value Function Update Magnitude: 0.45907
Collected Steps per Second: 12,280.80691
Overall Steps per Second: 6,498.41539
Timestep Collection Time: 4.07253
Timestep Consumption Time: 3.62380
PPO Batch Consumption Time: 0.25110
Total Iteration Time: 7.69634
Cumulative Model Updates: 924
Cumulative Timesteps: 5,202,120
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 5202120...
Checkpoint 5202120 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.42448
Policy Entropy: 4.01404
Value Function Loss: 0.19592
Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06408
Policy Update Magnitude: 0.42225
Value Function Update Magnitude: 0.49821
Collected Steps per Second: 12,211.84519
Overall Steps per Second: 6,611.60398
Timestep Collection Time: 4.09602
Timestep Consumption Time: 3.46946
PPO Batch Consumption Time: 0.24362
Total Iteration Time: 7.56549
Cumulative Model Updates: 933
Cumulative Timesteps: 5,252,140
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.04768
Policy Entropy: 4.01311
Value Function Loss: 0.18855
Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05983
Policy Update Magnitude: 0.42077
Value Function Update Magnitude: 0.47636
Collected Steps per Second: 12,421.44505
Overall Steps per Second: 6,656.34612
Timestep Collection Time: 4.02723
Timestep Consumption Time: 3.48801
PPO Batch Consumption Time: 0.24244
Total Iteration Time: 7.51523
Cumulative Model Updates: 942
Cumulative Timesteps: 5,302,164
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 5302164...
Checkpoint 5302164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.49750
Policy Entropy: 4.01718
Value Function Loss: 0.18525
Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06564
Policy Update Magnitude: 0.41783
Value Function Update Magnitude: 0.45896
Collected Steps per Second: 12,147.34396
Overall Steps per Second: 6,562.64192
Timestep Collection Time: 4.11744
Timestep Consumption Time: 3.50388
PPO Batch Consumption Time: 0.24348
Total Iteration Time: 7.62132
Cumulative Model Updates: 951
Cumulative Timesteps: 5,352,180
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.27083
Policy Entropy: 4.02232
Value Function Loss: 0.18529
Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.40979
Value Function Update Magnitude: 0.47696
Collected Steps per Second: 12,165.83219
Overall Steps per Second: 6,659.44989
Timestep Collection Time: 4.11069
Timestep Consumption Time: 3.39894
PPO Batch Consumption Time: 0.24300
Total Iteration Time: 7.50963
Cumulative Model Updates: 960
Cumulative Timesteps: 5,402,190
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 5402190...
Checkpoint 5402190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.15416
Policy Entropy: 4.02542
Value Function Loss: 0.19133
Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06748
Policy Update Magnitude: 0.41373
Value Function Update Magnitude: 0.57933
Collected Steps per Second: 12,406.77952
Overall Steps per Second: 6,666.43517
Timestep Collection Time: 4.03086
Timestep Consumption Time: 3.47090
PPO Batch Consumption Time: 0.24279
Total Iteration Time: 7.50176
Cumulative Model Updates: 969
Cumulative Timesteps: 5,452,200
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.97301
Policy Entropy: 4.02360
Value Function Loss: 0.19903
Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.42611
Value Function Update Magnitude: 0.59996
Collected Steps per Second: 12,269.81527
Overall Steps per Second: 6,566.47139
Timestep Collection Time: 4.07749
Timestep Consumption Time: 3.54152
PPO Batch Consumption Time: 0.25013
Total Iteration Time: 7.61901
Cumulative Model Updates: 978
Cumulative Timesteps: 5,502,230
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 5502230...
Checkpoint 5502230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.39065
Policy Entropy: 4.02201
Value Function Loss: 0.19818
Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06718
Policy Update Magnitude: 0.43341
Value Function Update Magnitude: 0.60617
Collected Steps per Second: 12,221.26083
Overall Steps per Second: 6,650.02061
Timestep Collection Time: 4.09221
Timestep Consumption Time: 3.42837
PPO Batch Consumption Time: 0.24737
Total Iteration Time: 7.52058
Cumulative Model Updates: 987
Cumulative Timesteps: 5,552,242
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.39325
Policy Entropy: 4.01791
Value Function Loss: 0.18943
Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.41988
Value Function Update Magnitude: 0.54863
Collected Steps per Second: 12,268.46336
Overall Steps per Second: 6,558.10516
Timestep Collection Time: 4.07614
Timestep Consumption Time: 3.54923
PPO Batch Consumption Time: 0.24701
Total Iteration Time: 7.62537
Cumulative Model Updates: 996
Cumulative Timesteps: 5,602,250
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 5602250...
Checkpoint 5602250 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.52226
Policy Entropy: 4.01352
Value Function Loss: 0.19134
Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06581
Policy Update Magnitude: 0.41527
Value Function Update Magnitude: 0.49596
Collected Steps per Second: 12,195.61892
Overall Steps per Second: 6,608.57173
Timestep Collection Time: 4.10049
Timestep Consumption Time: 3.46665
PPO Batch Consumption Time: 0.24313
Total Iteration Time: 7.56714
Cumulative Model Updates: 1,005
Cumulative Timesteps: 5,652,258
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.35530
Policy Entropy: 4.01197
Value Function Loss: 0.18517
Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06272
Policy Update Magnitude: 0.41470
Value Function Update Magnitude: 0.48497
Collected Steps per Second: 12,571.91166
Overall Steps per Second: 6,697.52900
Timestep Collection Time: 3.97919
Timestep Consumption Time: 3.49013
PPO Batch Consumption Time: 0.24295
Total Iteration Time: 7.46932
Cumulative Model Updates: 1,014
Cumulative Timesteps: 5,702,284
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 5702284...
Checkpoint 5702284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.62586
Policy Entropy: 4.01657
Value Function Loss: 0.19503
Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06553
Policy Update Magnitude: 0.42565
Value Function Update Magnitude: 0.47447
Collected Steps per Second: 12,087.19684
Overall Steps per Second: 6,574.04892
Timestep Collection Time: 4.13661
Timestep Consumption Time: 3.46905
PPO Batch Consumption Time: 0.24260
Total Iteration Time: 7.60566
Cumulative Model Updates: 1,023
Cumulative Timesteps: 5,752,284
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.32512
Policy Entropy: 4.00719
Value Function Loss: 0.19028
Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06682
Policy Update Magnitude: 0.43451
Value Function Update Magnitude: 0.54274
Collected Steps per Second: 12,177.77832
Overall Steps per Second: 6,563.41642
Timestep Collection Time: 4.10666
Timestep Consumption Time: 3.51285
PPO Batch Consumption Time: 0.25213
Total Iteration Time: 7.61951
Cumulative Model Updates: 1,032
Cumulative Timesteps: 5,802,294
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 5802294...
Checkpoint 5802294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68626
Policy Entropy: 4.01056
Value Function Loss: 0.19102
Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06932
Policy Update Magnitude: 0.43762
Value Function Update Magnitude: 0.57012
Collected Steps per Second: 12,087.51453
Overall Steps per Second: 6,506.82240
Timestep Collection Time: 4.13931
Timestep Consumption Time: 3.55016
PPO Batch Consumption Time: 0.24682
Total Iteration Time: 7.68947
Cumulative Model Updates: 1,041
Cumulative Timesteps: 5,852,328
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69837
Policy Entropy: 4.01501
Value Function Loss: 0.19071
Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07133
Policy Update Magnitude: 0.44120
Value Function Update Magnitude: 0.54588
Collected Steps per Second: 11,370.56286
Overall Steps per Second: 6,242.04903
Timestep Collection Time: 4.39961
Timestep Consumption Time: 3.61475
PPO Batch Consumption Time: 0.25567
Total Iteration Time: 8.01436
Cumulative Model Updates: 1,050
Cumulative Timesteps: 5,902,354
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 5902354...
Checkpoint 5902354 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.42359
Policy Entropy: 4.01174
Value Function Loss: 0.18424
Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06465
Policy Update Magnitude: 0.44525
Value Function Update Magnitude: 0.49066
Collected Steps per Second: 12,100.46808
Overall Steps per Second: 6,544.97213
Timestep Collection Time: 4.13455
Timestep Consumption Time: 3.50948
PPO Batch Consumption Time: 0.24346
Total Iteration Time: 7.64404
Cumulative Model Updates: 1,059
Cumulative Timesteps: 5,952,384
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.34554
Policy Entropy: 4.01009
Value Function Loss: 0.19094
Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06062
Policy Update Magnitude: 0.43450
Value Function Update Magnitude: 0.48234
Collected Steps per Second: 12,275.70416
Overall Steps per Second: 6,568.40568
Timestep Collection Time: 4.07586
Timestep Consumption Time: 3.54152
PPO Batch Consumption Time: 0.24327
Total Iteration Time: 7.61737
Cumulative Model Updates: 1,068
Cumulative Timesteps: 6,002,418
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 6002418...
Checkpoint 6002418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.20843
Policy Entropy: 4.01041
Value Function Loss: 0.19016
Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06837
Policy Update Magnitude: 0.42837
Value Function Update Magnitude: 0.45616
Collected Steps per Second: 12,263.90999
Overall Steps per Second: 6,713.82382
Timestep Collection Time: 4.08010
Timestep Consumption Time: 3.37288
PPO Batch Consumption Time: 0.24227
Total Iteration Time: 7.45298
Cumulative Model Updates: 1,077
Cumulative Timesteps: 6,052,456
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84775
Policy Entropy: 4.00856
Value Function Loss: 0.19962
Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.07115
Policy Update Magnitude: 0.42555
Value Function Update Magnitude: 0.62253
Collected Steps per Second: 12,318.94135
Overall Steps per Second: 6,506.48381
Timestep Collection Time: 4.06090
Timestep Consumption Time: 3.62774
PPO Batch Consumption Time: 0.25173
Total Iteration Time: 7.68864
Cumulative Model Updates: 1,086
Cumulative Timesteps: 6,102,482
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 6102482...
Checkpoint 6102482 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.29953
Policy Entropy: 4.00455
Value Function Loss: 0.19282
Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06960
Policy Update Magnitude: 0.43435
Value Function Update Magnitude: 0.73417
Collected Steps per Second: 12,346.76004
Overall Steps per Second: 6,609.64258
Timestep Collection Time: 4.05191
Timestep Consumption Time: 3.51703
PPO Batch Consumption Time: 0.24318
Total Iteration Time: 7.56894
Cumulative Model Updates: 1,095
Cumulative Timesteps: 6,152,510
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.50869
Policy Entropy: 4.00477
Value Function Loss: 0.22367
Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07146
Policy Update Magnitude: 0.43426
Value Function Update Magnitude: 0.59254
Collected Steps per Second: 12,512.19065
Overall Steps per Second: 6,663.54329
Timestep Collection Time: 3.99866
Timestep Consumption Time: 3.50966
PPO Batch Consumption Time: 0.24331
Total Iteration Time: 7.50832
Cumulative Model Updates: 1,104
Cumulative Timesteps: 6,202,542
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 6202542...
Checkpoint 6202542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.99214
Policy Entropy: 3.99784
Value Function Loss: 0.24368
Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.43586
Value Function Update Magnitude: 0.36774
Collected Steps per Second: 12,303.90725
Overall Steps per Second: 6,601.11145
Timestep Collection Time: 4.06781
Timestep Consumption Time: 3.51424
PPO Batch Consumption Time: 0.24317
Total Iteration Time: 7.58206
Cumulative Model Updates: 1,113
Cumulative Timesteps: 6,252,592
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76044
Policy Entropy: 3.99450
Value Function Loss: 0.22024
Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.43669
Value Function Update Magnitude: 0.34127
Collected Steps per Second: 12,320.46583
Overall Steps per Second: 6,714.57404
Timestep Collection Time: 4.05926
Timestep Consumption Time: 3.38901
PPO Batch Consumption Time: 0.24325
Total Iteration Time: 7.44828
Cumulative Model Updates: 1,122
Cumulative Timesteps: 6,302,604
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 6302604...
Checkpoint 6302604 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.21399
Policy Entropy: 3.99108
Value Function Loss: 0.21421
Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07237
Policy Update Magnitude: 0.44167
Value Function Update Magnitude: 0.38297
Collected Steps per Second: 12,365.40689
Overall Steps per Second: 6,524.56237
Timestep Collection Time: 4.04629
Timestep Consumption Time: 3.62227
PPO Batch Consumption Time: 0.24893
Total Iteration Time: 7.66856
Cumulative Model Updates: 1,131
Cumulative Timesteps: 6,352,638
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.17143
Policy Entropy: 3.98826
Value Function Loss: 0.21099
Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.45517
Value Function Update Magnitude: 0.39977
Collected Steps per Second: 11,936.19439
Overall Steps per Second: 6,455.34905
Timestep Collection Time: 4.19179
Timestep Consumption Time: 3.55899
PPO Batch Consumption Time: 0.24890
Total Iteration Time: 7.75078
Cumulative Model Updates: 1,140
Cumulative Timesteps: 6,402,672
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 6402672...
Checkpoint 6402672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.58777
Policy Entropy: 3.99143
Value Function Loss: 0.21541
Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07454
Policy Update Magnitude: 0.47334
Value Function Update Magnitude: 0.51333
Collected Steps per Second: 11,952.30930
Overall Steps per Second: 6,580.99608
Timestep Collection Time: 4.18430
Timestep Consumption Time: 3.41516
PPO Batch Consumption Time: 0.24784
Total Iteration Time: 7.59946
Cumulative Model Updates: 1,149
Cumulative Timesteps: 6,452,684
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.21819
Policy Entropy: 3.98879
Value Function Loss: 0.22951
Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.46567
Value Function Update Magnitude: 0.60231
Collected Steps per Second: 11,534.00463
Overall Steps per Second: 6,211.83448
Timestep Collection Time: 4.33709
Timestep Consumption Time: 3.71593
PPO Batch Consumption Time: 0.25972
Total Iteration Time: 8.05302
Cumulative Model Updates: 1,158
Cumulative Timesteps: 6,502,708
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 6502708...
Checkpoint 6502708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.61988
Policy Entropy: 3.98812
Value Function Loss: 0.22667
Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.46399
Value Function Update Magnitude: 0.46006
Collected Steps per Second: 11,640.08928
Overall Steps per Second: 6,388.37144
Timestep Collection Time: 4.29636
Timestep Consumption Time: 3.53193
PPO Batch Consumption Time: 0.24297
Total Iteration Time: 7.82829
Cumulative Model Updates: 1,167
Cumulative Timesteps: 6,552,718
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.17296
Policy Entropy: 3.98319
Value Function Loss: 0.22776
Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.45747
Value Function Update Magnitude: 0.39374
Collected Steps per Second: 11,181.08921
Overall Steps per Second: 6,204.25423
Timestep Collection Time: 4.47416
Timestep Consumption Time: 3.58902
PPO Batch Consumption Time: 0.25050
Total Iteration Time: 8.06318
Cumulative Model Updates: 1,176
Cumulative Timesteps: 6,602,744
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 6602744...
Checkpoint 6602744 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.20227
Policy Entropy: 3.98314
Value Function Loss: 0.22327
Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.44493
Value Function Update Magnitude: 0.36593
Collected Steps per Second: 11,968.11941
Overall Steps per Second: 6,481.95484
Timestep Collection Time: 4.17927
Timestep Consumption Time: 3.53723
PPO Batch Consumption Time: 0.24652
Total Iteration Time: 7.71650
Cumulative Model Updates: 1,185
Cumulative Timesteps: 6,652,762
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.00026
Policy Entropy: 3.98407
Value Function Loss: 0.22499
Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07765
Policy Update Magnitude: 0.45793
Value Function Update Magnitude: 0.38040
Collected Steps per Second: 12,085.19726
Overall Steps per Second: 6,499.92110
Timestep Collection Time: 4.13994
Timestep Consumption Time: 3.55738
PPO Batch Consumption Time: 0.24952
Total Iteration Time: 7.69732
Cumulative Model Updates: 1,194
Cumulative Timesteps: 6,702,794
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 6702794...
Checkpoint 6702794 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.88466
Policy Entropy: 3.98514
Value Function Loss: 0.23934
Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.48788
Value Function Update Magnitude: 0.40469
Collected Steps per Second: 11,853.25752
Overall Steps per Second: 6,449.54779
Timestep Collection Time: 4.21994
Timestep Consumption Time: 3.53565
PPO Batch Consumption Time: 0.24251
Total Iteration Time: 7.75558
Cumulative Model Updates: 1,203
Cumulative Timesteps: 6,752,814
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.94122
Policy Entropy: 3.97996
Value Function Loss: 0.24818
Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07942
Policy Update Magnitude: 0.50569
Value Function Update Magnitude: 0.54635
Collected Steps per Second: 10,597.66278
Overall Steps per Second: 5,916.56704
Timestep Collection Time: 4.72236
Timestep Consumption Time: 3.73626
PPO Batch Consumption Time: 0.25101
Total Iteration Time: 8.45862
Cumulative Model Updates: 1,212
Cumulative Timesteps: 6,802,860
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 6802860...
Checkpoint 6802860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87234
Policy Entropy: 3.97822
Value Function Loss: 0.23551
Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.49647
Value Function Update Magnitude: 0.62499
Collected Steps per Second: 11,650.35618
Overall Steps per Second: 6,404.41703
Timestep Collection Time: 4.29326
Timestep Consumption Time: 3.51666
PPO Batch Consumption Time: 0.24566
Total Iteration Time: 7.80992
Cumulative Model Updates: 1,221
Cumulative Timesteps: 6,852,878
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.91191
Policy Entropy: 3.97751
Value Function Loss: 0.23535
Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.49776
Value Function Update Magnitude: 0.48544
Collected Steps per Second: 11,582.40257
Overall Steps per Second: 6,237.44241
Timestep Collection Time: 4.31931
Timestep Consumption Time: 3.70128
PPO Batch Consumption Time: 0.25608
Total Iteration Time: 8.02060
Cumulative Model Updates: 1,230
Cumulative Timesteps: 6,902,906
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 6902906...
Checkpoint 6902906 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.08493
Policy Entropy: 3.97558
Value Function Loss: 0.23018
Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.49345
Value Function Update Magnitude: 0.44179
Collected Steps per Second: 11,568.23084
Overall Steps per Second: 6,297.89948
Timestep Collection Time: 4.32460
Timestep Consumption Time: 3.61900
PPO Batch Consumption Time: 0.25547
Total Iteration Time: 7.94360
Cumulative Model Updates: 1,239
Cumulative Timesteps: 6,952,934
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03078
Policy Entropy: 3.97440
Value Function Loss: 0.22715
Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07992
Policy Update Magnitude: 0.49288
Value Function Update Magnitude: 0.51164
Collected Steps per Second: 11,753.57043
Overall Steps per Second: 6,307.28789
Timestep Collection Time: 4.25488
Timestep Consumption Time: 3.67405
PPO Batch Consumption Time: 0.25474
Total Iteration Time: 7.92892
Cumulative Model Updates: 1,248
Cumulative Timesteps: 7,002,944
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 7002944...
Checkpoint 7002944 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.16873
Policy Entropy: 3.97560
Value Function Loss: 0.23107
Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.48620
Value Function Update Magnitude: 0.53146
Collected Steps per Second: 11,914.69672
Overall Steps per Second: 6,478.95357
Timestep Collection Time: 4.19700
Timestep Consumption Time: 3.52122
PPO Batch Consumption Time: 0.24345
Total Iteration Time: 7.71822
Cumulative Model Updates: 1,257
Cumulative Timesteps: 7,052,950
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01097
Policy Entropy: 3.97466
Value Function Loss: 0.22825
Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.49530
Value Function Update Magnitude: 0.57375
Collected Steps per Second: 11,902.80148
Overall Steps per Second: 6,539.59891
Timestep Collection Time: 4.20220
Timestep Consumption Time: 3.44628
PPO Batch Consumption Time: 0.24727
Total Iteration Time: 7.64848
Cumulative Model Updates: 1,266
Cumulative Timesteps: 7,102,968
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 7102968...
Checkpoint 7102968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68331
Policy Entropy: 3.97043
Value Function Loss: 0.23339
Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.51969
Value Function Update Magnitude: 0.53480
Collected Steps per Second: 11,581.43521
Overall Steps per Second: 6,289.96500
Timestep Collection Time: 4.32105
Timestep Consumption Time: 3.63511
PPO Batch Consumption Time: 0.24528
Total Iteration Time: 7.95617
Cumulative Model Updates: 1,275
Cumulative Timesteps: 7,153,012
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.78977
Policy Entropy: 3.97178
Value Function Loss: 0.23965
Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.51189
Value Function Update Magnitude: 0.52894
Collected Steps per Second: 11,714.66144
Overall Steps per Second: 6,431.03112
Timestep Collection Time: 4.27020
Timestep Consumption Time: 3.50833
PPO Batch Consumption Time: 0.24554
Total Iteration Time: 7.77853
Cumulative Model Updates: 1,284
Cumulative Timesteps: 7,203,036
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 7203036...
Checkpoint 7203036 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.03809
Policy Entropy: 3.96308
Value Function Loss: 0.23592
Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.50209
Value Function Update Magnitude: 0.52537
Collected Steps per Second: 12,355.04645
Overall Steps per Second: 6,476.04133
Timestep Collection Time: 4.04936
Timestep Consumption Time: 3.67604
PPO Batch Consumption Time: 0.24573
Total Iteration Time: 7.72540
Cumulative Model Updates: 1,293
Cumulative Timesteps: 7,253,066
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97556
Policy Entropy: 3.96279
Value Function Loss: 0.23841
Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.49831
Value Function Update Magnitude: 0.54793
Collected Steps per Second: 10,995.06431
Overall Steps per Second: 6,139.59959
Timestep Collection Time: 4.54895
Timestep Consumption Time: 3.59751
PPO Batch Consumption Time: 0.24696
Total Iteration Time: 8.14646
Cumulative Model Updates: 1,302
Cumulative Timesteps: 7,303,082
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 7303082...
Checkpoint 7303082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50252
Policy Entropy: 3.96268
Value Function Loss: 0.23665
Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.48533
Value Function Update Magnitude: 0.60262
Collected Steps per Second: 11,125.39654
Overall Steps per Second: 6,239.44001
Timestep Collection Time: 4.49440
Timestep Consumption Time: 3.51946
PPO Batch Consumption Time: 0.24607
Total Iteration Time: 8.01386
Cumulative Model Updates: 1,311
Cumulative Timesteps: 7,353,084
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.86394
Policy Entropy: 3.96738
Value Function Loss: 0.27626
Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.50054
Value Function Update Magnitude: 0.45521
Collected Steps per Second: 12,028.91461
Overall Steps per Second: 6,468.17992
Timestep Collection Time: 4.15815
Timestep Consumption Time: 3.57479
PPO Batch Consumption Time: 0.24840
Total Iteration Time: 7.73293
Cumulative Model Updates: 1,320
Cumulative Timesteps: 7,403,102
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 7403102...
Checkpoint 7403102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87617
Policy Entropy: 3.96786
Value Function Loss: 0.27696
Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.52690
Value Function Update Magnitude: 0.41043
Collected Steps per Second: 12,047.08111
Overall Steps per Second: 6,552.68051
Timestep Collection Time: 4.15204
Timestep Consumption Time: 3.48147
PPO Batch Consumption Time: 0.24497
Total Iteration Time: 7.63352
Cumulative Model Updates: 1,329
Cumulative Timesteps: 7,453,122
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02503
Policy Entropy: 3.96616
Value Function Loss: 0.29380
Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.52244
Value Function Update Magnitude: 0.43019
Collected Steps per Second: 10,722.84846
Overall Steps per Second: 6,167.00190
Timestep Collection Time: 4.66406
Timestep Consumption Time: 3.44555
PPO Batch Consumption Time: 0.24784
Total Iteration Time: 8.10961
Cumulative Model Updates: 1,338
Cumulative Timesteps: 7,503,134
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 7503134...
Checkpoint 7503134 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.82347
Policy Entropy: 3.96104
Value Function Loss: 0.26882
Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.50848
Value Function Update Magnitude: 0.44676
Collected Steps per Second: 11,374.93258
Overall Steps per Second: 6,256.97581
Timestep Collection Time: 4.39598
Timestep Consumption Time: 3.59574
PPO Batch Consumption Time: 0.25225
Total Iteration Time: 7.99172
Cumulative Model Updates: 1,347
Cumulative Timesteps: 7,553,138
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56574
Policy Entropy: 3.95789
Value Function Loss: 0.26391
Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.50273
Value Function Update Magnitude: 0.42779
Collected Steps per Second: 11,584.52501
Overall Steps per Second: 6,271.33072
Timestep Collection Time: 4.31835
Timestep Consumption Time: 3.65859
PPO Batch Consumption Time: 0.25314
Total Iteration Time: 7.97694
Cumulative Model Updates: 1,356
Cumulative Timesteps: 7,603,164
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 7603164...
Checkpoint 7603164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.62689
Policy Entropy: 3.95789
Value Function Loss: 0.24901
Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.50114
Value Function Update Magnitude: 0.46015
Collected Steps per Second: 11,350.55616
Overall Steps per Second: 6,207.66300
Timestep Collection Time: 4.40560
Timestep Consumption Time: 3.64993
PPO Batch Consumption Time: 0.24494
Total Iteration Time: 8.05553
Cumulative Model Updates: 1,365
Cumulative Timesteps: 7,653,170
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04319
Policy Entropy: 3.95836
Value Function Loss: 0.26028
Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.51034
Value Function Update Magnitude: 0.49084
Collected Steps per Second: 11,516.66114
Overall Steps per Second: 6,205.33348
Timestep Collection Time: 4.34240
Timestep Consumption Time: 3.71679
PPO Batch Consumption Time: 0.25226
Total Iteration Time: 8.05920
Cumulative Model Updates: 1,374
Cumulative Timesteps: 7,703,180
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 7703180...
Checkpoint 7703180 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.47417
Policy Entropy: 3.95671
Value Function Loss: 0.26155
Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.51989
Value Function Update Magnitude: 0.57778
Collected Steps per Second: 10,857.62727
Overall Steps per Second: 6,185.86805
Timestep Collection Time: 4.60561
Timestep Consumption Time: 3.47830
PPO Batch Consumption Time: 0.24588
Total Iteration Time: 8.08391
Cumulative Model Updates: 1,383
Cumulative Timesteps: 7,753,186
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50922
Policy Entropy: 3.95688
Value Function Loss: 0.26221
Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.51404
Value Function Update Magnitude: 0.56501
Collected Steps per Second: 11,895.75049
Overall Steps per Second: 6,435.69493
Timestep Collection Time: 4.20604
Timestep Consumption Time: 3.56841
PPO Batch Consumption Time: 0.24929
Total Iteration Time: 7.77445
Cumulative Model Updates: 1,392
Cumulative Timesteps: 7,803,220
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 7803220...
Checkpoint 7803220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.00572
Policy Entropy: 3.95656
Value Function Loss: 0.26113
Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.51437
Value Function Update Magnitude: 0.55567
Collected Steps per Second: 12,171.04064
Overall Steps per Second: 6,607.99925
Timestep Collection Time: 4.11041
Timestep Consumption Time: 3.46041
PPO Batch Consumption Time: 0.24250
Total Iteration Time: 7.57082
Cumulative Model Updates: 1,401
Cumulative Timesteps: 7,853,248
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01970
Policy Entropy: 3.96483
Value Function Loss: 0.26128
Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.49308
Value Function Update Magnitude: 0.50793
Collected Steps per Second: 11,425.23610
Overall Steps per Second: 6,264.81979
Timestep Collection Time: 4.37978
Timestep Consumption Time: 3.60768
PPO Batch Consumption Time: 0.25535
Total Iteration Time: 7.98746
Cumulative Model Updates: 1,410
Cumulative Timesteps: 7,903,288
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 7903288...
Checkpoint 7903288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.71417
Policy Entropy: 3.96683
Value Function Loss: 0.26006
Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.47933
Value Function Update Magnitude: 0.47613
Collected Steps per Second: 11,204.17533
Overall Steps per Second: 6,188.88842
Timestep Collection Time: 4.46405
Timestep Consumption Time: 3.61753
PPO Batch Consumption Time: 0.24947
Total Iteration Time: 8.08158
Cumulative Model Updates: 1,419
Cumulative Timesteps: 7,953,304
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46985
Policy Entropy: 3.96366
Value Function Loss: 0.26903
Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.48439
Value Function Update Magnitude: 0.49682
Collected Steps per Second: 11,899.94954
Overall Steps per Second: 6,579.29067
Timestep Collection Time: 4.20321
Timestep Consumption Time: 3.39913
PPO Batch Consumption Time: 0.24536
Total Iteration Time: 7.60234
Cumulative Model Updates: 1,428
Cumulative Timesteps: 8,003,322
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 8003322...
Checkpoint 8003322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84147
Policy Entropy: 3.96396
Value Function Loss: 0.25870
Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.48695
Value Function Update Magnitude: 0.53212
Collected Steps per Second: 12,294.83555
Overall Steps per Second: 6,567.79578
Timestep Collection Time: 4.06984
Timestep Consumption Time: 3.54885
PPO Batch Consumption Time: 0.24715
Total Iteration Time: 7.61869
Cumulative Model Updates: 1,437
Cumulative Timesteps: 8,053,360
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80148
Policy Entropy: 3.96458
Value Function Loss: 0.26353
Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.49193
Value Function Update Magnitude: 0.50848
Collected Steps per Second: 11,414.13401
Overall Steps per Second: 6,373.95568
Timestep Collection Time: 4.38123
Timestep Consumption Time: 3.46444
PPO Batch Consumption Time: 0.24264
Total Iteration Time: 7.84568
Cumulative Model Updates: 1,446
Cumulative Timesteps: 8,103,368
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 8103368...
Checkpoint 8103368 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.35737
Policy Entropy: 3.96162
Value Function Loss: 0.24937
Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.48741
Value Function Update Magnitude: 0.52089
Collected Steps per Second: 11,794.63659
Overall Steps per Second: 6,487.34771
Timestep Collection Time: 4.24176
Timestep Consumption Time: 3.47018
PPO Batch Consumption Time: 0.24930
Total Iteration Time: 7.71193
Cumulative Model Updates: 1,455
Cumulative Timesteps: 8,153,398
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.36368
Policy Entropy: 3.96058
Value Function Loss: 0.26531
Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.48779
Value Function Update Magnitude: 0.51816
Collected Steps per Second: 11,205.25304
Overall Steps per Second: 6,174.62689
Timestep Collection Time: 4.46291
Timestep Consumption Time: 3.63604
PPO Batch Consumption Time: 0.24638
Total Iteration Time: 8.09895
Cumulative Model Updates: 1,464
Cumulative Timesteps: 8,203,406
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 8203406...
Checkpoint 8203406 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03873
Policy Entropy: 3.95626
Value Function Loss: 0.26211
Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.49068
Value Function Update Magnitude: 0.64572
Collected Steps per Second: 11,252.18397
Overall Steps per Second: 6,373.94636
Timestep Collection Time: 4.44643
Timestep Consumption Time: 3.40303
PPO Batch Consumption Time: 0.24510
Total Iteration Time: 7.84945
Cumulative Model Updates: 1,473
Cumulative Timesteps: 8,253,438
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.81653
Policy Entropy: 3.95661
Value Function Loss: 0.28727
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.48825
Value Function Update Magnitude: 0.46963
Collected Steps per Second: 10,854.03569
Overall Steps per Second: 5,986.86236
Timestep Collection Time: 4.60658
Timestep Consumption Time: 3.74504
PPO Batch Consumption Time: 0.25786
Total Iteration Time: 8.35162
Cumulative Model Updates: 1,482
Cumulative Timesteps: 8,303,438
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 8303438...
Checkpoint 8303438 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54756
Policy Entropy: 3.95172
Value Function Loss: 0.28418
Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.49080
Value Function Update Magnitude: 0.45974
Collected Steps per Second: 10,884.58274
Overall Steps per Second: 6,186.80608
Timestep Collection Time: 4.59623
Timestep Consumption Time: 3.49001
PPO Batch Consumption Time: 0.24241
Total Iteration Time: 8.08624
Cumulative Model Updates: 1,491
Cumulative Timesteps: 8,353,466
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.70058
Policy Entropy: 3.95324
Value Function Loss: 0.28521
Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.51029
Value Function Update Magnitude: 0.54070
Collected Steps per Second: 11,909.14490
Overall Steps per Second: 6,583.44279
Timestep Collection Time: 4.19913
Timestep Consumption Time: 3.39690
PPO Batch Consumption Time: 0.24333
Total Iteration Time: 7.59603
Cumulative Model Updates: 1,500
Cumulative Timesteps: 8,403,474
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 8403474...
Checkpoint 8403474 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.70154
Policy Entropy: 3.94884
Value Function Loss: 0.28350
Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.51623
Value Function Update Magnitude: 0.64035
Collected Steps per Second: 11,748.81860
Overall Steps per Second: 6,367.27950
Timestep Collection Time: 4.25949
Timestep Consumption Time: 3.60007
PPO Batch Consumption Time: 0.24326
Total Iteration Time: 7.85956
Cumulative Model Updates: 1,509
Cumulative Timesteps: 8,453,518
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.92259
Policy Entropy: 3.94834
Value Function Loss: 0.27045
Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.50989
Value Function Update Magnitude: 0.57047
Collected Steps per Second: 11,931.34156
Overall Steps per Second: 6,453.87664
Timestep Collection Time: 4.19333
Timestep Consumption Time: 3.55891
PPO Batch Consumption Time: 0.26006
Total Iteration Time: 7.75224
Cumulative Model Updates: 1,518
Cumulative Timesteps: 8,503,550
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 8503550...
Checkpoint 8503550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16868
Policy Entropy: 3.94273
Value Function Loss: 0.27428
Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.50445
Value Function Update Magnitude: 0.49632
Collected Steps per Second: 11,213.46100
Overall Steps per Second: 6,289.25074
Timestep Collection Time: 4.45910
Timestep Consumption Time: 3.49129
PPO Batch Consumption Time: 0.24318
Total Iteration Time: 7.95039
Cumulative Model Updates: 1,527
Cumulative Timesteps: 8,553,552
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.47532
Policy Entropy: 3.93884
Value Function Loss: 0.27282
Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.50754
Value Function Update Magnitude: 0.71374
Collected Steps per Second: 11,922.28657
Overall Steps per Second: 6,343.05083
Timestep Collection Time: 4.19450
Timestep Consumption Time: 3.68941
PPO Batch Consumption Time: 0.26016
Total Iteration Time: 7.88390
Cumulative Model Updates: 1,536
Cumulative Timesteps: 8,603,560
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 8603560...
Checkpoint 8603560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65478
Policy Entropy: 3.93642
Value Function Loss: 0.26698
Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.51701
Value Function Update Magnitude: 0.80947
Collected Steps per Second: 11,830.78223
Overall Steps per Second: 6,534.74507
Timestep Collection Time: 4.23049
Timestep Consumption Time: 3.42857
PPO Batch Consumption Time: 0.24432
Total Iteration Time: 7.65906
Cumulative Model Updates: 1,545
Cumulative Timesteps: 8,653,610
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.20936
Policy Entropy: 3.94179
Value Function Loss: 0.27428
Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09602
Policy Update Magnitude: 0.51713
Value Function Update Magnitude: 0.77190
Collected Steps per Second: 11,749.23909
Overall Steps per Second: 6,396.22317
Timestep Collection Time: 4.25679
Timestep Consumption Time: 3.56252
PPO Batch Consumption Time: 0.24717
Total Iteration Time: 7.81930
Cumulative Model Updates: 1,554
Cumulative Timesteps: 8,703,624
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 8703624...
Checkpoint 8703624 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18119
Policy Entropy: 3.94758
Value Function Loss: 0.28281
Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.50283
Value Function Update Magnitude: 0.46075
Collected Steps per Second: 11,299.56679
Overall Steps per Second: 6,336.92326
Timestep Collection Time: 4.42495
Timestep Consumption Time: 3.46532
PPO Batch Consumption Time: 0.24359
Total Iteration Time: 7.89026
Cumulative Model Updates: 1,563
Cumulative Timesteps: 8,753,624
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.94816
Policy Entropy: 3.94949
Value Function Loss: 0.29215
Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.49570
Value Function Update Magnitude: 0.33261
Collected Steps per Second: 12,182.81925
Overall Steps per Second: 6,450.30081
Timestep Collection Time: 4.10578
Timestep Consumption Time: 3.64890
PPO Batch Consumption Time: 0.25295
Total Iteration Time: 7.75468
Cumulative Model Updates: 1,572
Cumulative Timesteps: 8,803,644
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 8803644...
Checkpoint 8803644 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71035
Policy Entropy: 3.95150
Value Function Loss: 0.29760
Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.51371
Value Function Update Magnitude: 0.38456
Collected Steps per Second: 11,801.31937
Overall Steps per Second: 6,434.71154
Timestep Collection Time: 4.23936
Timestep Consumption Time: 3.53566
PPO Batch Consumption Time: 0.24446
Total Iteration Time: 7.77502
Cumulative Model Updates: 1,581
Cumulative Timesteps: 8,853,674
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.55681
Policy Entropy: 3.94944
Value Function Loss: 0.29628
Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.54270
Value Function Update Magnitude: 0.60285
Collected Steps per Second: 11,798.76398
Overall Steps per Second: 6,393.93219
Timestep Collection Time: 4.23909
Timestep Consumption Time: 3.58333
PPO Batch Consumption Time: 0.25293
Total Iteration Time: 7.82242
Cumulative Model Updates: 1,590
Cumulative Timesteps: 8,903,690
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 8903690...
Checkpoint 8903690 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.73068
Policy Entropy: 3.95045
Value Function Loss: 0.30714
Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10798
Policy Update Magnitude: 0.55458
Value Function Update Magnitude: 0.57411
Collected Steps per Second: 11,729.57684
Overall Steps per Second: 6,453.61781
Timestep Collection Time: 4.26512
Timestep Consumption Time: 3.48682
PPO Batch Consumption Time: 0.24363
Total Iteration Time: 7.75193
Cumulative Model Updates: 1,599
Cumulative Timesteps: 8,953,718
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.55691
Policy Entropy: 3.95064
Value Function Loss: 0.31374
Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.45460
Collected Steps per Second: 11,410.82399
Overall Steps per Second: 6,211.79935
Timestep Collection Time: 4.38689
Timestep Consumption Time: 3.67165
PPO Batch Consumption Time: 0.25246
Total Iteration Time: 8.05853
Cumulative Model Updates: 1,608
Cumulative Timesteps: 9,003,776
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 9003776...
Checkpoint 9003776 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.50880
Policy Entropy: 3.94814
Value Function Loss: 0.31598
Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.55240
Value Function Update Magnitude: 0.42231
Collected Steps per Second: 10,527.07642
Overall Steps per Second: 5,924.21312
Timestep Collection Time: 4.75365
Timestep Consumption Time: 3.69338
PPO Batch Consumption Time: 0.25776
Total Iteration Time: 8.44703
Cumulative Model Updates: 1,617
Cumulative Timesteps: 9,053,818
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.09317
Policy Entropy: 3.95077
Value Function Loss: 0.31244
Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.55625
Value Function Update Magnitude: 0.62752
Collected Steps per Second: 11,316.21573
Overall Steps per Second: 6,040.78731
Timestep Collection Time: 4.41932
Timestep Consumption Time: 3.85940
PPO Batch Consumption Time: 0.26887
Total Iteration Time: 8.27872
Cumulative Model Updates: 1,626
Cumulative Timesteps: 9,103,828
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 9103828...
Checkpoint 9103828 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00353
Policy Entropy: 3.95295
Value Function Loss: 0.30743
Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.57279
Value Function Update Magnitude: 0.61765
Collected Steps per Second: 11,075.03727
Overall Steps per Second: 6,106.08149
Timestep Collection Time: 4.51719
Timestep Consumption Time: 3.67596
PPO Batch Consumption Time: 0.25495
Total Iteration Time: 8.19314
Cumulative Model Updates: 1,635
Cumulative Timesteps: 9,153,856
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47293
Policy Entropy: 3.94738
Value Function Loss: 0.29467
Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.53511
Value Function Update Magnitude: 0.54806
Collected Steps per Second: 11,543.58314
Overall Steps per Second: 6,329.04835
Timestep Collection Time: 4.33436
Timestep Consumption Time: 3.57110
PPO Batch Consumption Time: 0.24307
Total Iteration Time: 7.90545
Cumulative Model Updates: 1,644
Cumulative Timesteps: 9,203,890
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 9203890...
Checkpoint 9203890 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69804
Policy Entropy: 3.94938
Value Function Loss: 0.28460
Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.51637
Value Function Update Magnitude: 0.51918
Collected Steps per Second: 11,903.95837
Overall Steps per Second: 6,427.31906
Timestep Collection Time: 4.20314
Timestep Consumption Time: 3.58144
PPO Batch Consumption Time: 0.24838
Total Iteration Time: 7.78458
Cumulative Model Updates: 1,653
Cumulative Timesteps: 9,253,924
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.58764
Policy Entropy: 3.94252
Value Function Loss: 0.27212
Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.51735
Value Function Update Magnitude: 0.48227
Collected Steps per Second: 12,189.32384
Overall Steps per Second: 6,676.06625
Timestep Collection Time: 4.10458
Timestep Consumption Time: 3.38966
PPO Batch Consumption Time: 0.24260
Total Iteration Time: 7.49423
Cumulative Model Updates: 1,662
Cumulative Timesteps: 9,303,956
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 9303956...
Checkpoint 9303956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.54701
Policy Entropy: 3.94585
Value Function Loss: 0.26395
Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.50701
Value Function Update Magnitude: 0.48461
Collected Steps per Second: 12,007.24784
Overall Steps per Second: 6,513.12454
Timestep Collection Time: 4.16648
Timestep Consumption Time: 3.51462
PPO Batch Consumption Time: 0.24346
Total Iteration Time: 7.68111
Cumulative Model Updates: 1,671
Cumulative Timesteps: 9,353,984
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.15570
Policy Entropy: 3.95102
Value Function Loss: 0.25908
Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.50245
Value Function Update Magnitude: 0.48430
Collected Steps per Second: 12,104.64478
Overall Steps per Second: 6,524.65244
Timestep Collection Time: 4.13263
Timestep Consumption Time: 3.53429
PPO Batch Consumption Time: 0.24609
Total Iteration Time: 7.66692
Cumulative Model Updates: 1,680
Cumulative Timesteps: 9,404,008
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 9404008...
Checkpoint 9404008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80668
Policy Entropy: 3.95273
Value Function Loss: 0.26724
Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.51272
Value Function Update Magnitude: 0.48783
Collected Steps per Second: 12,383.94415
Overall Steps per Second: 6,644.72143
Timestep Collection Time: 4.03975
Timestep Consumption Time: 3.48924
PPO Batch Consumption Time: 0.24313
Total Iteration Time: 7.52898
Cumulative Model Updates: 1,689
Cumulative Timesteps: 9,454,036
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.63591
Policy Entropy: 3.95307
Value Function Loss: 0.26422
Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.52526
Value Function Update Magnitude: 0.48213
Collected Steps per Second: 12,274.30315
Overall Steps per Second: 6,595.70035
Timestep Collection Time: 4.07583
Timestep Consumption Time: 3.50911
PPO Batch Consumption Time: 0.24311
Total Iteration Time: 7.58494
Cumulative Model Updates: 1,698
Cumulative Timesteps: 9,504,064
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 9504064...
Checkpoint 9504064 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.50064
Policy Entropy: 3.94629
Value Function Loss: 0.25637
Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11305
Policy Update Magnitude: 0.53416
Value Function Update Magnitude: 0.48256
Collected Steps per Second: 12,191.74859
Overall Steps per Second: 6,599.14001
Timestep Collection Time: 4.10245
Timestep Consumption Time: 3.47672
PPO Batch Consumption Time: 0.24351
Total Iteration Time: 7.57917
Cumulative Model Updates: 1,707
Cumulative Timesteps: 9,554,080
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.73373
Policy Entropy: 3.94185
Value Function Loss: 0.25645
Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.53645
Value Function Update Magnitude: 0.49675
Collected Steps per Second: 12,381.83427
Overall Steps per Second: 6,634.93196
Timestep Collection Time: 4.03817
Timestep Consumption Time: 3.49770
PPO Batch Consumption Time: 0.24419
Total Iteration Time: 7.53587
Cumulative Model Updates: 1,716
Cumulative Timesteps: 9,604,080
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 9604080...
Checkpoint 9604080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75484
Policy Entropy: 3.93510
Value Function Loss: 0.26470
Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.54290
Value Function Update Magnitude: 0.52735
Collected Steps per Second: 11,742.04687
Overall Steps per Second: 6,442.94428
Timestep Collection Time: 4.26025
Timestep Consumption Time: 3.50391
PPO Batch Consumption Time: 0.24759
Total Iteration Time: 7.76415
Cumulative Model Updates: 1,725
Cumulative Timesteps: 9,654,104
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52849
Policy Entropy: 3.93217
Value Function Loss: 0.25980
Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.51069
Collected Steps per Second: 11,651.81478
Overall Steps per Second: 6,435.39262
Timestep Collection Time: 4.29324
Timestep Consumption Time: 3.48003
PPO Batch Consumption Time: 0.25230
Total Iteration Time: 7.77326
Cumulative Model Updates: 1,734
Cumulative Timesteps: 9,704,128
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 9704128...
Checkpoint 9704128 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11603
Policy Entropy: 3.92992
Value Function Loss: 0.24898
Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.54585
Value Function Update Magnitude: 0.50031
Collected Steps per Second: 11,701.40228
Overall Steps per Second: 6,401.30805
Timestep Collection Time: 4.27350
Timestep Consumption Time: 3.53834
PPO Batch Consumption Time: 0.24624
Total Iteration Time: 7.81184
Cumulative Model Updates: 1,743
Cumulative Timesteps: 9,754,134
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.62351
Policy Entropy: 3.92906
Value Function Loss: 0.24682
Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.57142
Value Function Update Magnitude: 0.52244
Collected Steps per Second: 10,911.02499
Overall Steps per Second: 6,130.78276
Timestep Collection Time: 4.58380
Timestep Consumption Time: 3.57405
PPO Batch Consumption Time: 0.24286
Total Iteration Time: 8.15785
Cumulative Model Updates: 1,752
Cumulative Timesteps: 9,804,148
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 9804148...
Checkpoint 9804148 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22305
Policy Entropy: 3.92970
Value Function Loss: 0.24763
Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.55972
Value Function Update Magnitude: 0.56173
Collected Steps per Second: 11,811.27624
Overall Steps per Second: 6,339.00498
Timestep Collection Time: 4.23443
Timestep Consumption Time: 3.65545
PPO Batch Consumption Time: 0.25404
Total Iteration Time: 7.88988
Cumulative Model Updates: 1,761
Cumulative Timesteps: 9,854,162
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.11972
Policy Entropy: 3.93499
Value Function Loss: 0.26242
Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.49030
Collected Steps per Second: 10,646.03811
Overall Steps per Second: 6,034.58860
Timestep Collection Time: 4.69940
Timestep Consumption Time: 3.59114
PPO Batch Consumption Time: 0.24925
Total Iteration Time: 8.29054
Cumulative Model Updates: 1,770
Cumulative Timesteps: 9,904,192
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 9904192...
Checkpoint 9904192 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86519
Policy Entropy: 3.93533
Value Function Loss: 0.25899
Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.55072
Value Function Update Magnitude: 0.50081
Collected Steps per Second: 11,375.35157
Overall Steps per Second: 6,382.44949
Timestep Collection Time: 4.39881
Timestep Consumption Time: 3.44113
PPO Batch Consumption Time: 0.24306
Total Iteration Time: 7.83994
Cumulative Model Updates: 1,779
Cumulative Timesteps: 9,954,230
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.34178
Policy Entropy: 3.93623
Value Function Loss: 0.26411
Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.55564
Value Function Update Magnitude: 0.49324
Collected Steps per Second: 12,166.94585
Overall Steps per Second: 6,347.27144
Timestep Collection Time: 4.11065
Timestep Consumption Time: 3.76896
PPO Batch Consumption Time: 0.26803
Total Iteration Time: 7.87961
Cumulative Model Updates: 1,788
Cumulative Timesteps: 10,004,244
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 10004244...
Checkpoint 10004244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.50379
Policy Entropy: 3.93049
Value Function Loss: 0.25747
Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.55278
Value Function Update Magnitude: 0.50451
Collected Steps per Second: 11,276.72520
Overall Steps per Second: 6,136.82197
Timestep Collection Time: 4.43498
Timestep Consumption Time: 3.71452
PPO Batch Consumption Time: 0.25561
Total Iteration Time: 8.14950
Cumulative Model Updates: 1,797
Cumulative Timesteps: 10,054,256
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56630
Policy Entropy: 3.92498
Value Function Loss: 0.26056
Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.54396
Value Function Update Magnitude: 0.46892
Collected Steps per Second: 11,075.62546
Overall Steps per Second: 6,284.59803
Timestep Collection Time: 4.51622
Timestep Consumption Time: 3.44292
PPO Batch Consumption Time: 0.24542
Total Iteration Time: 7.95914
Cumulative Model Updates: 1,806
Cumulative Timesteps: 10,104,276
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 10104276...
Checkpoint 10104276 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.69733
Policy Entropy: 3.92564
Value Function Loss: 0.26647
Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.54612
Value Function Update Magnitude: 0.48421
Collected Steps per Second: 11,501.42064
Overall Steps per Second: 6,319.47576
Timestep Collection Time: 4.34833
Timestep Consumption Time: 3.56562
PPO Batch Consumption Time: 0.24791
Total Iteration Time: 7.91395
Cumulative Model Updates: 1,815
Cumulative Timesteps: 10,154,288
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.45146
Policy Entropy: 3.92743
Value Function Loss: 0.27687
Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.54415
Value Function Update Magnitude: 0.51791
Collected Steps per Second: 11,134.48156
Overall Steps per Second: 6,214.25822
Timestep Collection Time: 4.49271
Timestep Consumption Time: 3.55716
PPO Batch Consumption Time: 0.24329
Total Iteration Time: 8.04987
Cumulative Model Updates: 1,824
Cumulative Timesteps: 10,204,312
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 10204312...
Checkpoint 10204312 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.23294
Policy Entropy: 3.92795
Value Function Loss: 0.27085
Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.53814
Value Function Update Magnitude: 0.55802
Collected Steps per Second: 12,327.33757
Overall Steps per Second: 6,619.82865
Timestep Collection Time: 4.05895
Timestep Consumption Time: 3.49956
PPO Batch Consumption Time: 0.24292
Total Iteration Time: 7.55850
Cumulative Model Updates: 1,833
Cumulative Timesteps: 10,254,348
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51122
Policy Entropy: 3.93020
Value Function Loss: 0.27123
Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.53637
Value Function Update Magnitude: 0.54427
Collected Steps per Second: 12,123.78067
Overall Steps per Second: 6,523.03826
Timestep Collection Time: 4.12495
Timestep Consumption Time: 3.54172
PPO Batch Consumption Time: 0.24397
Total Iteration Time: 7.66667
Cumulative Model Updates: 1,842
Cumulative Timesteps: 10,304,358
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 10304358...
Checkpoint 10304358 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99938
Policy Entropy: 3.93127
Value Function Loss: 0.25941
Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.53086
Value Function Update Magnitude: 0.56349
Collected Steps per Second: 12,263.23314
Overall Steps per Second: 6,686.91286
Timestep Collection Time: 4.07723
Timestep Consumption Time: 3.40006
PPO Batch Consumption Time: 0.24399
Total Iteration Time: 7.47729
Cumulative Model Updates: 1,851
Cumulative Timesteps: 10,354,358
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46775
Policy Entropy: 3.92902
Value Function Loss: 0.27675
Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.52616
Value Function Update Magnitude: 0.52850
Collected Steps per Second: 12,203.10348
Overall Steps per Second: 6,571.82875
Timestep Collection Time: 4.09879
Timestep Consumption Time: 3.51218
PPO Batch Consumption Time: 0.24286
Total Iteration Time: 7.61097
Cumulative Model Updates: 1,860
Cumulative Timesteps: 10,404,376
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 10404376...
Checkpoint 10404376 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.16024
Policy Entropy: 3.92343
Value Function Loss: 0.28688
Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.55752
Collected Steps per Second: 12,036.98632
Overall Steps per Second: 6,558.66005
Timestep Collection Time: 4.15553
Timestep Consumption Time: 3.47103
PPO Batch Consumption Time: 0.24318
Total Iteration Time: 7.62656
Cumulative Model Updates: 1,869
Cumulative Timesteps: 10,454,396
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.77411
Policy Entropy: 3.92459
Value Function Loss: 0.30632
Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.57477
Value Function Update Magnitude: 0.53656
Collected Steps per Second: 12,266.33321
Overall Steps per Second: 6,654.62163
Timestep Collection Time: 4.07734
Timestep Consumption Time: 3.43834
PPO Batch Consumption Time: 0.24218
Total Iteration Time: 7.51568
Cumulative Model Updates: 1,878
Cumulative Timesteps: 10,504,410
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 10504410...
Checkpoint 10504410 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.09810
Policy Entropy: 3.92920
Value Function Loss: 0.29754
Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.57487
Value Function Update Magnitude: 0.53222
Collected Steps per Second: 12,305.85359
Overall Steps per Second: 6,617.52103
Timestep Collection Time: 4.06571
Timestep Consumption Time: 3.49483
PPO Batch Consumption Time: 0.24361
Total Iteration Time: 7.56054
Cumulative Model Updates: 1,887
Cumulative Timesteps: 10,554,442
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.56351
Policy Entropy: 3.91933
Value Function Loss: 0.29586
Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.57286
Value Function Update Magnitude: 0.52519
Collected Steps per Second: 12,160.23495
Overall Steps per Second: 6,523.49245
Timestep Collection Time: 4.11489
Timestep Consumption Time: 3.55554
PPO Batch Consumption Time: 0.24971
Total Iteration Time: 7.67043
Cumulative Model Updates: 1,896
Cumulative Timesteps: 10,604,480
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 10604480...
Checkpoint 10604480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.29361
Policy Entropy: 3.91969
Value Function Loss: 0.28839
Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.52118
Collected Steps per Second: 12,439.72542
Overall Steps per Second: 6,677.45057
Timestep Collection Time: 4.02147
Timestep Consumption Time: 3.47031
PPO Batch Consumption Time: 0.24238
Total Iteration Time: 7.49178
Cumulative Model Updates: 1,905
Cumulative Timesteps: 10,654,506
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52068
Policy Entropy: 3.91918
Value Function Loss: 0.28972
Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.54285
Value Function Update Magnitude: 0.48661
Collected Steps per Second: 12,133.04393
Overall Steps per Second: 6,570.63342
Timestep Collection Time: 4.12345
Timestep Consumption Time: 3.49073
PPO Batch Consumption Time: 0.24246
Total Iteration Time: 7.61418
Cumulative Model Updates: 1,914
Cumulative Timesteps: 10,704,536
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 10704536...
Checkpoint 10704536 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32190
Policy Entropy: 3.91469
Value Function Loss: 0.28197
Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.53550
Value Function Update Magnitude: 0.49636
Collected Steps per Second: 12,369.80452
Overall Steps per Second: 6,740.30930
Timestep Collection Time: 4.04275
Timestep Consumption Time: 3.37650
PPO Batch Consumption Time: 0.24265
Total Iteration Time: 7.41924
Cumulative Model Updates: 1,923
Cumulative Timesteps: 10,754,544
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46696
Policy Entropy: 3.91995
Value Function Loss: 0.27857
Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.53745
Value Function Update Magnitude: 0.49377
Collected Steps per Second: 12,356.83809
Overall Steps per Second: 6,646.15513
Timestep Collection Time: 4.04764
Timestep Consumption Time: 3.47792
PPO Batch Consumption Time: 0.24229
Total Iteration Time: 7.52555
Cumulative Model Updates: 1,932
Cumulative Timesteps: 10,804,560
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 10804560...
Checkpoint 10804560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71567
Policy Entropy: 3.91631
Value Function Loss: 0.27315
Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.52944
Value Function Update Magnitude: 0.49985
Collected Steps per Second: 12,220.64195
Overall Steps per Second: 6,622.79184
Timestep Collection Time: 4.09373
Timestep Consumption Time: 3.46018
PPO Batch Consumption Time: 0.24226
Total Iteration Time: 7.55391
Cumulative Model Updates: 1,941
Cumulative Timesteps: 10,854,588
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58320
Policy Entropy: 3.91524
Value Function Loss: 0.27020
Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.53780
Value Function Update Magnitude: 0.49466
Collected Steps per Second: 12,466.13339
Overall Steps per Second: 6,551.05407
Timestep Collection Time: 4.01199
Timestep Consumption Time: 3.62251
PPO Batch Consumption Time: 0.25203
Total Iteration Time: 7.63450
Cumulative Model Updates: 1,950
Cumulative Timesteps: 10,904,602
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 10904602...
Checkpoint 10904602 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05352
Policy Entropy: 3.91416
Value Function Loss: 0.25679
Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.56674
Value Function Update Magnitude: 0.47282
Collected Steps per Second: 12,291.53690
Overall Steps per Second: 6,605.32238
Timestep Collection Time: 4.07077
Timestep Consumption Time: 3.50434
PPO Batch Consumption Time: 0.24281
Total Iteration Time: 7.57510
Cumulative Model Updates: 1,959
Cumulative Timesteps: 10,954,638
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61274
Policy Entropy: 3.91531
Value Function Loss: 0.27123
Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.57698
Value Function Update Magnitude: 0.50114
Collected Steps per Second: 12,184.33133
Overall Steps per Second: 6,613.36915
Timestep Collection Time: 4.10429
Timestep Consumption Time: 3.45737
PPO Batch Consumption Time: 0.24270
Total Iteration Time: 7.56165
Cumulative Model Updates: 1,968
Cumulative Timesteps: 11,004,646
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 11004646...
Checkpoint 11004646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32936
Policy Entropy: 3.91883
Value Function Loss: 0.28024
Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.57894
Value Function Update Magnitude: 0.50043
Collected Steps per Second: 12,418.02940
Overall Steps per Second: 6,650.76749
Timestep Collection Time: 4.02801
Timestep Consumption Time: 3.49292
PPO Batch Consumption Time: 0.24235
Total Iteration Time: 7.52094
Cumulative Model Updates: 1,977
Cumulative Timesteps: 11,054,666
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.83181
Policy Entropy: 3.91593
Value Function Loss: 0.28983
Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.56752
Value Function Update Magnitude: 0.50653
Collected Steps per Second: 12,263.07072
Overall Steps per Second: 6,613.26173
Timestep Collection Time: 4.07924
Timestep Consumption Time: 3.48496
PPO Batch Consumption Time: 0.24267
Total Iteration Time: 7.56419
Cumulative Model Updates: 1,986
Cumulative Timesteps: 11,104,690
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 11104690...
Checkpoint 11104690 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68599
Policy Entropy: 3.91792
Value Function Loss: 0.28305
Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.48589
Collected Steps per Second: 12,199.79004
Overall Steps per Second: 6,710.92852
Timestep Collection Time: 4.09892
Timestep Consumption Time: 3.35250
PPO Batch Consumption Time: 0.24232
Total Iteration Time: 7.45143
Cumulative Model Updates: 1,995
Cumulative Timesteps: 11,154,696
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.76752
Policy Entropy: 3.91207
Value Function Loss: 0.29542
Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.56036
Value Function Update Magnitude: 0.51143
Collected Steps per Second: 12,152.17657
Overall Steps per Second: 6,524.03012
Timestep Collection Time: 4.11498
Timestep Consumption Time: 3.54991
PPO Batch Consumption Time: 0.24481
Total Iteration Time: 7.66489
Cumulative Model Updates: 2,004
Cumulative Timesteps: 11,204,702
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 11204702...
Checkpoint 11204702 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.27868
Policy Entropy: 3.90770
Value Function Loss: 0.30127
Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.57126
Value Function Update Magnitude: 0.51478
Collected Steps per Second: 12,232.56907
Overall Steps per Second: 6,618.54388
Timestep Collection Time: 4.08892
Timestep Consumption Time: 3.46833
PPO Batch Consumption Time: 0.24214
Total Iteration Time: 7.55725
Cumulative Model Updates: 2,013
Cumulative Timesteps: 11,254,720
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.26056
Policy Entropy: 3.90384
Value Function Loss: 0.30758
Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.54889
Collected Steps per Second: 12,684.44882
Overall Steps per Second: 6,733.59010
Timestep Collection Time: 3.94515
Timestep Consumption Time: 3.48655
PPO Batch Consumption Time: 0.24289
Total Iteration Time: 7.43170
Cumulative Model Updates: 2,022
Cumulative Timesteps: 11,304,762
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 11304762...
Checkpoint 11304762 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46054
Policy Entropy: 3.89388
Value Function Loss: 0.28870
Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.56755
Value Function Update Magnitude: 0.57055
Collected Steps per Second: 12,300.46851
Overall Steps per Second: 6,621.07843
Timestep Collection Time: 4.06911
Timestep Consumption Time: 3.49038
PPO Batch Consumption Time: 0.24272
Total Iteration Time: 7.55949
Cumulative Model Updates: 2,031
Cumulative Timesteps: 11,354,814
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.74705
Policy Entropy: 3.89466
Value Function Loss: 0.27944
Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08995
Policy Update Magnitude: 0.57842
Value Function Update Magnitude: 0.64796
Collected Steps per Second: 12,192.09459
Overall Steps per Second: 6,671.08703
Timestep Collection Time: 4.10282
Timestep Consumption Time: 3.39551
PPO Batch Consumption Time: 0.24308
Total Iteration Time: 7.49833
Cumulative Model Updates: 2,040
Cumulative Timesteps: 11,404,836
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 11404836...
Checkpoint 11404836 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06099
Policy Entropy: 3.89684
Value Function Loss: 0.27122
Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.58238
Value Function Update Magnitude: 0.79828
Collected Steps per Second: 12,212.96494
Overall Steps per Second: 6,594.92140
Timestep Collection Time: 4.09712
Timestep Consumption Time: 3.49023
PPO Batch Consumption Time: 0.24250
Total Iteration Time: 7.58735
Cumulative Model Updates: 2,049
Cumulative Timesteps: 11,454,874
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19648
Policy Entropy: 3.90151
Value Function Loss: 0.26872
Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.58230
Value Function Update Magnitude: 0.83623
Collected Steps per Second: 12,231.20085
Overall Steps per Second: 6,569.89308
Timestep Collection Time: 4.08938
Timestep Consumption Time: 3.52384
PPO Batch Consumption Time: 0.24801
Total Iteration Time: 7.61321
Cumulative Model Updates: 2,058
Cumulative Timesteps: 11,504,892
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 11504892...
Checkpoint 11504892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03099
Policy Entropy: 3.89736
Value Function Loss: 0.28093
Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.58865
Value Function Update Magnitude: 0.82975
Collected Steps per Second: 12,164.35109
Overall Steps per Second: 6,675.63796
Timestep Collection Time: 4.11333
Timestep Consumption Time: 3.38198
PPO Batch Consumption Time: 0.24303
Total Iteration Time: 7.49531
Cumulative Model Updates: 2,067
Cumulative Timesteps: 11,554,928
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.75749
Policy Entropy: 3.89700
Value Function Loss: 0.27902
Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.59211
Value Function Update Magnitude: 0.56833
Collected Steps per Second: 12,217.29192
Overall Steps per Second: 6,585.84758
Timestep Collection Time: 4.09371
Timestep Consumption Time: 3.50046
PPO Batch Consumption Time: 0.24286
Total Iteration Time: 7.59416
Cumulative Model Updates: 2,076
Cumulative Timesteps: 11,604,942
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 11604942...
Checkpoint 11604942 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.41352
Policy Entropy: 3.89123
Value Function Loss: 0.27762
Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10566
Policy Update Magnitude: 0.57828
Value Function Update Magnitude: 0.53065
Collected Steps per Second: 12,227.79934
Overall Steps per Second: 6,612.44756
Timestep Collection Time: 4.09084
Timestep Consumption Time: 3.47398
PPO Batch Consumption Time: 0.24313
Total Iteration Time: 7.56482
Cumulative Model Updates: 2,085
Cumulative Timesteps: 11,654,964
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70573
Policy Entropy: 3.89180
Value Function Loss: 0.27860
Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.11355
Policy Update Magnitude: 0.56422
Value Function Update Magnitude: 0.47852
Collected Steps per Second: 12,438.69269
Overall Steps per Second: 6,657.52007
Timestep Collection Time: 4.02020
Timestep Consumption Time: 3.49101
PPO Batch Consumption Time: 0.24250
Total Iteration Time: 7.51121
Cumulative Model Updates: 2,094
Cumulative Timesteps: 11,704,970
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 11704970...
Checkpoint 11704970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90055
Policy Entropy: 3.89568
Value Function Loss: 0.28520
Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.48703
Collected Steps per Second: 12,331.60122
Overall Steps per Second: 6,634.25972
Timestep Collection Time: 4.05560
Timestep Consumption Time: 3.48285
PPO Batch Consumption Time: 0.24204
Total Iteration Time: 7.53844
Cumulative Model Updates: 2,103
Cumulative Timesteps: 11,754,982
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06580
Policy Entropy: 3.89482
Value Function Loss: 0.29469
Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.55351
Value Function Update Magnitude: 0.51569
Collected Steps per Second: 11,917.46123
Overall Steps per Second: 6,501.17100
Timestep Collection Time: 4.19670
Timestep Consumption Time: 3.49638
PPO Batch Consumption Time: 0.24922
Total Iteration Time: 7.69308
Cumulative Model Updates: 2,112
Cumulative Timesteps: 11,804,996
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 11804996...
Checkpoint 11804996 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.62152
Policy Entropy: 3.89567
Value Function Loss: 0.29229
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11536
Policy Update Magnitude: 0.56331
Value Function Update Magnitude: 0.47115
Collected Steps per Second: 12,338.37008
Overall Steps per Second: 6,610.54664
Timestep Collection Time: 4.05305
Timestep Consumption Time: 3.51183
PPO Batch Consumption Time: 0.24390
Total Iteration Time: 7.56488
Cumulative Model Updates: 2,121
Cumulative Timesteps: 11,855,004
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.16463
Policy Entropy: 3.89551
Value Function Loss: 0.29909
Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.58463
Value Function Update Magnitude: 0.48030
Collected Steps per Second: 12,324.40039
Overall Steps per Second: 6,657.00970
Timestep Collection Time: 4.05862
Timestep Consumption Time: 3.45527
PPO Batch Consumption Time: 0.24227
Total Iteration Time: 7.51388
Cumulative Model Updates: 2,130
Cumulative Timesteps: 11,905,024
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 11905024...
Checkpoint 11905024 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22710
Policy Entropy: 3.89940
Value Function Loss: 0.30933
Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15387
Policy Update Magnitude: 0.58949
Value Function Update Magnitude: 0.53548
Collected Steps per Second: 12,625.40841
Overall Steps per Second: 6,693.94533
Timestep Collection Time: 3.96280
Timestep Consumption Time: 3.51141
PPO Batch Consumption Time: 0.24332
Total Iteration Time: 7.47422
Cumulative Model Updates: 2,139
Cumulative Timesteps: 11,955,056
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23801
Policy Entropy: 3.90140
Value Function Loss: 0.31125
Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.60789
Value Function Update Magnitude: 0.54687
Collected Steps per Second: 12,332.40203
Overall Steps per Second: 6,619.09157
Timestep Collection Time: 4.05501
Timestep Consumption Time: 3.50011
PPO Batch Consumption Time: 0.24308
Total Iteration Time: 7.55512
Cumulative Model Updates: 2,148
Cumulative Timesteps: 12,005,064
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 12005064...
Checkpoint 12005064 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.39566
Policy Entropy: 3.90403
Value Function Loss: 0.31760
Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.61120
Value Function Update Magnitude: 0.53417
Collected Steps per Second: 12,284.99630
Overall Steps per Second: 6,704.85815
Timestep Collection Time: 4.07212
Timestep Consumption Time: 3.38904
PPO Batch Consumption Time: 0.24286
Total Iteration Time: 7.46116
Cumulative Model Updates: 2,157
Cumulative Timesteps: 12,055,090
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64362
Policy Entropy: 3.90520
Value Function Loss: 0.30562
Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.61834
Value Function Update Magnitude: 0.56981
Collected Steps per Second: 12,264.70869
Overall Steps per Second: 6,579.49561
Timestep Collection Time: 4.07821
Timestep Consumption Time: 3.52390
PPO Batch Consumption Time: 0.24324
Total Iteration Time: 7.60210
Cumulative Model Updates: 2,166
Cumulative Timesteps: 12,105,108
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 12105108...
Checkpoint 12105108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.45966
Policy Entropy: 3.90926
Value Function Loss: 0.30526
Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.61103
Value Function Update Magnitude: 0.51758
Collected Steps per Second: 12,307.28401
Overall Steps per Second: 6,646.62552
Timestep Collection Time: 4.06345
Timestep Consumption Time: 3.46067
PPO Batch Consumption Time: 0.24322
Total Iteration Time: 7.52412
Cumulative Model Updates: 2,175
Cumulative Timesteps: 12,155,118
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.53149
Policy Entropy: 3.90207
Value Function Loss: 0.30064
Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.60187
Value Function Update Magnitude: 0.54387
Collected Steps per Second: 12,139.78269
Overall Steps per Second: 6,660.39075
Timestep Collection Time: 4.12017
Timestep Consumption Time: 3.38960
PPO Batch Consumption Time: 0.24244
Total Iteration Time: 7.50977
Cumulative Model Updates: 2,184
Cumulative Timesteps: 12,205,136
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 12205136...
Checkpoint 12205136 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24875
Policy Entropy: 3.90428
Value Function Loss: 0.30257
Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11654
Policy Update Magnitude: 0.58927
Value Function Update Magnitude: 0.49224
Collected Steps per Second: 12,184.61316
Overall Steps per Second: 6,584.51095
Timestep Collection Time: 4.10551
Timestep Consumption Time: 3.49172
PPO Batch Consumption Time: 0.24244
Total Iteration Time: 7.59722
Cumulative Model Updates: 2,193
Cumulative Timesteps: 12,255,160
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.78821
Policy Entropy: 3.89592
Value Function Loss: 0.29777
Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11537
Policy Update Magnitude: 0.58035
Value Function Update Magnitude: 0.52508
Collected Steps per Second: 11,884.13124
Overall Steps per Second: 6,535.36398
Timestep Collection Time: 4.20796
Timestep Consumption Time: 3.44394
PPO Batch Consumption Time: 0.24232
Total Iteration Time: 7.65191
Cumulative Model Updates: 2,202
Cumulative Timesteps: 12,305,168
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 12305168...
Checkpoint 12305168 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.15183
Policy Entropy: 3.90209
Value Function Loss: 0.31935
Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14266
Policy Update Magnitude: 0.58387
Value Function Update Magnitude: 0.56935
Collected Steps per Second: 12,089.86073
Overall Steps per Second: 6,428.31644
Timestep Collection Time: 4.13785
Timestep Consumption Time: 3.64428
PPO Batch Consumption Time: 0.24536
Total Iteration Time: 7.78213
Cumulative Model Updates: 2,211
Cumulative Timesteps: 12,355,194
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.23347
Policy Entropy: 3.89636
Value Function Loss: 0.31503
Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.59208
Value Function Update Magnitude: 0.84799
Collected Steps per Second: 11,462.60298
Overall Steps per Second: 6,211.00304
Timestep Collection Time: 4.36358
Timestep Consumption Time: 3.68955
PPO Batch Consumption Time: 0.25307
Total Iteration Time: 8.05313
Cumulative Model Updates: 2,220
Cumulative Timesteps: 12,405,212
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 12405212...
Checkpoint 12405212 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.22980
Policy Entropy: 3.89363
Value Function Loss: 0.32617
Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.58925
Value Function Update Magnitude: 0.82921
Collected Steps per Second: 11,629.00891
Overall Steps per Second: 6,400.07792
Timestep Collection Time: 4.30320
Timestep Consumption Time: 3.51576
PPO Batch Consumption Time: 0.24609
Total Iteration Time: 7.81897
Cumulative Model Updates: 2,229
Cumulative Timesteps: 12,455,254
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97049
Policy Entropy: 3.89145
Value Function Loss: 0.31246
Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14472
Policy Update Magnitude: 0.56932
Value Function Update Magnitude: 0.63792
Collected Steps per Second: 11,749.88886
Overall Steps per Second: 6,401.59866
Timestep Collection Time: 4.25774
Timestep Consumption Time: 3.55718
PPO Batch Consumption Time: 0.24307
Total Iteration Time: 7.81492
Cumulative Model Updates: 2,238
Cumulative Timesteps: 12,505,282
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 12505282...
Checkpoint 12505282 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19117
Policy Entropy: 3.89291
Value Function Loss: 0.31031
Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.56155
Value Function Update Magnitude: 0.55411
Collected Steps per Second: 12,320.89732
Overall Steps per Second: 6,656.24132
Timestep Collection Time: 4.06074
Timestep Consumption Time: 3.45581
PPO Batch Consumption Time: 0.24251
Total Iteration Time: 7.51655
Cumulative Model Updates: 2,247
Cumulative Timesteps: 12,555,314
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19130
Policy Entropy: 3.88868
Value Function Loss: 0.30645
Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.57727
Value Function Update Magnitude: 0.59095
Collected Steps per Second: 12,657.47090
Overall Steps per Second: 6,703.07917
Timestep Collection Time: 3.95324
Timestep Consumption Time: 3.51169
PPO Batch Consumption Time: 0.24247
Total Iteration Time: 7.46493
Cumulative Model Updates: 2,256
Cumulative Timesteps: 12,605,352
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 12605352...
Checkpoint 12605352 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.04864
Policy Entropy: 3.89187
Value Function Loss: 0.33070
Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.59748
Value Function Update Magnitude: 0.60845
Collected Steps per Second: 12,420.01570
Overall Steps per Second: 6,635.18247
Timestep Collection Time: 4.02785
Timestep Consumption Time: 3.51165
PPO Batch Consumption Time: 0.24264
Total Iteration Time: 7.53951
Cumulative Model Updates: 2,265
Cumulative Timesteps: 12,655,378
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.81851
Policy Entropy: 3.88570
Value Function Loss: 0.33180
Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.59813
Value Function Update Magnitude: 0.64060
Collected Steps per Second: 12,405.31762
Overall Steps per Second: 6,664.60822
Timestep Collection Time: 4.03198
Timestep Consumption Time: 3.47304
PPO Batch Consumption Time: 0.24941
Total Iteration Time: 7.50502
Cumulative Model Updates: 2,274
Cumulative Timesteps: 12,705,396
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 12705396...
Checkpoint 12705396 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.42109
Policy Entropy: 3.88716
Value Function Loss: 0.34249
Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.59067
Value Function Update Magnitude: 0.63410
Collected Steps per Second: 12,200.09630
Overall Steps per Second: 6,594.10724
Timestep Collection Time: 4.10177
Timestep Consumption Time: 3.48713
PPO Batch Consumption Time: 0.24369
Total Iteration Time: 7.58890
Cumulative Model Updates: 2,283
Cumulative Timesteps: 12,755,438
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79484
Policy Entropy: 3.88309
Value Function Loss: 0.32632
Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.58956
Value Function Update Magnitude: 0.58136
Collected Steps per Second: 12,315.56622
Overall Steps per Second: 6,655.31126
Timestep Collection Time: 4.06218
Timestep Consumption Time: 3.45483
PPO Batch Consumption Time: 0.24257
Total Iteration Time: 7.51700
Cumulative Model Updates: 2,292
Cumulative Timesteps: 12,805,466
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 12805466...
Checkpoint 12805466 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.96330
Policy Entropy: 3.88732
Value Function Loss: 0.32270
Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.58388
Value Function Update Magnitude: 0.56834
Collected Steps per Second: 12,466.56476
Overall Steps per Second: 6,650.23725
Timestep Collection Time: 4.01089
Timestep Consumption Time: 3.50794
PPO Batch Consumption Time: 0.24286
Total Iteration Time: 7.51883
Cumulative Model Updates: 2,301
Cumulative Timesteps: 12,855,468
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58146
Policy Entropy: 3.88817
Value Function Loss: 0.31767
Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.57790
Value Function Update Magnitude: 0.52529
Collected Steps per Second: 12,289.83883
Overall Steps per Second: 6,612.34214
Timestep Collection Time: 4.07019
Timestep Consumption Time: 3.49475
PPO Batch Consumption Time: 0.24255
Total Iteration Time: 7.56494
Cumulative Model Updates: 2,310
Cumulative Timesteps: 12,905,490
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 12905490...
Checkpoint 12905490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.10513
Policy Entropy: 3.88483
Value Function Loss: 0.33028
Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10461
Policy Update Magnitude: 0.58317
Value Function Update Magnitude: 0.57288
Collected Steps per Second: 12,177.98985
Overall Steps per Second: 6,701.49153
Timestep Collection Time: 4.10889
Timestep Consumption Time: 3.35781
PPO Batch Consumption Time: 0.24277
Total Iteration Time: 7.46670
Cumulative Model Updates: 2,319
Cumulative Timesteps: 12,955,528
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.54924
Policy Entropy: 3.88503
Value Function Loss: 0.33086
Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.59787
Value Function Update Magnitude: 0.51162
Collected Steps per Second: 12,180.47533
Overall Steps per Second: 6,486.19212
Timestep Collection Time: 4.10575
Timestep Consumption Time: 3.60447
PPO Batch Consumption Time: 0.25005
Total Iteration Time: 7.71022
Cumulative Model Updates: 2,328
Cumulative Timesteps: 13,005,538
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 13005538...
Checkpoint 13005538 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33110
Policy Entropy: 3.88142
Value Function Loss: 0.33649
Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.60426
Value Function Update Magnitude: 0.71257
Collected Steps per Second: 12,223.99052
Overall Steps per Second: 6,611.09995
Timestep Collection Time: 4.09277
Timestep Consumption Time: 3.47480
PPO Batch Consumption Time: 0.24340
Total Iteration Time: 7.56758
Cumulative Model Updates: 2,337
Cumulative Timesteps: 13,055,568
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.97971
Policy Entropy: 3.87643
Value Function Loss: 0.32128
Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.62084
Value Function Update Magnitude: 0.61042
Collected Steps per Second: 12,436.41672
Overall Steps per Second: 6,660.15725
Timestep Collection Time: 4.02158
Timestep Consumption Time: 3.48786
PPO Batch Consumption Time: 0.24201
Total Iteration Time: 7.50943
Cumulative Model Updates: 2,346
Cumulative Timesteps: 13,105,582
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 13105582...
Checkpoint 13105582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33401
Policy Entropy: 3.87601
Value Function Loss: 0.32883
Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.61638
Value Function Update Magnitude: 0.57004
Collected Steps per Second: 12,427.97837
Overall Steps per Second: 6,613.15323
Timestep Collection Time: 4.02624
Timestep Consumption Time: 3.54020
PPO Batch Consumption Time: 0.24280
Total Iteration Time: 7.56644
Cumulative Model Updates: 2,355
Cumulative Timesteps: 13,155,620
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.94503
Policy Entropy: 3.88636
Value Function Loss: 0.34990
Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.61158
Value Function Update Magnitude: 0.60414
Collected Steps per Second: 12,277.93986
Overall Steps per Second: 6,685.40054
Timestep Collection Time: 4.07577
Timestep Consumption Time: 3.40950
PPO Batch Consumption Time: 0.24310
Total Iteration Time: 7.48527
Cumulative Model Updates: 2,364
Cumulative Timesteps: 13,205,662
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 13205662...
Checkpoint 13205662 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52426
Policy Entropy: 3.88440
Value Function Loss: 0.34498
Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15172
Policy Update Magnitude: 0.61613
Value Function Update Magnitude: 0.60504
Collected Steps per Second: 12,431.68267
Overall Steps per Second: 6,636.80969
Timestep Collection Time: 4.02263
Timestep Consumption Time: 3.51232
PPO Batch Consumption Time: 0.24316
Total Iteration Time: 7.53495
Cumulative Model Updates: 2,373
Cumulative Timesteps: 13,255,670
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.11098
Policy Entropy: 3.88781
Value Function Loss: 0.33362
Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.60551
Value Function Update Magnitude: 0.64677
Collected Steps per Second: 12,357.66652
Overall Steps per Second: 6,590.59043
Timestep Collection Time: 4.04866
Timestep Consumption Time: 3.54277
PPO Batch Consumption Time: 0.24394
Total Iteration Time: 7.59143
Cumulative Model Updates: 2,382
Cumulative Timesteps: 13,305,702
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 13305702...
Checkpoint 13305702 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03686
Policy Entropy: 3.89089
Value Function Loss: 0.33767
Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.61236
Value Function Update Magnitude: 0.65500
Collected Steps per Second: 11,733.25478
Overall Steps per Second: 6,519.71127
Timestep Collection Time: 4.26395
Timestep Consumption Time: 3.40970
PPO Batch Consumption Time: 0.24352
Total Iteration Time: 7.67365
Cumulative Model Updates: 2,391
Cumulative Timesteps: 13,355,732
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.07096
Policy Entropy: 3.88706
Value Function Loss: 0.35305
Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.61869
Value Function Update Magnitude: 0.70755
Collected Steps per Second: 11,844.05805
Overall Steps per Second: 6,438.05469
Timestep Collection Time: 4.22406
Timestep Consumption Time: 3.54692
PPO Batch Consumption Time: 0.24387
Total Iteration Time: 7.77098
Cumulative Model Updates: 2,400
Cumulative Timesteps: 13,405,762
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 13405762...
Checkpoint 13405762 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.09326
Policy Entropy: 3.88755
Value Function Loss: 0.35291
Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.60987
Value Function Update Magnitude: 0.57698
Collected Steps per Second: 12,024.56580
Overall Steps per Second: 6,556.64528
Timestep Collection Time: 4.15815
Timestep Consumption Time: 3.46770
PPO Batch Consumption Time: 0.24220
Total Iteration Time: 7.62585
Cumulative Model Updates: 2,409
Cumulative Timesteps: 13,455,762
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.11660
Policy Entropy: 3.88690
Value Function Loss: 0.33908
Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.59990
Value Function Update Magnitude: 0.57346
Collected Steps per Second: 12,576.71496
Overall Steps per Second: 6,704.33995
Timestep Collection Time: 3.97656
Timestep Consumption Time: 3.48309
PPO Batch Consumption Time: 0.24224
Total Iteration Time: 7.45965
Cumulative Model Updates: 2,418
Cumulative Timesteps: 13,505,774
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 13505774...
Checkpoint 13505774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01875
Policy Entropy: 3.88216
Value Function Loss: 0.34785
Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.58834
Value Function Update Magnitude: 0.53004
Collected Steps per Second: 12,334.59211
Overall Steps per Second: 6,619.31857
Timestep Collection Time: 4.05461
Timestep Consumption Time: 3.50085
PPO Batch Consumption Time: 0.24277
Total Iteration Time: 7.55546
Cumulative Model Updates: 2,427
Cumulative Timesteps: 13,555,786
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85466
Policy Entropy: 3.88268
Value Function Loss: 0.33825
Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.58556
Value Function Update Magnitude: 0.52946
Collected Steps per Second: 12,167.78272
Overall Steps per Second: 6,626.49105
Timestep Collection Time: 4.10921
Timestep Consumption Time: 3.43626
PPO Batch Consumption Time: 0.24393
Total Iteration Time: 7.54547
Cumulative Model Updates: 2,436
Cumulative Timesteps: 13,605,786
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 13605786...
Checkpoint 13605786 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12329
Policy Entropy: 3.88307
Value Function Loss: 0.34042
Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.58132
Value Function Update Magnitude: 0.52019
Collected Steps per Second: 12,287.50764
Overall Steps per Second: 6,590.24488
Timestep Collection Time: 4.07292
Timestep Consumption Time: 3.52103
PPO Batch Consumption Time: 0.24351
Total Iteration Time: 7.59395
Cumulative Model Updates: 2,445
Cumulative Timesteps: 13,655,832
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49831
Policy Entropy: 3.88606
Value Function Loss: 0.33117
Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.52295
Collected Steps per Second: 12,406.21127
Overall Steps per Second: 6,665.87091
Timestep Collection Time: 4.03056
Timestep Consumption Time: 3.47093
PPO Batch Consumption Time: 0.24254
Total Iteration Time: 7.50150
Cumulative Model Updates: 2,454
Cumulative Timesteps: 13,705,836
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 13705836...
Checkpoint 13705836 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05516
Policy Entropy: 3.87820
Value Function Loss: 0.33396
Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.57880
Value Function Update Magnitude: 0.53023
Collected Steps per Second: 12,559.60235
Overall Steps per Second: 6,735.54591
Timestep Collection Time: 3.98118
Timestep Consumption Time: 3.44242
PPO Batch Consumption Time: 0.24251
Total Iteration Time: 7.42360
Cumulative Model Updates: 2,463
Cumulative Timesteps: 13,755,838
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.56659
Policy Entropy: 3.86602
Value Function Loss: 0.33182
Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.56903
Value Function Update Magnitude: 0.53996
Collected Steps per Second: 12,301.12292
Overall Steps per Second: 6,628.11056
Timestep Collection Time: 4.06922
Timestep Consumption Time: 3.48285
PPO Batch Consumption Time: 0.24239
Total Iteration Time: 7.55208
Cumulative Model Updates: 2,472
Cumulative Timesteps: 13,805,894
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 13805894...
Checkpoint 13805894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.14737
Policy Entropy: 3.87392
Value Function Loss: 0.33066
Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.55456
Value Function Update Magnitude: 0.54453
Collected Steps per Second: 12,437.51999
Overall Steps per Second: 6,682.65391
Timestep Collection Time: 4.02267
Timestep Consumption Time: 3.46418
PPO Batch Consumption Time: 0.24252
Total Iteration Time: 7.48685
Cumulative Model Updates: 2,481
Cumulative Timesteps: 13,855,926
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.15338
Policy Entropy: 3.87141
Value Function Loss: 0.34104
Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12250
Policy Update Magnitude: 0.56419
Value Function Update Magnitude: 0.50017
Collected Steps per Second: 12,625.94362
Overall Steps per Second: 6,655.73999
Timestep Collection Time: 3.96200
Timestep Consumption Time: 3.55392
PPO Batch Consumption Time: 0.24898
Total Iteration Time: 7.51592
Cumulative Model Updates: 2,490
Cumulative Timesteps: 13,905,950
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 13905950...
Checkpoint 13905950 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64153
Policy Entropy: 3.87389
Value Function Loss: 0.36629
Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.58576
Value Function Update Magnitude: 0.59217
Collected Steps per Second: 12,403.66581
Overall Steps per Second: 6,641.92149
Timestep Collection Time: 4.03348
Timestep Consumption Time: 3.49897
PPO Batch Consumption Time: 0.24249
Total Iteration Time: 7.53246
Cumulative Model Updates: 2,499
Cumulative Timesteps: 13,955,980
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.67607
Policy Entropy: 3.86649
Value Function Loss: 0.36675
Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.59836
Value Function Update Magnitude: 0.61254
Collected Steps per Second: 12,401.55011
Overall Steps per Second: 6,746.41669
Timestep Collection Time: 4.03208
Timestep Consumption Time: 3.37986
PPO Batch Consumption Time: 0.24254
Total Iteration Time: 7.41193
Cumulative Model Updates: 2,508
Cumulative Timesteps: 14,005,984
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 14005984...
Checkpoint 14005984 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90832
Policy Entropy: 3.86273
Value Function Loss: 0.36336
Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.58549
Value Function Update Magnitude: 0.59970
Collected Steps per Second: 12,361.76291
Overall Steps per Second: 6,634.35659
Timestep Collection Time: 4.04538
Timestep Consumption Time: 3.49235
PPO Batch Consumption Time: 0.24343
Total Iteration Time: 7.53773
Cumulative Model Updates: 2,517
Cumulative Timesteps: 14,055,992
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.12667
Policy Entropy: 3.85744
Value Function Loss: 0.33776
Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.58207
Value Function Update Magnitude: 0.54711
Collected Steps per Second: 12,343.44740
Overall Steps per Second: 6,673.06768
Timestep Collection Time: 4.05122
Timestep Consumption Time: 3.44249
PPO Batch Consumption Time: 0.24243
Total Iteration Time: 7.49370
Cumulative Model Updates: 2,526
Cumulative Timesteps: 14,105,998
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 14105998...
Checkpoint 14105998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.73243
Policy Entropy: 3.84946
Value Function Loss: 0.34664
Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.59117
Value Function Update Magnitude: 0.61103
Collected Steps per Second: 12,525.70404
Overall Steps per Second: 6,683.01957
Timestep Collection Time: 3.99227
Timestep Consumption Time: 3.49028
PPO Batch Consumption Time: 0.24218
Total Iteration Time: 7.48255
Cumulative Model Updates: 2,535
Cumulative Timesteps: 14,156,004
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46300
Policy Entropy: 3.84408
Value Function Loss: 0.33721
Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.58981
Value Function Update Magnitude: 0.62353
Collected Steps per Second: 12,126.93107
Overall Steps per Second: 6,534.18426
Timestep Collection Time: 4.12388
Timestep Consumption Time: 3.52972
PPO Batch Consumption Time: 0.24749
Total Iteration Time: 7.65359
Cumulative Model Updates: 2,544
Cumulative Timesteps: 14,206,014
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 14206014...
Checkpoint 14206014 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.85039
Policy Entropy: 3.84648
Value Function Loss: 0.35056
Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.58860
Value Function Update Magnitude: 0.63936
Collected Steps per Second: 12,179.35570
Overall Steps per Second: 6,603.87249
Timestep Collection Time: 4.10695
Timestep Consumption Time: 3.46739
PPO Batch Consumption Time: 0.24284
Total Iteration Time: 7.57434
Cumulative Model Updates: 2,553
Cumulative Timesteps: 14,256,034
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80907
Policy Entropy: 3.85000
Value Function Loss: 0.35535
Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.58643
Value Function Update Magnitude: 0.58919
Collected Steps per Second: 12,612.16129
Overall Steps per Second: 6,709.10707
Timestep Collection Time: 3.96633
Timestep Consumption Time: 3.48980
PPO Batch Consumption Time: 0.24208
Total Iteration Time: 7.45613
Cumulative Model Updates: 2,562
Cumulative Timesteps: 14,306,058
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 14306058...
Checkpoint 14306058 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71492
Policy Entropy: 3.85374
Value Function Loss: 0.35190
Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.58452
Value Function Update Magnitude: 0.56401
Collected Steps per Second: 12,103.98360
Overall Steps per Second: 6,550.45548
Timestep Collection Time: 4.13170
Timestep Consumption Time: 3.50289
PPO Batch Consumption Time: 0.24304
Total Iteration Time: 7.63458
Cumulative Model Updates: 2,571
Cumulative Timesteps: 14,356,068
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85901
Policy Entropy: 3.85333
Value Function Loss: 0.34868
Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.58003
Value Function Update Magnitude: 0.55824
Collected Steps per Second: 12,289.71134
Overall Steps per Second: 6,701.03009
Timestep Collection Time: 4.07056
Timestep Consumption Time: 3.39486
PPO Batch Consumption Time: 0.24216
Total Iteration Time: 7.46542
Cumulative Model Updates: 2,580
Cumulative Timesteps: 14,406,094
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 14406094...
Checkpoint 14406094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27346
Policy Entropy: 3.85908
Value Function Loss: 0.33758
Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.57111
Value Function Update Magnitude: 0.52095
Collected Steps per Second: 12,354.38469
Overall Steps per Second: 6,637.81615
Timestep Collection Time: 4.04731
Timestep Consumption Time: 3.48559
PPO Batch Consumption Time: 0.24188
Total Iteration Time: 7.53290
Cumulative Model Updates: 2,589
Cumulative Timesteps: 14,456,096
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.20109
Policy Entropy: 3.85179
Value Function Loss: 0.32708
Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.56323
Value Function Update Magnitude: 0.49374
Collected Steps per Second: 12,383.06336
Overall Steps per Second: 6,671.34006
Timestep Collection Time: 4.03793
Timestep Consumption Time: 3.45711
PPO Batch Consumption Time: 0.24264
Total Iteration Time: 7.49505
Cumulative Model Updates: 2,598
Cumulative Timesteps: 14,506,098
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 14506098...
Checkpoint 14506098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.15141
Policy Entropy: 3.85050
Value Function Loss: 0.32853
Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.56378
Value Function Update Magnitude: 0.49216
Collected Steps per Second: 12,693.13065
Overall Steps per Second: 6,682.57772
Timestep Collection Time: 3.94339
Timestep Consumption Time: 3.54683
PPO Batch Consumption Time: 0.24473
Total Iteration Time: 7.49022
Cumulative Model Updates: 2,607
Cumulative Timesteps: 14,556,152
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.30232
Policy Entropy: 3.84869
Value Function Loss: 0.33000
Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.56263
Value Function Update Magnitude: 0.51833
Collected Steps per Second: 12,455.12222
Overall Steps per Second: 6,648.10187
Timestep Collection Time: 4.01602
Timestep Consumption Time: 3.50793
PPO Batch Consumption Time: 0.24266
Total Iteration Time: 7.52395
Cumulative Model Updates: 2,616
Cumulative Timesteps: 14,606,172
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 14606172...
Checkpoint 14606172 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85015
Policy Entropy: 3.85020
Value Function Loss: 0.35532
Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.57945
Value Function Update Magnitude: 0.56048
Collected Steps per Second: 12,419.02152
Overall Steps per Second: 6,736.33661
Timestep Collection Time: 4.02801
Timestep Consumption Time: 3.39798
PPO Batch Consumption Time: 0.24310
Total Iteration Time: 7.42599
Cumulative Model Updates: 2,625
Cumulative Timesteps: 14,656,196
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97360
Policy Entropy: 3.85612
Value Function Loss: 0.35272
Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.60830
Value Function Update Magnitude: 0.58828
Collected Steps per Second: 12,449.08648
Overall Steps per Second: 6,649.43786
Timestep Collection Time: 4.01797
Timestep Consumption Time: 3.50447
PPO Batch Consumption Time: 0.24206
Total Iteration Time: 7.52244
Cumulative Model Updates: 2,634
Cumulative Timesteps: 14,706,216
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 14706216...
Checkpoint 14706216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76890
Policy Entropy: 3.85303
Value Function Loss: 0.34603
Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.61329
Value Function Update Magnitude: 0.55230
Collected Steps per Second: 12,264.49135
Overall Steps per Second: 6,646.07424
Timestep Collection Time: 4.07811
Timestep Consumption Time: 3.44753
PPO Batch Consumption Time: 0.24219
Total Iteration Time: 7.52565
Cumulative Model Updates: 2,643
Cumulative Timesteps: 14,756,232
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.14433
Policy Entropy: 3.85350
Value Function Loss: 0.33082
Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.59974
Value Function Update Magnitude: 0.54026
Collected Steps per Second: 12,275.20985
Overall Steps per Second: 6,696.03333
Timestep Collection Time: 4.07423
Timestep Consumption Time: 3.39467
PPO Batch Consumption Time: 0.24222
Total Iteration Time: 7.46890
Cumulative Model Updates: 2,652
Cumulative Timesteps: 14,806,244
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 14806244...
Checkpoint 14806244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.66380
Policy Entropy: 3.85251
Value Function Loss: 0.34094
Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.11097
Policy Update Magnitude: 0.59135
Value Function Update Magnitude: 0.56262
Collected Steps per Second: 12,216.34449
Overall Steps per Second: 6,546.45925
Timestep Collection Time: 4.09419
Timestep Consumption Time: 3.54597
PPO Batch Consumption Time: 0.24461
Total Iteration Time: 7.64016
Cumulative Model Updates: 2,661
Cumulative Timesteps: 14,856,260
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.20092
Policy Entropy: 3.84268
Value Function Loss: 0.33240
Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.60354
Value Function Update Magnitude: 0.57967
Collected Steps per Second: 12,255.87438
Overall Steps per Second: 6,637.29406
Timestep Collection Time: 4.08196
Timestep Consumption Time: 3.45545
PPO Batch Consumption Time: 0.24216
Total Iteration Time: 7.53741
Cumulative Model Updates: 2,670
Cumulative Timesteps: 14,906,288
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 14906288...
Checkpoint 14906288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93692
Policy Entropy: 3.84084
Value Function Loss: 0.34438
Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.60429
Value Function Update Magnitude: 0.57180
Collected Steps per Second: 12,429.95507
Overall Steps per Second: 6,661.94619
Timestep Collection Time: 4.02383
Timestep Consumption Time: 3.48389
PPO Batch Consumption Time: 0.24181
Total Iteration Time: 7.50772
Cumulative Model Updates: 2,679
Cumulative Timesteps: 14,956,304
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.48711
Policy Entropy: 3.83998
Value Function Loss: 0.33840
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.59682
Value Function Update Magnitude: 0.58937
Collected Steps per Second: 12,299.55739
Overall Steps per Second: 6,618.55049
Timestep Collection Time: 4.06876
Timestep Consumption Time: 3.49241
PPO Batch Consumption Time: 0.24218
Total Iteration Time: 7.56117
Cumulative Model Updates: 2,688
Cumulative Timesteps: 15,006,348
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 15006348...
Checkpoint 15006348 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29163
Policy Entropy: 3.83953
Value Function Loss: 0.35329
Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.59576
Value Function Update Magnitude: 0.54189
Collected Steps per Second: 12,247.62529
Overall Steps per Second: 6,699.34630
Timestep Collection Time: 4.08487
Timestep Consumption Time: 3.38302
PPO Batch Consumption Time: 0.24223
Total Iteration Time: 7.46789
Cumulative Model Updates: 2,697
Cumulative Timesteps: 15,056,378
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77769
Policy Entropy: 3.84258
Value Function Loss: 0.35780
Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.59936
Value Function Update Magnitude: 0.56868
Collected Steps per Second: 12,302.80373
Overall Steps per Second: 6,628.80552
Timestep Collection Time: 4.06574
Timestep Consumption Time: 3.48011
PPO Batch Consumption Time: 0.24258
Total Iteration Time: 7.54585
Cumulative Model Updates: 2,706
Cumulative Timesteps: 15,106,398
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 15106398...
Checkpoint 15106398 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.67267
Policy Entropy: 3.84299
Value Function Loss: 0.35360
Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.59275
Value Function Update Magnitude: 0.57542
Collected Steps per Second: 12,243.10837
Overall Steps per Second: 6,574.60000
Timestep Collection Time: 4.08393
Timestep Consumption Time: 3.52110
PPO Batch Consumption Time: 0.24362
Total Iteration Time: 7.60503
Cumulative Model Updates: 2,715
Cumulative Timesteps: 15,156,398
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.26568
Policy Entropy: 3.84171
Value Function Loss: 0.35532
Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.58635
Value Function Update Magnitude: 0.56589
Collected Steps per Second: 12,639.77503
Overall Steps per Second: 6,712.68637
Timestep Collection Time: 3.95624
Timestep Consumption Time: 3.49324
PPO Batch Consumption Time: 0.24258
Total Iteration Time: 7.44948
Cumulative Model Updates: 2,724
Cumulative Timesteps: 15,206,404
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 15206404...
Checkpoint 15206404 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.78166
Policy Entropy: 3.83094
Value Function Loss: 0.35119
Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15667
Policy Update Magnitude: 0.58211
Value Function Update Magnitude: 0.55525
Collected Steps per Second: 12,345.23078
Overall Steps per Second: 6,630.36479
Timestep Collection Time: 4.05161
Timestep Consumption Time: 3.49217
PPO Batch Consumption Time: 0.24296
Total Iteration Time: 7.54378
Cumulative Model Updates: 2,733
Cumulative Timesteps: 15,256,422
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.20799
Policy Entropy: 3.83288
Value Function Loss: 0.36186
Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.58443
Value Function Update Magnitude: 0.54046
Collected Steps per Second: 12,204.02685
Overall Steps per Second: 6,674.82517
Timestep Collection Time: 4.09750
Timestep Consumption Time: 3.39423
PPO Batch Consumption Time: 0.24276
Total Iteration Time: 7.49173
Cumulative Model Updates: 2,742
Cumulative Timesteps: 15,306,428
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 15306428...
Checkpoint 15306428 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77014
Policy Entropy: 3.82828
Value Function Loss: 0.35929
Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.58311
Value Function Update Magnitude: 0.53497
Collected Steps per Second: 12,441.07286
Overall Steps per Second: 6,660.32677
Timestep Collection Time: 4.02200
Timestep Consumption Time: 3.49084
PPO Batch Consumption Time: 0.24260
Total Iteration Time: 7.51284
Cumulative Model Updates: 2,751
Cumulative Timesteps: 15,356,466
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28620
Policy Entropy: 3.83076
Value Function Loss: 0.36326
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.58561
Value Function Update Magnitude: 0.55206
Collected Steps per Second: 12,454.62586
Overall Steps per Second: 6,691.89189
Timestep Collection Time: 4.01666
Timestep Consumption Time: 3.45895
PPO Batch Consumption Time: 0.24219
Total Iteration Time: 7.47561
Cumulative Model Updates: 2,760
Cumulative Timesteps: 15,406,492
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 15406492...
Checkpoint 15406492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01227
Policy Entropy: 3.83219
Value Function Loss: 0.35509
Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.57871
Value Function Update Magnitude: 0.60728
Collected Steps per Second: 12,164.60140
Overall Steps per Second: 6,625.29953
Timestep Collection Time: 4.11094
Timestep Consumption Time: 3.43709
PPO Batch Consumption Time: 0.24431
Total Iteration Time: 7.54804
Cumulative Model Updates: 2,769
Cumulative Timesteps: 15,456,500
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64435
Policy Entropy: 3.83108
Value Function Loss: 0.34924
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.57894
Value Function Update Magnitude: 0.56352
Collected Steps per Second: 12,246.61814
Overall Steps per Second: 6,598.72659
Timestep Collection Time: 4.08619
Timestep Consumption Time: 3.49740
PPO Batch Consumption Time: 0.24195
Total Iteration Time: 7.58358
Cumulative Model Updates: 2,778
Cumulative Timesteps: 15,506,542
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 15506542...
Checkpoint 15506542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01199
Policy Entropy: 3.82700
Value Function Loss: 0.33522
Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.56658
Value Function Update Magnitude: 0.55134
Collected Steps per Second: 12,250.15109
Overall Steps per Second: 6,715.71216
Timestep Collection Time: 4.08207
Timestep Consumption Time: 3.36405
PPO Batch Consumption Time: 0.24222
Total Iteration Time: 7.44612
Cumulative Model Updates: 2,787
Cumulative Timesteps: 15,556,548
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24626
Policy Entropy: 3.82089
Value Function Loss: 0.34234
Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.56060
Value Function Update Magnitude: 0.53571
Collected Steps per Second: 12,348.04420
Overall Steps per Second: 6,632.22795
Timestep Collection Time: 4.05052
Timestep Consumption Time: 3.49084
PPO Batch Consumption Time: 0.24279
Total Iteration Time: 7.54136
Cumulative Model Updates: 2,796
Cumulative Timesteps: 15,606,564
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 15606564...
Checkpoint 15606564 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.17355
Policy Entropy: 3.81904
Value Function Loss: 0.34635
Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.56875
Collected Steps per Second: 12,298.41710
Overall Steps per Second: 6,648.71780
Timestep Collection Time: 4.06735
Timestep Consumption Time: 3.45620
PPO Batch Consumption Time: 0.24275
Total Iteration Time: 7.52356
Cumulative Model Updates: 2,805
Cumulative Timesteps: 15,656,586
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.48671
Policy Entropy: 3.81373
Value Function Loss: 0.36832
Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.58098
Value Function Update Magnitude: 0.63154
Collected Steps per Second: 12,336.89652
Overall Steps per Second: 6,723.48518
Timestep Collection Time: 4.05450
Timestep Consumption Time: 3.38509
PPO Batch Consumption Time: 0.24264
Total Iteration Time: 7.43959
Cumulative Model Updates: 2,814
Cumulative Timesteps: 15,706,606
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 15706606...
Checkpoint 15706606 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56511
Policy Entropy: 3.81028
Value Function Loss: 0.37631
Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.59746
Value Function Update Magnitude: 0.64772
Collected Steps per Second: 12,311.35582
Overall Steps per Second: 6,546.17648
Timestep Collection Time: 4.06470
Timestep Consumption Time: 3.57976
PPO Batch Consumption Time: 0.24980
Total Iteration Time: 7.64446
Cumulative Model Updates: 2,823
Cumulative Timesteps: 15,756,648
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77352
Policy Entropy: 3.80917
Value Function Loss: 0.38326
Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.60299
Value Function Update Magnitude: 0.65444
Collected Steps per Second: 12,298.31198
Overall Steps per Second: 6,641.01564
Timestep Collection Time: 4.06625
Timestep Consumption Time: 3.46392
PPO Batch Consumption Time: 0.24243
Total Iteration Time: 7.53017
Cumulative Model Updates: 2,832
Cumulative Timesteps: 15,806,656
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 15806656...
Checkpoint 15806656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.49704
Policy Entropy: 3.80527
Value Function Loss: 0.37629
Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.59520
Value Function Update Magnitude: 0.65049
Collected Steps per Second: 12,776.13680
Overall Steps per Second: 6,746.81418
Timestep Collection Time: 3.91589
Timestep Consumption Time: 3.49946
PPO Batch Consumption Time: 0.24226
Total Iteration Time: 7.41535
Cumulative Model Updates: 2,841
Cumulative Timesteps: 15,856,686
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.68911
Policy Entropy: 3.80146
Value Function Loss: 0.38949
Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.59561
Value Function Update Magnitude: 0.61279
Collected Steps per Second: 12,343.93770
Overall Steps per Second: 6,626.20692
Timestep Collection Time: 4.05187
Timestep Consumption Time: 3.49634
PPO Batch Consumption Time: 0.24228
Total Iteration Time: 7.54821
Cumulative Model Updates: 2,850
Cumulative Timesteps: 15,906,702
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 15906702...
Checkpoint 15906702 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.64218
Policy Entropy: 3.80204
Value Function Loss: 0.38507
Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.60133
Value Function Update Magnitude: 0.65406
Collected Steps per Second: 12,332.20990
Overall Steps per Second: 6,733.36564
Timestep Collection Time: 4.05702
Timestep Consumption Time: 3.37344
PPO Batch Consumption Time: 0.24196
Total Iteration Time: 7.43046
Cumulative Model Updates: 2,859
Cumulative Timesteps: 15,956,734
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.21887
Policy Entropy: 3.80365
Value Function Loss: 0.37839
Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.63143
Value Function Update Magnitude: 0.66417
Collected Steps per Second: 12,528.94640
Overall Steps per Second: 6,676.83110
Timestep Collection Time: 3.99363
Timestep Consumption Time: 3.50034
PPO Batch Consumption Time: 0.24225
Total Iteration Time: 7.49397
Cumulative Model Updates: 2,868
Cumulative Timesteps: 16,006,770
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 16006770...
Checkpoint 16006770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.93335
Policy Entropy: 3.80145
Value Function Loss: 0.36819
Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.62398
Value Function Update Magnitude: 0.60160
Collected Steps per Second: 12,279.20511
Overall Steps per Second: 6,587.88373
Timestep Collection Time: 4.07486
Timestep Consumption Time: 3.52030
PPO Batch Consumption Time: 0.25053
Total Iteration Time: 7.59516
Cumulative Model Updates: 2,877
Cumulative Timesteps: 16,056,806
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12866
Policy Entropy: 3.79924
Value Function Loss: 0.36830
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.61200
Value Function Update Magnitude: 0.59731
Collected Steps per Second: 12,208.80747
Overall Steps per Second: 6,712.11077
Timestep Collection Time: 4.09655
Timestep Consumption Time: 3.35476
PPO Batch Consumption Time: 0.24267
Total Iteration Time: 7.45131
Cumulative Model Updates: 2,886
Cumulative Timesteps: 16,106,820
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 16106820...
Checkpoint 16106820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 20.14654
Policy Entropy: 3.80264
Value Function Loss: 0.39418
Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14096
Policy Update Magnitude: 0.61021
Value Function Update Magnitude: 0.65935
Collected Steps per Second: 12,307.47252
Overall Steps per Second: 6,620.22436
Timestep Collection Time: 4.06550
Timestep Consumption Time: 3.49255
PPO Batch Consumption Time: 0.24279
Total Iteration Time: 7.55805
Cumulative Model Updates: 2,895
Cumulative Timesteps: 16,156,856
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54646
Policy Entropy: 3.80396
Value Function Loss: 0.40149
Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.61442
Value Function Update Magnitude: 0.65001
Collected Steps per Second: 12,147.08863
Overall Steps per Second: 6,589.40356
Timestep Collection Time: 4.11737
Timestep Consumption Time: 3.47270
PPO Batch Consumption Time: 0.24322
Total Iteration Time: 7.59006
Cumulative Model Updates: 2,904
Cumulative Timesteps: 16,206,870
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 16206870...
Checkpoint 16206870 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.62951
Policy Entropy: 3.79858
Value Function Loss: 0.41479
Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.61418
Value Function Update Magnitude: 0.72268
Collected Steps per Second: 12,453.19257
Overall Steps per Second: 6,662.29385
Timestep Collection Time: 4.01760
Timestep Consumption Time: 3.49212
PPO Batch Consumption Time: 0.24258
Total Iteration Time: 7.50973
Cumulative Model Updates: 2,913
Cumulative Timesteps: 16,256,902
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82562
Policy Entropy: 3.79150
Value Function Loss: 0.39883
Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.61457
Value Function Update Magnitude: 0.64165
Collected Steps per Second: 12,227.64239
Overall Steps per Second: 6,581.47965
Timestep Collection Time: 4.09139
Timestep Consumption Time: 3.50994
PPO Batch Consumption Time: 0.24216
Total Iteration Time: 7.60133
Cumulative Model Updates: 2,922
Cumulative Timesteps: 16,306,930
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 16306930...
Checkpoint 16306930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.38603
Policy Entropy: 3.79134
Value Function Loss: 0.41125
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.61246
Value Function Update Magnitude: 0.65462
Collected Steps per Second: 12,055.31183
Overall Steps per Second: 6,594.97965
Timestep Collection Time: 4.14854
Timestep Consumption Time: 3.43480
PPO Batch Consumption Time: 0.24417
Total Iteration Time: 7.58334
Cumulative Model Updates: 2,931
Cumulative Timesteps: 16,356,942
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.89619
Policy Entropy: 3.78864
Value Function Loss: 0.38756
Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.61321
Value Function Update Magnitude: 0.63300
Collected Steps per Second: 12,433.46001
Overall Steps per Second: 6,648.49797
Timestep Collection Time: 4.02269
Timestep Consumption Time: 3.50021
PPO Batch Consumption Time: 0.24270
Total Iteration Time: 7.52290
Cumulative Model Updates: 2,940
Cumulative Timesteps: 16,406,958
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 16406958...
Checkpoint 16406958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.16060
Policy Entropy: 3.78858
Value Function Loss: 0.39114
Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.60586
Value Function Update Magnitude: 0.58734
Collected Steps per Second: 12,299.24982
Overall Steps per Second: 6,560.85692
Timestep Collection Time: 4.06822
Timestep Consumption Time: 3.55823
PPO Batch Consumption Time: 0.25363
Total Iteration Time: 7.62644
Cumulative Model Updates: 2,949
Cumulative Timesteps: 16,456,994
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.09991
Policy Entropy: 3.78595
Value Function Loss: 0.37345
Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.60917
Value Function Update Magnitude: 0.56621
Collected Steps per Second: 11,198.92832
Overall Steps per Second: 6,268.29247
Timestep Collection Time: 4.46507
Timestep Consumption Time: 3.51222
PPO Batch Consumption Time: 0.24220
Total Iteration Time: 7.97729
Cumulative Model Updates: 2,958
Cumulative Timesteps: 16,506,998
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 16506998...
Checkpoint 16506998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.49646
Policy Entropy: 3.78457
Value Function Loss: 0.37248
Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.59984
Value Function Update Magnitude: 0.56918
Collected Steps per Second: 12,039.39746
Overall Steps per Second: 6,473.51737
Timestep Collection Time: 4.15336
Timestep Consumption Time: 3.57103
PPO Batch Consumption Time: 0.25060
Total Iteration Time: 7.72439
Cumulative Model Updates: 2,967
Cumulative Timesteps: 16,557,002
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32410
Policy Entropy: 3.78678
Value Function Loss: 0.37650
Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.57774
Value Function Update Magnitude: 0.52451
Collected Steps per Second: 11,992.22497
Overall Steps per Second: 6,475.21379
Timestep Collection Time: 4.17254
Timestep Consumption Time: 3.55508
PPO Batch Consumption Time: 0.25337
Total Iteration Time: 7.72762
Cumulative Model Updates: 2,976
Cumulative Timesteps: 16,607,040
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 16607040...
Checkpoint 16607040 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.62512
Policy Entropy: 3.79031
Value Function Loss: 0.41206
Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.59763
Value Function Update Magnitude: 0.60611
Collected Steps per Second: 11,032.54975
Overall Steps per Second: 6,183.65691
Timestep Collection Time: 4.53621
Timestep Consumption Time: 3.55706
PPO Batch Consumption Time: 0.24623
Total Iteration Time: 8.09327
Cumulative Model Updates: 2,985
Cumulative Timesteps: 16,657,086
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.62771
Policy Entropy: 3.78305
Value Function Loss: 0.40907
Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.60253
Value Function Update Magnitude: 0.59308
Collected Steps per Second: 10,512.26902
Overall Steps per Second: 5,954.56611
Timestep Collection Time: 4.75749
Timestep Consumption Time: 3.64144
PPO Batch Consumption Time: 0.24863
Total Iteration Time: 8.39893
Cumulative Model Updates: 2,994
Cumulative Timesteps: 16,707,098
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 16707098...
Checkpoint 16707098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23676
Policy Entropy: 3.78543
Value Function Loss: 0.40377
Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.59541
Value Function Update Magnitude: 0.57228
Collected Steps per Second: 11,351.79799
Overall Steps per Second: 6,385.37179
Timestep Collection Time: 4.40565
Timestep Consumption Time: 3.42663
PPO Batch Consumption Time: 0.24599
Total Iteration Time: 7.83228
Cumulative Model Updates: 3,003
Cumulative Timesteps: 16,757,110
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18273
Policy Entropy: 3.77909
Value Function Loss: 0.37918
Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.58636
Value Function Update Magnitude: 0.56692
Collected Steps per Second: 12,210.76548
Overall Steps per Second: 6,529.81615
Timestep Collection Time: 4.09770
Timestep Consumption Time: 3.56500
PPO Batch Consumption Time: 0.24989
Total Iteration Time: 7.66270
Cumulative Model Updates: 3,012
Cumulative Timesteps: 16,807,146
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 16807146...
Checkpoint 16807146 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.84446
Policy Entropy: 3.78128
Value Function Loss: 0.38689
Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.58741
Value Function Update Magnitude: 0.57326
Collected Steps per Second: 11,903.81669
Overall Steps per Second: 6,448.57525
Timestep Collection Time: 4.20033
Timestep Consumption Time: 3.55332
PPO Batch Consumption Time: 0.25036
Total Iteration Time: 7.75365
Cumulative Model Updates: 3,021
Cumulative Timesteps: 16,857,146
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50517
Policy Entropy: 3.78365
Value Function Loss: 0.39153
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.59906
Value Function Update Magnitude: 0.56130
Collected Steps per Second: 11,971.03111
Overall Steps per Second: 6,366.63635
Timestep Collection Time: 4.17926
Timestep Consumption Time: 3.67890
PPO Batch Consumption Time: 0.25336
Total Iteration Time: 7.85815
Cumulative Model Updates: 3,030
Cumulative Timesteps: 16,907,176
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 16907176...
Checkpoint 16907176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.03742
Policy Entropy: 3.78274
Value Function Loss: 0.38905
Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.60123
Value Function Update Magnitude: 0.59160
Collected Steps per Second: 11,823.32561
Overall Steps per Second: 6,350.54812
Timestep Collection Time: 4.23333
Timestep Consumption Time: 3.64820
PPO Batch Consumption Time: 0.25321
Total Iteration Time: 7.88152
Cumulative Model Updates: 3,039
Cumulative Timesteps: 16,957,228
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.53686
Policy Entropy: 3.78072
Value Function Loss: 0.40204
Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.61275
Value Function Update Magnitude: 0.62106
Collected Steps per Second: 11,167.52346
Overall Steps per Second: 6,286.35050
Timestep Collection Time: 4.47942
Timestep Consumption Time: 3.47814
PPO Batch Consumption Time: 0.23862
Total Iteration Time: 7.95756
Cumulative Model Updates: 3,048
Cumulative Timesteps: 17,007,252
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 17007252...
Checkpoint 17007252 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.10463
Policy Entropy: 3.78229
Value Function Loss: 0.39613
Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.60842
Value Function Update Magnitude: 0.63564
Collected Steps per Second: 12,318.02586
Overall Steps per Second: 6,636.55173
Timestep Collection Time: 4.06348
Timestep Consumption Time: 3.47869
PPO Batch Consumption Time: 0.23957
Total Iteration Time: 7.54217
Cumulative Model Updates: 3,057
Cumulative Timesteps: 17,057,306
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.51794
Policy Entropy: 3.78097
Value Function Loss: 0.39566
Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.60461
Value Function Update Magnitude: 0.58701
Collected Steps per Second: 12,193.83191
Overall Steps per Second: 6,636.95735
Timestep Collection Time: 4.10273
Timestep Consumption Time: 3.43506
PPO Batch Consumption Time: 0.23827
Total Iteration Time: 7.53779
Cumulative Model Updates: 3,066
Cumulative Timesteps: 17,107,334
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 17107334...
Checkpoint 17107334 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65739
Policy Entropy: 3.77924
Value Function Loss: 0.38384
Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.60158
Value Function Update Magnitude: 0.58878
Collected Steps per Second: 12,486.03944
Overall Steps per Second: 6,772.87598
Timestep Collection Time: 4.00960
Timestep Consumption Time: 3.38224
PPO Batch Consumption Time: 0.24078
Total Iteration Time: 7.39184
Cumulative Model Updates: 3,075
Cumulative Timesteps: 17,157,398
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61279
Policy Entropy: 3.78190
Value Function Loss: 0.39750
Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.60398
Value Function Update Magnitude: 0.58774
Collected Steps per Second: 11,974.54624
Overall Steps per Second: 6,538.49806
Timestep Collection Time: 4.17820
Timestep Consumption Time: 3.47371
PPO Batch Consumption Time: 0.24193
Total Iteration Time: 7.65191
Cumulative Model Updates: 3,084
Cumulative Timesteps: 17,207,430
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 17207430...
Checkpoint 17207430 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.03004
Policy Entropy: 3.77399
Value Function Loss: 0.41166
Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.60513
Value Function Update Magnitude: 0.58640
Collected Steps per Second: 11,746.13073
Overall Steps per Second: 6,326.07117
Timestep Collection Time: 4.25774
Timestep Consumption Time: 3.64795
PPO Batch Consumption Time: 0.25336
Total Iteration Time: 7.90570
Cumulative Model Updates: 3,093
Cumulative Timesteps: 17,257,442
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.49310
Policy Entropy: 3.77701
Value Function Loss: 0.41658
Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10674
Policy Update Magnitude: 0.60948
Value Function Update Magnitude: 0.55290
Collected Steps per Second: 11,857.00012
Overall Steps per Second: 6,505.09334
Timestep Collection Time: 4.21861
Timestep Consumption Time: 3.47075
PPO Batch Consumption Time: 0.23854
Total Iteration Time: 7.68936
Cumulative Model Updates: 3,102
Cumulative Timesteps: 17,307,462
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 17307462...
Checkpoint 17307462 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.68243
Policy Entropy: 3.76521
Value Function Loss: 0.40942
Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.60380
Value Function Update Magnitude: 0.57049
Collected Steps per Second: 12,054.99727
Overall Steps per Second: 6,507.64298
Timestep Collection Time: 4.14998
Timestep Consumption Time: 3.53760
PPO Batch Consumption Time: 0.24509
Total Iteration Time: 7.68758
Cumulative Model Updates: 3,111
Cumulative Timesteps: 17,357,490
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.94424
Policy Entropy: 3.76723
Value Function Loss: 0.41314
Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.60950
Value Function Update Magnitude: 0.60404
Collected Steps per Second: 11,961.94083
Overall Steps per Second: 6,589.42005
Timestep Collection Time: 4.18009
Timestep Consumption Time: 3.40813
PPO Batch Consumption Time: 0.23966
Total Iteration Time: 7.58822
Cumulative Model Updates: 3,120
Cumulative Timesteps: 17,407,492
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 17407492...
Checkpoint 17407492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.15314
Policy Entropy: 3.76956
Value Function Loss: 0.42769
Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.61867
Value Function Update Magnitude: 0.66990
Collected Steps per Second: 11,947.53462
Overall Steps per Second: 6,430.83335
Timestep Collection Time: 4.18597
Timestep Consumption Time: 3.59094
PPO Batch Consumption Time: 0.25049
Total Iteration Time: 7.77691
Cumulative Model Updates: 3,129
Cumulative Timesteps: 17,457,504
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82008
Policy Entropy: 3.77121
Value Function Loss: 0.42579
Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.63108
Value Function Update Magnitude: 0.59067
Collected Steps per Second: 11,262.29111
Overall Steps per Second: 6,315.55279
Timestep Collection Time: 4.44172
Timestep Consumption Time: 3.47904
PPO Batch Consumption Time: 0.24183
Total Iteration Time: 7.92076
Cumulative Model Updates: 3,138
Cumulative Timesteps: 17,507,528
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 17507528...
Checkpoint 17507528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.74601
Policy Entropy: 3.76484
Value Function Loss: 0.41133
Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.63857
Value Function Update Magnitude: 0.54848
Collected Steps per Second: 12,098.44645
Overall Steps per Second: 6,567.89757
Timestep Collection Time: 4.13557
Timestep Consumption Time: 3.48239
PPO Batch Consumption Time: 0.24566
Total Iteration Time: 7.61796
Cumulative Model Updates: 3,147
Cumulative Timesteps: 17,557,562
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.12997
Policy Entropy: 3.76512
Value Function Loss: 0.39356
Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.63180
Value Function Update Magnitude: 0.50364
Collected Steps per Second: 11,840.93824
Overall Steps per Second: 6,452.55784
Timestep Collection Time: 4.22399
Timestep Consumption Time: 3.52736
PPO Batch Consumption Time: 0.24772
Total Iteration Time: 7.75134
Cumulative Model Updates: 3,156
Cumulative Timesteps: 17,607,578
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 17607578...
Checkpoint 17607578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29395
Policy Entropy: 3.76776
Value Function Loss: 0.39092
Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.10247
Policy Update Magnitude: 0.62219
Value Function Update Magnitude: 0.51272
Collected Steps per Second: 9,430.80346
Overall Steps per Second: 4,284.80729
Timestep Collection Time: 5.30623
Timestep Consumption Time: 6.37271
PPO Batch Consumption Time: 0.55810
Total Iteration Time: 11.67894
Cumulative Model Updates: 3,165
Cumulative Timesteps: 17,657,620
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81887
Policy Entropy: 3.77375
Value Function Loss: 0.39740
Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.62278
Value Function Update Magnitude: 0.50545
Collected Steps per Second: 9,120.72259
Overall Steps per Second: 4,196.65442
Timestep Collection Time: 5.48421
Timestep Consumption Time: 6.43480
PPO Batch Consumption Time: 0.56165
Total Iteration Time: 11.91902
Cumulative Model Updates: 3,174
Cumulative Timesteps: 17,707,640
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 17707640...
Checkpoint 17707640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.16204
Policy Entropy: 3.76177
Value Function Loss: 0.40886
Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.62477
Value Function Update Magnitude: 0.50714
Collected Steps per Second: 9,684.14641
Overall Steps per Second: 4,316.94661
Timestep Collection Time: 5.16432
Timestep Consumption Time: 6.42072
PPO Batch Consumption Time: 0.55413
Total Iteration Time: 11.58504
Cumulative Model Updates: 3,183
Cumulative Timesteps: 17,757,652
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.15374
Policy Entropy: 3.76088
Value Function Loss: 0.41812
Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.62949
Value Function Update Magnitude: 0.54018
Collected Steps per Second: 7,708.49393
Overall Steps per Second: 4,948.89897
Timestep Collection Time: 6.48661
Timestep Consumption Time: 3.61705
PPO Batch Consumption Time: 0.24201
Total Iteration Time: 10.10366
Cumulative Model Updates: 3,192
Cumulative Timesteps: 17,807,654
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 17807654...
Checkpoint 17807654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.19107
Policy Entropy: 3.76029
Value Function Loss: 0.42559
Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.61353
Value Function Update Magnitude: 0.61110
Collected Steps per Second: 10,844.28415
Overall Steps per Second: 5,831.35204
Timestep Collection Time: 4.61460
Timestep Consumption Time: 3.96695
PPO Batch Consumption Time: 0.27011
Total Iteration Time: 8.58154
Cumulative Model Updates: 3,201
Cumulative Timesteps: 17,857,696
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.15689
Policy Entropy: 3.75964
Value Function Loss: 0.40931
Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15612
Policy Update Magnitude: 0.59932
Value Function Update Magnitude: 0.57340
Collected Steps per Second: 11,043.54305
Overall Steps per Second: 6,183.37995
Timestep Collection Time: 4.52826
Timestep Consumption Time: 3.55923
PPO Batch Consumption Time: 0.24886
Total Iteration Time: 8.08749
Cumulative Model Updates: 3,210
Cumulative Timesteps: 17,907,704
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 17907704...
Checkpoint 17907704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.14161
Policy Entropy: 3.76242
Value Function Loss: 0.40338
Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.60574
Value Function Update Magnitude: 0.58615
Collected Steps per Second: 11,135.76000
Overall Steps per Second: 6,227.49792
Timestep Collection Time: 4.49058
Timestep Consumption Time: 3.53929
PPO Batch Consumption Time: 0.24387
Total Iteration Time: 8.02987
Cumulative Model Updates: 3,219
Cumulative Timesteps: 17,957,710
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.34577
Policy Entropy: 3.75507
Value Function Loss: 0.40673
Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.61405
Value Function Update Magnitude: 0.57141
Collected Steps per Second: 11,500.74119
Overall Steps per Second: 6,304.29074
Timestep Collection Time: 4.34911
Timestep Consumption Time: 3.58485
PPO Batch Consumption Time: 0.24891
Total Iteration Time: 7.93396
Cumulative Model Updates: 3,228
Cumulative Timesteps: 18,007,728
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 18007728...
Checkpoint 18007728 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90208
Policy Entropy: 3.76249
Value Function Loss: 0.41713
Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.61741
Value Function Update Magnitude: 0.61921
Collected Steps per Second: 11,818.55863
Overall Steps per Second: 6,470.77082
Timestep Collection Time: 4.23436
Timestep Consumption Time: 3.49950
PPO Batch Consumption Time: 0.24406
Total Iteration Time: 7.73385
Cumulative Model Updates: 3,237
Cumulative Timesteps: 18,057,772
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.90916
Policy Entropy: 3.75814
Value Function Loss: 0.41343
Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.62331
Value Function Update Magnitude: 0.58495
Collected Steps per Second: 11,968.16245
Overall Steps per Second: 6,552.10820
Timestep Collection Time: 4.17809
Timestep Consumption Time: 3.45366
PPO Batch Consumption Time: 0.23894
Total Iteration Time: 7.63174
Cumulative Model Updates: 3,246
Cumulative Timesteps: 18,107,776
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 18107776...
Checkpoint 18107776 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.39769
Policy Entropy: 3.75532
Value Function Loss: 0.37792
Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.61808
Value Function Update Magnitude: 0.69272
Collected Steps per Second: 12,188.76090
Overall Steps per Second: 6,569.13227
Timestep Collection Time: 4.10444
Timestep Consumption Time: 3.51118
PPO Batch Consumption Time: 0.24034
Total Iteration Time: 7.61562
Cumulative Model Updates: 3,255
Cumulative Timesteps: 18,157,804
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50501
Policy Entropy: 3.75839
Value Function Loss: 0.35802
Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.60019
Value Function Update Magnitude: 0.66846
Collected Steps per Second: 12,290.90570
Overall Steps per Second: 6,745.84196
Timestep Collection Time: 4.06984
Timestep Consumption Time: 3.34540
PPO Batch Consumption Time: 0.24028
Total Iteration Time: 7.41523
Cumulative Model Updates: 3,264
Cumulative Timesteps: 18,207,826
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 18207826...
Checkpoint 18207826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41392
Policy Entropy: 3.76063
Value Function Loss: 0.34773
Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.59671
Value Function Update Magnitude: 0.71493
Collected Steps per Second: 11,863.55915
Overall Steps per Second: 6,489.56607
Timestep Collection Time: 4.21577
Timestep Consumption Time: 3.49107
PPO Batch Consumption Time: 0.23927
Total Iteration Time: 7.70683
Cumulative Model Updates: 3,273
Cumulative Timesteps: 18,257,840
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50104
Policy Entropy: 3.77090
Value Function Loss: 0.34627
Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.58737
Value Function Update Magnitude: 0.55274
Collected Steps per Second: 12,231.20543
Overall Steps per Second: 6,597.75215
Timestep Collection Time: 4.08970
Timestep Consumption Time: 3.49197
PPO Batch Consumption Time: 0.24181
Total Iteration Time: 7.58167
Cumulative Model Updates: 3,282
Cumulative Timesteps: 18,307,862
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 18307862...
Checkpoint 18307862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.51971
Policy Entropy: 3.76518
Value Function Loss: 0.35180
Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.59088
Value Function Update Magnitude: 0.50829
Collected Steps per Second: 11,930.71184
Overall Steps per Second: 6,493.69518
Timestep Collection Time: 4.19388
Timestep Consumption Time: 3.51144
PPO Batch Consumption Time: 0.23878
Total Iteration Time: 7.70532
Cumulative Model Updates: 3,291
Cumulative Timesteps: 18,357,898
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.18524
Policy Entropy: 3.76837
Value Function Loss: 0.34310
Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.58925
Value Function Update Magnitude: 0.57477
Collected Steps per Second: 12,177.84633
Overall Steps per Second: 6,570.88525
Timestep Collection Time: 4.10631
Timestep Consumption Time: 3.50393
PPO Batch Consumption Time: 0.23942
Total Iteration Time: 7.61024
Cumulative Model Updates: 3,300
Cumulative Timesteps: 18,407,904
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 18407904...
Checkpoint 18407904 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.25756
Policy Entropy: 3.76180
Value Function Loss: 0.35217
Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.59084
Value Function Update Magnitude: 0.59765
Collected Steps per Second: 12,245.21761
Overall Steps per Second: 6,536.82623
Timestep Collection Time: 4.08355
Timestep Consumption Time: 3.56603
PPO Batch Consumption Time: 0.25247
Total Iteration Time: 7.64958
Cumulative Model Updates: 3,309
Cumulative Timesteps: 18,457,908
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.87484
Policy Entropy: 3.76366
Value Function Loss: 0.33664
Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.59356
Value Function Update Magnitude: 0.59971
Collected Steps per Second: 12,234.26280
Overall Steps per Second: 6,628.03555
Timestep Collection Time: 4.08852
Timestep Consumption Time: 3.45821
PPO Batch Consumption Time: 0.23877
Total Iteration Time: 7.54673
Cumulative Model Updates: 3,318
Cumulative Timesteps: 18,507,928
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 18507928...
Checkpoint 18507928 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23067
Policy Entropy: 3.76730
Value Function Loss: 0.33505
Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.60714
Value Function Update Magnitude: 0.56753
Collected Steps per Second: 12,090.94257
Overall Steps per Second: 6,513.27413
Timestep Collection Time: 4.13665
Timestep Consumption Time: 3.54244
PPO Batch Consumption Time: 0.24646
Total Iteration Time: 7.67909
Cumulative Model Updates: 3,327
Cumulative Timesteps: 18,557,944
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64920
Policy Entropy: 3.77422
Value Function Loss: 0.34904
Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.59829
Value Function Update Magnitude: 0.57333
Collected Steps per Second: 12,160.73772
Overall Steps per Second: 6,662.20442
Timestep Collection Time: 4.11324
Timestep Consumption Time: 3.39479
PPO Batch Consumption Time: 0.24164
Total Iteration Time: 7.50803
Cumulative Model Updates: 3,336
Cumulative Timesteps: 18,607,964
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 18607964...
Checkpoint 18607964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40319
Policy Entropy: 3.77283
Value Function Loss: 0.34413
Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.60465
Value Function Update Magnitude: 0.61402
Collected Steps per Second: 10,646.08075
Overall Steps per Second: 5,888.64681
Timestep Collection Time: 4.69976
Timestep Consumption Time: 3.79693
PPO Batch Consumption Time: 0.25823
Total Iteration Time: 8.49669
Cumulative Model Updates: 3,345
Cumulative Timesteps: 18,657,998
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.41134
Policy Entropy: 3.76478
Value Function Loss: 0.34069
Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.62426
Value Function Update Magnitude: 0.59750
Collected Steps per Second: 10,297.33408
Overall Steps per Second: 5,986.54861
Timestep Collection Time: 4.85563
Timestep Consumption Time: 3.49643
PPO Batch Consumption Time: 0.25032
Total Iteration Time: 8.35206
Cumulative Model Updates: 3,354
Cumulative Timesteps: 18,707,998
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 18707998...
Checkpoint 18707998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.09204
Policy Entropy: 3.75764
Value Function Loss: 0.33315
Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.63023
Value Function Update Magnitude: 0.55752
Collected Steps per Second: 10,881.78635
Overall Steps per Second: 6,164.34761
Timestep Collection Time: 4.59833
Timestep Consumption Time: 3.51900
PPO Batch Consumption Time: 0.24196
Total Iteration Time: 8.11732
Cumulative Model Updates: 3,363
Cumulative Timesteps: 18,758,036
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42364
Policy Entropy: 3.76455
Value Function Loss: 0.34492
Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.63162
Value Function Update Magnitude: 0.59229
Collected Steps per Second: 10,905.54113
Overall Steps per Second: 6,125.75722
Timestep Collection Time: 4.58538
Timestep Consumption Time: 3.57786
PPO Batch Consumption Time: 0.25363
Total Iteration Time: 8.16324
Cumulative Model Updates: 3,372
Cumulative Timesteps: 18,808,042
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 18808042...
Checkpoint 18808042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.44340
Policy Entropy: 3.76389
Value Function Loss: 0.34026
Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.61983
Value Function Update Magnitude: 0.60771
Collected Steps per Second: 10,621.12240
Overall Steps per Second: 6,146.93236
Timestep Collection Time: 4.70779
Timestep Consumption Time: 3.42668
PPO Batch Consumption Time: 0.24152
Total Iteration Time: 8.13446
Cumulative Model Updates: 3,381
Cumulative Timesteps: 18,858,044
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95572
Policy Entropy: 3.76179
Value Function Loss: 0.33096
Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.60649
Value Function Update Magnitude: 0.56189
Collected Steps per Second: 11,412.45895
Overall Steps per Second: 6,223.40152
Timestep Collection Time: 4.38205
Timestep Consumption Time: 3.65375
PPO Batch Consumption Time: 0.25477
Total Iteration Time: 8.03580
Cumulative Model Updates: 3,390
Cumulative Timesteps: 18,908,054
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 18908054...
Checkpoint 18908054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.47129
Policy Entropy: 3.75626
Value Function Loss: 0.32937
Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.60427
Value Function Update Magnitude: 0.53966
Collected Steps per Second: 11,066.11320
Overall Steps per Second: 6,175.21253
Timestep Collection Time: 4.52137
Timestep Consumption Time: 3.58102
PPO Batch Consumption Time: 0.23912
Total Iteration Time: 8.10239
Cumulative Model Updates: 3,399
Cumulative Timesteps: 18,958,088
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.51084
Policy Entropy: 3.75127
Value Function Loss: 0.32505
Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09494
Policy Update Magnitude: 0.59921
Value Function Update Magnitude: 0.55073
Collected Steps per Second: 11,750.14531
Overall Steps per Second: 6,234.04298
Timestep Collection Time: 4.25646
Timestep Consumption Time: 3.76627
PPO Batch Consumption Time: 0.26555
Total Iteration Time: 8.02272
Cumulative Model Updates: 3,408
Cumulative Timesteps: 19,008,102
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 19008102...
Checkpoint 19008102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.98988
Policy Entropy: 3.74824
Value Function Loss: 0.33391
Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.59405
Value Function Update Magnitude: 0.55351
Collected Steps per Second: 10,295.15091
Overall Steps per Second: 5,673.42229
Timestep Collection Time: 4.85938
Timestep Consumption Time: 3.95858
PPO Batch Consumption Time: 0.27241
Total Iteration Time: 8.81796
Cumulative Model Updates: 3,417
Cumulative Timesteps: 19,058,130
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33827
Policy Entropy: 3.74589
Value Function Loss: 0.34082
Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.59326
Value Function Update Magnitude: 0.58132
Collected Steps per Second: 11,461.03894
Overall Steps per Second: 6,482.10656
Timestep Collection Time: 4.36505
Timestep Consumption Time: 3.35281
PPO Batch Consumption Time: 0.23991
Total Iteration Time: 7.71786
Cumulative Model Updates: 3,426
Cumulative Timesteps: 19,108,158
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 19108158...
Checkpoint 19108158 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06416
Policy Entropy: 3.75828
Value Function Loss: 0.34105
Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.59058
Value Function Update Magnitude: 0.58898
Collected Steps per Second: 11,872.27725
Overall Steps per Second: 6,357.12852
Timestep Collection Time: 4.21419
Timestep Consumption Time: 3.65603
PPO Batch Consumption Time: 0.25059
Total Iteration Time: 7.87022
Cumulative Model Updates: 3,435
Cumulative Timesteps: 19,158,190
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.35597
Policy Entropy: 3.75911
Value Function Loss: 0.34256
Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.58869
Value Function Update Magnitude: 0.63391
Collected Steps per Second: 10,805.42745
Overall Steps per Second: 6,110.54308
Timestep Collection Time: 4.63008
Timestep Consumption Time: 3.55741
PPO Batch Consumption Time: 0.25592
Total Iteration Time: 8.18749
Cumulative Model Updates: 3,444
Cumulative Timesteps: 19,208,220
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 19208220...
Checkpoint 19208220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76638
Policy Entropy: 3.75448
Value Function Loss: 0.34003
Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.58808
Value Function Update Magnitude: 0.61724
Collected Steps per Second: 10,751.90174
Overall Steps per Second: 6,077.49752
Timestep Collection Time: 4.65146
Timestep Consumption Time: 3.57759
PPO Batch Consumption Time: 0.26138
Total Iteration Time: 8.22904
Cumulative Model Updates: 3,453
Cumulative Timesteps: 19,258,232
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.28061
Policy Entropy: 3.74618
Value Function Loss: 0.33460
Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.59519
Value Function Update Magnitude: 0.66332
Collected Steps per Second: 11,642.99712
Overall Steps per Second: 6,333.26631
Timestep Collection Time: 4.29889
Timestep Consumption Time: 3.60414
PPO Batch Consumption Time: 0.25511
Total Iteration Time: 7.90303
Cumulative Model Updates: 3,462
Cumulative Timesteps: 19,308,284
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 19308284...
Checkpoint 19308284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.63442
Policy Entropy: 3.74190
Value Function Loss: 0.31495
Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.59400
Value Function Update Magnitude: 0.61149
Collected Steps per Second: 10,827.89091
Overall Steps per Second: 5,972.73642
Timestep Collection Time: 4.62121
Timestep Consumption Time: 3.75652
PPO Batch Consumption Time: 0.26198
Total Iteration Time: 8.37773
Cumulative Model Updates: 3,471
Cumulative Timesteps: 19,358,322
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.83654
Policy Entropy: 3.74661
Value Function Loss: 0.31047
Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.58996
Value Function Update Magnitude: 0.56776
Collected Steps per Second: 10,894.11147
Overall Steps per Second: 6,186.86999
Timestep Collection Time: 4.59257
Timestep Consumption Time: 3.49423
PPO Batch Consumption Time: 0.24132
Total Iteration Time: 8.08680
Cumulative Model Updates: 3,480
Cumulative Timesteps: 19,408,354
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 19408354...
Checkpoint 19408354 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22430
Policy Entropy: 3.74914
Value Function Loss: 0.30575
Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.59766
Value Function Update Magnitude: 0.57239
Collected Steps per Second: 11,245.00664
Overall Steps per Second: 6,300.83732
Timestep Collection Time: 4.44891
Timestep Consumption Time: 3.49099
PPO Batch Consumption Time: 0.24150
Total Iteration Time: 7.93990
Cumulative Model Updates: 3,489
Cumulative Timesteps: 19,458,382
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11865
Policy Entropy: 3.74599
Value Function Loss: 0.30936
Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.58643
Value Function Update Magnitude: 0.58865
Collected Steps per Second: 10,760.00814
Overall Steps per Second: 6,077.77097
Timestep Collection Time: 4.64777
Timestep Consumption Time: 3.58058
PPO Batch Consumption Time: 0.26186
Total Iteration Time: 8.22835
Cumulative Model Updates: 3,498
Cumulative Timesteps: 19,508,392
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 19508392...
Checkpoint 19508392 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.91420
Policy Entropy: 3.74909
Value Function Loss: 0.30672
Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.58754
Value Function Update Magnitude: 0.60782
Collected Steps per Second: 10,216.04030
Overall Steps per Second: 5,608.93377
Timestep Collection Time: 4.89740
Timestep Consumption Time: 4.02266
PPO Batch Consumption Time: 0.27239
Total Iteration Time: 8.92006
Cumulative Model Updates: 3,507
Cumulative Timesteps: 19,558,424
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.62719
Policy Entropy: 3.75202
Value Function Loss: 0.30705
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.57296
Value Function Update Magnitude: 0.60307
Collected Steps per Second: 10,994.51872
Overall Steps per Second: 6,102.43008
Timestep Collection Time: 4.54845
Timestep Consumption Time: 3.64632
PPO Batch Consumption Time: 0.24708
Total Iteration Time: 8.19477
Cumulative Model Updates: 3,516
Cumulative Timesteps: 19,608,432
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 19608432...
Checkpoint 19608432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.29599
Policy Entropy: 3.75304
Value Function Loss: 0.31020
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.56865
Value Function Update Magnitude: 0.56465
Collected Steps per Second: 11,135.56556
Overall Steps per Second: 6,115.27543
Timestep Collection Time: 4.49407
Timestep Consumption Time: 3.68937
PPO Batch Consumption Time: 0.25500
Total Iteration Time: 8.18344
Cumulative Model Updates: 3,525
Cumulative Timesteps: 19,658,476
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.18670
Policy Entropy: 3.74901
Value Function Loss: 0.30635
Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.57251
Value Function Update Magnitude: 0.56730
Collected Steps per Second: 10,176.80945
Overall Steps per Second: 5,724.35300
Timestep Collection Time: 4.91549
Timestep Consumption Time: 3.82331
PPO Batch Consumption Time: 0.26412
Total Iteration Time: 8.73880
Cumulative Model Updates: 3,534
Cumulative Timesteps: 19,708,500
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 19708500...
Checkpoint 19708500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.80810
Policy Entropy: 3.74682
Value Function Loss: 0.30476
Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.55058
Collected Steps per Second: 10,967.01424
Overall Steps per Second: 5,993.54369
Timestep Collection Time: 4.56131
Timestep Consumption Time: 3.78500
PPO Batch Consumption Time: 0.26686
Total Iteration Time: 8.34631
Cumulative Model Updates: 3,543
Cumulative Timesteps: 19,758,524
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.76994
Policy Entropy: 3.74814
Value Function Loss: 0.30026
Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.58269
Collected Steps per Second: 10,604.97425
Overall Steps per Second: 5,857.60940
Timestep Collection Time: 4.71760
Timestep Consumption Time: 3.82343
PPO Batch Consumption Time: 0.26324
Total Iteration Time: 8.54103
Cumulative Model Updates: 3,552
Cumulative Timesteps: 19,808,554
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 19808554...
Checkpoint 19808554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.48670
Policy Entropy: 3.75496
Value Function Loss: 0.29870
Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.55347
Collected Steps per Second: 11,521.84557
Overall Steps per Second: 6,333.21582
Timestep Collection Time: 4.34427
Timestep Consumption Time: 3.55914
PPO Batch Consumption Time: 0.24677
Total Iteration Time: 7.90341
Cumulative Model Updates: 3,561
Cumulative Timesteps: 19,858,608
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60453
Policy Entropy: 3.75623
Value Function Loss: 0.29711
Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.58565
Value Function Update Magnitude: 0.57126
Collected Steps per Second: 11,401.42903
Overall Steps per Second: 6,169.15676
Timestep Collection Time: 4.38770
Timestep Consumption Time: 3.72135
PPO Batch Consumption Time: 0.27344
Total Iteration Time: 8.10905
Cumulative Model Updates: 3,570
Cumulative Timesteps: 19,908,634
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 19908634...
Checkpoint 19908634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.17177
Policy Entropy: 3.75676
Value Function Loss: 0.29872
Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.58625
Value Function Update Magnitude: 0.55667
Collected Steps per Second: 10,790.42925
Overall Steps per Second: 5,995.96163
Timestep Collection Time: 4.63577
Timestep Consumption Time: 3.70684
PPO Batch Consumption Time: 0.25256
Total Iteration Time: 8.34262
Cumulative Model Updates: 3,579
Cumulative Timesteps: 19,958,656
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.77762
Policy Entropy: 3.75420
Value Function Loss: 0.29715
Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.58451
Value Function Update Magnitude: 0.56997
Collected Steps per Second: 10,436.72074
Overall Steps per Second: 5,902.71215
Timestep Collection Time: 4.79423
Timestep Consumption Time: 3.68256
PPO Batch Consumption Time: 0.25412
Total Iteration Time: 8.47678
Cumulative Model Updates: 3,588
Cumulative Timesteps: 20,008,692
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 20008692...
Checkpoint 20008692 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.91304
Policy Entropy: 3.74958
Value Function Loss: 0.30029
Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.58557
Value Function Update Magnitude: 0.55693
Collected Steps per Second: 10,928.05673
Overall Steps per Second: 6,033.09166
Timestep Collection Time: 4.57556
Timestep Consumption Time: 3.71239
PPO Batch Consumption Time: 0.25731
Total Iteration Time: 8.28796
Cumulative Model Updates: 3,597
Cumulative Timesteps: 20,058,694
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71111
Policy Entropy: 3.75010
Value Function Loss: 0.30298
Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.58945
Value Function Update Magnitude: 0.59186
Collected Steps per Second: 10,721.52902
Overall Steps per Second: 5,945.28964
Timestep Collection Time: 4.66426
Timestep Consumption Time: 3.74710
PPO Batch Consumption Time: 0.26278
Total Iteration Time: 8.41136
Cumulative Model Updates: 3,606
Cumulative Timesteps: 20,108,702
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 20108702...
Checkpoint 20108702 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.05382
Policy Entropy: 3.74999
Value Function Loss: 0.31522
Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.58727
Value Function Update Magnitude: 0.64428
Collected Steps per Second: 11,170.05325
Overall Steps per Second: 6,084.47099
Timestep Collection Time: 4.47661
Timestep Consumption Time: 3.74169
PPO Batch Consumption Time: 0.27024
Total Iteration Time: 8.21830
Cumulative Model Updates: 3,615
Cumulative Timesteps: 20,158,706
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.26718
Policy Entropy: 3.74321
Value Function Loss: 0.31307
Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.58923
Value Function Update Magnitude: 0.62785
Collected Steps per Second: 11,628.86333
Overall Steps per Second: 6,287.48212
Timestep Collection Time: 4.30171
Timestep Consumption Time: 3.65442
PPO Batch Consumption Time: 0.25848
Total Iteration Time: 7.95613
Cumulative Model Updates: 3,624
Cumulative Timesteps: 20,208,730
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 20208730...
Checkpoint 20208730 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.80949
Policy Entropy: 3.74423
Value Function Loss: 0.30993
Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.58674
Value Function Update Magnitude: 0.55926
Collected Steps per Second: 11,548.05609
Overall Steps per Second: 6,312.52469
Timestep Collection Time: 4.33198
Timestep Consumption Time: 3.59290
PPO Batch Consumption Time: 0.24048
Total Iteration Time: 7.92488
Cumulative Model Updates: 3,633
Cumulative Timesteps: 20,258,756
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.80614
Policy Entropy: 3.74772
Value Function Loss: 0.30709
Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.58528
Value Function Update Magnitude: 0.54288
Collected Steps per Second: 10,990.29649
Overall Steps per Second: 6,301.70486
Timestep Collection Time: 4.54947
Timestep Consumption Time: 3.38489
PPO Batch Consumption Time: 0.24105
Total Iteration Time: 7.93436
Cumulative Model Updates: 3,642
Cumulative Timesteps: 20,308,756
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 20308756...
Checkpoint 20308756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50689
Policy Entropy: 3.74343
Value Function Loss: 0.31501
Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.59520
Value Function Update Magnitude: 0.58402
Collected Steps per Second: 11,223.22651
Overall Steps per Second: 6,257.78073
Timestep Collection Time: 4.45915
Timestep Consumption Time: 3.53826
PPO Batch Consumption Time: 0.23906
Total Iteration Time: 7.99740
Cumulative Model Updates: 3,651
Cumulative Timesteps: 20,358,802
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57439
Policy Entropy: 3.74346
Value Function Loss: 0.32031
Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.61364
Value Function Update Magnitude: 0.57739
Collected Steps per Second: 11,718.73920
Overall Steps per Second: 6,440.65994
Timestep Collection Time: 4.26718
Timestep Consumption Time: 3.49693
PPO Batch Consumption Time: 0.24057
Total Iteration Time: 7.76411
Cumulative Model Updates: 3,660
Cumulative Timesteps: 20,408,808
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 20408808...
Checkpoint 20408808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38147
Policy Entropy: 3.74070
Value Function Loss: 0.31575
Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.59040
Value Function Update Magnitude: 0.55455
Collected Steps per Second: 11,679.89939
Overall Steps per Second: 6,348.58937
Timestep Collection Time: 4.28240
Timestep Consumption Time: 3.59620
PPO Batch Consumption Time: 0.24828
Total Iteration Time: 7.87860
Cumulative Model Updates: 3,669
Cumulative Timesteps: 20,458,826
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43090
Policy Entropy: 3.74720
Value Function Loss: 0.30953
Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.58678
Value Function Update Magnitude: 0.56904
Collected Steps per Second: 10,892.84799
Overall Steps per Second: 6,165.14206
Timestep Collection Time: 4.59035
Timestep Consumption Time: 3.52009
PPO Batch Consumption Time: 0.24494
Total Iteration Time: 8.11044
Cumulative Model Updates: 3,678
Cumulative Timesteps: 20,508,828
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 20508828...
Checkpoint 20508828 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12539
Policy Entropy: 3.74313
Value Function Loss: 0.31946
Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.58400
Value Function Update Magnitude: 0.60663
Collected Steps per Second: 11,240.59051
Overall Steps per Second: 6,125.71201
Timestep Collection Time: 4.44959
Timestep Consumption Time: 3.71534
PPO Batch Consumption Time: 0.25850
Total Iteration Time: 8.16493
Cumulative Model Updates: 3,687
Cumulative Timesteps: 20,558,844
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50426
Policy Entropy: 3.74000
Value Function Loss: 0.32538
Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.60056
Value Function Update Magnitude: 0.60371
Collected Steps per Second: 11,555.31283
Overall Steps per Second: 6,331.31575
Timestep Collection Time: 4.33117
Timestep Consumption Time: 3.57367
PPO Batch Consumption Time: 0.24594
Total Iteration Time: 7.90483
Cumulative Model Updates: 3,696
Cumulative Timesteps: 20,608,892
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 20608892...
Checkpoint 20608892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.70393
Policy Entropy: 3.74357
Value Function Loss: 0.32336
Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09944
Policy Update Magnitude: 0.59904
Value Function Update Magnitude: 0.58231
Collected Steps per Second: 10,963.79433
Overall Steps per Second: 6,129.30602
Timestep Collection Time: 4.56466
Timestep Consumption Time: 3.60037
PPO Batch Consumption Time: 0.24771
Total Iteration Time: 8.16504
Cumulative Model Updates: 3,705
Cumulative Timesteps: 20,658,938
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.52193
Policy Entropy: 3.74501
Value Function Loss: 0.30747
Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.58597
Value Function Update Magnitude: 0.60835
Collected Steps per Second: 11,457.35111
Overall Steps per Second: 6,489.44856
Timestep Collection Time: 4.36645
Timestep Consumption Time: 3.34268
PPO Batch Consumption Time: 0.23894
Total Iteration Time: 7.70913
Cumulative Model Updates: 3,714
Cumulative Timesteps: 20,708,966
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 20708966...
Checkpoint 20708966 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.09502
Policy Entropy: 3.74119
Value Function Loss: 0.31349
Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.58425
Value Function Update Magnitude: 0.62450
Collected Steps per Second: 12,466.43700
Overall Steps per Second: 6,712.56792
Timestep Collection Time: 4.01141
Timestep Consumption Time: 3.43850
PPO Batch Consumption Time: 0.23825
Total Iteration Time: 7.44991
Cumulative Model Updates: 3,723
Cumulative Timesteps: 20,758,974
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.84525
Policy Entropy: 3.74911
Value Function Loss: 0.31257
Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.58569
Value Function Update Magnitude: 0.60462
Collected Steps per Second: 12,368.40124
Overall Steps per Second: 6,671.92467
Timestep Collection Time: 4.04482
Timestep Consumption Time: 3.45346
PPO Batch Consumption Time: 0.23848
Total Iteration Time: 7.49829
Cumulative Model Updates: 3,732
Cumulative Timesteps: 20,809,002
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 20809002...
Checkpoint 20809002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 23.99400
Policy Entropy: 3.74155
Value Function Loss: 0.31232
Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.58491
Value Function Update Magnitude: 0.70297
Collected Steps per Second: 12,615.85491
Overall Steps per Second: 6,690.36335
Timestep Collection Time: 3.96644
Timestep Consumption Time: 3.51298
PPO Batch Consumption Time: 0.24097
Total Iteration Time: 7.47941
Cumulative Model Updates: 3,741
Cumulative Timesteps: 20,859,042
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.08495
Policy Entropy: 3.75137
Value Function Loss: 0.28382
Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.60296
Value Function Update Magnitude: 0.71517
Collected Steps per Second: 12,359.67006
Overall Steps per Second: 6,642.44951
Timestep Collection Time: 4.04606
Timestep Consumption Time: 3.48249
PPO Batch Consumption Time: 0.23946
Total Iteration Time: 7.52855
Cumulative Model Updates: 3,750
Cumulative Timesteps: 20,909,050
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 20909050...
Checkpoint 20909050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.04555
Policy Entropy: 3.75348
Value Function Loss: 0.27093
Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.58675
Value Function Update Magnitude: 0.61050
Collected Steps per Second: 12,487.11471
Overall Steps per Second: 6,765.78757
Timestep Collection Time: 4.00573
Timestep Consumption Time: 3.38735
PPO Batch Consumption Time: 0.24217
Total Iteration Time: 7.39308
Cumulative Model Updates: 3,759
Cumulative Timesteps: 20,959,070
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95094
Policy Entropy: 3.75718
Value Function Loss: 0.26575
Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.57733
Value Function Update Magnitude: 0.58373
Collected Steps per Second: 12,365.23698
Overall Steps per Second: 6,676.42668
Timestep Collection Time: 4.04376
Timestep Consumption Time: 3.44558
PPO Batch Consumption Time: 0.23912
Total Iteration Time: 7.48934
Cumulative Model Updates: 3,768
Cumulative Timesteps: 21,009,072
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 21009072...
Checkpoint 21009072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97741
Policy Entropy: 3.76176
Value Function Loss: 0.26815
Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.57261
Value Function Update Magnitude: 0.63904
Collected Steps per Second: 12,337.88583
Overall Steps per Second: 6,678.03638
Timestep Collection Time: 4.05483
Timestep Consumption Time: 3.43660
PPO Batch Consumption Time: 0.24178
Total Iteration Time: 7.49142
Cumulative Model Updates: 3,777
Cumulative Timesteps: 21,059,100
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.89768
Policy Entropy: 3.75968
Value Function Loss: 0.25235
Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.56398
Value Function Update Magnitude: 0.71254
Collected Steps per Second: 11,821.04285
Overall Steps per Second: 6,574.08868
Timestep Collection Time: 4.23245
Timestep Consumption Time: 3.37803
PPO Batch Consumption Time: 0.23821
Total Iteration Time: 7.61048
Cumulative Model Updates: 3,786
Cumulative Timesteps: 21,109,132
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 21109132...
Checkpoint 21109132 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60067
Policy Entropy: 3.75668
Value Function Loss: 0.24019
Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.54364
Value Function Update Magnitude: 0.62851
Collected Steps per Second: 11,807.95165
Overall Steps per Second: 6,468.32061
Timestep Collection Time: 4.23731
Timestep Consumption Time: 3.49792
PPO Batch Consumption Time: 0.23979
Total Iteration Time: 7.73524
Cumulative Model Updates: 3,795
Cumulative Timesteps: 21,159,166
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.48870
Policy Entropy: 3.76363
Value Function Loss: 0.24449
Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.53588
Value Function Update Magnitude: 0.56680
Collected Steps per Second: 12,143.79758
Overall Steps per Second: 6,646.23814
Timestep Collection Time: 4.11930
Timestep Consumption Time: 3.40736
PPO Batch Consumption Time: 0.23872
Total Iteration Time: 7.52666
Cumulative Model Updates: 3,804
Cumulative Timesteps: 21,209,190
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 21209190...
Checkpoint 21209190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23369
Policy Entropy: 3.76935
Value Function Loss: 0.25398
Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11097
Policy Update Magnitude: 0.54030
Value Function Update Magnitude: 0.58133
Collected Steps per Second: 12,488.11126
Overall Steps per Second: 6,645.71423
Timestep Collection Time: 4.00589
Timestep Consumption Time: 3.52167
PPO Batch Consumption Time: 0.24412
Total Iteration Time: 7.52756
Cumulative Model Updates: 3,813
Cumulative Timesteps: 21,259,216
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12907
Policy Entropy: 3.77493
Value Function Loss: 0.26923
Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.54716
Value Function Update Magnitude: 0.60846
Collected Steps per Second: 11,904.56843
Overall Steps per Second: 6,494.67028
Timestep Collection Time: 4.20259
Timestep Consumption Time: 3.50065
PPO Batch Consumption Time: 0.24473
Total Iteration Time: 7.70324
Cumulative Model Updates: 3,822
Cumulative Timesteps: 21,309,246
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 21309246...
Checkpoint 21309246 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49575
Policy Entropy: 3.77515
Value Function Loss: 0.26708
Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.63385
Collected Steps per Second: 11,321.25981
Overall Steps per Second: 6,200.20718
Timestep Collection Time: 4.41912
Timestep Consumption Time: 3.64997
PPO Batch Consumption Time: 0.25607
Total Iteration Time: 8.06909
Cumulative Model Updates: 3,831
Cumulative Timesteps: 21,359,276
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.58586
Policy Entropy: 3.77399
Value Function Loss: 0.26876
Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.54333
Value Function Update Magnitude: 0.60543
Collected Steps per Second: 10,792.92064
Overall Steps per Second: 6,022.28237
Timestep Collection Time: 4.63748
Timestep Consumption Time: 3.67365
PPO Batch Consumption Time: 0.25432
Total Iteration Time: 8.31113
Cumulative Model Updates: 3,840
Cumulative Timesteps: 21,409,328
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 21409328...
Checkpoint 21409328 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.43882
Policy Entropy: 3.78130
Value Function Loss: 0.25693
Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.54135
Value Function Update Magnitude: 0.62541
Collected Steps per Second: 9,918.61297
Overall Steps per Second: 5,641.43778
Timestep Collection Time: 5.04385
Timestep Consumption Time: 3.82410
PPO Batch Consumption Time: 0.26518
Total Iteration Time: 8.86795
Cumulative Model Updates: 3,849
Cumulative Timesteps: 21,459,356
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85481
Policy Entropy: 3.77171
Value Function Loss: 0.26145
Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.56844
Collected Steps per Second: 11,061.25843
Overall Steps per Second: 6,252.97813
Timestep Collection Time: 4.52137
Timestep Consumption Time: 3.47674
PPO Batch Consumption Time: 0.24774
Total Iteration Time: 7.99811
Cumulative Model Updates: 3,858
Cumulative Timesteps: 21,509,368
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 21509368...
Checkpoint 21509368 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.21876
Policy Entropy: 3.77279
Value Function Loss: 0.26551
Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.53609
Value Function Update Magnitude: 0.62893
Collected Steps per Second: 11,080.64991
Overall Steps per Second: 6,043.41427
Timestep Collection Time: 4.51237
Timestep Consumption Time: 3.76110
PPO Batch Consumption Time: 0.25424
Total Iteration Time: 8.27347
Cumulative Model Updates: 3,867
Cumulative Timesteps: 21,559,368
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.33203
Policy Entropy: 3.76652
Value Function Loss: 0.26001
Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.54980
Value Function Update Magnitude: 0.59959
Collected Steps per Second: 11,432.55603
Overall Steps per Second: 6,291.29741
Timestep Collection Time: 4.37627
Timestep Consumption Time: 3.57630
PPO Batch Consumption Time: 0.24732
Total Iteration Time: 7.95257
Cumulative Model Updates: 3,876
Cumulative Timesteps: 21,609,400
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 21609400...
Checkpoint 21609400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60742
Policy Entropy: 3.76556
Value Function Loss: 0.25466
Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.58065
Collected Steps per Second: 12,345.44113
Overall Steps per Second: 6,616.66299
Timestep Collection Time: 4.05332
Timestep Consumption Time: 3.50941
PPO Batch Consumption Time: 0.24498
Total Iteration Time: 7.56272
Cumulative Model Updates: 3,885
Cumulative Timesteps: 21,659,440
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53113
Policy Entropy: 3.75885
Value Function Loss: 0.25473
Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.54056
Value Function Update Magnitude: 0.57835
Collected Steps per Second: 11,520.21210
Overall Steps per Second: 6,422.60321
Timestep Collection Time: 4.34089
Timestep Consumption Time: 3.44536
PPO Batch Consumption Time: 0.23831
Total Iteration Time: 7.78625
Cumulative Model Updates: 3,894
Cumulative Timesteps: 21,709,448
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 21709448...
Checkpoint 21709448 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.72401
Policy Entropy: 3.76017
Value Function Loss: 0.25868
Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.54070
Value Function Update Magnitude: 0.65713
Collected Steps per Second: 12,101.92580
Overall Steps per Second: 6,466.71270
Timestep Collection Time: 4.13174
Timestep Consumption Time: 3.60047
PPO Batch Consumption Time: 0.25872
Total Iteration Time: 7.73221
Cumulative Model Updates: 3,903
Cumulative Timesteps: 21,759,450
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.47274
Policy Entropy: 3.76092
Value Function Loss: 0.26761
Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.54851
Value Function Update Magnitude: 0.63497
Collected Steps per Second: 11,078.10454
Overall Steps per Second: 6,201.97534
Timestep Collection Time: 4.51395
Timestep Consumption Time: 3.54897
PPO Batch Consumption Time: 0.24171
Total Iteration Time: 8.06291
Cumulative Model Updates: 3,912
Cumulative Timesteps: 21,809,456
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 21809456...
Checkpoint 21809456 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.64270
Policy Entropy: 3.76452
Value Function Loss: 0.26554
Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.55097
Value Function Update Magnitude: 0.67615
Collected Steps per Second: 11,650.30186
Overall Steps per Second: 6,273.20628
Timestep Collection Time: 4.29448
Timestep Consumption Time: 3.68103
PPO Batch Consumption Time: 0.25716
Total Iteration Time: 7.97551
Cumulative Model Updates: 3,921
Cumulative Timesteps: 21,859,488
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.41342
Policy Entropy: 3.77369
Value Function Loss: 0.25816
Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.54315
Value Function Update Magnitude: 0.64936
Collected Steps per Second: 11,255.36786
Overall Steps per Second: 6,515.84140
Timestep Collection Time: 4.44535
Timestep Consumption Time: 3.23348
PPO Batch Consumption Time: 0.24611
Total Iteration Time: 7.67882
Cumulative Model Updates: 3,930
Cumulative Timesteps: 21,909,522
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 21909522...
Checkpoint 21909522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.63016
Policy Entropy: 3.77085
Value Function Loss: 0.25501
Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.65533
Collected Steps per Second: 11,710.84840
Overall Steps per Second: 6,513.04714
Timestep Collection Time: 4.27040
Timestep Consumption Time: 3.40803
PPO Batch Consumption Time: 0.25121
Total Iteration Time: 7.67843
Cumulative Model Updates: 3,939
Cumulative Timesteps: 21,959,532
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.75755
Policy Entropy: 3.77188
Value Function Loss: 0.26043
Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.56322
Value Function Update Magnitude: 0.64381
Collected Steps per Second: 11,656.05483
Overall Steps per Second: 6,499.43155
Timestep Collection Time: 4.29253
Timestep Consumption Time: 3.40568
PPO Batch Consumption Time: 0.25288
Total Iteration Time: 7.69821
Cumulative Model Updates: 3,948
Cumulative Timesteps: 22,009,566
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 22009566...
Checkpoint 22009566 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97675
Policy Entropy: 3.76671
Value Function Loss: 0.26270
Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.54640
Value Function Update Magnitude: 0.60237
Collected Steps per Second: 11,773.48351
Overall Steps per Second: 6,494.80756
Timestep Collection Time: 4.24904
Timestep Consumption Time: 3.45342
PPO Batch Consumption Time: 0.25386
Total Iteration Time: 7.70246
Cumulative Model Updates: 3,957
Cumulative Timesteps: 22,059,592
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.36326
Policy Entropy: 3.77593
Value Function Loss: 0.26909
Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.59821
Collected Steps per Second: 11,897.05026
Overall Steps per Second: 6,604.98424
Timestep Collection Time: 4.20592
Timestep Consumption Time: 3.36988
PPO Batch Consumption Time: 0.25034
Total Iteration Time: 7.57579
Cumulative Model Updates: 3,966
Cumulative Timesteps: 22,109,630
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 22109630...
Checkpoint 22109630 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.55372
Policy Entropy: 3.77638
Value Function Loss: 0.26137
Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.54636
Value Function Update Magnitude: 0.69571
Collected Steps per Second: 11,934.07522
Overall Steps per Second: 6,685.17243
Timestep Collection Time: 4.19052
Timestep Consumption Time: 3.29021
PPO Batch Consumption Time: 0.24168
Total Iteration Time: 7.48073
Cumulative Model Updates: 3,975
Cumulative Timesteps: 22,159,640
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.88230
Policy Entropy: 3.77584
Value Function Loss: 0.26585
Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.54678
Value Function Update Magnitude: 0.66802
Collected Steps per Second: 11,098.97125
Overall Steps per Second: 6,408.22771
Timestep Collection Time: 4.50618
Timestep Consumption Time: 3.29847
PPO Batch Consumption Time: 0.23901
Total Iteration Time: 7.80465
Cumulative Model Updates: 3,984
Cumulative Timesteps: 22,209,654
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 22209654...
Checkpoint 22209654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10026
Policy Entropy: 3.77361
Value Function Loss: 0.27010
Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.63820
Collected Steps per Second: 11,524.88264
Overall Steps per Second: 6,611.74142
Timestep Collection Time: 4.34087
Timestep Consumption Time: 3.22567
PPO Batch Consumption Time: 0.23959
Total Iteration Time: 7.56654
Cumulative Model Updates: 3,993
Cumulative Timesteps: 22,259,682
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.78803
Policy Entropy: 3.77319
Value Function Loss: 0.27235
Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.55203
Value Function Update Magnitude: 0.65018
Collected Steps per Second: 11,850.85041
Overall Steps per Second: 6,667.31472
Timestep Collection Time: 4.22383
Timestep Consumption Time: 3.28384
PPO Batch Consumption Time: 0.24201
Total Iteration Time: 7.50767
Cumulative Model Updates: 4,002
Cumulative Timesteps: 22,309,738
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 22309738...
Checkpoint 22309738 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42653
Policy Entropy: 3.77066
Value Function Loss: 0.27281
Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.55739
Value Function Update Magnitude: 0.63209
Collected Steps per Second: 11,632.35101
Overall Steps per Second: 6,473.74905
Timestep Collection Time: 4.29973
Timestep Consumption Time: 3.42624
PPO Batch Consumption Time: 0.24992
Total Iteration Time: 7.72597
Cumulative Model Updates: 4,011
Cumulative Timesteps: 22,359,754
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.84778
Policy Entropy: 3.77042
Value Function Loss: 0.27482
Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.55162
Value Function Update Magnitude: 0.63440
Collected Steps per Second: 11,463.27600
Overall Steps per Second: 6,524.26100
Timestep Collection Time: 4.36280
Timestep Consumption Time: 3.30274
PPO Batch Consumption Time: 0.24825
Total Iteration Time: 7.66554
Cumulative Model Updates: 4,020
Cumulative Timesteps: 22,409,766
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 22409766...
Checkpoint 22409766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52348
Policy Entropy: 3.77271
Value Function Loss: 0.27316
Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.55240
Value Function Update Magnitude: 0.64982
Collected Steps per Second: 12,479.44233
Overall Steps per Second: 6,871.47275
Timestep Collection Time: 4.00963
Timestep Consumption Time: 3.27236
PPO Batch Consumption Time: 0.24100
Total Iteration Time: 7.28199
Cumulative Model Updates: 4,029
Cumulative Timesteps: 22,459,804
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.21587
Policy Entropy: 3.76255
Value Function Loss: 0.27088
Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.61477
Collected Steps per Second: 12,266.95525
Overall Steps per Second: 6,786.31972
Timestep Collection Time: 4.07778
Timestep Consumption Time: 3.29322
PPO Batch Consumption Time: 0.24517
Total Iteration Time: 7.37101
Cumulative Model Updates: 4,038
Cumulative Timesteps: 22,509,826
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 22509826...
Checkpoint 22509826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.11628
Policy Entropy: 3.76076
Value Function Loss: 0.25226
Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.54858
Value Function Update Magnitude: 0.66722
Collected Steps per Second: 11,189.12045
Overall Steps per Second: 6,531.00039
Timestep Collection Time: 4.46988
Timestep Consumption Time: 3.18806
PPO Batch Consumption Time: 0.24039
Total Iteration Time: 7.65794
Cumulative Model Updates: 4,047
Cumulative Timesteps: 22,559,840
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.04188
Policy Entropy: 3.76003
Value Function Loss: 0.25475
Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.54002
Value Function Update Magnitude: 0.61085
Collected Steps per Second: 11,836.71780
Overall Steps per Second: 6,687.40793
Timestep Collection Time: 4.22887
Timestep Consumption Time: 3.25624
PPO Batch Consumption Time: 0.23866
Total Iteration Time: 7.48511
Cumulative Model Updates: 4,056
Cumulative Timesteps: 22,609,896
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 22609896...
Checkpoint 22609896 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.92215
Policy Entropy: 3.75777
Value Function Loss: 0.26287
Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.62952
Collected Steps per Second: 10,830.20189
Overall Steps per Second: 6,160.33361
Timestep Collection Time: 4.61912
Timestep Consumption Time: 3.50154
PPO Batch Consumption Time: 0.25541
Total Iteration Time: 8.12066
Cumulative Model Updates: 4,065
Cumulative Timesteps: 22,659,922
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.00422
Policy Entropy: 3.76458
Value Function Loss: 0.26929
Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.56356
Value Function Update Magnitude: 0.65815
Collected Steps per Second: 11,706.41918
Overall Steps per Second: 6,523.82029
Timestep Collection Time: 4.27407
Timestep Consumption Time: 3.39537
PPO Batch Consumption Time: 0.25047
Total Iteration Time: 7.66943
Cumulative Model Updates: 4,074
Cumulative Timesteps: 22,709,956
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 22709956...
Checkpoint 22709956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49123
Policy Entropy: 3.76142
Value Function Loss: 0.24901
Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.55247
Value Function Update Magnitude: 0.62040
Collected Steps per Second: 11,621.02552
Overall Steps per Second: 6,459.47434
Timestep Collection Time: 4.30530
Timestep Consumption Time: 3.44022
PPO Batch Consumption Time: 0.25120
Total Iteration Time: 7.74552
Cumulative Model Updates: 4,083
Cumulative Timesteps: 22,759,988
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.34315
Policy Entropy: 3.76363
Value Function Loss: 0.25120
Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.57234
Value Function Update Magnitude: 0.61042
Collected Steps per Second: 11,713.51452
Overall Steps per Second: 6,541.38676
Timestep Collection Time: 4.27096
Timestep Consumption Time: 3.37696
PPO Batch Consumption Time: 0.25068
Total Iteration Time: 7.64792
Cumulative Model Updates: 4,092
Cumulative Timesteps: 22,810,016
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 22810016...
Checkpoint 22810016 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31619
Policy Entropy: 3.76094
Value Function Loss: 0.26237
Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.57845
Value Function Update Magnitude: 0.58492
Collected Steps per Second: 11,544.02566
Overall Steps per Second: 6,492.38613
Timestep Collection Time: 4.33367
Timestep Consumption Time: 3.37197
PPO Batch Consumption Time: 0.24807
Total Iteration Time: 7.70564
Cumulative Model Updates: 4,101
Cumulative Timesteps: 22,860,044
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.06157
Policy Entropy: 3.75859
Value Function Loss: 0.28365
Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.59192
Value Function Update Magnitude: 0.61535
Collected Steps per Second: 11,621.64075
Overall Steps per Second: 6,642.00075
Timestep Collection Time: 4.30473
Timestep Consumption Time: 3.22734
PPO Batch Consumption Time: 0.23869
Total Iteration Time: 7.53207
Cumulative Model Updates: 4,110
Cumulative Timesteps: 22,910,072
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 22910072...
Checkpoint 22910072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50886
Policy Entropy: 3.75949
Value Function Loss: 0.27576
Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.59165
Value Function Update Magnitude: 0.64190
Collected Steps per Second: 12,050.95755
Overall Steps per Second: 6,828.75229
Timestep Collection Time: 4.14988
Timestep Consumption Time: 3.17357
PPO Batch Consumption Time: 0.24198
Total Iteration Time: 7.32345
Cumulative Model Updates: 4,119
Cumulative Timesteps: 22,960,082
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29043
Policy Entropy: 3.76632
Value Function Loss: 0.27314
Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10692
Policy Update Magnitude: 0.58460
Value Function Update Magnitude: 0.68307
Collected Steps per Second: 10,587.12311
Overall Steps per Second: 6,021.53759
Timestep Collection Time: 4.72499
Timestep Consumption Time: 3.58253
PPO Batch Consumption Time: 0.26141
Total Iteration Time: 8.30751
Cumulative Model Updates: 4,128
Cumulative Timesteps: 23,010,106
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 23010106...
Checkpoint 23010106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27357
Policy Entropy: 3.76967
Value Function Loss: 0.28211
Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.58166
Value Function Update Magnitude: 0.73868
Collected Steps per Second: 10,916.92143
Overall Steps per Second: 6,258.06548
Timestep Collection Time: 4.58133
Timestep Consumption Time: 3.41060
PPO Batch Consumption Time: 0.25278
Total Iteration Time: 7.99193
Cumulative Model Updates: 4,137
Cumulative Timesteps: 23,060,120
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.80823
Policy Entropy: 3.77556
Value Function Loss: 0.29701
Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.58919
Value Function Update Magnitude: 0.71236
Collected Steps per Second: 12,149.69866
Overall Steps per Second: 6,700.08235
Timestep Collection Time: 4.11780
Timestep Consumption Time: 3.34927
PPO Batch Consumption Time: 0.24876
Total Iteration Time: 7.46707
Cumulative Model Updates: 4,146
Cumulative Timesteps: 23,110,150
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 23110150...
Checkpoint 23110150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.46343
Policy Entropy: 3.77053
Value Function Loss: 0.29638
Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.59378
Value Function Update Magnitude: 0.72179
Collected Steps per Second: 11,283.77702
Overall Steps per Second: 6,416.00189
Timestep Collection Time: 4.43238
Timestep Consumption Time: 3.36282
PPO Batch Consumption Time: 0.24693
Total Iteration Time: 7.79520
Cumulative Model Updates: 4,155
Cumulative Timesteps: 23,160,164
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.99328
Policy Entropy: 3.76510
Value Function Loss: 0.28327
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.58163
Value Function Update Magnitude: 0.69435
Collected Steps per Second: 11,334.37575
Overall Steps per Second: 6,485.96204
Timestep Collection Time: 4.41312
Timestep Consumption Time: 3.29892
PPO Batch Consumption Time: 0.24964
Total Iteration Time: 7.71204
Cumulative Model Updates: 4,164
Cumulative Timesteps: 23,210,184
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 23210184...
Checkpoint 23210184 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43843
Policy Entropy: 3.76855
Value Function Loss: 0.27571
Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.56871
Value Function Update Magnitude: 0.65982
Collected Steps per Second: 11,491.43639
Overall Steps per Second: 6,502.15860
Timestep Collection Time: 4.35246
Timestep Consumption Time: 3.33976
PPO Batch Consumption Time: 0.24457
Total Iteration Time: 7.69221
Cumulative Model Updates: 4,173
Cumulative Timesteps: 23,260,200
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.38705
Policy Entropy: 3.76655
Value Function Loss: 0.26405
Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.56020
Value Function Update Magnitude: 0.63643
Collected Steps per Second: 11,497.77572
Overall Steps per Second: 6,446.36561
Timestep Collection Time: 4.35319
Timestep Consumption Time: 3.41119
PPO Batch Consumption Time: 0.25493
Total Iteration Time: 7.76437
Cumulative Model Updates: 4,182
Cumulative Timesteps: 23,310,252
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 23310252...
Checkpoint 23310252 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.81499
Policy Entropy: 3.75756
Value Function Loss: 0.25139
Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.55350
Value Function Update Magnitude: 0.60766
Collected Steps per Second: 11,547.80383
Overall Steps per Second: 6,603.68904
Timestep Collection Time: 4.33295
Timestep Consumption Time: 3.24403
PPO Batch Consumption Time: 0.24791
Total Iteration Time: 7.57698
Cumulative Model Updates: 4,191
Cumulative Timesteps: 23,360,288
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52359
Policy Entropy: 3.75994
Value Function Loss: 0.24812
Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.58824
Collected Steps per Second: 12,269.31615
Overall Steps per Second: 6,800.74689
Timestep Collection Time: 4.08010
Timestep Consumption Time: 3.28086
PPO Batch Consumption Time: 0.24190
Total Iteration Time: 7.36096
Cumulative Model Updates: 4,200
Cumulative Timesteps: 23,410,348
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 23410348...
Checkpoint 23410348 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.98010
Policy Entropy: 3.75873
Value Function Loss: 0.25309
Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11382
Policy Update Magnitude: 0.55184
Value Function Update Magnitude: 0.60347
Collected Steps per Second: 12,119.60363
Overall Steps per Second: 6,797.01588
Timestep Collection Time: 4.12885
Timestep Consumption Time: 3.23321
PPO Batch Consumption Time: 0.23872
Total Iteration Time: 7.36205
Cumulative Model Updates: 4,209
Cumulative Timesteps: 23,460,388
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23084
Policy Entropy: 3.77080
Value Function Loss: 0.26305
Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.55856
Value Function Update Magnitude: 0.58283
Collected Steps per Second: 12,762.52522
Overall Steps per Second: 6,927.17169
Timestep Collection Time: 3.91991
Timestep Consumption Time: 3.30208
PPO Batch Consumption Time: 0.24309
Total Iteration Time: 7.22200
Cumulative Model Updates: 4,218
Cumulative Timesteps: 23,510,416
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 23510416...
Checkpoint 23510416 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.47083
Policy Entropy: 3.77055
Value Function Loss: 0.26841
Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.55436
Value Function Update Magnitude: 0.60656
Collected Steps per Second: 11,437.16739
Overall Steps per Second: 6,536.44216
Timestep Collection Time: 4.37189
Timestep Consumption Time: 3.27784
PPO Batch Consumption Time: 0.23908
Total Iteration Time: 7.64973
Cumulative Model Updates: 4,227
Cumulative Timesteps: 23,560,418
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.13783
Policy Entropy: 3.77669
Value Function Loss: 0.27170
Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11487
Policy Update Magnitude: 0.55932
Value Function Update Magnitude: 0.67743
Collected Steps per Second: 11,462.84766
Overall Steps per Second: 6,483.46146
Timestep Collection Time: 4.36541
Timestep Consumption Time: 3.35269
PPO Batch Consumption Time: 0.25562
Total Iteration Time: 7.71810
Cumulative Model Updates: 4,236
Cumulative Timesteps: 23,610,458
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 23610458...
Checkpoint 23610458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.08595
Policy Entropy: 3.77290
Value Function Loss: 0.27084
Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.67169
Collected Steps per Second: 12,120.45215
Overall Steps per Second: 6,552.00539
Timestep Collection Time: 4.12773
Timestep Consumption Time: 3.50810
PPO Batch Consumption Time: 0.25601
Total Iteration Time: 7.63583
Cumulative Model Updates: 4,245
Cumulative Timesteps: 23,660,488
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.04484
Policy Entropy: 3.77793
Value Function Loss: 0.26357
Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.56352
Value Function Update Magnitude: 0.63855
Collected Steps per Second: 11,328.87136
Overall Steps per Second: 6,426.44045
Timestep Collection Time: 4.41650
Timestep Consumption Time: 3.36914
PPO Batch Consumption Time: 0.24651
Total Iteration Time: 7.78565
Cumulative Model Updates: 4,254
Cumulative Timesteps: 23,710,522
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 23710522...
Checkpoint 23710522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54022
Policy Entropy: 3.77190
Value Function Loss: 0.26297
Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.70131
Collected Steps per Second: 12,343.98648
Overall Steps per Second: 6,740.54771
Timestep Collection Time: 4.05412
Timestep Consumption Time: 3.37020
PPO Batch Consumption Time: 0.24604
Total Iteration Time: 7.42432
Cumulative Model Updates: 4,263
Cumulative Timesteps: 23,760,566
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.98026
Policy Entropy: 3.77918
Value Function Loss: 0.26163
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.55487
Value Function Update Magnitude: 0.65670
Collected Steps per Second: 11,253.26831
Overall Steps per Second: 6,500.44829
Timestep Collection Time: 4.44564
Timestep Consumption Time: 3.25044
PPO Batch Consumption Time: 0.23880
Total Iteration Time: 7.69608
Cumulative Model Updates: 4,272
Cumulative Timesteps: 23,810,594
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 23810594...
Checkpoint 23810594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.82164
Policy Entropy: 3.77581
Value Function Loss: 0.27838
Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.56732
Value Function Update Magnitude: 0.66611
Collected Steps per Second: 11,352.24103
Overall Steps per Second: 6,434.09918
Timestep Collection Time: 4.40671
Timestep Consumption Time: 3.36843
PPO Batch Consumption Time: 0.24804
Total Iteration Time: 7.77514
Cumulative Model Updates: 4,281
Cumulative Timesteps: 23,860,620
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.39460
Policy Entropy: 3.77259
Value Function Loss: 0.27746
Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.57692
Value Function Update Magnitude: 0.66880
Collected Steps per Second: 11,488.67318
Overall Steps per Second: 6,355.83537
Timestep Collection Time: 4.35281
Timestep Consumption Time: 3.51524
PPO Batch Consumption Time: 0.26035
Total Iteration Time: 7.86805
Cumulative Model Updates: 4,290
Cumulative Timesteps: 23,910,628
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 23910628...
Checkpoint 23910628 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.17790
Policy Entropy: 3.76626
Value Function Loss: 0.29041
Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.59290
Value Function Update Magnitude: 0.69273
Collected Steps per Second: 11,599.92491
Overall Steps per Second: 6,390.94312
Timestep Collection Time: 4.31348
Timestep Consumption Time: 3.51573
PPO Batch Consumption Time: 0.25378
Total Iteration Time: 7.82920
Cumulative Model Updates: 4,299
Cumulative Timesteps: 23,960,664
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43227
Policy Entropy: 3.76105
Value Function Loss: 0.29090
Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.60263
Value Function Update Magnitude: 0.68475
Collected Steps per Second: 11,586.31055
Overall Steps per Second: 6,577.50257
Timestep Collection Time: 4.31854
Timestep Consumption Time: 3.28860
PPO Batch Consumption Time: 0.24014
Total Iteration Time: 7.60714
Cumulative Model Updates: 4,308
Cumulative Timesteps: 24,010,700
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 24010700...
Checkpoint 24010700 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74291
Policy Entropy: 3.76194
Value Function Loss: 0.29257
Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.59101
Value Function Update Magnitude: 0.72578
Collected Steps per Second: 12,327.82714
Overall Steps per Second: 6,832.68693
Timestep Collection Time: 4.05732
Timestep Consumption Time: 3.26307
PPO Batch Consumption Time: 0.23873
Total Iteration Time: 7.32040
Cumulative Model Updates: 4,317
Cumulative Timesteps: 24,060,718
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.95816
Policy Entropy: 3.76563
Value Function Loss: 0.29123
Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.58611
Value Function Update Magnitude: 0.65261
Collected Steps per Second: 12,399.74039
Overall Steps per Second: 6,908.23286
Timestep Collection Time: 4.03460
Timestep Consumption Time: 3.20719
PPO Batch Consumption Time: 0.24471
Total Iteration Time: 7.24179
Cumulative Model Updates: 4,326
Cumulative Timesteps: 24,110,746
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 24110746...
Checkpoint 24110746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.88453
Policy Entropy: 3.76911
Value Function Loss: 0.29000
Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.59327
Value Function Update Magnitude: 0.64950
Collected Steps per Second: 11,095.16399
Overall Steps per Second: 6,300.67817
Timestep Collection Time: 4.50719
Timestep Consumption Time: 3.42973
PPO Batch Consumption Time: 0.24899
Total Iteration Time: 7.93692
Cumulative Model Updates: 4,335
Cumulative Timesteps: 24,160,754
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29915
Policy Entropy: 3.76706
Value Function Loss: 0.28445
Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.59067
Value Function Update Magnitude: 0.67004
Collected Steps per Second: 11,291.22038
Overall Steps per Second: 6,353.94955
Timestep Collection Time: 4.42946
Timestep Consumption Time: 3.44187
PPO Batch Consumption Time: 0.25474
Total Iteration Time: 7.87132
Cumulative Model Updates: 4,344
Cumulative Timesteps: 24,210,768
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 24210768...
Checkpoint 24210768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.60987
Policy Entropy: 3.76339
Value Function Loss: 0.28214
Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.58563
Value Function Update Magnitude: 0.66738
Collected Steps per Second: 11,744.38846
Overall Steps per Second: 6,498.55705
Timestep Collection Time: 4.26212
Timestep Consumption Time: 3.44051
PPO Batch Consumption Time: 0.25817
Total Iteration Time: 7.70263
Cumulative Model Updates: 4,353
Cumulative Timesteps: 24,260,824
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.40006
Policy Entropy: 3.75761
Value Function Loss: 0.28252
Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.58886
Value Function Update Magnitude: 0.66832
Collected Steps per Second: 11,082.59664
Overall Steps per Second: 6,263.66113
Timestep Collection Time: 4.51194
Timestep Consumption Time: 3.47125
PPO Batch Consumption Time: 0.25756
Total Iteration Time: 7.98319
Cumulative Model Updates: 4,362
Cumulative Timesteps: 24,310,828
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 24310828...
Checkpoint 24310828 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.79710
Policy Entropy: 3.75756
Value Function Loss: 0.27593
Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.58439
Value Function Update Magnitude: 0.68454
Collected Steps per Second: 11,193.46302
Overall Steps per Second: 6,409.19043
Timestep Collection Time: 4.47172
Timestep Consumption Time: 3.33801
PPO Batch Consumption Time: 0.24715
Total Iteration Time: 7.80972
Cumulative Model Updates: 4,371
Cumulative Timesteps: 24,360,882
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.86016
Policy Entropy: 3.75815
Value Function Loss: 0.28191
Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.59115
Value Function Update Magnitude: 0.70622
Collected Steps per Second: 12,215.72278
Overall Steps per Second: 6,659.73633
Timestep Collection Time: 4.09390
Timestep Consumption Time: 3.41540
PPO Batch Consumption Time: 0.24650
Total Iteration Time: 7.50931
Cumulative Model Updates: 4,380
Cumulative Timesteps: 24,410,892
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 24410892...
Checkpoint 24410892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.08242
Policy Entropy: 3.75881
Value Function Loss: 0.29449
Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.60247
Value Function Update Magnitude: 0.70066
Collected Steps per Second: 11,884.84935
Overall Steps per Second: 6,648.39336
Timestep Collection Time: 4.20721
Timestep Consumption Time: 3.31371
PPO Batch Consumption Time: 0.24498
Total Iteration Time: 7.52091
Cumulative Model Updates: 4,389
Cumulative Timesteps: 24,460,894
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.55337
Policy Entropy: 3.76084
Value Function Loss: 0.29643
Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.61025
Value Function Update Magnitude: 0.70477
Collected Steps per Second: 12,051.15275
Overall Steps per Second: 6,750.30573
Timestep Collection Time: 4.15014
Timestep Consumption Time: 3.25900
PPO Batch Consumption Time: 0.24717
Total Iteration Time: 7.40915
Cumulative Model Updates: 4,398
Cumulative Timesteps: 24,510,908
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 24510908...
Checkpoint 24510908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41013
Policy Entropy: 3.75175
Value Function Loss: 0.30264
Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.61161
Value Function Update Magnitude: 0.69711
Collected Steps per Second: 11,707.13599
Overall Steps per Second: 6,379.49401
Timestep Collection Time: 4.27141
Timestep Consumption Time: 3.56714
PPO Batch Consumption Time: 0.26520
Total Iteration Time: 7.83855
Cumulative Model Updates: 4,407
Cumulative Timesteps: 24,560,914
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.98721
Policy Entropy: 3.74002
Value Function Loss: 0.29772
Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.61589
Value Function Update Magnitude: 0.70043
Collected Steps per Second: 11,892.34179
Overall Steps per Second: 6,651.42121
Timestep Collection Time: 4.20640
Timestep Consumption Time: 3.31439
PPO Batch Consumption Time: 0.24617
Total Iteration Time: 7.52080
Cumulative Model Updates: 4,416
Cumulative Timesteps: 24,610,938
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 24610938...
Checkpoint 24610938 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00418
Policy Entropy: 3.74096
Value Function Loss: 0.29745
Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.61463
Value Function Update Magnitude: 0.70985
Collected Steps per Second: 12,212.23216
Overall Steps per Second: 6,717.86471
Timestep Collection Time: 4.09704
Timestep Consumption Time: 3.35086
PPO Batch Consumption Time: 0.24600
Total Iteration Time: 7.44790
Cumulative Model Updates: 4,425
Cumulative Timesteps: 24,660,972
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23545
Policy Entropy: 3.74159
Value Function Loss: 0.29214
Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.61338
Value Function Update Magnitude: 0.65922
Collected Steps per Second: 11,702.66089
Overall Steps per Second: 6,582.12566
Timestep Collection Time: 4.27441
Timestep Consumption Time: 3.32526
PPO Batch Consumption Time: 0.24345
Total Iteration Time: 7.59967
Cumulative Model Updates: 4,434
Cumulative Timesteps: 24,710,994
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 24710994...
Checkpoint 24710994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.26160
Policy Entropy: 3.74439
Value Function Loss: 0.28188
Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.60884
Value Function Update Magnitude: 0.68893
Collected Steps per Second: 11,794.06234
Overall Steps per Second: 6,652.59290
Timestep Collection Time: 4.24146
Timestep Consumption Time: 3.27802
PPO Batch Consumption Time: 0.24768
Total Iteration Time: 7.51947
Cumulative Model Updates: 4,443
Cumulative Timesteps: 24,761,018
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.39249
Policy Entropy: 3.74664
Value Function Loss: 0.28118
Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.60787
Value Function Update Magnitude: 0.63648
Collected Steps per Second: 11,842.20167
Overall Steps per Second: 6,604.47078
Timestep Collection Time: 4.22421
Timestep Consumption Time: 3.35005
PPO Batch Consumption Time: 0.24919
Total Iteration Time: 7.57426
Cumulative Model Updates: 4,452
Cumulative Timesteps: 24,811,042
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 24811042...
Checkpoint 24811042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.26903
Policy Entropy: 3.74652
Value Function Loss: 0.28678
Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.61372
Value Function Update Magnitude: 0.64585
Collected Steps per Second: 11,419.11130
Overall Steps per Second: 6,395.29006
Timestep Collection Time: 4.37880
Timestep Consumption Time: 3.43977
PPO Batch Consumption Time: 0.25732
Total Iteration Time: 7.81857
Cumulative Model Updates: 4,461
Cumulative Timesteps: 24,861,044
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70994
Policy Entropy: 3.75322
Value Function Loss: 0.28273
Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.63462
Value Function Update Magnitude: 0.62749
Collected Steps per Second: 11,395.11794
Overall Steps per Second: 6,360.51598
Timestep Collection Time: 4.39153
Timestep Consumption Time: 3.47607
PPO Batch Consumption Time: 0.25391
Total Iteration Time: 7.86760
Cumulative Model Updates: 4,470
Cumulative Timesteps: 24,911,086
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 24911086...
Checkpoint 24911086 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.28651
Policy Entropy: 3.74715
Value Function Loss: 0.27816
Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.63616
Value Function Update Magnitude: 0.61911
Collected Steps per Second: 12,044.87713
Overall Steps per Second: 6,670.72127
Timestep Collection Time: 4.15446
Timestep Consumption Time: 3.34697
PPO Batch Consumption Time: 0.24359
Total Iteration Time: 7.50144
Cumulative Model Updates: 4,479
Cumulative Timesteps: 24,961,126
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31413
Policy Entropy: 3.74829
Value Function Loss: 0.28001
Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.62244
Value Function Update Magnitude: 0.60606
Collected Steps per Second: 11,132.89258
Overall Steps per Second: 6,398.68754
Timestep Collection Time: 4.49245
Timestep Consumption Time: 3.32384
PPO Batch Consumption Time: 0.25353
Total Iteration Time: 7.81629
Cumulative Model Updates: 4,488
Cumulative Timesteps: 25,011,140
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 25011140...
Checkpoint 25011140 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67602
Policy Entropy: 3.74483
Value Function Loss: 0.28192
Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10541
Policy Update Magnitude: 0.62953
Value Function Update Magnitude: 0.65219
Collected Steps per Second: 11,053.29867
Overall Steps per Second: 6,280.27651
Timestep Collection Time: 4.52354
Timestep Consumption Time: 3.43790
PPO Batch Consumption Time: 0.25177
Total Iteration Time: 7.96143
Cumulative Model Updates: 4,497
Cumulative Timesteps: 25,061,140
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32400
Policy Entropy: 3.74378
Value Function Loss: 0.28796
Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.63342
Value Function Update Magnitude: 0.63362
Collected Steps per Second: 11,701.16456
Overall Steps per Second: 6,544.62701
Timestep Collection Time: 4.27564
Timestep Consumption Time: 3.36880
PPO Batch Consumption Time: 0.25021
Total Iteration Time: 7.64444
Cumulative Model Updates: 4,506
Cumulative Timesteps: 25,111,170
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 25111170...
Checkpoint 25111170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.20223
Policy Entropy: 3.75277
Value Function Loss: 0.28219
Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.62152
Value Function Update Magnitude: 0.62924
Collected Steps per Second: 10,604.80511
Overall Steps per Second: 6,250.63123
Timestep Collection Time: 4.71899
Timestep Consumption Time: 3.28724
PPO Batch Consumption Time: 0.24924
Total Iteration Time: 8.00623
Cumulative Model Updates: 4,515
Cumulative Timesteps: 25,161,214
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57552
Policy Entropy: 3.75870
Value Function Loss: 0.28683
Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.62859
Value Function Update Magnitude: 0.61716
Collected Steps per Second: 12,408.39619
Overall Steps per Second: 6,739.28693
Timestep Collection Time: 4.03227
Timestep Consumption Time: 3.39196
PPO Batch Consumption Time: 0.24025
Total Iteration Time: 7.42423
Cumulative Model Updates: 4,524
Cumulative Timesteps: 25,211,248
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 25211248...
Checkpoint 25211248 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.68475
Policy Entropy: 3.76167
Value Function Loss: 0.28516
Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.62429
Value Function Update Magnitude: 0.61857
Collected Steps per Second: 11,454.32067
Overall Steps per Second: 6,564.63192
Timestep Collection Time: 4.36970
Timestep Consumption Time: 3.25479
PPO Batch Consumption Time: 0.23998
Total Iteration Time: 7.62449
Cumulative Model Updates: 4,533
Cumulative Timesteps: 25,261,300
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67582
Policy Entropy: 3.76156
Value Function Loss: 0.28400
Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.61147
Value Function Update Magnitude: 0.61007
Collected Steps per Second: 12,311.56500
Overall Steps per Second: 6,798.09820
Timestep Collection Time: 4.06285
Timestep Consumption Time: 3.29509
PPO Batch Consumption Time: 0.24353
Total Iteration Time: 7.35794
Cumulative Model Updates: 4,542
Cumulative Timesteps: 25,311,320
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 25311320...
Checkpoint 25311320 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.31231
Policy Entropy: 3.76137
Value Function Loss: 0.28501
Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.60961
Value Function Update Magnitude: 0.66515
Collected Steps per Second: 11,206.07104
Overall Steps per Second: 6,445.28133
Timestep Collection Time: 4.46276
Timestep Consumption Time: 3.29641
PPO Batch Consumption Time: 0.23890
Total Iteration Time: 7.75916
Cumulative Model Updates: 4,551
Cumulative Timesteps: 25,361,330
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.39297
Policy Entropy: 3.76498
Value Function Loss: 0.27802
Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.60782
Value Function Update Magnitude: 0.64023
Collected Steps per Second: 12,537.66043
Overall Steps per Second: 7,019.89428
Timestep Collection Time: 3.98830
Timestep Consumption Time: 3.13488
PPO Batch Consumption Time: 0.23807
Total Iteration Time: 7.12318
Cumulative Model Updates: 4,560
Cumulative Timesteps: 25,411,334
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 25411334...
Checkpoint 25411334 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.12701
Policy Entropy: 3.76209
Value Function Loss: 0.28579
Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.61234
Value Function Update Magnitude: 0.65517
Collected Steps per Second: 11,638.55191
Overall Steps per Second: 6,547.12677
Timestep Collection Time: 4.29847
Timestep Consumption Time: 3.34274
PPO Batch Consumption Time: 0.24840
Total Iteration Time: 7.64121
Cumulative Model Updates: 4,569
Cumulative Timesteps: 25,461,362
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.64149
Policy Entropy: 3.76341
Value Function Loss: 0.28272
Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.12116
Policy Update Magnitude: 0.60736
Value Function Update Magnitude: 0.61667
Collected Steps per Second: 11,252.17843
Overall Steps per Second: 6,492.00001
Timestep Collection Time: 4.44483
Timestep Consumption Time: 3.25912
PPO Batch Consumption Time: 0.23871
Total Iteration Time: 7.70394
Cumulative Model Updates: 4,578
Cumulative Timesteps: 25,511,376
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 25511376...
Checkpoint 25511376 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.81794
Policy Entropy: 3.76433
Value Function Loss: 0.28776
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.60719
Value Function Update Magnitude: 0.62159
Collected Steps per Second: 12,441.70932
Overall Steps per Second: 6,975.15405
Timestep Collection Time: 4.02196
Timestep Consumption Time: 3.15208
PPO Batch Consumption Time: 0.23824
Total Iteration Time: 7.17404
Cumulative Model Updates: 4,587
Cumulative Timesteps: 25,561,416
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.39485
Policy Entropy: 3.75828
Value Function Loss: 0.28424
Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.60442
Value Function Update Magnitude: 0.61749
Collected Steps per Second: 11,868.67820
Overall Steps per Second: 6,641.30659
Timestep Collection Time: 4.21378
Timestep Consumption Time: 3.31667
PPO Batch Consumption Time: 0.24429
Total Iteration Time: 7.53045
Cumulative Model Updates: 4,596
Cumulative Timesteps: 25,611,428
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 25611428...
Checkpoint 25611428 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.12735
Policy Entropy: 3.76090
Value Function Loss: 0.29037
Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.59796
Value Function Update Magnitude: 0.66449
Collected Steps per Second: 11,952.41062
Overall Steps per Second: 6,560.62935
Timestep Collection Time: 4.18409
Timestep Consumption Time: 3.43865
PPO Batch Consumption Time: 0.25172
Total Iteration Time: 7.62274
Cumulative Model Updates: 4,605
Cumulative Timesteps: 25,661,438
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.45877
Policy Entropy: 3.75311
Value Function Loss: 0.28781
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.61056
Value Function Update Magnitude: 0.66632
Collected Steps per Second: 11,416.76979
Overall Steps per Second: 6,508.93677
Timestep Collection Time: 4.38215
Timestep Consumption Time: 3.30420
PPO Batch Consumption Time: 0.24854
Total Iteration Time: 7.68636
Cumulative Model Updates: 4,614
Cumulative Timesteps: 25,711,468
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 25711468...
Checkpoint 25711468 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28696
Policy Entropy: 3.76589
Value Function Loss: 0.28442
Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.60685
Value Function Update Magnitude: 0.64419
Collected Steps per Second: 11,417.24461
Overall Steps per Second: 6,346.81561
Timestep Collection Time: 4.38232
Timestep Consumption Time: 3.50101
PPO Batch Consumption Time: 0.26509
Total Iteration Time: 7.88332
Cumulative Model Updates: 4,623
Cumulative Timesteps: 25,761,502
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97478
Policy Entropy: 3.75965
Value Function Loss: 0.29343
Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.60543
Value Function Update Magnitude: 0.60990
Collected Steps per Second: 11,329.94516
Overall Steps per Second: 6,565.63189
Timestep Collection Time: 4.41591
Timestep Consumption Time: 3.20438
PPO Batch Consumption Time: 0.24289
Total Iteration Time: 7.62029
Cumulative Model Updates: 4,632
Cumulative Timesteps: 25,811,534
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 25811534...
Checkpoint 25811534 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70347
Policy Entropy: 3.76087
Value Function Loss: 0.28522
Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.60681
Value Function Update Magnitude: 0.62388
Collected Steps per Second: 11,983.15657
Overall Steps per Second: 6,699.00854
Timestep Collection Time: 4.17269
Timestep Consumption Time: 3.29140
PPO Batch Consumption Time: 0.24172
Total Iteration Time: 7.46409
Cumulative Model Updates: 4,641
Cumulative Timesteps: 25,861,536
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43284
Policy Entropy: 3.75227
Value Function Loss: 0.27668
Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.59832
Value Function Update Magnitude: 0.58150
Collected Steps per Second: 12,204.74611
Overall Steps per Second: 6,793.93364
Timestep Collection Time: 4.09906
Timestep Consumption Time: 3.26457
PPO Batch Consumption Time: 0.24200
Total Iteration Time: 7.36363
Cumulative Model Updates: 4,650
Cumulative Timesteps: 25,911,564
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 25911564...
Checkpoint 25911564 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.26547
Policy Entropy: 3.74996
Value Function Loss: 0.27328
Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.58776
Value Function Update Magnitude: 0.56601
Collected Steps per Second: 12,247.85724
Overall Steps per Second: 6,823.87896
Timestep Collection Time: 4.08594
Timestep Consumption Time: 3.24772
PPO Batch Consumption Time: 0.23776
Total Iteration Time: 7.33366
Cumulative Model Updates: 4,659
Cumulative Timesteps: 25,961,608
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21317
Policy Entropy: 3.75024
Value Function Loss: 0.28201
Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.58976
Value Function Update Magnitude: 0.57945
Collected Steps per Second: 12,472.38991
Overall Steps per Second: 6,913.48036
Timestep Collection Time: 4.01126
Timestep Consumption Time: 3.22533
PPO Batch Consumption Time: 0.23866
Total Iteration Time: 7.23659
Cumulative Model Updates: 4,668
Cumulative Timesteps: 26,011,638
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 26011638...
Checkpoint 26011638 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01459
Policy Entropy: 3.75451
Value Function Loss: 0.29613
Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.15003
Policy Update Magnitude: 0.58758
Value Function Update Magnitude: 0.60973
Collected Steps per Second: 12,328.35600
Overall Steps per Second: 6,948.59913
Timestep Collection Time: 4.05569
Timestep Consumption Time: 3.14000
PPO Batch Consumption Time: 0.23784
Total Iteration Time: 7.19569
Cumulative Model Updates: 4,677
Cumulative Timesteps: 26,061,638
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22035
Policy Entropy: 3.75714
Value Function Loss: 0.29210
Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.58789
Value Function Update Magnitude: 0.59584
Collected Steps per Second: 11,394.38275
Overall Steps per Second: 6,331.29488
Timestep Collection Time: 4.39146
Timestep Consumption Time: 3.51182
PPO Batch Consumption Time: 0.25945
Total Iteration Time: 7.90328
Cumulative Model Updates: 4,686
Cumulative Timesteps: 26,111,676
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 26111676...
Checkpoint 26111676 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42348
Policy Entropy: 3.75468
Value Function Loss: 0.29555
Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.59090
Value Function Update Magnitude: 0.59853
Collected Steps per Second: 11,565.64853
Overall Steps per Second: 6,449.79985
Timestep Collection Time: 4.32643
Timestep Consumption Time: 3.43164
PPO Batch Consumption Time: 0.25660
Total Iteration Time: 7.75807
Cumulative Model Updates: 4,695
Cumulative Timesteps: 26,161,714
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.64029
Policy Entropy: 3.75589
Value Function Loss: 0.29764
Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.58758
Value Function Update Magnitude: 0.59548
Collected Steps per Second: 11,116.84728
Overall Steps per Second: 6,471.42687
Timestep Collection Time: 4.49894
Timestep Consumption Time: 3.22950
PPO Batch Consumption Time: 0.24534
Total Iteration Time: 7.72843
Cumulative Model Updates: 4,704
Cumulative Timesteps: 26,211,728
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 26211728...
Checkpoint 26211728 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.64770
Policy Entropy: 3.75787
Value Function Loss: 0.30991
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.59975
Value Function Update Magnitude: 0.61985
Collected Steps per Second: 11,922.02637
Overall Steps per Second: 6,645.56793
Timestep Collection Time: 4.19476
Timestep Consumption Time: 3.33056
PPO Batch Consumption Time: 0.24578
Total Iteration Time: 7.52532
Cumulative Model Updates: 4,713
Cumulative Timesteps: 26,261,738
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.79850
Policy Entropy: 3.76068
Value Function Loss: 0.30262
Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.60324
Value Function Update Magnitude: 0.60927
Collected Steps per Second: 11,953.53089
Overall Steps per Second: 6,658.97947
Timestep Collection Time: 4.18404
Timestep Consumption Time: 3.32672
PPO Batch Consumption Time: 0.24832
Total Iteration Time: 7.51076
Cumulative Model Updates: 4,722
Cumulative Timesteps: 26,311,752
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 26311752...
Checkpoint 26311752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40543
Policy Entropy: 3.76275
Value Function Loss: 0.30007
Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.60284
Value Function Update Magnitude: 0.64885
Collected Steps per Second: 12,186.95523
Overall Steps per Second: 6,738.71303
Timestep Collection Time: 4.10291
Timestep Consumption Time: 3.31720
PPO Batch Consumption Time: 0.24563
Total Iteration Time: 7.42011
Cumulative Model Updates: 4,731
Cumulative Timesteps: 26,361,754
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.04995
Policy Entropy: 3.76487
Value Function Loss: 0.30402
Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.60872
Value Function Update Magnitude: 0.61399
Collected Steps per Second: 11,893.56687
Overall Steps per Second: 6,487.65365
Timestep Collection Time: 4.20446
Timestep Consumption Time: 3.50341
PPO Batch Consumption Time: 0.26250
Total Iteration Time: 7.70787
Cumulative Model Updates: 4,740
Cumulative Timesteps: 26,411,760
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 26411760...
Checkpoint 26411760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.38227
Policy Entropy: 3.76911
Value Function Loss: 0.30108
Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.61232
Value Function Update Magnitude: 0.62665
Collected Steps per Second: 11,904.56552
Overall Steps per Second: 6,748.26868
Timestep Collection Time: 4.20091
Timestep Consumption Time: 3.20988
PPO Batch Consumption Time: 0.24622
Total Iteration Time: 7.41079
Cumulative Model Updates: 4,749
Cumulative Timesteps: 26,461,770
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70820
Policy Entropy: 3.77023
Value Function Loss: 0.30122
Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.61092
Value Function Update Magnitude: 0.64118
Collected Steps per Second: 11,843.66756
Overall Steps per Second: 6,630.06089
Timestep Collection Time: 4.22504
Timestep Consumption Time: 3.32240
PPO Batch Consumption Time: 0.24454
Total Iteration Time: 7.54744
Cumulative Model Updates: 4,758
Cumulative Timesteps: 26,511,810
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 26511810...
Checkpoint 26511810 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.86211
Policy Entropy: 3.77059
Value Function Loss: 0.29746
Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.61085
Value Function Update Magnitude: 0.65043
Collected Steps per Second: 11,760.44683
Overall Steps per Second: 6,568.11966
Timestep Collection Time: 4.25392
Timestep Consumption Time: 3.36287
PPO Batch Consumption Time: 0.25453
Total Iteration Time: 7.61679
Cumulative Model Updates: 4,767
Cumulative Timesteps: 26,561,838
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.20629
Policy Entropy: 3.76891
Value Function Loss: 0.30834
Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.61091
Value Function Update Magnitude: 0.69449
Collected Steps per Second: 11,339.49155
Overall Steps per Second: 6,438.87121
Timestep Collection Time: 4.41131
Timestep Consumption Time: 3.35744
PPO Batch Consumption Time: 0.24535
Total Iteration Time: 7.76875
Cumulative Model Updates: 4,776
Cumulative Timesteps: 26,611,860
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 26611860...
Checkpoint 26611860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90019
Policy Entropy: 3.76628
Value Function Loss: 0.31365
Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11168
Policy Update Magnitude: 0.62154
Value Function Update Magnitude: 0.71052
Collected Steps per Second: 11,818.25921
Overall Steps per Second: 6,707.80992
Timestep Collection Time: 4.23345
Timestep Consumption Time: 3.22532
PPO Batch Consumption Time: 0.23765
Total Iteration Time: 7.45877
Cumulative Model Updates: 4,785
Cumulative Timesteps: 26,661,892
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.87137
Policy Entropy: 3.76363
Value Function Loss: 0.30161
Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.62500
Value Function Update Magnitude: 0.69012
Collected Steps per Second: 12,440.15494
Overall Steps per Second: 6,907.21059
Timestep Collection Time: 4.02214
Timestep Consumption Time: 3.22189
PPO Batch Consumption Time: 0.23857
Total Iteration Time: 7.24402
Cumulative Model Updates: 4,794
Cumulative Timesteps: 26,711,928
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 26711928...
Checkpoint 26711928 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.57363
Policy Entropy: 3.75397
Value Function Loss: 0.30477
Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.62121
Value Function Update Magnitude: 0.66685
Collected Steps per Second: 12,219.87708
Overall Steps per Second: 6,624.70771
Timestep Collection Time: 4.09366
Timestep Consumption Time: 3.45747
PPO Batch Consumption Time: 0.25710
Total Iteration Time: 7.55113
Cumulative Model Updates: 4,803
Cumulative Timesteps: 26,761,952
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.09640
Policy Entropy: 3.76198
Value Function Loss: 0.30497
Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.61396
Value Function Update Magnitude: 0.68217
Collected Steps per Second: 12,349.40187
Overall Steps per Second: 6,866.88078
Timestep Collection Time: 4.05105
Timestep Consumption Time: 3.23436
PPO Batch Consumption Time: 0.23914
Total Iteration Time: 7.28540
Cumulative Model Updates: 4,812
Cumulative Timesteps: 26,811,980
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 26811980...
Checkpoint 26811980 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.82630
Policy Entropy: 3.76307
Value Function Loss: 0.30819
Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.61401
Value Function Update Magnitude: 0.67538
Collected Steps per Second: 11,322.11916
Overall Steps per Second: 6,548.93602
Timestep Collection Time: 4.41843
Timestep Consumption Time: 3.22037
PPO Batch Consumption Time: 0.24488
Total Iteration Time: 7.63880
Cumulative Model Updates: 4,821
Cumulative Timesteps: 26,862,006
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.38461
Policy Entropy: 3.76954
Value Function Loss: 0.31146
Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.62177
Value Function Update Magnitude: 0.67868
Collected Steps per Second: 11,478.11107
Overall Steps per Second: 6,535.10980
Timestep Collection Time: 4.35629
Timestep Consumption Time: 3.29500
PPO Batch Consumption Time: 0.24264
Total Iteration Time: 7.65129
Cumulative Model Updates: 4,830
Cumulative Timesteps: 26,912,008
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 26912008...
Checkpoint 26912008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.27300
Policy Entropy: 3.76899
Value Function Loss: 0.29939
Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.61185
Value Function Update Magnitude: 0.67287
Collected Steps per Second: 12,140.50818
Overall Steps per Second: 6,767.00504
Timestep Collection Time: 4.12042
Timestep Consumption Time: 3.27192
PPO Batch Consumption Time: 0.24421
Total Iteration Time: 7.39234
Cumulative Model Updates: 4,839
Cumulative Timesteps: 26,962,032
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.06995
Policy Entropy: 3.77384
Value Function Loss: 0.29786
Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.61242
Value Function Update Magnitude: 0.64916
Collected Steps per Second: 12,078.30976
Overall Steps per Second: 6,742.67949
Timestep Collection Time: 4.14048
Timestep Consumption Time: 3.27645
PPO Batch Consumption Time: 0.23814
Total Iteration Time: 7.41693
Cumulative Model Updates: 4,848
Cumulative Timesteps: 27,012,042
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 27012042...
Checkpoint 27012042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06759
Policy Entropy: 3.77383
Value Function Loss: 0.28684
Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.60655
Value Function Update Magnitude: 0.64059
Collected Steps per Second: 12,350.25440
Overall Steps per Second: 6,660.22938
Timestep Collection Time: 4.05093
Timestep Consumption Time: 3.46082
PPO Batch Consumption Time: 0.25135
Total Iteration Time: 7.51175
Cumulative Model Updates: 4,857
Cumulative Timesteps: 27,062,072
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56263
Policy Entropy: 3.77150
Value Function Loss: 0.28991
Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.59574
Value Function Update Magnitude: 0.61294
Collected Steps per Second: 12,317.02575
Overall Steps per Second: 6,949.44436
Timestep Collection Time: 4.06202
Timestep Consumption Time: 3.13740
PPO Batch Consumption Time: 0.23771
Total Iteration Time: 7.19942
Cumulative Model Updates: 4,866
Cumulative Timesteps: 27,112,104
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 27112104...
Checkpoint 27112104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.76098
Policy Entropy: 3.77309
Value Function Loss: 0.29152
Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.60337
Value Function Update Magnitude: 0.62629
Collected Steps per Second: 11,713.93059
Overall Steps per Second: 6,650.54988
Timestep Collection Time: 4.27081
Timestep Consumption Time: 3.25157
PPO Batch Consumption Time: 0.23910
Total Iteration Time: 7.52239
Cumulative Model Updates: 4,875
Cumulative Timesteps: 27,162,132
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.82716
Policy Entropy: 3.76636
Value Function Loss: 0.28405
Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.60575
Value Function Update Magnitude: 0.62617
Collected Steps per Second: 11,637.52071
Overall Steps per Second: 6,562.96479
Timestep Collection Time: 4.29799
Timestep Consumption Time: 3.32326
PPO Batch Consumption Time: 0.24421
Total Iteration Time: 7.62125
Cumulative Model Updates: 4,884
Cumulative Timesteps: 27,212,150
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 27212150...
Checkpoint 27212150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64887
Policy Entropy: 3.77285
Value Function Loss: 0.28911
Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.60770
Value Function Update Magnitude: 0.66806
Collected Steps per Second: 10,550.14728
Overall Steps per Second: 6,291.02363
Timestep Collection Time: 4.74401
Timestep Consumption Time: 3.21177
PPO Batch Consumption Time: 0.24353
Total Iteration Time: 7.95578
Cumulative Model Updates: 4,893
Cumulative Timesteps: 27,262,200
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.21766
Policy Entropy: 3.76613
Value Function Loss: 0.29441
Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.61269
Value Function Update Magnitude: 0.69792
Collected Steps per Second: 11,872.25353
Overall Steps per Second: 6,607.59098
Timestep Collection Time: 4.21470
Timestep Consumption Time: 3.35810
PPO Batch Consumption Time: 0.24619
Total Iteration Time: 7.57281
Cumulative Model Updates: 4,902
Cumulative Timesteps: 27,312,238
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 27312238...
Checkpoint 27312238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.11499
Policy Entropy: 3.76473
Value Function Loss: 0.30589
Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11385
Policy Update Magnitude: 0.62455
Value Function Update Magnitude: 0.73531
Collected Steps per Second: 11,906.76561
Overall Steps per Second: 6,683.29434
Timestep Collection Time: 4.20114
Timestep Consumption Time: 3.28349
PPO Batch Consumption Time: 0.24553
Total Iteration Time: 7.48463
Cumulative Model Updates: 4,911
Cumulative Timesteps: 27,362,260
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51952
Policy Entropy: 3.76517
Value Function Loss: 0.30368
Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.63808
Value Function Update Magnitude: 0.71821
Collected Steps per Second: 11,492.31473
Overall Steps per Second: 6,547.48808
Timestep Collection Time: 4.35421
Timestep Consumption Time: 3.28841
PPO Batch Consumption Time: 0.23799
Total Iteration Time: 7.64263
Cumulative Model Updates: 4,920
Cumulative Timesteps: 27,412,300
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 27412300...
Checkpoint 27412300 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.88098
Policy Entropy: 3.76116
Value Function Loss: 0.31764
Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.64031
Value Function Update Magnitude: 0.71218
Collected Steps per Second: 11,989.25243
Overall Steps per Second: 6,708.12930
Timestep Collection Time: 4.17240
Timestep Consumption Time: 3.28482
PPO Batch Consumption Time: 0.23848
Total Iteration Time: 7.45722
Cumulative Model Updates: 4,929
Cumulative Timesteps: 27,462,324
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21969
Policy Entropy: 3.76567
Value Function Loss: 0.31048
Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.64509
Value Function Update Magnitude: 0.69831
Collected Steps per Second: 9,407.07096
Overall Steps per Second: 5,844.13164
Timestep Collection Time: 5.31791
Timestep Consumption Time: 3.24213
PPO Batch Consumption Time: 0.24469
Total Iteration Time: 8.56004
Cumulative Model Updates: 4,938
Cumulative Timesteps: 27,512,350
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 27512350...
Checkpoint 27512350 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22148
Policy Entropy: 3.76002
Value Function Loss: 0.30503
Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.64628
Value Function Update Magnitude: 0.65145
Collected Steps per Second: 11,403.96282
Overall Steps per Second: 6,346.50992
Timestep Collection Time: 4.38532
Timestep Consumption Time: 3.49460
PPO Batch Consumption Time: 0.24718
Total Iteration Time: 7.87992
Cumulative Model Updates: 4,947
Cumulative Timesteps: 27,562,360
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.09006
Policy Entropy: 3.76495
Value Function Loss: 0.30551
Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.64647
Value Function Update Magnitude: 0.61727
Collected Steps per Second: 11,076.49123
Overall Steps per Second: 6,486.12983
Timestep Collection Time: 4.51587
Timestep Consumption Time: 3.19597
PPO Batch Consumption Time: 0.23833
Total Iteration Time: 7.71184
Cumulative Model Updates: 4,956
Cumulative Timesteps: 27,612,380
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 27612380...
Checkpoint 27612380 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.98295
Policy Entropy: 3.76159
Value Function Loss: 0.30931
Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.63498
Value Function Update Magnitude: 0.64843
Collected Steps per Second: 12,279.00588
Overall Steps per Second: 6,910.24194
Timestep Collection Time: 4.07346
Timestep Consumption Time: 3.16478
PPO Batch Consumption Time: 0.23824
Total Iteration Time: 7.23824
Cumulative Model Updates: 4,965
Cumulative Timesteps: 27,662,398
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.76967
Policy Entropy: 3.76021
Value Function Loss: 0.31357
Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.63778
Value Function Update Magnitude: 0.64275
Collected Steps per Second: 12,340.80084
Overall Steps per Second: 6,808.96410
Timestep Collection Time: 4.05257
Timestep Consumption Time: 3.29245
PPO Batch Consumption Time: 0.23950
Total Iteration Time: 7.34502
Cumulative Model Updates: 4,974
Cumulative Timesteps: 27,712,410
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 27712410...
Checkpoint 27712410 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19939
Policy Entropy: 3.75940
Value Function Loss: 0.31075
Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.62998
Value Function Update Magnitude: 0.66590
Collected Steps per Second: 12,250.27374
Overall Steps per Second: 6,844.68335
Timestep Collection Time: 4.08301
Timestep Consumption Time: 3.22456
PPO Batch Consumption Time: 0.23866
Total Iteration Time: 7.30757
Cumulative Model Updates: 4,983
Cumulative Timesteps: 27,762,428
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.75388
Policy Entropy: 3.76147
Value Function Loss: 0.30902
Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.62051
Value Function Update Magnitude: 0.73043
Collected Steps per Second: 12,454.66112
Overall Steps per Second: 6,852.75833
Timestep Collection Time: 4.01601
Timestep Consumption Time: 3.28295
PPO Batch Consumption Time: 0.23789
Total Iteration Time: 7.29896
Cumulative Model Updates: 4,992
Cumulative Timesteps: 27,812,446
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 27812446...
Checkpoint 27812446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.88182
Policy Entropy: 3.75904
Value Function Loss: 0.31313
Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.63134
Value Function Update Magnitude: 0.74617
Collected Steps per Second: 12,345.15187
Overall Steps per Second: 6,863.46234
Timestep Collection Time: 4.05163
Timestep Consumption Time: 3.23594
PPO Batch Consumption Time: 0.23815
Total Iteration Time: 7.28758
Cumulative Model Updates: 5,001
Cumulative Timesteps: 27,862,464
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.78908
Policy Entropy: 3.75817
Value Function Loss: 0.30413
Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.63667
Value Function Update Magnitude: 0.67675
Collected Steps per Second: 12,430.84943
Overall Steps per Second: 6,982.79534
Timestep Collection Time: 4.02515
Timestep Consumption Time: 3.14046
PPO Batch Consumption Time: 0.23839
Total Iteration Time: 7.16561
Cumulative Model Updates: 5,010
Cumulative Timesteps: 27,912,500
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 27912500...
Checkpoint 27912500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.45008
Policy Entropy: 3.75785
Value Function Loss: 0.30566
Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.62910
Value Function Update Magnitude: 0.69166
Collected Steps per Second: 12,265.89672
Overall Steps per Second: 6,825.45213
Timestep Collection Time: 4.07993
Timestep Consumption Time: 3.25204
PPO Batch Consumption Time: 0.23874
Total Iteration Time: 7.33197
Cumulative Model Updates: 5,019
Cumulative Timesteps: 27,962,544
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51282
Policy Entropy: 3.76218
Value Function Loss: 0.29974
Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12220
Policy Update Magnitude: 0.62447
Value Function Update Magnitude: 0.69920
Collected Steps per Second: 12,487.14549
Overall Steps per Second: 6,926.62628
Timestep Collection Time: 4.00492
Timestep Consumption Time: 3.21505
PPO Batch Consumption Time: 0.23833
Total Iteration Time: 7.21997
Cumulative Model Updates: 5,028
Cumulative Timesteps: 28,012,554
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 28012554...
Checkpoint 28012554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.38330
Policy Entropy: 3.76128
Value Function Loss: 0.31576
Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.63230
Value Function Update Magnitude: 0.70171
Collected Steps per Second: 12,465.55389
Overall Steps per Second: 6,838.54915
Timestep Collection Time: 4.01137
Timestep Consumption Time: 3.30070
PPO Batch Consumption Time: 0.24057
Total Iteration Time: 7.31208
Cumulative Model Updates: 5,037
Cumulative Timesteps: 28,062,558
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56887
Policy Entropy: 3.76053
Value Function Loss: 0.30092
Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.63516
Value Function Update Magnitude: 0.70902
Collected Steps per Second: 12,492.93368
Overall Steps per Second: 6,878.62849
Timestep Collection Time: 4.00226
Timestep Consumption Time: 3.26663
PPO Batch Consumption Time: 0.23861
Total Iteration Time: 7.26889
Cumulative Model Updates: 5,046
Cumulative Timesteps: 28,112,558
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 28112558...
Checkpoint 28112558 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.28111
Policy Entropy: 3.75805
Value Function Loss: 0.30542
Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.62785
Value Function Update Magnitude: 0.67365
Collected Steps per Second: 12,262.80733
Overall Steps per Second: 6,925.65554
Timestep Collection Time: 4.07982
Timestep Consumption Time: 3.14405
PPO Batch Consumption Time: 0.23821
Total Iteration Time: 7.22386
Cumulative Model Updates: 5,055
Cumulative Timesteps: 28,162,588
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.36152
Policy Entropy: 3.75718
Value Function Loss: 0.30683
Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.62985
Value Function Update Magnitude: 0.65900
Collected Steps per Second: 11,464.00208
Overall Steps per Second: 6,349.70524
Timestep Collection Time: 4.36200
Timestep Consumption Time: 3.51332
PPO Batch Consumption Time: 0.25674
Total Iteration Time: 7.87533
Cumulative Model Updates: 5,064
Cumulative Timesteps: 28,212,594
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 28212594...
Checkpoint 28212594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.92016
Policy Entropy: 3.75828
Value Function Loss: 0.31823
Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.65699
Value Function Update Magnitude: 0.69780
Collected Steps per Second: 11,131.08470
Overall Steps per Second: 6,452.77556
Timestep Collection Time: 4.49516
Timestep Consumption Time: 3.25902
PPO Batch Consumption Time: 0.23823
Total Iteration Time: 7.75418
Cumulative Model Updates: 5,073
Cumulative Timesteps: 28,262,630
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76784
Policy Entropy: 3.75664
Value Function Loss: 0.31104
Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.66709
Value Function Update Magnitude: 0.68629
Collected Steps per Second: 12,451.66392
Overall Steps per Second: 6,971.58462
Timestep Collection Time: 4.01713
Timestep Consumption Time: 3.15771
PPO Batch Consumption Time: 0.23777
Total Iteration Time: 7.17484
Cumulative Model Updates: 5,082
Cumulative Timesteps: 28,312,650
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 28312650...
Checkpoint 28312650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49955
Policy Entropy: 3.75331
Value Function Loss: 0.30126
Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.66096
Value Function Update Magnitude: 0.72497
Collected Steps per Second: 12,414.01807
Overall Steps per Second: 6,784.89464
Timestep Collection Time: 4.02996
Timestep Consumption Time: 3.34348
PPO Batch Consumption Time: 0.24563
Total Iteration Time: 7.37344
Cumulative Model Updates: 5,091
Cumulative Timesteps: 28,362,678
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.48865
Policy Entropy: 3.75739
Value Function Loss: 0.31133
Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.67090
Value Function Update Magnitude: 0.73395
Collected Steps per Second: 11,921.60056
Overall Steps per Second: 6,754.89345
Timestep Collection Time: 4.19457
Timestep Consumption Time: 3.20836
PPO Batch Consumption Time: 0.24710
Total Iteration Time: 7.40293
Cumulative Model Updates: 5,100
Cumulative Timesteps: 28,412,684
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 28412684...
Checkpoint 28412684 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.08230
Policy Entropy: 3.75522
Value Function Loss: 0.31121
Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.67281
Value Function Update Magnitude: 0.66571
Collected Steps per Second: 11,992.05911
Overall Steps per Second: 6,644.92908
Timestep Collection Time: 4.17193
Timestep Consumption Time: 3.35712
PPO Batch Consumption Time: 0.25083
Total Iteration Time: 7.52905
Cumulative Model Updates: 5,109
Cumulative Timesteps: 28,462,714
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90399
Policy Entropy: 3.76033
Value Function Loss: 0.32080
Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.65952
Value Function Update Magnitude: 0.63407
Collected Steps per Second: 11,269.90104
Overall Steps per Second: 6,555.82229
Timestep Collection Time: 4.43802
Timestep Consumption Time: 3.19123
PPO Batch Consumption Time: 0.23794
Total Iteration Time: 7.62925
Cumulative Model Updates: 5,118
Cumulative Timesteps: 28,512,730
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 28512730...
Checkpoint 28512730 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64922
Policy Entropy: 3.75475
Value Function Loss: 0.31974
Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.65416
Value Function Update Magnitude: 0.66289
Collected Steps per Second: 12,403.10585
Overall Steps per Second: 6,989.43175
Timestep Collection Time: 4.03238
Timestep Consumption Time: 3.12328
PPO Batch Consumption Time: 0.23818
Total Iteration Time: 7.15566
Cumulative Model Updates: 5,127
Cumulative Timesteps: 28,562,744
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.40305
Policy Entropy: 3.75872
Value Function Loss: 0.31284
Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.65169
Value Function Update Magnitude: 0.65628
Collected Steps per Second: 12,558.01808
Overall Steps per Second: 6,921.60914
Timestep Collection Time: 3.98391
Timestep Consumption Time: 3.24418
PPO Batch Consumption Time: 0.23820
Total Iteration Time: 7.22809
Cumulative Model Updates: 5,136
Cumulative Timesteps: 28,612,774
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 28612774...
Checkpoint 28612774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52659
Policy Entropy: 3.75755
Value Function Loss: 0.31283
Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10530
Policy Update Magnitude: 0.65544
Value Function Update Magnitude: 0.66707
Collected Steps per Second: 12,329.51912
Overall Steps per Second: 6,884.86512
Timestep Collection Time: 4.05531
Timestep Consumption Time: 3.20700
PPO Batch Consumption Time: 0.23793
Total Iteration Time: 7.26231
Cumulative Model Updates: 5,145
Cumulative Timesteps: 28,662,774
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.08027
Policy Entropy: 3.75223
Value Function Loss: 0.31159
Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.65202
Value Function Update Magnitude: 0.65882
Collected Steps per Second: 12,676.15171
Overall Steps per Second: 6,879.20600
Timestep Collection Time: 3.94757
Timestep Consumption Time: 3.32652
PPO Batch Consumption Time: 0.24591
Total Iteration Time: 7.27410
Cumulative Model Updates: 5,154
Cumulative Timesteps: 28,712,814
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 28712814...
Checkpoint 28712814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.53331
Policy Entropy: 3.74289
Value Function Loss: 0.31061
Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.64588
Value Function Update Magnitude: 0.66786
Collected Steps per Second: 12,439.44209
Overall Steps per Second: 6,894.46377
Timestep Collection Time: 4.02381
Timestep Consumption Time: 3.23621
PPO Batch Consumption Time: 0.23763
Total Iteration Time: 7.26003
Cumulative Model Updates: 5,163
Cumulative Timesteps: 28,762,868
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.27507
Policy Entropy: 3.74757
Value Function Loss: 0.30962
Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.64192
Value Function Update Magnitude: 0.66522
Collected Steps per Second: 12,462.42209
Overall Steps per Second: 7,036.52270
Timestep Collection Time: 4.01655
Timestep Consumption Time: 3.09719
PPO Batch Consumption Time: 0.23761
Total Iteration Time: 7.11374
Cumulative Model Updates: 5,172
Cumulative Timesteps: 28,812,924
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 28812924...
Checkpoint 28812924 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.76294
Policy Entropy: 3.74466
Value Function Loss: 0.31218
Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.64401
Value Function Update Magnitude: 0.66052
Collected Steps per Second: 12,461.10360
Overall Steps per Second: 6,883.42546
Timestep Collection Time: 4.01249
Timestep Consumption Time: 3.25134
PPO Batch Consumption Time: 0.23813
Total Iteration Time: 7.26383
Cumulative Model Updates: 5,181
Cumulative Timesteps: 28,862,924
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77973
Policy Entropy: 3.74584
Value Function Loss: 0.31244
Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11383
Policy Update Magnitude: 0.65270
Value Function Update Magnitude: 0.65310
Collected Steps per Second: 12,406.61531
Overall Steps per Second: 6,903.37399
Timestep Collection Time: 4.03269
Timestep Consumption Time: 3.21478
PPO Batch Consumption Time: 0.23790
Total Iteration Time: 7.24747
Cumulative Model Updates: 5,190
Cumulative Timesteps: 28,912,956
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 28912956...
Checkpoint 28912956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.87592
Policy Entropy: 3.74591
Value Function Loss: 0.31831
Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.65700
Value Function Update Magnitude: 0.67279
Collected Steps per Second: 12,512.63088
Overall Steps per Second: 7,014.93714
Timestep Collection Time: 3.99804
Timestep Consumption Time: 3.13331
PPO Batch Consumption Time: 0.23837
Total Iteration Time: 7.13135
Cumulative Model Updates: 5,199
Cumulative Timesteps: 28,962,982
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.37419
Policy Entropy: 3.75144
Value Function Loss: 0.32079
Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10829
Policy Update Magnitude: 0.66378
Value Function Update Magnitude: 0.69257
Collected Steps per Second: 12,492.71787
Overall Steps per Second: 6,923.65481
Timestep Collection Time: 4.00329
Timestep Consumption Time: 3.22006
PPO Batch Consumption Time: 0.23784
Total Iteration Time: 7.22335
Cumulative Model Updates: 5,208
Cumulative Timesteps: 29,012,994
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 29012994...
Checkpoint 29012994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71441
Policy Entropy: 3.74234
Value Function Loss: 0.31590
Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.65910
Value Function Update Magnitude: 0.68903
Collected Steps per Second: 12,341.59794
Overall Steps per Second: 6,756.88138
Timestep Collection Time: 4.05183
Timestep Consumption Time: 3.34893
PPO Batch Consumption Time: 0.24882
Total Iteration Time: 7.40075
Cumulative Model Updates: 5,217
Cumulative Timesteps: 29,063,000
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23921
Policy Entropy: 3.73500
Value Function Loss: 0.31066
Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.64820
Value Function Update Magnitude: 0.67355
Collected Steps per Second: 12,649.41019
Overall Steps per Second: 6,916.71434
Timestep Collection Time: 3.95323
Timestep Consumption Time: 3.27651
PPO Batch Consumption Time: 0.23867
Total Iteration Time: 7.22973
Cumulative Model Updates: 5,226
Cumulative Timesteps: 29,113,006
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 29113006...
Checkpoint 29113006 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.44091
Policy Entropy: 3.73677
Value Function Loss: 0.30868
Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.63663
Value Function Update Magnitude: 0.64165
Collected Steps per Second: 12,401.99338
Overall Steps per Second: 6,868.33623
Timestep Collection Time: 4.03322
Timestep Consumption Time: 3.24947
PPO Batch Consumption Time: 0.23838
Total Iteration Time: 7.28270
Cumulative Model Updates: 5,235
Cumulative Timesteps: 29,163,026
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.25887
Policy Entropy: 3.73168
Value Function Loss: 0.31331
Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14871
Policy Update Magnitude: 0.63402
Value Function Update Magnitude: 0.64726
Collected Steps per Second: 12,443.31998
Overall Steps per Second: 6,989.72230
Timestep Collection Time: 4.02143
Timestep Consumption Time: 3.13765
PPO Batch Consumption Time: 0.23841
Total Iteration Time: 7.15908
Cumulative Model Updates: 5,244
Cumulative Timesteps: 29,213,066
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 29213066...
Checkpoint 29213066 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.47283
Policy Entropy: 3.73029
Value Function Loss: 0.31185
Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15902
Policy Update Magnitude: 0.63350
Value Function Update Magnitude: 0.69676
Collected Steps per Second: 12,480.24529
Overall Steps per Second: 6,903.31038
Timestep Collection Time: 4.00809
Timestep Consumption Time: 3.23799
PPO Batch Consumption Time: 0.23757
Total Iteration Time: 7.24609
Cumulative Model Updates: 5,253
Cumulative Timesteps: 29,263,088
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79198
Policy Entropy: 3.72122
Value Function Loss: 0.31546
Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.63086
Value Function Update Magnitude: 0.73200
Collected Steps per Second: 12,363.84851
Overall Steps per Second: 6,917.73014
Timestep Collection Time: 4.04599
Timestep Consumption Time: 3.18528
PPO Batch Consumption Time: 0.23774
Total Iteration Time: 7.23127
Cumulative Model Updates: 5,262
Cumulative Timesteps: 29,313,112
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 29313112...
Checkpoint 29313112 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.77597
Policy Entropy: 3.73433
Value Function Loss: 0.31480
Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.64182
Value Function Update Magnitude: 0.88179
Collected Steps per Second: 12,676.79604
Overall Steps per Second: 6,967.63843
Timestep Collection Time: 3.94563
Timestep Consumption Time: 3.23298
PPO Batch Consumption Time: 0.23820
Total Iteration Time: 7.17862
Cumulative Model Updates: 5,271
Cumulative Timesteps: 29,363,130
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.59893
Policy Entropy: 3.72962
Value Function Loss: 0.31835
Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11446
Policy Update Magnitude: 0.64990
Value Function Update Magnitude: 0.80268
Collected Steps per Second: 12,527.11317
Overall Steps per Second: 6,865.42648
Timestep Collection Time: 3.99294
Timestep Consumption Time: 3.29284
PPO Batch Consumption Time: 0.23924
Total Iteration Time: 7.28578
Cumulative Model Updates: 5,280
Cumulative Timesteps: 29,413,150
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 29413150...
Checkpoint 29413150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.87412
Policy Entropy: 3.72997
Value Function Loss: 0.30977
Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12852
Policy Update Magnitude: 0.63879
Value Function Update Magnitude: 0.74937
Collected Steps per Second: 12,482.87392
Overall Steps per Second: 6,916.09907
Timestep Collection Time: 4.00741
Timestep Consumption Time: 3.22557
PPO Batch Consumption Time: 0.23859
Total Iteration Time: 7.23298
Cumulative Model Updates: 5,289
Cumulative Timesteps: 29,463,174
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.21566
Policy Entropy: 3.72833
Value Function Loss: 0.31215
Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.62539
Value Function Update Magnitude: 0.71224
Collected Steps per Second: 12,782.04071
Overall Steps per Second: 7,000.68279
Timestep Collection Time: 3.91502
Timestep Consumption Time: 3.23314
PPO Batch Consumption Time: 0.23796
Total Iteration Time: 7.14816
Cumulative Model Updates: 5,298
Cumulative Timesteps: 29,513,216
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 29513216...
Checkpoint 29513216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.07846
Policy Entropy: 3.73034
Value Function Loss: 0.30439
Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.62899
Value Function Update Magnitude: 0.66379
Collected Steps per Second: 12,524.84665
Overall Steps per Second: 6,904.13422
Timestep Collection Time: 3.99430
Timestep Consumption Time: 3.25179
PPO Batch Consumption Time: 0.23838
Total Iteration Time: 7.24609
Cumulative Model Updates: 5,307
Cumulative Timesteps: 29,563,244
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.20926
Policy Entropy: 3.73288
Value Function Loss: 0.31698
Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.64058
Value Function Update Magnitude: 0.66741
Collected Steps per Second: 12,480.90022
Overall Steps per Second: 7,019.54598
Timestep Collection Time: 4.00869
Timestep Consumption Time: 3.11884
PPO Batch Consumption Time: 0.23796
Total Iteration Time: 7.12753
Cumulative Model Updates: 5,316
Cumulative Timesteps: 29,613,276
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 29613276...
Checkpoint 29613276 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71438
Policy Entropy: 3.73370
Value Function Loss: 0.31442
Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.64648
Value Function Update Magnitude: 0.68423
Collected Steps per Second: 12,579.95705
Overall Steps per Second: 6,948.56332
Timestep Collection Time: 3.97521
Timestep Consumption Time: 3.22167
PPO Batch Consumption Time: 0.23797
Total Iteration Time: 7.19688
Cumulative Model Updates: 5,325
Cumulative Timesteps: 29,663,284
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.41742
Policy Entropy: 3.73726
Value Function Loss: 0.31751
Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.64562
Value Function Update Magnitude: 0.69669
Collected Steps per Second: 12,502.96226
Overall Steps per Second: 6,946.67471
Timestep Collection Time: 3.99905
Timestep Consumption Time: 3.19864
PPO Batch Consumption Time: 0.23752
Total Iteration Time: 7.19769
Cumulative Model Updates: 5,334
Cumulative Timesteps: 29,713,284
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 29713284...
Checkpoint 29713284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93826
Policy Entropy: 3.73505
Value Function Loss: 0.31651
Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.64024
Value Function Update Magnitude: 0.70257
Collected Steps per Second: 12,604.47495
Overall Steps per Second: 6,896.10778
Timestep Collection Time: 3.97002
Timestep Consumption Time: 3.28625
PPO Batch Consumption Time: 0.23987
Total Iteration Time: 7.25627
Cumulative Model Updates: 5,343
Cumulative Timesteps: 29,763,324
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.02321
Policy Entropy: 3.72751
Value Function Loss: 0.31689
Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.65583
Value Function Update Magnitude: 0.66891
Collected Steps per Second: 12,324.62590
Overall Steps per Second: 6,765.95110
Timestep Collection Time: 4.05951
Timestep Consumption Time: 3.33516
PPO Batch Consumption Time: 0.24710
Total Iteration Time: 7.39467
Cumulative Model Updates: 5,352
Cumulative Timesteps: 29,813,356
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 29813356...
Checkpoint 29813356 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.14280
Policy Entropy: 3.72087
Value Function Loss: 0.31896
Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.66304
Value Function Update Magnitude: 0.65846
Collected Steps per Second: 10,486.69250
Overall Steps per Second: 6,100.33035
Timestep Collection Time: 4.77043
Timestep Consumption Time: 3.43011
PPO Batch Consumption Time: 0.24700
Total Iteration Time: 8.20054
Cumulative Model Updates: 5,361
Cumulative Timesteps: 29,863,382
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.47104
Policy Entropy: 3.71412
Value Function Loss: 0.30739
Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.64691
Value Function Update Magnitude: 0.69001
Collected Steps per Second: 11,534.72396
Overall Steps per Second: 6,564.81274
Timestep Collection Time: 4.33734
Timestep Consumption Time: 3.28359
PPO Batch Consumption Time: 0.23845
Total Iteration Time: 7.62093
Cumulative Model Updates: 5,370
Cumulative Timesteps: 29,913,412
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 29913412...
Checkpoint 29913412 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.50132
Policy Entropy: 3.71161
Value Function Loss: 0.31613
Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.66210
Value Function Update Magnitude: 0.67672
Collected Steps per Second: 12,284.33224
Overall Steps per Second: 6,805.11757
Timestep Collection Time: 4.07185
Timestep Consumption Time: 3.27850
PPO Batch Consumption Time: 0.24155
Total Iteration Time: 7.35035
Cumulative Model Updates: 5,379
Cumulative Timesteps: 29,963,432
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.20037
Policy Entropy: 3.71137
Value Function Loss: 0.30162
Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.67316
Value Function Update Magnitude: 0.68248
Collected Steps per Second: 12,128.49603
Overall Steps per Second: 6,836.98156
Timestep Collection Time: 4.12582
Timestep Consumption Time: 3.19320
PPO Batch Consumption Time: 0.24327
Total Iteration Time: 7.31902
Cumulative Model Updates: 5,388
Cumulative Timesteps: 30,013,472
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 30013472...
Checkpoint 30013472 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.99882
Policy Entropy: 3.70740
Value Function Loss: 0.31217
Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.65532
Value Function Update Magnitude: 0.66251
Collected Steps per Second: 11,592.26182
Overall Steps per Second: 6,320.56602
Timestep Collection Time: 4.31495
Timestep Consumption Time: 3.59890
PPO Batch Consumption Time: 0.26046
Total Iteration Time: 7.91385
Cumulative Model Updates: 5,397
Cumulative Timesteps: 30,063,492
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.69870
Policy Entropy: 3.71583
Value Function Loss: 0.30081
Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.66519
Value Function Update Magnitude: 0.65323
Collected Steps per Second: 11,802.50639
Overall Steps per Second: 6,642.74843
Timestep Collection Time: 4.23639
Timestep Consumption Time: 3.29062
PPO Batch Consumption Time: 0.24661
Total Iteration Time: 7.52700
Cumulative Model Updates: 5,406
Cumulative Timesteps: 30,113,492
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 30113492...
Checkpoint 30113492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.44287
Policy Entropy: 3.71913
Value Function Loss: 0.30059
Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.66132
Value Function Update Magnitude: 0.65389
Collected Steps per Second: 11,444.79104
Overall Steps per Second: 6,473.57690
Timestep Collection Time: 4.37072
Timestep Consumption Time: 3.35638
PPO Batch Consumption Time: 0.24428
Total Iteration Time: 7.72710
Cumulative Model Updates: 5,415
Cumulative Timesteps: 30,163,514
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50822
Policy Entropy: 3.71853
Value Function Loss: 0.30680
Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.65688
Value Function Update Magnitude: 0.65264
Collected Steps per Second: 11,766.15676
Overall Steps per Second: 6,546.53991
Timestep Collection Time: 4.25220
Timestep Consumption Time: 3.39031
PPO Batch Consumption Time: 0.24797
Total Iteration Time: 7.64251
Cumulative Model Updates: 5,424
Cumulative Timesteps: 30,213,546
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 30213546...
Checkpoint 30213546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.52743
Policy Entropy: 3.71348
Value Function Loss: 0.30383
Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.66377
Value Function Update Magnitude: 0.66038
Collected Steps per Second: 11,617.37423
Overall Steps per Second: 6,584.68588
Timestep Collection Time: 4.30562
Timestep Consumption Time: 3.29079
PPO Batch Consumption Time: 0.24706
Total Iteration Time: 7.59641
Cumulative Model Updates: 5,433
Cumulative Timesteps: 30,263,566
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77654
Policy Entropy: 3.71082
Value Function Loss: 0.32217
Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.66590
Value Function Update Magnitude: 0.68983
Collected Steps per Second: 12,260.23805
Overall Steps per Second: 6,757.51835
Timestep Collection Time: 4.07969
Timestep Consumption Time: 3.32214
PPO Batch Consumption Time: 0.24673
Total Iteration Time: 7.40183
Cumulative Model Updates: 5,442
Cumulative Timesteps: 30,313,584
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 30313584...
Checkpoint 30313584 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.05448
Policy Entropy: 3.70991
Value Function Loss: 0.31660
Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.66327
Value Function Update Magnitude: 0.70541
Collected Steps per Second: 11,878.40660
Overall Steps per Second: 6,593.72821
Timestep Collection Time: 4.20982
Timestep Consumption Time: 3.37405
PPO Batch Consumption Time: 0.24870
Total Iteration Time: 7.58387
Cumulative Model Updates: 5,451
Cumulative Timesteps: 30,363,590
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40705
Policy Entropy: 3.71257
Value Function Loss: 0.31634
Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.66159
Value Function Update Magnitude: 0.68970
Collected Steps per Second: 11,790.64845
Overall Steps per Second: 6,709.69962
Timestep Collection Time: 4.24218
Timestep Consumption Time: 3.21241
PPO Batch Consumption Time: 0.24650
Total Iteration Time: 7.45458
Cumulative Model Updates: 5,460
Cumulative Timesteps: 30,413,608
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 30413608...
Checkpoint 30413608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22125
Policy Entropy: 3.71732
Value Function Loss: 0.30410
Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.65554
Value Function Update Magnitude: 0.69633
Collected Steps per Second: 11,832.47639
Overall Steps per Second: 6,624.61088
Timestep Collection Time: 4.22870
Timestep Consumption Time: 3.32435
PPO Batch Consumption Time: 0.24705
Total Iteration Time: 7.55305
Cumulative Model Updates: 5,469
Cumulative Timesteps: 30,463,644
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.82186
Policy Entropy: 3.71854
Value Function Loss: 0.31275
Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.65051
Value Function Update Magnitude: 0.68504
Collected Steps per Second: 11,945.63404
Overall Steps per Second: 6,659.07259
Timestep Collection Time: 4.18730
Timestep Consumption Time: 3.32425
PPO Batch Consumption Time: 0.24647
Total Iteration Time: 7.51156
Cumulative Model Updates: 5,478
Cumulative Timesteps: 30,513,664
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 30513664...
Checkpoint 30513664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.55400
Policy Entropy: 3.70923
Value Function Loss: 0.30908
Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.64373
Value Function Update Magnitude: 0.64505
Collected Steps per Second: 11,985.80367
Overall Steps per Second: 6,664.12543
Timestep Collection Time: 4.17294
Timestep Consumption Time: 3.33232
PPO Batch Consumption Time: 0.24721
Total Iteration Time: 7.50526
Cumulative Model Updates: 5,487
Cumulative Timesteps: 30,563,680
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93771
Policy Entropy: 3.70557
Value Function Loss: 0.31213
Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.64674
Value Function Update Magnitude: 0.64761
Collected Steps per Second: 11,986.59712
Overall Steps per Second: 6,654.56020
Timestep Collection Time: 4.17149
Timestep Consumption Time: 3.34245
PPO Batch Consumption Time: 0.24709
Total Iteration Time: 7.51395
Cumulative Model Updates: 5,496
Cumulative Timesteps: 30,613,682
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 30613682...
Checkpoint 30613682 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.77272
Policy Entropy: 3.70942
Value Function Loss: 0.30711
Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.64984
Value Function Update Magnitude: 0.67489
Collected Steps per Second: 11,838.59291
Overall Steps per Second: 6,581.12857
Timestep Collection Time: 4.22652
Timestep Consumption Time: 3.37644
PPO Batch Consumption Time: 0.25853
Total Iteration Time: 7.60295
Cumulative Model Updates: 5,505
Cumulative Timesteps: 30,663,718
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01950
Policy Entropy: 3.71706
Value Function Loss: 0.31894
Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.65196
Value Function Update Magnitude: 0.63835
Collected Steps per Second: 12,049.12047
Overall Steps per Second: 6,683.46903
Timestep Collection Time: 4.15200
Timestep Consumption Time: 3.33333
PPO Batch Consumption Time: 0.24716
Total Iteration Time: 7.48533
Cumulative Model Updates: 5,514
Cumulative Timesteps: 30,713,746
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 30713746...
Checkpoint 30713746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06031
Policy Entropy: 3.71114
Value Function Loss: 0.33900
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.66204
Value Function Update Magnitude: 0.67009
Collected Steps per Second: 11,891.11113
Overall Steps per Second: 6,630.28298
Timestep Collection Time: 4.20533
Timestep Consumption Time: 3.33674
PPO Batch Consumption Time: 0.25083
Total Iteration Time: 7.54206
Cumulative Model Updates: 5,523
Cumulative Timesteps: 30,763,752
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56218
Policy Entropy: 3.71494
Value Function Loss: 0.33629
Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.66480
Value Function Update Magnitude: 0.69198
Collected Steps per Second: 11,042.70083
Overall Steps per Second: 6,459.09231
Timestep Collection Time: 4.53023
Timestep Consumption Time: 3.21482
PPO Batch Consumption Time: 0.24204
Total Iteration Time: 7.74505
Cumulative Model Updates: 5,532
Cumulative Timesteps: 30,813,778
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 30813778...
Checkpoint 30813778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.16718
Policy Entropy: 3.71987
Value Function Loss: 0.31579
Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.15193
Policy Update Magnitude: 0.64524
Value Function Update Magnitude: 0.75370
Collected Steps per Second: 12,398.76541
Overall Steps per Second: 6,821.52854
Timestep Collection Time: 4.03589
Timestep Consumption Time: 3.29971
PPO Batch Consumption Time: 0.24356
Total Iteration Time: 7.33560
Cumulative Model Updates: 5,541
Cumulative Timesteps: 30,863,818
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.25168
Policy Entropy: 3.72746
Value Function Loss: 0.29000
Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.17056
Policy Update Magnitude: 0.61875
Value Function Update Magnitude: 0.68916
Collected Steps per Second: 12,326.24655
Overall Steps per Second: 6,846.04018
Timestep Collection Time: 4.06028
Timestep Consumption Time: 3.25022
PPO Batch Consumption Time: 0.24219
Total Iteration Time: 7.31050
Cumulative Model Updates: 5,550
Cumulative Timesteps: 30,913,866
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 30913866...
Checkpoint 30913866 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.43697
Policy Entropy: 3.72717
Value Function Loss: 0.28869
Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.61510
Value Function Update Magnitude: 0.63812
Collected Steps per Second: 12,592.83288
Overall Steps per Second: 6,853.65835
Timestep Collection Time: 3.97305
Timestep Consumption Time: 3.32699
PPO Batch Consumption Time: 0.24341
Total Iteration Time: 7.30004
Cumulative Model Updates: 5,559
Cumulative Timesteps: 30,963,898
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.93099
Policy Entropy: 3.72178
Value Function Loss: 0.29817
Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.62056
Value Function Update Magnitude: 0.64689
Collected Steps per Second: 12,358.15343
Overall Steps per Second: 6,811.53727
Timestep Collection Time: 4.04769
Timestep Consumption Time: 3.29602
PPO Batch Consumption Time: 0.24213
Total Iteration Time: 7.34372
Cumulative Model Updates: 5,568
Cumulative Timesteps: 31,013,920
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 31013920...
Checkpoint 31013920 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.50778
Policy Entropy: 3.72561
Value Function Loss: 0.29576
Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12088
Policy Update Magnitude: 0.62572
Value Function Update Magnitude: 0.70054
Collected Steps per Second: 12,275.36425
Overall Steps per Second: 6,925.47418
Timestep Collection Time: 4.07385
Timestep Consumption Time: 3.14703
PPO Batch Consumption Time: 0.24204
Total Iteration Time: 7.22088
Cumulative Model Updates: 5,577
Cumulative Timesteps: 31,063,928
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.55447
Policy Entropy: 3.73105
Value Function Loss: 0.29520
Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.62659
Value Function Update Magnitude: 0.71044
Collected Steps per Second: 12,208.08794
Overall Steps per Second: 6,791.81541
Timestep Collection Time: 4.09778
Timestep Consumption Time: 3.26785
PPO Batch Consumption Time: 0.24184
Total Iteration Time: 7.36563
Cumulative Model Updates: 5,586
Cumulative Timesteps: 31,113,954
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 31113954...
Checkpoint 31113954 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.13171
Policy Entropy: 3.73337
Value Function Loss: 0.30202
Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.63077
Value Function Update Magnitude: 0.70919
Collected Steps per Second: 12,066.76464
Overall Steps per Second: 6,773.42029
Timestep Collection Time: 4.14709
Timestep Consumption Time: 3.24090
PPO Batch Consumption Time: 0.24227
Total Iteration Time: 7.38800
Cumulative Model Updates: 5,595
Cumulative Timesteps: 31,163,996
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.92146
Policy Entropy: 3.73129
Value Function Loss: 0.32927
Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.64437
Value Function Update Magnitude: 0.74779
Collected Steps per Second: 12,517.96526
Overall Steps per Second: 6,853.85463
Timestep Collection Time: 3.99570
Timestep Consumption Time: 3.30209
PPO Batch Consumption Time: 0.24425
Total Iteration Time: 7.29779
Cumulative Model Updates: 5,604
Cumulative Timesteps: 31,214,014
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 31214014...
Checkpoint 31214014 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.25168
Policy Entropy: 3.72381
Value Function Loss: 0.31070
Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.64783
Value Function Update Magnitude: 0.76897
Collected Steps per Second: 12,268.03455
Overall Steps per Second: 6,801.06233
Timestep Collection Time: 4.07645
Timestep Consumption Time: 3.27682
PPO Batch Consumption Time: 0.24232
Total Iteration Time: 7.35326
Cumulative Model Updates: 5,613
Cumulative Timesteps: 31,264,024
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.62759
Policy Entropy: 3.72587
Value Function Loss: 0.29965
Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.63966
Value Function Update Magnitude: 0.78194
Collected Steps per Second: 12,114.07946
Overall Steps per Second: 6,789.32557
Timestep Collection Time: 4.13106
Timestep Consumption Time: 3.23992
PPO Batch Consumption Time: 0.24430
Total Iteration Time: 7.37098
Cumulative Model Updates: 5,622
Cumulative Timesteps: 31,314,068
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 31314068...
Checkpoint 31314068 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01634
Policy Entropy: 3.72741
Value Function Loss: 0.28362
Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.64226
Value Function Update Magnitude: 0.76103
Collected Steps per Second: 12,326.11796
Overall Steps per Second: 6,829.28907
Timestep Collection Time: 4.05902
Timestep Consumption Time: 3.26707
PPO Batch Consumption Time: 0.24190
Total Iteration Time: 7.32609
Cumulative Model Updates: 5,631
Cumulative Timesteps: 31,364,100
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97322
Policy Entropy: 3.73018
Value Function Loss: 0.28596
Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.11125
Policy Update Magnitude: 0.63543
Value Function Update Magnitude: 0.72519
Collected Steps per Second: 12,326.20130
Overall Steps per Second: 6,838.36059
Timestep Collection Time: 4.05883
Timestep Consumption Time: 3.25725
PPO Batch Consumption Time: 0.24243
Total Iteration Time: 7.31608
Cumulative Model Updates: 5,640
Cumulative Timesteps: 31,414,130
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 31414130...
Checkpoint 31414130 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.81431
Policy Entropy: 3.72886
Value Function Loss: 0.28599
Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.63755
Value Function Update Magnitude: 0.70417
Collected Steps per Second: 12,249.36235
Overall Steps per Second: 6,905.36404
Timestep Collection Time: 4.08201
Timestep Consumption Time: 3.15903
PPO Batch Consumption Time: 0.24186
Total Iteration Time: 7.24104
Cumulative Model Updates: 5,649
Cumulative Timesteps: 31,464,132
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21777
Policy Entropy: 3.73099
Value Function Loss: 0.28396
Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.62676
Value Function Update Magnitude: 0.73064
Collected Steps per Second: 12,336.10222
Overall Steps per Second: 6,820.86448
Timestep Collection Time: 4.05752
Timestep Consumption Time: 3.28084
PPO Batch Consumption Time: 0.24244
Total Iteration Time: 7.33837
Cumulative Model Updates: 5,658
Cumulative Timesteps: 31,514,186
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 31514186...
Checkpoint 31514186 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99212
Policy Entropy: 3.72330
Value Function Loss: 0.27944
Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.62445
Value Function Update Magnitude: 0.70284
Collected Steps per Second: 12,273.99747
Overall Steps per Second: 6,846.95953
Timestep Collection Time: 4.07626
Timestep Consumption Time: 3.23093
PPO Batch Consumption Time: 0.24195
Total Iteration Time: 7.30718
Cumulative Model Updates: 5,667
Cumulative Timesteps: 31,564,218
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.40030
Policy Entropy: 3.72274
Value Function Loss: 0.27417
Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.62396
Value Function Update Magnitude: 0.67355
Collected Steps per Second: 12,617.36909
Overall Steps per Second: 6,917.28573
Timestep Collection Time: 3.96327
Timestep Consumption Time: 3.26587
PPO Batch Consumption Time: 0.24172
Total Iteration Time: 7.22914
Cumulative Model Updates: 5,676
Cumulative Timesteps: 31,614,224
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 31614224...
Checkpoint 31614224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.45171
Policy Entropy: 3.72268
Value Function Loss: 0.27350
Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.61546
Value Function Update Magnitude: 0.65218
Collected Steps per Second: 12,355.72645
Overall Steps per Second: 6,791.33357
Timestep Collection Time: 4.04833
Timestep Consumption Time: 3.31694
PPO Batch Consumption Time: 0.24342
Total Iteration Time: 7.36527
Cumulative Model Updates: 5,685
Cumulative Timesteps: 31,664,244
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.97776
Policy Entropy: 3.71847
Value Function Loss: 0.28010
Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.62549
Value Function Update Magnitude: 0.70152
Collected Steps per Second: 12,223.51220
Overall Steps per Second: 6,868.08424
Timestep Collection Time: 4.09162
Timestep Consumption Time: 3.19047
PPO Batch Consumption Time: 0.24251
Total Iteration Time: 7.28209
Cumulative Model Updates: 5,694
Cumulative Timesteps: 31,714,258
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 31714258...
Checkpoint 31714258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.53568
Policy Entropy: 3.71598
Value Function Loss: 0.28045
Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.62440
Value Function Update Magnitude: 0.68905
Collected Steps per Second: 12,265.74228
Overall Steps per Second: 6,793.92973
Timestep Collection Time: 4.07656
Timestep Consumption Time: 3.28325
PPO Batch Consumption Time: 0.24281
Total Iteration Time: 7.35981
Cumulative Model Updates: 5,703
Cumulative Timesteps: 31,764,260
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.69422
Policy Entropy: 3.72426
Value Function Loss: 0.28542
Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.62454
Value Function Update Magnitude: 0.66755
Collected Steps per Second: 12,258.48382
Overall Steps per Second: 6,803.76022
Timestep Collection Time: 4.07897
Timestep Consumption Time: 3.27020
PPO Batch Consumption Time: 0.24223
Total Iteration Time: 7.34917
Cumulative Model Updates: 5,712
Cumulative Timesteps: 31,814,262
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 31814262...
Checkpoint 31814262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.65411
Policy Entropy: 3.71829
Value Function Loss: 0.27797
Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.62807
Value Function Update Magnitude: 0.66662
Collected Steps per Second: 12,485.40721
Overall Steps per Second: 6,821.24844
Timestep Collection Time: 4.00532
Timestep Consumption Time: 3.32589
PPO Batch Consumption Time: 0.24388
Total Iteration Time: 7.33121
Cumulative Model Updates: 5,721
Cumulative Timesteps: 31,864,270
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.23469
Policy Entropy: 3.72364
Value Function Loss: 0.28594
Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.63481
Value Function Update Magnitude: 0.66547
Collected Steps per Second: 12,192.48948
Overall Steps per Second: 6,775.08235
Timestep Collection Time: 4.10121
Timestep Consumption Time: 3.27936
PPO Batch Consumption Time: 0.24231
Total Iteration Time: 7.38057
Cumulative Model Updates: 5,730
Cumulative Timesteps: 31,914,274
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 31914274...
Checkpoint 31914274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.15836
Policy Entropy: 3.71660
Value Function Loss: 0.29257
Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.63688
Value Function Update Magnitude: 0.70367
Collected Steps per Second: 12,249.74359
Overall Steps per Second: 6,842.89320
Timestep Collection Time: 4.08270
Timestep Consumption Time: 3.22591
PPO Batch Consumption Time: 0.24336
Total Iteration Time: 7.30860
Cumulative Model Updates: 5,739
Cumulative Timesteps: 31,964,286
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.64235
Policy Entropy: 3.71587
Value Function Loss: 0.29758
Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.64171
Value Function Update Magnitude: 0.68731
Collected Steps per Second: 12,350.45056
Overall Steps per Second: 6,833.04811
Timestep Collection Time: 4.04844
Timestep Consumption Time: 3.26894
PPO Batch Consumption Time: 0.24203
Total Iteration Time: 7.31738
Cumulative Model Updates: 5,748
Cumulative Timesteps: 32,014,286
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 32014286...
Checkpoint 32014286 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.77382
Policy Entropy: 3.71203
Value Function Loss: 0.29697
Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.64346
Value Function Update Magnitude: 0.69412
Collected Steps per Second: 12,330.42279
Overall Steps per Second: 6,835.56897
Timestep Collection Time: 4.05696
Timestep Consumption Time: 3.26123
PPO Batch Consumption Time: 0.24420
Total Iteration Time: 7.31819
Cumulative Model Updates: 5,757
Cumulative Timesteps: 32,064,310
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.21508
Policy Entropy: 3.71860
Value Function Loss: 0.29319
Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.64685
Value Function Update Magnitude: 0.74808
Collected Steps per Second: 11,525.00247
Overall Steps per Second: 6,622.23587
Timestep Collection Time: 4.34100
Timestep Consumption Time: 3.21385
PPO Batch Consumption Time: 0.24621
Total Iteration Time: 7.55485
Cumulative Model Updates: 5,766
Cumulative Timesteps: 32,114,340
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 32114340...
Checkpoint 32114340 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.64257
Policy Entropy: 3.70973
Value Function Loss: 0.30293
Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.63813
Value Function Update Magnitude: 0.75565
Collected Steps per Second: 12,189.73203
Overall Steps per Second: 6,784.31150
Timestep Collection Time: 4.10296
Timestep Consumption Time: 3.26905
PPO Batch Consumption Time: 0.24278
Total Iteration Time: 7.37201
Cumulative Model Updates: 5,775
Cumulative Timesteps: 32,164,354
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.92137
Policy Entropy: 3.71367
Value Function Loss: 0.30652
Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.63770
Value Function Update Magnitude: 0.73649
Collected Steps per Second: 12,298.35794
Overall Steps per Second: 6,827.43347
Timestep Collection Time: 4.06900
Timestep Consumption Time: 3.26055
PPO Batch Consumption Time: 0.24298
Total Iteration Time: 7.32955
Cumulative Model Updates: 5,784
Cumulative Timesteps: 32,214,396
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 32214396...
Checkpoint 32214396 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.44786
Policy Entropy: 3.71026
Value Function Loss: 0.29703
Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10798
Policy Update Magnitude: 0.63587
Value Function Update Magnitude: 0.71713
Collected Steps per Second: 12,473.67315
Overall Steps per Second: 6,870.03639
Timestep Collection Time: 4.01069
Timestep Consumption Time: 3.27137
PPO Batch Consumption Time: 0.24254
Total Iteration Time: 7.28206
Cumulative Model Updates: 5,793
Cumulative Timesteps: 32,264,424
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51797
Policy Entropy: 3.71676
Value Function Loss: 0.28220
Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.62806
Value Function Update Magnitude: 0.69650
Collected Steps per Second: 12,227.88412
Overall Steps per Second: 6,757.95338
Timestep Collection Time: 4.09180
Timestep Consumption Time: 3.31193
PPO Batch Consumption Time: 0.24286
Total Iteration Time: 7.40372
Cumulative Model Updates: 5,802
Cumulative Timesteps: 32,314,458
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 32314458...
Checkpoint 32314458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.64610
Policy Entropy: 3.71737
Value Function Loss: 0.29330
Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.62699
Value Function Update Magnitude: 0.71765
Collected Steps per Second: 12,368.18938
Overall Steps per Second: 6,908.88117
Timestep Collection Time: 4.04538
Timestep Consumption Time: 3.19661
PPO Batch Consumption Time: 0.24267
Total Iteration Time: 7.24198
Cumulative Model Updates: 5,811
Cumulative Timesteps: 32,364,492
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.04948
Policy Entropy: 3.72298
Value Function Loss: 0.31057
Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.63206
Value Function Update Magnitude: 0.76344
Collected Steps per Second: 12,168.09339
Overall Steps per Second: 6,776.30931
Timestep Collection Time: 4.11042
Timestep Consumption Time: 3.27059
PPO Batch Consumption Time: 0.24162
Total Iteration Time: 7.38101
Cumulative Model Updates: 5,820
Cumulative Timesteps: 32,414,508
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 32414508...
Checkpoint 32414508 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30812
Policy Entropy: 3.71845
Value Function Loss: 0.30931
Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.64227
Value Function Update Magnitude: 0.71721
Collected Steps per Second: 12,205.83044
Overall Steps per Second: 6,796.65318
Timestep Collection Time: 4.09739
Timestep Consumption Time: 3.26094
PPO Batch Consumption Time: 0.24322
Total Iteration Time: 7.35833
Cumulative Model Updates: 5,829
Cumulative Timesteps: 32,464,520
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.86420
Policy Entropy: 3.72145
Value Function Loss: 0.30092
Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.63861
Value Function Update Magnitude: 0.71484
Collected Steps per Second: 12,369.93686
Overall Steps per Second: 6,832.01240
Timestep Collection Time: 4.04497
Timestep Consumption Time: 3.27879
PPO Batch Consumption Time: 0.24216
Total Iteration Time: 7.32376
Cumulative Model Updates: 5,838
Cumulative Timesteps: 32,514,556
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 32514556...
Checkpoint 32514556 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99059
Policy Entropy: 3.71775
Value Function Loss: 0.28578
Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.62888
Value Function Update Magnitude: 0.68502
Collected Steps per Second: 12,226.07462
Overall Steps per Second: 6,777.58679
Timestep Collection Time: 4.09240
Timestep Consumption Time: 3.28987
PPO Batch Consumption Time: 0.24219
Total Iteration Time: 7.38227
Cumulative Model Updates: 5,847
Cumulative Timesteps: 32,564,590
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66393
Policy Entropy: 3.72393
Value Function Loss: 0.29102
Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11694
Policy Update Magnitude: 0.62436
Value Function Update Magnitude: 0.66379
Collected Steps per Second: 12,192.37973
Overall Steps per Second: 6,864.86537
Timestep Collection Time: 4.10207
Timestep Consumption Time: 3.18343
PPO Batch Consumption Time: 0.24271
Total Iteration Time: 7.28550
Cumulative Model Updates: 5,856
Cumulative Timesteps: 32,614,604
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 32614604...
Checkpoint 32614604 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.63335
Policy Entropy: 3.72861
Value Function Loss: 0.29842
Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.63397
Value Function Update Magnitude: 0.66419
Collected Steps per Second: 12,159.47767
Overall Steps per Second: 6,718.64502
Timestep Collection Time: 4.11317
Timestep Consumption Time: 3.33089
PPO Batch Consumption Time: 0.24425
Total Iteration Time: 7.44406
Cumulative Model Updates: 5,865
Cumulative Timesteps: 32,664,618
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42287
Policy Entropy: 3.72784
Value Function Loss: 0.30538
Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.63837
Value Function Update Magnitude: 0.70299
Collected Steps per Second: 12,286.49549
Overall Steps per Second: 6,847.49447
Timestep Collection Time: 4.07179
Timestep Consumption Time: 3.23424
PPO Batch Consumption Time: 0.24198
Total Iteration Time: 7.30603
Cumulative Model Updates: 5,874
Cumulative Timesteps: 32,714,646
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 32714646...
Checkpoint 32714646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 23.24450
Policy Entropy: 3.72159
Value Function Loss: 0.32157
Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.64404
Value Function Update Magnitude: 0.78494
Collected Steps per Second: 12,435.66038
Overall Steps per Second: 6,839.27389
Timestep Collection Time: 4.02070
Timestep Consumption Time: 3.29002
PPO Batch Consumption Time: 0.24289
Total Iteration Time: 7.31072
Cumulative Model Updates: 5,883
Cumulative Timesteps: 32,764,646
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74296
Policy Entropy: 3.72189
Value Function Loss: 0.32304
Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.64529
Value Function Update Magnitude: 0.79136
Collected Steps per Second: 12,273.80323
Overall Steps per Second: 6,801.63526
Timestep Collection Time: 4.07730
Timestep Consumption Time: 3.28034
PPO Batch Consumption Time: 0.24219
Total Iteration Time: 7.35764
Cumulative Model Updates: 5,892
Cumulative Timesteps: 32,814,690
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 32814690...
Checkpoint 32814690 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61120
Policy Entropy: 3.72233
Value Function Loss: 0.30224
Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.63407
Value Function Update Magnitude: 0.81608
Collected Steps per Second: 12,273.60267
Overall Steps per Second: 6,896.39345
Timestep Collection Time: 4.07411
Timestep Consumption Time: 3.17664
PPO Batch Consumption Time: 0.24219
Total Iteration Time: 7.25075
Cumulative Model Updates: 5,901
Cumulative Timesteps: 32,864,694
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.34292
Policy Entropy: 3.72549
Value Function Loss: 0.28209
Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.62022
Value Function Update Magnitude: 0.78688
Collected Steps per Second: 12,449.58416
Overall Steps per Second: 6,851.31913
Timestep Collection Time: 4.01620
Timestep Consumption Time: 3.28167
PPO Batch Consumption Time: 0.24410
Total Iteration Time: 7.29786
Cumulative Model Updates: 5,910
Cumulative Timesteps: 32,914,694
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 32914694...
Checkpoint 32914694 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44699
Policy Entropy: 3.72749
Value Function Loss: 0.29404
Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.63110
Value Function Update Magnitude: 0.71267
Collected Steps per Second: 12,036.40601
Overall Steps per Second: 6,702.32604
Timestep Collection Time: 4.15639
Timestep Consumption Time: 3.30788
PPO Batch Consumption Time: 0.24530
Total Iteration Time: 7.46427
Cumulative Model Updates: 5,919
Cumulative Timesteps: 32,964,722
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.74369
Policy Entropy: 3.72955
Value Function Loss: 0.30244
Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.64966
Value Function Update Magnitude: 0.71415
Collected Steps per Second: 10,506.76175
Overall Steps per Second: 6,212.36197
Timestep Collection Time: 4.76246
Timestep Consumption Time: 3.29213
PPO Batch Consumption Time: 0.24962
Total Iteration Time: 8.05459
Cumulative Model Updates: 5,928
Cumulative Timesteps: 33,014,760
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 33014760...
Checkpoint 33014760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.38212
Policy Entropy: 3.72793
Value Function Loss: 0.31087
Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.65757
Value Function Update Magnitude: 0.71753
Collected Steps per Second: 11,238.81959
Overall Steps per Second: 6,425.97268
Timestep Collection Time: 4.45314
Timestep Consumption Time: 3.33526
PPO Batch Consumption Time: 0.24440
Total Iteration Time: 7.78839
Cumulative Model Updates: 5,937
Cumulative Timesteps: 33,064,808
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.22271
Policy Entropy: 3.72785
Value Function Loss: 0.30144
Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.65255
Value Function Update Magnitude: 0.75362
Collected Steps per Second: 11,526.33417
Overall Steps per Second: 6,560.32829
Timestep Collection Time: 4.33980
Timestep Consumption Time: 3.28512
PPO Batch Consumption Time: 0.24356
Total Iteration Time: 7.62492
Cumulative Model Updates: 5,946
Cumulative Timesteps: 33,114,830
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 33114830...
Checkpoint 33114830 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.60495
Policy Entropy: 3.72916
Value Function Loss: 0.32193
Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.65785
Value Function Update Magnitude: 0.74843
Collected Steps per Second: 11,918.03715
Overall Steps per Second: 6,629.36563
Timestep Collection Time: 4.19650
Timestep Consumption Time: 3.34782
PPO Batch Consumption Time: 0.24628
Total Iteration Time: 7.54431
Cumulative Model Updates: 5,955
Cumulative Timesteps: 33,164,844
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.21710
Policy Entropy: 3.73078
Value Function Loss: 0.32678
Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.65431
Value Function Update Magnitude: 0.74155
Collected Steps per Second: 11,638.33860
Overall Steps per Second: 6,587.18525
Timestep Collection Time: 4.29786
Timestep Consumption Time: 3.29567
PPO Batch Consumption Time: 0.24236
Total Iteration Time: 7.59353
Cumulative Model Updates: 5,964
Cumulative Timesteps: 33,214,864
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 33214864...
Checkpoint 33214864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.68511
Policy Entropy: 3.72460
Value Function Loss: 0.33763
Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.12008
Policy Update Magnitude: 0.65775
Value Function Update Magnitude: 0.75344
Collected Steps per Second: 11,648.21605
Overall Steps per Second: 6,552.01518
Timestep Collection Time: 4.29370
Timestep Consumption Time: 3.33967
PPO Batch Consumption Time: 0.25392
Total Iteration Time: 7.63338
Cumulative Model Updates: 5,973
Cumulative Timesteps: 33,264,878
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.02479
Policy Entropy: 3.72650
Value Function Loss: 0.31336
Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.65525
Value Function Update Magnitude: 0.77602
Collected Steps per Second: 11,528.22021
Overall Steps per Second: 6,381.00783
Timestep Collection Time: 4.33770
Timestep Consumption Time: 3.49899
PPO Batch Consumption Time: 0.24845
Total Iteration Time: 7.83669
Cumulative Model Updates: 5,982
Cumulative Timesteps: 33,314,884
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 33314884...
Checkpoint 33314884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.81892
Policy Entropy: 3.73021
Value Function Loss: 0.31557
Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.65691
Value Function Update Magnitude: 0.76727
Collected Steps per Second: 11,947.14311
Overall Steps per Second: 6,723.63404
Timestep Collection Time: 4.18711
Timestep Consumption Time: 3.25291
PPO Batch Consumption Time: 0.24494
Total Iteration Time: 7.44002
Cumulative Model Updates: 5,991
Cumulative Timesteps: 33,364,908
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42277
Policy Entropy: 3.73024
Value Function Loss: 0.31547
Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.66875
Value Function Update Magnitude: 0.71894
Collected Steps per Second: 11,692.68624
Overall Steps per Second: 6,692.86039
Timestep Collection Time: 4.27891
Timestep Consumption Time: 3.19651
PPO Batch Consumption Time: 0.24386
Total Iteration Time: 7.47543
Cumulative Model Updates: 6,000
Cumulative Timesteps: 33,414,940
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 33414940...
Checkpoint 33414940 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.63879
Policy Entropy: 3.72749
Value Function Loss: 0.31769
Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.65761
Value Function Update Magnitude: 0.69317
Collected Steps per Second: 11,754.90351
Overall Steps per Second: 6,611.47505
Timestep Collection Time: 4.25371
Timestep Consumption Time: 3.30920
PPO Batch Consumption Time: 0.24247
Total Iteration Time: 7.56291
Cumulative Model Updates: 6,009
Cumulative Timesteps: 33,464,942
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.00026
Policy Entropy: 3.72914
Value Function Loss: 0.31812
Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.65228
Value Function Update Magnitude: 0.72614
Collected Steps per Second: 12,017.34877
Overall Steps per Second: 6,741.44171
Timestep Collection Time: 4.16331
Timestep Consumption Time: 3.25824
PPO Batch Consumption Time: 0.24302
Total Iteration Time: 7.42156
Cumulative Model Updates: 6,018
Cumulative Timesteps: 33,514,974
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 33514974...
Checkpoint 33514974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.64820
Policy Entropy: 3.72636
Value Function Loss: 0.31057
Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.64853
Value Function Update Magnitude: 0.71998
Collected Steps per Second: 12,212.26770
Overall Steps per Second: 6,663.73133
Timestep Collection Time: 4.09473
Timestep Consumption Time: 3.40947
PPO Batch Consumption Time: 0.25598
Total Iteration Time: 7.50420
Cumulative Model Updates: 6,027
Cumulative Timesteps: 33,564,980
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.51419
Policy Entropy: 3.72675
Value Function Loss: 0.32646
Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.65411
Value Function Update Magnitude: 0.70888
Collected Steps per Second: 11,941.84558
Overall Steps per Second: 6,668.41869
Timestep Collection Time: 4.18779
Timestep Consumption Time: 3.31173
PPO Batch Consumption Time: 0.24482
Total Iteration Time: 7.49953
Cumulative Model Updates: 6,036
Cumulative Timesteps: 33,614,990
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 33614990...
Checkpoint 33614990 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.84757
Policy Entropy: 3.72461
Value Function Loss: 0.31560
Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.64878
Value Function Update Magnitude: 0.75615
Collected Steps per Second: 11,609.94567
Overall Steps per Second: 6,643.93895
Timestep Collection Time: 4.30700
Timestep Consumption Time: 3.21926
PPO Batch Consumption Time: 0.24658
Total Iteration Time: 7.52626
Cumulative Model Updates: 6,045
Cumulative Timesteps: 33,664,994
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85977
Policy Entropy: 3.72778
Value Function Loss: 0.30707
Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11765
Policy Update Magnitude: 0.64527
Value Function Update Magnitude: 0.82859
Collected Steps per Second: 11,583.38218
Overall Steps per Second: 6,528.96698
Timestep Collection Time: 4.31946
Timestep Consumption Time: 3.34392
PPO Batch Consumption Time: 0.24661
Total Iteration Time: 7.66339
Cumulative Model Updates: 6,054
Cumulative Timesteps: 33,715,028
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 33715028...
Checkpoint 33715028 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.97333
Policy Entropy: 3.72641
Value Function Loss: 0.28553
Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.63442
Value Function Update Magnitude: 0.70127
Collected Steps per Second: 11,638.23322
Overall Steps per Second: 6,619.45699
Timestep Collection Time: 4.29893
Timestep Consumption Time: 3.25939
PPO Batch Consumption Time: 0.24413
Total Iteration Time: 7.55832
Cumulative Model Updates: 6,063
Cumulative Timesteps: 33,765,060
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.76932
Policy Entropy: 3.71744
Value Function Loss: 0.28855
Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.62821
Value Function Update Magnitude: 0.85621
Collected Steps per Second: 11,444.30832
Overall Steps per Second: 6,544.37238
Timestep Collection Time: 4.37073
Timestep Consumption Time: 3.27248
PPO Batch Consumption Time: 0.24405
Total Iteration Time: 7.64321
Cumulative Model Updates: 6,072
Cumulative Timesteps: 33,815,080
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 33815080...
Checkpoint 33815080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.79913
Policy Entropy: 3.72190
Value Function Loss: 0.29254
Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.62525
Value Function Update Magnitude: 0.73164
Collected Steps per Second: 11,195.65334
Overall Steps per Second: 6,353.07990
Timestep Collection Time: 4.46798
Timestep Consumption Time: 3.40568
PPO Batch Consumption Time: 0.24461
Total Iteration Time: 7.87366
Cumulative Model Updates: 6,081
Cumulative Timesteps: 33,865,102
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95339
Policy Entropy: 3.71908
Value Function Loss: 0.29896
Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.63510
Value Function Update Magnitude: 0.71436
Collected Steps per Second: 11,837.01580
Overall Steps per Second: 6,741.46960
Timestep Collection Time: 4.22674
Timestep Consumption Time: 3.19479
PPO Batch Consumption Time: 0.23645
Total Iteration Time: 7.42153
Cumulative Model Updates: 6,090
Cumulative Timesteps: 33,915,134
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 33915134...
Checkpoint 33915134 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.67121
Policy Entropy: 3.71711
Value Function Loss: 0.30903
Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.64520
Value Function Update Magnitude: 0.70329
Collected Steps per Second: 12,033.96975
Overall Steps per Second: 6,678.58375
Timestep Collection Time: 4.15540
Timestep Consumption Time: 3.33211
PPO Batch Consumption Time: 0.24600
Total Iteration Time: 7.48752
Cumulative Model Updates: 6,099
Cumulative Timesteps: 33,965,140
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.11311
Policy Entropy: 3.71296
Value Function Loss: 0.31717
Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.65451
Value Function Update Magnitude: 0.76264
Collected Steps per Second: 11,665.51462
Overall Steps per Second: 6,675.09039
Timestep Collection Time: 4.28717
Timestep Consumption Time: 3.20517
PPO Batch Consumption Time: 0.23312
Total Iteration Time: 7.49233
Cumulative Model Updates: 6,108
Cumulative Timesteps: 34,015,152
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 34015152...
Checkpoint 34015152 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.18200
Policy Entropy: 3.70765
Value Function Loss: 0.30996
Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.65952
Value Function Update Magnitude: 0.85570
Collected Steps per Second: 11,529.83834
Overall Steps per Second: 5,314.14248
Timestep Collection Time: 4.33866
Timestep Consumption Time: 5.07472
PPO Batch Consumption Time: 0.44894
Total Iteration Time: 9.41337
Cumulative Model Updates: 6,117
Cumulative Timesteps: 34,065,176
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.98602
Policy Entropy: 3.71106
Value Function Loss: 0.30122
Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.65322
Value Function Update Magnitude: 0.78140
Collected Steps per Second: 11,726.06687
Overall Steps per Second: 6,604.25473
Timestep Collection Time: 4.26759
Timestep Consumption Time: 3.30965
PPO Batch Consumption Time: 0.24422
Total Iteration Time: 7.57724
Cumulative Model Updates: 6,126
Cumulative Timesteps: 34,115,218
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 34115218...
Checkpoint 34115218 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97858
Policy Entropy: 3.71112
Value Function Loss: 0.30001
Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11946
Policy Update Magnitude: 0.65200
Value Function Update Magnitude: 0.73925
Collected Steps per Second: 10,181.32404
Overall Steps per Second: 6,025.56404
Timestep Collection Time: 4.91135
Timestep Consumption Time: 3.38730
PPO Batch Consumption Time: 0.24363
Total Iteration Time: 8.29864
Cumulative Model Updates: 6,135
Cumulative Timesteps: 34,165,222
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81240
Policy Entropy: 3.70722
Value Function Loss: 0.33010
Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.66387
Value Function Update Magnitude: 0.74621
Collected Steps per Second: 12,506.08945
Overall Steps per Second: 6,974.71155
Timestep Collection Time: 4.00077
Timestep Consumption Time: 3.17286
PPO Batch Consumption Time: 0.23004
Total Iteration Time: 7.17363
Cumulative Model Updates: 6,144
Cumulative Timesteps: 34,215,256
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 34215256...
Checkpoint 34215256 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.01680
Policy Entropy: 3.70975
Value Function Loss: 0.31724
Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.67908
Value Function Update Magnitude: 0.76121
Collected Steps per Second: 12,511.79360
Overall Steps per Second: 6,929.14318
Timestep Collection Time: 3.99719
Timestep Consumption Time: 3.22044
PPO Batch Consumption Time: 0.23522
Total Iteration Time: 7.21763
Cumulative Model Updates: 6,153
Cumulative Timesteps: 34,265,268
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.03868
Policy Entropy: 3.70893
Value Function Loss: 0.31364
Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.66388
Value Function Update Magnitude: 0.73653
Collected Steps per Second: 11,365.47256
Overall Steps per Second: 6,479.21713
Timestep Collection Time: 4.40263
Timestep Consumption Time: 3.32021
PPO Batch Consumption Time: 0.24048
Total Iteration Time: 7.72285
Cumulative Model Updates: 6,162
Cumulative Timesteps: 34,315,306
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 34315306...
Checkpoint 34315306 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95160
Policy Entropy: 3.71432
Value Function Loss: 0.31269
Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.65874
Value Function Update Magnitude: 0.69639
Collected Steps per Second: 9,230.11110
Overall Steps per Second: 5,646.86231
Timestep Collection Time: 5.42420
Timestep Consumption Time: 3.44196
PPO Batch Consumption Time: 0.24453
Total Iteration Time: 8.86616
Cumulative Model Updates: 6,171
Cumulative Timesteps: 34,365,372
Timesteps Collected: 50,066
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50086
Policy Entropy: 3.71641
Value Function Loss: 0.31440
Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.67295
Value Function Update Magnitude: 0.71011
Collected Steps per Second: 10,551.60163
Overall Steps per Second: 5,683.68587
Timestep Collection Time: 4.74070
Timestep Consumption Time: 4.06028
PPO Batch Consumption Time: 0.30309
Total Iteration Time: 8.80098
Cumulative Model Updates: 6,180
Cumulative Timesteps: 34,415,394
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 34415394...
Checkpoint 34415394 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.87266
Policy Entropy: 3.71260
Value Function Loss: 0.30640
Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10983
Policy Update Magnitude: 0.68117
Value Function Update Magnitude: 0.72219
Collected Steps per Second: 9,536.68650
Overall Steps per Second: 5,415.68853
Timestep Collection Time: 5.24480
Timestep Consumption Time: 3.99096
PPO Batch Consumption Time: 0.32496
Total Iteration Time: 9.23576
Cumulative Model Updates: 6,189
Cumulative Timesteps: 34,465,412
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.88344
Policy Entropy: 3.71477
Value Function Loss: 0.30163
Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.66884
Value Function Update Magnitude: 0.72731
Collected Steps per Second: 9,826.05814
Overall Steps per Second: 5,489.04674
Timestep Collection Time: 5.09055
Timestep Consumption Time: 4.02215
PPO Batch Consumption Time: 0.31920
Total Iteration Time: 9.11269
Cumulative Model Updates: 6,198
Cumulative Timesteps: 34,515,432
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 34515432...
Checkpoint 34515432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52123
Policy Entropy: 3.71127
Value Function Loss: 0.29863
Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.66354
Value Function Update Magnitude: 0.71685
Collected Steps per Second: 9,783.88808
Overall Steps per Second: 5,489.74004
Timestep Collection Time: 5.11555
Timestep Consumption Time: 4.00145
PPO Batch Consumption Time: 0.31954
Total Iteration Time: 9.11701
Cumulative Model Updates: 6,207
Cumulative Timesteps: 34,565,482
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.93533
Policy Entropy: 3.71298
Value Function Loss: 0.28862
Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.65066
Value Function Update Magnitude: 0.69123
Collected Steps per Second: 10,399.72306
Overall Steps per Second: 5,648.18337
Timestep Collection Time: 4.80878
Timestep Consumption Time: 4.04539
PPO Batch Consumption Time: 0.32100
Total Iteration Time: 8.85417
Cumulative Model Updates: 6,216
Cumulative Timesteps: 34,615,492
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 34615492...
Checkpoint 34615492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.82139
Policy Entropy: 3.70783
Value Function Loss: 0.29052
Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.64331
Value Function Update Magnitude: 0.66016
Collected Steps per Second: 10,277.20969
Overall Steps per Second: 5,611.91120
Timestep Collection Time: 4.86591
Timestep Consumption Time: 4.04513
PPO Batch Consumption Time: 0.31873
Total Iteration Time: 8.91105
Cumulative Model Updates: 6,225
Cumulative Timesteps: 34,665,500
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81640
Policy Entropy: 3.70138
Value Function Loss: 0.29871
Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.64616
Value Function Update Magnitude: 0.69795
Collected Steps per Second: 9,390.02476
Overall Steps per Second: 5,757.05895
Timestep Collection Time: 5.32714
Timestep Consumption Time: 3.36167
PPO Batch Consumption Time: 0.23775
Total Iteration Time: 8.68881
Cumulative Model Updates: 6,234
Cumulative Timesteps: 34,715,522
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 34715522...
Checkpoint 34715522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.55895
Policy Entropy: 3.69940
Value Function Loss: 0.32364
Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.66318
Value Function Update Magnitude: 0.73294
Collected Steps per Second: 11,658.15862
Overall Steps per Second: 6,394.80004
Timestep Collection Time: 4.29021
Timestep Consumption Time: 3.53114
PPO Batch Consumption Time: 0.26002
Total Iteration Time: 7.82135
Cumulative Model Updates: 6,243
Cumulative Timesteps: 34,765,538
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38610
Policy Entropy: 3.70229
Value Function Loss: 0.32379
Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.68263
Value Function Update Magnitude: 0.78182
Collected Steps per Second: 11,798.04404
Overall Steps per Second: 6,752.49251
Timestep Collection Time: 4.23867
Timestep Consumption Time: 3.16719
PPO Batch Consumption Time: 0.23174
Total Iteration Time: 7.40586
Cumulative Model Updates: 6,252
Cumulative Timesteps: 34,815,546
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 34815546...
Checkpoint 34815546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.78138
Policy Entropy: 3.70382
Value Function Loss: 0.31053
Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.68047
Value Function Update Magnitude: 0.77164
Collected Steps per Second: 12,988.79214
Overall Steps per Second: 7,167.57727
Timestep Collection Time: 3.84978
Timestep Consumption Time: 3.12664
PPO Batch Consumption Time: 0.23593
Total Iteration Time: 6.97642
Cumulative Model Updates: 6,261
Cumulative Timesteps: 34,865,550
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.73278
Policy Entropy: 3.69522
Value Function Loss: 0.30445
Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.66778
Value Function Update Magnitude: 0.72227
Collected Steps per Second: 11,768.22347
Overall Steps per Second: 6,681.37738
Timestep Collection Time: 4.24924
Timestep Consumption Time: 3.23515
PPO Batch Consumption Time: 0.24078
Total Iteration Time: 7.48438
Cumulative Model Updates: 6,270
Cumulative Timesteps: 34,915,556
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 34915556...
Checkpoint 34915556 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.10994
Policy Entropy: 3.69833
Value Function Loss: 0.29486
Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14718
Policy Update Magnitude: 0.65324
Value Function Update Magnitude: 0.75271
Collected Steps per Second: 11,499.58607
Overall Steps per Second: 6,633.10343
Timestep Collection Time: 4.34990
Timestep Consumption Time: 3.19137
PPO Batch Consumption Time: 0.23040
Total Iteration Time: 7.54127
Cumulative Model Updates: 6,279
Cumulative Timesteps: 34,965,578
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56904
Policy Entropy: 3.70119
Value Function Loss: 0.30381
Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14790
Policy Update Magnitude: 0.64903
Value Function Update Magnitude: 0.74265
Collected Steps per Second: 12,517.19068
Overall Steps per Second: 6,859.42580
Timestep Collection Time: 3.99642
Timestep Consumption Time: 3.29631
PPO Batch Consumption Time: 0.24066
Total Iteration Time: 7.29274
Cumulative Model Updates: 6,288
Cumulative Timesteps: 35,015,602
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 35015602...
Checkpoint 35015602 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.26539
Policy Entropy: 3.70491
Value Function Loss: 0.29163
Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.64144
Value Function Update Magnitude: 0.72475
Collected Steps per Second: 13,095.45001
Overall Steps per Second: 7,141.25984
Timestep Collection Time: 3.82224
Timestep Consumption Time: 3.18688
PPO Batch Consumption Time: 0.23117
Total Iteration Time: 7.00913
Cumulative Model Updates: 6,297
Cumulative Timesteps: 35,065,656
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.63391
Policy Entropy: 3.70126
Value Function Loss: 0.28462
Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.62922
Value Function Update Magnitude: 0.71185
Collected Steps per Second: 11,590.87089
Overall Steps per Second: 6,635.93455
Timestep Collection Time: 4.31616
Timestep Consumption Time: 3.22280
PPO Batch Consumption Time: 0.23688
Total Iteration Time: 7.53895
Cumulative Model Updates: 6,306
Cumulative Timesteps: 35,115,684
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 35115684...
Checkpoint 35115684 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.80592
Policy Entropy: 3.69545
Value Function Loss: 0.28083
Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.63552
Value Function Update Magnitude: 0.71298
Collected Steps per Second: 13,403.89920
Overall Steps per Second: 7,297.30564
Timestep Collection Time: 3.73265
Timestep Consumption Time: 3.12358
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.85623
Cumulative Model Updates: 6,315
Cumulative Timesteps: 35,165,716
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76606
Policy Entropy: 3.69264
Value Function Loss: 0.27843
Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.63328
Value Function Update Magnitude: 0.74350
Collected Steps per Second: 13,205.06929
Overall Steps per Second: 7,212.65432
Timestep Collection Time: 3.78945
Timestep Consumption Time: 3.14835
PPO Batch Consumption Time: 0.22951
Total Iteration Time: 6.93781
Cumulative Model Updates: 6,324
Cumulative Timesteps: 35,215,756
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 35215756...
Checkpoint 35215756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50724
Policy Entropy: 3.69940
Value Function Loss: 0.27446
Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.62968
Value Function Update Magnitude: 0.73058
Collected Steps per Second: 12,952.70432
Overall Steps per Second: 7,242.27631
Timestep Collection Time: 3.86128
Timestep Consumption Time: 3.04456
PPO Batch Consumption Time: 0.22941
Total Iteration Time: 6.90584
Cumulative Model Updates: 6,333
Cumulative Timesteps: 35,265,770
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22924
Policy Entropy: 3.70375
Value Function Loss: 0.29015
Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.64073
Value Function Update Magnitude: 0.76684
Collected Steps per Second: 13,156.15743
Overall Steps per Second: 7,214.69158
Timestep Collection Time: 3.80202
Timestep Consumption Time: 3.13105
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.93308
Cumulative Model Updates: 6,342
Cumulative Timesteps: 35,315,790
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 35315790...
Checkpoint 35315790 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.87675
Policy Entropy: 3.70530
Value Function Loss: 0.30402
Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.65286
Value Function Update Magnitude: 0.77350
Collected Steps per Second: 12,928.48939
Overall Steps per Second: 7,172.96913
Timestep Collection Time: 3.87037
Timestep Consumption Time: 3.10554
PPO Batch Consumption Time: 0.22965
Total Iteration Time: 6.97591
Cumulative Model Updates: 6,351
Cumulative Timesteps: 35,365,828
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.87924
Policy Entropy: 3.71089
Value Function Loss: 0.29950
Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.65673
Value Function Update Magnitude: 0.70696
Collected Steps per Second: 13,428.73432
Overall Steps per Second: 7,269.02273
Timestep Collection Time: 3.72470
Timestep Consumption Time: 3.15628
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.88098
Cumulative Model Updates: 6,360
Cumulative Timesteps: 35,415,846
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 35415846...
Checkpoint 35415846 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.43488
Policy Entropy: 3.70869
Value Function Loss: 0.29952
Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.64471
Value Function Update Magnitude: 0.69443
Collected Steps per Second: 13,073.10373
Overall Steps per Second: 7,100.96005
Timestep Collection Time: 3.82755
Timestep Consumption Time: 3.21910
PPO Batch Consumption Time: 0.23114
Total Iteration Time: 7.04665
Cumulative Model Updates: 6,369
Cumulative Timesteps: 35,465,884
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.49677
Policy Entropy: 3.71330
Value Function Loss: 0.28660
Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.63559
Value Function Update Magnitude: 0.67858
Collected Steps per Second: 12,966.20452
Overall Steps per Second: 7,180.59919
Timestep Collection Time: 3.85726
Timestep Consumption Time: 3.10790
PPO Batch Consumption Time: 0.22982
Total Iteration Time: 6.96516
Cumulative Model Updates: 6,378
Cumulative Timesteps: 35,515,898
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 35515898...
Checkpoint 35515898 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31159
Policy Entropy: 3.71117
Value Function Loss: 0.29223
Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11645
Policy Update Magnitude: 0.64441
Value Function Update Magnitude: 0.69478
Collected Steps per Second: 13,404.98160
Overall Steps per Second: 7,259.75469
Timestep Collection Time: 3.73264
Timestep Consumption Time: 3.15960
PPO Batch Consumption Time: 0.22981
Total Iteration Time: 6.89224
Cumulative Model Updates: 6,387
Cumulative Timesteps: 35,565,934
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18897
Policy Entropy: 3.71091
Value Function Loss: 0.27331
Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.64186
Value Function Update Magnitude: 0.71974
Collected Steps per Second: 13,051.26735
Overall Steps per Second: 7,171.26083
Timestep Collection Time: 3.83334
Timestep Consumption Time: 3.14311
PPO Batch Consumption Time: 0.23019
Total Iteration Time: 6.97646
Cumulative Model Updates: 6,396
Cumulative Timesteps: 35,615,964
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 35615964...
Checkpoint 35615964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.77288
Policy Entropy: 3.71869
Value Function Loss: 0.27082
Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.63931
Value Function Update Magnitude: 0.70427
Collected Steps per Second: 12,939.30195
Overall Steps per Second: 7,230.65318
Timestep Collection Time: 3.86559
Timestep Consumption Time: 3.05191
PPO Batch Consumption Time: 0.23003
Total Iteration Time: 6.91749
Cumulative Model Updates: 6,405
Cumulative Timesteps: 35,665,982
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75105
Policy Entropy: 3.71408
Value Function Loss: 0.26437
Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.63321
Value Function Update Magnitude: 0.72273
Collected Steps per Second: 13,281.34809
Overall Steps per Second: 7,236.25499
Timestep Collection Time: 3.76558
Timestep Consumption Time: 3.14573
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 6.91131
Cumulative Model Updates: 6,414
Cumulative Timesteps: 35,715,994
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 35715994...
Checkpoint 35715994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 22.44704
Policy Entropy: 3.71786
Value Function Loss: 0.27564
Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.63994
Value Function Update Magnitude: 0.83301
Collected Steps per Second: 13,082.88505
Overall Steps per Second: 7,245.55474
Timestep Collection Time: 3.82393
Timestep Consumption Time: 3.08072
PPO Batch Consumption Time: 0.22959
Total Iteration Time: 6.90465
Cumulative Model Updates: 6,423
Cumulative Timesteps: 35,766,022
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.07012
Policy Entropy: 3.71660
Value Function Loss: 0.27041
Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.63790
Value Function Update Magnitude: 0.92303
Collected Steps per Second: 13,242.16262
Overall Steps per Second: 7,218.76392
Timestep Collection Time: 3.77672
Timestep Consumption Time: 3.15133
PPO Batch Consumption Time: 0.24123
Total Iteration Time: 6.92806
Cumulative Model Updates: 6,432
Cumulative Timesteps: 35,816,034
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 35816034...
Checkpoint 35816034 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.89129
Policy Entropy: 3.72050
Value Function Loss: 0.27028
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.63616
Value Function Update Magnitude: 0.76148
Collected Steps per Second: 13,129.59577
Overall Steps per Second: 7,189.90675
Timestep Collection Time: 3.81063
Timestep Consumption Time: 3.14802
PPO Batch Consumption Time: 0.22937
Total Iteration Time: 6.95864
Cumulative Model Updates: 6,441
Cumulative Timesteps: 35,866,066
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.22028
Policy Entropy: 3.72251
Value Function Loss: 0.27048
Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.62842
Value Function Update Magnitude: 0.72659
Collected Steps per Second: 13,236.33006
Overall Steps per Second: 7,250.01989
Timestep Collection Time: 3.77945
Timestep Consumption Time: 3.12067
PPO Batch Consumption Time: 0.22937
Total Iteration Time: 6.90012
Cumulative Model Updates: 6,450
Cumulative Timesteps: 35,916,092
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 35916092...
Checkpoint 35916092 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.46542
Policy Entropy: 3.72498
Value Function Loss: 0.27293
Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.63180
Value Function Update Magnitude: 0.75315
Collected Steps per Second: 13,250.33602
Overall Steps per Second: 7,237.03936
Timestep Collection Time: 3.77726
Timestep Consumption Time: 3.13855
PPO Batch Consumption Time: 0.22926
Total Iteration Time: 6.91581
Cumulative Model Updates: 6,459
Cumulative Timesteps: 35,966,142
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.00844
Policy Entropy: 3.72782
Value Function Loss: 0.26520
Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.63091
Value Function Update Magnitude: 0.76494
Collected Steps per Second: 13,178.00823
Overall Steps per Second: 7,189.23680
Timestep Collection Time: 3.79557
Timestep Consumption Time: 3.16178
PPO Batch Consumption Time: 0.22973
Total Iteration Time: 6.95734
Cumulative Model Updates: 6,468
Cumulative Timesteps: 36,016,160
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 36016160...
Checkpoint 36016160 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.16318
Policy Entropy: 3.72953
Value Function Loss: 0.26583
Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.62952
Value Function Update Magnitude: 0.80416
Collected Steps per Second: 13,059.26715
Overall Steps per Second: 7,266.02580
Timestep Collection Time: 3.82977
Timestep Consumption Time: 3.05350
PPO Batch Consumption Time: 0.22993
Total Iteration Time: 6.88327
Cumulative Model Updates: 6,477
Cumulative Timesteps: 36,066,174
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.78668
Policy Entropy: 3.72524
Value Function Loss: 0.27557
Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.63600
Value Function Update Magnitude: 0.78541
Collected Steps per Second: 12,502.60034
Overall Steps per Second: 6,966.38889
Timestep Collection Time: 4.00285
Timestep Consumption Time: 3.18108
PPO Batch Consumption Time: 0.23105
Total Iteration Time: 7.18392
Cumulative Model Updates: 6,486
Cumulative Timesteps: 36,116,220
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 36116220...
Checkpoint 36116220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.26596
Policy Entropy: 3.72425
Value Function Loss: 0.27566
Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.63702
Value Function Update Magnitude: 0.76440
Collected Steps per Second: 13,036.11580
Overall Steps per Second: 7,074.76556
Timestep Collection Time: 3.83550
Timestep Consumption Time: 3.23187
PPO Batch Consumption Time: 0.24118
Total Iteration Time: 7.06737
Cumulative Model Updates: 6,495
Cumulative Timesteps: 36,166,220
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 20.15801
Policy Entropy: 3.72579
Value Function Loss: 0.28096
Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.64161
Value Function Update Magnitude: 0.73983
Collected Steps per Second: 12,975.95000
Overall Steps per Second: 7,272.10067
Timestep Collection Time: 3.85467
Timestep Consumption Time: 3.02340
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 6.87807
Cumulative Model Updates: 6,504
Cumulative Timesteps: 36,216,238
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 36216238...
Checkpoint 36216238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74804
Policy Entropy: 3.71926
Value Function Loss: 0.27398
Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.63235
Value Function Update Magnitude: 0.78188
Collected Steps per Second: 13,249.33151
Overall Steps per Second: 7,212.32856
Timestep Collection Time: 3.77378
Timestep Consumption Time: 3.15880
PPO Batch Consumption Time: 0.22991
Total Iteration Time: 6.93257
Cumulative Model Updates: 6,513
Cumulative Timesteps: 36,266,238
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 20.37052
Policy Entropy: 3.71413
Value Function Loss: 0.27299
Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10941
Policy Update Magnitude: 0.63965
Value Function Update Magnitude: 0.79428
Collected Steps per Second: 13,153.29818
Overall Steps per Second: 7,245.98357
Timestep Collection Time: 3.80376
Timestep Consumption Time: 3.10103
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 6.90479
Cumulative Model Updates: 6,522
Cumulative Timesteps: 36,316,270
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 36316270...
Checkpoint 36316270 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.35342
Policy Entropy: 3.70985
Value Function Loss: 0.27214
Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.63400
Value Function Update Magnitude: 0.81906
Collected Steps per Second: 12,460.95239
Overall Steps per Second: 6,938.58025
Timestep Collection Time: 4.01350
Timestep Consumption Time: 3.19432
PPO Batch Consumption Time: 0.23346
Total Iteration Time: 7.20781
Cumulative Model Updates: 6,531
Cumulative Timesteps: 36,366,282
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.67213
Policy Entropy: 3.70720
Value Function Loss: 0.26604
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.63399
Value Function Update Magnitude: 0.77109
Collected Steps per Second: 11,885.03295
Overall Steps per Second: 6,706.62915
Timestep Collection Time: 4.21118
Timestep Consumption Time: 3.25159
PPO Batch Consumption Time: 0.23852
Total Iteration Time: 7.46277
Cumulative Model Updates: 6,540
Cumulative Timesteps: 36,416,332
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 36416332...
Checkpoint 36416332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.92063
Policy Entropy: 3.70273
Value Function Loss: 0.26091
Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.62748
Value Function Update Magnitude: 0.73708
Collected Steps per Second: 11,548.61113
Overall Steps per Second: 6,517.12225
Timestep Collection Time: 4.33178
Timestep Consumption Time: 3.34431
PPO Batch Consumption Time: 0.25566
Total Iteration Time: 7.67609
Cumulative Model Updates: 6,549
Cumulative Timesteps: 36,466,358
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.13083
Policy Entropy: 3.69827
Value Function Loss: 0.26522
Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.62755
Value Function Update Magnitude: 0.74085
Collected Steps per Second: 11,207.04202
Overall Steps per Second: 6,504.86067
Timestep Collection Time: 4.46344
Timestep Consumption Time: 3.22650
PPO Batch Consumption Time: 0.23076
Total Iteration Time: 7.68994
Cumulative Model Updates: 6,558
Cumulative Timesteps: 36,516,380
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 36516380...
Checkpoint 36516380 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.03346
Policy Entropy: 3.70418
Value Function Loss: 0.26839
Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.63855
Value Function Update Magnitude: 0.81138
Collected Steps per Second: 12,484.14525
Overall Steps per Second: 6,969.95351
Timestep Collection Time: 4.00684
Timestep Consumption Time: 3.16996
PPO Batch Consumption Time: 0.23163
Total Iteration Time: 7.17681
Cumulative Model Updates: 6,567
Cumulative Timesteps: 36,566,402
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.42929
Policy Entropy: 3.70765
Value Function Loss: 0.26595
Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.63224
Value Function Update Magnitude: 0.80333
Collected Steps per Second: 12,840.38502
Overall Steps per Second: 7,027.27271
Timestep Collection Time: 3.89521
Timestep Consumption Time: 3.22220
PPO Batch Consumption Time: 0.23294
Total Iteration Time: 7.11741
Cumulative Model Updates: 6,576
Cumulative Timesteps: 36,616,418
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 36616418...
Checkpoint 36616418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.83614
Policy Entropy: 3.71234
Value Function Loss: 0.27233
Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.63597
Value Function Update Magnitude: 0.76100
Collected Steps per Second: 11,881.90739
Overall Steps per Second: 6,779.77349
Timestep Collection Time: 4.21330
Timestep Consumption Time: 3.17073
PPO Batch Consumption Time: 0.23035
Total Iteration Time: 7.38402
Cumulative Model Updates: 6,585
Cumulative Timesteps: 36,666,480
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57575
Policy Entropy: 3.71296
Value Function Loss: 0.27456
Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.63980
Value Function Update Magnitude: 0.74117
Collected Steps per Second: 12,817.69877
Overall Steps per Second: 7,058.77004
Timestep Collection Time: 3.90257
Timestep Consumption Time: 3.18393
PPO Batch Consumption Time: 0.23599
Total Iteration Time: 7.08650
Cumulative Model Updates: 6,594
Cumulative Timesteps: 36,716,502
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 36716502...
Checkpoint 36716502 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.41207
Policy Entropy: 3.71016
Value Function Loss: 0.27468
Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.64326
Value Function Update Magnitude: 0.82556
Collected Steps per Second: 11,816.43100
Overall Steps per Second: 6,643.50601
Timestep Collection Time: 4.23444
Timestep Consumption Time: 3.29712
PPO Batch Consumption Time: 0.23840
Total Iteration Time: 7.53157
Cumulative Model Updates: 6,603
Cumulative Timesteps: 36,766,538
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30200
Policy Entropy: 3.70776
Value Function Loss: 0.26272
Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.63895
Value Function Update Magnitude: 0.72197
Collected Steps per Second: 12,142.68750
Overall Steps per Second: 6,819.23448
Timestep Collection Time: 4.12199
Timestep Consumption Time: 3.21784
PPO Batch Consumption Time: 0.23634
Total Iteration Time: 7.33983
Cumulative Model Updates: 6,612
Cumulative Timesteps: 36,816,590
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 36816590...
Checkpoint 36816590 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.73544
Policy Entropy: 3.70185
Value Function Loss: 0.25733
Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.62940
Value Function Update Magnitude: 0.74068
Collected Steps per Second: 11,779.92717
Overall Steps per Second: 6,739.84164
Timestep Collection Time: 4.24638
Timestep Consumption Time: 3.17546
PPO Batch Consumption Time: 0.23802
Total Iteration Time: 7.42184
Cumulative Model Updates: 6,621
Cumulative Timesteps: 36,866,612
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.39128
Policy Entropy: 3.70245
Value Function Loss: 0.25706
Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.62610
Value Function Update Magnitude: 0.68167
Collected Steps per Second: 11,634.21541
Overall Steps per Second: 6,608.48729
Timestep Collection Time: 4.30008
Timestep Consumption Time: 3.27019
PPO Batch Consumption Time: 0.23492
Total Iteration Time: 7.57027
Cumulative Model Updates: 6,630
Cumulative Timesteps: 36,916,640
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 36916640...
Checkpoint 36916640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43276
Policy Entropy: 3.69251
Value Function Loss: 0.26851
Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.63573
Value Function Update Magnitude: 0.69104
Collected Steps per Second: 11,927.19276
Overall Steps per Second: 6,724.73837
Timestep Collection Time: 4.19395
Timestep Consumption Time: 3.24456
PPO Batch Consumption Time: 0.23642
Total Iteration Time: 7.43851
Cumulative Model Updates: 6,639
Cumulative Timesteps: 36,966,662
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.94967
Policy Entropy: 3.69740
Value Function Loss: 0.27744
Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.64682
Value Function Update Magnitude: 0.72202
Collected Steps per Second: 11,921.69474
Overall Steps per Second: 6,742.45466
Timestep Collection Time: 4.19655
Timestep Consumption Time: 3.22360
PPO Batch Consumption Time: 0.23548
Total Iteration Time: 7.42015
Cumulative Model Updates: 6,648
Cumulative Timesteps: 37,016,692
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 37016692...
Checkpoint 37016692 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.71491
Policy Entropy: 3.68999
Value Function Loss: 0.27110
Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.64147
Value Function Update Magnitude: 0.70990
Collected Steps per Second: 11,725.31347
Overall Steps per Second: 6,538.42446
Timestep Collection Time: 4.26735
Timestep Consumption Time: 3.38526
PPO Batch Consumption Time: 0.24740
Total Iteration Time: 7.65261
Cumulative Model Updates: 6,657
Cumulative Timesteps: 37,066,728
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.39813
Policy Entropy: 3.69379
Value Function Loss: 0.26713
Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.63904
Value Function Update Magnitude: 0.71390
Collected Steps per Second: 12,326.45453
Overall Steps per Second: 6,954.22339
Timestep Collection Time: 4.05778
Timestep Consumption Time: 3.13469
PPO Batch Consumption Time: 0.23062
Total Iteration Time: 7.19246
Cumulative Model Updates: 6,666
Cumulative Timesteps: 37,116,746
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 37116746...
Checkpoint 37116746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.89379
Policy Entropy: 3.69506
Value Function Loss: 0.28213
Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.64642
Value Function Update Magnitude: 0.77921
Collected Steps per Second: 12,654.46763
Overall Steps per Second: 6,955.39810
Timestep Collection Time: 3.95512
Timestep Consumption Time: 3.24072
PPO Batch Consumption Time: 0.23564
Total Iteration Time: 7.19585
Cumulative Model Updates: 6,675
Cumulative Timesteps: 37,166,796
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.32071
Policy Entropy: 3.69292
Value Function Loss: 0.27387
Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11592
Policy Update Magnitude: 0.65267
Value Function Update Magnitude: 0.72706
Collected Steps per Second: 11,487.16534
Overall Steps per Second: 6,562.66943
Timestep Collection Time: 4.35425
Timestep Consumption Time: 3.26734
PPO Batch Consumption Time: 0.23357
Total Iteration Time: 7.62159
Cumulative Model Updates: 6,684
Cumulative Timesteps: 37,216,814
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 37216814...
Checkpoint 37216814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40833
Policy Entropy: 3.68786
Value Function Loss: 0.27664
Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.63750
Value Function Update Magnitude: 0.73811
Collected Steps per Second: 11,412.91036
Overall Steps per Second: 6,552.52009
Timestep Collection Time: 4.38153
Timestep Consumption Time: 3.25004
PPO Batch Consumption Time: 0.24087
Total Iteration Time: 7.63157
Cumulative Model Updates: 6,693
Cumulative Timesteps: 37,266,820
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.95764
Policy Entropy: 3.68665
Value Function Loss: 0.26522
Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.63478
Value Function Update Magnitude: 0.78872
Collected Steps per Second: 12,131.34168
Overall Steps per Second: 6,741.19006
Timestep Collection Time: 4.12271
Timestep Consumption Time: 3.29646
PPO Batch Consumption Time: 0.24001
Total Iteration Time: 7.41916
Cumulative Model Updates: 6,702
Cumulative Timesteps: 37,316,834
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 37316834...
Checkpoint 37316834 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.08814
Policy Entropy: 3.68051
Value Function Loss: 0.26333
Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.64139
Value Function Update Magnitude: 0.75836
Collected Steps per Second: 12,029.69920
Overall Steps per Second: 6,611.80203
Timestep Collection Time: 4.15788
Timestep Consumption Time: 3.40708
PPO Batch Consumption Time: 0.25581
Total Iteration Time: 7.56496
Cumulative Model Updates: 6,711
Cumulative Timesteps: 37,366,852
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.97218
Policy Entropy: 3.67580
Value Function Loss: 0.26350
Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.64235
Value Function Update Magnitude: 0.69798
Collected Steps per Second: 11,084.39077
Overall Steps per Second: 6,319.89484
Timestep Collection Time: 4.51337
Timestep Consumption Time: 3.40258
PPO Batch Consumption Time: 0.24201
Total Iteration Time: 7.91595
Cumulative Model Updates: 6,720
Cumulative Timesteps: 37,416,880
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 37416880...
Checkpoint 37416880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.91632
Policy Entropy: 3.68030
Value Function Loss: 0.25624
Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14840
Policy Update Magnitude: 0.63097
Value Function Update Magnitude: 0.67543
Collected Steps per Second: 11,338.21053
Overall Steps per Second: 6,164.66457
Timestep Collection Time: 4.41181
Timestep Consumption Time: 3.70250
PPO Batch Consumption Time: 0.24645
Total Iteration Time: 8.11431
Cumulative Model Updates: 6,729
Cumulative Timesteps: 37,466,902
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01094
Policy Entropy: 3.67893
Value Function Loss: 0.25881
Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.61924
Value Function Update Magnitude: 0.69862
Collected Steps per Second: 12,087.37768
Overall Steps per Second: 6,891.49768
Timestep Collection Time: 4.13704
Timestep Consumption Time: 3.11914
PPO Batch Consumption Time: 0.23573
Total Iteration Time: 7.25619
Cumulative Model Updates: 6,738
Cumulative Timesteps: 37,516,908
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 37516908...
Checkpoint 37516908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.36840
Policy Entropy: 3.68752
Value Function Loss: 0.25432
Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.62881
Value Function Update Magnitude: 0.67470
Collected Steps per Second: 11,894.25913
Overall Steps per Second: 6,790.42564
Timestep Collection Time: 4.20388
Timestep Consumption Time: 3.15973
PPO Batch Consumption Time: 0.23024
Total Iteration Time: 7.36360
Cumulative Model Updates: 6,747
Cumulative Timesteps: 37,566,910
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.63884
Policy Entropy: 3.68221
Value Function Loss: 0.26556
Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.63427
Value Function Update Magnitude: 0.69623
Collected Steps per Second: 12,244.84931
Overall Steps per Second: 6,907.88941
Timestep Collection Time: 4.08596
Timestep Consumption Time: 3.15677
PPO Batch Consumption Time: 0.23019
Total Iteration Time: 7.24273
Cumulative Model Updates: 6,756
Cumulative Timesteps: 37,616,942
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 37616942...
Checkpoint 37616942 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.24628
Policy Entropy: 3.68523
Value Function Loss: 0.25975
Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.63240
Value Function Update Magnitude: 0.68823
Collected Steps per Second: 12,559.26887
Overall Steps per Second: 7,055.84622
Timestep Collection Time: 3.98160
Timestep Consumption Time: 3.10557
PPO Batch Consumption Time: 0.23466
Total Iteration Time: 7.08717
Cumulative Model Updates: 6,765
Cumulative Timesteps: 37,666,948
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06598
Policy Entropy: 3.68324
Value Function Loss: 0.26162
Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.62683
Value Function Update Magnitude: 0.67628
Collected Steps per Second: 11,818.40490
Overall Steps per Second: 6,580.61549
Timestep Collection Time: 4.23086
Timestep Consumption Time: 3.36752
PPO Batch Consumption Time: 0.24696
Total Iteration Time: 7.59838
Cumulative Model Updates: 6,774
Cumulative Timesteps: 37,716,950
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 37716950...
Checkpoint 37716950 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95319
Policy Entropy: 3.68091
Value Function Loss: 0.25308
Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.62584
Value Function Update Magnitude: 0.68895
Collected Steps per Second: 12,419.29894
Overall Steps per Second: 6,818.86935
Timestep Collection Time: 4.02905
Timestep Consumption Time: 3.30911
PPO Batch Consumption Time: 0.24829
Total Iteration Time: 7.33817
Cumulative Model Updates: 6,783
Cumulative Timesteps: 37,766,988
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56346
Policy Entropy: 3.68289
Value Function Loss: 0.26136
Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.63027
Value Function Update Magnitude: 0.66680
Collected Steps per Second: 12,029.18841
Overall Steps per Second: 6,709.47374
Timestep Collection Time: 4.16005
Timestep Consumption Time: 3.29836
PPO Batch Consumption Time: 0.24233
Total Iteration Time: 7.45841
Cumulative Model Updates: 6,792
Cumulative Timesteps: 37,817,030
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 37817030...
Checkpoint 37817030 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.92527
Policy Entropy: 3.68303
Value Function Loss: 0.26275
Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.64515
Value Function Update Magnitude: 0.73852
Collected Steps per Second: 11,829.48838
Overall Steps per Second: 6,633.57282
Timestep Collection Time: 4.22774
Timestep Consumption Time: 3.31149
PPO Batch Consumption Time: 0.24113
Total Iteration Time: 7.53923
Cumulative Model Updates: 6,801
Cumulative Timesteps: 37,867,042
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10296
Policy Entropy: 3.67694
Value Function Loss: 0.26723
Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.66272
Value Function Update Magnitude: 0.73119
Collected Steps per Second: 12,067.50496
Overall Steps per Second: 6,725.78936
Timestep Collection Time: 4.14402
Timestep Consumption Time: 3.29124
PPO Batch Consumption Time: 0.24335
Total Iteration Time: 7.43526
Cumulative Model Updates: 6,810
Cumulative Timesteps: 37,917,050
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 37917050...
Checkpoint 37917050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.90479
Policy Entropy: 3.67974
Value Function Loss: 0.26150
Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.65864
Value Function Update Magnitude: 0.70723
Collected Steps per Second: 11,788.85252
Overall Steps per Second: 6,704.39421
Timestep Collection Time: 4.24197
Timestep Consumption Time: 3.21702
PPO Batch Consumption Time: 0.23494
Total Iteration Time: 7.45899
Cumulative Model Updates: 6,819
Cumulative Timesteps: 37,967,058
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24215
Policy Entropy: 3.68367
Value Function Loss: 0.26109
Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.67337
Value Function Update Magnitude: 0.71162
Collected Steps per Second: 12,351.29162
Overall Steps per Second: 6,847.81773
Timestep Collection Time: 4.04865
Timestep Consumption Time: 3.25383
PPO Batch Consumption Time: 0.23974
Total Iteration Time: 7.30247
Cumulative Model Updates: 6,828
Cumulative Timesteps: 38,017,064
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 38017064...
Checkpoint 38017064 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.26303
Policy Entropy: 3.69132
Value Function Loss: 0.25442
Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.66087
Value Function Update Magnitude: 0.69546
Collected Steps per Second: 12,392.52321
Overall Steps per Second: 6,999.61469
Timestep Collection Time: 4.03663
Timestep Consumption Time: 3.11005
PPO Batch Consumption Time: 0.23237
Total Iteration Time: 7.14668
Cumulative Model Updates: 6,837
Cumulative Timesteps: 38,067,088
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28122
Policy Entropy: 3.68906
Value Function Loss: 0.25028
Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11850
Policy Update Magnitude: 0.64854
Value Function Update Magnitude: 0.65923
Collected Steps per Second: 12,571.11209
Overall Steps per Second: 6,905.49474
Timestep Collection Time: 3.97912
Timestep Consumption Time: 3.26467
PPO Batch Consumption Time: 0.23987
Total Iteration Time: 7.24380
Cumulative Model Updates: 6,846
Cumulative Timesteps: 38,117,110
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 38117110...
Checkpoint 38117110 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49247
Policy Entropy: 3.68875
Value Function Loss: 0.25497
Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.63392
Value Function Update Magnitude: 0.67908
Collected Steps per Second: 12,029.59341
Overall Steps per Second: 6,850.73903
Timestep Collection Time: 4.16124
Timestep Consumption Time: 3.14571
PPO Batch Consumption Time: 0.22989
Total Iteration Time: 7.30695
Cumulative Model Updates: 6,855
Cumulative Timesteps: 38,167,168
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.69685
Policy Entropy: 3.68518
Value Function Loss: 0.25884
Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.64029
Value Function Update Magnitude: 0.70345
Collected Steps per Second: 12,422.56013
Overall Steps per Second: 6,875.27211
Timestep Collection Time: 4.02719
Timestep Consumption Time: 3.24932
PPO Batch Consumption Time: 0.23950
Total Iteration Time: 7.27651
Cumulative Model Updates: 6,864
Cumulative Timesteps: 38,217,196
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 38217196...
Checkpoint 38217196 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.81144
Policy Entropy: 3.68048
Value Function Loss: 0.26202
Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.64459
Value Function Update Magnitude: 0.71720
Collected Steps per Second: 11,275.37938
Overall Steps per Second: 6,481.03505
Timestep Collection Time: 4.43675
Timestep Consumption Time: 3.28208
PPO Batch Consumption Time: 0.23972
Total Iteration Time: 7.71883
Cumulative Model Updates: 6,873
Cumulative Timesteps: 38,267,222
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21459
Policy Entropy: 3.67959
Value Function Loss: 0.26479
Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.64056
Value Function Update Magnitude: 0.70791
Collected Steps per Second: 12,281.43108
Overall Steps per Second: 6,921.82392
Timestep Collection Time: 4.07396
Timestep Consumption Time: 3.15449
PPO Batch Consumption Time: 0.23782
Total Iteration Time: 7.22844
Cumulative Model Updates: 6,882
Cumulative Timesteps: 38,317,256
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 38317256...
Checkpoint 38317256 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56542
Policy Entropy: 3.68249
Value Function Loss: 0.26064
Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.63837
Value Function Update Magnitude: 0.67099
Collected Steps per Second: 12,919.66973
Overall Steps per Second: 7,114.85988
Timestep Collection Time: 3.87177
Timestep Consumption Time: 3.15887
PPO Batch Consumption Time: 0.23044
Total Iteration Time: 7.03064
Cumulative Model Updates: 6,891
Cumulative Timesteps: 38,367,278
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.08602
Policy Entropy: 3.68172
Value Function Loss: 0.25709
Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.63067
Value Function Update Magnitude: 0.65427
Collected Steps per Second: 12,773.31062
Overall Steps per Second: 7,083.76549
Timestep Collection Time: 3.91488
Timestep Consumption Time: 3.14436
PPO Batch Consumption Time: 0.23067
Total Iteration Time: 7.05924
Cumulative Model Updates: 6,900
Cumulative Timesteps: 38,417,284
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 38417284...
Checkpoint 38417284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53604
Policy Entropy: 3.68927
Value Function Loss: 0.26291
Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.63162
Value Function Update Magnitude: 0.62531
Collected Steps per Second: 13,109.60200
Overall Steps per Second: 7,176.81195
Timestep Collection Time: 3.81598
Timestep Consumption Time: 3.15452
PPO Batch Consumption Time: 0.22998
Total Iteration Time: 6.97050
Cumulative Model Updates: 6,909
Cumulative Timesteps: 38,467,310
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.88249
Policy Entropy: 3.68743
Value Function Loss: 0.27649
Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.64172
Value Function Update Magnitude: 0.64716
Collected Steps per Second: 12,940.94111
Overall Steps per Second: 7,128.08982
Timestep Collection Time: 3.86649
Timestep Consumption Time: 3.15306
PPO Batch Consumption Time: 0.23038
Total Iteration Time: 7.01955
Cumulative Model Updates: 6,918
Cumulative Timesteps: 38,517,346
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 38517346...
Checkpoint 38517346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.91559
Policy Entropy: 3.68793
Value Function Loss: 0.27689
Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.65101
Value Function Update Magnitude: 0.70583
Collected Steps per Second: 12,055.15238
Overall Steps per Second: 6,737.76840
Timestep Collection Time: 4.14976
Timestep Consumption Time: 3.27495
PPO Batch Consumption Time: 0.24466
Total Iteration Time: 7.42471
Cumulative Model Updates: 6,927
Cumulative Timesteps: 38,567,372
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.44042
Policy Entropy: 3.68758
Value Function Loss: 0.26695
Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11557
Policy Update Magnitude: 0.64761
Value Function Update Magnitude: 0.68881
Collected Steps per Second: 12,492.00872
Overall Steps per Second: 6,844.29841
Timestep Collection Time: 4.00624
Timestep Consumption Time: 3.30583
PPO Batch Consumption Time: 0.24365
Total Iteration Time: 7.31207
Cumulative Model Updates: 6,936
Cumulative Timesteps: 38,617,418
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 38617418...
Checkpoint 38617418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.62022
Policy Entropy: 3.69340
Value Function Loss: 0.26262
Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.64068
Value Function Update Magnitude: 0.69737
Collected Steps per Second: 12,408.12220
Overall Steps per Second: 6,914.64109
Timestep Collection Time: 4.02962
Timestep Consumption Time: 3.20141
PPO Batch Consumption Time: 0.23341
Total Iteration Time: 7.23103
Cumulative Model Updates: 6,945
Cumulative Timesteps: 38,667,418
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.32988
Policy Entropy: 3.69110
Value Function Loss: 0.26643
Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.63915
Value Function Update Magnitude: 0.71348
Collected Steps per Second: 12,866.43922
Overall Steps per Second: 7,198.14253
Timestep Collection Time: 3.88623
Timestep Consumption Time: 3.06028
PPO Batch Consumption Time: 0.23031
Total Iteration Time: 6.94651
Cumulative Model Updates: 6,954
Cumulative Timesteps: 38,717,420
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 38717420...
Checkpoint 38717420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.26371
Policy Entropy: 3.68431
Value Function Loss: 0.26874
Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.64229
Value Function Update Magnitude: 0.71764
Collected Steps per Second: 12,786.07867
Overall Steps per Second: 7,089.08172
Timestep Collection Time: 3.91066
Timestep Consumption Time: 3.14272
PPO Batch Consumption Time: 0.22962
Total Iteration Time: 7.05338
Cumulative Model Updates: 6,963
Cumulative Timesteps: 38,767,422
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.29963
Policy Entropy: 3.68312
Value Function Loss: 0.27216
Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.65036
Value Function Update Magnitude: 0.71426
Collected Steps per Second: 12,907.83114
Overall Steps per Second: 7,124.30751
Timestep Collection Time: 3.87377
Timestep Consumption Time: 3.14473
PPO Batch Consumption Time: 0.22971
Total Iteration Time: 7.01851
Cumulative Model Updates: 6,972
Cumulative Timesteps: 38,817,424
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 38817424...
Checkpoint 38817424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.40673
Policy Entropy: 3.67829
Value Function Loss: 0.26805
Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.65098
Value Function Update Magnitude: 0.71083
Collected Steps per Second: 12,996.30075
Overall Steps per Second: 7,131.58053
Timestep Collection Time: 3.84740
Timestep Consumption Time: 3.16395
PPO Batch Consumption Time: 0.23014
Total Iteration Time: 7.01135
Cumulative Model Updates: 6,981
Cumulative Timesteps: 38,867,426
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.28478
Policy Entropy: 3.67556
Value Function Loss: 0.26748
Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.64187
Value Function Update Magnitude: 0.69262
Collected Steps per Second: 12,914.53482
Overall Steps per Second: 7,100.82781
Timestep Collection Time: 3.87176
Timestep Consumption Time: 3.16995
PPO Batch Consumption Time: 0.23060
Total Iteration Time: 7.04171
Cumulative Model Updates: 6,990
Cumulative Timesteps: 38,917,428
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 38917428...
Checkpoint 38917428 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.02304
Policy Entropy: 3.67803
Value Function Loss: 0.28163
Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12400
Policy Update Magnitude: 0.63949
Value Function Update Magnitude: 0.70837
Collected Steps per Second: 12,923.54548
Overall Steps per Second: 7,206.08917
Timestep Collection Time: 3.87154
Timestep Consumption Time: 3.07176
PPO Batch Consumption Time: 0.23059
Total Iteration Time: 6.94329
Cumulative Model Updates: 6,999
Cumulative Timesteps: 38,967,462
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.92646
Policy Entropy: 3.68498
Value Function Loss: 0.28691
Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.64781
Value Function Update Magnitude: 0.75994
Collected Steps per Second: 12,803.62522
Overall Steps per Second: 6,916.71121
Timestep Collection Time: 3.90827
Timestep Consumption Time: 3.32638
PPO Batch Consumption Time: 0.24221
Total Iteration Time: 7.23465
Cumulative Model Updates: 7,008
Cumulative Timesteps: 39,017,502
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 39017502...
Checkpoint 39017502 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.69463
Policy Entropy: 3.68682
Value Function Loss: 0.28633
Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14871
Policy Update Magnitude: 0.64032
Value Function Update Magnitude: 0.72850
Collected Steps per Second: 12,790.92868
Overall Steps per Second: 7,114.01505
Timestep Collection Time: 3.91105
Timestep Consumption Time: 3.12098
PPO Batch Consumption Time: 0.22986
Total Iteration Time: 7.03203
Cumulative Model Updates: 7,017
Cumulative Timesteps: 39,067,528
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40734
Policy Entropy: 3.68941
Value Function Loss: 0.28858
Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.63812
Value Function Update Magnitude: 0.70212
Collected Steps per Second: 12,660.78861
Overall Steps per Second: 7,131.18934
Timestep Collection Time: 3.95204
Timestep Consumption Time: 3.06446
PPO Batch Consumption Time: 0.23109
Total Iteration Time: 7.01650
Cumulative Model Updates: 7,026
Cumulative Timesteps: 39,117,564
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 39117564...
Checkpoint 39117564 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.81855
Policy Entropy: 3.69107
Value Function Loss: 0.28267
Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.63292
Value Function Update Magnitude: 0.69857
Collected Steps per Second: 12,917.29219
Overall Steps per Second: 7,106.02198
Timestep Collection Time: 3.87233
Timestep Consumption Time: 3.16677
PPO Batch Consumption Time: 0.23045
Total Iteration Time: 7.03910
Cumulative Model Updates: 7,035
Cumulative Timesteps: 39,167,584
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 21.80751
Policy Entropy: 3.69354
Value Function Loss: 0.27731
Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.63534
Value Function Update Magnitude: 0.68582
Collected Steps per Second: 12,614.39408
Overall Steps per Second: 7,059.91654
Timestep Collection Time: 3.96515
Timestep Consumption Time: 3.11963
PPO Batch Consumption Time: 0.23004
Total Iteration Time: 7.08479
Cumulative Model Updates: 7,044
Cumulative Timesteps: 39,217,602
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 39217602...
Checkpoint 39217602 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.52148
Policy Entropy: 3.69162
Value Function Loss: 0.27603
Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.63231
Value Function Update Magnitude: 0.77616
Collected Steps per Second: 13,016.03727
Overall Steps per Second: 7,171.19740
Timestep Collection Time: 3.84403
Timestep Consumption Time: 3.13305
PPO Batch Consumption Time: 0.23041
Total Iteration Time: 6.97708
Cumulative Model Updates: 7,053
Cumulative Timesteps: 39,267,636
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54329
Policy Entropy: 3.68551
Value Function Loss: 0.26885
Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.63778
Value Function Update Magnitude: 0.76407
Collected Steps per Second: 12,906.92180
Overall Steps per Second: 7,076.02046
Timestep Collection Time: 3.87621
Timestep Consumption Time: 3.19414
PPO Batch Consumption Time: 0.23123
Total Iteration Time: 7.07036
Cumulative Model Updates: 7,062
Cumulative Timesteps: 39,317,666
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 39317666...
Checkpoint 39317666 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.41641
Policy Entropy: 3.68068
Value Function Loss: 0.27636
Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.64145
Value Function Update Magnitude: 0.71462
Collected Steps per Second: 12,843.48356
Overall Steps per Second: 7,125.54959
Timestep Collection Time: 3.89302
Timestep Consumption Time: 3.12398
PPO Batch Consumption Time: 0.23212
Total Iteration Time: 7.01700
Cumulative Model Updates: 7,071
Cumulative Timesteps: 39,367,666
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23236
Policy Entropy: 3.68607
Value Function Loss: 0.27655
Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.63679
Value Function Update Magnitude: 0.65455
Collected Steps per Second: 12,932.07560
Overall Steps per Second: 7,135.36273
Timestep Collection Time: 3.86728
Timestep Consumption Time: 3.14175
PPO Batch Consumption Time: 0.22996
Total Iteration Time: 7.00903
Cumulative Model Updates: 7,080
Cumulative Timesteps: 39,417,678
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 39417678...
Checkpoint 39417678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.26376
Policy Entropy: 3.68428
Value Function Loss: 0.28237
Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.63242
Value Function Update Magnitude: 0.66112
Collected Steps per Second: 11,580.85661
Overall Steps per Second: 6,524.27559
Timestep Collection Time: 4.31937
Timestep Consumption Time: 3.34769
PPO Batch Consumption Time: 0.24265
Total Iteration Time: 7.66706
Cumulative Model Updates: 7,089
Cumulative Timesteps: 39,467,700
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.17472
Policy Entropy: 3.68965
Value Function Loss: 0.27801
Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.63967
Value Function Update Magnitude: 0.67279
Collected Steps per Second: 12,488.30236
Overall Steps per Second: 7,064.85348
Timestep Collection Time: 4.00391
Timestep Consumption Time: 3.07366
PPO Batch Consumption Time: 0.23142
Total Iteration Time: 7.07757
Cumulative Model Updates: 7,098
Cumulative Timesteps: 39,517,702
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 39517702...
Checkpoint 39517702 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93185
Policy Entropy: 3.69422
Value Function Loss: 0.29056
Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.64164
Value Function Update Magnitude: 0.68357
Collected Steps per Second: 12,717.97418
Overall Steps per Second: 7,046.47111
Timestep Collection Time: 3.93160
Timestep Consumption Time: 3.16443
PPO Batch Consumption Time: 0.23288
Total Iteration Time: 7.09603
Cumulative Model Updates: 7,107
Cumulative Timesteps: 39,567,704
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.74536
Policy Entropy: 3.69645
Value Function Loss: 0.29719
Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.64498
Value Function Update Magnitude: 0.75382
Collected Steps per Second: 11,464.61854
Overall Steps per Second: 6,575.42081
Timestep Collection Time: 4.36438
Timestep Consumption Time: 3.24517
PPO Batch Consumption Time: 0.23594
Total Iteration Time: 7.60955
Cumulative Model Updates: 7,116
Cumulative Timesteps: 39,617,740
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 39617740...
Checkpoint 39617740 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97907
Policy Entropy: 3.69434
Value Function Loss: 0.30260
Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.65356
Value Function Update Magnitude: 0.83836
Collected Steps per Second: 12,492.50542
Overall Steps per Second: 6,910.02936
Timestep Collection Time: 4.00256
Timestep Consumption Time: 3.23359
PPO Batch Consumption Time: 0.23952
Total Iteration Time: 7.23615
Cumulative Model Updates: 7,125
Cumulative Timesteps: 39,667,742
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75171
Policy Entropy: 3.69355
Value Function Loss: 0.29419
Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.65957
Value Function Update Magnitude: 0.76576
Collected Steps per Second: 12,743.38144
Overall Steps per Second: 6,911.06513
Timestep Collection Time: 3.92580
Timestep Consumption Time: 3.31302
PPO Batch Consumption Time: 0.24244
Total Iteration Time: 7.23883
Cumulative Model Updates: 7,134
Cumulative Timesteps: 39,717,770
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 39717770...
Checkpoint 39717770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27446
Policy Entropy: 3.68676
Value Function Loss: 0.27704
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.65681
Value Function Update Magnitude: 0.75719
Collected Steps per Second: 11,747.58004
Overall Steps per Second: 6,751.84499
Timestep Collection Time: 4.25858
Timestep Consumption Time: 3.15095
PPO Batch Consumption Time: 0.23242
Total Iteration Time: 7.40953
Cumulative Model Updates: 7,143
Cumulative Timesteps: 39,767,798
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.73013
Policy Entropy: 3.68687
Value Function Loss: 0.27003
Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.64655
Value Function Update Magnitude: 0.71541
Collected Steps per Second: 11,488.55385
Overall Steps per Second: 6,626.22406
Timestep Collection Time: 4.35425
Timestep Consumption Time: 3.19515
PPO Batch Consumption Time: 0.23266
Total Iteration Time: 7.54940
Cumulative Model Updates: 7,152
Cumulative Timesteps: 39,817,822
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 39817822...
Checkpoint 39817822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05444
Policy Entropy: 3.68327
Value Function Loss: 0.26743
Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.66221
Value Function Update Magnitude: 0.73493
Collected Steps per Second: 11,647.14130
Overall Steps per Second: 6,649.26846
Timestep Collection Time: 4.29513
Timestep Consumption Time: 3.22840
PPO Batch Consumption Time: 0.23988
Total Iteration Time: 7.52353
Cumulative Model Updates: 7,161
Cumulative Timesteps: 39,867,848
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41097
Policy Entropy: 3.67747
Value Function Loss: 0.27845
Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.66893
Value Function Update Magnitude: 0.72900
Collected Steps per Second: 10,940.51817
Overall Steps per Second: 6,454.36035
Timestep Collection Time: 4.57437
Timestep Consumption Time: 3.17946
PPO Batch Consumption Time: 0.24130
Total Iteration Time: 7.75383
Cumulative Model Updates: 7,170
Cumulative Timesteps: 39,917,894
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 39917894...
Checkpoint 39917894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54765
Policy Entropy: 3.67988
Value Function Loss: 0.28336
Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.67742
Value Function Update Magnitude: 0.74331
Collected Steps per Second: 11,575.84397
Overall Steps per Second: 6,593.81143
Timestep Collection Time: 4.32124
Timestep Consumption Time: 3.26496
PPO Batch Consumption Time: 0.23706
Total Iteration Time: 7.58620
Cumulative Model Updates: 7,179
Cumulative Timesteps: 39,967,916
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.22675
Policy Entropy: 3.67834
Value Function Loss: 0.26797
Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11990
Policy Update Magnitude: 0.66754
Value Function Update Magnitude: 0.72454
Collected Steps per Second: 12,273.47829
Overall Steps per Second: 6,832.88443
Timestep Collection Time: 4.07480
Timestep Consumption Time: 3.24451
PPO Batch Consumption Time: 0.24016
Total Iteration Time: 7.31931
Cumulative Model Updates: 7,188
Cumulative Timesteps: 40,017,928
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 40017928...
Checkpoint 40017928 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.00234
Policy Entropy: 3.68394
Value Function Loss: 0.27613
Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.65459
Value Function Update Magnitude: 0.72039
Collected Steps per Second: 11,472.95574
Overall Steps per Second: 6,603.01401
Timestep Collection Time: 4.36139
Timestep Consumption Time: 3.21667
PPO Batch Consumption Time: 0.23632
Total Iteration Time: 7.57805
Cumulative Model Updates: 7,197
Cumulative Timesteps: 40,067,966
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.16377
Policy Entropy: 3.68302
Value Function Loss: 0.28225
Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.65986
Value Function Update Magnitude: 0.73060
Collected Steps per Second: 12,102.92788
Overall Steps per Second: 6,781.03219
Timestep Collection Time: 4.13239
Timestep Consumption Time: 3.24318
PPO Batch Consumption Time: 0.23618
Total Iteration Time: 7.37557
Cumulative Model Updates: 7,206
Cumulative Timesteps: 40,117,980
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 40117980...
Checkpoint 40117980 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.98473
Policy Entropy: 3.68215
Value Function Loss: 0.30380
Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.68430
Value Function Update Magnitude: 0.75008
Collected Steps per Second: 12,001.03291
Overall Steps per Second: 6,795.98972
Timestep Collection Time: 4.16647
Timestep Consumption Time: 3.19110
PPO Batch Consumption Time: 0.23643
Total Iteration Time: 7.35757
Cumulative Model Updates: 7,215
Cumulative Timesteps: 40,167,982
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.76015
Policy Entropy: 3.68399
Value Function Loss: 0.29465
Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.68318
Value Function Update Magnitude: 0.75335
Collected Steps per Second: 12,149.36198
Overall Steps per Second: 6,759.65356
Timestep Collection Time: 4.11594
Timestep Consumption Time: 3.28178
PPO Batch Consumption Time: 0.23678
Total Iteration Time: 7.39772
Cumulative Model Updates: 7,224
Cumulative Timesteps: 40,217,988
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 40217988...
Checkpoint 40217988 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30966
Policy Entropy: 3.68063
Value Function Loss: 0.29157
Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.66329
Value Function Update Magnitude: 0.76493
Collected Steps per Second: 12,330.30333
Overall Steps per Second: 6,869.69822
Timestep Collection Time: 4.05651
Timestep Consumption Time: 3.22445
PPO Batch Consumption Time: 0.23575
Total Iteration Time: 7.28096
Cumulative Model Updates: 7,233
Cumulative Timesteps: 40,268,006
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.57890
Policy Entropy: 3.68038
Value Function Loss: 0.28850
Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12945
Policy Update Magnitude: 0.66203
Value Function Update Magnitude: 0.72936
Collected Steps per Second: 12,273.62246
Overall Steps per Second: 6,947.36205
Timestep Collection Time: 4.07687
Timestep Consumption Time: 3.12557
PPO Batch Consumption Time: 0.23531
Total Iteration Time: 7.20245
Cumulative Model Updates: 7,242
Cumulative Timesteps: 40,318,044
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 40318044...
Checkpoint 40318044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60018
Policy Entropy: 3.68073
Value Function Loss: 0.28583
Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.65733
Value Function Update Magnitude: 0.74390
Collected Steps per Second: 12,475.13119
Overall Steps per Second: 6,788.01650
Timestep Collection Time: 4.01150
Timestep Consumption Time: 3.36090
PPO Batch Consumption Time: 0.24649
Total Iteration Time: 7.37240
Cumulative Model Updates: 7,251
Cumulative Timesteps: 40,368,088
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.09852
Policy Entropy: 3.67788
Value Function Loss: 0.29026
Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.65166
Value Function Update Magnitude: 0.72495
Collected Steps per Second: 12,276.85270
Overall Steps per Second: 6,898.83797
Timestep Collection Time: 4.07368
Timestep Consumption Time: 3.17565
PPO Batch Consumption Time: 0.23531
Total Iteration Time: 7.24934
Cumulative Model Updates: 7,260
Cumulative Timesteps: 40,418,100
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 40418100...
Checkpoint 40418100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.82784
Policy Entropy: 3.67985
Value Function Loss: 0.27730
Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.64778
Value Function Update Magnitude: 0.72763
Collected Steps per Second: 12,378.91715
Overall Steps per Second: 6,903.97608
Timestep Collection Time: 4.03961
Timestep Consumption Time: 3.20346
PPO Batch Consumption Time: 0.23571
Total Iteration Time: 7.24307
Cumulative Model Updates: 7,269
Cumulative Timesteps: 40,468,106
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.63257
Policy Entropy: 3.68239
Value Function Loss: 0.26859
Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.64148
Value Function Update Magnitude: 0.71511
Collected Steps per Second: 12,497.90455
Overall Steps per Second: 6,911.88759
Timestep Collection Time: 4.00451
Timestep Consumption Time: 3.23635
PPO Batch Consumption Time: 0.23611
Total Iteration Time: 7.24086
Cumulative Model Updates: 7,278
Cumulative Timesteps: 40,518,154
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 40518154...
Checkpoint 40518154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31578
Policy Entropy: 3.68141
Value Function Loss: 0.27359
Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.63860
Value Function Update Magnitude: 0.70596
Collected Steps per Second: 12,331.32267
Overall Steps per Second: 6,886.08666
Timestep Collection Time: 4.05585
Timestep Consumption Time: 3.20720
PPO Batch Consumption Time: 0.23675
Total Iteration Time: 7.26305
Cumulative Model Updates: 7,287
Cumulative Timesteps: 40,568,168
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.72029
Policy Entropy: 3.68412
Value Function Loss: 0.27560
Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.64333
Value Function Update Magnitude: 0.74216
Collected Steps per Second: 12,705.17744
Overall Steps per Second: 6,956.95799
Timestep Collection Time: 3.93619
Timestep Consumption Time: 3.25230
PPO Batch Consumption Time: 0.23699
Total Iteration Time: 7.18849
Cumulative Model Updates: 7,296
Cumulative Timesteps: 40,618,178
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 40618178...
Checkpoint 40618178 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61628
Policy Entropy: 3.68498
Value Function Loss: 0.27271
Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.64097
Value Function Update Magnitude: 0.74782
Collected Steps per Second: 12,120.28258
Overall Steps per Second: 6,797.66183
Timestep Collection Time: 4.12845
Timestep Consumption Time: 3.23261
PPO Batch Consumption Time: 0.23652
Total Iteration Time: 7.36106
Cumulative Model Updates: 7,305
Cumulative Timesteps: 40,668,216
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 22.73051
Policy Entropy: 3.68551
Value Function Loss: 0.29335
Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.64187
Value Function Update Magnitude: 0.79025
Collected Steps per Second: 12,889.43647
Overall Steps per Second: 7,223.74435
Timestep Collection Time: 3.88070
Timestep Consumption Time: 3.04369
PPO Batch Consumption Time: 0.22994
Total Iteration Time: 6.92439
Cumulative Model Updates: 7,314
Cumulative Timesteps: 40,718,236
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 40718236...
Checkpoint 40718236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29922
Policy Entropy: 3.67816
Value Function Loss: 0.28869
Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.64694
Value Function Update Magnitude: 1.05757
Collected Steps per Second: 12,822.30895
Overall Steps per Second: 7,123.90847
Timestep Collection Time: 3.90226
Timestep Consumption Time: 3.12141
PPO Batch Consumption Time: 0.23032
Total Iteration Time: 7.02367
Cumulative Model Updates: 7,323
Cumulative Timesteps: 40,768,272
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.72851
Policy Entropy: 3.67731
Value Function Loss: 0.29348
Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.65464
Value Function Update Magnitude: 0.81912
Collected Steps per Second: 12,813.76783
Overall Steps per Second: 7,109.81793
Timestep Collection Time: 3.90299
Timestep Consumption Time: 3.13123
PPO Batch Consumption Time: 0.22982
Total Iteration Time: 7.03422
Cumulative Model Updates: 7,332
Cumulative Timesteps: 40,818,284
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 40818284...
Checkpoint 40818284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97676
Policy Entropy: 3.67708
Value Function Loss: 0.28655
Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.65554
Value Function Update Magnitude: 0.76736
Collected Steps per Second: 13,021.59315
Overall Steps per Second: 7,119.85814
Timestep Collection Time: 3.84208
Timestep Consumption Time: 3.18475
PPO Batch Consumption Time: 0.23064
Total Iteration Time: 7.02683
Cumulative Model Updates: 7,341
Cumulative Timesteps: 40,868,314
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23391
Policy Entropy: 3.67416
Value Function Loss: 0.28681
Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11346
Policy Update Magnitude: 0.66053
Value Function Update Magnitude: 0.79789
Collected Steps per Second: 12,856.78629
Overall Steps per Second: 7,099.45133
Timestep Collection Time: 3.89071
Timestep Consumption Time: 3.15519
PPO Batch Consumption Time: 0.23034
Total Iteration Time: 7.04590
Cumulative Model Updates: 7,350
Cumulative Timesteps: 40,918,336
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 40918336...
Checkpoint 40918336 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.71138
Policy Entropy: 3.67914
Value Function Loss: 0.29084
Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.66630
Value Function Update Magnitude: 0.75495
Collected Steps per Second: 12,294.59315
Overall Steps per Second: 6,798.61662
Timestep Collection Time: 4.06715
Timestep Consumption Time: 3.28787
PPO Batch Consumption Time: 0.23816
Total Iteration Time: 7.35503
Cumulative Model Updates: 7,359
Cumulative Timesteps: 40,968,340
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38032
Policy Entropy: 3.67944
Value Function Loss: 0.28916
Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.67595
Value Function Update Magnitude: 0.75628
Collected Steps per Second: 12,195.54716
Overall Steps per Second: 6,673.72537
Timestep Collection Time: 4.10133
Timestep Consumption Time: 3.39343
PPO Batch Consumption Time: 0.24932
Total Iteration Time: 7.49476
Cumulative Model Updates: 7,368
Cumulative Timesteps: 41,018,358
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 41018358...
Checkpoint 41018358 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56558
Policy Entropy: 3.68361
Value Function Loss: 0.28405
Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.66915
Value Function Update Magnitude: 0.77204
Collected Steps per Second: 12,112.75275
Overall Steps per Second: 6,792.87507
Timestep Collection Time: 4.13069
Timestep Consumption Time: 3.23497
PPO Batch Consumption Time: 0.23590
Total Iteration Time: 7.36566
Cumulative Model Updates: 7,377
Cumulative Timesteps: 41,068,392
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.08771
Policy Entropy: 3.68222
Value Function Loss: 0.28150
Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.66305
Value Function Update Magnitude: 0.69985
Collected Steps per Second: 12,235.09116
Overall Steps per Second: 6,927.65814
Timestep Collection Time: 4.08775
Timestep Consumption Time: 3.13172
PPO Batch Consumption Time: 0.23627
Total Iteration Time: 7.21947
Cumulative Model Updates: 7,386
Cumulative Timesteps: 41,118,406
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 41118406...
Checkpoint 41118406 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.34987
Policy Entropy: 3.67909
Value Function Loss: 0.28668
Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.66649
Value Function Update Magnitude: 0.66523
Collected Steps per Second: 12,408.83151
Overall Steps per Second: 6,868.99032
Timestep Collection Time: 4.03374
Timestep Consumption Time: 3.25321
PPO Batch Consumption Time: 0.23727
Total Iteration Time: 7.28695
Cumulative Model Updates: 7,395
Cumulative Timesteps: 41,168,460
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.62708
Policy Entropy: 3.68419
Value Function Loss: 0.28797
Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.66364
Value Function Update Magnitude: 0.66342
Collected Steps per Second: 12,414.36948
Overall Steps per Second: 6,936.27576
Timestep Collection Time: 4.03307
Timestep Consumption Time: 3.18521
PPO Batch Consumption Time: 0.23589
Total Iteration Time: 7.21828
Cumulative Model Updates: 7,404
Cumulative Timesteps: 41,218,528
Timesteps Collected: 50,068
--------END ITERATION REPORT--------
Saving checkpoint 41218528...
Checkpoint 41218528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.97019
Policy Entropy: 3.67580
Value Function Loss: 0.29592
Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.66352
Value Function Update Magnitude: 0.68174
Collected Steps per Second: 12,509.25338
Overall Steps per Second: 6,940.71914
Timestep Collection Time: 3.99800
Timestep Consumption Time: 3.20759
PPO Batch Consumption Time: 0.23553
Total Iteration Time: 7.20559
Cumulative Model Updates: 7,413
Cumulative Timesteps: 41,268,540
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.61488
Policy Entropy: 3.67549
Value Function Loss: 0.28951
Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.66800
Value Function Update Magnitude: 0.72233
Collected Steps per Second: 12,192.14196
Overall Steps per Second: 6,771.28515
Timestep Collection Time: 4.10215
Timestep Consumption Time: 3.28404
PPO Batch Consumption Time: 0.23688
Total Iteration Time: 7.38619
Cumulative Model Updates: 7,422
Cumulative Timesteps: 41,318,554
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 41318554...
Checkpoint 41318554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.76996
Policy Entropy: 3.67601
Value Function Loss: 0.29293
Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.66836
Value Function Update Magnitude: 0.72533
Collected Steps per Second: 12,368.88946
Overall Steps per Second: 6,891.09778
Timestep Collection Time: 4.04240
Timestep Consumption Time: 3.21334
PPO Batch Consumption Time: 0.23525
Total Iteration Time: 7.25574
Cumulative Model Updates: 7,431
Cumulative Timesteps: 41,368,554
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10625
Policy Entropy: 3.68656
Value Function Loss: 0.28184
Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.65908
Value Function Update Magnitude: 0.73756
Collected Steps per Second: 12,642.36918
Overall Steps per Second: 6,965.36567
Timestep Collection Time: 3.95527
Timestep Consumption Time: 3.22368
PPO Batch Consumption Time: 0.23536
Total Iteration Time: 7.17895
Cumulative Model Updates: 7,440
Cumulative Timesteps: 41,418,558
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 41418558...
Checkpoint 41418558 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.75753
Policy Entropy: 3.68792
Value Function Loss: 0.29385
Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.66079
Value Function Update Magnitude: 0.72274
Collected Steps per Second: 12,343.66271
Overall Steps per Second: 6,875.08644
Timestep Collection Time: 4.05277
Timestep Consumption Time: 3.22365
PPO Batch Consumption Time: 0.23612
Total Iteration Time: 7.27642
Cumulative Model Updates: 7,449
Cumulative Timesteps: 41,468,584
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43045
Policy Entropy: 3.68597
Value Function Loss: 0.28472
Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.65886
Value Function Update Magnitude: 0.70884
Collected Steps per Second: 12,245.49103
Overall Steps per Second: 6,930.36009
Timestep Collection Time: 4.08461
Timestep Consumption Time: 3.13262
PPO Batch Consumption Time: 0.23625
Total Iteration Time: 7.21723
Cumulative Model Updates: 7,458
Cumulative Timesteps: 41,518,602
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 41518602...
Checkpoint 41518602 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.15830
Policy Entropy: 3.67548
Value Function Loss: 0.29057
Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11590
Policy Update Magnitude: 0.65702
Value Function Update Magnitude: 0.68576
Collected Steps per Second: 12,147.80634
Overall Steps per Second: 6,811.65166
Timestep Collection Time: 4.11696
Timestep Consumption Time: 3.22517
PPO Batch Consumption Time: 0.23706
Total Iteration Time: 7.34213
Cumulative Model Updates: 7,467
Cumulative Timesteps: 41,568,614
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.52287
Policy Entropy: 3.67711
Value Function Loss: 0.28459
Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.65376
Value Function Update Magnitude: 0.69847
Collected Steps per Second: 12,199.38289
Overall Steps per Second: 6,850.59524
Timestep Collection Time: 4.10021
Timestep Consumption Time: 3.20135
PPO Batch Consumption Time: 0.23554
Total Iteration Time: 7.30156
Cumulative Model Updates: 7,476
Cumulative Timesteps: 41,618,634
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 41618634...
Checkpoint 41618634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.22273
Policy Entropy: 3.67273
Value Function Loss: 0.28578
Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.64776
Value Function Update Magnitude: 0.67368
Collected Steps per Second: 12,569.60241
Overall Steps per Second: 6,823.15928
Timestep Collection Time: 3.97944
Timestep Consumption Time: 3.35147
PPO Batch Consumption Time: 0.24630
Total Iteration Time: 7.33091
Cumulative Model Updates: 7,485
Cumulative Timesteps: 41,668,654
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.47131
Policy Entropy: 3.67482
Value Function Loss: 0.28950
Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.64312
Value Function Update Magnitude: 0.67459
Collected Steps per Second: 12,287.97037
Overall Steps per Second: 6,855.49543
Timestep Collection Time: 4.07162
Timestep Consumption Time: 3.22646
PPO Batch Consumption Time: 0.23524
Total Iteration Time: 7.29809
Cumulative Model Updates: 7,494
Cumulative Timesteps: 41,718,686
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 41718686...
Checkpoint 41718686 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.11664
Policy Entropy: 3.67780
Value Function Loss: 0.29506
Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.65022
Value Function Update Magnitude: 0.70751
Collected Steps per Second: 12,336.79834
Overall Steps per Second: 6,911.82219
Timestep Collection Time: 4.05486
Timestep Consumption Time: 3.18259
PPO Batch Consumption Time: 0.23536
Total Iteration Time: 7.23745
Cumulative Model Updates: 7,503
Cumulative Timesteps: 41,768,710
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.94018
Policy Entropy: 3.67885
Value Function Loss: 0.29869
Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.65318
Value Function Update Magnitude: 0.75570
Collected Steps per Second: 12,883.57311
Overall Steps per Second: 7,011.52298
Timestep Collection Time: 3.88153
Timestep Consumption Time: 3.25073
PPO Batch Consumption Time: 0.23666
Total Iteration Time: 7.13226
Cumulative Model Updates: 7,512
Cumulative Timesteps: 41,818,718
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 41818718...
Checkpoint 41818718 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97954
Policy Entropy: 3.67862
Value Function Loss: 0.29412
Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.65101
Value Function Update Magnitude: 0.77091
Collected Steps per Second: 10,958.20815
Overall Steps per Second: 6,354.50250
Timestep Collection Time: 4.56334
Timestep Consumption Time: 3.30604
PPO Batch Consumption Time: 0.24233
Total Iteration Time: 7.86938
Cumulative Model Updates: 7,521
Cumulative Timesteps: 41,868,724
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.84883
Policy Entropy: 3.67362
Value Function Loss: 0.28087
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11836
Policy Update Magnitude: 0.65372
Value Function Update Magnitude: 0.76917
Collected Steps per Second: 11,251.24212
Overall Steps per Second: 6,629.36076
Timestep Collection Time: 4.44431
Timestep Consumption Time: 3.09850
PPO Batch Consumption Time: 0.22958
Total Iteration Time: 7.54281
Cumulative Model Updates: 7,530
Cumulative Timesteps: 41,918,728
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 41918728...
Checkpoint 41918728 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.47485
Policy Entropy: 3.67688
Value Function Loss: 0.27210
Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.65443
Value Function Update Magnitude: 0.82491
Collected Steps per Second: 12,000.95270
Overall Steps per Second: 6,709.60047
Timestep Collection Time: 4.16667
Timestep Consumption Time: 3.28594
PPO Batch Consumption Time: 0.23897
Total Iteration Time: 7.45260
Cumulative Model Updates: 7,539
Cumulative Timesteps: 41,968,732
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64944
Policy Entropy: 3.66739
Value Function Loss: 0.27671
Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.66388
Value Function Update Magnitude: 0.77494
Collected Steps per Second: 11,442.55642
Overall Steps per Second: 6,650.71331
Timestep Collection Time: 4.36983
Timestep Consumption Time: 3.14846
PPO Batch Consumption Time: 0.23085
Total Iteration Time: 7.51829
Cumulative Model Updates: 7,548
Cumulative Timesteps: 42,018,734
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 42018734...
Checkpoint 42018734 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.94671
Policy Entropy: 3.66759
Value Function Loss: 0.28831
Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.67688
Value Function Update Magnitude: 0.71435
Collected Steps per Second: 12,143.16530
Overall Steps per Second: 6,731.38981
Timestep Collection Time: 4.12100
Timestep Consumption Time: 3.31312
PPO Batch Consumption Time: 0.23705
Total Iteration Time: 7.43413
Cumulative Model Updates: 7,557
Cumulative Timesteps: 42,068,776
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.58559
Policy Entropy: 3.66248
Value Function Loss: 0.28281
Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.67339
Value Function Update Magnitude: 0.70139
Collected Steps per Second: 12,338.16398
Overall Steps per Second: 6,843.56285
Timestep Collection Time: 4.05328
Timestep Consumption Time: 3.25432
PPO Batch Consumption Time: 0.23756
Total Iteration Time: 7.30760
Cumulative Model Updates: 7,566
Cumulative Timesteps: 42,118,786
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 42118786...
Checkpoint 42118786 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.96189
Policy Entropy: 3.66864
Value Function Loss: 0.28253
Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.66494
Value Function Update Magnitude: 0.75050
Collected Steps per Second: 11,009.73606
Overall Steps per Second: 6,351.97031
Timestep Collection Time: 4.54543
Timestep Consumption Time: 3.33307
PPO Batch Consumption Time: 0.23857
Total Iteration Time: 7.87850
Cumulative Model Updates: 7,575
Cumulative Timesteps: 42,168,830
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.75853
Policy Entropy: 3.66342
Value Function Loss: 0.28058
Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.65897
Value Function Update Magnitude: 0.74972
Collected Steps per Second: 12,798.15411
Overall Steps per Second: 7,078.22769
Timestep Collection Time: 3.90853
Timestep Consumption Time: 3.15849
PPO Batch Consumption Time: 0.22958
Total Iteration Time: 7.06702
Cumulative Model Updates: 7,584
Cumulative Timesteps: 42,218,852
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 42218852...
Checkpoint 42218852 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05050
Policy Entropy: 3.66160
Value Function Loss: 0.27996
Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.66788
Value Function Update Magnitude: 0.78266
Collected Steps per Second: 12,806.66553
Overall Steps per Second: 7,042.07035
Timestep Collection Time: 3.90672
Timestep Consumption Time: 3.19801
PPO Batch Consumption Time: 0.23775
Total Iteration Time: 7.10473
Cumulative Model Updates: 7,593
Cumulative Timesteps: 42,268,884
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.03951
Policy Entropy: 3.65692
Value Function Loss: 0.29217
Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.67363
Value Function Update Magnitude: 0.76787
Collected Steps per Second: 12,367.52929
Overall Steps per Second: 6,973.04837
Timestep Collection Time: 4.04543
Timestep Consumption Time: 3.12962
PPO Batch Consumption Time: 0.23248
Total Iteration Time: 7.17505
Cumulative Model Updates: 7,602
Cumulative Timesteps: 42,318,916
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 42318916...
Checkpoint 42318916 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.88972
Policy Entropy: 3.65844
Value Function Loss: 0.28789
Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.67156
Value Function Update Magnitude: 0.75241
Collected Steps per Second: 11,612.66640
Overall Steps per Second: 6,697.01413
Timestep Collection Time: 4.30857
Timestep Consumption Time: 3.16252
PPO Batch Consumption Time: 0.23187
Total Iteration Time: 7.47109
Cumulative Model Updates: 7,611
Cumulative Timesteps: 42,368,950
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.27909
Policy Entropy: 3.65156
Value Function Loss: 0.30633
Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.67742
Value Function Update Magnitude: 0.82708
Collected Steps per Second: 12,673.86249
Overall Steps per Second: 6,854.15975
Timestep Collection Time: 3.94734
Timestep Consumption Time: 3.35159
PPO Batch Consumption Time: 0.24131
Total Iteration Time: 7.29893
Cumulative Model Updates: 7,620
Cumulative Timesteps: 42,418,978
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 42418978...
Checkpoint 42418978 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.96057
Policy Entropy: 3.65344
Value Function Loss: 0.32098
Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14142
Policy Update Magnitude: 0.68777
Value Function Update Magnitude: 0.79682
Collected Steps per Second: 12,822.06724
Overall Steps per Second: 7,081.07375
Timestep Collection Time: 3.90202
Timestep Consumption Time: 3.16357
PPO Batch Consumption Time: 0.23111
Total Iteration Time: 7.06560
Cumulative Model Updates: 7,629
Cumulative Timesteps: 42,469,010
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75030
Policy Entropy: 3.65120
Value Function Loss: 0.32456
Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.16418
Policy Update Magnitude: 0.68163
Value Function Update Magnitude: 0.75209
Collected Steps per Second: 12,882.79995
Overall Steps per Second: 7,099.13827
Timestep Collection Time: 3.88534
Timestep Consumption Time: 3.16538
PPO Batch Consumption Time: 0.23029
Total Iteration Time: 7.05071
Cumulative Model Updates: 7,638
Cumulative Timesteps: 42,519,064
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 42519064...
Checkpoint 42519064 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.02811
Policy Entropy: 3.65836
Value Function Loss: 0.31668
Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15984
Policy Update Magnitude: 0.66395
Value Function Update Magnitude: 0.77331
Collected Steps per Second: 12,731.71250
Overall Steps per Second: 7,083.82777
Timestep Collection Time: 3.92940
Timestep Consumption Time: 3.13288
PPO Batch Consumption Time: 0.22946
Total Iteration Time: 7.06228
Cumulative Model Updates: 7,647
Cumulative Timesteps: 42,569,092
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.36154
Policy Entropy: 3.66730
Value Function Loss: 0.31092
Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.67050
Value Function Update Magnitude: 0.73883
Collected Steps per Second: 13,311.69870
Overall Steps per Second: 7,240.49859
Timestep Collection Time: 3.75805
Timestep Consumption Time: 3.15114
PPO Batch Consumption Time: 0.22996
Total Iteration Time: 6.90919
Cumulative Model Updates: 7,656
Cumulative Timesteps: 42,619,118
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 42619118...
Checkpoint 42619118 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.68027
Policy Entropy: 3.66492
Value Function Loss: 0.30165
Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.66998
Value Function Update Magnitude: 0.74425
Collected Steps per Second: 12,873.30407
Overall Steps per Second: 6,950.60278
Timestep Collection Time: 3.88540
Timestep Consumption Time: 3.31081
PPO Batch Consumption Time: 0.24049
Total Iteration Time: 7.19621
Cumulative Model Updates: 7,665
Cumulative Timesteps: 42,669,136
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.11904
Policy Entropy: 3.66415
Value Function Loss: 0.29190
Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.66708
Value Function Update Magnitude: 0.70628
Collected Steps per Second: 12,876.74965
Overall Steps per Second: 7,207.51838
Timestep Collection Time: 3.88405
Timestep Consumption Time: 3.05509
PPO Batch Consumption Time: 0.22994
Total Iteration Time: 6.93914
Cumulative Model Updates: 7,674
Cumulative Timesteps: 42,719,150
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 42719150...
Checkpoint 42719150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.13249
Policy Entropy: 3.66450
Value Function Loss: 0.28093
Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.65764
Value Function Update Magnitude: 0.69758
Collected Steps per Second: 12,719.37424
Overall Steps per Second: 7,006.98146
Timestep Collection Time: 3.93258
Timestep Consumption Time: 3.20601
PPO Batch Consumption Time: 0.23547
Total Iteration Time: 7.13859
Cumulative Model Updates: 7,683
Cumulative Timesteps: 42,769,170
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76008
Policy Entropy: 3.67424
Value Function Loss: 0.28598
Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.64825
Value Function Update Magnitude: 0.67412
Collected Steps per Second: 12,642.24771
Overall Steps per Second: 6,958.88784
Timestep Collection Time: 3.95752
Timestep Consumption Time: 3.23213
PPO Batch Consumption Time: 0.23858
Total Iteration Time: 7.18965
Cumulative Model Updates: 7,692
Cumulative Timesteps: 42,819,202
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 42819202...
Checkpoint 42819202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.47589
Policy Entropy: 3.67220
Value Function Loss: 0.29184
Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.65781
Value Function Update Magnitude: 0.68867
Collected Steps per Second: 12,755.37793
Overall Steps per Second: 7,012.20609
Timestep Collection Time: 3.92054
Timestep Consumption Time: 3.21102
PPO Batch Consumption Time: 0.23120
Total Iteration Time: 7.13156
Cumulative Model Updates: 7,701
Cumulative Timesteps: 42,869,210
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.90736
Policy Entropy: 3.67147
Value Function Loss: 0.28969
Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.66501
Value Function Update Magnitude: 0.69266
Collected Steps per Second: 11,899.95199
Overall Steps per Second: 6,792.00068
Timestep Collection Time: 4.20287
Timestep Consumption Time: 3.16079
PPO Batch Consumption Time: 0.22951
Total Iteration Time: 7.36366
Cumulative Model Updates: 7,710
Cumulative Timesteps: 42,919,224
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 42919224...
Checkpoint 42919224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67274
Policy Entropy: 3.66747
Value Function Loss: 0.28377
Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.67141
Value Function Update Magnitude: 0.73997
Collected Steps per Second: 12,789.68341
Overall Steps per Second: 7,095.03905
Timestep Collection Time: 3.91143
Timestep Consumption Time: 3.13941
PPO Batch Consumption Time: 0.23054
Total Iteration Time: 7.05084
Cumulative Model Updates: 7,719
Cumulative Timesteps: 42,969,250
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.94298
Policy Entropy: 3.66541
Value Function Loss: 0.28540
Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.66275
Value Function Update Magnitude: 0.73291
Collected Steps per Second: 13,044.26004
Overall Steps per Second: 7,140.68989
Timestep Collection Time: 3.83571
Timestep Consumption Time: 3.17118
PPO Batch Consumption Time: 0.23201
Total Iteration Time: 7.00689
Cumulative Model Updates: 7,728
Cumulative Timesteps: 43,019,284
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 43019284...
Checkpoint 43019284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.03402
Policy Entropy: 3.66272
Value Function Loss: 0.28389
Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11687
Policy Update Magnitude: 0.66077
Value Function Update Magnitude: 0.76167
Collected Steps per Second: 12,982.05854
Overall Steps per Second: 7,112.34094
Timestep Collection Time: 3.85224
Timestep Consumption Time: 3.17920
PPO Batch Consumption Time: 0.23013
Total Iteration Time: 7.03144
Cumulative Model Updates: 7,737
Cumulative Timesteps: 43,069,294
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97962
Policy Entropy: 3.67122
Value Function Loss: 0.28278
Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.65526
Value Function Update Magnitude: 0.71084
Collected Steps per Second: 12,761.31222
Overall Steps per Second: 7,164.13130
Timestep Collection Time: 3.92029
Timestep Consumption Time: 3.06284
PPO Batch Consumption Time: 0.22956
Total Iteration Time: 6.98312
Cumulative Model Updates: 7,746
Cumulative Timesteps: 43,119,322
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 43119322...
Checkpoint 43119322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.00364
Policy Entropy: 3.67154
Value Function Loss: 0.27390
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.65786
Value Function Update Magnitude: 1.02710
Collected Steps per Second: 12,852.28522
Overall Steps per Second: 7,104.38869
Timestep Collection Time: 3.89114
Timestep Consumption Time: 3.14817
PPO Batch Consumption Time: 0.23043
Total Iteration Time: 7.03931
Cumulative Model Updates: 7,755
Cumulative Timesteps: 43,169,332
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.86532
Policy Entropy: 3.66987
Value Function Loss: 0.26314
Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.65318
Value Function Update Magnitude: 0.96095
Collected Steps per Second: 12,867.26696
Overall Steps per Second: 7,117.28028
Timestep Collection Time: 3.88832
Timestep Consumption Time: 3.14134
PPO Batch Consumption Time: 0.23046
Total Iteration Time: 7.02965
Cumulative Model Updates: 7,764
Cumulative Timesteps: 43,219,364
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 43219364...
Checkpoint 43219364 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.28313
Policy Entropy: 3.66343
Value Function Loss: 0.27038
Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.65626
Value Function Update Magnitude: 0.76083
Collected Steps per Second: 13,027.97776
Overall Steps per Second: 7,134.07085
Timestep Collection Time: 3.84004
Timestep Consumption Time: 3.17250
PPO Batch Consumption Time: 0.23030
Total Iteration Time: 7.01255
Cumulative Model Updates: 7,773
Cumulative Timesteps: 43,269,392
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.53161
Policy Entropy: 3.65468
Value Function Loss: 0.29203
Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.65963
Value Function Update Magnitude: 0.72206
Collected Steps per Second: 12,922.46493
Overall Steps per Second: 7,106.23871
Timestep Collection Time: 3.87000
Timestep Consumption Time: 3.16747
PPO Batch Consumption Time: 0.22981
Total Iteration Time: 7.03748
Cumulative Model Updates: 7,782
Cumulative Timesteps: 43,319,402
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 43319402...
Checkpoint 43319402 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23679
Policy Entropy: 3.65325
Value Function Loss: 0.29589
Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.67233
Value Function Update Magnitude: 0.75523
Collected Steps per Second: 12,829.07837
Overall Steps per Second: 6,967.13903
Timestep Collection Time: 3.89740
Timestep Consumption Time: 3.27915
PPO Batch Consumption Time: 0.24172
Total Iteration Time: 7.17655
Cumulative Model Updates: 7,791
Cumulative Timesteps: 43,369,402
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.32498
Policy Entropy: 3.66205
Value Function Loss: 0.31959
Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.68756
Value Function Update Magnitude: 0.71855
Collected Steps per Second: 13,199.71650
Overall Steps per Second: 7,194.58499
Timestep Collection Time: 3.79008
Timestep Consumption Time: 3.16348
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 6.95356
Cumulative Model Updates: 7,800
Cumulative Timesteps: 43,419,430
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 43419430...
Checkpoint 43419430 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.91087
Policy Entropy: 3.66128
Value Function Loss: 0.32733
Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.69301
Value Function Update Magnitude: 0.75530
Collected Steps per Second: 12,631.07621
Overall Steps per Second: 7,032.48634
Timestep Collection Time: 3.95976
Timestep Consumption Time: 3.15238
PPO Batch Consumption Time: 0.23026
Total Iteration Time: 7.11214
Cumulative Model Updates: 7,809
Cumulative Timesteps: 43,469,446
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.51363
Policy Entropy: 3.65976
Value Function Loss: 0.32506
Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.69359
Value Function Update Magnitude: 0.77477
Collected Steps per Second: 12,677.32833
Overall Steps per Second: 7,167.16300
Timestep Collection Time: 3.94768
Timestep Consumption Time: 3.03500
PPO Batch Consumption Time: 0.22995
Total Iteration Time: 6.98268
Cumulative Model Updates: 7,818
Cumulative Timesteps: 43,519,492
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 43519492...
Checkpoint 43519492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.88339
Policy Entropy: 3.65782
Value Function Loss: 0.32299
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.69537
Value Function Update Magnitude: 0.77355
Collected Steps per Second: 12,468.62341
Overall Steps per Second: 6,817.60980
Timestep Collection Time: 4.01167
Timestep Consumption Time: 3.32521
PPO Batch Consumption Time: 0.25020
Total Iteration Time: 7.33688
Cumulative Model Updates: 7,827
Cumulative Timesteps: 43,569,512
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.50689
Policy Entropy: 3.65504
Value Function Loss: 0.32290
Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.69598
Value Function Update Magnitude: 0.77279
Collected Steps per Second: 12,298.79739
Overall Steps per Second: 6,875.20927
Timestep Collection Time: 4.06690
Timestep Consumption Time: 3.20822
PPO Batch Consumption Time: 0.23209
Total Iteration Time: 7.27512
Cumulative Model Updates: 7,836
Cumulative Timesteps: 43,619,530
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 43619530...
Checkpoint 43619530 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.06617
Policy Entropy: 3.65998
Value Function Loss: 0.32351
Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.68512
Value Function Update Magnitude: 0.74712
Collected Steps per Second: 12,754.90403
Overall Steps per Second: 7,048.19395
Timestep Collection Time: 3.92288
Timestep Consumption Time: 3.17624
PPO Batch Consumption Time: 0.23038
Total Iteration Time: 7.09912
Cumulative Model Updates: 7,845
Cumulative Timesteps: 43,669,566
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82220
Policy Entropy: 3.64158
Value Function Loss: 0.32419
Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.68429
Value Function Update Magnitude: 0.75657
Collected Steps per Second: 12,644.79764
Overall Steps per Second: 6,978.34292
Timestep Collection Time: 3.95688
Timestep Consumption Time: 3.21301
PPO Batch Consumption Time: 0.23180
Total Iteration Time: 7.16990
Cumulative Model Updates: 7,854
Cumulative Timesteps: 43,719,600
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 43719600...
Checkpoint 43719600 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95163
Policy Entropy: 3.63942
Value Function Loss: 0.31385
Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.68236
Value Function Update Magnitude: 0.74828
Collected Steps per Second: 12,524.33346
Overall Steps per Second: 7,018.70104
Timestep Collection Time: 3.99255
Timestep Consumption Time: 3.13185
PPO Batch Consumption Time: 0.23025
Total Iteration Time: 7.12440
Cumulative Model Updates: 7,863
Cumulative Timesteps: 43,769,604
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.68201
Policy Entropy: 3.63225
Value Function Loss: 0.31900
Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.68047
Value Function Update Magnitude: 0.68922
Collected Steps per Second: 12,805.44712
Overall Steps per Second: 7,033.32966
Timestep Collection Time: 3.90912
Timestep Consumption Time: 3.20814
PPO Batch Consumption Time: 0.23050
Total Iteration Time: 7.11725
Cumulative Model Updates: 7,872
Cumulative Timesteps: 43,819,662
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 43819662...
Checkpoint 43819662 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23805
Policy Entropy: 3.63994
Value Function Loss: 0.30931
Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.67930
Value Function Update Magnitude: 0.69646
Collected Steps per Second: 12,460.79505
Overall Steps per Second: 6,962.09375
Timestep Collection Time: 4.01467
Timestep Consumption Time: 3.17081
PPO Batch Consumption Time: 0.23055
Total Iteration Time: 7.18548
Cumulative Model Updates: 7,881
Cumulative Timesteps: 43,869,688
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.60605
Policy Entropy: 3.63755
Value Function Loss: 0.30550
Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.66897
Value Function Update Magnitude: 0.70193
Collected Steps per Second: 12,188.77898
Overall Steps per Second: 6,951.28889
Timestep Collection Time: 4.10345
Timestep Consumption Time: 3.09177
PPO Batch Consumption Time: 0.23110
Total Iteration Time: 7.19521
Cumulative Model Updates: 7,890
Cumulative Timesteps: 43,919,704
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 43919704...
Checkpoint 43919704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.73026
Policy Entropy: 3.63860
Value Function Loss: 0.29854
Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.66600
Value Function Update Magnitude: 0.73304
Collected Steps per Second: 12,599.04776
Overall Steps per Second: 6,927.39453
Timestep Collection Time: 3.96935
Timestep Consumption Time: 3.24982
PPO Batch Consumption Time: 0.24125
Total Iteration Time: 7.21916
Cumulative Model Updates: 7,899
Cumulative Timesteps: 43,969,714
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.32717
Policy Entropy: 3.63767
Value Function Loss: 0.29282
Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.65800
Value Function Update Magnitude: 0.68881
Collected Steps per Second: 11,798.47681
Overall Steps per Second: 6,716.74499
Timestep Collection Time: 4.24072
Timestep Consumption Time: 3.20843
PPO Batch Consumption Time: 0.23538
Total Iteration Time: 7.44914
Cumulative Model Updates: 7,908
Cumulative Timesteps: 44,019,748
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 44019748...
Checkpoint 44019748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.75575
Policy Entropy: 3.63694
Value Function Loss: 0.29074
Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.64247
Value Function Update Magnitude: 0.67805
Collected Steps per Second: 12,746.48199
Overall Steps per Second: 7,033.66915
Timestep Collection Time: 3.92595
Timestep Consumption Time: 3.18869
PPO Batch Consumption Time: 0.23304
Total Iteration Time: 7.11464
Cumulative Model Updates: 7,917
Cumulative Timesteps: 44,069,790
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.52582
Policy Entropy: 3.63298
Value Function Loss: 0.29732
Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.64357
Value Function Update Magnitude: 0.67261
Collected Steps per Second: 10,990.24174
Overall Steps per Second: 6,422.87343
Timestep Collection Time: 4.55186
Timestep Consumption Time: 3.23687
PPO Batch Consumption Time: 0.23386
Total Iteration Time: 7.78873
Cumulative Model Updates: 7,926
Cumulative Timesteps: 44,119,816
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 44119816...
Checkpoint 44119816 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.03899
Policy Entropy: 3.63666
Value Function Loss: 0.31202
Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.65816
Value Function Update Magnitude: 0.73845
Collected Steps per Second: 11,391.17925
Overall Steps per Second: 6,388.91261
Timestep Collection Time: 4.39059
Timestep Consumption Time: 3.43766
PPO Batch Consumption Time: 0.24396
Total Iteration Time: 7.82825
Cumulative Model Updates: 7,935
Cumulative Timesteps: 44,169,830
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.60550
Policy Entropy: 3.63845
Value Function Loss: 0.31149
Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.66850
Value Function Update Magnitude: 0.76290
Collected Steps per Second: 12,003.72295
Overall Steps per Second: 6,779.20830
Timestep Collection Time: 4.16787
Timestep Consumption Time: 3.21204
PPO Batch Consumption Time: 0.23439
Total Iteration Time: 7.37992
Cumulative Model Updates: 7,944
Cumulative Timesteps: 44,219,860
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 44219860...
Checkpoint 44219860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.19668
Policy Entropy: 3.63843
Value Function Loss: 0.30116
Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.66381
Value Function Update Magnitude: 0.71060
Collected Steps per Second: 11,597.47588
Overall Steps per Second: 6,666.04159
Timestep Collection Time: 4.31146
Timestep Consumption Time: 3.18955
PPO Batch Consumption Time: 0.23097
Total Iteration Time: 7.50100
Cumulative Model Updates: 7,953
Cumulative Timesteps: 44,269,862
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.79563
Policy Entropy: 3.64286
Value Function Loss: 0.29344
Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.65626
Value Function Update Magnitude: 0.66396
Collected Steps per Second: 12,131.81930
Overall Steps per Second: 6,879.98595
Timestep Collection Time: 4.12139
Timestep Consumption Time: 3.14606
PPO Batch Consumption Time: 0.23552
Total Iteration Time: 7.26746
Cumulative Model Updates: 7,962
Cumulative Timesteps: 44,319,862
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 44319862...
Checkpoint 44319862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.51155
Policy Entropy: 3.64405
Value Function Loss: 0.29856
Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.65455
Value Function Update Magnitude: 0.70039
Collected Steps per Second: 11,840.47589
Overall Steps per Second: 6,728.66725
Timestep Collection Time: 4.22635
Timestep Consumption Time: 3.21078
PPO Batch Consumption Time: 0.23092
Total Iteration Time: 7.43713
Cumulative Model Updates: 7,971
Cumulative Timesteps: 44,369,904
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.46190
Policy Entropy: 3.63937
Value Function Loss: 0.29892
Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.66198
Value Function Update Magnitude: 0.69518
Collected Steps per Second: 12,184.21277
Overall Steps per Second: 6,841.30350
Timestep Collection Time: 4.10630
Timestep Consumption Time: 3.20693
PPO Batch Consumption Time: 0.23596
Total Iteration Time: 7.31323
Cumulative Model Updates: 7,980
Cumulative Timesteps: 44,419,936
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 44419936...
Checkpoint 44419936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.19906
Policy Entropy: 3.64144
Value Function Loss: 0.29947
Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.65770
Value Function Update Magnitude: 0.67057
Collected Steps per Second: 11,827.06007
Overall Steps per Second: 6,819.98186
Timestep Collection Time: 4.23182
Timestep Consumption Time: 3.10691
PPO Batch Consumption Time: 0.23011
Total Iteration Time: 7.33873
Cumulative Model Updates: 7,989
Cumulative Timesteps: 44,469,986
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.88647
Policy Entropy: 3.63920
Value Function Loss: 0.29626
Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14814
Policy Update Magnitude: 0.64210
Value Function Update Magnitude: 0.62478
Collected Steps per Second: 12,540.55320
Overall Steps per Second: 6,975.21350
Timestep Collection Time: 3.98834
Timestep Consumption Time: 3.18219
PPO Batch Consumption Time: 0.23051
Total Iteration Time: 7.17053
Cumulative Model Updates: 7,998
Cumulative Timesteps: 44,520,002
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 44520002...
Checkpoint 44520002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36978
Policy Entropy: 3.64068
Value Function Loss: 0.30423
Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.64293
Value Function Update Magnitude: 0.64854
Collected Steps per Second: 12,308.68040
Overall Steps per Second: 6,805.60060
Timestep Collection Time: 4.06315
Timestep Consumption Time: 3.28550
PPO Batch Consumption Time: 0.24271
Total Iteration Time: 7.34865
Cumulative Model Updates: 8,007
Cumulative Timesteps: 44,570,014
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29436
Policy Entropy: 3.64656
Value Function Loss: 0.29591
Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.64948
Value Function Update Magnitude: 0.69332
Collected Steps per Second: 10,866.12552
Overall Steps per Second: 6,349.31962
Timestep Collection Time: 4.60164
Timestep Consumption Time: 3.27353
PPO Batch Consumption Time: 0.23970
Total Iteration Time: 7.87517
Cumulative Model Updates: 8,016
Cumulative Timesteps: 44,620,016
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 44620016...
Checkpoint 44620016 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.09234
Policy Entropy: 3.64862
Value Function Loss: 0.30012
Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.65228
Value Function Update Magnitude: 0.71063
Collected Steps per Second: 11,440.35580
Overall Steps per Second: 6,490.65457
Timestep Collection Time: 4.37102
Timestep Consumption Time: 3.33329
PPO Batch Consumption Time: 0.24379
Total Iteration Time: 7.70431
Cumulative Model Updates: 8,025
Cumulative Timesteps: 44,670,022
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97702
Policy Entropy: 3.65509
Value Function Loss: 0.29307
Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.64791
Value Function Update Magnitude: 0.66043
Collected Steps per Second: 11,435.75523
Overall Steps per Second: 6,649.58581
Timestep Collection Time: 4.37540
Timestep Consumption Time: 3.14928
PPO Batch Consumption Time: 0.23896
Total Iteration Time: 7.52468
Cumulative Model Updates: 8,034
Cumulative Timesteps: 44,720,058
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 44720058...
Checkpoint 44720058 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.08262
Policy Entropy: 3.65416
Value Function Loss: 0.30107
Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.64485
Value Function Update Magnitude: 0.67639
Collected Steps per Second: 11,972.48756
Overall Steps per Second: 6,808.16388
Timestep Collection Time: 4.17641
Timestep Consumption Time: 3.16801
PPO Batch Consumption Time: 0.23030
Total Iteration Time: 7.34442
Cumulative Model Updates: 8,043
Cumulative Timesteps: 44,770,060
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.65398
Policy Entropy: 3.65193
Value Function Loss: 0.28436
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.64260
Value Function Update Magnitude: 0.72204
Collected Steps per Second: 12,501.38596
Overall Steps per Second: 7,009.37261
Timestep Collection Time: 4.00084
Timestep Consumption Time: 3.13475
PPO Batch Consumption Time: 0.23031
Total Iteration Time: 7.13559
Cumulative Model Updates: 8,052
Cumulative Timesteps: 44,820,076
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 44820076...
Checkpoint 44820076 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.26225
Policy Entropy: 3.64897
Value Function Loss: 0.28220
Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.63960
Value Function Update Magnitude: 0.70443
Collected Steps per Second: 12,727.65815
Overall Steps per Second: 7,048.68226
Timestep Collection Time: 3.92861
Timestep Consumption Time: 3.16520
PPO Batch Consumption Time: 0.23047
Total Iteration Time: 7.09381
Cumulative Model Updates: 8,061
Cumulative Timesteps: 44,870,078
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85638
Policy Entropy: 3.64905
Value Function Loss: 0.28703
Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.64813
Value Function Update Magnitude: 0.70114
Collected Steps per Second: 12,656.84777
Overall Steps per Second: 7,015.23351
Timestep Collection Time: 3.95043
Timestep Consumption Time: 3.17692
PPO Batch Consumption Time: 0.23037
Total Iteration Time: 7.12735
Cumulative Model Updates: 8,070
Cumulative Timesteps: 44,920,078
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 44920078...
Checkpoint 44920078 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42467
Policy Entropy: 3.65571
Value Function Loss: 0.29974
Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.66232
Value Function Update Magnitude: 0.72389
Collected Steps per Second: 12,537.81617
Overall Steps per Second: 7,003.97946
Timestep Collection Time: 3.98953
Timestep Consumption Time: 3.15212
PPO Batch Consumption Time: 0.23060
Total Iteration Time: 7.14165
Cumulative Model Updates: 8,079
Cumulative Timesteps: 44,970,098
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.25104
Policy Entropy: 3.65282
Value Function Loss: 0.30177
Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.67695
Value Function Update Magnitude: 0.76233
Collected Steps per Second: 12,839.76334
Overall Steps per Second: 6,953.65969
Timestep Collection Time: 3.89587
Timestep Consumption Time: 3.29776
PPO Batch Consumption Time: 0.24039
Total Iteration Time: 7.19362
Cumulative Model Updates: 8,088
Cumulative Timesteps: 45,020,120
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 45020120...
Checkpoint 45020120 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.77186
Policy Entropy: 3.66341
Value Function Loss: 0.31398
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.68262
Value Function Update Magnitude: 0.76415
Collected Steps per Second: 12,607.17256
Overall Steps per Second: 7,000.19462
Timestep Collection Time: 3.96949
Timestep Consumption Time: 3.17946
PPO Batch Consumption Time: 0.23051
Total Iteration Time: 7.14894
Cumulative Model Updates: 8,097
Cumulative Timesteps: 45,070,164
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.90475
Policy Entropy: 3.65408
Value Function Loss: 0.32706
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.68717
Value Function Update Magnitude: 0.81870
Collected Steps per Second: 12,636.11335
Overall Steps per Second: 7,140.40854
Timestep Collection Time: 3.95897
Timestep Consumption Time: 3.04707
PPO Batch Consumption Time: 0.22991
Total Iteration Time: 7.00604
Cumulative Model Updates: 8,106
Cumulative Timesteps: 45,120,190
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 45120190...
Checkpoint 45120190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.57654
Policy Entropy: 3.64158
Value Function Loss: 0.31862
Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.69099
Value Function Update Magnitude: 0.82584
Collected Steps per Second: 12,722.99173
Overall Steps per Second: 7,043.42893
Timestep Collection Time: 3.93005
Timestep Consumption Time: 3.16905
PPO Batch Consumption Time: 0.23056
Total Iteration Time: 7.09910
Cumulative Model Updates: 8,115
Cumulative Timesteps: 45,170,192
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.78722
Policy Entropy: 3.63851
Value Function Loss: 0.30694
Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.68327
Value Function Update Magnitude: 0.75448
Collected Steps per Second: 12,505.58875
Overall Steps per Second: 7,002.32619
Timestep Collection Time: 3.99933
Timestep Consumption Time: 3.14315
PPO Batch Consumption Time: 0.23025
Total Iteration Time: 7.14248
Cumulative Model Updates: 8,124
Cumulative Timesteps: 45,220,206
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 45220206...
Checkpoint 45220206 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.56388
Policy Entropy: 3.64255
Value Function Loss: 0.30106
Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.67066
Value Function Update Magnitude: 0.73493
Collected Steps per Second: 12,878.83433
Overall Steps per Second: 7,096.83981
Timestep Collection Time: 3.88327
Timestep Consumption Time: 3.16381
PPO Batch Consumption Time: 0.22987
Total Iteration Time: 7.04708
Cumulative Model Updates: 8,133
Cumulative Timesteps: 45,270,218
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24826
Policy Entropy: 3.65361
Value Function Loss: 0.31963
Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.67234
Value Function Update Magnitude: 0.73229
Collected Steps per Second: 12,476.01340
Overall Steps per Second: 6,976.64223
Timestep Collection Time: 4.01042
Timestep Consumption Time: 3.16123
PPO Batch Consumption Time: 0.23003
Total Iteration Time: 7.17164
Cumulative Model Updates: 8,142
Cumulative Timesteps: 45,320,252
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 45320252...
Checkpoint 45320252 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.55614
Policy Entropy: 3.65030
Value Function Loss: 0.32331
Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.68693
Value Function Update Magnitude: 0.74862
Collected Steps per Second: 12,586.87434
Overall Steps per Second: 6,859.07994
Timestep Collection Time: 3.97557
Timestep Consumption Time: 3.31987
PPO Batch Consumption Time: 0.24059
Total Iteration Time: 7.29544
Cumulative Model Updates: 8,151
Cumulative Timesteps: 45,370,292
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.44033
Policy Entropy: 3.64883
Value Function Loss: 0.33009
Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.68678
Value Function Update Magnitude: 0.72718
Collected Steps per Second: 12,968.47198
Overall Steps per Second: 7,114.81413
Timestep Collection Time: 3.85674
Timestep Consumption Time: 3.17310
PPO Batch Consumption Time: 0.23015
Total Iteration Time: 7.02984
Cumulative Model Updates: 8,160
Cumulative Timesteps: 45,420,308
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 45420308...
Checkpoint 45420308 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99615
Policy Entropy: 3.64798
Value Function Loss: 0.30852
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.68244
Value Function Update Magnitude: 0.76049
Collected Steps per Second: 12,544.80287
Overall Steps per Second: 7,019.23672
Timestep Collection Time: 3.98858
Timestep Consumption Time: 3.13983
PPO Batch Consumption Time: 0.23057
Total Iteration Time: 7.12841
Cumulative Model Updates: 8,169
Cumulative Timesteps: 45,470,344
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49000
Policy Entropy: 3.64127
Value Function Loss: 0.30240
Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.66539
Value Function Update Magnitude: 0.69231
Collected Steps per Second: 12,495.11461
Overall Steps per Second: 7,076.58284
Timestep Collection Time: 4.00172
Timestep Consumption Time: 3.06412
PPO Batch Consumption Time: 0.23017
Total Iteration Time: 7.06584
Cumulative Model Updates: 8,178
Cumulative Timesteps: 45,520,346
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 45520346...
Checkpoint 45520346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.04758
Policy Entropy: 3.64710
Value Function Loss: 0.30413
Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.66060
Value Function Update Magnitude: 0.66799
Collected Steps per Second: 12,590.67266
Overall Steps per Second: 7,015.33339
Timestep Collection Time: 3.97151
Timestep Consumption Time: 3.15630
PPO Batch Consumption Time: 0.23014
Total Iteration Time: 7.12782
Cumulative Model Updates: 8,187
Cumulative Timesteps: 45,570,350
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.50858
Policy Entropy: 3.64147
Value Function Loss: 0.31407
Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12014
Policy Update Magnitude: 0.67706
Value Function Update Magnitude: 0.71067
Collected Steps per Second: 12,588.18657
Overall Steps per Second: 7,025.65032
Timestep Collection Time: 3.97420
Timestep Consumption Time: 3.14656
PPO Batch Consumption Time: 0.23093
Total Iteration Time: 7.12076
Cumulative Model Updates: 8,196
Cumulative Timesteps: 45,620,378
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 45620378...
Checkpoint 45620378 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.29821
Policy Entropy: 3.64372
Value Function Loss: 0.32632
Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.69162
Value Function Update Magnitude: 0.77267
Collected Steps per Second: 12,971.00542
Overall Steps per Second: 7,128.05677
Timestep Collection Time: 3.85629
Timestep Consumption Time: 3.16105
PPO Batch Consumption Time: 0.23128
Total Iteration Time: 7.01734
Cumulative Model Updates: 8,205
Cumulative Timesteps: 45,670,398
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.04516
Policy Entropy: 3.64349
Value Function Loss: 0.32470
Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12207
Policy Update Magnitude: 0.70179
Value Function Update Magnitude: 0.75661
Collected Steps per Second: 12,768.67527
Overall Steps per Second: 6,993.72001
Timestep Collection Time: 3.91771
Timestep Consumption Time: 3.23499
PPO Batch Consumption Time: 0.23485
Total Iteration Time: 7.15270
Cumulative Model Updates: 8,214
Cumulative Timesteps: 45,720,422
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 45720422...
Checkpoint 45720422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31756
Policy Entropy: 3.64645
Value Function Loss: 0.32150
Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.69314
Value Function Update Magnitude: 0.78443
Collected Steps per Second: 12,612.92595
Overall Steps per Second: 7,132.18721
Timestep Collection Time: 3.96435
Timestep Consumption Time: 3.04641
PPO Batch Consumption Time: 0.22991
Total Iteration Time: 7.01075
Cumulative Model Updates: 8,223
Cumulative Timesteps: 45,770,424
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.89130
Policy Entropy: 3.64781
Value Function Loss: 0.31862
Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.68768
Value Function Update Magnitude: 0.76173
Collected Steps per Second: 12,670.71436
Overall Steps per Second: 7,047.72178
Timestep Collection Time: 3.94674
Timestep Consumption Time: 3.14889
PPO Batch Consumption Time: 0.22974
Total Iteration Time: 7.09563
Cumulative Model Updates: 8,232
Cumulative Timesteps: 45,820,432
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 45820432...
Checkpoint 45820432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.66876
Policy Entropy: 3.64482
Value Function Loss: 0.31864
Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.69159
Value Function Update Magnitude: 0.80410
Collected Steps per Second: 12,560.17223
Overall Steps per Second: 7,063.89266
Timestep Collection Time: 3.98163
Timestep Consumption Time: 3.09803
PPO Batch Consumption Time: 0.23001
Total Iteration Time: 7.07967
Cumulative Model Updates: 8,241
Cumulative Timesteps: 45,870,442
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.57475
Policy Entropy: 3.64230
Value Function Loss: 0.32378
Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.69116
Value Function Update Magnitude: 0.86937
Collected Steps per Second: 12,598.30439
Overall Steps per Second: 7,143.49373
Timestep Collection Time: 3.97323
Timestep Consumption Time: 3.03398
PPO Batch Consumption Time: 0.22975
Total Iteration Time: 7.00722
Cumulative Model Updates: 8,250
Cumulative Timesteps: 45,920,498
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 45920498...
Checkpoint 45920498 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.83045
Policy Entropy: 3.64206
Value Function Loss: 0.30580
Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.68808
Value Function Update Magnitude: 1.06649
Collected Steps per Second: 12,421.38687
Overall Steps per Second: 6,960.18106
Timestep Collection Time: 4.02773
Timestep Consumption Time: 3.16030
PPO Batch Consumption Time: 0.23009
Total Iteration Time: 7.18803
Cumulative Model Updates: 8,259
Cumulative Timesteps: 45,970,528
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.29924
Policy Entropy: 3.63924
Value Function Loss: 0.29273
Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.68099
Value Function Update Magnitude: 0.96011
Collected Steps per Second: 12,550.71372
Overall Steps per Second: 7,017.82338
Timestep Collection Time: 3.98686
Timestep Consumption Time: 3.14327
PPO Batch Consumption Time: 0.23004
Total Iteration Time: 7.13013
Cumulative Model Updates: 8,268
Cumulative Timesteps: 46,020,566
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 46020566...
Checkpoint 46020566 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.80331
Policy Entropy: 3.64054
Value Function Loss: 0.29363
Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12122
Policy Update Magnitude: 0.67288
Value Function Update Magnitude: 0.96277
Collected Steps per Second: 12,775.83024
Overall Steps per Second: 6,947.81309
Timestep Collection Time: 3.91474
Timestep Consumption Time: 3.28379
PPO Batch Consumption Time: 0.24115
Total Iteration Time: 7.19852
Cumulative Model Updates: 8,277
Cumulative Timesteps: 46,070,580
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49826
Policy Entropy: 3.64546
Value Function Loss: 0.30350
Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.68010
Value Function Update Magnitude: 0.82498
Collected Steps per Second: 12,692.98639
Overall Steps per Second: 7,021.99374
Timestep Collection Time: 3.93966
Timestep Consumption Time: 3.18168
PPO Batch Consumption Time: 0.23036
Total Iteration Time: 7.12134
Cumulative Model Updates: 8,286
Cumulative Timesteps: 46,120,586
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 46120586...
Checkpoint 46120586 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12412
Policy Entropy: 3.64130
Value Function Loss: 0.31502
Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.68648
Value Function Update Magnitude: 0.73441
Collected Steps per Second: 12,379.08796
Overall Steps per Second: 6,980.04574
Timestep Collection Time: 4.03939
Timestep Consumption Time: 3.12446
PPO Batch Consumption Time: 0.23037
Total Iteration Time: 7.16385
Cumulative Model Updates: 8,295
Cumulative Timesteps: 46,170,590
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.71769
Policy Entropy: 3.63850
Value Function Loss: 0.30535
Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.68376
Value Function Update Magnitude: 0.79849
Collected Steps per Second: 12,811.09643
Overall Steps per Second: 7,058.04219
Timestep Collection Time: 3.90318
Timestep Consumption Time: 3.18151
PPO Batch Consumption Time: 0.23099
Total Iteration Time: 7.08468
Cumulative Model Updates: 8,304
Cumulative Timesteps: 46,220,594
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 46220594...
Checkpoint 46220594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.66427
Policy Entropy: 3.63849
Value Function Loss: 0.30839
Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.68334
Value Function Update Magnitude: 0.76689
Collected Steps per Second: 12,580.82586
Overall Steps per Second: 7,008.21139
Timestep Collection Time: 3.97653
Timestep Consumption Time: 3.16196
PPO Batch Consumption Time: 0.23108
Total Iteration Time: 7.13848
Cumulative Model Updates: 8,313
Cumulative Timesteps: 46,270,622
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.56502
Policy Entropy: 3.63884
Value Function Loss: 0.30767
Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.69049
Value Function Update Magnitude: 0.74540
Collected Steps per Second: 12,550.50184
Overall Steps per Second: 7,040.76713
Timestep Collection Time: 3.98550
Timestep Consumption Time: 3.11884
PPO Batch Consumption Time: 0.23042
Total Iteration Time: 7.10434
Cumulative Model Updates: 8,322
Cumulative Timesteps: 46,320,642
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 46320642...
Checkpoint 46320642 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74846
Policy Entropy: 3.64652
Value Function Loss: 0.30256
Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.68847
Value Function Update Magnitude: 0.75795
Collected Steps per Second: 12,434.74049
Overall Steps per Second: 6,947.48271
Timestep Collection Time: 4.02164
Timestep Consumption Time: 3.17637
PPO Batch Consumption Time: 0.22969
Total Iteration Time: 7.19800
Cumulative Model Updates: 8,331
Cumulative Timesteps: 46,370,650
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53025
Policy Entropy: 3.64637
Value Function Loss: 0.31703
Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.70136
Value Function Update Magnitude: 0.76643
Collected Steps per Second: 10,686.31603
Overall Steps per Second: 6,220.68020
Timestep Collection Time: 4.68057
Timestep Consumption Time: 3.36003
PPO Batch Consumption Time: 0.24960
Total Iteration Time: 8.04060
Cumulative Model Updates: 8,340
Cumulative Timesteps: 46,420,668
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 46420668...
Checkpoint 46420668 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.84046
Policy Entropy: 3.64291
Value Function Loss: 0.31279
Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.70761
Value Function Update Magnitude: 0.80204
Collected Steps per Second: 12,354.16427
Overall Steps per Second: 6,888.98025
Timestep Collection Time: 4.04754
Timestep Consumption Time: 3.21101
PPO Batch Consumption Time: 0.23475
Total Iteration Time: 7.25855
Cumulative Model Updates: 8,349
Cumulative Timesteps: 46,470,672
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.49766
Policy Entropy: 3.64459
Value Function Loss: 0.29865
Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.69336
Value Function Update Magnitude: 0.81554
Collected Steps per Second: 11,445.53764
Overall Steps per Second: 6,558.84529
Timestep Collection Time: 4.37131
Timestep Consumption Time: 3.25686
PPO Batch Consumption Time: 0.23622
Total Iteration Time: 7.62817
Cumulative Model Updates: 8,358
Cumulative Timesteps: 46,520,704
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 46520704...
Checkpoint 46520704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01631
Policy Entropy: 3.64273
Value Function Loss: 0.29439
Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.68351
Value Function Update Magnitude: 0.76138
Collected Steps per Second: 11,878.42510
Overall Steps per Second: 6,812.66542
Timestep Collection Time: 4.20948
Timestep Consumption Time: 3.13008
PPO Batch Consumption Time: 0.23039
Total Iteration Time: 7.33956
Cumulative Model Updates: 8,367
Cumulative Timesteps: 46,570,706
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53866
Policy Entropy: 3.64470
Value Function Loss: 0.29915
Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.68071
Value Function Update Magnitude: 0.77204
Collected Steps per Second: 12,888.11594
Overall Steps per Second: 7,109.68212
Timestep Collection Time: 3.88125
Timestep Consumption Time: 3.15451
PPO Batch Consumption Time: 0.22982
Total Iteration Time: 7.03576
Cumulative Model Updates: 8,376
Cumulative Timesteps: 46,620,728
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 46620728...
Checkpoint 46620728 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.51652
Policy Entropy: 3.62753
Value Function Loss: 0.31254
Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.68996
Value Function Update Magnitude: 0.84011
Collected Steps per Second: 12,732.26851
Overall Steps per Second: 7,064.20385
Timestep Collection Time: 3.92844
Timestep Consumption Time: 3.15204
PPO Batch Consumption Time: 0.22945
Total Iteration Time: 7.08049
Cumulative Model Updates: 8,385
Cumulative Timesteps: 46,670,746
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.72367
Policy Entropy: 3.62690
Value Function Loss: 0.30677
Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.69894
Value Function Update Magnitude: 0.79786
Collected Steps per Second: 12,671.89277
Overall Steps per Second: 7,014.22583
Timestep Collection Time: 3.94969
Timestep Consumption Time: 3.18581
PPO Batch Consumption Time: 0.24334
Total Iteration Time: 7.13550
Cumulative Model Updates: 8,394
Cumulative Timesteps: 46,720,796
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 46720796...
Checkpoint 46720796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.12297
Policy Entropy: 3.63734
Value Function Loss: 0.32296
Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.68977
Value Function Update Magnitude: 0.73612
Collected Steps per Second: 12,235.84526
Overall Steps per Second: 6,751.05686
Timestep Collection Time: 4.08668
Timestep Consumption Time: 3.32016
PPO Batch Consumption Time: 0.23631
Total Iteration Time: 7.40684
Cumulative Model Updates: 8,403
Cumulative Timesteps: 46,770,800
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.57037
Policy Entropy: 3.64351
Value Function Loss: 0.32132
Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.68332
Value Function Update Magnitude: 0.75873
Collected Steps per Second: 10,969.08103
Overall Steps per Second: 6,391.25728
Timestep Collection Time: 4.56246
Timestep Consumption Time: 3.26792
PPO Batch Consumption Time: 0.23357
Total Iteration Time: 7.83038
Cumulative Model Updates: 8,412
Cumulative Timesteps: 46,820,846
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 46820846...
Checkpoint 46820846 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10347
Policy Entropy: 3.64628
Value Function Loss: 0.31719
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.68145
Value Function Update Magnitude: 0.82562
Collected Steps per Second: 12,485.15093
Overall Steps per Second: 6,886.37732
Timestep Collection Time: 4.00732
Timestep Consumption Time: 3.25804
PPO Batch Consumption Time: 0.24008
Total Iteration Time: 7.26536
Cumulative Model Updates: 8,421
Cumulative Timesteps: 46,870,878
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.80238
Policy Entropy: 3.64739
Value Function Loss: 0.31269
Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.68230
Value Function Update Magnitude: 0.85466
Collected Steps per Second: 11,550.97092
Overall Steps per Second: 6,623.75589
Timestep Collection Time: 4.32881
Timestep Consumption Time: 3.22008
PPO Batch Consumption Time: 0.23466
Total Iteration Time: 7.54889
Cumulative Model Updates: 8,430
Cumulative Timesteps: 46,920,880
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 46920880...
Checkpoint 46920880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.28142
Policy Entropy: 3.64373
Value Function Loss: 0.32178
Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.69092
Value Function Update Magnitude: 0.81844
Collected Steps per Second: 11,943.75104
Overall Steps per Second: 6,709.54409
Timestep Collection Time: 4.18780
Timestep Consumption Time: 3.26696
PPO Batch Consumption Time: 0.24359
Total Iteration Time: 7.45475
Cumulative Model Updates: 8,439
Cumulative Timesteps: 46,970,898
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.57259
Policy Entropy: 3.63333
Value Function Loss: 0.31567
Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.70018
Value Function Update Magnitude: 0.78327
Collected Steps per Second: 11,963.60824
Overall Steps per Second: 6,721.27742
Timestep Collection Time: 4.18018
Timestep Consumption Time: 3.26037
PPO Batch Consumption Time: 0.23426
Total Iteration Time: 7.44055
Cumulative Model Updates: 8,448
Cumulative Timesteps: 47,020,908
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 47020908...
Checkpoint 47020908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.13240
Policy Entropy: 3.63233
Value Function Loss: 0.31536
Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.68994
Value Function Update Magnitude: 0.80377
Collected Steps per Second: 12,285.32845
Overall Steps per Second: 6,765.29023
Timestep Collection Time: 4.07217
Timestep Consumption Time: 3.32263
PPO Batch Consumption Time: 0.24625
Total Iteration Time: 7.39480
Cumulative Model Updates: 8,457
Cumulative Timesteps: 47,070,936
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54612
Policy Entropy: 3.63609
Value Function Loss: 0.31249
Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14968
Policy Update Magnitude: 0.67171
Value Function Update Magnitude: 0.78484
Collected Steps per Second: 11,715.14774
Overall Steps per Second: 6,833.55959
Timestep Collection Time: 4.27054
Timestep Consumption Time: 3.05068
PPO Batch Consumption Time: 0.23134
Total Iteration Time: 7.32122
Cumulative Model Updates: 8,466
Cumulative Timesteps: 47,120,966
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 47120966...
Checkpoint 47120966 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.45450
Policy Entropy: 3.64733
Value Function Loss: 0.31873
Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.67343
Value Function Update Magnitude: 0.74670
Collected Steps per Second: 11,853.08339
Overall Steps per Second: 6,695.82329
Timestep Collection Time: 4.21899
Timestep Consumption Time: 3.24955
PPO Batch Consumption Time: 0.23908
Total Iteration Time: 7.46854
Cumulative Model Updates: 8,475
Cumulative Timesteps: 47,170,974
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.27479
Policy Entropy: 3.63714
Value Function Loss: 0.31715
Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.68428
Value Function Update Magnitude: 0.75424
Collected Steps per Second: 11,568.53833
Overall Steps per Second: 6,570.00786
Timestep Collection Time: 4.32501
Timestep Consumption Time: 3.29051
PPO Batch Consumption Time: 0.23930
Total Iteration Time: 7.61552
Cumulative Model Updates: 8,484
Cumulative Timesteps: 47,221,008
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 47221008...
Checkpoint 47221008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.26704
Policy Entropy: 3.62749
Value Function Loss: 0.32418
Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.68645
Value Function Update Magnitude: 0.75204
Collected Steps per Second: 12,087.95619
Overall Steps per Second: 6,662.04845
Timestep Collection Time: 4.13651
Timestep Consumption Time: 3.36899
PPO Batch Consumption Time: 0.23807
Total Iteration Time: 7.50550
Cumulative Model Updates: 8,493
Cumulative Timesteps: 47,271,010
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10602
Policy Entropy: 3.62674
Value Function Loss: 0.31987
Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.68266
Value Function Update Magnitude: 0.74451
Collected Steps per Second: 11,027.92694
Overall Steps per Second: 6,484.20335
Timestep Collection Time: 4.53485
Timestep Consumption Time: 3.17774
PPO Batch Consumption Time: 0.22989
Total Iteration Time: 7.71259
Cumulative Model Updates: 8,502
Cumulative Timesteps: 47,321,020
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 47321020...
Checkpoint 47321020 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.06272
Policy Entropy: 3.62243
Value Function Loss: 0.32187
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.68388
Value Function Update Magnitude: 0.70168
Collected Steps per Second: 12,523.97696
Overall Steps per Second: 6,935.38314
Timestep Collection Time: 3.99394
Timestep Consumption Time: 3.21835
PPO Batch Consumption Time: 0.23760
Total Iteration Time: 7.21229
Cumulative Model Updates: 8,511
Cumulative Timesteps: 47,371,040
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23382
Policy Entropy: 3.62640
Value Function Loss: 0.31430
Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.68139
Value Function Update Magnitude: 0.77043
Collected Steps per Second: 12,099.09127
Overall Steps per Second: 6,853.05469
Timestep Collection Time: 4.13585
Timestep Consumption Time: 3.16601
PPO Batch Consumption Time: 0.22974
Total Iteration Time: 7.30185
Cumulative Model Updates: 8,520
Cumulative Timesteps: 47,421,080
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 47421080...
Checkpoint 47421080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.43532
Policy Entropy: 3.62379
Value Function Loss: 0.31058
Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.67232
Value Function Update Magnitude: 0.75322
Collected Steps per Second: 12,529.33197
Overall Steps per Second: 7,005.04092
Timestep Collection Time: 3.99351
Timestep Consumption Time: 3.14935
PPO Batch Consumption Time: 0.23072
Total Iteration Time: 7.14286
Cumulative Model Updates: 8,529
Cumulative Timesteps: 47,471,116
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.37591
Policy Entropy: 3.62370
Value Function Loss: 0.31604
Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.68181
Value Function Update Magnitude: 0.77278
Collected Steps per Second: 12,474.52442
Overall Steps per Second: 7,092.24293
Timestep Collection Time: 4.00977
Timestep Consumption Time: 3.04300
PPO Batch Consumption Time: 0.22988
Total Iteration Time: 7.05278
Cumulative Model Updates: 8,538
Cumulative Timesteps: 47,521,136
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 47521136...
Checkpoint 47521136 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.67960
Policy Entropy: 3.62777
Value Function Loss: 0.31981
Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.68945
Value Function Update Magnitude: 0.76794
Collected Steps per Second: 12,462.98121
Overall Steps per Second: 6,873.43565
Timestep Collection Time: 4.01252
Timestep Consumption Time: 3.26302
PPO Batch Consumption Time: 0.23608
Total Iteration Time: 7.27555
Cumulative Model Updates: 8,547
Cumulative Timesteps: 47,571,144
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.48883
Policy Entropy: 3.62521
Value Function Loss: 0.32628
Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.68970
Value Function Update Magnitude: 0.76642
Collected Steps per Second: 12,131.03035
Overall Steps per Second: 6,895.60572
Timestep Collection Time: 4.12529
Timestep Consumption Time: 3.13209
PPO Batch Consumption Time: 0.22986
Total Iteration Time: 7.25738
Cumulative Model Updates: 8,556
Cumulative Timesteps: 47,621,188
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 47621188...
Checkpoint 47621188 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23767
Policy Entropy: 3.63094
Value Function Loss: 0.30804
Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.68969
Value Function Update Magnitude: 0.74788
Collected Steps per Second: 12,710.23597
Overall Steps per Second: 6,947.82753
Timestep Collection Time: 3.93510
Timestep Consumption Time: 3.26370
PPO Batch Consumption Time: 0.23158
Total Iteration Time: 7.19880
Cumulative Model Updates: 8,565
Cumulative Timesteps: 47,671,204
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22036
Policy Entropy: 3.62930
Value Function Loss: 0.30078
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.68004
Value Function Update Magnitude: 0.74147
Collected Steps per Second: 11,782.45295
Overall Steps per Second: 6,618.89470
Timestep Collection Time: 4.24581
Timestep Consumption Time: 3.31225
PPO Batch Consumption Time: 0.24301
Total Iteration Time: 7.55806
Cumulative Model Updates: 8,574
Cumulative Timesteps: 47,721,230
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 47721230...
Checkpoint 47721230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.14583
Policy Entropy: 3.63425
Value Function Loss: 0.29580
Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.66932
Value Function Update Magnitude: 0.69923
Collected Steps per Second: 12,483.32662
Overall Steps per Second: 6,885.81198
Timestep Collection Time: 4.00759
Timestep Consumption Time: 3.25779
PPO Batch Consumption Time: 0.24071
Total Iteration Time: 7.26537
Cumulative Model Updates: 8,583
Cumulative Timesteps: 47,771,258
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23763
Policy Entropy: 3.62904
Value Function Loss: 0.31650
Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.68467
Value Function Update Magnitude: 0.69938
Collected Steps per Second: 12,232.85409
Overall Steps per Second: 6,871.05251
Timestep Collection Time: 4.08964
Timestep Consumption Time: 3.19134
PPO Batch Consumption Time: 0.22997
Total Iteration Time: 7.28098
Cumulative Model Updates: 8,592
Cumulative Timesteps: 47,821,286
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 47821286...
Checkpoint 47821286 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.03077
Policy Entropy: 3.62774
Value Function Loss: 0.32729
Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13599
Policy Update Magnitude: 0.69877
Value Function Update Magnitude: 0.72842
Collected Steps per Second: 12,531.67786
Overall Steps per Second: 7,037.51151
Timestep Collection Time: 3.99021
Timestep Consumption Time: 3.11514
PPO Batch Consumption Time: 0.22969
Total Iteration Time: 7.10535
Cumulative Model Updates: 8,601
Cumulative Timesteps: 47,871,290
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.38958
Policy Entropy: 3.63063
Value Function Loss: 0.33260
Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.69935
Value Function Update Magnitude: 0.74186
Collected Steps per Second: 12,612.62702
Overall Steps per Second: 7,136.64646
Timestep Collection Time: 3.96476
Timestep Consumption Time: 3.04218
PPO Batch Consumption Time: 0.23038
Total Iteration Time: 7.00693
Cumulative Model Updates: 8,610
Cumulative Timesteps: 47,921,296
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 47921296...
Checkpoint 47921296 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.07235
Policy Entropy: 3.62721
Value Function Loss: 0.33132
Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.69416
Value Function Update Magnitude: 0.74807
Collected Steps per Second: 11,826.67610
Overall Steps per Second: 6,635.68730
Timestep Collection Time: 4.23027
Timestep Consumption Time: 3.30927
PPO Batch Consumption Time: 0.23957
Total Iteration Time: 7.53954
Cumulative Model Updates: 8,619
Cumulative Timesteps: 47,971,326
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.83188
Policy Entropy: 3.62788
Value Function Loss: 0.31250
Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12894
Policy Update Magnitude: 0.68938
Value Function Update Magnitude: 0.74273
Collected Steps per Second: 11,332.49353
Overall Steps per Second: 6,344.59120
Timestep Collection Time: 4.41580
Timestep Consumption Time: 3.47155
PPO Batch Consumption Time: 0.24895
Total Iteration Time: 7.88735
Cumulative Model Updates: 8,628
Cumulative Timesteps: 48,021,368
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 48021368...
Checkpoint 48021368 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.58233
Policy Entropy: 3.62751
Value Function Loss: 0.31913
Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11994
Policy Update Magnitude: 0.68594
Value Function Update Magnitude: 0.76192
Collected Steps per Second: 11,975.31748
Overall Steps per Second: 6,539.23231
Timestep Collection Time: 4.17609
Timestep Consumption Time: 3.47160
PPO Batch Consumption Time: 0.25960
Total Iteration Time: 7.64769
Cumulative Model Updates: 8,637
Cumulative Timesteps: 48,071,378
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.07093
Policy Entropy: 3.62441
Value Function Loss: 0.32122
Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.68857
Value Function Update Magnitude: 0.76475
Collected Steps per Second: 11,823.54248
Overall Steps per Second: 6,701.33975
Timestep Collection Time: 4.23308
Timestep Consumption Time: 3.23558
PPO Batch Consumption Time: 0.23520
Total Iteration Time: 7.46866
Cumulative Model Updates: 8,646
Cumulative Timesteps: 48,121,428
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 48121428...
Checkpoint 48121428 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.39775
Policy Entropy: 3.62587
Value Function Loss: 0.32302
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.69328
Value Function Update Magnitude: 0.74407
Collected Steps per Second: 12,080.77954
Overall Steps per Second: 6,886.49448
Timestep Collection Time: 4.14145
Timestep Consumption Time: 3.12378
PPO Batch Consumption Time: 0.23517
Total Iteration Time: 7.26523
Cumulative Model Updates: 8,655
Cumulative Timesteps: 48,171,460
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.32145
Policy Entropy: 3.62790
Value Function Loss: 0.32201
Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.68567
Value Function Update Magnitude: 0.74232
Collected Steps per Second: 11,261.28889
Overall Steps per Second: 6,483.84332
Timestep Collection Time: 4.44248
Timestep Consumption Time: 3.27332
PPO Batch Consumption Time: 0.24131
Total Iteration Time: 7.71579
Cumulative Model Updates: 8,664
Cumulative Timesteps: 48,221,488
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 48221488...
Checkpoint 48221488 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.09866
Policy Entropy: 3.63384
Value Function Loss: 0.31932
Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.68677
Value Function Update Magnitude: 0.70193
Collected Steps per Second: 10,949.77582
Overall Steps per Second: 6,497.08485
Timestep Collection Time: 4.56795
Timestep Consumption Time: 3.13058
PPO Batch Consumption Time: 0.23105
Total Iteration Time: 7.69853
Cumulative Model Updates: 8,673
Cumulative Timesteps: 48,271,506
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74548
Policy Entropy: 3.63954
Value Function Loss: 0.32825
Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.68691
Value Function Update Magnitude: 0.73892
Collected Steps per Second: 12,153.19706
Overall Steps per Second: 6,964.18895
Timestep Collection Time: 4.11546
Timestep Consumption Time: 3.06642
PPO Batch Consumption Time: 0.23057
Total Iteration Time: 7.18188
Cumulative Model Updates: 8,682
Cumulative Timesteps: 48,321,522
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 48321522...
Checkpoint 48321522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.15756
Policy Entropy: 3.64168
Value Function Loss: 0.33792
Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.15090
Policy Update Magnitude: 0.68727
Value Function Update Magnitude: 0.78313
Collected Steps per Second: 11,914.48884
Overall Steps per Second: 6,593.62193
Timestep Collection Time: 4.19674
Timestep Consumption Time: 3.38665
PPO Batch Consumption Time: 0.24808
Total Iteration Time: 7.58339
Cumulative Model Updates: 8,691
Cumulative Timesteps: 48,371,524
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.79274
Policy Entropy: 3.63278
Value Function Loss: 0.31531
Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.68341
Value Function Update Magnitude: 0.78099
Collected Steps per Second: 11,510.67904
Overall Steps per Second: 6,599.77743
Timestep Collection Time: 4.34483
Timestep Consumption Time: 3.23300
PPO Batch Consumption Time: 0.23879
Total Iteration Time: 7.57783
Cumulative Model Updates: 8,700
Cumulative Timesteps: 48,421,536
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 48421536...
Checkpoint 48421536 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.68380
Policy Entropy: 3.62494
Value Function Loss: 0.31419
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.68305
Value Function Update Magnitude: 0.76756
Collected Steps per Second: 12,326.55462
Overall Steps per Second: 6,806.30794
Timestep Collection Time: 4.05726
Timestep Consumption Time: 3.29063
PPO Batch Consumption Time: 0.23720
Total Iteration Time: 7.34789
Cumulative Model Updates: 8,709
Cumulative Timesteps: 48,471,548
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.98650
Policy Entropy: 3.62442
Value Function Loss: 0.31583
Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.68535
Value Function Update Magnitude: 0.74062
Collected Steps per Second: 12,324.23799
Overall Steps per Second: 6,818.83037
Timestep Collection Time: 4.05851
Timestep Consumption Time: 3.27677
PPO Batch Consumption Time: 0.24139
Total Iteration Time: 7.33528
Cumulative Model Updates: 8,718
Cumulative Timesteps: 48,521,566
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 48521566...
Checkpoint 48521566 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.96105
Policy Entropy: 3.62314
Value Function Loss: 0.33510
Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.69986
Value Function Update Magnitude: 0.75536
Collected Steps per Second: 12,118.13510
Overall Steps per Second: 6,850.77970
Timestep Collection Time: 4.12638
Timestep Consumption Time: 3.17265
PPO Batch Consumption Time: 0.23492
Total Iteration Time: 7.29902
Cumulative Model Updates: 8,727
Cumulative Timesteps: 48,571,570
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.91892
Policy Entropy: 3.62092
Value Function Loss: 0.33514
Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.69382
Value Function Update Magnitude: 0.72727
Collected Steps per Second: 11,779.71074
Overall Steps per Second: 6,673.32184
Timestep Collection Time: 4.24561
Timestep Consumption Time: 3.24871
PPO Batch Consumption Time: 0.23550
Total Iteration Time: 7.49432
Cumulative Model Updates: 8,736
Cumulative Timesteps: 48,621,582
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 48621582...
Checkpoint 48621582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.76174
Policy Entropy: 3.62097
Value Function Loss: 0.32596
Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.67931
Value Function Update Magnitude: 0.73110
Collected Steps per Second: 11,234.29042
Overall Steps per Second: 6,366.99150
Timestep Collection Time: 4.45351
Timestep Consumption Time: 3.40452
PPO Batch Consumption Time: 0.24660
Total Iteration Time: 7.85803
Cumulative Model Updates: 8,745
Cumulative Timesteps: 48,671,614
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27732
Policy Entropy: 3.62407
Value Function Loss: 0.32552
Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.68667
Value Function Update Magnitude: 0.72077
Collected Steps per Second: 11,392.01159
Overall Steps per Second: 6,653.65095
Timestep Collection Time: 4.38939
Timestep Consumption Time: 3.12588
PPO Batch Consumption Time: 0.23532
Total Iteration Time: 7.51527
Cumulative Model Updates: 8,754
Cumulative Timesteps: 48,721,618
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 48721618...
Checkpoint 48721618 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30498
Policy Entropy: 3.61489
Value Function Loss: 0.32124
Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.69157
Value Function Update Magnitude: 0.71316
Collected Steps per Second: 12,238.20477
Overall Steps per Second: 6,845.09474
Timestep Collection Time: 4.08884
Timestep Consumption Time: 3.22151
PPO Batch Consumption Time: 0.23576
Total Iteration Time: 7.31034
Cumulative Model Updates: 8,763
Cumulative Timesteps: 48,771,658
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.26129
Policy Entropy: 3.60973
Value Function Loss: 0.32581
Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12478
Policy Update Magnitude: 0.69358
Value Function Update Magnitude: 0.77424
Collected Steps per Second: 11,289.45416
Overall Steps per Second: 6,422.33099
Timestep Collection Time: 4.42927
Timestep Consumption Time: 3.35669
PPO Batch Consumption Time: 0.24247
Total Iteration Time: 7.78596
Cumulative Model Updates: 8,772
Cumulative Timesteps: 48,821,662
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 48821662...
Checkpoint 48821662 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.63943
Policy Entropy: 3.60555
Value Function Loss: 0.30659
Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.68849
Value Function Update Magnitude: 0.71962
Collected Steps per Second: 11,377.64962
Overall Steps per Second: 6,468.97564
Timestep Collection Time: 4.39511
Timestep Consumption Time: 3.33502
PPO Batch Consumption Time: 0.24384
Total Iteration Time: 7.73013
Cumulative Model Updates: 8,781
Cumulative Timesteps: 48,871,668
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.09571
Policy Entropy: 3.60813
Value Function Loss: 0.31194
Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.67826
Value Function Update Magnitude: 0.74828
Collected Steps per Second: 11,809.58385
Overall Steps per Second: 6,707.84503
Timestep Collection Time: 4.23842
Timestep Consumption Time: 3.22359
PPO Batch Consumption Time: 0.23470
Total Iteration Time: 7.46201
Cumulative Model Updates: 8,790
Cumulative Timesteps: 48,921,722
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 48921722...
Checkpoint 48921722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.64588
Policy Entropy: 3.61779
Value Function Loss: 0.31147
Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.67250
Value Function Update Magnitude: 0.76344
Collected Steps per Second: 12,236.69722
Overall Steps per Second: 6,882.49047
Timestep Collection Time: 4.08803
Timestep Consumption Time: 3.18027
PPO Batch Consumption Time: 0.23451
Total Iteration Time: 7.26830
Cumulative Model Updates: 8,799
Cumulative Timesteps: 48,971,746
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52881
Policy Entropy: 3.62513
Value Function Loss: 0.30579
Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11815
Policy Update Magnitude: 0.67722
Value Function Update Magnitude: 0.73276
Collected Steps per Second: 11,739.04630
Overall Steps per Second: 6,342.06028
Timestep Collection Time: 4.26099
Timestep Consumption Time: 3.62603
PPO Batch Consumption Time: 0.26867
Total Iteration Time: 7.88703
Cumulative Model Updates: 8,808
Cumulative Timesteps: 49,021,766
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 49021766...
Checkpoint 49021766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76714
Policy Entropy: 3.62709
Value Function Loss: 0.30820
Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.67311
Value Function Update Magnitude: 0.70370
Collected Steps per Second: 11,177.55754
Overall Steps per Second: 6,467.22118
Timestep Collection Time: 4.47701
Timestep Consumption Time: 3.26078
PPO Batch Consumption Time: 0.24069
Total Iteration Time: 7.73779
Cumulative Model Updates: 8,817
Cumulative Timesteps: 49,071,808
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67459
Policy Entropy: 3.63407
Value Function Loss: 0.31471
Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.67144
Value Function Update Magnitude: 0.76404
Collected Steps per Second: 12,199.26408
Overall Steps per Second: 6,924.11823
Timestep Collection Time: 4.09976
Timestep Consumption Time: 3.12340
PPO Batch Consumption Time: 0.23595
Total Iteration Time: 7.22316
Cumulative Model Updates: 8,826
Cumulative Timesteps: 49,121,822
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 49121822...
Checkpoint 49121822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.18395
Policy Entropy: 3.62556
Value Function Loss: 0.31765
Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.67353
Value Function Update Magnitude: 0.79159
Collected Steps per Second: 11,457.64502
Overall Steps per Second: 6,466.78298
Timestep Collection Time: 4.36512
Timestep Consumption Time: 3.36886
PPO Batch Consumption Time: 0.24705
Total Iteration Time: 7.73398
Cumulative Model Updates: 8,835
Cumulative Timesteps: 49,171,836
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.40803
Policy Entropy: 3.62599
Value Function Loss: 0.31965
Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.68022
Value Function Update Magnitude: 0.82303
Collected Steps per Second: 11,156.18238
Overall Steps per Second: 6,435.57662
Timestep Collection Time: 4.48236
Timestep Consumption Time: 3.28789
PPO Batch Consumption Time: 0.24422
Total Iteration Time: 7.77024
Cumulative Model Updates: 8,844
Cumulative Timesteps: 49,221,842
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 49221842...
Checkpoint 49221842 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.17147
Policy Entropy: 3.62174
Value Function Loss: 0.32242
Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.68220
Value Function Update Magnitude: 0.78411
Collected Steps per Second: 11,798.89257
Overall Steps per Second: 6,712.49753
Timestep Collection Time: 4.24125
Timestep Consumption Time: 3.21380
PPO Batch Consumption Time: 0.23262
Total Iteration Time: 7.45505
Cumulative Model Updates: 8,853
Cumulative Timesteps: 49,271,884
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31932
Policy Entropy: 3.62832
Value Function Loss: 0.31513
Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.68172
Value Function Update Magnitude: 0.80164
Collected Steps per Second: 11,440.31021
Overall Steps per Second: 6,384.23626
Timestep Collection Time: 4.37086
Timestep Consumption Time: 3.46156
PPO Batch Consumption Time: 0.25246
Total Iteration Time: 7.83242
Cumulative Model Updates: 8,862
Cumulative Timesteps: 49,321,888
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 49321888...
Checkpoint 49321888 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.94381
Policy Entropy: 3.62001
Value Function Loss: 0.31621
Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.68070
Value Function Update Magnitude: 0.77222
Collected Steps per Second: 11,847.74794
Overall Steps per Second: 6,693.98310
Timestep Collection Time: 4.22173
Timestep Consumption Time: 3.25035
PPO Batch Consumption Time: 0.24030
Total Iteration Time: 7.47208
Cumulative Model Updates: 8,871
Cumulative Timesteps: 49,371,906
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.63846
Policy Entropy: 3.61399
Value Function Loss: 0.31525
Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.69112
Value Function Update Magnitude: 0.76806
Collected Steps per Second: 11,471.80446
Overall Steps per Second: 6,537.98202
Timestep Collection Time: 4.36270
Timestep Consumption Time: 3.29226
PPO Batch Consumption Time: 0.24202
Total Iteration Time: 7.65496
Cumulative Model Updates: 8,880
Cumulative Timesteps: 49,421,954
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 49421954...
Checkpoint 49421954 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27883
Policy Entropy: 3.61529
Value Function Loss: 0.31571
Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.68213
Value Function Update Magnitude: 0.73123
Collected Steps per Second: 12,054.08560
Overall Steps per Second: 6,811.05773
Timestep Collection Time: 4.14880
Timestep Consumption Time: 3.19367
PPO Batch Consumption Time: 0.23209
Total Iteration Time: 7.34247
Cumulative Model Updates: 8,889
Cumulative Timesteps: 49,471,964
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85513
Policy Entropy: 3.61971
Value Function Loss: 0.31734
Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.68183
Value Function Update Magnitude: 0.75032
Collected Steps per Second: 12,050.43151
Overall Steps per Second: 6,829.46380
Timestep Collection Time: 4.15305
Timestep Consumption Time: 3.17491
PPO Batch Consumption Time: 0.24010
Total Iteration Time: 7.32795
Cumulative Model Updates: 8,898
Cumulative Timesteps: 49,522,010
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 49522010...
Checkpoint 49522010 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.01419
Policy Entropy: 3.61526
Value Function Loss: 0.32741
Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.68658
Value Function Update Magnitude: 0.75622
Collected Steps per Second: 11,307.51306
Overall Steps per Second: 6,556.94621
Timestep Collection Time: 4.42520
Timestep Consumption Time: 3.20610
PPO Batch Consumption Time: 0.23002
Total Iteration Time: 7.63130
Cumulative Model Updates: 8,907
Cumulative Timesteps: 49,572,048
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.14246
Policy Entropy: 3.61069
Value Function Loss: 0.33225
Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.69646
Value Function Update Magnitude: 0.79183
Collected Steps per Second: 12,116.44679
Overall Steps per Second: 6,758.26324
Timestep Collection Time: 4.12728
Timestep Consumption Time: 3.27225
PPO Batch Consumption Time: 0.24344
Total Iteration Time: 7.39953
Cumulative Model Updates: 8,916
Cumulative Timesteps: 49,622,056
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 49622056...
Checkpoint 49622056 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50632
Policy Entropy: 3.60101
Value Function Loss: 0.33853
Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.69449
Value Function Update Magnitude: 0.80861
Collected Steps per Second: 11,084.26331
Overall Steps per Second: 6,518.00887
Timestep Collection Time: 4.51343
Timestep Consumption Time: 3.16192
PPO Batch Consumption Time: 0.23035
Total Iteration Time: 7.67535
Cumulative Model Updates: 8,925
Cumulative Timesteps: 49,672,084
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.92827
Policy Entropy: 3.60231
Value Function Loss: 0.33683
Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.69971
Value Function Update Magnitude: 0.83313
Collected Steps per Second: 12,140.51342
Overall Steps per Second: 6,827.02397
Timestep Collection Time: 4.12207
Timestep Consumption Time: 3.20821
PPO Batch Consumption Time: 0.23157
Total Iteration Time: 7.33028
Cumulative Model Updates: 8,934
Cumulative Timesteps: 49,722,128
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 49722128...
Checkpoint 49722128 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.44660
Policy Entropy: 3.60420
Value Function Loss: 0.31644
Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.68890
Value Function Update Magnitude: 0.80051
Collected Steps per Second: 11,870.39029
Overall Steps per Second: 6,733.93776
Timestep Collection Time: 4.21486
Timestep Consumption Time: 3.21497
PPO Batch Consumption Time: 0.23960
Total Iteration Time: 7.42983
Cumulative Model Updates: 8,943
Cumulative Timesteps: 49,772,160
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.97831
Policy Entropy: 3.60397
Value Function Loss: 0.32542
Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.67869
Value Function Update Magnitude: 0.77986
Collected Steps per Second: 12,071.33080
Overall Steps per Second: 6,812.83257
Timestep Collection Time: 4.14735
Timestep Consumption Time: 3.20114
PPO Batch Consumption Time: 0.23054
Total Iteration Time: 7.34849
Cumulative Model Updates: 8,952
Cumulative Timesteps: 49,822,224
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
Saving checkpoint 49822224...
Checkpoint 49822224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.63471
Policy Entropy: 3.60816
Value Function Loss: 0.31458
Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.68040
Value Function Update Magnitude: 0.79433
Collected Steps per Second: 12,271.78397
Overall Steps per Second: 6,824.17041
Timestep Collection Time: 4.07862
Timestep Consumption Time: 3.25589
PPO Batch Consumption Time: 0.23857
Total Iteration Time: 7.33452
Cumulative Model Updates: 8,961
Cumulative Timesteps: 49,872,276
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.07775
Policy Entropy: 3.60693
Value Function Loss: 0.31516
Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.67369
Value Function Update Magnitude: 0.77015
Collected Steps per Second: 11,330.17670
Overall Steps per Second: 6,491.41895
Timestep Collection Time: 4.41441
Timestep Consumption Time: 3.29053
PPO Batch Consumption Time: 0.24585
Total Iteration Time: 7.70494
Cumulative Model Updates: 8,970
Cumulative Timesteps: 49,922,292
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 49922292...
Checkpoint 49922292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.97491
Policy Entropy: 3.62084
Value Function Loss: 0.30331
Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.67189
Value Function Update Magnitude: 0.74818
Collected Steps per Second: 11,504.57073
Overall Steps per Second: 6,577.48199
Timestep Collection Time: 4.34923
Timestep Consumption Time: 3.25794
PPO Batch Consumption Time: 0.23935
Total Iteration Time: 7.60717
Cumulative Model Updates: 8,979
Cumulative Timesteps: 49,972,328
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67945
Policy Entropy: 3.61460
Value Function Loss: 0.30807
Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.69078
Value Function Update Magnitude: 0.76092
Collected Steps per Second: 11,362.88992
Overall Steps per Second: 6,517.66085
Timestep Collection Time: 4.40117
Timestep Consumption Time: 3.27183
PPO Batch Consumption Time: 0.23808
Total Iteration Time: 7.67300
Cumulative Model Updates: 8,988
Cumulative Timesteps: 50,022,338
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 50022338...
Checkpoint 50022338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.74977
Policy Entropy: 3.61738
Value Function Loss: 0.32219
Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.69740
Value Function Update Magnitude: 0.73038
Collected Steps per Second: 12,461.53440
Overall Steps per Second: 6,917.52374
Timestep Collection Time: 4.01459
Timestep Consumption Time: 3.21747
PPO Batch Consumption Time: 0.23513
Total Iteration Time: 7.23207
Cumulative Model Updates: 8,997
Cumulative Timesteps: 50,072,366
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.19727
Policy Entropy: 3.60674
Value Function Loss: 0.31626
Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.69635
Value Function Update Magnitude: 0.76822
Collected Steps per Second: 11,193.07645
Overall Steps per Second: 6,373.85790
Timestep Collection Time: 4.46830
Timestep Consumption Time: 3.37844
PPO Batch Consumption Time: 0.24207
Total Iteration Time: 7.84674
Cumulative Model Updates: 9,006
Cumulative Timesteps: 50,122,380
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 50122380...
Checkpoint 50122380 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.88307
Policy Entropy: 3.60553
Value Function Loss: 0.31132
Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.69597
Value Function Update Magnitude: 0.75144
Collected Steps per Second: 11,831.65630
Overall Steps per Second: 6,676.96617
Timestep Collection Time: 4.22764
Timestep Consumption Time: 3.26378
PPO Batch Consumption Time: 0.24179
Total Iteration Time: 7.49143
Cumulative Model Updates: 9,015
Cumulative Timesteps: 50,172,400
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.73382
Policy Entropy: 3.60587
Value Function Loss: 0.30578
Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.70097
Value Function Update Magnitude: 0.75124
Collected Steps per Second: 11,300.16112
Overall Steps per Second: 6,387.38218
Timestep Collection Time: 4.42737
Timestep Consumption Time: 3.40526
PPO Batch Consumption Time: 0.24579
Total Iteration Time: 7.83263
Cumulative Model Updates: 9,024
Cumulative Timesteps: 50,222,430
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 50222430...
Checkpoint 50222430 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.96508
Policy Entropy: 3.60350
Value Function Loss: 0.33417
Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.70945
Value Function Update Magnitude: 0.77086
Collected Steps per Second: 11,042.12389
Overall Steps per Second: 6,470.21895
Timestep Collection Time: 4.53119
Timestep Consumption Time: 3.20178
PPO Batch Consumption Time: 0.23615
Total Iteration Time: 7.73297
Cumulative Model Updates: 9,033
Cumulative Timesteps: 50,272,464
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.25935
Policy Entropy: 3.60275
Value Function Loss: 0.33684
Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.71505
Value Function Update Magnitude: 0.77320
Collected Steps per Second: 11,463.28278
Overall Steps per Second: 6,613.59683
Timestep Collection Time: 4.36524
Timestep Consumption Time: 3.20099
PPO Batch Consumption Time: 0.23945
Total Iteration Time: 7.56623
Cumulative Model Updates: 9,042
Cumulative Timesteps: 50,322,504
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 50322504...
Checkpoint 50322504 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.48355
Policy Entropy: 3.60959
Value Function Loss: 0.34264
Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.15094
Policy Update Magnitude: 0.71813
Value Function Update Magnitude: 0.80564
Collected Steps per Second: 11,810.02665
Overall Steps per Second: 6,707.59539
Timestep Collection Time: 4.23725
Timestep Consumption Time: 3.22325
PPO Batch Consumption Time: 0.23515
Total Iteration Time: 7.46050
Cumulative Model Updates: 9,051
Cumulative Timesteps: 50,372,546
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.94329
Policy Entropy: 3.60954
Value Function Loss: 0.32188
Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.72105
Value Function Update Magnitude: 0.91089
Collected Steps per Second: 12,172.79349
Overall Steps per Second: 6,720.00136
Timestep Collection Time: 4.10768
Timestep Consumption Time: 3.33309
PPO Batch Consumption Time: 0.24537
Total Iteration Time: 7.44077
Cumulative Model Updates: 9,060
Cumulative Timesteps: 50,422,548
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 50422548...
Checkpoint 50422548 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.39601
Policy Entropy: 3.61248
Value Function Loss: 0.30264
Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14483
Policy Update Magnitude: 0.72044
Value Function Update Magnitude: 0.96047
Collected Steps per Second: 11,309.29676
Overall Steps per Second: 6,488.09139
Timestep Collection Time: 4.42273
Timestep Consumption Time: 3.28647
PPO Batch Consumption Time: 0.23410
Total Iteration Time: 7.70920
Cumulative Model Updates: 9,069
Cumulative Timesteps: 50,472,566
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.90498
Policy Entropy: 3.61300
Value Function Loss: 0.30393
Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.70927
Value Function Update Magnitude: 0.90851
Collected Steps per Second: 12,392.49245
Overall Steps per Second: 6,868.50261
Timestep Collection Time: 4.03825
Timestep Consumption Time: 3.24776
PPO Batch Consumption Time: 0.23319
Total Iteration Time: 7.28601
Cumulative Model Updates: 9,078
Cumulative Timesteps: 50,522,610
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 50522610...
Checkpoint 50522610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.36061
Policy Entropy: 3.61603
Value Function Loss: 0.29529
Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.70740
Value Function Update Magnitude: 0.85741
Collected Steps per Second: 11,415.26642
Overall Steps per Second: 6,555.04129
Timestep Collection Time: 4.38185
Timestep Consumption Time: 3.24892
PPO Batch Consumption Time: 0.23522
Total Iteration Time: 7.63077
Cumulative Model Updates: 9,087
Cumulative Timesteps: 50,572,630
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.87943
Policy Entropy: 3.61570
Value Function Loss: 0.29369
Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.70690
Value Function Update Magnitude: 0.83024
Collected Steps per Second: 10,979.87340
Overall Steps per Second: 6,374.51312
Timestep Collection Time: 4.55779
Timestep Consumption Time: 3.29284
PPO Batch Consumption Time: 0.23591
Total Iteration Time: 7.85064
Cumulative Model Updates: 9,096
Cumulative Timesteps: 50,622,674
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 50622674...
Checkpoint 50622674 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.58463
Policy Entropy: 3.62040
Value Function Loss: 0.30431
Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.69915
Value Function Update Magnitude: 0.79832
Collected Steps per Second: 10,581.21421
Overall Steps per Second: 6,194.25798
Timestep Collection Time: 4.72781
Timestep Consumption Time: 3.34838
PPO Batch Consumption Time: 0.23591
Total Iteration Time: 8.07619
Cumulative Model Updates: 9,105
Cumulative Timesteps: 50,672,700
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.15533
Policy Entropy: 3.62011
Value Function Loss: 0.29959
Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.70572
Value Function Update Magnitude: 0.81781
Collected Steps per Second: 11,783.91179
Overall Steps per Second: 6,746.31395
Timestep Collection Time: 4.24698
Timestep Consumption Time: 3.17130
PPO Batch Consumption Time: 0.24295
Total Iteration Time: 7.41827
Cumulative Model Updates: 9,114
Cumulative Timesteps: 50,722,746
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 50722746...
Checkpoint 50722746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75944
Policy Entropy: 3.61174
Value Function Loss: 0.30357
Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11946
Policy Update Magnitude: 0.70762
Value Function Update Magnitude: 0.78200
Collected Steps per Second: 11,806.05234
Overall Steps per Second: 6,628.43061
Timestep Collection Time: 4.23512
Timestep Consumption Time: 3.30815
PPO Batch Consumption Time: 0.24101
Total Iteration Time: 7.54326
Cumulative Model Updates: 9,123
Cumulative Timesteps: 50,772,746
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.21284
Policy Entropy: 3.61652
Value Function Loss: 0.28149
Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12220
Policy Update Magnitude: 0.70093
Value Function Update Magnitude: 0.81380
Collected Steps per Second: 11,328.05988
Overall Steps per Second: 6,485.51788
Timestep Collection Time: 4.41523
Timestep Consumption Time: 3.29672
PPO Batch Consumption Time: 0.24211
Total Iteration Time: 7.71195
Cumulative Model Updates: 9,132
Cumulative Timesteps: 50,822,762
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 50822762...
Checkpoint 50822762 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.06538
Policy Entropy: 3.61729
Value Function Loss: 0.30752
Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.70214
Value Function Update Magnitude: 0.80314
Collected Steps per Second: 11,274.36218
Overall Steps per Second: 6,458.69932
Timestep Collection Time: 4.43697
Timestep Consumption Time: 3.30824
PPO Batch Consumption Time: 0.23125
Total Iteration Time: 7.74521
Cumulative Model Updates: 9,141
Cumulative Timesteps: 50,872,786
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.75369
Policy Entropy: 3.62893
Value Function Loss: 0.30268
Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.70214
Value Function Update Magnitude: 0.79764
Collected Steps per Second: 11,022.00232
Overall Steps per Second: 6,455.29519
Timestep Collection Time: 4.53892
Timestep Consumption Time: 3.21100
PPO Batch Consumption Time: 0.23311
Total Iteration Time: 7.74992
Cumulative Model Updates: 9,150
Cumulative Timesteps: 50,922,814
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 50922814...
Checkpoint 50922814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.93902
Policy Entropy: 3.62879
Value Function Loss: 0.31004
Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.70651
Value Function Update Magnitude: 0.79150
Collected Steps per Second: 12,023.05309
Overall Steps per Second: 6,809.39715
Timestep Collection Time: 4.16267
Timestep Consumption Time: 3.18717
PPO Batch Consumption Time: 0.23346
Total Iteration Time: 7.34984
Cumulative Model Updates: 9,159
Cumulative Timesteps: 50,972,862
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.00719
Policy Entropy: 3.62595
Value Function Loss: 0.30737
Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11358
Policy Update Magnitude: 0.70176
Value Function Update Magnitude: 0.78774
Collected Steps per Second: 12,211.09677
Overall Steps per Second: 6,866.08698
Timestep Collection Time: 4.09906
Timestep Consumption Time: 3.19097
PPO Batch Consumption Time: 0.23352
Total Iteration Time: 7.29003
Cumulative Model Updates: 9,168
Cumulative Timesteps: 51,022,916
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 51022916...
Checkpoint 51022916 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.11692
Policy Entropy: 3.61841
Value Function Loss: 0.30860
Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.69859
Value Function Update Magnitude: 0.80732
Collected Steps per Second: 11,181.64447
Overall Steps per Second: 6,410.35985
Timestep Collection Time: 4.47305
Timestep Consumption Time: 3.32932
PPO Batch Consumption Time: 0.24404
Total Iteration Time: 7.80237
Cumulative Model Updates: 9,177
Cumulative Timesteps: 51,072,932
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.43108
Policy Entropy: 3.62014
Value Function Loss: 0.30861
Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.68850
Value Function Update Magnitude: 0.81878
Collected Steps per Second: 11,058.98623
Overall Steps per Second: 6,351.13393
Timestep Collection Time: 4.52428
Timestep Consumption Time: 3.35368
PPO Batch Consumption Time: 0.25684
Total Iteration Time: 7.87796
Cumulative Model Updates: 9,186
Cumulative Timesteps: 51,122,966
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 51122966...
Checkpoint 51122966 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.90629
Policy Entropy: 3.62543
Value Function Loss: 0.29439
Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.66702
Value Function Update Magnitude: 0.80284
Collected Steps per Second: 10,985.80081
Overall Steps per Second: 6,358.23587
Timestep Collection Time: 4.55624
Timestep Consumption Time: 3.31606
PPO Batch Consumption Time: 0.24605
Total Iteration Time: 7.87231
Cumulative Model Updates: 9,195
Cumulative Timesteps: 51,173,020
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.33834
Policy Entropy: 3.62979
Value Function Loss: 0.29133
Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.65281
Value Function Update Magnitude: 0.80917
Collected Steps per Second: 11,179.55872
Overall Steps per Second: 6,505.55108
Timestep Collection Time: 4.47621
Timestep Consumption Time: 3.21599
PPO Batch Consumption Time: 0.23888
Total Iteration Time: 7.69220
Cumulative Model Updates: 9,204
Cumulative Timesteps: 51,223,062
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 51223062...
Checkpoint 51223062 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.30099
Policy Entropy: 3.62594
Value Function Loss: 0.28302
Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.64921
Value Function Update Magnitude: 0.79104
Collected Steps per Second: 11,839.44639
Overall Steps per Second: 6,775.18505
Timestep Collection Time: 4.22418
Timestep Consumption Time: 3.15746
PPO Batch Consumption Time: 0.23046
Total Iteration Time: 7.38164
Cumulative Model Updates: 9,213
Cumulative Timesteps: 51,273,074
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.89743
Policy Entropy: 3.61962
Value Function Loss: 0.28974
Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.65327
Value Function Update Magnitude: 0.79868
Collected Steps per Second: 12,557.08642
Overall Steps per Second: 7,006.84030
Timestep Collection Time: 3.98468
Timestep Consumption Time: 3.15634
PPO Batch Consumption Time: 0.23035
Total Iteration Time: 7.14102
Cumulative Model Updates: 9,222
Cumulative Timesteps: 51,323,110
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 51323110...
Checkpoint 51323110 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.21691
Policy Entropy: 3.61317
Value Function Loss: 0.28266
Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.65551
Value Function Update Magnitude: 0.78138
Collected Steps per Second: 12,437.62191
Overall Steps per Second: 6,870.67222
Timestep Collection Time: 4.02006
Timestep Consumption Time: 3.25725
PPO Batch Consumption Time: 0.24661
Total Iteration Time: 7.27731
Cumulative Model Updates: 9,231
Cumulative Timesteps: 51,373,110
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.81025
Policy Entropy: 3.61058
Value Function Loss: 0.28773
Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.66290
Value Function Update Magnitude: 0.81770
Collected Steps per Second: 11,195.18866
Overall Steps per Second: 6,171.50995
Timestep Collection Time: 4.46871
Timestep Consumption Time: 3.63758
PPO Batch Consumption Time: 0.27596
Total Iteration Time: 8.10628
Cumulative Model Updates: 9,240
Cumulative Timesteps: 51,423,138
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 51423138...
Checkpoint 51423138 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.81688
Policy Entropy: 3.61696
Value Function Loss: 0.29172
Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11862
Policy Update Magnitude: 0.67727
Value Function Update Magnitude: 0.81869
Collected Steps per Second: 11,479.90787
Overall Steps per Second: 6,472.18007
Timestep Collection Time: 4.35892
Timestep Consumption Time: 3.37263
PPO Batch Consumption Time: 0.24620
Total Iteration Time: 7.73155
Cumulative Model Updates: 9,249
Cumulative Timesteps: 51,473,178
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.19384
Policy Entropy: 3.61574
Value Function Loss: 0.30256
Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.68465
Value Function Update Magnitude: 0.81627
Collected Steps per Second: 11,490.22413
Overall Steps per Second: 6,512.68781
Timestep Collection Time: 4.35605
Timestep Consumption Time: 3.32926
PPO Batch Consumption Time: 0.25061
Total Iteration Time: 7.68531
Cumulative Model Updates: 9,258
Cumulative Timesteps: 51,523,230
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 51523230...
Checkpoint 51523230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.30414
Policy Entropy: 3.62394
Value Function Loss: 0.29397
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.69925
Value Function Update Magnitude: 0.79817
Collected Steps per Second: 10,892.31590
Overall Steps per Second: 6,313.52232
Timestep Collection Time: 4.59131
Timestep Consumption Time: 3.32978
PPO Batch Consumption Time: 0.24280
Total Iteration Time: 7.92109
Cumulative Model Updates: 9,267
Cumulative Timesteps: 51,573,240
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23014
Policy Entropy: 3.61518
Value Function Loss: 0.28936
Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.69959
Value Function Update Magnitude: 0.75870
Collected Steps per Second: 11,226.22705
Overall Steps per Second: 6,515.77186
Timestep Collection Time: 4.45742
Timestep Consumption Time: 3.22241
PPO Batch Consumption Time: 0.23889
Total Iteration Time: 7.67983
Cumulative Model Updates: 9,276
Cumulative Timesteps: 51,623,280
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 51623280...
Checkpoint 51623280 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19439
Policy Entropy: 3.62018
Value Function Loss: 0.29784
Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.69147
Value Function Update Magnitude: 0.71217
Collected Steps per Second: 11,407.24929
Overall Steps per Second: 6,573.96481
Timestep Collection Time: 4.38423
Timestep Consumption Time: 3.22336
PPO Batch Consumption Time: 0.23597
Total Iteration Time: 7.60759
Cumulative Model Updates: 9,285
Cumulative Timesteps: 51,673,292
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.62833
Policy Entropy: 3.61660
Value Function Loss: 0.29616
Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.68985
Value Function Update Magnitude: 0.80347
Collected Steps per Second: 11,259.31723
Overall Steps per Second: 6,478.68539
Timestep Collection Time: 4.44592
Timestep Consumption Time: 3.28065
PPO Batch Consumption Time: 0.23919
Total Iteration Time: 7.72657
Cumulative Model Updates: 9,294
Cumulative Timesteps: 51,723,350
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 51723350...
Checkpoint 51723350 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.59193
Policy Entropy: 3.62413
Value Function Loss: 0.27970
Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.68362
Value Function Update Magnitude: 0.82735
Collected Steps per Second: 11,927.06906
Overall Steps per Second: 6,730.78843
Timestep Collection Time: 4.19399
Timestep Consumption Time: 3.23783
PPO Batch Consumption Time: 0.23572
Total Iteration Time: 7.43182
Cumulative Model Updates: 9,303
Cumulative Timesteps: 51,773,372
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.54183
Policy Entropy: 3.62497
Value Function Loss: 0.28008
Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.66925
Value Function Update Magnitude: 0.81162
Collected Steps per Second: 12,495.05006
Overall Steps per Second: 6,952.49060
Timestep Collection Time: 4.00206
Timestep Consumption Time: 3.19047
PPO Batch Consumption Time: 0.23541
Total Iteration Time: 7.19253
Cumulative Model Updates: 9,312
Cumulative Timesteps: 51,823,378
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 51823378...
Checkpoint 51823378 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.26156
Policy Entropy: 3.62191
Value Function Loss: 0.29194
Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.67328
Value Function Update Magnitude: 0.77032
Collected Steps per Second: 12,138.12281
Overall Steps per Second: 6,675.21087
Timestep Collection Time: 4.12255
Timestep Consumption Time: 3.37384
PPO Batch Consumption Time: 0.24142
Total Iteration Time: 7.49639
Cumulative Model Updates: 9,321
Cumulative Timesteps: 51,873,418
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01676
Policy Entropy: 3.61665
Value Function Loss: 0.29521
Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.67514
Value Function Update Magnitude: 0.76878
Collected Steps per Second: 10,963.35137
Overall Steps per Second: 6,503.93442
Timestep Collection Time: 4.56393
Timestep Consumption Time: 3.12926
PPO Batch Consumption Time: 0.23671
Total Iteration Time: 7.69319
Cumulative Model Updates: 9,330
Cumulative Timesteps: 51,923,454
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 51923454...
Checkpoint 51923454 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.41226
Policy Entropy: 3.61308
Value Function Loss: 0.29225
Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.68875
Value Function Update Magnitude: 0.82260
Collected Steps per Second: 11,628.19111
Overall Steps per Second: 6,549.49161
Timestep Collection Time: 4.30110
Timestep Consumption Time: 3.33522
PPO Batch Consumption Time: 0.24614
Total Iteration Time: 7.63632
Cumulative Model Updates: 9,339
Cumulative Timesteps: 51,973,468
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50197
Policy Entropy: 3.61567
Value Function Loss: 0.27707
Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.67071
Value Function Update Magnitude: 0.84510
Collected Steps per Second: 10,863.82298
Overall Steps per Second: 6,266.46011
Timestep Collection Time: 4.60243
Timestep Consumption Time: 3.37655
PPO Batch Consumption Time: 0.24162
Total Iteration Time: 7.97899
Cumulative Model Updates: 9,348
Cumulative Timesteps: 52,023,468
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 52023468...
Checkpoint 52023468 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.30950
Policy Entropy: 3.61694
Value Function Loss: 0.27933
Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.66462
Value Function Update Magnitude: 0.84441
Collected Steps per Second: 11,010.93952
Overall Steps per Second: 6,453.64769
Timestep Collection Time: 4.54203
Timestep Consumption Time: 3.20739
PPO Batch Consumption Time: 0.23293
Total Iteration Time: 7.74942
Cumulative Model Updates: 9,357
Cumulative Timesteps: 52,073,480
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49175
Policy Entropy: 3.61436
Value Function Loss: 0.28854
Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.67135
Value Function Update Magnitude: 0.78201
Collected Steps per Second: 10,959.37992
Overall Steps per Second: 6,349.22906
Timestep Collection Time: 4.56723
Timestep Consumption Time: 3.31625
PPO Batch Consumption Time: 0.23843
Total Iteration Time: 7.88348
Cumulative Model Updates: 9,366
Cumulative Timesteps: 52,123,534
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 52123534...
Checkpoint 52123534 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.87752
Policy Entropy: 3.61263
Value Function Loss: 0.29328
Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.67518
Value Function Update Magnitude: 0.79534
Collected Steps per Second: 11,969.56026
Overall Steps per Second: 6,679.15787
Timestep Collection Time: 4.18077
Timestep Consumption Time: 3.31149
PPO Batch Consumption Time: 0.23877
Total Iteration Time: 7.49226
Cumulative Model Updates: 9,375
Cumulative Timesteps: 52,173,576
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.45076
Policy Entropy: 3.61377
Value Function Loss: 0.28177
Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.67062
Value Function Update Magnitude: 0.83519
Collected Steps per Second: 12,783.90507
Overall Steps per Second: 7,014.45634
Timestep Collection Time: 3.91195
Timestep Consumption Time: 3.21761
PPO Batch Consumption Time: 0.22980
Total Iteration Time: 7.12956
Cumulative Model Updates: 9,384
Cumulative Timesteps: 52,223,586
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 52223586...
Checkpoint 52223586 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.20508
Policy Entropy: 3.61270
Value Function Loss: 0.28661
Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.67163
Value Function Update Magnitude: 0.73497
Collected Steps per Second: 11,627.17298
Overall Steps per Second: 6,711.32242
Timestep Collection Time: 4.30268
Timestep Consumption Time: 3.15159
PPO Batch Consumption Time: 0.22980
Total Iteration Time: 7.45427
Cumulative Model Updates: 9,393
Cumulative Timesteps: 52,273,614
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.21374
Policy Entropy: 3.61482
Value Function Loss: 0.29109
Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11268
Policy Update Magnitude: 0.67849
Value Function Update Magnitude: 0.80297
Collected Steps per Second: 12,410.70516
Overall Steps per Second: 7,056.90094
Timestep Collection Time: 4.02991
Timestep Consumption Time: 3.05734
PPO Batch Consumption Time: 0.22998
Total Iteration Time: 7.08725
Cumulative Model Updates: 9,402
Cumulative Timesteps: 52,323,628
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 52323628...
Checkpoint 52323628 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.12136
Policy Entropy: 3.61105
Value Function Loss: 0.29487
Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.67712
Value Function Update Magnitude: 0.79495
Collected Steps per Second: 12,432.79149
Overall Steps per Second: 6,897.24172
Timestep Collection Time: 4.02613
Timestep Consumption Time: 3.23127
PPO Batch Consumption Time: 0.23651
Total Iteration Time: 7.25739
Cumulative Model Updates: 9,411
Cumulative Timesteps: 52,373,684
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.56959
Policy Entropy: 3.61123
Value Function Loss: 0.27901
Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.67188
Value Function Update Magnitude: 0.76979
Collected Steps per Second: 12,568.97465
Overall Steps per Second: 6,958.99965
Timestep Collection Time: 3.97996
Timestep Consumption Time: 3.20843
PPO Batch Consumption Time: 0.24009
Total Iteration Time: 7.18839
Cumulative Model Updates: 9,420
Cumulative Timesteps: 52,423,708
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 52423708...
Checkpoint 52423708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.04811
Policy Entropy: 3.61445
Value Function Loss: 0.26942
Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.66437
Value Function Update Magnitude: 0.77537
Collected Steps per Second: 10,763.51449
Overall Steps per Second: 6,290.21830
Timestep Collection Time: 4.64867
Timestep Consumption Time: 3.30591
PPO Batch Consumption Time: 0.24795
Total Iteration Time: 7.95457
Cumulative Model Updates: 9,429
Cumulative Timesteps: 52,473,744
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.85650
Policy Entropy: 3.61721
Value Function Loss: 0.26839
Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.65995
Value Function Update Magnitude: 0.79399
Collected Steps per Second: 9,877.19850
Overall Steps per Second: 5,616.72575
Timestep Collection Time: 5.06723
Timestep Consumption Time: 3.84366
PPO Batch Consumption Time: 0.26398
Total Iteration Time: 8.91089
Cumulative Model Updates: 9,438
Cumulative Timesteps: 52,523,794
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 52523794...
Checkpoint 52523794 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.53709
Policy Entropy: 3.61149
Value Function Loss: 0.26814
Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.65500
Value Function Update Magnitude: 0.79557
Collected Steps per Second: 9,588.38869
Overall Steps per Second: 5,669.27057
Timestep Collection Time: 5.21610
Timestep Consumption Time: 3.60585
PPO Batch Consumption Time: 0.27203
Total Iteration Time: 8.82195
Cumulative Model Updates: 9,447
Cumulative Timesteps: 52,573,808
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.92688
Policy Entropy: 3.61915
Value Function Loss: 0.27350
Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.65335
Value Function Update Magnitude: 0.78803
Collected Steps per Second: 9,622.65482
Overall Steps per Second: 5,733.35894
Timestep Collection Time: 5.19732
Timestep Consumption Time: 3.52567
PPO Batch Consumption Time: 0.26087
Total Iteration Time: 8.72298
Cumulative Model Updates: 9,456
Cumulative Timesteps: 52,623,820
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 52623820...
Checkpoint 52623820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03726
Policy Entropy: 3.61846
Value Function Loss: 0.29118
Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.66441
Value Function Update Magnitude: 0.77775
Collected Steps per Second: 10,474.50233
Overall Steps per Second: 5,911.37728
Timestep Collection Time: 4.77502
Timestep Consumption Time: 3.68595
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 8.46097
Cumulative Model Updates: 9,465
Cumulative Timesteps: 52,673,836
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.89385
Policy Entropy: 3.61889
Value Function Loss: 0.30927
Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.67513
Value Function Update Magnitude: 0.84391
Collected Steps per Second: 9,869.15929
Overall Steps per Second: 5,683.99220
Timestep Collection Time: 5.07075
Timestep Consumption Time: 3.73363
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 8.80438
Cumulative Model Updates: 9,474
Cumulative Timesteps: 52,723,880
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 52723880...
Checkpoint 52723880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.54326
Policy Entropy: 3.61159
Value Function Loss: 0.31021
Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.68021
Value Function Update Magnitude: 0.82140
Collected Steps per Second: 10,505.42047
Overall Steps per Second: 5,994.88580
Timestep Collection Time: 4.76002
Timestep Consumption Time: 3.58142
PPO Batch Consumption Time: 0.27278
Total Iteration Time: 8.34144
Cumulative Model Updates: 9,483
Cumulative Timesteps: 52,773,886
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.88895
Policy Entropy: 3.60046
Value Function Loss: 0.30336
Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.68973
Value Function Update Magnitude: 0.91329
Collected Steps per Second: 8,991.66412
Overall Steps per Second: 5,420.55213
Timestep Collection Time: 5.56204
Timestep Consumption Time: 3.66433
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 9.22637
Cumulative Model Updates: 9,492
Cumulative Timesteps: 52,823,898
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 52823898...
Checkpoint 52823898 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.59680
Policy Entropy: 3.59903
Value Function Loss: 0.30220
Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.69098
Value Function Update Magnitude: 0.84160
Collected Steps per Second: 10,328.43408
Overall Steps per Second: 5,844.80304
Timestep Collection Time: 4.84100
Timestep Consumption Time: 3.71360
PPO Batch Consumption Time: 0.26701
Total Iteration Time: 8.55461
Cumulative Model Updates: 9,501
Cumulative Timesteps: 52,873,898
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.02299
Policy Entropy: 3.60397
Value Function Loss: 0.30526
Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.68259
Value Function Update Magnitude: 0.83015
Collected Steps per Second: 9,237.39414
Overall Steps per Second: 5,323.99412
Timestep Collection Time: 5.41625
Timestep Consumption Time: 3.98121
PPO Batch Consumption Time: 0.30134
Total Iteration Time: 9.39746
Cumulative Model Updates: 9,510
Cumulative Timesteps: 52,923,930
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 52923930...
Checkpoint 52923930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.00380
Policy Entropy: 3.60920
Value Function Loss: 0.30308
Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.67684
Value Function Update Magnitude: 0.87572
Collected Steps per Second: 8,866.29405
Overall Steps per Second: 4,615.80988
Timestep Collection Time: 5.64385
Timestep Consumption Time: 5.19715
PPO Batch Consumption Time: 0.40504
Total Iteration Time: 10.84100
Cumulative Model Updates: 9,519
Cumulative Timesteps: 52,973,970
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61472
Policy Entropy: 3.60291
Value Function Loss: 0.27790
Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.66813
Value Function Update Magnitude: 0.88486
Collected Steps per Second: 8,892.91461
Overall Steps per Second: 5,292.01693
Timestep Collection Time: 5.62560
Timestep Consumption Time: 3.82788
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 9.45348
Cumulative Model Updates: 9,528
Cumulative Timesteps: 53,023,998
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 53023998...
Checkpoint 53023998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.98797
Policy Entropy: 3.60555
Value Function Loss: 0.25958
Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.65361
Value Function Update Magnitude: 0.78826
Collected Steps per Second: 10,969.53464
Overall Steps per Second: 6,212.61391
Timestep Collection Time: 4.56045
Timestep Consumption Time: 3.49188
PPO Batch Consumption Time: 0.26013
Total Iteration Time: 8.05233
Cumulative Model Updates: 9,537
Cumulative Timesteps: 53,074,024
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.49378
Policy Entropy: 3.60751
Value Function Loss: 0.26073
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.64699
Value Function Update Magnitude: 0.76811
Collected Steps per Second: 11,461.75517
Overall Steps per Second: 6,407.73348
Timestep Collection Time: 4.36303
Timestep Consumption Time: 3.44129
PPO Batch Consumption Time: 0.26164
Total Iteration Time: 7.80432
Cumulative Model Updates: 9,546
Cumulative Timesteps: 53,124,032
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 53124032...
Checkpoint 53124032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.74642
Policy Entropy: 3.60907
Value Function Loss: 0.27480
Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.65892
Value Function Update Magnitude: 0.82236
Collected Steps per Second: 10,082.47031
Overall Steps per Second: 5,812.47540
Timestep Collection Time: 4.96148
Timestep Consumption Time: 3.64483
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 8.60632
Cumulative Model Updates: 9,555
Cumulative Timesteps: 53,174,056
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.99395
Policy Entropy: 3.59934
Value Function Loss: 0.26879
Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.66223
Value Function Update Magnitude: 0.98426
Collected Steps per Second: 9,523.39712
Overall Steps per Second: 5,621.28325
Timestep Collection Time: 5.25380
Timestep Consumption Time: 3.64702
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 8.90081
Cumulative Model Updates: 9,564
Cumulative Timesteps: 53,224,090
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 53224090...
Checkpoint 53224090 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.50246
Policy Entropy: 3.60976
Value Function Loss: 0.25531
Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.65276
Value Function Update Magnitude: 0.83371
Collected Steps per Second: 10,041.39698
Overall Steps per Second: 5,743.89917
Timestep Collection Time: 4.98297
Timestep Consumption Time: 3.72818
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 8.71116
Cumulative Model Updates: 9,573
Cumulative Timesteps: 53,274,126
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.90335
Policy Entropy: 3.61516
Value Function Loss: 0.24903
Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.64070
Value Function Update Magnitude: 0.90365
Collected Steps per Second: 10,438.72494
Overall Steps per Second: 5,945.80798
Timestep Collection Time: 4.79407
Timestep Consumption Time: 3.62261
PPO Batch Consumption Time: 0.27033
Total Iteration Time: 8.41669
Cumulative Model Updates: 9,582
Cumulative Timesteps: 53,324,170
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 53324170...
Checkpoint 53324170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99360
Policy Entropy: 3.61271
Value Function Loss: 0.23907
Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.63485
Value Function Update Magnitude: 1.06871
Collected Steps per Second: 9,801.59527
Overall Steps per Second: 5,846.16946
Timestep Collection Time: 5.10448
Timestep Consumption Time: 3.45361
PPO Batch Consumption Time: 0.25528
Total Iteration Time: 8.55808
Cumulative Model Updates: 9,591
Cumulative Timesteps: 53,374,202
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67599
Policy Entropy: 3.60354
Value Function Loss: 0.22850
Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.64279
Value Function Update Magnitude: 1.18350
Collected Steps per Second: 11,071.27858
Overall Steps per Second: 6,225.44086
Timestep Collection Time: 4.52107
Timestep Consumption Time: 3.51917
PPO Batch Consumption Time: 0.25530
Total Iteration Time: 8.04023
Cumulative Model Updates: 9,600
Cumulative Timesteps: 53,424,256
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 53424256...
Checkpoint 53424256 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52857
Policy Entropy: 3.59910
Value Function Loss: 0.24029
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.65396
Value Function Update Magnitude: 1.10207
Collected Steps per Second: 11,231.93598
Overall Steps per Second: 6,354.61018
Timestep Collection Time: 4.45515
Timestep Consumption Time: 3.41944
PPO Batch Consumption Time: 0.25467
Total Iteration Time: 7.87460
Cumulative Model Updates: 9,609
Cumulative Timesteps: 53,474,296
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.81335
Policy Entropy: 3.60499
Value Function Loss: 0.24196
Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.65943
Value Function Update Magnitude: 1.08316
Collected Steps per Second: 10,579.14394
Overall Steps per Second: 6,008.54493
Timestep Collection Time: 4.72836
Timestep Consumption Time: 3.59678
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 8.32514
Cumulative Model Updates: 9,618
Cumulative Timesteps: 53,524,318
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 53524318...
Checkpoint 53524318 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.38271
Policy Entropy: 3.59837
Value Function Loss: 0.24904
Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11757
Policy Update Magnitude: 0.66151
Value Function Update Magnitude: 1.06221
Collected Steps per Second: 10,147.48659
Overall Steps per Second: 5,829.52170
Timestep Collection Time: 4.93048
Timestep Consumption Time: 3.65204
PPO Batch Consumption Time: 0.27598
Total Iteration Time: 8.58252
Cumulative Model Updates: 9,627
Cumulative Timesteps: 53,574,350
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.25027
Policy Entropy: 3.59149
Value Function Loss: 0.25464
Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11672
Policy Update Magnitude: 0.65977
Value Function Update Magnitude: 0.84108
Collected Steps per Second: 10,972.12482
Overall Steps per Second: 6,255.56565
Timestep Collection Time: 4.56047
Timestep Consumption Time: 3.43849
PPO Batch Consumption Time: 0.26248
Total Iteration Time: 7.99896
Cumulative Model Updates: 9,636
Cumulative Timesteps: 53,624,388
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 53624388...
Checkpoint 53624388 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11156
Policy Entropy: 3.59402
Value Function Loss: 0.25278
Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.65023
Value Function Update Magnitude: 0.94370
Collected Steps per Second: 10,157.58266
Overall Steps per Second: 5,892.04505
Timestep Collection Time: 4.92420
Timestep Consumption Time: 3.56487
PPO Batch Consumption Time: 0.27512
Total Iteration Time: 8.48907
Cumulative Model Updates: 9,645
Cumulative Timesteps: 53,674,406
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.42083
Policy Entropy: 3.59900
Value Function Loss: 0.27098
Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11536
Policy Update Magnitude: 0.65853
Value Function Update Magnitude: 0.79804
Collected Steps per Second: 11,199.85586
Overall Steps per Second: 6,321.98613
Timestep Collection Time: 4.47024
Timestep Consumption Time: 3.44911
PPO Batch Consumption Time: 0.25406
Total Iteration Time: 7.91935
Cumulative Model Updates: 9,654
Cumulative Timesteps: 53,724,472
Timesteps Collected: 50,066
--------END ITERATION REPORT--------
Saving checkpoint 53724472...
Checkpoint 53724472 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.45209
Policy Entropy: 3.60570
Value Function Loss: 0.26681
Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.66698
Value Function Update Magnitude: 0.72420
Collected Steps per Second: 11,503.19131
Overall Steps per Second: 6,510.70679
Timestep Collection Time: 4.34749
Timestep Consumption Time: 3.33370
PPO Batch Consumption Time: 0.25263
Total Iteration Time: 7.68119
Cumulative Model Updates: 9,663
Cumulative Timesteps: 53,774,482
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.58837
Policy Entropy: 3.60298
Value Function Loss: 0.27359
Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.66621
Value Function Update Magnitude: 0.72072
Collected Steps per Second: 11,429.58556
Overall Steps per Second: 6,232.41125
Timestep Collection Time: 4.37811
Timestep Consumption Time: 3.65088
PPO Batch Consumption Time: 0.26634
Total Iteration Time: 8.02900
Cumulative Model Updates: 9,672
Cumulative Timesteps: 53,824,522
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 53824522...
Checkpoint 53824522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.83048
Policy Entropy: 3.60671
Value Function Loss: 0.27280
Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.66039
Value Function Update Magnitude: 0.72960
Collected Steps per Second: 10,871.23885
Overall Steps per Second: 6,005.24371
Timestep Collection Time: 4.59948
Timestep Consumption Time: 3.72691
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 8.32639
Cumulative Model Updates: 9,681
Cumulative Timesteps: 53,874,524
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.24588
Policy Entropy: 3.60381
Value Function Loss: 0.26347
Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.65489
Value Function Update Magnitude: 0.73268
Collected Steps per Second: 10,101.26310
Overall Steps per Second: 5,956.99234
Timestep Collection Time: 4.95067
Timestep Consumption Time: 3.44417
PPO Batch Consumption Time: 0.26786
Total Iteration Time: 8.39484
Cumulative Model Updates: 9,690
Cumulative Timesteps: 53,924,532
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 53924532...
Checkpoint 53924532 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.93403
Policy Entropy: 3.61696
Value Function Loss: 0.25758
Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.64247
Value Function Update Magnitude: 0.73589
Collected Steps per Second: 11,153.43671
Overall Steps per Second: 6,247.54329
Timestep Collection Time: 4.48418
Timestep Consumption Time: 3.52121
PPO Batch Consumption Time: 0.25542
Total Iteration Time: 8.00539
Cumulative Model Updates: 9,699
Cumulative Timesteps: 53,974,546
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.05689
Policy Entropy: 3.62304
Value Function Loss: 0.25149
Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.63785
Value Function Update Magnitude: 0.72353
Collected Steps per Second: 11,718.83157
Overall Steps per Second: 6,535.13819
Timestep Collection Time: 4.26698
Timestep Consumption Time: 3.38458
PPO Batch Consumption Time: 0.25513
Total Iteration Time: 7.65156
Cumulative Model Updates: 9,708
Cumulative Timesteps: 54,024,550
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 54024550...
Checkpoint 54024550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.59043
Policy Entropy: 3.62315
Value Function Loss: 0.25475
Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.63894
Value Function Update Magnitude: 0.74277
Collected Steps per Second: 11,634.81931
Overall Steps per Second: 6,569.56768
Timestep Collection Time: 4.30054
Timestep Consumption Time: 3.31579
PPO Batch Consumption Time: 0.25394
Total Iteration Time: 7.61633
Cumulative Model Updates: 9,717
Cumulative Timesteps: 54,074,586
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.49751
Policy Entropy: 3.61828
Value Function Loss: 0.26122
Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.64419
Value Function Update Magnitude: 0.73811
Collected Steps per Second: 11,585.11076
Overall Steps per Second: 6,449.21032
Timestep Collection Time: 4.31830
Timestep Consumption Time: 3.43893
PPO Batch Consumption Time: 0.25313
Total Iteration Time: 7.75723
Cumulative Model Updates: 9,726
Cumulative Timesteps: 54,124,614
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 54124614...
Checkpoint 54124614 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.59096
Policy Entropy: 3.61288
Value Function Loss: 0.24852
Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.65187
Value Function Update Magnitude: 0.78183
Collected Steps per Second: 11,699.56939
Overall Steps per Second: 6,468.90331
Timestep Collection Time: 4.27674
Timestep Consumption Time: 3.45811
PPO Batch Consumption Time: 0.26237
Total Iteration Time: 7.73485
Cumulative Model Updates: 9,735
Cumulative Timesteps: 54,174,650
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.63547
Policy Entropy: 3.61352
Value Function Loss: 0.25829
Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.64342
Value Function Update Magnitude: 0.73815
Collected Steps per Second: 12,042.26773
Overall Steps per Second: 6,610.21509
Timestep Collection Time: 4.15370
Timestep Consumption Time: 3.41337
PPO Batch Consumption Time: 0.25455
Total Iteration Time: 7.56708
Cumulative Model Updates: 9,744
Cumulative Timesteps: 54,224,670
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 54224670...
Checkpoint 54224670 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.11853
Policy Entropy: 3.61117
Value Function Loss: 0.24833
Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.63842
Value Function Update Magnitude: 0.73215
Collected Steps per Second: 11,608.55641
Overall Steps per Second: 6,493.80178
Timestep Collection Time: 4.30803
Timestep Consumption Time: 3.39316
PPO Batch Consumption Time: 0.25347
Total Iteration Time: 7.70119
Cumulative Model Updates: 9,753
Cumulative Timesteps: 54,274,680
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.17812
Policy Entropy: 3.61968
Value Function Loss: 0.25094
Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.64250
Value Function Update Magnitude: 0.69974
Collected Steps per Second: 11,412.70485
Overall Steps per Second: 6,518.22376
Timestep Collection Time: 4.38161
Timestep Consumption Time: 3.29011
PPO Batch Consumption Time: 0.25301
Total Iteration Time: 7.67172
Cumulative Model Updates: 9,762
Cumulative Timesteps: 54,324,686
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 54324686...
Checkpoint 54324686 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75390
Policy Entropy: 3.61717
Value Function Loss: 0.24945
Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.64426
Value Function Update Magnitude: 0.72542
Collected Steps per Second: 11,708.58914
Overall Steps per Second: 6,500.37253
Timestep Collection Time: 4.27344
Timestep Consumption Time: 3.42396
PPO Batch Consumption Time: 0.25502
Total Iteration Time: 7.69741
Cumulative Model Updates: 9,771
Cumulative Timesteps: 54,374,722
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.13224
Policy Entropy: 3.61788
Value Function Loss: 0.25910
Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.65399
Value Function Update Magnitude: 0.77035
Collected Steps per Second: 11,634.52654
Overall Steps per Second: 6,521.38502
Timestep Collection Time: 4.29927
Timestep Consumption Time: 3.37088
PPO Batch Consumption Time: 0.25510
Total Iteration Time: 7.67015
Cumulative Model Updates: 9,780
Cumulative Timesteps: 54,424,742
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 54424742...
Checkpoint 54424742 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42257
Policy Entropy: 3.60652
Value Function Loss: 0.25974
Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.66305
Value Function Update Magnitude: 0.77878
Collected Steps per Second: 11,850.24012
Overall Steps per Second: 6,495.26587
Timestep Collection Time: 4.22236
Timestep Consumption Time: 3.48110
PPO Batch Consumption Time: 0.26315
Total Iteration Time: 7.70346
Cumulative Model Updates: 9,789
Cumulative Timesteps: 54,474,778
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.51404
Policy Entropy: 3.60351
Value Function Loss: 0.26420
Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11963
Policy Update Magnitude: 0.66297
Value Function Update Magnitude: 0.80509
Collected Steps per Second: 11,618.98784
Overall Steps per Second: 6,475.79007
Timestep Collection Time: 4.30692
Timestep Consumption Time: 3.42064
PPO Batch Consumption Time: 0.25375
Total Iteration Time: 7.72755
Cumulative Model Updates: 9,798
Cumulative Timesteps: 54,524,820
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 54524820...
Checkpoint 54524820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.20420
Policy Entropy: 3.60680
Value Function Loss: 0.25972
Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.66425
Value Function Update Magnitude: 0.81289
Collected Steps per Second: 11,679.00778
Overall Steps per Second: 6,527.92046
Timestep Collection Time: 4.28153
Timestep Consumption Time: 3.37849
PPO Batch Consumption Time: 0.25522
Total Iteration Time: 7.66002
Cumulative Model Updates: 9,807
Cumulative Timesteps: 54,574,824
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.90324
Policy Entropy: 3.61528
Value Function Loss: 0.25840
Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.65338
Value Function Update Magnitude: 0.81559
Collected Steps per Second: 12,129.79158
Overall Steps per Second: 6,639.28570
Timestep Collection Time: 4.12373
Timestep Consumption Time: 3.41021
PPO Batch Consumption Time: 0.25479
Total Iteration Time: 7.53394
Cumulative Model Updates: 9,816
Cumulative Timesteps: 54,624,844
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 54624844...
Checkpoint 54624844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.65341
Policy Entropy: 3.61330
Value Function Loss: 0.24919
Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.64624
Value Function Update Magnitude: 0.82486
Collected Steps per Second: 11,718.15533
Overall Steps per Second: 6,527.56555
Timestep Collection Time: 4.27166
Timestep Consumption Time: 3.39674
PPO Batch Consumption Time: 0.25508
Total Iteration Time: 7.66840
Cumulative Model Updates: 9,825
Cumulative Timesteps: 54,674,900
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.08907
Policy Entropy: 3.61570
Value Function Loss: 0.25831
Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.65514
Value Function Update Magnitude: 0.83895
Collected Steps per Second: 11,661.54583
Overall Steps per Second: 6,591.13902
Timestep Collection Time: 4.29051
Timestep Consumption Time: 3.30059
PPO Batch Consumption Time: 0.25382
Total Iteration Time: 7.59110
Cumulative Model Updates: 9,834
Cumulative Timesteps: 54,724,934
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 54724934...
Checkpoint 54724934 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.91642
Policy Entropy: 3.61784
Value Function Loss: 0.26332
Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.65088
Value Function Update Magnitude: 0.80440
Collected Steps per Second: 11,661.57967
Overall Steps per Second: 6,450.95770
Timestep Collection Time: 4.28793
Timestep Consumption Time: 3.46348
PPO Batch Consumption Time: 0.26314
Total Iteration Time: 7.75141
Cumulative Model Updates: 9,843
Cumulative Timesteps: 54,774,938
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.50086
Policy Entropy: 3.61728
Value Function Loss: 0.25693
Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.64203
Value Function Update Magnitude: 0.76503
Collected Steps per Second: 11,708.98481
Overall Steps per Second: 6,661.09166
Timestep Collection Time: 4.27347
Timestep Consumption Time: 3.23851
PPO Batch Consumption Time: 0.23964
Total Iteration Time: 7.51198
Cumulative Model Updates: 9,852
Cumulative Timesteps: 54,824,976
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 54824976...
Checkpoint 54824976 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.78764
Policy Entropy: 3.61042
Value Function Loss: 0.24643
Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.64114
Value Function Update Magnitude: 0.79061
Collected Steps per Second: 12,807.69287
Overall Steps per Second: 7,028.07076
Timestep Collection Time: 3.90687
Timestep Consumption Time: 3.21286
PPO Batch Consumption Time: 0.23432
Total Iteration Time: 7.11973
Cumulative Model Updates: 9,861
Cumulative Timesteps: 54,875,014
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.76296
Policy Entropy: 3.60993
Value Function Loss: 0.25753
Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.65441
Value Function Update Magnitude: 0.80464
Collected Steps per Second: 12,503.00450
Overall Steps per Second: 6,937.02514
Timestep Collection Time: 3.99984
Timestep Consumption Time: 3.20930
PPO Batch Consumption Time: 0.23467
Total Iteration Time: 7.20914
Cumulative Model Updates: 9,870
Cumulative Timesteps: 54,925,024
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 54925024...
Checkpoint 54925024 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.73472
Policy Entropy: 3.61669
Value Function Loss: 0.26477
Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12220
Policy Update Magnitude: 0.66782
Value Function Update Magnitude: 0.83749
Collected Steps per Second: 12,593.35168
Overall Steps per Second: 7,008.68626
Timestep Collection Time: 3.97035
Timestep Consumption Time: 3.16366
PPO Batch Consumption Time: 0.23447
Total Iteration Time: 7.13400
Cumulative Model Updates: 9,879
Cumulative Timesteps: 54,975,024
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.84627
Policy Entropy: 3.61645
Value Function Loss: 0.27671
Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11994
Policy Update Magnitude: 0.67150
Value Function Update Magnitude: 0.79999
Collected Steps per Second: 12,981.99688
Overall Steps per Second: 7,115.39345
Timestep Collection Time: 3.85149
Timestep Consumption Time: 3.17553
PPO Batch Consumption Time: 0.23417
Total Iteration Time: 7.02702
Cumulative Model Updates: 9,888
Cumulative Timesteps: 55,025,024
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 55025024...
Checkpoint 55025024 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85570
Policy Entropy: 3.62360
Value Function Loss: 0.25095
Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.66081
Value Function Update Magnitude: 0.85677
Collected Steps per Second: 12,485.04593
Overall Steps per Second: 6,973.68624
Timestep Collection Time: 4.00543
Timestep Consumption Time: 3.16552
PPO Batch Consumption Time: 0.23352
Total Iteration Time: 7.17096
Cumulative Model Updates: 9,897
Cumulative Timesteps: 55,075,032
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.61176
Policy Entropy: 3.62220
Value Function Loss: 0.24309
Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.64638
Value Function Update Magnitude: 0.77667
Collected Steps per Second: 11,996.80421
Overall Steps per Second: 6,676.15433
Timestep Collection Time: 4.17061
Timestep Consumption Time: 3.32382
PPO Batch Consumption Time: 0.24867
Total Iteration Time: 7.49443
Cumulative Model Updates: 9,906
Cumulative Timesteps: 55,125,066
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 55125066...
Checkpoint 55125066 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.47125
Policy Entropy: 3.62252
Value Function Loss: 0.25094
Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.65001
Value Function Update Magnitude: 0.75291
Collected Steps per Second: 12,649.72821
Overall Steps per Second: 7,002.98901
Timestep Collection Time: 3.95534
Timestep Consumption Time: 3.18932
PPO Batch Consumption Time: 0.23392
Total Iteration Time: 7.14466
Cumulative Model Updates: 9,915
Cumulative Timesteps: 55,175,100
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.48188
Policy Entropy: 3.62228
Value Function Loss: 0.26470
Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.66006
Value Function Update Magnitude: 0.77597
Collected Steps per Second: 12,595.07548
Overall Steps per Second: 7,017.54022
Timestep Collection Time: 3.96996
Timestep Consumption Time: 3.15532
PPO Batch Consumption Time: 0.23370
Total Iteration Time: 7.12529
Cumulative Model Updates: 9,924
Cumulative Timesteps: 55,225,102
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 55225102...
Checkpoint 55225102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.82478
Policy Entropy: 3.62371
Value Function Loss: 0.27019
Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.66495
Value Function Update Magnitude: 0.82815
Collected Steps per Second: 12,752.23927
Overall Steps per Second: 7,057.98670
Timestep Collection Time: 3.92308
Timestep Consumption Time: 3.16506
PPO Batch Consumption Time: 0.23360
Total Iteration Time: 7.08814
Cumulative Model Updates: 9,933
Cumulative Timesteps: 55,275,130
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.19908
Policy Entropy: 3.62287
Value Function Loss: 0.25961
Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.66500
Value Function Update Magnitude: 0.78060
Collected Steps per Second: 12,581.52835
Overall Steps per Second: 6,977.53859
Timestep Collection Time: 3.97487
Timestep Consumption Time: 3.19241
PPO Batch Consumption Time: 0.23385
Total Iteration Time: 7.16728
Cumulative Model Updates: 9,942
Cumulative Timesteps: 55,325,140
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 55325140...
Checkpoint 55325140 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11986
Policy Entropy: 3.62017
Value Function Loss: 0.25957
Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.66560
Value Function Update Magnitude: 0.72452
Collected Steps per Second: 12,575.23561
Overall Steps per Second: 7,004.27665
Timestep Collection Time: 3.97814
Timestep Consumption Time: 3.16407
PPO Batch Consumption Time: 0.23406
Total Iteration Time: 7.14221
Cumulative Model Updates: 9,951
Cumulative Timesteps: 55,375,166
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38328
Policy Entropy: 3.62261
Value Function Loss: 0.25797
Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.65610
Value Function Update Magnitude: 0.69196
Collected Steps per Second: 12,907.18934
Overall Steps per Second: 7,079.29718
Timestep Collection Time: 3.87598
Timestep Consumption Time: 3.19082
PPO Batch Consumption Time: 0.23353
Total Iteration Time: 7.06680
Cumulative Model Updates: 9,960
Cumulative Timesteps: 55,425,194
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 55425194...
Checkpoint 55425194 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.35995
Policy Entropy: 3.61364
Value Function Loss: 0.26030
Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.65298
Value Function Update Magnitude: 0.73526
Collected Steps per Second: 12,687.56273
Overall Steps per Second: 6,834.31251
Timestep Collection Time: 3.94307
Timestep Consumption Time: 3.37705
PPO Batch Consumption Time: 0.24815
Total Iteration Time: 7.32012
Cumulative Model Updates: 9,969
Cumulative Timesteps: 55,475,222
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.89533
Policy Entropy: 3.61799
Value Function Loss: 0.25570
Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.65410
Value Function Update Magnitude: 0.71014
Collected Steps per Second: 12,486.44339
Overall Steps per Second: 7,040.30681
Timestep Collection Time: 4.00450
Timestep Consumption Time: 3.09774
PPO Batch Consumption Time: 0.23453
Total Iteration Time: 7.10225
Cumulative Model Updates: 9,978
Cumulative Timesteps: 55,525,224
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 55525224...
Checkpoint 55525224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23383
Policy Entropy: 3.62341
Value Function Loss: 0.25782
Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.65834
Value Function Update Magnitude: 0.72041
Collected Steps per Second: 12,521.90294
Overall Steps per Second: 6,978.08839
Timestep Collection Time: 3.99524
Timestep Consumption Time: 3.17406
PPO Batch Consumption Time: 0.23349
Total Iteration Time: 7.16930
Cumulative Model Updates: 9,987
Cumulative Timesteps: 55,575,252
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.33673
Policy Entropy: 3.62573
Value Function Loss: 0.26629
Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.66941
Value Function Update Magnitude: 0.74532
Collected Steps per Second: 12,599.53036
Overall Steps per Second: 7,005.69611
Timestep Collection Time: 3.96935
Timestep Consumption Time: 3.16941
PPO Batch Consumption Time: 0.23414
Total Iteration Time: 7.13876
Cumulative Model Updates: 9,996
Cumulative Timesteps: 55,625,264
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 55625264...
Checkpoint 55625264 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70981
Policy Entropy: 3.63052
Value Function Loss: 0.26397
Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.66518
Value Function Update Magnitude: 0.79827
Collected Steps per Second: 12,737.28412
Overall Steps per Second: 7,020.48153
Timestep Collection Time: 3.92705
Timestep Consumption Time: 3.19781
PPO Batch Consumption Time: 0.23428
Total Iteration Time: 7.12487
Cumulative Model Updates: 10,005
Cumulative Timesteps: 55,675,284
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 20.18822
Policy Entropy: 3.61997
Value Function Loss: 0.27417
Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.67421
Value Function Update Magnitude: 0.76926
Collected Steps per Second: 12,464.85411
Overall Steps per Second: 6,940.34731
Timestep Collection Time: 4.01192
Timestep Consumption Time: 3.19348
PPO Batch Consumption Time: 0.23418
Total Iteration Time: 7.20540
Cumulative Model Updates: 10,014
Cumulative Timesteps: 55,725,292
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 55725292...
Checkpoint 55725292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.09054
Policy Entropy: 3.62119
Value Function Loss: 0.28019
Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.67934
Value Function Update Magnitude: 0.80140
Collected Steps per Second: 12,451.41256
Overall Steps per Second: 6,982.35541
Timestep Collection Time: 4.01593
Timestep Consumption Time: 3.14555
PPO Batch Consumption Time: 0.23440
Total Iteration Time: 7.16148
Cumulative Model Updates: 10,023
Cumulative Timesteps: 55,775,296
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.25262
Policy Entropy: 3.61725
Value Function Loss: 0.28128
Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.68858
Value Function Update Magnitude: 0.73523
Collected Steps per Second: 12,696.79899
Overall Steps per Second: 6,897.67122
Timestep Collection Time: 3.94241
Timestep Consumption Time: 3.31453
PPO Batch Consumption Time: 0.24482
Total Iteration Time: 7.25694
Cumulative Model Updates: 10,032
Cumulative Timesteps: 55,825,352
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 55825352...
Checkpoint 55825352 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.75123
Policy Entropy: 3.62098
Value Function Loss: 0.26828
Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.67568
Value Function Update Magnitude: 0.74018
Collected Steps per Second: 12,529.84513
Overall Steps per Second: 6,964.21363
Timestep Collection Time: 3.99127
Timestep Consumption Time: 3.18973
PPO Batch Consumption Time: 0.23371
Total Iteration Time: 7.18100
Cumulative Model Updates: 10,041
Cumulative Timesteps: 55,875,362
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.13780
Policy Entropy: 3.62415
Value Function Loss: 0.25236
Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.65991
Value Function Update Magnitude: 0.69363
Collected Steps per Second: 12,589.83308
Overall Steps per Second: 7,065.49654
Timestep Collection Time: 3.97273
Timestep Consumption Time: 3.10618
PPO Batch Consumption Time: 0.23387
Total Iteration Time: 7.07891
Cumulative Model Updates: 10,050
Cumulative Timesteps: 55,925,378
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 55925378...
Checkpoint 55925378 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81164
Policy Entropy: 3.62301
Value Function Loss: 0.26341
Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.66266
Value Function Update Magnitude: 0.73425
Collected Steps per Second: 12,208.45069
Overall Steps per Second: 6,859.87228
Timestep Collection Time: 4.09733
Timestep Consumption Time: 3.19465
PPO Batch Consumption Time: 0.23470
Total Iteration Time: 7.29197
Cumulative Model Updates: 10,059
Cumulative Timesteps: 55,975,400
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95177
Policy Entropy: 3.62759
Value Function Loss: 0.26891
Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.67063
Value Function Update Magnitude: 0.76868
Collected Steps per Second: 11,545.05663
Overall Steps per Second: 6,510.74557
Timestep Collection Time: 4.33224
Timestep Consumption Time: 3.34983
PPO Batch Consumption Time: 0.24341
Total Iteration Time: 7.68207
Cumulative Model Updates: 10,068
Cumulative Timesteps: 56,025,416
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 56025416...
Checkpoint 56025416 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.86020
Policy Entropy: 3.62322
Value Function Loss: 0.25636
Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.66493
Value Function Update Magnitude: 0.85352
Collected Steps per Second: 11,636.82455
Overall Steps per Second: 6,624.09919
Timestep Collection Time: 4.29945
Timestep Consumption Time: 3.25357
PPO Batch Consumption Time: 0.23836
Total Iteration Time: 7.55303
Cumulative Model Updates: 10,077
Cumulative Timesteps: 56,075,448
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.45847
Policy Entropy: 3.63097
Value Function Loss: 0.24570
Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.65420
Value Function Update Magnitude: 0.77351
Collected Steps per Second: 11,656.44057
Overall Steps per Second: 6,441.45738
Timestep Collection Time: 4.29033
Timestep Consumption Time: 3.47344
PPO Batch Consumption Time: 0.24936
Total Iteration Time: 7.76377
Cumulative Model Updates: 10,086
Cumulative Timesteps: 56,125,458
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 56125458...
Checkpoint 56125458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.18376
Policy Entropy: 3.63110
Value Function Loss: 0.25974
Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.65722
Value Function Update Magnitude: 0.72115
Collected Steps per Second: 11,946.63508
Overall Steps per Second: 6,717.75050
Timestep Collection Time: 4.18796
Timestep Consumption Time: 3.25977
PPO Batch Consumption Time: 0.23955
Total Iteration Time: 7.44773
Cumulative Model Updates: 10,095
Cumulative Timesteps: 56,175,490
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.84593
Policy Entropy: 3.62471
Value Function Loss: 0.26238
Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.65926
Value Function Update Magnitude: 0.72257
Collected Steps per Second: 11,876.27630
Overall Steps per Second: 6,696.65519
Timestep Collection Time: 4.21428
Timestep Consumption Time: 3.25960
PPO Batch Consumption Time: 0.23481
Total Iteration Time: 7.47388
Cumulative Model Updates: 10,104
Cumulative Timesteps: 56,225,540
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 56225540...
Checkpoint 56225540 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.89855
Policy Entropy: 3.62562
Value Function Loss: 0.26435
Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.65726
Value Function Update Magnitude: 0.73676
Collected Steps per Second: 12,303.03717
Overall Steps per Second: 6,887.13141
Timestep Collection Time: 4.06631
Timestep Consumption Time: 3.19767
PPO Batch Consumption Time: 0.23465
Total Iteration Time: 7.26398
Cumulative Model Updates: 10,113
Cumulative Timesteps: 56,275,568
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.03695
Policy Entropy: 3.62072
Value Function Loss: 0.26244
Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.66643
Value Function Update Magnitude: 0.75557
Collected Steps per Second: 11,352.25697
Overall Steps per Second: 6,502.54753
Timestep Collection Time: 4.40529
Timestep Consumption Time: 3.28554
PPO Batch Consumption Time: 0.24902
Total Iteration Time: 7.69083
Cumulative Model Updates: 10,122
Cumulative Timesteps: 56,325,578
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 56325578...
Checkpoint 56325578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.79506
Policy Entropy: 3.62589
Value Function Loss: 0.25505
Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11554
Policy Update Magnitude: 0.67258
Value Function Update Magnitude: 0.91381
Collected Steps per Second: 11,051.11694
Overall Steps per Second: 6,270.40053
Timestep Collection Time: 4.52479
Timestep Consumption Time: 3.44982
PPO Batch Consumption Time: 0.25766
Total Iteration Time: 7.97461
Cumulative Model Updates: 10,131
Cumulative Timesteps: 56,375,582
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85303
Policy Entropy: 3.62841
Value Function Loss: 0.24950
Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11421
Policy Update Magnitude: 0.66829
Value Function Update Magnitude: 0.90802
Collected Steps per Second: 12,141.52613
Overall Steps per Second: 6,873.04633
Timestep Collection Time: 4.11909
Timestep Consumption Time: 3.15745
PPO Batch Consumption Time: 0.23412
Total Iteration Time: 7.27654
Cumulative Model Updates: 10,140
Cumulative Timesteps: 56,425,594
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 56425594...
Checkpoint 56425594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.29377
Policy Entropy: 3.62618
Value Function Loss: 0.23918
Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.66013
Value Function Update Magnitude: 0.86823
Collected Steps per Second: 12,807.25436
Overall Steps per Second: 6,857.12985
Timestep Collection Time: 3.90404
Timestep Consumption Time: 3.38764
PPO Batch Consumption Time: 0.25175
Total Iteration Time: 7.29168
Cumulative Model Updates: 10,149
Cumulative Timesteps: 56,475,594
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.25537
Policy Entropy: 3.61790
Value Function Loss: 0.25924
Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11344
Policy Update Magnitude: 0.66520
Value Function Update Magnitude: 0.76169
Collected Steps per Second: 12,121.09586
Overall Steps per Second: 6,832.83296
Timestep Collection Time: 4.12850
Timestep Consumption Time: 3.19525
PPO Batch Consumption Time: 0.23418
Total Iteration Time: 7.32376
Cumulative Model Updates: 10,158
Cumulative Timesteps: 56,525,636
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 56525636...
Checkpoint 56525636 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 20.41002
Policy Entropy: 3.61568
Value Function Loss: 0.25916
Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.67561
Value Function Update Magnitude: 0.78643
Collected Steps per Second: 12,457.41402
Overall Steps per Second: 6,963.05427
Timestep Collection Time: 4.01367
Timestep Consumption Time: 3.16708
PPO Batch Consumption Time: 0.23470
Total Iteration Time: 7.18076
Cumulative Model Updates: 10,167
Cumulative Timesteps: 56,575,636
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.38577
Policy Entropy: 3.61141
Value Function Loss: 0.26084
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.67596
Value Function Update Magnitude: 0.74759
Collected Steps per Second: 12,808.49495
Overall Steps per Second: 7,040.02691
Timestep Collection Time: 3.90647
Timestep Consumption Time: 3.20089
PPO Batch Consumption Time: 0.23364
Total Iteration Time: 7.10736
Cumulative Model Updates: 10,176
Cumulative Timesteps: 56,625,672
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 56625672...
Checkpoint 56625672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.72603
Policy Entropy: 3.61711
Value Function Loss: 0.25360
Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.67130
Value Function Update Magnitude: 0.73767
Collected Steps per Second: 12,656.77597
Overall Steps per Second: 7,000.56698
Timestep Collection Time: 3.95298
Timestep Consumption Time: 3.19387
PPO Batch Consumption Time: 0.23403
Total Iteration Time: 7.14685
Cumulative Model Updates: 10,185
Cumulative Timesteps: 56,675,704
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.65779
Policy Entropy: 3.61474
Value Function Loss: 0.24470
Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.66520
Value Function Update Magnitude: 0.75282
Collected Steps per Second: 12,530.65181
Overall Steps per Second: 7,067.87986
Timestep Collection Time: 3.99181
Timestep Consumption Time: 3.08528
PPO Batch Consumption Time: 0.23415
Total Iteration Time: 7.07709
Cumulative Model Updates: 10,194
Cumulative Timesteps: 56,725,724
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 56725724...
Checkpoint 56725724 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85760
Policy Entropy: 3.61585
Value Function Loss: 0.24702
Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.66553
Value Function Update Magnitude: 0.73271
Collected Steps per Second: 12,365.16961
Overall Steps per Second: 6,925.17429
Timestep Collection Time: 4.04475
Timestep Consumption Time: 3.17731
PPO Batch Consumption Time: 0.23422
Total Iteration Time: 7.22206
Cumulative Model Updates: 10,203
Cumulative Timesteps: 56,775,738
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56685
Policy Entropy: 3.61314
Value Function Loss: 0.24630
Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.66488
Value Function Update Magnitude: 0.72100
Collected Steps per Second: 12,461.50579
Overall Steps per Second: 6,777.44059
Timestep Collection Time: 4.01236
Timestep Consumption Time: 3.36506
PPO Batch Consumption Time: 0.25087
Total Iteration Time: 7.37742
Cumulative Model Updates: 10,212
Cumulative Timesteps: 56,825,738
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 56825738...
Checkpoint 56825738 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42289
Policy Entropy: 3.60850
Value Function Loss: 0.25894
Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.67964
Value Function Update Magnitude: 0.74198
Collected Steps per Second: 12,824.10959
Overall Steps per Second: 7,043.47875
Timestep Collection Time: 3.90093
Timestep Consumption Time: 3.20152
PPO Batch Consumption Time: 0.23410
Total Iteration Time: 7.10246
Cumulative Model Updates: 10,221
Cumulative Timesteps: 56,875,764
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.56284
Policy Entropy: 3.61200
Value Function Loss: 0.25499
Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.69791
Value Function Update Magnitude: 0.80672
Collected Steps per Second: 12,588.64434
Overall Steps per Second: 6,832.37242
Timestep Collection Time: 3.97215
Timestep Consumption Time: 3.34654
PPO Batch Consumption Time: 0.24838
Total Iteration Time: 7.31869
Cumulative Model Updates: 10,230
Cumulative Timesteps: 56,925,768
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 56925768...
Checkpoint 56925768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.23506
Policy Entropy: 3.61059
Value Function Loss: 0.26055
Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.68096
Value Function Update Magnitude: 0.76091
Collected Steps per Second: 12,122.23010
Overall Steps per Second: 6,781.69771
Timestep Collection Time: 4.12581
Timestep Consumption Time: 3.24904
PPO Batch Consumption Time: 0.24389
Total Iteration Time: 7.37485
Cumulative Model Updates: 10,239
Cumulative Timesteps: 56,975,782
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.58921
Policy Entropy: 3.61601
Value Function Loss: 0.24671
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.67197
Value Function Update Magnitude: 0.76739
Collected Steps per Second: 11,254.55468
Overall Steps per Second: 6,449.29308
Timestep Collection Time: 4.44282
Timestep Consumption Time: 3.31027
PPO Batch Consumption Time: 0.24140
Total Iteration Time: 7.75310
Cumulative Model Updates: 10,248
Cumulative Timesteps: 57,025,784
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 57025784...
Checkpoint 57025784 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.77695
Policy Entropy: 3.61010
Value Function Loss: 0.25475
Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.66546
Value Function Update Magnitude: 0.75046
Collected Steps per Second: 12,511.00370
Overall Steps per Second: 6,973.02794
Timestep Collection Time: 3.99968
Timestep Consumption Time: 3.17654
PPO Batch Consumption Time: 0.23439
Total Iteration Time: 7.17622
Cumulative Model Updates: 10,257
Cumulative Timesteps: 57,075,824
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.45716
Policy Entropy: 3.60951
Value Function Loss: 0.26162
Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.67030
Value Function Update Magnitude: 0.79136
Collected Steps per Second: 12,582.26223
Overall Steps per Second: 7,103.50969
Timestep Collection Time: 3.97417
Timestep Consumption Time: 3.06517
PPO Batch Consumption Time: 0.23500
Total Iteration Time: 7.03934
Cumulative Model Updates: 10,266
Cumulative Timesteps: 57,125,828
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 57125828...
Checkpoint 57125828 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.05697
Policy Entropy: 3.61046
Value Function Loss: 0.26276
Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.68909
Value Function Update Magnitude: 0.82810
Collected Steps per Second: 12,547.88371
Overall Steps per Second: 6,803.51523
Timestep Collection Time: 3.98601
Timestep Consumption Time: 3.36548
PPO Batch Consumption Time: 0.24736
Total Iteration Time: 7.35149
Cumulative Model Updates: 10,275
Cumulative Timesteps: 57,175,844
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.15601
Policy Entropy: 3.61095
Value Function Loss: 0.26022
Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11378
Policy Update Magnitude: 0.68551
Value Function Update Magnitude: 0.84078
Collected Steps per Second: 12,337.17448
Overall Steps per Second: 6,944.52262
Timestep Collection Time: 4.05506
Timestep Consumption Time: 3.14889
PPO Batch Consumption Time: 0.23384
Total Iteration Time: 7.20395
Cumulative Model Updates: 10,284
Cumulative Timesteps: 57,225,872
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 57225872...
Checkpoint 57225872 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.24446
Policy Entropy: 3.60910
Value Function Loss: 0.25791
Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.68116
Value Function Update Magnitude: 0.81595
Collected Steps per Second: 12,617.28338
Overall Steps per Second: 7,006.63818
Timestep Collection Time: 3.96678
Timestep Consumption Time: 3.17645
PPO Batch Consumption Time: 0.23364
Total Iteration Time: 7.14323
Cumulative Model Updates: 10,293
Cumulative Timesteps: 57,275,922
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.95007
Policy Entropy: 3.60746
Value Function Loss: 0.25574
Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.68441
Value Function Update Magnitude: 0.89278
Collected Steps per Second: 12,578.06034
Overall Steps per Second: 6,979.69924
Timestep Collection Time: 3.97708
Timestep Consumption Time: 3.18999
PPO Batch Consumption Time: 0.23420
Total Iteration Time: 7.16707
Cumulative Model Updates: 10,302
Cumulative Timesteps: 57,325,946
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 57325946...
Checkpoint 57325946 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.37896
Policy Entropy: 3.61126
Value Function Loss: 0.24674
Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.68269
Value Function Update Magnitude: 0.90957
Collected Steps per Second: 12,397.58267
Overall Steps per Second: 6,957.38646
Timestep Collection Time: 4.03385
Timestep Consumption Time: 3.15419
PPO Batch Consumption Time: 0.23442
Total Iteration Time: 7.18804
Cumulative Model Updates: 10,311
Cumulative Timesteps: 57,375,956
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.42251
Policy Entropy: 3.61741
Value Function Loss: 0.23159
Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.67473
Value Function Update Magnitude: 0.98491
Collected Steps per Second: 12,847.45250
Overall Steps per Second: 7,049.48146
Timestep Collection Time: 3.89431
Timestep Consumption Time: 3.20295
PPO Batch Consumption Time: 0.23470
Total Iteration Time: 7.09726
Cumulative Model Updates: 10,320
Cumulative Timesteps: 57,425,988
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 57425988...
Checkpoint 57425988 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.82044
Policy Entropy: 3.61445
Value Function Loss: 0.24099
Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.67282
Value Function Update Magnitude: 0.81094
Collected Steps per Second: 12,399.40195
Overall Steps per Second: 6,920.51091
Timestep Collection Time: 4.03665
Timestep Consumption Time: 3.19577
PPO Batch Consumption Time: 0.23400
Total Iteration Time: 7.23241
Cumulative Model Updates: 10,329
Cumulative Timesteps: 57,476,040
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.00190
Policy Entropy: 3.62000
Value Function Loss: 0.24620
Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.66578
Value Function Update Magnitude: 0.79355
Collected Steps per Second: 11,087.97845
Overall Steps per Second: 6,385.09185
Timestep Collection Time: 4.50993
Timestep Consumption Time: 3.32175
PPO Batch Consumption Time: 0.25175
Total Iteration Time: 7.83168
Cumulative Model Updates: 10,338
Cumulative Timesteps: 57,526,046
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 57526046...
Checkpoint 57526046 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.02250
Policy Entropy: 3.61489
Value Function Loss: 0.25753
Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.67537
Value Function Update Magnitude: 0.87067
Collected Steps per Second: 11,785.18453
Overall Steps per Second: 6,738.58469
Timestep Collection Time: 4.24465
Timestep Consumption Time: 3.17887
PPO Batch Consumption Time: 0.23416
Total Iteration Time: 7.42352
Cumulative Model Updates: 10,347
Cumulative Timesteps: 57,576,070
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.42666
Policy Entropy: 3.62059
Value Function Loss: 0.24003
Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.67179
Value Function Update Magnitude: 0.83004
Collected Steps per Second: 12,554.43733
Overall Steps per Second: 6,998.85395
Timestep Collection Time: 3.98297
Timestep Consumption Time: 3.16162
PPO Batch Consumption Time: 0.23447
Total Iteration Time: 7.14460
Cumulative Model Updates: 10,356
Cumulative Timesteps: 57,626,074
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 57626074...
Checkpoint 57626074 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.79826
Policy Entropy: 3.61638
Value Function Loss: 0.24555
Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.67489
Value Function Update Magnitude: 0.85555
Collected Steps per Second: 12,431.02765
Overall Steps per Second: 6,812.13847
Timestep Collection Time: 4.02364
Timestep Consumption Time: 3.31884
PPO Batch Consumption Time: 0.24276
Total Iteration Time: 7.34248
Cumulative Model Updates: 10,365
Cumulative Timesteps: 57,676,092
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.40150
Policy Entropy: 3.61877
Value Function Loss: 0.23452
Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.67848
Value Function Update Magnitude: 0.88819
Collected Steps per Second: 11,771.85231
Overall Steps per Second: 6,626.09844
Timestep Collection Time: 4.24844
Timestep Consumption Time: 3.29929
PPO Batch Consumption Time: 0.23646
Total Iteration Time: 7.54773
Cumulative Model Updates: 10,374
Cumulative Timesteps: 57,726,104
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 57726104...
Checkpoint 57726104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.99983
Policy Entropy: 3.62064
Value Function Loss: 0.22961
Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.66041
Value Function Update Magnitude: 1.06594
Collected Steps per Second: 12,249.06844
Overall Steps per Second: 6,904.67029
Timestep Collection Time: 4.08390
Timestep Consumption Time: 3.16105
PPO Batch Consumption Time: 0.23456
Total Iteration Time: 7.24495
Cumulative Model Updates: 10,383
Cumulative Timesteps: 57,776,128
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.69273
Policy Entropy: 3.62630
Value Function Loss: 0.21964
Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.66466
Value Function Update Magnitude: 1.06220
Collected Steps per Second: 12,423.79821
Overall Steps per Second: 6,942.32682
Timestep Collection Time: 4.02743
Timestep Consumption Time: 3.17995
PPO Batch Consumption Time: 0.23402
Total Iteration Time: 7.20738
Cumulative Model Updates: 10,392
Cumulative Timesteps: 57,826,164
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 57826164...
Checkpoint 57826164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52412
Policy Entropy: 3.62447
Value Function Loss: 0.21774
Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.65626
Value Function Update Magnitude: 0.98026
Collected Steps per Second: 12,432.03445
Overall Steps per Second: 6,825.30839
Timestep Collection Time: 4.02299
Timestep Consumption Time: 3.30473
PPO Batch Consumption Time: 0.24454
Total Iteration Time: 7.32773
Cumulative Model Updates: 10,401
Cumulative Timesteps: 57,876,178
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.41486
Policy Entropy: 3.61467
Value Function Loss: 0.22376
Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.64984
Value Function Update Magnitude: 0.98260
Collected Steps per Second: 12,442.36512
Overall Steps per Second: 7,032.35385
Timestep Collection Time: 4.01933
Timestep Consumption Time: 3.09208
PPO Batch Consumption Time: 0.23431
Total Iteration Time: 7.11142
Cumulative Model Updates: 10,410
Cumulative Timesteps: 57,926,188
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 57926188...
Checkpoint 57926188 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.02179
Policy Entropy: 3.61727
Value Function Loss: 0.23722
Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.65527
Value Function Update Magnitude: 0.87225
Collected Steps per Second: 12,580.34663
Overall Steps per Second: 6,968.28322
Timestep Collection Time: 3.97652
Timestep Consumption Time: 3.20258
PPO Batch Consumption Time: 0.23378
Total Iteration Time: 7.17910
Cumulative Model Updates: 10,419
Cumulative Timesteps: 57,976,214
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.97637
Policy Entropy: 3.61717
Value Function Loss: 0.23969
Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.66373
Value Function Update Magnitude: 0.75982
Collected Steps per Second: 12,489.04549
Overall Steps per Second: 6,948.88479
Timestep Collection Time: 4.00463
Timestep Consumption Time: 3.19278
PPO Batch Consumption Time: 0.23423
Total Iteration Time: 7.19741
Cumulative Model Updates: 10,428
Cumulative Timesteps: 58,026,228
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 58026228...
Checkpoint 58026228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.98683
Policy Entropy: 3.61934
Value Function Loss: 0.23985
Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11654
Policy Update Magnitude: 0.66340
Value Function Update Magnitude: 0.76256
Collected Steps per Second: 12,816.72385
Overall Steps per Second: 7,087.85516
Timestep Collection Time: 3.90303
Timestep Consumption Time: 3.15468
PPO Batch Consumption Time: 0.23485
Total Iteration Time: 7.05771
Cumulative Model Updates: 10,437
Cumulative Timesteps: 58,076,252
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58781
Policy Entropy: 3.62076
Value Function Loss: 0.23372
Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.11268
Policy Update Magnitude: 0.65551
Value Function Update Magnitude: 0.74599
Collected Steps per Second: 12,474.06288
Overall Steps per Second: 6,948.74959
Timestep Collection Time: 4.00912
Timestep Consumption Time: 3.18786
PPO Batch Consumption Time: 0.23516
Total Iteration Time: 7.19698
Cumulative Model Updates: 10,446
Cumulative Timesteps: 58,126,262
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 58126262...
Checkpoint 58126262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52259
Policy Entropy: 3.63076
Value Function Loss: 0.23231
Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.66028
Value Function Update Magnitude: 0.73205
Collected Steps per Second: 12,605.03344
Overall Steps per Second: 7,002.13118
Timestep Collection Time: 3.96937
Timestep Consumption Time: 3.17617
PPO Batch Consumption Time: 0.23486
Total Iteration Time: 7.14554
Cumulative Model Updates: 10,455
Cumulative Timesteps: 58,176,296
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.20998
Policy Entropy: 3.62621
Value Function Loss: 0.23712
Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11403
Policy Update Magnitude: 0.66398
Value Function Update Magnitude: 0.73485
Collected Steps per Second: 12,763.02797
Overall Steps per Second: 6,952.06914
Timestep Collection Time: 3.92039
Timestep Consumption Time: 3.27690
PPO Batch Consumption Time: 0.24334
Total Iteration Time: 7.19728
Cumulative Model Updates: 10,464
Cumulative Timesteps: 58,226,332
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 58226332...
Checkpoint 58226332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.34903
Policy Entropy: 3.63014
Value Function Loss: 0.23970
Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.66488
Value Function Update Magnitude: 0.75680
Collected Steps per Second: 12,372.35367
Overall Steps per Second: 6,897.52215
Timestep Collection Time: 4.04240
Timestep Consumption Time: 3.20861
PPO Batch Consumption Time: 0.23387
Total Iteration Time: 7.25101
Cumulative Model Updates: 10,473
Cumulative Timesteps: 58,276,346
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.68094
Policy Entropy: 3.62407
Value Function Loss: 0.23582
Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.65790
Value Function Update Magnitude: 0.78922
Collected Steps per Second: 12,452.27539
Overall Steps per Second: 7,040.90215
Timestep Collection Time: 4.01645
Timestep Consumption Time: 3.08690
PPO Batch Consumption Time: 0.23421
Total Iteration Time: 7.10335
Cumulative Model Updates: 10,482
Cumulative Timesteps: 58,326,360
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 58326360...
Checkpoint 58326360 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.32078
Policy Entropy: 3.62257
Value Function Loss: 0.23896
Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.66255
Value Function Update Magnitude: 0.81680
Collected Steps per Second: 12,575.53885
Overall Steps per Second: 6,979.14291
Timestep Collection Time: 3.97693
Timestep Consumption Time: 3.18900
PPO Batch Consumption Time: 0.23391
Total Iteration Time: 7.16592
Cumulative Model Updates: 10,491
Cumulative Timesteps: 58,376,372
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 23.03636
Policy Entropy: 3.62713
Value Function Loss: 0.23455
Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.11231
Policy Update Magnitude: 0.67573
Value Function Update Magnitude: 0.93274
Collected Steps per Second: 12,330.86922
Overall Steps per Second: 6,957.04080
Timestep Collection Time: 4.05746
Timestep Consumption Time: 3.13410
PPO Batch Consumption Time: 0.23323
Total Iteration Time: 7.19156
Cumulative Model Updates: 10,500
Cumulative Timesteps: 58,426,404
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 58426404...
Checkpoint 58426404 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60546
Policy Entropy: 3.63609
Value Function Loss: 0.23833
Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.67713
Value Function Update Magnitude: 0.81869
Collected Steps per Second: 12,925.22792
Overall Steps per Second: 7,122.96040
Timestep Collection Time: 3.86995
Timestep Consumption Time: 3.15241
PPO Batch Consumption Time: 0.23464
Total Iteration Time: 7.02236
Cumulative Model Updates: 10,509
Cumulative Timesteps: 58,476,424
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.57607
Policy Entropy: 3.63718
Value Function Loss: 0.23773
Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.66854
Value Function Update Magnitude: 0.77003
Collected Steps per Second: 12,785.43234
Overall Steps per Second: 7,024.84541
Timestep Collection Time: 3.91258
Timestep Consumption Time: 3.20843
PPO Batch Consumption Time: 0.23430
Total Iteration Time: 7.12101
Cumulative Model Updates: 10,518
Cumulative Timesteps: 58,526,448
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 58526448...
Checkpoint 58526448 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.53058
Policy Entropy: 3.64394
Value Function Loss: 0.23988
Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.66425
Value Function Update Magnitude: 0.70505
Collected Steps per Second: 12,480.59806
Overall Steps per Second: 6,829.82729
Timestep Collection Time: 4.00894
Timestep Consumption Time: 3.31687
PPO Batch Consumption Time: 0.24585
Total Iteration Time: 7.32581
Cumulative Model Updates: 10,527
Cumulative Timesteps: 58,576,482
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.58649
Policy Entropy: 3.64501
Value Function Loss: 0.23610
Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.66151
Value Function Update Magnitude: 0.67163
Collected Steps per Second: 12,760.93391
Overall Steps per Second: 7,042.60858
Timestep Collection Time: 3.92307
Timestep Consumption Time: 3.18538
PPO Batch Consumption Time: 0.23553
Total Iteration Time: 7.10845
Cumulative Model Updates: 10,536
Cumulative Timesteps: 58,626,544
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
Saving checkpoint 58626544...
Checkpoint 58626544 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.84040
Policy Entropy: 3.64628
Value Function Loss: 0.23471
Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.66530
Value Function Update Magnitude: 0.75892
Collected Steps per Second: 11,313.20170
Overall Steps per Second: 6,479.92355
Timestep Collection Time: 4.42032
Timestep Consumption Time: 3.29705
PPO Batch Consumption Time: 0.23505
Total Iteration Time: 7.71737
Cumulative Model Updates: 10,545
Cumulative Timesteps: 58,676,552
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.00124
Policy Entropy: 3.63671
Value Function Loss: 0.24025
Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.67244
Value Function Update Magnitude: 0.79147
Collected Steps per Second: 11,670.32528
Overall Steps per Second: 6,669.59254
Timestep Collection Time: 4.28728
Timestep Consumption Time: 3.21452
PPO Batch Consumption Time: 0.23856
Total Iteration Time: 7.50181
Cumulative Model Updates: 10,554
Cumulative Timesteps: 58,726,586
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 58726586...
Checkpoint 58726586 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.94594
Policy Entropy: 3.63595
Value Function Loss: 0.25069
Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.68294
Value Function Update Magnitude: 0.79139
Collected Steps per Second: 11,578.94330
Overall Steps per Second: 6,664.46703
Timestep Collection Time: 4.31922
Timestep Consumption Time: 3.18506
PPO Batch Consumption Time: 0.23353
Total Iteration Time: 7.50428
Cumulative Model Updates: 10,563
Cumulative Timesteps: 58,776,598
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.30625
Policy Entropy: 3.63743
Value Function Loss: 0.25272
Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.68368
Value Function Update Magnitude: 0.76907
Collected Steps per Second: 12,424.43701
Overall Steps per Second: 6,974.06068
Timestep Collection Time: 4.02561
Timestep Consumption Time: 3.14610
PPO Batch Consumption Time: 0.23644
Total Iteration Time: 7.17172
Cumulative Model Updates: 10,572
Cumulative Timesteps: 58,826,614
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 58826614...
Checkpoint 58826614 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.35609
Policy Entropy: 3.64013
Value Function Loss: 0.24057
Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.67178
Value Function Update Magnitude: 0.77658
Collected Steps per Second: 12,826.35987
Overall Steps per Second: 7,050.98539
Timestep Collection Time: 3.90072
Timestep Consumption Time: 3.19503
PPO Batch Consumption Time: 0.23429
Total Iteration Time: 7.09575
Cumulative Model Updates: 10,581
Cumulative Timesteps: 58,876,646
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.26583
Policy Entropy: 3.63882
Value Function Loss: 0.23658
Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.66162
Value Function Update Magnitude: 0.73783
Collected Steps per Second: 12,354.66944
Overall Steps per Second: 6,780.63073
Timestep Collection Time: 4.04738
Timestep Consumption Time: 3.32716
PPO Batch Consumption Time: 0.24352
Total Iteration Time: 7.37454
Cumulative Model Updates: 10,590
Cumulative Timesteps: 58,926,650
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 58926650...
Checkpoint 58926650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.80039
Policy Entropy: 3.64295
Value Function Loss: 0.23279
Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.66318
Value Function Update Magnitude: 0.74482
Collected Steps per Second: 12,531.71088
Overall Steps per Second: 6,980.73657
Timestep Collection Time: 3.99307
Timestep Consumption Time: 3.17523
PPO Batch Consumption Time: 0.23401
Total Iteration Time: 7.16830
Cumulative Model Updates: 10,599
Cumulative Timesteps: 58,976,690
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.83622
Policy Entropy: 3.64229
Value Function Loss: 0.23889
Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.69751
Value Function Update Magnitude: 0.89127
Collected Steps per Second: 12,881.57952
Overall Steps per Second: 7,052.84022
Timestep Collection Time: 3.88337
Timestep Consumption Time: 3.20937
PPO Batch Consumption Time: 0.23464
Total Iteration Time: 7.09275
Cumulative Model Updates: 10,608
Cumulative Timesteps: 59,026,714
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 59026714...
Checkpoint 59026714 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.17421
Policy Entropy: 3.63791
Value Function Loss: 0.24252
Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.69623
Value Function Update Magnitude: 0.82206
Collected Steps per Second: 12,458.22173
Overall Steps per Second: 6,941.48216
Timestep Collection Time: 4.01614
Timestep Consumption Time: 3.19183
PPO Batch Consumption Time: 0.23475
Total Iteration Time: 7.20797
Cumulative Model Updates: 10,617
Cumulative Timesteps: 59,076,748
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.17389
Policy Entropy: 3.63595
Value Function Loss: 0.24372
Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.69039
Value Function Update Magnitude: 0.79109
Collected Steps per Second: 12,596.62851
Overall Steps per Second: 7,084.89512
Timestep Collection Time: 3.97090
Timestep Consumption Time: 3.08919
PPO Batch Consumption Time: 0.23394
Total Iteration Time: 7.06009
Cumulative Model Updates: 10,626
Cumulative Timesteps: 59,126,768
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 59126768...
Checkpoint 59126768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.15364
Policy Entropy: 3.63071
Value Function Loss: 0.25114
Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.70102
Value Function Update Magnitude: 0.78675
Collected Steps per Second: 12,561.48670
Overall Steps per Second: 6,974.78221
Timestep Collection Time: 3.98169
Timestep Consumption Time: 3.18928
PPO Batch Consumption Time: 0.23379
Total Iteration Time: 7.17098
Cumulative Model Updates: 10,635
Cumulative Timesteps: 59,176,784
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.04621
Policy Entropy: 3.63327
Value Function Loss: 0.24355
Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.70004
Value Function Update Magnitude: 1.07065
Collected Steps per Second: 12,631.14052
Overall Steps per Second: 7,003.73557
Timestep Collection Time: 3.95958
Timestep Consumption Time: 3.18147
PPO Batch Consumption Time: 0.23493
Total Iteration Time: 7.14105
Cumulative Model Updates: 10,644
Cumulative Timesteps: 59,226,798
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 59226798...
Checkpoint 59226798 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.67641
Policy Entropy: 3.63260
Value Function Loss: 0.24654
Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.70181
Value Function Update Magnitude: 1.06178
Collected Steps per Second: 12,730.66311
Overall Steps per Second: 6,855.21307
Timestep Collection Time: 3.92972
Timestep Consumption Time: 3.36808
PPO Batch Consumption Time: 0.25070
Total Iteration Time: 7.29780
Cumulative Model Updates: 10,653
Cumulative Timesteps: 59,276,826
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.54360
Policy Entropy: 3.63494
Value Function Loss: 0.23559
Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.69429
Value Function Update Magnitude: 0.82423
Collected Steps per Second: 12,401.24808
Overall Steps per Second: 6,906.33946
Timestep Collection Time: 4.03217
Timestep Consumption Time: 3.20813
PPO Batch Consumption Time: 0.23438
Total Iteration Time: 7.24030
Cumulative Model Updates: 10,662
Cumulative Timesteps: 59,326,830
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 59326830...
Checkpoint 59326830 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.05561
Policy Entropy: 3.62949
Value Function Loss: 0.24763
Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.68901
Value Function Update Magnitude: 0.94528
Collected Steps per Second: 12,443.60039
Overall Steps per Second: 6,966.34722
Timestep Collection Time: 4.01829
Timestep Consumption Time: 3.15936
PPO Batch Consumption Time: 0.23358
Total Iteration Time: 7.17765
Cumulative Model Updates: 10,671
Cumulative Timesteps: 59,376,832
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.90128
Policy Entropy: 3.62864
Value Function Loss: 0.25241
Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.70246
Value Function Update Magnitude: 0.86117
Collected Steps per Second: 12,892.94258
Overall Steps per Second: 7,065.03444
Timestep Collection Time: 3.88042
Timestep Consumption Time: 3.20094
PPO Batch Consumption Time: 0.23553
Total Iteration Time: 7.08135
Cumulative Model Updates: 10,680
Cumulative Timesteps: 59,426,862
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 59426862...
Checkpoint 59426862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.16768
Policy Entropy: 3.62830
Value Function Loss: 0.26203
Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.70647
Value Function Update Magnitude: 0.79704
Collected Steps per Second: 12,515.42135
Overall Steps per Second: 6,961.15427
Timestep Collection Time: 3.99795
Timestep Consumption Time: 3.18994
PPO Batch Consumption Time: 0.23388
Total Iteration Time: 7.18789
Cumulative Model Updates: 10,689
Cumulative Timesteps: 59,476,898
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.88637
Policy Entropy: 3.62421
Value Function Loss: 0.26809
Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.70629
Value Function Update Magnitude: 0.81867
Collected Steps per Second: 12,649.48835
Overall Steps per Second: 7,105.51727
Timestep Collection Time: 3.95368
Timestep Consumption Time: 3.08480
PPO Batch Consumption Time: 0.23395
Total Iteration Time: 7.03847
Cumulative Model Updates: 10,698
Cumulative Timesteps: 59,526,910
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 59526910...
Checkpoint 59526910 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.12472
Policy Entropy: 3.62419
Value Function Loss: 0.25539
Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.69844
Value Function Update Magnitude: 1.03103
Collected Steps per Second: 12,583.65108
Overall Steps per Second: 6,979.09939
Timestep Collection Time: 3.97691
Timestep Consumption Time: 3.19365
PPO Batch Consumption Time: 0.23448
Total Iteration Time: 7.17055
Cumulative Model Updates: 10,707
Cumulative Timesteps: 59,576,954
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56725
Policy Entropy: 3.61729
Value Function Loss: 0.24837
Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.69252
Value Function Update Magnitude: 1.15827
Collected Steps per Second: 12,473.61636
Overall Steps per Second: 6,863.56694
Timestep Collection Time: 4.01087
Timestep Consumption Time: 3.27835
PPO Batch Consumption Time: 0.24371
Total Iteration Time: 7.28921
Cumulative Model Updates: 10,716
Cumulative Timesteps: 59,626,984
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 59626984...
Checkpoint 59626984 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.52078
Policy Entropy: 3.61950
Value Function Loss: 0.23869
Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.69751
Value Function Update Magnitude: 1.04308
Collected Steps per Second: 12,686.65650
Overall Steps per Second: 7,046.80187
Timestep Collection Time: 3.94383
Timestep Consumption Time: 3.15641
PPO Batch Consumption Time: 0.23420
Total Iteration Time: 7.10024
Cumulative Model Updates: 10,725
Cumulative Timesteps: 59,677,018
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.35932
Policy Entropy: 3.62339
Value Function Loss: 0.23652
Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.68703
Value Function Update Magnitude: 0.95423
Collected Steps per Second: 12,722.87451
Overall Steps per Second: 7,025.74596
Timestep Collection Time: 3.93056
Timestep Consumption Time: 3.18726
PPO Batch Consumption Time: 0.23475
Total Iteration Time: 7.11782
Cumulative Model Updates: 10,734
Cumulative Timesteps: 59,727,026
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 59727026...
Checkpoint 59727026 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.02680
Policy Entropy: 3.62875
Value Function Loss: 0.25093
Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.69379
Value Function Update Magnitude: 1.03107
Collected Steps per Second: 12,217.83567
Overall Steps per Second: 6,906.23831
Timestep Collection Time: 4.09385
Timestep Consumption Time: 3.14859
PPO Batch Consumption Time: 0.23360
Total Iteration Time: 7.24244
Cumulative Model Updates: 10,743
Cumulative Timesteps: 59,777,044
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.21016
Policy Entropy: 3.62668
Value Function Loss: 0.25055
Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.70659
Value Function Update Magnitude: 0.95453
Collected Steps per Second: 12,717.81587
Overall Steps per Second: 7,030.50589
Timestep Collection Time: 3.93181
Timestep Consumption Time: 3.18063
PPO Batch Consumption Time: 0.23414
Total Iteration Time: 7.11243
Cumulative Model Updates: 10,752
Cumulative Timesteps: 59,827,048
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 59827048...
Checkpoint 59827048 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.81582
Policy Entropy: 3.62636
Value Function Loss: 0.25583
Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.70739
Value Function Update Magnitude: 0.77114
Collected Steps per Second: 12,514.41794
Overall Steps per Second: 6,963.16860
Timestep Collection Time: 3.99667
Timestep Consumption Time: 3.18627
PPO Batch Consumption Time: 0.23417
Total Iteration Time: 7.18294
Cumulative Model Updates: 10,761
Cumulative Timesteps: 59,877,064
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.63213
Policy Entropy: 3.63077
Value Function Loss: 0.24801
Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11377
Policy Update Magnitude: 0.69641
Value Function Update Magnitude: 0.69381
Collected Steps per Second: 12,462.39467
Overall Steps per Second: 7,060.29862
Timestep Collection Time: 4.01223
Timestep Consumption Time: 3.06991
PPO Batch Consumption Time: 0.23308
Total Iteration Time: 7.08214
Cumulative Model Updates: 10,770
Cumulative Timesteps: 59,927,066
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 59927066...
Checkpoint 59927066 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.69870
Policy Entropy: 3.63184
Value Function Loss: 0.25177
Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.70282
Value Function Update Magnitude: 0.70914
Collected Steps per Second: 12,576.14433
Overall Steps per Second: 6,823.34016
Timestep Collection Time: 3.97658
Timestep Consumption Time: 3.35268
PPO Batch Consumption Time: 0.24756
Total Iteration Time: 7.32925
Cumulative Model Updates: 10,779
Cumulative Timesteps: 59,977,076
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.63101
Policy Entropy: 3.63220
Value Function Loss: 0.24576
Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.71556
Value Function Update Magnitude: 0.70428
Collected Steps per Second: 12,474.02305
Overall Steps per Second: 6,976.87197
Timestep Collection Time: 4.00961
Timestep Consumption Time: 3.15922
PPO Batch Consumption Time: 0.23471
Total Iteration Time: 7.16883
Cumulative Model Updates: 10,788
Cumulative Timesteps: 60,027,092
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 60027092...
Checkpoint 60027092 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.23672
Policy Entropy: 3.63367
Value Function Loss: 0.25187
Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.72009
Value Function Update Magnitude: 0.67836
Collected Steps per Second: 12,413.31004
Overall Steps per Second: 7,008.77884
Timestep Collection Time: 4.03148
Timestep Consumption Time: 3.10871
PPO Batch Consumption Time: 0.23421
Total Iteration Time: 7.14019
Cumulative Model Updates: 10,797
Cumulative Timesteps: 60,077,136
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50504
Policy Entropy: 3.63266
Value Function Loss: 0.25042
Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.72242
Value Function Update Magnitude: 0.69646
Collected Steps per Second: 12,719.39042
Overall Steps per Second: 7,019.55965
Timestep Collection Time: 3.93336
Timestep Consumption Time: 3.19386
PPO Batch Consumption Time: 0.23418
Total Iteration Time: 7.12723
Cumulative Model Updates: 10,806
Cumulative Timesteps: 60,127,166
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 60127166...
Checkpoint 60127166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.35532
Policy Entropy: 3.63149
Value Function Loss: 0.26079
Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.70837
Value Function Update Magnitude: 0.73319
Collected Steps per Second: 12,478.84083
Overall Steps per Second: 7,036.24157
Timestep Collection Time: 4.00742
Timestep Consumption Time: 3.09978
PPO Batch Consumption Time: 0.23578
Total Iteration Time: 7.10720
Cumulative Model Updates: 10,815
Cumulative Timesteps: 60,177,174
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.39142
Policy Entropy: 3.62699
Value Function Loss: 0.26936
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.73025
Value Function Update Magnitude: 0.87629
Collected Steps per Second: 12,282.62540
Overall Steps per Second: 6,902.73144
Timestep Collection Time: 4.07323
Timestep Consumption Time: 3.17462
PPO Batch Consumption Time: 0.23382
Total Iteration Time: 7.24786
Cumulative Model Updates: 10,824
Cumulative Timesteps: 60,227,204
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 60227204...
Checkpoint 60227204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.02991
Policy Entropy: 3.62352
Value Function Loss: 0.26216
Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.75211
Value Function Update Magnitude: 0.80711
Collected Steps per Second: 12,280.15380
Overall Steps per Second: 6,936.00766
Timestep Collection Time: 4.07226
Timestep Consumption Time: 3.13765
PPO Batch Consumption Time: 0.23430
Total Iteration Time: 7.20991
Cumulative Model Updates: 10,833
Cumulative Timesteps: 60,277,212
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.44997
Policy Entropy: 3.62712
Value Function Loss: 0.25655
Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.73061
Value Function Update Magnitude: 0.74289
Collected Steps per Second: 10,980.93861
Overall Steps per Second: 5,886.95396
Timestep Collection Time: 4.55589
Timestep Consumption Time: 3.94222
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 8.49811
Cumulative Model Updates: 10,842
Cumulative Timesteps: 60,327,240
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 60327240...
Checkpoint 60327240 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.18762
Policy Entropy: 3.63887
Value Function Loss: 0.24904
Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11480
Policy Update Magnitude: 0.71135
Value Function Update Magnitude: 0.72811
Collected Steps per Second: 12,188.92487
Overall Steps per Second: 6,883.45763
Timestep Collection Time: 4.10225
Timestep Consumption Time: 3.16183
PPO Batch Consumption Time: 0.23028
Total Iteration Time: 7.26408
Cumulative Model Updates: 10,851
Cumulative Timesteps: 60,377,242
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.17375
Policy Entropy: 3.63281
Value Function Loss: 0.25194
Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.70161
Value Function Update Magnitude: 0.79806
Collected Steps per Second: 12,684.36919
Overall Steps per Second: 7,095.25500
Timestep Collection Time: 3.94312
Timestep Consumption Time: 3.10610
PPO Batch Consumption Time: 0.23005
Total Iteration Time: 7.04922
Cumulative Model Updates: 10,860
Cumulative Timesteps: 60,427,258
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 60427258...
Checkpoint 60427258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.16947
Policy Entropy: 3.63578
Value Function Loss: 0.24865
Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.70559
Value Function Update Magnitude: 0.77832
Collected Steps per Second: 12,913.48964
Overall Steps per Second: 7,136.29667
Timestep Collection Time: 3.87254
Timestep Consumption Time: 3.13502
PPO Batch Consumption Time: 0.22977
Total Iteration Time: 7.00756
Cumulative Model Updates: 10,869
Cumulative Timesteps: 60,477,266
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.06945
Policy Entropy: 3.63432
Value Function Loss: 0.24990
Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.70469
Value Function Update Magnitude: 0.70633
Collected Steps per Second: 12,824.17925
Overall Steps per Second: 7,097.88033
Timestep Collection Time: 3.90060
Timestep Consumption Time: 3.14686
PPO Batch Consumption Time: 0.22981
Total Iteration Time: 7.04746
Cumulative Model Updates: 10,878
Cumulative Timesteps: 60,527,288
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 60527288...
Checkpoint 60527288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.74095
Policy Entropy: 3.63913
Value Function Loss: 0.25360
Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.71306
Value Function Update Magnitude: 0.69069
Collected Steps per Second: 12,662.84690
Overall Steps per Second: 7,149.29694
Timestep Collection Time: 3.95061
Timestep Consumption Time: 3.04672
PPO Batch Consumption Time: 0.22994
Total Iteration Time: 6.99733
Cumulative Model Updates: 10,887
Cumulative Timesteps: 60,577,314
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22109
Policy Entropy: 3.63360
Value Function Loss: 0.24980
Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.71768
Value Function Update Magnitude: 0.69795
Collected Steps per Second: 12,818.32956
Overall Steps per Second: 7,086.31182
Timestep Collection Time: 3.90207
Timestep Consumption Time: 3.15633
PPO Batch Consumption Time: 0.23044
Total Iteration Time: 7.05840
Cumulative Model Updates: 10,896
Cumulative Timesteps: 60,627,332
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 60627332...
Checkpoint 60627332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31448
Policy Entropy: 3.62447
Value Function Loss: 0.25655
Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.72753
Value Function Update Magnitude: 0.73128
Collected Steps per Second: 13,000.35022
Overall Steps per Second: 7,118.64572
Timestep Collection Time: 3.84959
Timestep Consumption Time: 3.18068
PPO Batch Consumption Time: 0.23803
Total Iteration Time: 7.03027
Cumulative Model Updates: 10,905
Cumulative Timesteps: 60,677,378
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.35923
Policy Entropy: 3.61904
Value Function Loss: 0.25365
Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11759
Policy Update Magnitude: 0.73826
Value Function Update Magnitude: 0.74283
Collected Steps per Second: 12,665.30265
Overall Steps per Second: 7,142.42061
Timestep Collection Time: 3.95127
Timestep Consumption Time: 3.05532
PPO Batch Consumption Time: 0.23034
Total Iteration Time: 7.00659
Cumulative Model Updates: 10,914
Cumulative Timesteps: 60,727,422
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 60727422...
Checkpoint 60727422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.43750
Policy Entropy: 3.61622
Value Function Loss: 0.27082
Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.74151
Value Function Update Magnitude: 0.75968
Collected Steps per Second: 12,869.32121
Overall Steps per Second: 7,119.85868
Timestep Collection Time: 3.88521
Timestep Consumption Time: 3.13740
PPO Batch Consumption Time: 0.23049
Total Iteration Time: 7.02261
Cumulative Model Updates: 10,923
Cumulative Timesteps: 60,777,422
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.60955
Policy Entropy: 3.61562
Value Function Loss: 0.26270
Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.74163
Value Function Update Magnitude: 0.80105
Collected Steps per Second: 12,888.99762
Overall Steps per Second: 7,160.88410
Timestep Collection Time: 3.88098
Timestep Consumption Time: 3.10447
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.98545
Cumulative Model Updates: 10,932
Cumulative Timesteps: 60,827,444
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 60827444...
Checkpoint 60827444 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.67854
Policy Entropy: 3.61631
Value Function Loss: 0.26322
Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.73398
Value Function Update Magnitude: 0.76792
Collected Steps per Second: 12,994.88208
Overall Steps per Second: 7,179.76475
Timestep Collection Time: 3.84952
Timestep Consumption Time: 3.11784
PPO Batch Consumption Time: 0.22991
Total Iteration Time: 6.96736
Cumulative Model Updates: 10,941
Cumulative Timesteps: 60,877,468
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51626
Policy Entropy: 3.61561
Value Function Loss: 0.24672
Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.72456
Value Function Update Magnitude: 1.04009
Collected Steps per Second: 12,410.45196
Overall Steps per Second: 7,001.69922
Timestep Collection Time: 4.02935
Timestep Consumption Time: 3.11263
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 7.14198
Cumulative Model Updates: 10,950
Cumulative Timesteps: 60,927,474
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 60927474...
Checkpoint 60927474 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.01796
Policy Entropy: 3.61383
Value Function Loss: 0.23163
Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.70605
Value Function Update Magnitude: 1.09023
Collected Steps per Second: 12,565.32454
Overall Steps per Second: 7,141.64942
Timestep Collection Time: 3.98032
Timestep Consumption Time: 3.02283
PPO Batch Consumption Time: 0.23035
Total Iteration Time: 7.00314
Cumulative Model Updates: 10,959
Cumulative Timesteps: 60,977,488
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76786
Policy Entropy: 3.62162
Value Function Loss: 0.23297
Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.70289
Value Function Update Magnitude: 1.03081
Collected Steps per Second: 12,657.07672
Overall Steps per Second: 6,989.59376
Timestep Collection Time: 3.95210
Timestep Consumption Time: 3.20454
PPO Batch Consumption Time: 0.23112
Total Iteration Time: 7.15664
Cumulative Model Updates: 10,968
Cumulative Timesteps: 61,027,510
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 61027510...
Checkpoint 61027510 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.47961
Policy Entropy: 3.61718
Value Function Loss: 0.24785
Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.70643
Value Function Update Magnitude: 0.78848
Collected Steps per Second: 12,753.32962
Overall Steps per Second: 7,123.10932
Timestep Collection Time: 3.92133
Timestep Consumption Time: 3.09948
PPO Batch Consumption Time: 0.23008
Total Iteration Time: 7.02081
Cumulative Model Updates: 10,977
Cumulative Timesteps: 61,077,520
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.60087
Policy Entropy: 3.62138
Value Function Loss: 0.24225
Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.70434
Value Function Update Magnitude: 0.95300
Collected Steps per Second: 12,910.52270
Overall Steps per Second: 7,117.61623
Timestep Collection Time: 3.87544
Timestep Consumption Time: 3.15416
PPO Batch Consumption Time: 0.23013
Total Iteration Time: 7.02960
Cumulative Model Updates: 10,986
Cumulative Timesteps: 61,127,554
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 61127554...
Checkpoint 61127554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.72923
Policy Entropy: 3.61728
Value Function Loss: 0.23485
Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.69999
Value Function Update Magnitude: 0.95311
Collected Steps per Second: 12,788.80278
Overall Steps per Second: 7,101.03276
Timestep Collection Time: 3.91217
Timestep Consumption Time: 3.13356
PPO Batch Consumption Time: 0.22981
Total Iteration Time: 7.04574
Cumulative Model Updates: 10,995
Cumulative Timesteps: 61,177,586
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30282
Policy Entropy: 3.62074
Value Function Loss: 0.25718
Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.70747
Value Function Update Magnitude: 0.96040
Collected Steps per Second: 12,824.38422
Overall Steps per Second: 7,137.84125
Timestep Collection Time: 3.90007
Timestep Consumption Time: 3.10709
PPO Batch Consumption Time: 0.22992
Total Iteration Time: 7.00716
Cumulative Model Updates: 11,004
Cumulative Timesteps: 61,227,602
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 61227602...
Checkpoint 61227602 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.44910
Policy Entropy: 3.60956
Value Function Loss: 0.25783
Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.71863
Value Function Update Magnitude: 0.91128
Collected Steps per Second: 12,950.87180
Overall Steps per Second: 7,160.83581
Timestep Collection Time: 3.86306
Timestep Consumption Time: 3.12355
PPO Batch Consumption Time: 0.22974
Total Iteration Time: 6.98661
Cumulative Model Updates: 11,013
Cumulative Timesteps: 61,277,632
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95812
Policy Entropy: 3.60790
Value Function Loss: 0.26440
Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.72449
Value Function Update Magnitude: 0.82130
Collected Steps per Second: 12,836.76761
Overall Steps per Second: 7,107.34608
Timestep Collection Time: 3.89802
Timestep Consumption Time: 3.14230
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 7.04032
Cumulative Model Updates: 11,022
Cumulative Timesteps: 61,327,670
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 61327670...
Checkpoint 61327670 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.96588
Policy Entropy: 3.61218
Value Function Loss: 0.25207
Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.71242
Value Function Update Magnitude: 0.74229
Collected Steps per Second: 12,847.70116
Overall Steps per Second: 7,169.22914
Timestep Collection Time: 3.89284
Timestep Consumption Time: 3.08337
PPO Batch Consumption Time: 0.23087
Total Iteration Time: 6.97620
Cumulative Model Updates: 11,031
Cumulative Timesteps: 61,377,684
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 30.38370
Policy Entropy: 3.61648
Value Function Loss: 0.27324
Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.70834
Value Function Update Magnitude: 0.94107
Collected Steps per Second: 12,786.01731
Overall Steps per Second: 7,115.72332
Timestep Collection Time: 3.91318
Timestep Consumption Time: 3.11829
PPO Batch Consumption Time: 0.23021
Total Iteration Time: 7.03147
Cumulative Model Updates: 11,040
Cumulative Timesteps: 61,427,718
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 61427718...
Checkpoint 61427718 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74075
Policy Entropy: 3.61920
Value Function Loss: 0.27059
Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.71288
Value Function Update Magnitude: 0.82829
Collected Steps per Second: 12,799.88242
Overall Steps per Second: 7,158.33155
Timestep Collection Time: 3.90816
Timestep Consumption Time: 3.08006
PPO Batch Consumption Time: 0.23003
Total Iteration Time: 6.98822
Cumulative Model Updates: 11,049
Cumulative Timesteps: 61,477,742
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23808
Policy Entropy: 3.61275
Value Function Loss: 0.27572
Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.71746
Value Function Update Magnitude: 0.76757
Collected Steps per Second: 12,795.29725
Overall Steps per Second: 7,225.47445
Timestep Collection Time: 3.90784
Timestep Consumption Time: 3.01240
PPO Batch Consumption Time: 0.23037
Total Iteration Time: 6.92024
Cumulative Model Updates: 11,058
Cumulative Timesteps: 61,527,744
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 61527744...
Checkpoint 61527744 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.11214
Policy Entropy: 3.60743
Value Function Loss: 0.28850
Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.72794
Value Function Update Magnitude: 0.76463
Collected Steps per Second: 12,537.21539
Overall Steps per Second: 7,006.81728
Timestep Collection Time: 3.98988
Timestep Consumption Time: 3.14917
PPO Batch Consumption Time: 0.23011
Total Iteration Time: 7.13905
Cumulative Model Updates: 11,067
Cumulative Timesteps: 61,577,766
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.91937
Policy Entropy: 3.60467
Value Function Loss: 0.27514
Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.71591
Value Function Update Magnitude: 0.78252
Collected Steps per Second: 12,755.77132
Overall Steps per Second: 7,117.06502
Timestep Collection Time: 3.92215
Timestep Consumption Time: 3.10744
PPO Batch Consumption Time: 0.23025
Total Iteration Time: 7.02958
Cumulative Model Updates: 11,076
Cumulative Timesteps: 61,627,796
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 61627796...
Checkpoint 61627796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.51899
Policy Entropy: 3.61018
Value Function Loss: 0.26448
Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.70778
Value Function Update Magnitude: 0.79937
Collected Steps per Second: 12,912.69933
Overall Steps per Second: 7,129.84198
Timestep Collection Time: 3.87293
Timestep Consumption Time: 3.14125
PPO Batch Consumption Time: 0.22996
Total Iteration Time: 7.01418
Cumulative Model Updates: 11,085
Cumulative Timesteps: 61,677,806
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.16221
Policy Entropy: 3.60849
Value Function Loss: 0.25565
Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.70522
Value Function Update Magnitude: 0.83248
Collected Steps per Second: 12,843.52851
Overall Steps per Second: 6,960.31066
Timestep Collection Time: 3.89550
Timestep Consumption Time: 3.29268
PPO Batch Consumption Time: 0.24180
Total Iteration Time: 7.18818
Cumulative Model Updates: 11,094
Cumulative Timesteps: 61,727,838
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 61727838...
Checkpoint 61727838 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.43335
Policy Entropy: 3.60751
Value Function Loss: 0.23962
Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.70208
Value Function Update Magnitude: 0.99195
Collected Steps per Second: 12,725.61669
Overall Steps per Second: 7,188.48655
Timestep Collection Time: 3.93238
Timestep Consumption Time: 3.02903
PPO Batch Consumption Time: 0.23004
Total Iteration Time: 6.96141
Cumulative Model Updates: 11,103
Cumulative Timesteps: 61,777,880
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.97155
Policy Entropy: 3.60879
Value Function Loss: 0.23556
Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.69374
Value Function Update Magnitude: 0.96795
Collected Steps per Second: 12,916.94972
Overall Steps per Second: 7,137.34062
Timestep Collection Time: 3.87212
Timestep Consumption Time: 3.13553
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 7.00765
Cumulative Model Updates: 11,112
Cumulative Timesteps: 61,827,896
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 61827896...
Checkpoint 61827896 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.52844
Policy Entropy: 3.60715
Value Function Loss: 0.24972
Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.69956
Value Function Update Magnitude: 0.87226
Collected Steps per Second: 12,592.21742
Overall Steps per Second: 7,083.41745
Timestep Collection Time: 3.97388
Timestep Consumption Time: 3.09050
PPO Batch Consumption Time: 0.22981
Total Iteration Time: 7.06439
Cumulative Model Updates: 11,121
Cumulative Timesteps: 61,877,936
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.86799
Policy Entropy: 3.61206
Value Function Loss: 0.26930
Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.71110
Value Function Update Magnitude: 0.86358
Collected Steps per Second: 12,781.37167
Overall Steps per Second: 7,205.91331
Timestep Collection Time: 3.91476
Timestep Consumption Time: 3.02898
PPO Batch Consumption Time: 0.22987
Total Iteration Time: 6.94374
Cumulative Model Updates: 11,130
Cumulative Timesteps: 61,927,972
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 61927972...
Checkpoint 61927972 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.48863
Policy Entropy: 3.60798
Value Function Loss: 0.26901
Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.71847
Value Function Update Magnitude: 0.77295
Collected Steps per Second: 12,727.49455
Overall Steps per Second: 7,087.07151
Timestep Collection Time: 3.93023
Timestep Consumption Time: 3.12797
PPO Batch Consumption Time: 0.22986
Total Iteration Time: 7.05820
Cumulative Model Updates: 11,139
Cumulative Timesteps: 61,977,994
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.89186
Policy Entropy: 3.61115
Value Function Loss: 0.26523
Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.70212
Value Function Update Magnitude: 0.73782
Collected Steps per Second: 12,859.41485
Overall Steps per Second: 7,144.43480
Timestep Collection Time: 3.88929
Timestep Consumption Time: 3.11112
PPO Batch Consumption Time: 0.22943
Total Iteration Time: 7.00041
Cumulative Model Updates: 11,148
Cumulative Timesteps: 62,028,008
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 62028008...
Checkpoint 62028008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.52650
Policy Entropy: 3.62468
Value Function Loss: 0.25184
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.68947
Value Function Update Magnitude: 0.72182
Collected Steps per Second: 12,971.01332
Overall Steps per Second: 7,107.63123
Timestep Collection Time: 3.85706
Timestep Consumption Time: 3.18185
PPO Batch Consumption Time: 0.23024
Total Iteration Time: 7.03891
Cumulative Model Updates: 11,157
Cumulative Timesteps: 62,078,038
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.65651
Policy Entropy: 3.64020
Value Function Loss: 0.24627
Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.68160
Value Function Update Magnitude: 0.69523
Collected Steps per Second: 12,718.49018
Overall Steps per Second: 7,056.21336
Timestep Collection Time: 3.93239
Timestep Consumption Time: 3.15555
PPO Batch Consumption Time: 0.23018
Total Iteration Time: 7.08794
Cumulative Model Updates: 11,166
Cumulative Timesteps: 62,128,052
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 62128052...
Checkpoint 62128052 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 21.35832
Policy Entropy: 3.64393
Value Function Loss: 0.27103
Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.70226
Value Function Update Magnitude: 0.76039
Collected Steps per Second: 12,797.46329
Overall Steps per Second: 7,202.70417
Timestep Collection Time: 3.90781
Timestep Consumption Time: 3.03542
PPO Batch Consumption Time: 0.23016
Total Iteration Time: 6.94323
Cumulative Model Updates: 11,175
Cumulative Timesteps: 62,178,062
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.32794
Policy Entropy: 3.63752
Value Function Loss: 0.27245
Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.71688
Value Function Update Magnitude: 0.74368
Collected Steps per Second: 12,813.84805
Overall Steps per Second: 7,081.33125
Timestep Collection Time: 3.90515
Timestep Consumption Time: 3.16132
PPO Batch Consumption Time: 0.22959
Total Iteration Time: 7.06647
Cumulative Model Updates: 11,184
Cumulative Timesteps: 62,228,102
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 62228102...
Checkpoint 62228102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.39104
Policy Entropy: 3.63384
Value Function Loss: 0.26989
Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.70762
Value Function Update Magnitude: 0.78701
Collected Steps per Second: 12,809.71330
Overall Steps per Second: 7,132.64962
Timestep Collection Time: 3.90485
Timestep Consumption Time: 3.10797
PPO Batch Consumption Time: 0.22971
Total Iteration Time: 7.01282
Cumulative Model Updates: 11,193
Cumulative Timesteps: 62,278,122
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 22.84964
Policy Entropy: 3.62635
Value Function Loss: 0.28165
Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.71711
Value Function Update Magnitude: 0.83178
Collected Steps per Second: 12,710.81453
Overall Steps per Second: 7,184.92451
Timestep Collection Time: 3.93429
Timestep Consumption Time: 3.02584
PPO Batch Consumption Time: 0.23013
Total Iteration Time: 6.96013
Cumulative Model Updates: 11,202
Cumulative Timesteps: 62,328,130
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 62328130...
Checkpoint 62328130 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95600
Policy Entropy: 3.62241
Value Function Loss: 0.27980
Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.72930
Value Function Update Magnitude: 0.86839
Collected Steps per Second: 12,607.52822
Overall Steps per Second: 7,033.86371
Timestep Collection Time: 3.96795
Timestep Consumption Time: 3.14422
PPO Batch Consumption Time: 0.23032
Total Iteration Time: 7.11217
Cumulative Model Updates: 11,211
Cumulative Timesteps: 62,378,156
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99536
Policy Entropy: 3.61513
Value Function Loss: 0.26743
Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.72067
Value Function Update Magnitude: 0.80020
Collected Steps per Second: 12,730.92075
Overall Steps per Second: 7,061.23156
Timestep Collection Time: 3.92760
Timestep Consumption Time: 3.15360
PPO Batch Consumption Time: 0.23369
Total Iteration Time: 7.08120
Cumulative Model Updates: 11,220
Cumulative Timesteps: 62,428,158
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 62428158...
Checkpoint 62428158 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.65723
Policy Entropy: 3.61539
Value Function Loss: 0.25390
Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.70664
Value Function Update Magnitude: 0.76628
Collected Steps per Second: 12,940.10714
Overall Steps per Second: 7,139.42719
Timestep Collection Time: 3.86411
Timestep Consumption Time: 3.13953
PPO Batch Consumption Time: 0.22964
Total Iteration Time: 7.00364
Cumulative Model Updates: 11,229
Cumulative Timesteps: 62,478,160
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81306
Policy Entropy: 3.61991
Value Function Loss: 0.25286
Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.69664
Value Function Update Magnitude: 0.74271
Collected Steps per Second: 12,965.44608
Overall Steps per Second: 7,128.03084
Timestep Collection Time: 3.85903
Timestep Consumption Time: 3.16030
PPO Batch Consumption Time: 0.22992
Total Iteration Time: 7.01933
Cumulative Model Updates: 11,238
Cumulative Timesteps: 62,528,194
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 62528194...
Checkpoint 62528194 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.49782
Policy Entropy: 3.62396
Value Function Loss: 0.25832
Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.70361
Value Function Update Magnitude: 0.85546
Collected Steps per Second: 12,703.31228
Overall Steps per Second: 7,176.50180
Timestep Collection Time: 3.93866
Timestep Consumption Time: 3.03326
PPO Batch Consumption Time: 0.23029
Total Iteration Time: 6.97192
Cumulative Model Updates: 11,247
Cumulative Timesteps: 62,578,228
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.19260
Policy Entropy: 3.62209
Value Function Loss: 0.28132
Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.71887
Value Function Update Magnitude: 0.78932
Collected Steps per Second: 12,781.46497
Overall Steps per Second: 7,077.07908
Timestep Collection Time: 3.91489
Timestep Consumption Time: 3.15554
PPO Batch Consumption Time: 0.23008
Total Iteration Time: 7.07043
Cumulative Model Updates: 11,256
Cumulative Timesteps: 62,628,266
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 62628266...
Checkpoint 62628266 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42957
Policy Entropy: 3.62243
Value Function Loss: 0.27814
Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.70962
Value Function Update Magnitude: 0.78366
Collected Steps per Second: 12,737.98277
Overall Steps per Second: 7,106.87641
Timestep Collection Time: 3.92668
Timestep Consumption Time: 3.11129
PPO Batch Consumption Time: 0.23011
Total Iteration Time: 7.03797
Cumulative Model Updates: 11,265
Cumulative Timesteps: 62,678,284
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.06841
Policy Entropy: 3.61178
Value Function Loss: 0.26485
Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.70305
Value Function Update Magnitude: 0.76753
Collected Steps per Second: 13,116.00424
Overall Steps per Second: 7,203.98805
Timestep Collection Time: 3.81229
Timestep Consumption Time: 3.12859
PPO Batch Consumption Time: 0.23019
Total Iteration Time: 6.94088
Cumulative Model Updates: 11,274
Cumulative Timesteps: 62,728,286
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 62728286...
Checkpoint 62728286 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.44364
Policy Entropy: 3.61734
Value Function Loss: 0.25654
Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.69993
Value Function Update Magnitude: 0.80560
Collected Steps per Second: 12,736.35820
Overall Steps per Second: 6,946.32570
Timestep Collection Time: 3.92687
Timestep Consumption Time: 3.27320
PPO Batch Consumption Time: 0.24093
Total Iteration Time: 7.20007
Cumulative Model Updates: 11,283
Cumulative Timesteps: 62,778,300
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76222
Policy Entropy: 3.61257
Value Function Loss: 0.24990
Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.70322
Value Function Update Magnitude: 0.81475
Collected Steps per Second: 12,653.94300
Overall Steps per Second: 7,047.52732
Timestep Collection Time: 3.95181
Timestep Consumption Time: 3.14373
PPO Batch Consumption Time: 0.22967
Total Iteration Time: 7.09554
Cumulative Model Updates: 11,292
Cumulative Timesteps: 62,828,306
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 62828306...
Checkpoint 62828306 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.64461
Policy Entropy: 3.61091
Value Function Loss: 0.26225
Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.70533
Value Function Update Magnitude: 0.79127
Collected Steps per Second: 13,017.71532
Overall Steps per Second: 7,168.20414
Timestep Collection Time: 3.84276
Timestep Consumption Time: 3.13583
PPO Batch Consumption Time: 0.23032
Total Iteration Time: 6.97860
Cumulative Model Updates: 11,301
Cumulative Timesteps: 62,878,330
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.20370
Policy Entropy: 3.60600
Value Function Loss: 0.25217
Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.69244
Value Function Update Magnitude: 0.80615
Collected Steps per Second: 12,820.67224
Overall Steps per Second: 7,085.48429
Timestep Collection Time: 3.90026
Timestep Consumption Time: 3.15698
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 7.05725
Cumulative Model Updates: 11,310
Cumulative Timesteps: 62,928,334
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 62928334...
Checkpoint 62928334 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.88447
Policy Entropy: 3.60895
Value Function Loss: 0.24036
Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.68043
Value Function Update Magnitude: 0.98433
Collected Steps per Second: 12,888.09152
Overall Steps per Second: 7,225.08547
Timestep Collection Time: 3.88002
Timestep Consumption Time: 3.04115
PPO Batch Consumption Time: 0.23039
Total Iteration Time: 6.92116
Cumulative Model Updates: 11,319
Cumulative Timesteps: 62,978,340
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.98246
Policy Entropy: 3.60656
Value Function Loss: 0.23161
Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.69171
Value Function Update Magnitude: 1.11482
Collected Steps per Second: 12,719.56951
Overall Steps per Second: 7,076.25487
Timestep Collection Time: 3.93158
Timestep Consumption Time: 3.13544
PPO Batch Consumption Time: 0.23039
Total Iteration Time: 7.06702
Cumulative Model Updates: 11,328
Cumulative Timesteps: 63,028,348
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 63028348...
Checkpoint 63028348 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.08173
Policy Entropy: 3.60533
Value Function Loss: 0.25655
Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.71537
Value Function Update Magnitude: 1.07845
Collected Steps per Second: 12,653.67228
Overall Steps per Second: 7,099.94191
Timestep Collection Time: 3.95427
Timestep Consumption Time: 3.09311
PPO Batch Consumption Time: 0.23015
Total Iteration Time: 7.04738
Cumulative Model Updates: 11,337
Cumulative Timesteps: 63,078,384
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.68071
Policy Entropy: 3.59838
Value Function Loss: 0.25857
Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.71593
Value Function Update Magnitude: 0.82715
Collected Steps per Second: 13,099.20606
Overall Steps per Second: 7,145.77949
Timestep Collection Time: 3.81886
Timestep Consumption Time: 3.18164
PPO Batch Consumption Time: 0.23462
Total Iteration Time: 7.00050
Cumulative Model Updates: 11,346
Cumulative Timesteps: 63,128,408
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 63128408...
Checkpoint 63128408 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.36042
Policy Entropy: 3.59991
Value Function Loss: 0.27347
Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.71772
Value Function Update Magnitude: 0.76284
Collected Steps per Second: 12,752.84790
Overall Steps per Second: 7,088.70961
Timestep Collection Time: 3.92305
Timestep Consumption Time: 3.13466
PPO Batch Consumption Time: 0.22970
Total Iteration Time: 7.05770
Cumulative Model Updates: 11,355
Cumulative Timesteps: 63,178,438
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01222
Policy Entropy: 3.60367
Value Function Loss: 0.26314
Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.71167
Value Function Update Magnitude: 0.80089
Collected Steps per Second: 12,727.85923
Overall Steps per Second: 7,087.78314
Timestep Collection Time: 3.92839
Timestep Consumption Time: 3.12600
PPO Batch Consumption Time: 0.22980
Total Iteration Time: 7.05439
Cumulative Model Updates: 11,364
Cumulative Timesteps: 63,228,438
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 63228438...
Checkpoint 63228438 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.40074
Policy Entropy: 3.60497
Value Function Loss: 0.25948
Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.69430
Value Function Update Magnitude: 0.82348
Collected Steps per Second: 12,917.56229
Overall Steps per Second: 7,131.06055
Timestep Collection Time: 3.87318
Timestep Consumption Time: 3.14289
PPO Batch Consumption Time: 0.23031
Total Iteration Time: 7.01607
Cumulative Model Updates: 11,373
Cumulative Timesteps: 63,278,470
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.46455
Policy Entropy: 3.60385
Value Function Loss: 0.27307
Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.69853
Value Function Update Magnitude: 0.83841
Collected Steps per Second: 12,858.22248
Overall Steps per Second: 7,098.33471
Timestep Collection Time: 3.89090
Timestep Consumption Time: 3.15724
PPO Batch Consumption Time: 0.23015
Total Iteration Time: 7.04813
Cumulative Model Updates: 11,382
Cumulative Timesteps: 63,328,500
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 63328500...
Checkpoint 63328500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.09067
Policy Entropy: 3.60138
Value Function Loss: 0.26894
Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.71151
Value Function Update Magnitude: 0.80530
Collected Steps per Second: 12,629.65788
Overall Steps per Second: 7,136.12273
Timestep Collection Time: 3.96052
Timestep Consumption Time: 3.04889
PPO Batch Consumption Time: 0.23016
Total Iteration Time: 7.00941
Cumulative Model Updates: 11,391
Cumulative Timesteps: 63,378,520
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.58608
Policy Entropy: 3.60362
Value Function Loss: 0.27816
Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14684
Policy Update Magnitude: 0.70923
Value Function Update Magnitude: 0.79480
Collected Steps per Second: 12,792.58278
Overall Steps per Second: 7,093.70951
Timestep Collection Time: 3.91133
Timestep Consumption Time: 3.14224
PPO Batch Consumption Time: 0.23013
Total Iteration Time: 7.05357
Cumulative Model Updates: 11,400
Cumulative Timesteps: 63,428,556
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 63428556...
Checkpoint 63428556 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53243
Policy Entropy: 3.60540
Value Function Loss: 0.27296
Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.70961
Value Function Update Magnitude: 0.82357
Collected Steps per Second: 12,757.11651
Overall Steps per Second: 7,084.95325
Timestep Collection Time: 3.92189
Timestep Consumption Time: 3.13984
PPO Batch Consumption Time: 0.23130
Total Iteration Time: 7.06173
Cumulative Model Updates: 11,409
Cumulative Timesteps: 63,478,588
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.09719
Policy Entropy: 3.60934
Value Function Loss: 0.27448
Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14474
Policy Update Magnitude: 0.70995
Value Function Update Magnitude: 0.81602
Collected Steps per Second: 13,171.93491
Overall Steps per Second: 7,243.20755
Timestep Collection Time: 3.79747
Timestep Consumption Time: 3.10831
PPO Batch Consumption Time: 0.22982
Total Iteration Time: 6.90578
Cumulative Model Updates: 11,418
Cumulative Timesteps: 63,528,608
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 63528608...
Checkpoint 63528608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.91189
Policy Entropy: 3.60371
Value Function Loss: 0.27039
Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14474
Policy Update Magnitude: 0.71052
Value Function Update Magnitude: 0.84185
Collected Steps per Second: 12,876.58595
Overall Steps per Second: 7,113.17402
Timestep Collection Time: 3.88426
Timestep Consumption Time: 3.14720
PPO Batch Consumption Time: 0.23034
Total Iteration Time: 7.03146
Cumulative Model Updates: 11,427
Cumulative Timesteps: 63,578,624
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.63541
Policy Entropy: 3.61464
Value Function Loss: 0.26618
Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.71728
Value Function Update Magnitude: 0.84572
Collected Steps per Second: 12,775.89121
Overall Steps per Second: 7,121.47655
Timestep Collection Time: 3.91675
Timestep Consumption Time: 3.10988
PPO Batch Consumption Time: 0.23006
Total Iteration Time: 7.02663
Cumulative Model Updates: 11,436
Cumulative Timesteps: 63,628,664
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 63628664...
Checkpoint 63628664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.35398
Policy Entropy: 3.60365
Value Function Loss: 0.26767
Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.70955
Value Function Update Magnitude: 0.80945
Collected Steps per Second: 12,791.00456
Overall Steps per Second: 7,088.88759
Timestep Collection Time: 3.91181
Timestep Consumption Time: 3.14656
PPO Batch Consumption Time: 0.22997
Total Iteration Time: 7.05837
Cumulative Model Updates: 11,445
Cumulative Timesteps: 63,678,700
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70346
Policy Entropy: 3.60510
Value Function Loss: 0.27753
Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.70897
Value Function Update Magnitude: 0.79639
Collected Steps per Second: 12,871.63673
Overall Steps per Second: 7,103.72342
Timestep Collection Time: 3.88591
Timestep Consumption Time: 3.15519
PPO Batch Consumption Time: 0.22976
Total Iteration Time: 7.04110
Cumulative Model Updates: 11,454
Cumulative Timesteps: 63,728,718
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 63728718...
Checkpoint 63728718 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.18212
Policy Entropy: 3.60794
Value Function Loss: 0.27587
Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.70806
Value Function Update Magnitude: 0.82052
Collected Steps per Second: 12,701.94541
Overall Steps per Second: 7,168.19787
Timestep Collection Time: 3.93672
Timestep Consumption Time: 3.03909
PPO Batch Consumption Time: 0.22973
Total Iteration Time: 6.97581
Cumulative Model Updates: 11,463
Cumulative Timesteps: 63,778,722
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.93279
Policy Entropy: 3.60193
Value Function Loss: 0.26711
Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.70638
Value Function Update Magnitude: 0.77870
Collected Steps per Second: 12,725.62466
Overall Steps per Second: 7,027.68273
Timestep Collection Time: 3.92955
Timestep Consumption Time: 3.18602
PPO Batch Consumption Time: 0.23355
Total Iteration Time: 7.11557
Cumulative Model Updates: 11,472
Cumulative Timesteps: 63,828,728
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 63828728...
Checkpoint 63828728 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.90507
Policy Entropy: 3.60942
Value Function Loss: 0.25085
Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.68659
Value Function Update Magnitude: 0.74081
Collected Steps per Second: 12,560.95952
Overall Steps per Second: 7,086.57725
Timestep Collection Time: 3.98314
Timestep Consumption Time: 3.07697
PPO Batch Consumption Time: 0.23002
Total Iteration Time: 7.06011
Cumulative Model Updates: 11,481
Cumulative Timesteps: 63,878,760
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.30685
Policy Entropy: 3.60730
Value Function Loss: 0.24992
Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.68341
Value Function Update Magnitude: 0.74567
Collected Steps per Second: 13,004.37281
Overall Steps per Second: 7,187.04051
Timestep Collection Time: 3.84624
Timestep Consumption Time: 3.11323
PPO Batch Consumption Time: 0.22963
Total Iteration Time: 6.95947
Cumulative Model Updates: 11,490
Cumulative Timesteps: 63,928,778
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 63928778...
Checkpoint 63928778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.17594
Policy Entropy: 3.60376
Value Function Loss: 0.26763
Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.70034
Value Function Update Magnitude: 0.75810
Collected Steps per Second: 12,713.52654
Overall Steps per Second: 7,067.57395
Timestep Collection Time: 3.93282
Timestep Consumption Time: 3.14174
PPO Batch Consumption Time: 0.22978
Total Iteration Time: 7.07456
Cumulative Model Updates: 11,499
Cumulative Timesteps: 63,978,778
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.88119
Policy Entropy: 3.60158
Value Function Loss: 0.27141
Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.70131
Value Function Update Magnitude: 0.75505
Collected Steps per Second: 12,763.84965
Overall Steps per Second: 7,115.80848
Timestep Collection Time: 3.92060
Timestep Consumption Time: 3.11191
PPO Batch Consumption Time: 0.23011
Total Iteration Time: 7.03251
Cumulative Model Updates: 11,508
Cumulative Timesteps: 64,028,820
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 64028820...
Checkpoint 64028820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.46188
Policy Entropy: 3.59631
Value Function Loss: 0.27673
Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.70799
Value Function Update Magnitude: 0.83231
Collected Steps per Second: 12,973.08528
Overall Steps per Second: 7,107.06919
Timestep Collection Time: 3.85413
Timestep Consumption Time: 3.18112
PPO Batch Consumption Time: 0.23514
Total Iteration Time: 7.03525
Cumulative Model Updates: 11,517
Cumulative Timesteps: 64,078,820
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.49722
Policy Entropy: 3.58747
Value Function Loss: 0.27028
Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.70951
Value Function Update Magnitude: 0.83729
Collected Steps per Second: 13,000.86038
Overall Steps per Second: 7,169.40505
Timestep Collection Time: 3.84713
Timestep Consumption Time: 3.12918
PPO Batch Consumption Time: 0.23020
Total Iteration Time: 6.97631
Cumulative Model Updates: 11,526
Cumulative Timesteps: 64,128,836
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 64128836...
Checkpoint 64128836 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.45833
Policy Entropy: 3.59072
Value Function Loss: 0.28426
Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.71816
Value Function Update Magnitude: 0.87130
Collected Steps per Second: 13,021.67771
Overall Steps per Second: 7,218.54002
Timestep Collection Time: 3.84282
Timestep Consumption Time: 3.08933
PPO Batch Consumption Time: 0.23468
Total Iteration Time: 6.93215
Cumulative Model Updates: 11,535
Cumulative Timesteps: 64,178,876
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.43762
Policy Entropy: 3.59882
Value Function Loss: 0.27372
Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.72251
Value Function Update Magnitude: 0.83598
Collected Steps per Second: 13,063.49240
Overall Steps per Second: 7,189.21800
Timestep Collection Time: 3.82869
Timestep Consumption Time: 3.12840
PPO Batch Consumption Time: 0.22977
Total Iteration Time: 6.95708
Cumulative Model Updates: 11,544
Cumulative Timesteps: 64,228,892
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 64228892...
Checkpoint 64228892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.85220
Policy Entropy: 3.60483
Value Function Loss: 0.28029
Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.71267
Value Function Update Magnitude: 0.82890
Collected Steps per Second: 12,754.56787
Overall Steps per Second: 7,099.63378
Timestep Collection Time: 3.92079
Timestep Consumption Time: 3.12295
PPO Batch Consumption Time: 0.23051
Total Iteration Time: 7.04374
Cumulative Model Updates: 11,553
Cumulative Timesteps: 64,278,900
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.86757
Policy Entropy: 3.60140
Value Function Loss: 0.28118
Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.71755
Value Function Update Magnitude: 0.80963
Collected Steps per Second: 12,765.34033
Overall Steps per Second: 7,143.75566
Timestep Collection Time: 3.91936
Timestep Consumption Time: 3.08424
PPO Batch Consumption Time: 0.23274
Total Iteration Time: 7.00360
Cumulative Model Updates: 11,562
Cumulative Timesteps: 64,328,932
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 64328932...
Checkpoint 64328932 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.72731
Policy Entropy: 3.59935
Value Function Loss: 0.26344
Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.70514
Value Function Update Magnitude: 0.85832
Collected Steps per Second: 13,068.19029
Overall Steps per Second: 7,184.75677
Timestep Collection Time: 3.82899
Timestep Consumption Time: 3.13547
PPO Batch Consumption Time: 0.22958
Total Iteration Time: 6.96447
Cumulative Model Updates: 11,571
Cumulative Timesteps: 64,378,970
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.57934
Policy Entropy: 3.59331
Value Function Loss: 0.26877
Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.70132
Value Function Update Magnitude: 0.84662
Collected Steps per Second: 12,921.92461
Overall Steps per Second: 7,199.30198
Timestep Collection Time: 3.87094
Timestep Consumption Time: 3.07696
PPO Batch Consumption Time: 0.22957
Total Iteration Time: 6.94790
Cumulative Model Updates: 11,580
Cumulative Timesteps: 64,428,990
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 64428990...
Checkpoint 64428990 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.11199
Policy Entropy: 3.59857
Value Function Loss: 0.26012
Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.70275
Value Function Update Magnitude: 0.89088
Collected Steps per Second: 13,341.68807
Overall Steps per Second: 7,292.87709
Timestep Collection Time: 3.75005
Timestep Consumption Time: 3.11034
PPO Batch Consumption Time: 0.22959
Total Iteration Time: 6.86039
Cumulative Model Updates: 11,589
Cumulative Timesteps: 64,479,022
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.04174
Policy Entropy: 3.60429
Value Function Loss: 0.25452
Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.69828
Value Function Update Magnitude: 0.81881
Collected Steps per Second: 12,966.96390
Overall Steps per Second: 6,990.44747
Timestep Collection Time: 3.85780
Timestep Consumption Time: 3.29825
PPO Batch Consumption Time: 0.24122
Total Iteration Time: 7.15605
Cumulative Model Updates: 11,598
Cumulative Timesteps: 64,529,046
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 64529046...
Checkpoint 64529046 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85881
Policy Entropy: 3.61721
Value Function Loss: 0.24617
Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.68723
Value Function Update Magnitude: 0.76177
Collected Steps per Second: 13,024.44331
Overall Steps per Second: 7,283.85830
Timestep Collection Time: 3.83955
Timestep Consumption Time: 3.02604
PPO Batch Consumption Time: 0.22929
Total Iteration Time: 6.86559
Cumulative Model Updates: 11,607
Cumulative Timesteps: 64,579,054
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.68047
Policy Entropy: 3.62072
Value Function Loss: 0.24823
Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.67649
Value Function Update Magnitude: 0.78723
Collected Steps per Second: 13,131.02520
Overall Steps per Second: 7,188.57174
Timestep Collection Time: 3.80778
Timestep Consumption Time: 3.14771
PPO Batch Consumption Time: 0.22965
Total Iteration Time: 6.95548
Cumulative Model Updates: 11,616
Cumulative Timesteps: 64,629,054
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 64629054...
Checkpoint 64629054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74924
Policy Entropy: 3.60754
Value Function Loss: 0.24941
Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.67142
Value Function Update Magnitude: 0.82771
Collected Steps per Second: 13,136.66684
Overall Steps per Second: 7,234.18617
Timestep Collection Time: 3.80873
Timestep Consumption Time: 3.10760
PPO Batch Consumption Time: 0.22936
Total Iteration Time: 6.91633
Cumulative Model Updates: 11,625
Cumulative Timesteps: 64,679,088
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.00387
Policy Entropy: 3.60326
Value Function Loss: 0.25473
Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.68680
Value Function Update Magnitude: 0.81441
Collected Steps per Second: 13,091.37291
Overall Steps per Second: 7,268.74143
Timestep Collection Time: 3.82221
Timestep Consumption Time: 3.06179
PPO Batch Consumption Time: 0.23043
Total Iteration Time: 6.88400
Cumulative Model Updates: 11,634
Cumulative Timesteps: 64,729,126
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 64729126...
Checkpoint 64729126 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.29450
Policy Entropy: 3.58949
Value Function Loss: 0.25808
Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.68778
Value Function Update Magnitude: 0.86496
Collected Steps per Second: 12,848.50603
Overall Steps per Second: 7,109.55836
Timestep Collection Time: 3.89353
Timestep Consumption Time: 3.14292
PPO Batch Consumption Time: 0.22938
Total Iteration Time: 7.03644
Cumulative Model Updates: 11,643
Cumulative Timesteps: 64,779,152
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.22432
Policy Entropy: 3.59052
Value Function Loss: 0.25648
Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.69301
Value Function Update Magnitude: 0.87269
Collected Steps per Second: 13,128.44246
Overall Steps per Second: 7,225.04607
Timestep Collection Time: 3.80852
Timestep Consumption Time: 3.11185
PPO Batch Consumption Time: 0.22946
Total Iteration Time: 6.92037
Cumulative Model Updates: 11,652
Cumulative Timesteps: 64,829,152
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 64829152...
Checkpoint 64829152 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85115
Policy Entropy: 3.59569
Value Function Loss: 0.25192
Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12057
Policy Update Magnitude: 0.69607
Value Function Update Magnitude: 0.83282
Collected Steps per Second: 13,376.62162
Overall Steps per Second: 7,209.04957
Timestep Collection Time: 3.73921
Timestep Consumption Time: 3.19901
PPO Batch Consumption Time: 0.23134
Total Iteration Time: 6.93822
Cumulative Model Updates: 11,661
Cumulative Timesteps: 64,879,170
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.94259
Policy Entropy: 3.59754
Value Function Loss: 0.26808
Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.70744
Value Function Update Magnitude: 0.83110
Collected Steps per Second: 13,035.29982
Overall Steps per Second: 7,164.41969
Timestep Collection Time: 3.83681
Timestep Consumption Time: 3.14407
PPO Batch Consumption Time: 0.23064
Total Iteration Time: 6.98089
Cumulative Model Updates: 11,670
Cumulative Timesteps: 64,929,184
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 64929184...
Checkpoint 64929184 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90907
Policy Entropy: 3.60743
Value Function Loss: 0.26404
Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.70947
Value Function Update Magnitude: 0.86815
Collected Steps per Second: 12,826.52583
Overall Steps per Second: 7,207.01398
Timestep Collection Time: 3.89817
Timestep Consumption Time: 3.03951
PPO Batch Consumption Time: 0.22972
Total Iteration Time: 6.93769
Cumulative Model Updates: 11,679
Cumulative Timesteps: 64,979,184
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 22.70646
Policy Entropy: 3.60367
Value Function Loss: 0.27098
Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.70938
Value Function Update Magnitude: 0.82506
Collected Steps per Second: 13,182.44156
Overall Steps per Second: 7,238.11873
Timestep Collection Time: 3.79581
Timestep Consumption Time: 3.11732
PPO Batch Consumption Time: 0.22982
Total Iteration Time: 6.91312
Cumulative Model Updates: 11,688
Cumulative Timesteps: 65,029,222
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 65029222...
Checkpoint 65029222 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61815
Policy Entropy: 3.59975
Value Function Loss: 0.27572
Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.70536
Value Function Update Magnitude: 0.83422
Collected Steps per Second: 13,077.26208
Overall Steps per Second: 7,215.01210
Timestep Collection Time: 3.82634
Timestep Consumption Time: 3.10893
PPO Batch Consumption Time: 0.22982
Total Iteration Time: 6.93526
Cumulative Model Updates: 11,697
Cumulative Timesteps: 65,079,260
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.24693
Policy Entropy: 3.59347
Value Function Loss: 0.26594
Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.71127
Value Function Update Magnitude: 0.85468
Collected Steps per Second: 13,395.52410
Overall Steps per Second: 7,286.70624
Timestep Collection Time: 3.73453
Timestep Consumption Time: 3.13085
PPO Batch Consumption Time: 0.22949
Total Iteration Time: 6.86538
Cumulative Model Updates: 11,706
Cumulative Timesteps: 65,129,286
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 65129286...
Checkpoint 65129286 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30385
Policy Entropy: 3.59354
Value Function Loss: 0.26116
Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.70437
Value Function Update Magnitude: 0.79866
Collected Steps per Second: 12,940.56711
Overall Steps per Second: 7,141.71911
Timestep Collection Time: 3.86675
Timestep Consumption Time: 3.13968
PPO Batch Consumption Time: 0.22981
Total Iteration Time: 7.00644
Cumulative Model Updates: 11,715
Cumulative Timesteps: 65,179,324
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.99781
Policy Entropy: 3.59700
Value Function Loss: 0.25526
Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.69859
Value Function Update Magnitude: 0.78699
Collected Steps per Second: 13,128.23039
Overall Steps per Second: 7,170.94906
Timestep Collection Time: 3.81026
Timestep Consumption Time: 3.16538
PPO Batch Consumption Time: 0.23163
Total Iteration Time: 6.97565
Cumulative Model Updates: 11,724
Cumulative Timesteps: 65,229,346
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 65229346...
Checkpoint 65229346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.38973
Policy Entropy: 3.59940
Value Function Loss: 0.24728
Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.69560
Value Function Update Magnitude: 0.77098
Collected Steps per Second: 13,422.78781
Overall Steps per Second: 7,286.28277
Timestep Collection Time: 3.72575
Timestep Consumption Time: 3.13783
PPO Batch Consumption Time: 0.23055
Total Iteration Time: 6.86358
Cumulative Model Updates: 11,733
Cumulative Timesteps: 65,279,356
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.46324
Policy Entropy: 3.58805
Value Function Loss: 0.26400
Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.69926
Value Function Update Magnitude: 0.81414
Collected Steps per Second: 13,128.84111
Overall Steps per Second: 7,213.15040
Timestep Collection Time: 3.81069
Timestep Consumption Time: 3.12525
PPO Batch Consumption Time: 0.22965
Total Iteration Time: 6.93594
Cumulative Model Updates: 11,742
Cumulative Timesteps: 65,329,386
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 65329386...
Checkpoint 65329386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.79294
Policy Entropy: 3.59159
Value Function Loss: 0.25853
Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.70661
Value Function Update Magnitude: 0.90829
Collected Steps per Second: 12,988.71905
Overall Steps per Second: 7,274.01054
Timestep Collection Time: 3.85180
Timestep Consumption Time: 3.02611
PPO Batch Consumption Time: 0.22999
Total Iteration Time: 6.87791
Cumulative Model Updates: 11,751
Cumulative Timesteps: 65,379,416
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30345
Policy Entropy: 3.58726
Value Function Loss: 0.26724
Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.71235
Value Function Update Magnitude: 0.84395
Collected Steps per Second: 11,802.23641
Overall Steps per Second: 6,722.58113
Timestep Collection Time: 4.23903
Timestep Consumption Time: 3.20305
PPO Batch Consumption Time: 0.23759
Total Iteration Time: 7.44208
Cumulative Model Updates: 11,760
Cumulative Timesteps: 65,429,446
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 65429446...
Checkpoint 65429446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.32489
Policy Entropy: 3.60579
Value Function Loss: 0.25032
Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.71142
Value Function Update Magnitude: 0.82743
Collected Steps per Second: 11,435.60354
Overall Steps per Second: 6,625.42321
Timestep Collection Time: 4.37406
Timestep Consumption Time: 3.17565
PPO Batch Consumption Time: 0.23853
Total Iteration Time: 7.54971
Cumulative Model Updates: 11,769
Cumulative Timesteps: 65,479,466
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.08205
Policy Entropy: 3.60691
Value Function Loss: 0.25611
Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12234
Policy Update Magnitude: 0.70735
Value Function Update Magnitude: 0.76076
Collected Steps per Second: 11,036.99205
Overall Steps per Second: 6,346.60005
Timestep Collection Time: 4.53421
Timestep Consumption Time: 3.35096
PPO Batch Consumption Time: 0.25270
Total Iteration Time: 7.88517
Cumulative Model Updates: 11,778
Cumulative Timesteps: 65,529,510
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 65529510...
Checkpoint 65529510 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.76378
Policy Entropy: 3.62486
Value Function Loss: 0.26976
Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12121
Policy Update Magnitude: 0.71978
Value Function Update Magnitude: 0.78632
Collected Steps per Second: 12,075.70961
Overall Steps per Second: 6,677.95156
Timestep Collection Time: 4.14419
Timestep Consumption Time: 3.34973
PPO Batch Consumption Time: 0.24500
Total Iteration Time: 7.49391
Cumulative Model Updates: 11,787
Cumulative Timesteps: 65,579,554
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.48544
Policy Entropy: 3.61899
Value Function Loss: 0.26512
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.71211
Value Function Update Magnitude: 0.79001
Collected Steps per Second: 11,717.30443
Overall Steps per Second: 6,735.68608
Timestep Collection Time: 4.26788
Timestep Consumption Time: 3.15646
PPO Batch Consumption Time: 0.23132
Total Iteration Time: 7.42434
Cumulative Model Updates: 11,796
Cumulative Timesteps: 65,629,562
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 65629562...
Checkpoint 65629562 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.05917
Policy Entropy: 3.61842
Value Function Loss: 0.27521
Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12060
Policy Update Magnitude: 0.70718
Value Function Update Magnitude: 0.86108
Collected Steps per Second: 12,544.37776
Overall Steps per Second: 7,057.03194
Timestep Collection Time: 3.98888
Timestep Consumption Time: 3.10164
PPO Batch Consumption Time: 0.23000
Total Iteration Time: 7.09052
Cumulative Model Updates: 11,805
Cumulative Timesteps: 65,679,600
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.16014
Policy Entropy: 3.60810
Value Function Loss: 0.26991
Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.70950
Value Function Update Magnitude: 0.85722
Collected Steps per Second: 12,422.44721
Overall Steps per Second: 6,838.01037
Timestep Collection Time: 4.02835
Timestep Consumption Time: 3.28986
PPO Batch Consumption Time: 0.24141
Total Iteration Time: 7.31821
Cumulative Model Updates: 11,814
Cumulative Timesteps: 65,729,642
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 65729642...
Checkpoint 65729642 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.39467
Policy Entropy: 3.61304
Value Function Loss: 0.26907
Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.71796
Value Function Update Magnitude: 0.82990
Collected Steps per Second: 11,813.53791
Overall Steps per Second: 6,762.96325
Timestep Collection Time: 4.23548
Timestep Consumption Time: 3.16305
PPO Batch Consumption Time: 0.23421
Total Iteration Time: 7.39853
Cumulative Model Updates: 11,823
Cumulative Timesteps: 65,779,678
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.55689
Policy Entropy: 3.61357
Value Function Loss: 0.26316
Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.71503
Value Function Update Magnitude: 0.82898
Collected Steps per Second: 11,509.72247
Overall Steps per Second: 6,558.50675
Timestep Collection Time: 4.34415
Timestep Consumption Time: 3.27953
PPO Batch Consumption Time: 0.23896
Total Iteration Time: 7.62369
Cumulative Model Updates: 11,832
Cumulative Timesteps: 65,829,678
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 65829678...
Checkpoint 65829678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01574
Policy Entropy: 3.61827
Value Function Loss: 0.26264
Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.70526
Value Function Update Magnitude: 0.79014
Collected Steps per Second: 11,097.30650
Overall Steps per Second: 6,433.22155
Timestep Collection Time: 4.50920
Timestep Consumption Time: 3.26917
PPO Batch Consumption Time: 0.24054
Total Iteration Time: 7.77837
Cumulative Model Updates: 11,841
Cumulative Timesteps: 65,879,718
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.71327
Policy Entropy: 3.61308
Value Function Loss: 0.27725
Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.70648
Value Function Update Magnitude: 0.81121
Collected Steps per Second: 12,221.40200
Overall Steps per Second: 6,843.02037
Timestep Collection Time: 4.09413
Timestep Consumption Time: 3.21785
PPO Batch Consumption Time: 0.24571
Total Iteration Time: 7.31198
Cumulative Model Updates: 11,850
Cumulative Timesteps: 65,929,754
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 65929754...
Checkpoint 65929754 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.91709
Policy Entropy: 3.60534
Value Function Loss: 0.27362
Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12144
Policy Update Magnitude: 0.71783
Value Function Update Magnitude: 1.01623
Collected Steps per Second: 12,235.98655
Overall Steps per Second: 6,650.68984
Timestep Collection Time: 4.08941
Timestep Consumption Time: 3.43432
PPO Batch Consumption Time: 0.24662
Total Iteration Time: 7.52373
Cumulative Model Updates: 11,859
Cumulative Timesteps: 65,979,792
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.36409
Policy Entropy: 3.60031
Value Function Loss: 0.26722
Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.72891
Value Function Update Magnitude: 1.10976
Collected Steps per Second: 10,735.49676
Overall Steps per Second: 6,374.94983
Timestep Collection Time: 4.66024
Timestep Consumption Time: 3.18766
PPO Batch Consumption Time: 0.23338
Total Iteration Time: 7.84790
Cumulative Model Updates: 11,868
Cumulative Timesteps: 66,029,822
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 66029822...
Checkpoint 66029822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.54518
Policy Entropy: 3.60719
Value Function Loss: 0.24667
Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.72619
Value Function Update Magnitude: 1.11312
Collected Steps per Second: 12,157.19066
Overall Steps per Second: 6,806.21752
Timestep Collection Time: 4.11575
Timestep Consumption Time: 3.23576
PPO Batch Consumption Time: 0.23359
Total Iteration Time: 7.35151
Cumulative Model Updates: 11,877
Cumulative Timesteps: 66,079,858
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.90748
Policy Entropy: 3.61312
Value Function Loss: 0.25010
Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.71445
Value Function Update Magnitude: 1.02577
Collected Steps per Second: 12,281.32468
Overall Steps per Second: 6,637.62911
Timestep Collection Time: 4.07301
Timestep Consumption Time: 3.46311
PPO Batch Consumption Time: 0.25314
Total Iteration Time: 7.53612
Cumulative Model Updates: 11,886
Cumulative Timesteps: 66,129,880
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 66129880...
Checkpoint 66129880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.84877
Policy Entropy: 3.61747
Value Function Loss: 0.26214
Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11674
Policy Update Magnitude: 0.71921
Value Function Update Magnitude: 0.81625
Collected Steps per Second: 11,808.54486
Overall Steps per Second: 6,804.63382
Timestep Collection Time: 4.23456
Timestep Consumption Time: 3.11396
PPO Batch Consumption Time: 0.23575
Total Iteration Time: 7.34852
Cumulative Model Updates: 11,895
Cumulative Timesteps: 66,179,884
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52098
Policy Entropy: 3.61560
Value Function Loss: 0.29407
Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.73553
Value Function Update Magnitude: 0.82706
Collected Steps per Second: 11,681.03602
Overall Steps per Second: 6,706.20087
Timestep Collection Time: 4.28198
Timestep Consumption Time: 3.17649
PPO Batch Consumption Time: 0.22980
Total Iteration Time: 7.45847
Cumulative Model Updates: 11,904
Cumulative Timesteps: 66,229,902
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 66229902...
Checkpoint 66229902 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.63384
Policy Entropy: 3.60355
Value Function Loss: 0.30230
Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.74589
Value Function Update Magnitude: 0.84007
Collected Steps per Second: 12,125.47598
Overall Steps per Second: 6,778.54069
Timestep Collection Time: 4.12487
Timestep Consumption Time: 3.25371
PPO Batch Consumption Time: 0.24243
Total Iteration Time: 7.37858
Cumulative Model Updates: 11,913
Cumulative Timesteps: 66,279,918
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.95117
Policy Entropy: 3.59725
Value Function Loss: 0.29724
Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.74192
Value Function Update Magnitude: 0.82979
Collected Steps per Second: 12,378.73568
Overall Steps per Second: 6,962.08137
Timestep Collection Time: 4.04225
Timestep Consumption Time: 3.14496
PPO Batch Consumption Time: 0.23568
Total Iteration Time: 7.18722
Cumulative Model Updates: 11,922
Cumulative Timesteps: 66,329,956
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 66329956...
Checkpoint 66329956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.42274
Policy Entropy: 3.59600
Value Function Loss: 0.28905
Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.74149
Value Function Update Magnitude: 0.77244
Collected Steps per Second: 12,730.59227
Overall Steps per Second: 7,043.02056
Timestep Collection Time: 3.93242
Timestep Consumption Time: 3.17561
PPO Batch Consumption Time: 0.23026
Total Iteration Time: 7.10803
Cumulative Model Updates: 11,931
Cumulative Timesteps: 66,380,018
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 20.04439
Policy Entropy: 3.59465
Value Function Loss: 0.28348
Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.74237
Value Function Update Magnitude: 1.04759
Collected Steps per Second: 11,701.93998
Overall Steps per Second: 6,608.34661
Timestep Collection Time: 4.27570
Timestep Consumption Time: 3.29563
PPO Batch Consumption Time: 0.23206
Total Iteration Time: 7.57133
Cumulative Model Updates: 11,940
Cumulative Timesteps: 66,430,052
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 66430052...
Checkpoint 66430052 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.68960
Policy Entropy: 3.59152
Value Function Loss: 0.28769
Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.74875
Value Function Update Magnitude: 0.96363
Collected Steps per Second: 11,327.45986
Overall Steps per Second: 6,408.97381
Timestep Collection Time: 4.41582
Timestep Consumption Time: 3.38886
PPO Batch Consumption Time: 0.24567
Total Iteration Time: 7.80468
Cumulative Model Updates: 11,949
Cumulative Timesteps: 66,480,072
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.47898
Policy Entropy: 3.59932
Value Function Loss: 0.28211
Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.74274
Value Function Update Magnitude: 0.80408
Collected Steps per Second: 11,825.28014
Overall Steps per Second: 6,568.54790
Timestep Collection Time: 4.23263
Timestep Consumption Time: 3.38732
PPO Batch Consumption Time: 0.25237
Total Iteration Time: 7.61995
Cumulative Model Updates: 11,958
Cumulative Timesteps: 66,530,124
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 66530124...
