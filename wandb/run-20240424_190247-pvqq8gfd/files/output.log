Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.36423
Policy Entropy: 4.32402
Value Function Loss: 0.00425
Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00240
Policy Update Magnitude: 0.40382
Value Function Update Magnitude: 0.37932
Collected Steps per Second: 12,650.91736
Overall Steps per Second: 8,415.29059
Timestep Collection Time: 3.95513
Timestep Consumption Time: 1.99072
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 5.94584
Cumulative Model Updates: 158,504
Cumulative Timesteps: 1,246,841,918
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.70601
Policy Entropy: 4.33630
Value Function Loss: 0.00344
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02780
Policy Update Magnitude: 0.89807
Value Function Update Magnitude: 0.70105
Collected Steps per Second: 12,604.46035
Overall Steps per Second: 7,834.69336
Timestep Collection Time: 3.97002
Timestep Consumption Time: 2.41695
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 6.38698
Cumulative Model Updates: 158,510
Cumulative Timesteps: 1,246,891,958
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1246891958...
Checkpoint 1246891958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71028
Policy Entropy: 4.34454
Value Function Loss: 0.00291
Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04089
Policy Update Magnitude: 0.85687
Value Function Update Magnitude: 0.66881
Collected Steps per Second: 12,838.02290
Overall Steps per Second: 7,933.16480
Timestep Collection Time: 3.89468
Timestep Consumption Time: 2.40797
PPO Batch Consumption Time: 0.23038
Total Iteration Time: 6.30265
Cumulative Model Updates: 158,516
Cumulative Timesteps: 1,246,941,958
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.58417
Policy Entropy: 4.35058
Value Function Loss: 0.00270
Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04650
Policy Update Magnitude: 1.13218
Value Function Update Magnitude: 0.91029
Collected Steps per Second: 13,057.53464
Overall Steps per Second: 7,296.30983
Timestep Collection Time: 3.83242
Timestep Consumption Time: 3.02611
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.85854
Cumulative Model Updates: 158,525
Cumulative Timesteps: 1,246,992,000
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1246992000...
Checkpoint 1246992000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.55500
Policy Entropy: 4.35722
Value Function Loss: 0.00243
Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04354
Policy Update Magnitude: 1.04740
Value Function Update Magnitude: 0.79587
Collected Steps per Second: 13,152.84220
Overall Steps per Second: 7,192.91007
Timestep Collection Time: 3.80450
Timestep Consumption Time: 3.15235
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.95685
Cumulative Model Updates: 158,534
Cumulative Timesteps: 1,247,042,040
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99082
Policy Entropy: 4.35644
Value Function Loss: 0.00247
Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04157
Policy Update Magnitude: 0.99963
Value Function Update Magnitude: 0.73033
Collected Steps per Second: 13,048.30159
Overall Steps per Second: 7,236.37752
Timestep Collection Time: 3.83345
Timestep Consumption Time: 3.07885
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.91230
Cumulative Model Updates: 158,543
Cumulative Timesteps: 1,247,092,060
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1247092060...
Checkpoint 1247092060 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85707
Policy Entropy: 4.35736
Value Function Loss: 0.00244
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03751
Policy Update Magnitude: 0.99843
Value Function Update Magnitude: 0.70911
Collected Steps per Second: 13,050.32993
Overall Steps per Second: 7,309.58885
Timestep Collection Time: 3.83347
Timestep Consumption Time: 3.01069
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.84416
Cumulative Model Updates: 158,552
Cumulative Timesteps: 1,247,142,088
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.52239
Policy Entropy: 4.35640
Value Function Loss: 0.00256
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03641
Policy Update Magnitude: 0.99332
Value Function Update Magnitude: 0.68435
Collected Steps per Second: 13,127.56457
Overall Steps per Second: 7,171.06976
Timestep Collection Time: 3.81000
Timestep Consumption Time: 3.16469
PPO Batch Consumption Time: 0.23286
Total Iteration Time: 6.97469
Cumulative Model Updates: 158,561
Cumulative Timesteps: 1,247,192,104
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1247192104...
Checkpoint 1247192104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43810
Policy Entropy: 4.35654
Value Function Loss: 0.00250
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 0.98694
Value Function Update Magnitude: 0.68822
Collected Steps per Second: 13,132.07047
Overall Steps per Second: 7,256.35195
Timestep Collection Time: 3.80945
Timestep Consumption Time: 3.08465
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.89410
Cumulative Model Updates: 158,570
Cumulative Timesteps: 1,247,242,130
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.04993
Policy Entropy: 4.35885
Value Function Loss: 0.00231
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03347
Policy Update Magnitude: 0.97505
Value Function Update Magnitude: 0.69242
Collected Steps per Second: 13,386.09784
Overall Steps per Second: 7,310.26453
Timestep Collection Time: 3.73731
Timestep Consumption Time: 3.10622
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.84353
Cumulative Model Updates: 158,579
Cumulative Timesteps: 1,247,292,158
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1247292158...
Checkpoint 1247292158 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56896
Policy Entropy: 4.35999
Value Function Loss: 0.00237
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 0.96933
Value Function Update Magnitude: 0.70538
Collected Steps per Second: 13,113.82916
Overall Steps per Second: 7,229.34563
Timestep Collection Time: 3.81277
Timestep Consumption Time: 3.10349
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.91626
Cumulative Model Updates: 158,588
Cumulative Timesteps: 1,247,342,158
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72377
Policy Entropy: 4.35888
Value Function Loss: 0.00243
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03289
Policy Update Magnitude: 0.99003
Value Function Update Magnitude: 0.72014
Collected Steps per Second: 13,158.72189
Overall Steps per Second: 7,285.11828
Timestep Collection Time: 3.80189
Timestep Consumption Time: 3.06526
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.86715
Cumulative Model Updates: 158,597
Cumulative Timesteps: 1,247,392,186
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1247392186...
Checkpoint 1247392186 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.30148
Policy Entropy: 4.35679
Value Function Loss: 0.00255
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03414
Policy Update Magnitude: 1.01490
Value Function Update Magnitude: 0.72258
Collected Steps per Second: 13,440.82590
Overall Steps per Second: 7,315.61155
Timestep Collection Time: 3.72120
Timestep Consumption Time: 3.11569
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.83689
Cumulative Model Updates: 158,606
Cumulative Timesteps: 1,247,442,202
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42855
Policy Entropy: 4.35604
Value Function Loss: 0.00259
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03572
Policy Update Magnitude: 1.00922
Value Function Update Magnitude: 0.74392
Collected Steps per Second: 13,110.92310
Overall Steps per Second: 7,195.44794
Timestep Collection Time: 3.81529
Timestep Consumption Time: 3.13660
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.95190
Cumulative Model Updates: 158,615
Cumulative Timesteps: 1,247,492,224
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1247492224...
Checkpoint 1247492224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53570
Policy Entropy: 4.35894
Value Function Loss: 0.00260
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03328
Policy Update Magnitude: 0.99037
Value Function Update Magnitude: 0.77133
Collected Steps per Second: 13,150.79727
Overall Steps per Second: 7,200.48372
Timestep Collection Time: 3.80251
Timestep Consumption Time: 3.14230
PPO Batch Consumption Time: 0.23500
Total Iteration Time: 6.94481
Cumulative Model Updates: 158,624
Cumulative Timesteps: 1,247,542,230
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81224
Policy Entropy: 4.35911
Value Function Loss: 0.00255
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03255
Policy Update Magnitude: 0.98243
Value Function Update Magnitude: 0.77956
Collected Steps per Second: 13,488.40940
Overall Steps per Second: 7,336.08146
Timestep Collection Time: 3.70748
Timestep Consumption Time: 3.10924
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.81672
Cumulative Model Updates: 158,633
Cumulative Timesteps: 1,247,592,238
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1247592238...
Checkpoint 1247592238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50796
Policy Entropy: 4.35990
Value Function Loss: 0.00259
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03070
Policy Update Magnitude: 0.98262
Value Function Update Magnitude: 0.76745
Collected Steps per Second: 13,252.60401
Overall Steps per Second: 7,245.79254
Timestep Collection Time: 3.77360
Timestep Consumption Time: 3.12834
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.90194
Cumulative Model Updates: 158,642
Cumulative Timesteps: 1,247,642,248
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71147
Policy Entropy: 4.35408
Value Function Loss: 0.00266
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 0.99694
Value Function Update Magnitude: 0.75125
Collected Steps per Second: 13,263.42529
Overall Steps per Second: 7,361.87054
Timestep Collection Time: 3.77248
Timestep Consumption Time: 3.02416
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.79664
Cumulative Model Updates: 158,651
Cumulative Timesteps: 1,247,692,284
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1247692284...
Checkpoint 1247692284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08124
Policy Entropy: 4.35394
Value Function Loss: 0.00256
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 1.00327
Value Function Update Magnitude: 0.69929
Collected Steps per Second: 13,124.43296
Overall Steps per Second: 7,221.96364
Timestep Collection Time: 3.81335
Timestep Consumption Time: 3.11663
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.92997
Cumulative Model Updates: 158,660
Cumulative Timesteps: 1,247,742,332
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31280
Policy Entropy: 4.35664
Value Function Loss: 0.00230
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.96818
Value Function Update Magnitude: 0.66384
Collected Steps per Second: 13,031.97862
Overall Steps per Second: 7,247.33428
Timestep Collection Time: 3.83932
Timestep Consumption Time: 3.06445
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.90378
Cumulative Model Updates: 158,669
Cumulative Timesteps: 1,247,792,366
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1247792366...
Checkpoint 1247792366 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.30615
Policy Entropy: 4.35675
Value Function Loss: 0.00222
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03076
Policy Update Magnitude: 0.94846
Value Function Update Magnitude: 0.65493
Collected Steps per Second: 13,054.76186
Overall Steps per Second: 7,336.33689
Timestep Collection Time: 3.83492
Timestep Consumption Time: 2.98919
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.82411
Cumulative Model Updates: 158,678
Cumulative Timesteps: 1,247,842,430
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.79937
Policy Entropy: 4.35898
Value Function Loss: 0.00223
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.94320
Value Function Update Magnitude: 0.66160
Collected Steps per Second: 13,304.10485
Overall Steps per Second: 7,106.71233
Timestep Collection Time: 3.75839
Timestep Consumption Time: 3.27749
PPO Batch Consumption Time: 0.24102
Total Iteration Time: 7.03588
Cumulative Model Updates: 158,687
Cumulative Timesteps: 1,247,892,432
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1247892432...
Checkpoint 1247892432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71747
Policy Entropy: 4.35724
Value Function Loss: 0.00242
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03055
Policy Update Magnitude: 0.94230
Value Function Update Magnitude: 0.68841
Collected Steps per Second: 12,958.78612
Overall Steps per Second: 7,219.39770
Timestep Collection Time: 3.85978
Timestep Consumption Time: 3.06850
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.92828
Cumulative Model Updates: 158,696
Cumulative Timesteps: 1,247,942,450
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42883
Policy Entropy: 4.35756
Value Function Loss: 0.00249
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02989
Policy Update Magnitude: 0.95309
Value Function Update Magnitude: 0.71556
Collected Steps per Second: 13,168.07990
Overall Steps per Second: 7,356.38819
Timestep Collection Time: 3.79706
Timestep Consumption Time: 2.99975
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.79681
Cumulative Model Updates: 158,705
Cumulative Timesteps: 1,247,992,450
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1247992450...
Checkpoint 1247992450 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13046
Policy Entropy: 4.35841
Value Function Loss: 0.00247
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02980
Policy Update Magnitude: 0.95474
Value Function Update Magnitude: 0.70322
Collected Steps per Second: 13,183.80234
Overall Steps per Second: 7,244.51071
Timestep Collection Time: 3.79390
Timestep Consumption Time: 3.11036
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 6.90426
Cumulative Model Updates: 158,714
Cumulative Timesteps: 1,248,042,468
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.97788
Policy Entropy: 4.35445
Value Function Loss: 0.00240
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.93607
Value Function Update Magnitude: 0.72421
Collected Steps per Second: 13,132.62189
Overall Steps per Second: 7,245.62271
Timestep Collection Time: 3.80823
Timestep Consumption Time: 3.09415
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.90237
Cumulative Model Updates: 158,723
Cumulative Timesteps: 1,248,092,480
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1248092480...
Checkpoint 1248092480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.02216
Policy Entropy: 4.35695
Value Function Loss: 0.00244
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02836
Policy Update Magnitude: 0.94173
Value Function Update Magnitude: 0.69032
Collected Steps per Second: 13,496.03244
Overall Steps per Second: 7,328.97205
Timestep Collection Time: 3.70687
Timestep Consumption Time: 3.11919
PPO Batch Consumption Time: 0.22961
Total Iteration Time: 6.82606
Cumulative Model Updates: 158,732
Cumulative Timesteps: 1,248,142,508
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20129
Policy Entropy: 4.36000
Value Function Loss: 0.00239
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03015
Policy Update Magnitude: 0.92527
Value Function Update Magnitude: 0.68520
Collected Steps per Second: 13,164.79747
Overall Steps per Second: 7,218.76723
Timestep Collection Time: 3.80074
Timestep Consumption Time: 3.13064
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.93138
Cumulative Model Updates: 158,741
Cumulative Timesteps: 1,248,192,544
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1248192544...
Checkpoint 1248192544 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95469
Policy Entropy: 4.36039
Value Function Loss: 0.00255
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.91483
Value Function Update Magnitude: 0.72110
Collected Steps per Second: 13,083.89155
Overall Steps per Second: 7,174.40000
Timestep Collection Time: 3.82302
Timestep Consumption Time: 3.14899
PPO Batch Consumption Time: 0.23120
Total Iteration Time: 6.97201
Cumulative Model Updates: 158,750
Cumulative Timesteps: 1,248,242,564
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.86136
Policy Entropy: 4.35760
Value Function Loss: 0.00251
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.92642
Value Function Update Magnitude: 0.72299
Collected Steps per Second: 13,525.61924
Overall Steps per Second: 7,338.67443
Timestep Collection Time: 3.69905
Timestep Consumption Time: 3.11853
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.81758
Cumulative Model Updates: 158,759
Cumulative Timesteps: 1,248,292,596
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1248292596...
Checkpoint 1248292596 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75471
Policy Entropy: 4.35343
Value Function Loss: 0.00267
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03199
Policy Update Magnitude: 0.94359
Value Function Update Magnitude: 0.70563
Collected Steps per Second: 13,170.60005
Overall Steps per Second: 7,226.84960
Timestep Collection Time: 3.79649
Timestep Consumption Time: 3.12243
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.91892
Cumulative Model Updates: 158,768
Cumulative Timesteps: 1,248,342,598
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.86726
Policy Entropy: 4.34959
Value Function Loss: 0.00283
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03322
Policy Update Magnitude: 0.96848
Value Function Update Magnitude: 0.69270
Collected Steps per Second: 13,118.36767
Overall Steps per Second: 7,328.87056
Timestep Collection Time: 3.81404
Timestep Consumption Time: 3.01293
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.82697
Cumulative Model Updates: 158,777
Cumulative Timesteps: 1,248,392,632
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1248392632...
Checkpoint 1248392632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.08350
Policy Entropy: 4.34838
Value Function Loss: 0.00278
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03493
Policy Update Magnitude: 0.97764
Value Function Update Magnitude: 0.72416
Collected Steps per Second: 13,070.03923
Overall Steps per Second: 7,212.67415
Timestep Collection Time: 3.82891
Timestep Consumption Time: 3.10943
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.93834
Cumulative Model Updates: 158,786
Cumulative Timesteps: 1,248,442,676
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.19105
Policy Entropy: 4.34969
Value Function Loss: 0.00272
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03273
Policy Update Magnitude: 0.94973
Value Function Update Magnitude: 0.73137
Collected Steps per Second: 13,090.01386
Overall Steps per Second: 7,243.39575
Timestep Collection Time: 3.82047
Timestep Consumption Time: 3.08375
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.90422
Cumulative Model Updates: 158,795
Cumulative Timesteps: 1,248,492,686
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1248492686...
Checkpoint 1248492686 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43449
Policy Entropy: 4.35394
Value Function Loss: 0.00242
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02935
Policy Update Magnitude: 0.91214
Value Function Update Magnitude: 0.71898
Collected Steps per Second: 12,871.75652
Overall Steps per Second: 7,245.95360
Timestep Collection Time: 3.88541
Timestep Consumption Time: 3.01665
PPO Batch Consumption Time: 0.22918
Total Iteration Time: 6.90206
Cumulative Model Updates: 158,804
Cumulative Timesteps: 1,248,542,698
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06719
Policy Entropy: 4.35647
Value Function Loss: 0.00238
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02701
Policy Update Magnitude: 0.88992
Value Function Update Magnitude: 0.75655
Collected Steps per Second: 13,141.30753
Overall Steps per Second: 7,189.16583
Timestep Collection Time: 3.80541
Timestep Consumption Time: 3.15062
PPO Batch Consumption Time: 0.23130
Total Iteration Time: 6.95602
Cumulative Model Updates: 158,813
Cumulative Timesteps: 1,248,592,706
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1248592706...
Checkpoint 1248592706 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37726
Policy Entropy: 4.35617
Value Function Loss: 0.00246
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.91485
Value Function Update Magnitude: 0.74954
Collected Steps per Second: 13,081.44397
Overall Steps per Second: 7,232.44159
Timestep Collection Time: 3.82374
Timestep Consumption Time: 3.09232
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.91606
Cumulative Model Updates: 158,822
Cumulative Timesteps: 1,248,642,726
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45632
Policy Entropy: 4.35258
Value Function Loss: 0.00273
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.95961
Value Function Update Magnitude: 0.78675
Collected Steps per Second: 13,549.68195
Overall Steps per Second: 7,355.56684
Timestep Collection Time: 3.69263
Timestep Consumption Time: 3.10956
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.80219
Cumulative Model Updates: 158,831
Cumulative Timesteps: 1,248,692,760
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1248692760...
Checkpoint 1248692760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.68411
Policy Entropy: 4.34964
Value Function Loss: 0.00272
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03061
Policy Update Magnitude: 0.96753
Value Function Update Magnitude: 0.79306
Collected Steps per Second: 13,374.02111
Overall Steps per Second: 7,270.50615
Timestep Collection Time: 3.74039
Timestep Consumption Time: 3.14002
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.88040
Cumulative Model Updates: 158,840
Cumulative Timesteps: 1,248,742,784
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.89525
Policy Entropy: 4.34846
Value Function Loss: 0.00272
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03246
Policy Update Magnitude: 0.96310
Value Function Update Magnitude: 0.77749
Collected Steps per Second: 13,194.00285
Overall Steps per Second: 7,262.65609
Timestep Collection Time: 3.78975
Timestep Consumption Time: 3.09506
PPO Batch Consumption Time: 0.22916
Total Iteration Time: 6.88481
Cumulative Model Updates: 158,849
Cumulative Timesteps: 1,248,792,786
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1248792786...
Checkpoint 1248792786 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.99545
Policy Entropy: 4.35144
Value Function Loss: 0.00259
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 0.93909
Value Function Update Magnitude: 0.75603
Collected Steps per Second: 13,317.89110
Overall Steps per Second: 7,276.90638
Timestep Collection Time: 3.75645
Timestep Consumption Time: 3.11845
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.87490
Cumulative Model Updates: 158,858
Cumulative Timesteps: 1,248,842,814
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75643
Policy Entropy: 4.35529
Value Function Loss: 0.00231
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03067
Policy Update Magnitude: 0.88713
Value Function Update Magnitude: 0.74992
Collected Steps per Second: 13,280.19063
Overall Steps per Second: 7,266.93914
Timestep Collection Time: 3.76696
Timestep Consumption Time: 3.11709
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.88405
Cumulative Model Updates: 158,867
Cumulative Timesteps: 1,248,892,840
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1248892840...
Checkpoint 1248892840 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.29258
Policy Entropy: 4.35550
Value Function Loss: 0.00224
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.86792
Value Function Update Magnitude: 0.70839
Collected Steps per Second: 13,286.16538
Overall Steps per Second: 7,209.40281
Timestep Collection Time: 3.76617
Timestep Consumption Time: 3.17448
PPO Batch Consumption Time: 0.24171
Total Iteration Time: 6.94066
Cumulative Model Updates: 158,876
Cumulative Timesteps: 1,248,942,878
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.73869
Policy Entropy: 4.35396
Value Function Loss: 0.00244
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.92017
Value Function Update Magnitude: 0.67514
Collected Steps per Second: 13,212.67294
Overall Steps per Second: 7,239.63359
Timestep Collection Time: 3.78697
Timestep Consumption Time: 3.12443
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.91140
Cumulative Model Updates: 158,885
Cumulative Timesteps: 1,248,992,914
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1248992914...
Checkpoint 1248992914 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.90986
Policy Entropy: 4.35354
Value Function Loss: 0.00267
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02984
Policy Update Magnitude: 0.93411
Value Function Update Magnitude: 0.73698
Collected Steps per Second: 13,030.05214
Overall Steps per Second: 7,214.58690
Timestep Collection Time: 3.83882
Timestep Consumption Time: 3.09436
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.93318
Cumulative Model Updates: 158,894
Cumulative Timesteps: 1,249,042,934
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41474
Policy Entropy: 4.35373
Value Function Loss: 0.00262
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03264
Policy Update Magnitude: 0.93247
Value Function Update Magnitude: 0.77415
Collected Steps per Second: 13,059.48871
Overall Steps per Second: 7,287.71948
Timestep Collection Time: 3.82894
Timestep Consumption Time: 3.03247
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.86141
Cumulative Model Updates: 158,903
Cumulative Timesteps: 1,249,092,938
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1249092938...
Checkpoint 1249092938 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66194
Policy Entropy: 4.35282
Value Function Loss: 0.00249
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02916
Policy Update Magnitude: 0.92951
Value Function Update Magnitude: 0.73069
Collected Steps per Second: 13,191.95117
Overall Steps per Second: 7,234.13557
Timestep Collection Time: 3.79034
Timestep Consumption Time: 3.12161
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.91195
Cumulative Model Updates: 158,912
Cumulative Timesteps: 1,249,142,940
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.62144
Policy Entropy: 4.35099
Value Function Loss: 0.00251
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02876
Policy Update Magnitude: 0.92380
Value Function Update Magnitude: 0.71718
Collected Steps per Second: 13,304.07893
Overall Steps per Second: 7,308.71451
Timestep Collection Time: 3.76080
Timestep Consumption Time: 3.08500
PPO Batch Consumption Time: 0.22939
Total Iteration Time: 6.84580
Cumulative Model Updates: 158,921
Cumulative Timesteps: 1,249,192,974
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1249192974...
Checkpoint 1249192974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02131
Policy Entropy: 4.35340
Value Function Loss: 0.00247
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.90391
Value Function Update Magnitude: 0.72818
Collected Steps per Second: 13,538.26047
Overall Steps per Second: 7,342.98090
Timestep Collection Time: 3.69590
Timestep Consumption Time: 3.11823
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.81413
Cumulative Model Updates: 158,930
Cumulative Timesteps: 1,249,243,010
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.99836
Policy Entropy: 4.35935
Value Function Loss: 0.00236
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02674
Policy Update Magnitude: 0.88760
Value Function Update Magnitude: 0.74427
Collected Steps per Second: 13,261.30025
Overall Steps per Second: 7,105.15421
Timestep Collection Time: 3.77293
Timestep Consumption Time: 3.26900
PPO Batch Consumption Time: 0.24058
Total Iteration Time: 7.04193
Cumulative Model Updates: 158,939
Cumulative Timesteps: 1,249,293,044
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1249293044...
Checkpoint 1249293044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62912
Policy Entropy: 4.35609
Value Function Loss: 0.00245
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02859
Policy Update Magnitude: 0.91501
Value Function Update Magnitude: 0.70331
Collected Steps per Second: 13,287.40140
Overall Steps per Second: 7,299.27774
Timestep Collection Time: 3.76612
Timestep Consumption Time: 3.08962
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.85575
Cumulative Model Updates: 158,948
Cumulative Timesteps: 1,249,343,086
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73804
Policy Entropy: 4.35229
Value Function Loss: 0.00254
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02886
Policy Update Magnitude: 0.92836
Value Function Update Magnitude: 0.68920
Collected Steps per Second: 13,625.21034
Overall Steps per Second: 7,367.22965
Timestep Collection Time: 3.67099
Timestep Consumption Time: 3.11827
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.78925
Cumulative Model Updates: 158,957
Cumulative Timesteps: 1,249,393,104
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1249393104...
Checkpoint 1249393104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03844
Policy Entropy: 4.35336
Value Function Loss: 0.00243
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03057
Policy Update Magnitude: 0.91167
Value Function Update Magnitude: 0.67790
Collected Steps per Second: 13,175.04563
Overall Steps per Second: 7,238.08441
Timestep Collection Time: 3.79718
Timestep Consumption Time: 3.11459
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.91177
Cumulative Model Updates: 158,966
Cumulative Timesteps: 1,249,443,132
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87803
Policy Entropy: 4.35985
Value Function Loss: 0.00228
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02800
Policy Update Magnitude: 0.89265
Value Function Update Magnitude: 0.68203
Collected Steps per Second: 13,104.45010
Overall Steps per Second: 7,323.95719
Timestep Collection Time: 3.81657
Timestep Consumption Time: 3.01226
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.82882
Cumulative Model Updates: 158,975
Cumulative Timesteps: 1,249,493,146
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1249493146...
Checkpoint 1249493146 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61861
Policy Entropy: 4.36028
Value Function Loss: 0.00245
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02732
Policy Update Magnitude: 0.92562
Value Function Update Magnitude: 0.67485
Collected Steps per Second: 13,248.94473
Overall Steps per Second: 7,248.52095
Timestep Collection Time: 3.77751
Timestep Consumption Time: 3.12707
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.90458
Cumulative Model Updates: 158,984
Cumulative Timesteps: 1,249,543,194
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.16261
Policy Entropy: 4.35833
Value Function Loss: 0.00255
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02745
Policy Update Magnitude: 0.92200
Value Function Update Magnitude: 0.68137
Collected Steps per Second: 13,359.75613
Overall Steps per Second: 7,308.74336
Timestep Collection Time: 3.74318
Timestep Consumption Time: 3.09903
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.84222
Cumulative Model Updates: 158,993
Cumulative Timesteps: 1,249,593,202
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1249593202...
Checkpoint 1249593202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76409
Policy Entropy: 4.35750
Value Function Loss: 0.00254
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.91189
Value Function Update Magnitude: 0.71025
Collected Steps per Second: 12,986.82526
Overall Steps per Second: 7,234.19906
Timestep Collection Time: 3.85344
Timestep Consumption Time: 3.06425
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.91770
Cumulative Model Updates: 159,002
Cumulative Timesteps: 1,249,643,246
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.19622
Policy Entropy: 4.35637
Value Function Loss: 0.00243
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.91654
Value Function Update Magnitude: 0.71292
Collected Steps per Second: 13,253.69845
Overall Steps per Second: 7,263.16224
Timestep Collection Time: 3.77434
Timestep Consumption Time: 3.11302
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.88736
Cumulative Model Updates: 159,011
Cumulative Timesteps: 1,249,693,270
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1249693270...
Checkpoint 1249693270 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.68964
Policy Entropy: 4.35570
Value Function Loss: 0.00233
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02998
Policy Update Magnitude: 0.91212
Value Function Update Magnitude: 0.71198
Collected Steps per Second: 13,161.46269
Overall Steps per Second: 7,268.63411
Timestep Collection Time: 3.80064
Timestep Consumption Time: 3.08126
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.88190
Cumulative Model Updates: 159,020
Cumulative Timesteps: 1,249,743,292
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90456
Policy Entropy: 4.35735
Value Function Loss: 0.00228
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.89115
Value Function Update Magnitude: 0.69826
Collected Steps per Second: 13,504.83164
Overall Steps per Second: 7,347.44646
Timestep Collection Time: 3.70623
Timestep Consumption Time: 3.10593
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.81216
Cumulative Model Updates: 159,029
Cumulative Timesteps: 1,249,793,344
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1249793344...
Checkpoint 1249793344 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.84110
Policy Entropy: 4.35664
Value Function Loss: 0.00224
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02902
Policy Update Magnitude: 0.88238
Value Function Update Magnitude: 0.72594
Collected Steps per Second: 13,230.98920
Overall Steps per Second: 7,257.13151
Timestep Collection Time: 3.77991
Timestep Consumption Time: 3.11151
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.89143
Cumulative Model Updates: 159,038
Cumulative Timesteps: 1,249,843,356
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87843
Policy Entropy: 4.35718
Value Function Loss: 0.00228
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.88457
Value Function Update Magnitude: 0.68468
Collected Steps per Second: 13,244.58938
Overall Steps per Second: 7,293.16420
Timestep Collection Time: 3.77588
Timestep Consumption Time: 3.08122
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.85711
Cumulative Model Updates: 159,047
Cumulative Timesteps: 1,249,893,366
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1249893366...
Checkpoint 1249893366 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53212
Policy Entropy: 4.35248
Value Function Loss: 0.00245
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.90366
Value Function Update Magnitude: 0.65068
Collected Steps per Second: 13,527.87207
Overall Steps per Second: 7,158.06913
Timestep Collection Time: 3.69814
Timestep Consumption Time: 3.29089
PPO Batch Consumption Time: 0.24282
Total Iteration Time: 6.98904
Cumulative Model Updates: 159,056
Cumulative Timesteps: 1,249,943,394
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73135
Policy Entropy: 4.34781
Value Function Loss: 0.00252
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.92137
Value Function Update Magnitude: 0.67774
Collected Steps per Second: 10,500.38377
Overall Steps per Second: 6,060.48405
Timestep Collection Time: 4.76497
Timestep Consumption Time: 3.49081
PPO Batch Consumption Time: 0.25108
Total Iteration Time: 8.25578
Cumulative Model Updates: 159,065
Cumulative Timesteps: 1,249,993,428
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1249993428...
Checkpoint 1249993428 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33500
Policy Entropy: 4.34940
Value Function Loss: 0.00232
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02986
Policy Update Magnitude: 0.89567
Value Function Update Magnitude: 0.61479
Collected Steps per Second: 11,242.48343
Overall Steps per Second: 6,545.27640
Timestep Collection Time: 4.44937
Timestep Consumption Time: 3.19309
PPO Batch Consumption Time: 0.24633
Total Iteration Time: 7.64246
Cumulative Model Updates: 159,074
Cumulative Timesteps: 1,250,043,450
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02307
Policy Entropy: 4.35295
Value Function Loss: 0.00229
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02803
Policy Update Magnitude: 0.87125
Value Function Update Magnitude: 0.58749
Collected Steps per Second: 12,813.42813
Overall Steps per Second: 6,950.26059
Timestep Collection Time: 3.90278
Timestep Consumption Time: 3.29235
PPO Batch Consumption Time: 0.23544
Total Iteration Time: 7.19513
Cumulative Model Updates: 159,083
Cumulative Timesteps: 1,250,093,458
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1250093458...
Checkpoint 1250093458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89240
Policy Entropy: 4.35745
Value Function Loss: 0.00219
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.86061
Value Function Update Magnitude: 0.59535
Collected Steps per Second: 13,180.87335
Overall Steps per Second: 7,263.13014
Timestep Collection Time: 3.79535
Timestep Consumption Time: 3.09232
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.88766
Cumulative Model Updates: 159,092
Cumulative Timesteps: 1,250,143,484
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.04934
Policy Entropy: 4.35424
Value Function Loss: 0.00228
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.85214
Value Function Update Magnitude: 0.62951
Collected Steps per Second: 13,219.61142
Overall Steps per Second: 7,303.17013
Timestep Collection Time: 3.78438
Timestep Consumption Time: 3.06580
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.85018
Cumulative Model Updates: 159,101
Cumulative Timesteps: 1,250,193,512
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1250193512...
Checkpoint 1250193512 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46777
Policy Entropy: 4.35255
Value Function Loss: 0.00251
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.90367
Value Function Update Magnitude: 0.65772
Collected Steps per Second: 13,258.19490
Overall Steps per Second: 7,257.50981
Timestep Collection Time: 3.77201
Timestep Consumption Time: 3.11879
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.89079
Cumulative Model Updates: 159,110
Cumulative Timesteps: 1,250,243,522
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.63207
Policy Entropy: 4.34942
Value Function Loss: 0.00256
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 0.92659
Value Function Update Magnitude: 0.68302
Collected Steps per Second: 12,659.26057
Overall Steps per Second: 7,112.24728
Timestep Collection Time: 3.95047
Timestep Consumption Time: 3.08107
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 7.03153
Cumulative Model Updates: 159,119
Cumulative Timesteps: 1,250,293,532
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1250293532...
Checkpoint 1250293532 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.48957
Policy Entropy: 4.34950
Value Function Loss: 0.00262
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.93369
Value Function Update Magnitude: 0.65837
Collected Steps per Second: 13,457.03650
Overall Steps per Second: 7,254.25336
Timestep Collection Time: 3.71761
Timestep Consumption Time: 3.17876
PPO Batch Consumption Time: 0.23000
Total Iteration Time: 6.89637
Cumulative Model Updates: 159,128
Cumulative Timesteps: 1,250,343,560
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.37473
Policy Entropy: 4.35340
Value Function Loss: 0.00238
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02826
Policy Update Magnitude: 0.92092
Value Function Update Magnitude: 0.62176
Collected Steps per Second: 13,223.23876
Overall Steps per Second: 7,247.11917
Timestep Collection Time: 3.78122
Timestep Consumption Time: 3.11807
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.89929
Cumulative Model Updates: 159,137
Cumulative Timesteps: 1,250,393,560
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1250393560...
Checkpoint 1250393560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44767
Policy Entropy: 4.35350
Value Function Loss: 0.00235
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 0.88648
Value Function Update Magnitude: 0.59368
Collected Steps per Second: 13,099.50221
Overall Steps per Second: 7,251.52100
Timestep Collection Time: 3.81786
Timestep Consumption Time: 3.07891
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.89676
Cumulative Model Updates: 159,146
Cumulative Timesteps: 1,250,443,572
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74643
Policy Entropy: 4.35664
Value Function Loss: 0.00235
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.90571
Value Function Update Magnitude: 0.57606
Collected Steps per Second: 13,701.85695
Overall Steps per Second: 7,393.47029
Timestep Collection Time: 3.65177
Timestep Consumption Time: 3.11583
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.76759
Cumulative Model Updates: 159,155
Cumulative Timesteps: 1,250,493,608
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1250493608...
Checkpoint 1250493608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.66497
Policy Entropy: 4.35185
Value Function Loss: 0.00250
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02959
Policy Update Magnitude: 0.92652
Value Function Update Magnitude: 0.59516
Collected Steps per Second: 12,969.90762
Overall Steps per Second: 7,166.38001
Timestep Collection Time: 3.85631
Timestep Consumption Time: 3.12294
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.97926
Cumulative Model Updates: 159,164
Cumulative Timesteps: 1,250,543,624
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.79929
Policy Entropy: 4.35077
Value Function Loss: 0.00254
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02907
Policy Update Magnitude: 0.92825
Value Function Update Magnitude: 0.61332
Collected Steps per Second: 12,777.65764
Overall Steps per Second: 7,185.27487
Timestep Collection Time: 3.91465
Timestep Consumption Time: 3.04681
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.96146
Cumulative Model Updates: 159,173
Cumulative Timesteps: 1,250,593,644
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1250593644...
Checkpoint 1250593644 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44882
Policy Entropy: 4.34855
Value Function Loss: 0.00253
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02904
Policy Update Magnitude: 0.91885
Value Function Update Magnitude: 0.62645
Collected Steps per Second: 13,070.06671
Overall Steps per Second: 7,180.74287
Timestep Collection Time: 3.82569
Timestep Consumption Time: 3.13766
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.96335
Cumulative Model Updates: 159,182
Cumulative Timesteps: 1,250,643,646
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.13091
Policy Entropy: 4.34858
Value Function Loss: 0.00248
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02745
Policy Update Magnitude: 0.90394
Value Function Update Magnitude: 0.66764
Collected Steps per Second: 13,290.69784
Overall Steps per Second: 7,147.28417
Timestep Collection Time: 3.76203
Timestep Consumption Time: 3.23363
PPO Batch Consumption Time: 0.24075
Total Iteration Time: 6.99566
Cumulative Model Updates: 159,191
Cumulative Timesteps: 1,250,693,646
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1250693646...
Checkpoint 1250693646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.95815
Policy Entropy: 4.34790
Value Function Loss: 0.00254
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02791
Policy Update Magnitude: 0.92261
Value Function Update Magnitude: 0.64802
Collected Steps per Second: 13,456.79841
Overall Steps per Second: 7,411.78762
Timestep Collection Time: 3.71782
Timestep Consumption Time: 3.03224
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.75006
Cumulative Model Updates: 159,200
Cumulative Timesteps: 1,250,743,676
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.45821
Policy Entropy: 4.34850
Value Function Loss: 0.00244
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.92631
Value Function Update Magnitude: 0.68590
Collected Steps per Second: 13,182.00569
Overall Steps per Second: 7,226.55844
Timestep Collection Time: 3.79517
Timestep Consumption Time: 3.12762
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.92280
Cumulative Model Updates: 159,209
Cumulative Timesteps: 1,250,793,704
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1250793704...
Checkpoint 1250793704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88023
Policy Entropy: 4.34804
Value Function Loss: 0.00243
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.90523
Value Function Update Magnitude: 0.66564
Collected Steps per Second: 13,367.83340
Overall Steps per Second: 7,323.07388
Timestep Collection Time: 3.74152
Timestep Consumption Time: 3.08840
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.82992
Cumulative Model Updates: 159,218
Cumulative Timesteps: 1,250,843,720
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62806
Policy Entropy: 4.35182
Value Function Loss: 0.00231
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 0.87699
Value Function Update Magnitude: 0.64277
Collected Steps per Second: 13,675.22638
Overall Steps per Second: 7,387.34349
Timestep Collection Time: 3.65888
Timestep Consumption Time: 3.11433
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.77321
Cumulative Model Updates: 159,227
Cumulative Timesteps: 1,250,893,756
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1250893756...
Checkpoint 1250893756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53554
Policy Entropy: 4.35149
Value Function Loss: 0.00241
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.89428
Value Function Update Magnitude: 0.60982
Collected Steps per Second: 13,277.74060
Overall Steps per Second: 7,248.24307
Timestep Collection Time: 3.76721
Timestep Consumption Time: 3.13378
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.90098
Cumulative Model Updates: 159,236
Cumulative Timesteps: 1,250,943,776
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09707
Policy Entropy: 4.35314
Value Function Loss: 0.00244
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.90596
Value Function Update Magnitude: 0.59799
Collected Steps per Second: 13,303.26141
Overall Steps per Second: 7,373.25434
Timestep Collection Time: 3.75983
Timestep Consumption Time: 3.02388
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.78371
Cumulative Model Updates: 159,245
Cumulative Timesteps: 1,250,993,794
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1250993794...
Checkpoint 1250993794 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81857
Policy Entropy: 4.35274
Value Function Loss: 0.00243
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 0.90916
Value Function Update Magnitude: 0.62537
Collected Steps per Second: 13,231.46741
Overall Steps per Second: 7,105.59328
Timestep Collection Time: 3.78174
Timestep Consumption Time: 3.26032
PPO Batch Consumption Time: 0.24030
Total Iteration Time: 7.04206
Cumulative Model Updates: 159,254
Cumulative Timesteps: 1,251,043,832
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.06229
Policy Entropy: 4.35348
Value Function Loss: 0.00237
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.89437
Value Function Update Magnitude: 0.61032
Collected Steps per Second: 13,269.17371
Overall Steps per Second: 7,307.24491
Timestep Collection Time: 3.77024
Timestep Consumption Time: 3.07611
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.84636
Cumulative Model Updates: 159,263
Cumulative Timesteps: 1,251,093,860
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1251093860...
Checkpoint 1251093860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.67126
Policy Entropy: 4.35502
Value Function Loss: 0.00233
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.87734
Value Function Update Magnitude: 0.58341
Collected Steps per Second: 13,213.51236
Overall Steps per Second: 7,369.02125
Timestep Collection Time: 3.78416
Timestep Consumption Time: 3.00128
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.78543
Cumulative Model Updates: 159,272
Cumulative Timesteps: 1,251,143,862
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.51546
Policy Entropy: 4.35148
Value Function Loss: 0.00246
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.88662
Value Function Update Magnitude: 0.65554
Collected Steps per Second: 13,343.48253
Overall Steps per Second: 7,294.98854
Timestep Collection Time: 3.75045
Timestep Consumption Time: 3.10961
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.86005
Cumulative Model Updates: 159,281
Cumulative Timesteps: 1,251,193,906
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1251193906...
Checkpoint 1251193906 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61146
Policy Entropy: 4.35457
Value Function Loss: 0.00245
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.90473
Value Function Update Magnitude: 0.66890
Collected Steps per Second: 13,223.25928
Overall Steps per Second: 7,271.82094
Timestep Collection Time: 3.78485
Timestep Consumption Time: 3.09761
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.88246
Cumulative Model Updates: 159,290
Cumulative Timesteps: 1,251,243,954
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.99447
Policy Entropy: 4.35233
Value Function Loss: 0.00263
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 0.93201
Value Function Update Magnitude: 0.68785
Collected Steps per Second: 13,573.60251
Overall Steps per Second: 7,353.84419
Timestep Collection Time: 3.68406
Timestep Consumption Time: 3.11592
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.79998
Cumulative Model Updates: 159,299
Cumulative Timesteps: 1,251,293,960
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1251293960...
Checkpoint 1251293960 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25664
Policy Entropy: 4.35229
Value Function Loss: 0.00252
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02889
Policy Update Magnitude: 0.93954
Value Function Update Magnitude: 0.70111
Collected Steps per Second: 13,187.42262
Overall Steps per Second: 7,242.41763
Timestep Collection Time: 3.79240
Timestep Consumption Time: 3.11303
PPO Batch Consumption Time: 0.22782
Total Iteration Time: 6.90543
Cumulative Model Updates: 159,308
Cumulative Timesteps: 1,251,343,972
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16841
Policy Entropy: 4.35215
Value Function Loss: 0.00243
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02978
Policy Update Magnitude: 0.92321
Value Function Update Magnitude: 0.63974
Collected Steps per Second: 13,243.09757
Overall Steps per Second: 7,244.03139
Timestep Collection Time: 3.77600
Timestep Consumption Time: 3.12706
PPO Batch Consumption Time: 0.22942
Total Iteration Time: 6.90306
Cumulative Model Updates: 159,317
Cumulative Timesteps: 1,251,393,978
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1251393978...
Checkpoint 1251393978 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31512
Policy Entropy: 4.35056
Value Function Loss: 0.00244
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03023
Policy Update Magnitude: 0.91518
Value Function Update Magnitude: 0.64785
Collected Steps per Second: 13,667.54542
Overall Steps per Second: 7,369.81756
Timestep Collection Time: 3.66123
Timestep Consumption Time: 3.12863
PPO Batch Consumption Time: 0.22933
Total Iteration Time: 6.78986
Cumulative Model Updates: 159,326
Cumulative Timesteps: 1,251,444,018
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49725
Policy Entropy: 4.35296
Value Function Loss: 0.00244
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03070
Policy Update Magnitude: 0.92620
Value Function Update Magnitude: 0.71277
Collected Steps per Second: 13,334.69566
Overall Steps per Second: 7,275.09988
Timestep Collection Time: 3.75142
Timestep Consumption Time: 3.12464
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.87606
Cumulative Model Updates: 159,335
Cumulative Timesteps: 1,251,494,042
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1251494042...
Checkpoint 1251494042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81361
Policy Entropy: 4.35098
Value Function Loss: 0.00247
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02988
Policy Update Magnitude: 0.94254
Value Function Update Magnitude: 0.69438
Collected Steps per Second: 13,267.60463
Overall Steps per Second: 7,266.96037
Timestep Collection Time: 3.77144
Timestep Consumption Time: 3.11424
PPO Batch Consumption Time: 0.23670
Total Iteration Time: 6.88568
Cumulative Model Updates: 159,344
Cumulative Timesteps: 1,251,544,080
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.48035
Policy Entropy: 4.35346
Value Function Loss: 0.00250
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.95629
Value Function Update Magnitude: 0.66611
Collected Steps per Second: 13,229.93524
Overall Steps per Second: 7,255.92062
Timestep Collection Time: 3.78037
Timestep Consumption Time: 3.11249
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.89285
Cumulative Model Updates: 159,353
Cumulative Timesteps: 1,251,594,094
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1251594094...
Checkpoint 1251594094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76711
Policy Entropy: 4.35393
Value Function Loss: 0.00244
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03030
Policy Update Magnitude: 0.95324
Value Function Update Magnitude: 0.61902
Collected Steps per Second: 13,238.09779
Overall Steps per Second: 7,290.05312
Timestep Collection Time: 3.77834
Timestep Consumption Time: 3.08279
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.86113
Cumulative Model Updates: 159,362
Cumulative Timesteps: 1,251,644,112
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75717
Policy Entropy: 4.35291
Value Function Loss: 0.00251
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02885
Policy Update Magnitude: 0.95121
Value Function Update Magnitude: 0.64639
Collected Steps per Second: 13,209.36887
Overall Steps per Second: 7,350.05639
Timestep Collection Time: 3.78519
Timestep Consumption Time: 3.01748
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.80267
Cumulative Model Updates: 159,371
Cumulative Timesteps: 1,251,694,112
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1251694112...
Checkpoint 1251694112 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.86860
Policy Entropy: 4.35053
Value Function Loss: 0.00255
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02915
Policy Update Magnitude: 0.95782
Value Function Update Magnitude: 0.65684
Collected Steps per Second: 13,410.13573
Overall Steps per Second: 7,239.26123
Timestep Collection Time: 3.72912
Timestep Consumption Time: 3.17877
PPO Batch Consumption Time: 0.22981
Total Iteration Time: 6.90789
Cumulative Model Updates: 159,380
Cumulative Timesteps: 1,251,744,120
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.60133
Policy Entropy: 4.34931
Value Function Loss: 0.00260
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02980
Policy Update Magnitude: 0.97102
Value Function Update Magnitude: 0.66597
Collected Steps per Second: 13,170.61827
Overall Steps per Second: 7,247.46059
Timestep Collection Time: 3.79663
Timestep Consumption Time: 3.10289
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.89952
Cumulative Model Updates: 159,389
Cumulative Timesteps: 1,251,794,124
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1251794124...
Checkpoint 1251794124 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.94245
Policy Entropy: 4.35124
Value Function Loss: 0.00249
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.95619
Value Function Update Magnitude: 0.62996
Collected Steps per Second: 13,566.19583
Overall Steps per Second: 7,352.79719
Timestep Collection Time: 3.68681
Timestep Consumption Time: 3.11550
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.80231
Cumulative Model Updates: 159,398
Cumulative Timesteps: 1,251,844,140
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56426
Policy Entropy: 4.35126
Value Function Loss: 0.00243
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 0.94784
Value Function Update Magnitude: 0.63914
Collected Steps per Second: 13,127.14912
Overall Steps per Second: 7,216.33109
Timestep Collection Time: 3.80936
Timestep Consumption Time: 3.12020
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.92956
Cumulative Model Updates: 159,407
Cumulative Timesteps: 1,251,894,146
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1251894146...
Checkpoint 1251894146 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.00230
Policy Entropy: 4.34932
Value Function Loss: 0.00244
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03128
Policy Update Magnitude: 0.92798
Value Function Update Magnitude: 0.64521
Collected Steps per Second: 12,975.54539
Overall Steps per Second: 7,194.41214
Timestep Collection Time: 3.85479
Timestep Consumption Time: 3.09755
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.95234
Cumulative Model Updates: 159,416
Cumulative Timesteps: 1,251,944,164
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.53529
Policy Entropy: 4.34961
Value Function Loss: 0.00250
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03236
Policy Update Magnitude: 0.89958
Value Function Update Magnitude: 0.64419
Collected Steps per Second: 13,496.54726
Overall Steps per Second: 7,351.10416
Timestep Collection Time: 3.70465
Timestep Consumption Time: 3.09705
PPO Batch Consumption Time: 0.22947
Total Iteration Time: 6.80170
Cumulative Model Updates: 159,425
Cumulative Timesteps: 1,251,994,164
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1251994164...
Checkpoint 1251994164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93376
Policy Entropy: 4.35234
Value Function Loss: 0.00258
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03102
Policy Update Magnitude: 0.91866
Value Function Update Magnitude: 0.67177
Collected Steps per Second: 12,935.45569
Overall Steps per Second: 7,121.70315
Timestep Collection Time: 3.86782
Timestep Consumption Time: 3.15747
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 7.02529
Cumulative Model Updates: 159,434
Cumulative Timesteps: 1,252,044,196
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.35376
Policy Entropy: 4.35040
Value Function Loss: 0.00255
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03155
Policy Update Magnitude: 0.93486
Value Function Update Magnitude: 0.67205
Collected Steps per Second: 13,049.77726
Overall Steps per Second: 7,251.83290
Timestep Collection Time: 3.83194
Timestep Consumption Time: 3.06369
PPO Batch Consumption Time: 0.23306
Total Iteration Time: 6.89564
Cumulative Model Updates: 159,443
Cumulative Timesteps: 1,252,094,202
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1252094202...
Checkpoint 1252094202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.24655
Policy Entropy: 4.34906
Value Function Loss: 0.00272
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03249
Policy Update Magnitude: 0.94944
Value Function Update Magnitude: 0.66168
Collected Steps per Second: 13,150.87972
Overall Steps per Second: 7,222.12453
Timestep Collection Time: 3.80218
Timestep Consumption Time: 3.12127
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.92345
Cumulative Model Updates: 159,452
Cumulative Timesteps: 1,252,144,204
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.29918
Policy Entropy: 4.35550
Value Function Loss: 0.00246
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03163
Policy Update Magnitude: 0.94190
Value Function Update Magnitude: 0.63735
Collected Steps per Second: 13,154.19099
Overall Steps per Second: 7,248.23822
Timestep Collection Time: 3.80411
Timestep Consumption Time: 3.09964
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.90375
Cumulative Model Updates: 159,461
Cumulative Timesteps: 1,252,194,244
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1252194244...
Checkpoint 1252194244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.91451
Policy Entropy: 4.35596
Value Function Loss: 0.00232
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.92022
Value Function Update Magnitude: 0.64985
Collected Steps per Second: 13,251.05145
Overall Steps per Second: 7,339.03420
Timestep Collection Time: 3.77676
Timestep Consumption Time: 3.04240
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.81915
Cumulative Model Updates: 159,470
Cumulative Timesteps: 1,252,244,290
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.40158
Policy Entropy: 4.36166
Value Function Loss: 0.00214
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.90554
Value Function Update Magnitude: 0.65321
Collected Steps per Second: 13,279.80123
Overall Steps per Second: 7,256.01725
Timestep Collection Time: 3.76527
Timestep Consumption Time: 3.12584
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.89111
Cumulative Model Updates: 159,479
Cumulative Timesteps: 1,252,294,292
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1252294292...
Checkpoint 1252294292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.62450
Policy Entropy: 4.35672
Value Function Loss: 0.00237
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.93113
Value Function Update Magnitude: 0.63802
Collected Steps per Second: 13,189.82251
Overall Steps per Second: 7,248.57414
Timestep Collection Time: 3.79232
Timestep Consumption Time: 3.10835
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.90067
Cumulative Model Updates: 159,488
Cumulative Timesteps: 1,252,344,312
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09564
Policy Entropy: 4.35524
Value Function Loss: 0.00240
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.92924
Value Function Update Magnitude: 0.63362
Collected Steps per Second: 13,714.98942
Overall Steps per Second: 7,367.06102
Timestep Collection Time: 3.64696
Timestep Consumption Time: 3.14245
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.78941
Cumulative Model Updates: 159,497
Cumulative Timesteps: 1,252,394,330
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1252394330...
Checkpoint 1252394330 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80632
Policy Entropy: 4.35252
Value Function Loss: 0.00246
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.93733
Value Function Update Magnitude: 0.65183
Collected Steps per Second: 13,160.93341
Overall Steps per Second: 7,146.60294
Timestep Collection Time: 3.79927
Timestep Consumption Time: 3.19734
PPO Batch Consumption Time: 0.23052
Total Iteration Time: 6.99661
Cumulative Model Updates: 159,506
Cumulative Timesteps: 1,252,444,332
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22361
Policy Entropy: 4.35164
Value Function Loss: 0.00240
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02804
Policy Update Magnitude: 0.93621
Value Function Update Magnitude: 0.62428
Collected Steps per Second: 13,207.04676
Overall Steps per Second: 7,335.49368
Timestep Collection Time: 3.78707
Timestep Consumption Time: 3.03129
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.81835
Cumulative Model Updates: 159,515
Cumulative Timesteps: 1,252,494,348
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1252494348...
Checkpoint 1252494348 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99178
Policy Entropy: 4.35268
Value Function Loss: 0.00248
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.92061
Value Function Update Magnitude: 0.61476
Collected Steps per Second: 13,065.43772
Overall Steps per Second: 7,200.43148
Timestep Collection Time: 3.82965
Timestep Consumption Time: 3.11938
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.94903
Cumulative Model Updates: 159,524
Cumulative Timesteps: 1,252,544,384
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66130
Policy Entropy: 4.35448
Value Function Loss: 0.00237
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.89661
Value Function Update Magnitude: 0.63055
Collected Steps per Second: 12,894.82410
Overall Steps per Second: 7,197.88981
Timestep Collection Time: 3.88032
Timestep Consumption Time: 3.07117
PPO Batch Consumption Time: 0.22943
Total Iteration Time: 6.95148
Cumulative Model Updates: 159,533
Cumulative Timesteps: 1,252,594,420
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1252594420...
Checkpoint 1252594420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.68875
Policy Entropy: 4.35666
Value Function Loss: 0.00237
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.89334
Value Function Update Magnitude: 0.63019
Collected Steps per Second: 13,082.97726
Overall Steps per Second: 7,326.14548
Timestep Collection Time: 3.82466
Timestep Consumption Time: 3.00539
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.83006
Cumulative Model Updates: 159,542
Cumulative Timesteps: 1,252,644,458
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.74171
Policy Entropy: 4.35370
Value Function Loss: 0.00239
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.90035
Value Function Update Magnitude: 0.67629
Collected Steps per Second: 13,216.35535
Overall Steps per Second: 7,237.19721
Timestep Collection Time: 3.78561
Timestep Consumption Time: 3.12756
PPO Batch Consumption Time: 0.22936
Total Iteration Time: 6.91317
Cumulative Model Updates: 159,551
Cumulative Timesteps: 1,252,694,490
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1252694490...
Checkpoint 1252694490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.52970
Policy Entropy: 4.35411
Value Function Loss: 0.00259
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03019
Policy Update Magnitude: 0.93137
Value Function Update Magnitude: 0.64561
Collected Steps per Second: 13,120.30489
Overall Steps per Second: 7,248.62998
Timestep Collection Time: 3.81195
Timestep Consumption Time: 3.08783
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.89979
Cumulative Model Updates: 159,560
Cumulative Timesteps: 1,252,744,504
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.47478
Policy Entropy: 4.35324
Value Function Loss: 0.00272
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 0.94845
Value Function Update Magnitude: 0.68946
Collected Steps per Second: 13,444.16457
Overall Steps per Second: 7,196.07424
Timestep Collection Time: 3.72147
Timestep Consumption Time: 3.23121
PPO Batch Consumption Time: 0.23520
Total Iteration Time: 6.95268
Cumulative Model Updates: 159,569
Cumulative Timesteps: 1,252,794,536
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1252794536...
Checkpoint 1252794536 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85635
Policy Entropy: 4.35272
Value Function Loss: 0.00260
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.93654
Value Function Update Magnitude: 0.66708
Collected Steps per Second: 13,183.68490
Overall Steps per Second: 7,218.10141
Timestep Collection Time: 3.79424
Timestep Consumption Time: 3.13584
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.93008
Cumulative Model Updates: 159,578
Cumulative Timesteps: 1,252,844,558
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.03130
Policy Entropy: 4.35641
Value Function Loss: 0.00238
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03060
Policy Update Magnitude: 0.91640
Value Function Update Magnitude: 0.60342
Collected Steps per Second: 13,198.13842
Overall Steps per Second: 7,236.36827
Timestep Collection Time: 3.78856
Timestep Consumption Time: 3.12126
PPO Batch Consumption Time: 0.22930
Total Iteration Time: 6.90982
Cumulative Model Updates: 159,587
Cumulative Timesteps: 1,252,894,560
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1252894560...
Checkpoint 1252894560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02837
Policy Entropy: 4.35916
Value Function Loss: 0.00232
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03026
Policy Update Magnitude: 0.90461
Value Function Update Magnitude: 0.60267
Collected Steps per Second: 13,439.36099
Overall Steps per Second: 7,322.34310
Timestep Collection Time: 3.72146
Timestep Consumption Time: 3.10887
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.83033
Cumulative Model Updates: 159,596
Cumulative Timesteps: 1,252,944,574
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54606
Policy Entropy: 4.35857
Value Function Loss: 0.00239
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.91101
Value Function Update Magnitude: 0.58669
Collected Steps per Second: 13,268.06864
Overall Steps per Second: 7,263.04065
Timestep Collection Time: 3.76890
Timestep Consumption Time: 3.11610
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.88500
Cumulative Model Updates: 159,605
Cumulative Timesteps: 1,252,994,580
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1252994580...
Checkpoint 1252994580 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02636
Policy Entropy: 4.35831
Value Function Loss: 0.00247
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 0.90770
Value Function Update Magnitude: 0.61569
Collected Steps per Second: 13,172.81149
Overall Steps per Second: 7,336.32565
Timestep Collection Time: 3.79722
Timestep Consumption Time: 3.02091
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.81813
Cumulative Model Updates: 159,614
Cumulative Timesteps: 1,253,044,600
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33073
Policy Entropy: 4.35768
Value Function Loss: 0.00248
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.91561
Value Function Update Magnitude: 0.66691
Collected Steps per Second: 13,229.97805
Overall Steps per Second: 7,246.09413
Timestep Collection Time: 3.78232
Timestep Consumption Time: 3.12347
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.90579
Cumulative Model Updates: 159,623
Cumulative Timesteps: 1,253,094,640
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1253094640...
Checkpoint 1253094640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85439
Policy Entropy: 4.35978
Value Function Loss: 0.00219
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02732
Policy Update Magnitude: 0.89755
Value Function Update Magnitude: 0.66043
Collected Steps per Second: 13,096.12646
Overall Steps per Second: 7,074.87617
Timestep Collection Time: 3.81960
Timestep Consumption Time: 3.25077
PPO Batch Consumption Time: 0.24177
Total Iteration Time: 7.07037
Cumulative Model Updates: 159,632
Cumulative Timesteps: 1,253,144,662
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45473
Policy Entropy: 4.35946
Value Function Loss: 0.00223
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.88958
Value Function Update Magnitude: 0.62422
Collected Steps per Second: 13,575.41926
Overall Steps per Second: 7,365.08210
Timestep Collection Time: 3.68490
Timestep Consumption Time: 3.10715
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.79205
Cumulative Model Updates: 159,641
Cumulative Timesteps: 1,253,194,686
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1253194686...
Checkpoint 1253194686 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.55344
Policy Entropy: 4.36017
Value Function Loss: 0.00226
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.91222
Value Function Update Magnitude: 0.65244
Collected Steps per Second: 13,145.72099
Overall Steps per Second: 7,231.79919
Timestep Collection Time: 3.80489
Timestep Consumption Time: 3.11151
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.91640
Cumulative Model Updates: 159,650
Cumulative Timesteps: 1,253,244,704
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.45946
Policy Entropy: 4.35573
Value Function Loss: 0.00250
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.93483
Value Function Update Magnitude: 0.63240
Collected Steps per Second: 13,157.02063
Overall Steps per Second: 7,260.30343
Timestep Collection Time: 3.80238
Timestep Consumption Time: 3.08824
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.89062
Cumulative Model Updates: 159,659
Cumulative Timesteps: 1,253,294,732
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1253294732...
Checkpoint 1253294732 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02430
Policy Entropy: 4.35584
Value Function Loss: 0.00240
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.94942
Value Function Update Magnitude: 0.63148
Collected Steps per Second: 13,455.31948
Overall Steps per Second: 7,296.92927
Timestep Collection Time: 3.71883
Timestep Consumption Time: 3.13858
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.85741
Cumulative Model Updates: 159,668
Cumulative Timesteps: 1,253,344,770
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.58732
Policy Entropy: 4.35927
Value Function Loss: 0.00224
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.91433
Value Function Update Magnitude: 0.61510
Collected Steps per Second: 13,214.00310
Overall Steps per Second: 7,234.49733
Timestep Collection Time: 3.78523
Timestep Consumption Time: 3.12859
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.91382
Cumulative Model Updates: 159,677
Cumulative Timesteps: 1,253,394,788
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1253394788...
Checkpoint 1253394788 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.93479
Policy Entropy: 4.36223
Value Function Loss: 0.00200
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.87249
Value Function Update Magnitude: 0.56318
Collected Steps per Second: 13,157.65910
Overall Steps per Second: 7,345.57846
Timestep Collection Time: 3.80265
Timestep Consumption Time: 3.00879
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.81144
Cumulative Model Updates: 159,686
Cumulative Timesteps: 1,253,444,822
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.36810
Policy Entropy: 4.36131
Value Function Loss: 0.00203
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02425
Policy Update Magnitude: 0.88421
Value Function Update Magnitude: 0.53051
Collected Steps per Second: 13,241.57941
Overall Steps per Second: 7,165.63650
Timestep Collection Time: 3.77750
Timestep Consumption Time: 3.20304
PPO Batch Consumption Time: 0.23415
Total Iteration Time: 6.98054
Cumulative Model Updates: 159,695
Cumulative Timesteps: 1,253,494,842
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1253494842...
Checkpoint 1253494842 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02719
Policy Entropy: 4.35956
Value Function Loss: 0.00228
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.90439
Value Function Update Magnitude: 0.64106
Collected Steps per Second: 13,116.28027
Overall Steps per Second: 7,250.58562
Timestep Collection Time: 3.81282
Timestep Consumption Time: 3.08456
PPO Batch Consumption Time: 0.22923
Total Iteration Time: 6.89737
Cumulative Model Updates: 159,704
Cumulative Timesteps: 1,253,544,852
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77608
Policy Entropy: 4.35874
Value Function Loss: 0.00238
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02785
Policy Update Magnitude: 0.91753
Value Function Update Magnitude: 0.65822
Collected Steps per Second: 13,279.07342
Overall Steps per Second: 7,382.30865
Timestep Collection Time: 3.76698
Timestep Consumption Time: 3.00895
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.77593
Cumulative Model Updates: 159,713
Cumulative Timesteps: 1,253,594,874
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1253594874...
Checkpoint 1253594874 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.95418
Policy Entropy: 4.36114
Value Function Loss: 0.00241
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03002
Policy Update Magnitude: 0.92522
Value Function Update Magnitude: 0.60502
Collected Steps per Second: 13,159.31948
Overall Steps per Second: 7,226.13050
Timestep Collection Time: 3.80217
Timestep Consumption Time: 3.12187
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.92404
Cumulative Model Updates: 159,722
Cumulative Timesteps: 1,253,644,908
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.92277
Policy Entropy: 4.36458
Value Function Loss: 0.00229
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03078
Policy Update Magnitude: 0.91663
Value Function Update Magnitude: 0.59118
Collected Steps per Second: 13,117.69624
Overall Steps per Second: 7,241.38149
Timestep Collection Time: 3.81210
Timestep Consumption Time: 3.09349
PPO Batch Consumption Time: 0.22936
Total Iteration Time: 6.90559
Cumulative Model Updates: 159,731
Cumulative Timesteps: 1,253,694,914
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1253694914...
Checkpoint 1253694914 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64481
Policy Entropy: 4.36555
Value Function Loss: 0.00248
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03109
Policy Update Magnitude: 0.94196
Value Function Update Magnitude: 0.63582
Collected Steps per Second: 13,187.74937
Overall Steps per Second: 7,333.95368
Timestep Collection Time: 3.79140
Timestep Consumption Time: 3.02621
PPO Batch Consumption Time: 0.22954
Total Iteration Time: 6.81761
Cumulative Model Updates: 159,740
Cumulative Timesteps: 1,253,744,914
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66315
Policy Entropy: 4.36340
Value Function Loss: 0.00244
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 0.94836
Value Function Update Magnitude: 0.67177
Collected Steps per Second: 13,104.16143
Overall Steps per Second: 7,202.89003
Timestep Collection Time: 3.81879
Timestep Consumption Time: 3.12870
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.94749
Cumulative Model Updates: 159,749
Cumulative Timesteps: 1,253,794,956
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1253794956...
Checkpoint 1253794956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17737
Policy Entropy: 4.36123
Value Function Loss: 0.00246
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02896
Policy Update Magnitude: 0.93486
Value Function Update Magnitude: 0.65412
Collected Steps per Second: 12,989.22690
Overall Steps per Second: 7,057.98694
Timestep Collection Time: 3.85227
Timestep Consumption Time: 3.23729
PPO Batch Consumption Time: 0.24121
Total Iteration Time: 7.08956
Cumulative Model Updates: 159,758
Cumulative Timesteps: 1,253,844,994
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.66186
Policy Entropy: 4.35991
Value Function Loss: 0.00237
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.92463
Value Function Update Magnitude: 0.64096
Collected Steps per Second: 13,583.62040
Overall Steps per Second: 7,353.13273
Timestep Collection Time: 3.68414
Timestep Consumption Time: 3.12166
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.80581
Cumulative Model Updates: 159,767
Cumulative Timesteps: 1,253,895,038
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1253895038...
Checkpoint 1253895038 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.69772
Policy Entropy: 4.36014
Value Function Loss: 0.00255
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 0.93700
Value Function Update Magnitude: 0.67932
Collected Steps per Second: 13,129.14799
Overall Steps per Second: 7,208.50084
Timestep Collection Time: 3.80954
Timestep Consumption Time: 3.12894
PPO Batch Consumption Time: 0.22960
Total Iteration Time: 6.93847
Cumulative Model Updates: 159,776
Cumulative Timesteps: 1,253,945,054
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87237
Policy Entropy: 4.36144
Value Function Loss: 0.00234
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.92113
Value Function Update Magnitude: 0.67592
Collected Steps per Second: 13,132.47955
Overall Steps per Second: 7,308.71098
Timestep Collection Time: 3.81025
Timestep Consumption Time: 3.03610
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.84635
Cumulative Model Updates: 159,785
Cumulative Timesteps: 1,253,995,092
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1253995092...
Checkpoint 1253995092 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.79001
Policy Entropy: 4.36484
Value Function Loss: 0.00226
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.88620
Value Function Update Magnitude: 0.66554
Collected Steps per Second: 13,374.33692
Overall Steps per Second: 7,274.60844
Timestep Collection Time: 3.74075
Timestep Consumption Time: 3.13660
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.87735
Cumulative Model Updates: 159,794
Cumulative Timesteps: 1,254,045,122
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33666
Policy Entropy: 4.36512
Value Function Loss: 0.00215
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.87143
Value Function Update Magnitude: 0.64069
Collected Steps per Second: 13,303.69613
Overall Steps per Second: 7,307.31206
Timestep Collection Time: 3.75865
Timestep Consumption Time: 3.08435
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.84301
Cumulative Model Updates: 159,803
Cumulative Timesteps: 1,254,095,126
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1254095126...
Checkpoint 1254095126 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87051
Policy Entropy: 4.36290
Value Function Loss: 0.00223
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.88861
Value Function Update Magnitude: 0.62036
Collected Steps per Second: 13,459.31937
Overall Steps per Second: 7,313.96115
Timestep Collection Time: 3.71505
Timestep Consumption Time: 3.12147
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.83651
Cumulative Model Updates: 159,812
Cumulative Timesteps: 1,254,145,128
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14280
Policy Entropy: 4.36286
Value Function Loss: 0.00223
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.90415
Value Function Update Magnitude: 0.62253
Collected Steps per Second: 13,305.07286
Overall Steps per Second: 7,207.84478
Timestep Collection Time: 3.76007
Timestep Consumption Time: 3.18070
PPO Batch Consumption Time: 0.23063
Total Iteration Time: 6.94077
Cumulative Model Updates: 159,821
Cumulative Timesteps: 1,254,195,156
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1254195156...
Checkpoint 1254195156 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.52681
Policy Entropy: 4.35736
Value Function Loss: 0.00244
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02856
Policy Update Magnitude: 0.93242
Value Function Update Magnitude: 0.63412
Collected Steps per Second: 13,386.01310
Overall Steps per Second: 7,314.91097
Timestep Collection Time: 3.73644
Timestep Consumption Time: 3.10110
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.83754
Cumulative Model Updates: 159,830
Cumulative Timesteps: 1,254,245,172
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.86805
Policy Entropy: 4.35638
Value Function Loss: 0.00258
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 0.95916
Value Function Update Magnitude: 0.63662
Collected Steps per Second: 13,613.27291
Overall Steps per Second: 7,359.19257
Timestep Collection Time: 3.67347
Timestep Consumption Time: 3.12184
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.79531
Cumulative Model Updates: 159,839
Cumulative Timesteps: 1,254,295,180
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1254295180...
Checkpoint 1254295180 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41140
Policy Entropy: 4.35086
Value Function Loss: 0.00279
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03487
Policy Update Magnitude: 0.95722
Value Function Update Magnitude: 0.68503
Collected Steps per Second: 13,140.66624
Overall Steps per Second: 7,224.04672
Timestep Collection Time: 3.80803
Timestep Consumption Time: 3.11884
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.92687
Cumulative Model Updates: 159,848
Cumulative Timesteps: 1,254,345,220
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.32886
Policy Entropy: 4.35311
Value Function Loss: 0.00286
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03197
Policy Update Magnitude: 0.98362
Value Function Update Magnitude: 0.68111
Collected Steps per Second: 13,250.71652
Overall Steps per Second: 7,353.16495
Timestep Collection Time: 3.77444
Timestep Consumption Time: 3.02726
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.80170
Cumulative Model Updates: 159,857
Cumulative Timesteps: 1,254,395,234
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1254395234...
Checkpoint 1254395234 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.83274
Policy Entropy: 4.35106
Value Function Loss: 0.00276
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03308
Policy Update Magnitude: 0.97869
Value Function Update Magnitude: 0.66728
Collected Steps per Second: 13,194.78841
Overall Steps per Second: 7,249.81038
Timestep Collection Time: 3.78937
Timestep Consumption Time: 3.10736
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.89673
Cumulative Model Updates: 159,866
Cumulative Timesteps: 1,254,445,234
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44292
Policy Entropy: 4.35447
Value Function Loss: 0.00261
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03119
Policy Update Magnitude: 0.95870
Value Function Update Magnitude: 0.66340
Collected Steps per Second: 13,332.51164
Overall Steps per Second: 7,312.83600
Timestep Collection Time: 3.75158
Timestep Consumption Time: 3.08817
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.83975
Cumulative Model Updates: 159,875
Cumulative Timesteps: 1,254,495,252
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1254495252...
Checkpoint 1254495252 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82583
Policy Entropy: 4.35510
Value Function Loss: 0.00234
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02933
Policy Update Magnitude: 0.91858
Value Function Update Magnitude: 0.62148
Collected Steps per Second: 13,634.36764
Overall Steps per Second: 7,310.24233
Timestep Collection Time: 3.66779
Timestep Consumption Time: 3.17302
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.84081
Cumulative Model Updates: 159,884
Cumulative Timesteps: 1,254,545,260
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.19079
Policy Entropy: 4.35682
Value Function Loss: 0.00227
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02818
Policy Update Magnitude: 0.89521
Value Function Update Magnitude: 0.56365
Collected Steps per Second: 13,295.41067
Overall Steps per Second: 7,247.83042
Timestep Collection Time: 3.76355
Timestep Consumption Time: 3.14030
PPO Batch Consumption Time: 0.22929
Total Iteration Time: 6.90386
Cumulative Model Updates: 159,893
Cumulative Timesteps: 1,254,595,298
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1254595298...
Checkpoint 1254595298 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51162
Policy Entropy: 4.35852
Value Function Loss: 0.00219
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02889
Policy Update Magnitude: 0.87657
Value Function Update Magnitude: 0.57609
Collected Steps per Second: 13,217.30904
Overall Steps per Second: 7,252.11162
Timestep Collection Time: 3.78489
Timestep Consumption Time: 3.11324
PPO Batch Consumption Time: 0.22918
Total Iteration Time: 6.89813
Cumulative Model Updates: 159,902
Cumulative Timesteps: 1,254,645,324
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.26200
Policy Entropy: 4.35932
Value Function Loss: 0.00216
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.87182
Value Function Update Magnitude: 0.64804
Collected Steps per Second: 13,509.83753
Overall Steps per Second: 7,319.83344
Timestep Collection Time: 3.70189
Timestep Consumption Time: 3.13050
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.83240
Cumulative Model Updates: 159,911
Cumulative Timesteps: 1,254,695,336
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1254695336...
Checkpoint 1254695336 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97532
Policy Entropy: 4.35545
Value Function Loss: 0.00247
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.91232
Value Function Update Magnitude: 0.67588
Collected Steps per Second: 13,111.97547
Overall Steps per Second: 7,180.33958
Timestep Collection Time: 3.81743
Timestep Consumption Time: 3.15355
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.97098
Cumulative Model Updates: 159,920
Cumulative Timesteps: 1,254,745,390
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.39670
Policy Entropy: 4.35284
Value Function Loss: 0.00250
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03038
Policy Update Magnitude: 0.93513
Value Function Update Magnitude: 0.64654
Collected Steps per Second: 12,821.59867
Overall Steps per Second: 7,205.78075
Timestep Collection Time: 3.89983
Timestep Consumption Time: 3.03933
PPO Batch Consumption Time: 0.23016
Total Iteration Time: 6.93915
Cumulative Model Updates: 159,929
Cumulative Timesteps: 1,254,795,392
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1254795392...
Checkpoint 1254795392 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22243
Policy Entropy: 4.35065
Value Function Loss: 0.00271
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03251
Policy Update Magnitude: 0.93874
Value Function Update Magnitude: 0.63192
Collected Steps per Second: 13,318.02391
Overall Steps per Second: 7,258.67460
Timestep Collection Time: 3.75716
Timestep Consumption Time: 3.13638
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.89354
Cumulative Model Updates: 159,938
Cumulative Timesteps: 1,254,845,430
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.12868
Policy Entropy: 4.35148
Value Function Loss: 0.00268
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 0.94076
Value Function Update Magnitude: 0.61724
Collected Steps per Second: 13,251.89434
Overall Steps per Second: 7,127.82973
Timestep Collection Time: 3.77320
Timestep Consumption Time: 3.24184
PPO Batch Consumption Time: 0.24037
Total Iteration Time: 7.01504
Cumulative Model Updates: 159,947
Cumulative Timesteps: 1,254,895,432
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1254895432...
Checkpoint 1254895432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.74436
Policy Entropy: 4.35015
Value Function Loss: 0.00274
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 0.94540
Value Function Update Magnitude: 0.63362
Collected Steps per Second: 13,242.74353
Overall Steps per Second: 7,368.33247
Timestep Collection Time: 3.77580
Timestep Consumption Time: 3.01026
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.78607
Cumulative Model Updates: 159,956
Cumulative Timesteps: 1,254,945,434
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50441
Policy Entropy: 4.35174
Value Function Loss: 0.00277
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03036
Policy Update Magnitude: 0.96283
Value Function Update Magnitude: 0.68974
Collected Steps per Second: 13,086.47192
Overall Steps per Second: 7,232.15577
Timestep Collection Time: 3.82288
Timestep Consumption Time: 3.09456
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.91744
Cumulative Model Updates: 159,965
Cumulative Timesteps: 1,254,995,462
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1254995462...
Checkpoint 1254995462 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.44747
Policy Entropy: 4.35262
Value Function Loss: 0.00259
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02943
Policy Update Magnitude: 0.95315
Value Function Update Magnitude: 0.72894
Collected Steps per Second: 13,107.59119
Overall Steps per Second: 7,258.70578
Timestep Collection Time: 3.81657
Timestep Consumption Time: 3.07530
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.89186
Cumulative Model Updates: 159,974
Cumulative Timesteps: 1,255,045,488
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.78510
Policy Entropy: 4.34838
Value Function Loss: 0.00280
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03278
Policy Update Magnitude: 0.95974
Value Function Update Magnitude: 0.70122
Collected Steps per Second: 13,599.97958
Overall Steps per Second: 7,363.01072
Timestep Collection Time: 3.67795
Timestep Consumption Time: 3.11547
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.79342
Cumulative Model Updates: 159,983
Cumulative Timesteps: 1,255,095,508
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1255095508...
Checkpoint 1255095508 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17985
Policy Entropy: 4.34564
Value Function Loss: 0.00271
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 0.94958
Value Function Update Magnitude: 0.66046
Collected Steps per Second: 13,196.95895
Overall Steps per Second: 7,255.01956
Timestep Collection Time: 3.79072
Timestep Consumption Time: 3.10464
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.89536
Cumulative Model Updates: 159,992
Cumulative Timesteps: 1,255,145,534
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65842
Policy Entropy: 4.35063
Value Function Loss: 0.00254
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02986
Policy Update Magnitude: 0.92898
Value Function Update Magnitude: 0.66421
Collected Steps per Second: 13,187.83369
Overall Steps per Second: 7,326.96076
Timestep Collection Time: 3.79259
Timestep Consumption Time: 3.03371
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.82630
Cumulative Model Updates: 160,001
Cumulative Timesteps: 1,255,195,550
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1255195550...
Checkpoint 1255195550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.05073
Policy Entropy: 4.35236
Value Function Loss: 0.00236
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02837
Policy Update Magnitude: 0.91233
Value Function Update Magnitude: 0.61512
Collected Steps per Second: 13,037.32672
Overall Steps per Second: 7,047.19222
Timestep Collection Time: 3.83637
Timestep Consumption Time: 3.26093
PPO Batch Consumption Time: 0.23995
Total Iteration Time: 7.09729
Cumulative Model Updates: 160,010
Cumulative Timesteps: 1,255,245,566
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57923
Policy Entropy: 4.35525
Value Function Loss: 0.00221
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.87609
Value Function Update Magnitude: 0.61338
Collected Steps per Second: 13,330.57658
Overall Steps per Second: 7,301.03153
Timestep Collection Time: 3.75273
Timestep Consumption Time: 3.09918
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 6.85191
Cumulative Model Updates: 160,019
Cumulative Timesteps: 1,255,295,592
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1255295592...
Checkpoint 1255295592 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42615
Policy Entropy: 4.35348
Value Function Loss: 0.00230
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.86431
Value Function Update Magnitude: 0.59650
Collected Steps per Second: 13,504.16873
Overall Steps per Second: 7,313.58869
Timestep Collection Time: 3.70419
Timestep Consumption Time: 3.13541
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.83960
Cumulative Model Updates: 160,028
Cumulative Timesteps: 1,255,345,614
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.13490
Policy Entropy: 4.35813
Value Function Loss: 0.00210
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.86037
Value Function Update Magnitude: 0.59978
Collected Steps per Second: 13,194.56207
Overall Steps per Second: 7,228.75918
Timestep Collection Time: 3.79217
Timestep Consumption Time: 3.12963
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.92180
Cumulative Model Updates: 160,037
Cumulative Timesteps: 1,255,395,650
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1255395650...
Checkpoint 1255395650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88749
Policy Entropy: 4.34989
Value Function Loss: 0.00241
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02910
Policy Update Magnitude: 0.88939
Value Function Update Magnitude: 0.66502
Collected Steps per Second: 13,171.59670
Overall Steps per Second: 7,225.05606
Timestep Collection Time: 3.79681
Timestep Consumption Time: 3.12494
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.92175
Cumulative Model Updates: 160,046
Cumulative Timesteps: 1,255,445,660
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89181
Policy Entropy: 4.34952
Value Function Loss: 0.00247
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.91476
Value Function Update Magnitude: 0.64330
Collected Steps per Second: 13,586.95025
Overall Steps per Second: 7,345.59266
Timestep Collection Time: 3.68162
Timestep Consumption Time: 3.12818
PPO Batch Consumption Time: 0.22946
Total Iteration Time: 6.80980
Cumulative Model Updates: 160,055
Cumulative Timesteps: 1,255,495,682
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1255495682...
Checkpoint 1255495682 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.42860
Policy Entropy: 4.34352
Value Function Loss: 0.00250
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02914
Policy Update Magnitude: 0.89359
Value Function Update Magnitude: 0.62628
Collected Steps per Second: 13,298.86519
Overall Steps per Second: 7,244.12587
Timestep Collection Time: 3.76092
Timestep Consumption Time: 3.14343
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.90435
Cumulative Model Updates: 160,064
Cumulative Timesteps: 1,255,545,698
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86073
Policy Entropy: 4.34723
Value Function Loss: 0.00238
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02780
Policy Update Magnitude: 0.89341
Value Function Update Magnitude: 0.58799
Collected Steps per Second: 13,285.97093
Overall Steps per Second: 7,294.24030
Timestep Collection Time: 3.76397
Timestep Consumption Time: 3.09185
PPO Batch Consumption Time: 0.23010
Total Iteration Time: 6.85582
Cumulative Model Updates: 160,073
Cumulative Timesteps: 1,255,595,706
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1255595706...
Checkpoint 1255595706 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42894
Policy Entropy: 4.34440
Value Function Loss: 0.00237
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03078
Policy Update Magnitude: 0.89678
Value Function Update Magnitude: 0.57242
Collected Steps per Second: 13,164.63803
Overall Steps per Second: 7,242.51030
Timestep Collection Time: 3.79851
Timestep Consumption Time: 3.10600
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.90451
Cumulative Model Updates: 160,082
Cumulative Timesteps: 1,255,645,712
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32811
Policy Entropy: 4.34549
Value Function Loss: 0.00255
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 0.90071
Value Function Update Magnitude: 0.59353
Collected Steps per Second: 13,105.09551
Overall Steps per Second: 7,243.30894
Timestep Collection Time: 3.81836
Timestep Consumption Time: 3.09008
PPO Batch Consumption Time: 0.22936
Total Iteration Time: 6.90844
Cumulative Model Updates: 160,091
Cumulative Timesteps: 1,255,695,752
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1255695752...
Checkpoint 1255695752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.26808
Policy Entropy: 4.35069
Value Function Loss: 0.00236
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02886
Policy Update Magnitude: 0.87165
Value Function Update Magnitude: 0.60917
Collected Steps per Second: 13,581.55930
Overall Steps per Second: 7,347.98023
Timestep Collection Time: 3.68220
Timestep Consumption Time: 3.12375
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.80595
Cumulative Model Updates: 160,100
Cumulative Timesteps: 1,255,745,762
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37789
Policy Entropy: 4.35359
Value Function Loss: 0.00221
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.84551
Value Function Update Magnitude: 0.57138
Collected Steps per Second: 13,261.59487
Overall Steps per Second: 7,250.29723
Timestep Collection Time: 3.77179
Timestep Consumption Time: 3.12723
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.89903
Cumulative Model Updates: 160,109
Cumulative Timesteps: 1,255,795,782
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1255795782...
Checkpoint 1255795782 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54532
Policy Entropy: 4.35764
Value Function Loss: 0.00202
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.83677
Value Function Update Magnitude: 0.55649
Collected Steps per Second: 13,224.96901
Overall Steps per Second: 7,280.18327
Timestep Collection Time: 3.78179
Timestep Consumption Time: 3.08810
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.86988
Cumulative Model Updates: 160,118
Cumulative Timesteps: 1,255,845,796
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.92376
Policy Entropy: 4.35516
Value Function Loss: 0.00233
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.86223
Value Function Update Magnitude: 0.55704
Collected Steps per Second: 13,527.65625
Overall Steps per Second: 7,356.37879
Timestep Collection Time: 3.69983
Timestep Consumption Time: 3.10379
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.80362
Cumulative Model Updates: 160,127
Cumulative Timesteps: 1,255,895,846
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1255895846...
Checkpoint 1255895846 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.56314
Policy Entropy: 4.35211
Value Function Loss: 0.00241
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.89529
Value Function Update Magnitude: 0.56406
Collected Steps per Second: 13,115.27423
Overall Steps per Second: 7,142.42695
Timestep Collection Time: 3.81494
Timestep Consumption Time: 3.19024
PPO Batch Consumption Time: 0.23543
Total Iteration Time: 7.00518
Cumulative Model Updates: 160,136
Cumulative Timesteps: 1,255,945,880
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.24575
Policy Entropy: 4.35305
Value Function Loss: 0.00230
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02690
Policy Update Magnitude: 0.87377
Value Function Update Magnitude: 0.58624
Collected Steps per Second: 13,075.09562
Overall Steps per Second: 7,317.73858
Timestep Collection Time: 3.82452
Timestep Consumption Time: 3.00901
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.83353
Cumulative Model Updates: 160,145
Cumulative Timesteps: 1,255,995,886
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1255995886...
Checkpoint 1255995886 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09469
Policy Entropy: 4.35478
Value Function Loss: 0.00214
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02503
Policy Update Magnitude: 0.85678
Value Function Update Magnitude: 0.62290
Collected Steps per Second: 13,323.66899
Overall Steps per Second: 7,247.19756
Timestep Collection Time: 3.75497
Timestep Consumption Time: 3.14839
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.90336
Cumulative Model Updates: 160,154
Cumulative Timesteps: 1,256,045,916
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.07441
Policy Entropy: 4.35348
Value Function Loss: 0.00218
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.86356
Value Function Update Magnitude: 0.60331
Collected Steps per Second: 13,233.65469
Overall Steps per Second: 7,281.62235
Timestep Collection Time: 3.77885
Timestep Consumption Time: 3.08885
PPO Batch Consumption Time: 0.22942
Total Iteration Time: 6.86770
Cumulative Model Updates: 160,163
Cumulative Timesteps: 1,256,095,924
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1256095924...
Checkpoint 1256095924 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90898
Policy Entropy: 4.35341
Value Function Loss: 0.00229
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.87622
Value Function Update Magnitude: 0.62429
Collected Steps per Second: 13,035.81108
Overall Steps per Second: 7,307.04077
Timestep Collection Time: 3.83651
Timestep Consumption Time: 3.00785
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.84436
Cumulative Model Updates: 160,172
Cumulative Timesteps: 1,256,145,936
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44400
Policy Entropy: 4.35360
Value Function Loss: 0.00240
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.90285
Value Function Update Magnitude: 0.62688
Collected Steps per Second: 13,271.15442
Overall Steps per Second: 7,256.16048
Timestep Collection Time: 3.76998
Timestep Consumption Time: 3.12513
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.89511
Cumulative Model Updates: 160,181
Cumulative Timesteps: 1,256,195,968
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1256195968...
Checkpoint 1256195968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61669
Policy Entropy: 4.35709
Value Function Loss: 0.00246
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.91778
Value Function Update Magnitude: 0.64675
Collected Steps per Second: 13,349.93833
Overall Steps per Second: 7,318.97584
Timestep Collection Time: 3.74698
Timestep Consumption Time: 3.08758
PPO Batch Consumption Time: 0.22926
Total Iteration Time: 6.83456
Cumulative Model Updates: 160,190
Cumulative Timesteps: 1,256,245,990
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45078
Policy Entropy: 4.35590
Value Function Loss: 0.00247
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.91671
Value Function Update Magnitude: 0.61112
Collected Steps per Second: 13,652.85422
Overall Steps per Second: 7,317.84766
Timestep Collection Time: 3.66487
Timestep Consumption Time: 3.17265
PPO Batch Consumption Time: 0.22992
Total Iteration Time: 6.83753
Cumulative Model Updates: 160,199
Cumulative Timesteps: 1,256,296,026
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1256296026...
Checkpoint 1256296026 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51133
Policy Entropy: 4.35901
Value Function Loss: 0.00226
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.89960
Value Function Update Magnitude: 0.62603
Collected Steps per Second: 13,179.90937
Overall Steps per Second: 7,249.26768
Timestep Collection Time: 3.79532
Timestep Consumption Time: 3.10496
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.90028
Cumulative Model Updates: 160,208
Cumulative Timesteps: 1,256,346,048
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35384
Policy Entropy: 4.35647
Value Function Loss: 0.00234
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.90332
Value Function Update Magnitude: 0.68226
Collected Steps per Second: 13,178.32079
Overall Steps per Second: 7,275.33890
Timestep Collection Time: 3.79623
Timestep Consumption Time: 3.08015
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.87638
Cumulative Model Updates: 160,217
Cumulative Timesteps: 1,256,396,076
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1256396076...
Checkpoint 1256396076 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97468
Policy Entropy: 4.35658
Value Function Loss: 0.00230
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.90983
Value Function Update Magnitude: 0.67875
Collected Steps per Second: 13,489.94795
Overall Steps per Second: 7,306.18333
Timestep Collection Time: 3.70869
Timestep Consumption Time: 3.13894
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.84762
Cumulative Model Updates: 160,226
Cumulative Timesteps: 1,256,446,106
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32538
Policy Entropy: 4.35702
Value Function Loss: 0.00234
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02684
Policy Update Magnitude: 0.88469
Value Function Update Magnitude: 0.67304
Collected Steps per Second: 13,212.61049
Overall Steps per Second: 7,233.07739
Timestep Collection Time: 3.78441
Timestep Consumption Time: 3.12855
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.91296
Cumulative Model Updates: 160,235
Cumulative Timesteps: 1,256,496,108
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1256496108...
Checkpoint 1256496108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.78137
Policy Entropy: 4.35571
Value Function Loss: 0.00217
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.87843
Value Function Update Magnitude: 0.63278
Collected Steps per Second: 13,259.74723
Overall Steps per Second: 7,369.95592
Timestep Collection Time: 3.77292
Timestep Consumption Time: 3.01518
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.78810
Cumulative Model Updates: 160,244
Cumulative Timesteps: 1,256,546,136
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.92892
Policy Entropy: 4.35935
Value Function Loss: 0.00203
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.87583
Value Function Update Magnitude: 0.59163
Collected Steps per Second: 13,354.78513
Overall Steps per Second: 7,250.06240
Timestep Collection Time: 3.74607
Timestep Consumption Time: 3.15428
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.90035
Cumulative Model Updates: 160,253
Cumulative Timesteps: 1,256,596,164
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1256596164...
Checkpoint 1256596164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54761
Policy Entropy: 4.36200
Value Function Loss: 0.00212
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.88125
Value Function Update Magnitude: 0.59580
Collected Steps per Second: 13,169.91502
Overall Steps per Second: 7,218.90866
Timestep Collection Time: 3.79775
Timestep Consumption Time: 3.13072
PPO Batch Consumption Time: 0.23032
Total Iteration Time: 6.92847
Cumulative Model Updates: 160,262
Cumulative Timesteps: 1,256,646,180
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.36634
Policy Entropy: 4.36375
Value Function Loss: 0.00224
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.89520
Value Function Update Magnitude: 0.63515
Collected Steps per Second: 13,257.49338
Overall Steps per Second: 7,366.28973
Timestep Collection Time: 3.77507
Timestep Consumption Time: 3.01912
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.79419
Cumulative Model Updates: 160,271
Cumulative Timesteps: 1,256,696,228
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1256696228...
Checkpoint 1256696228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68928
Policy Entropy: 4.36202
Value Function Loss: 0.00236
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.90436
Value Function Update Magnitude: 0.62776
Collected Steps per Second: 13,216.92076
Overall Steps per Second: 7,227.65536
Timestep Collection Time: 3.78363
Timestep Consumption Time: 3.13534
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.91898
Cumulative Model Updates: 160,280
Cumulative Timesteps: 1,256,746,236
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.80033
Policy Entropy: 4.35804
Value Function Loss: 0.00252
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.94439
Value Function Update Magnitude: 0.62872
Collected Steps per Second: 13,160.89161
Overall Steps per Second: 7,261.24837
Timestep Collection Time: 3.79913
Timestep Consumption Time: 3.08673
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.88587
Cumulative Model Updates: 160,289
Cumulative Timesteps: 1,256,796,236
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1256796236...
Checkpoint 1256796236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.24989
Policy Entropy: 4.35604
Value Function Loss: 0.00254
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.97206
Value Function Update Magnitude: 0.65209
Collected Steps per Second: 13,623.99304
Overall Steps per Second: 7,366.15596
Timestep Collection Time: 3.67249
Timestep Consumption Time: 3.11992
PPO Batch Consumption Time: 0.22945
Total Iteration Time: 6.79242
Cumulative Model Updates: 160,298
Cumulative Timesteps: 1,256,846,270
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.46079
Policy Entropy: 4.35709
Value Function Loss: 0.00229
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.93714
Value Function Update Magnitude: 0.66164
Collected Steps per Second: 13,396.21985
Overall Steps per Second: 7,261.57172
Timestep Collection Time: 3.73583
Timestep Consumption Time: 3.15607
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.89190
Cumulative Model Updates: 160,307
Cumulative Timesteps: 1,256,896,316
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1256896316...
Checkpoint 1256896316 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.79599
Policy Entropy: 4.35789
Value Function Loss: 0.00228
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02751
Policy Update Magnitude: 0.90577
Value Function Update Magnitude: 0.59831
Collected Steps per Second: 13,198.10650
Overall Steps per Second: 7,318.41887
Timestep Collection Time: 3.78873
Timestep Consumption Time: 3.04390
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.83262
Cumulative Model Updates: 160,316
Cumulative Timesteps: 1,256,946,320
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.75386
Policy Entropy: 4.36044
Value Function Loss: 0.00222
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02761
Policy Update Magnitude: 0.91257
Value Function Update Magnitude: 0.63099
Collected Steps per Second: 13,147.63579
Overall Steps per Second: 7,077.78181
Timestep Collection Time: 3.80464
Timestep Consumption Time: 3.26283
PPO Batch Consumption Time: 0.24006
Total Iteration Time: 7.06747
Cumulative Model Updates: 160,325
Cumulative Timesteps: 1,256,996,342
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1256996342...
Checkpoint 1256996342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27629
Policy Entropy: 4.36156
Value Function Loss: 0.00228
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.90298
Value Function Update Magnitude: 0.68436
Collected Steps per Second: 13,240.64056
Overall Steps per Second: 7,284.07346
Timestep Collection Time: 3.77791
Timestep Consumption Time: 3.08940
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.86731
Cumulative Model Updates: 160,334
Cumulative Timesteps: 1,257,046,364
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.83521
Policy Entropy: 4.36396
Value Function Loss: 0.00227
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.90521
Value Function Update Magnitude: 0.68344
Collected Steps per Second: 13,583.05389
Overall Steps per Second: 7,345.68936
Timestep Collection Time: 3.68341
Timestep Consumption Time: 3.12766
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.81107
Cumulative Model Updates: 160,343
Cumulative Timesteps: 1,257,096,396
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1257096396...
Checkpoint 1257096396 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.84667
Policy Entropy: 4.36460
Value Function Loss: 0.00214
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.88661
Value Function Update Magnitude: 0.65894
Collected Steps per Second: 13,356.95085
Overall Steps per Second: 7,262.37826
Timestep Collection Time: 3.74502
Timestep Consumption Time: 3.14281
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.88783
Cumulative Model Updates: 160,352
Cumulative Timesteps: 1,257,146,418
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58961
Policy Entropy: 4.36256
Value Function Loss: 0.00212
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02478
Policy Update Magnitude: 0.87452
Value Function Update Magnitude: 0.61277
Collected Steps per Second: 13,203.93690
Overall Steps per Second: 7,274.80069
Timestep Collection Time: 3.78720
Timestep Consumption Time: 3.08666
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.87387
Cumulative Model Updates: 160,361
Cumulative Timesteps: 1,257,196,424
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1257196424...
Checkpoint 1257196424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.47355
Policy Entropy: 4.36396
Value Function Loss: 0.00211
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.89221
Value Function Update Magnitude: 0.59073
Collected Steps per Second: 13,350.85736
Overall Steps per Second: 7,271.67032
Timestep Collection Time: 3.74807
Timestep Consumption Time: 3.13343
PPO Batch Consumption Time: 0.22920
Total Iteration Time: 6.88150
Cumulative Model Updates: 160,370
Cumulative Timesteps: 1,257,246,464
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81818
Policy Entropy: 4.36629
Value Function Loss: 0.00216
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.88397
Value Function Update Magnitude: 0.62745
Collected Steps per Second: 13,059.02064
Overall Steps per Second: 7,195.21698
Timestep Collection Time: 3.83107
Timestep Consumption Time: 3.12216
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.95323
Cumulative Model Updates: 160,379
Cumulative Timesteps: 1,257,296,494
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1257296494...
Checkpoint 1257296494 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.54139
Policy Entropy: 4.36450
Value Function Loss: 0.00238
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.91077
Value Function Update Magnitude: 0.64625
Collected Steps per Second: 13,023.07226
Overall Steps per Second: 7,242.84114
Timestep Collection Time: 3.84241
Timestep Consumption Time: 3.06648
PPO Batch Consumption Time: 0.22967
Total Iteration Time: 6.90889
Cumulative Model Updates: 160,388
Cumulative Timesteps: 1,257,346,534
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25035
Policy Entropy: 4.36869
Value Function Loss: 0.00225
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.90695
Value Function Update Magnitude: 0.68989
Collected Steps per Second: 13,256.80114
Overall Steps per Second: 7,240.21199
Timestep Collection Time: 3.77361
Timestep Consumption Time: 3.13586
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.90947
Cumulative Model Updates: 160,397
Cumulative Timesteps: 1,257,396,560
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1257396560...
Checkpoint 1257396560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49018
Policy Entropy: 4.36664
Value Function Loss: 0.00220
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.89409
Value Function Update Magnitude: 0.64638
Collected Steps per Second: 13,253.37926
Overall Steps per Second: 7,269.93865
Timestep Collection Time: 3.77443
Timestep Consumption Time: 3.10650
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.88094
Cumulative Model Updates: 160,406
Cumulative Timesteps: 1,257,446,584
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.44168
Policy Entropy: 4.37013
Value Function Loss: 0.00204
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02470
Policy Update Magnitude: 0.89311
Value Function Update Magnitude: 0.59761
Collected Steps per Second: 13,197.67369
Overall Steps per Second: 7,338.52150
Timestep Collection Time: 3.78976
Timestep Consumption Time: 3.02578
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.81554
Cumulative Model Updates: 160,415
Cumulative Timesteps: 1,257,496,600
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1257496600...
Checkpoint 1257496600 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98349
Policy Entropy: 4.36188
Value Function Loss: 0.00231
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.90632
Value Function Update Magnitude: 0.57059
Collected Steps per Second: 13,221.17195
Overall Steps per Second: 7,219.79830
Timestep Collection Time: 3.78348
Timestep Consumption Time: 3.14497
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.92845
Cumulative Model Updates: 160,424
Cumulative Timesteps: 1,257,546,622
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.19331
Policy Entropy: 4.36024
Value Function Loss: 0.00234
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.91116
Value Function Update Magnitude: 0.57762
Collected Steps per Second: 13,336.43689
Overall Steps per Second: 7,306.51943
Timestep Collection Time: 3.75183
Timestep Consumption Time: 3.09630
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.84813
Cumulative Model Updates: 160,433
Cumulative Timesteps: 1,257,596,658
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1257596658...
Checkpoint 1257596658 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91158
Policy Entropy: 4.36028
Value Function Loss: 0.00222
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.88966
Value Function Update Magnitude: 0.61884
Collected Steps per Second: 13,337.10132
Overall Steps per Second: 7,277.84743
Timestep Collection Time: 3.74984
Timestep Consumption Time: 3.12197
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.87181
Cumulative Model Updates: 160,442
Cumulative Timesteps: 1,257,646,670
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02739
Policy Entropy: 4.36300
Value Function Loss: 0.00227
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.89218
Value Function Update Magnitude: 0.64599
Collected Steps per Second: 13,221.25208
Overall Steps per Second: 7,087.68122
Timestep Collection Time: 3.78436
Timestep Consumption Time: 3.27493
PPO Batch Consumption Time: 0.24145
Total Iteration Time: 7.05929
Cumulative Model Updates: 160,451
Cumulative Timesteps: 1,257,696,704
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1257696704...
Checkpoint 1257696704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.99018
Policy Entropy: 4.36200
Value Function Loss: 0.00234
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.91998
Value Function Update Magnitude: 0.66997
Collected Steps per Second: 13,061.31864
Overall Steps per Second: 7,317.71192
Timestep Collection Time: 3.82871
Timestep Consumption Time: 3.00512
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.83383
Cumulative Model Updates: 160,460
Cumulative Timesteps: 1,257,746,712
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.36641
Policy Entropy: 4.35916
Value Function Loss: 0.00238
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.91762
Value Function Update Magnitude: 0.67860
Collected Steps per Second: 13,204.09645
Overall Steps per Second: 7,238.92532
Timestep Collection Time: 3.78686
Timestep Consumption Time: 3.12052
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.90738
Cumulative Model Updates: 160,469
Cumulative Timesteps: 1,257,796,714
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1257796714...
Checkpoint 1257796714 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28017
Policy Entropy: 4.35938
Value Function Loss: 0.00221
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.89209
Value Function Update Magnitude: 0.61760
Collected Steps per Second: 13,280.70730
Overall Steps per Second: 7,278.42619
Timestep Collection Time: 3.76546
Timestep Consumption Time: 3.10525
PPO Batch Consumption Time: 0.22935
Total Iteration Time: 6.87072
Cumulative Model Updates: 160,478
Cumulative Timesteps: 1,257,846,722
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48264
Policy Entropy: 4.36262
Value Function Loss: 0.00211
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.88823
Value Function Update Magnitude: 0.62824
Collected Steps per Second: 13,240.51102
Overall Steps per Second: 7,248.88778
Timestep Collection Time: 3.77689
Timestep Consumption Time: 3.12182
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.89871
Cumulative Model Updates: 160,487
Cumulative Timesteps: 1,257,896,730
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1257896730...
Checkpoint 1257896730 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43355
Policy Entropy: 4.36720
Value Function Loss: 0.00204
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.88609
Value Function Update Magnitude: 0.59395
Collected Steps per Second: 13,177.67400
Overall Steps per Second: 7,250.37893
Timestep Collection Time: 3.79657
Timestep Consumption Time: 3.10376
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.90033
Cumulative Model Updates: 160,496
Cumulative Timesteps: 1,257,946,760
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.29230
Policy Entropy: 4.36806
Value Function Loss: 0.00204
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.86432
Value Function Update Magnitude: 0.59076
Collected Steps per Second: 13,243.78521
Overall Steps per Second: 7,356.40313
Timestep Collection Time: 3.77641
Timestep Consumption Time: 3.02229
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.79870
Cumulative Model Updates: 160,505
Cumulative Timesteps: 1,257,996,774
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1257996774...
Checkpoint 1257996774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.23702
Policy Entropy: 4.36585
Value Function Loss: 0.00207
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02651
Policy Update Magnitude: 0.86391
Value Function Update Magnitude: 0.58096
Collected Steps per Second: 13,168.58565
Overall Steps per Second: 7,117.06859
Timestep Collection Time: 3.79737
Timestep Consumption Time: 3.22884
PPO Batch Consumption Time: 0.23869
Total Iteration Time: 7.02621
Cumulative Model Updates: 160,514
Cumulative Timesteps: 1,258,046,780
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39617
Policy Entropy: 4.36536
Value Function Loss: 0.00221
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.87557
Value Function Update Magnitude: 0.61967
Collected Steps per Second: 13,299.25756
Overall Steps per Second: 7,321.75309
Timestep Collection Time: 3.76216
Timestep Consumption Time: 3.07144
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.83361
Cumulative Model Updates: 160,523
Cumulative Timesteps: 1,258,096,814
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1258096814...
Checkpoint 1258096814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.21117
Policy Entropy: 4.36236
Value Function Loss: 0.00239
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02717
Policy Update Magnitude: 0.90994
Value Function Update Magnitude: 0.66008
Collected Steps per Second: 13,163.77575
Overall Steps per Second: 7,339.96192
Timestep Collection Time: 3.80104
Timestep Consumption Time: 3.01589
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.81693
Cumulative Model Updates: 160,532
Cumulative Timesteps: 1,258,146,850
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.84109
Policy Entropy: 4.36032
Value Function Loss: 0.00231
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.92476
Value Function Update Magnitude: 0.66959
Collected Steps per Second: 13,330.52693
Overall Steps per Second: 7,247.39739
Timestep Collection Time: 3.75094
Timestep Consumption Time: 3.14836
PPO Batch Consumption Time: 0.22952
Total Iteration Time: 6.89930
Cumulative Model Updates: 160,541
Cumulative Timesteps: 1,258,196,852
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1258196852...
Checkpoint 1258196852 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50977
Policy Entropy: 4.35954
Value Function Loss: 0.00234
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.90515
Value Function Update Magnitude: 0.65437
Collected Steps per Second: 13,179.36635
Overall Steps per Second: 7,269.05584
Timestep Collection Time: 3.79381
Timestep Consumption Time: 3.08466
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.87847
Cumulative Model Updates: 160,550
Cumulative Timesteps: 1,258,246,852
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20601
Policy Entropy: 4.36237
Value Function Loss: 0.00229
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02800
Policy Update Magnitude: 0.89983
Value Function Update Magnitude: 0.64820
Collected Steps per Second: 13,516.92636
Overall Steps per Second: 7,340.63492
Timestep Collection Time: 3.70143
Timestep Consumption Time: 3.11433
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.81576
Cumulative Model Updates: 160,559
Cumulative Timesteps: 1,258,296,884
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1258296884...
Checkpoint 1258296884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05026
Policy Entropy: 4.36441
Value Function Loss: 0.00227
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.88552
Value Function Update Magnitude: 0.67169
Collected Steps per Second: 13,254.31531
Overall Steps per Second: 7,261.27857
Timestep Collection Time: 3.77522
Timestep Consumption Time: 3.11585
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.89107
Cumulative Model Updates: 160,568
Cumulative Timesteps: 1,258,346,922
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.50895
Policy Entropy: 4.36225
Value Function Loss: 0.00235
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02841
Policy Update Magnitude: 0.89902
Value Function Update Magnitude: 0.68224
Collected Steps per Second: 13,291.88535
Overall Steps per Second: 7,150.87875
Timestep Collection Time: 3.76214
Timestep Consumption Time: 3.23084
PPO Batch Consumption Time: 0.23778
Total Iteration Time: 6.99299
Cumulative Model Updates: 160,577
Cumulative Timesteps: 1,258,396,928
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1258396928...
Checkpoint 1258396928 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.50025
Policy Entropy: 4.36039
Value Function Loss: 0.00241
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.91352
Value Function Update Magnitude: 0.68742
Collected Steps per Second: 13,519.47041
Overall Steps per Second: 7,339.70200
Timestep Collection Time: 3.69955
Timestep Consumption Time: 3.11489
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.81445
Cumulative Model Updates: 160,586
Cumulative Timesteps: 1,258,446,944
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66423
Policy Entropy: 4.35623
Value Function Loss: 0.00251
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 0.94192
Value Function Update Magnitude: 0.70469
Collected Steps per Second: 13,224.08152
Overall Steps per Second: 7,222.57994
Timestep Collection Time: 3.78204
Timestep Consumption Time: 3.14263
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.92467
Cumulative Model Updates: 160,595
Cumulative Timesteps: 1,258,496,958
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1258496958...
Checkpoint 1258496958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57167
Policy Entropy: 4.35512
Value Function Loss: 0.00246
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02960
Policy Update Magnitude: 0.94230
Value Function Update Magnitude: 0.69913
Collected Steps per Second: 13,076.91616
Overall Steps per Second: 7,299.79043
Timestep Collection Time: 3.82674
Timestep Consumption Time: 3.02852
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.85527
Cumulative Model Updates: 160,604
Cumulative Timesteps: 1,258,547,000
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.76687
Policy Entropy: 4.35493
Value Function Loss: 0.00246
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02999
Policy Update Magnitude: 0.93648
Value Function Update Magnitude: 0.69455
Collected Steps per Second: 13,144.81514
Overall Steps per Second: 7,238.28863
Timestep Collection Time: 3.80424
Timestep Consumption Time: 3.10430
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.90854
Cumulative Model Updates: 160,613
Cumulative Timesteps: 1,258,597,006
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1258597006...
Checkpoint 1258597006 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50185
Policy Entropy: 4.35588
Value Function Loss: 0.00244
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.90866
Value Function Update Magnitude: 0.71137
Collected Steps per Second: 13,128.06911
Overall Steps per Second: 7,262.59090
Timestep Collection Time: 3.81061
Timestep Consumption Time: 3.07756
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.88818
Cumulative Model Updates: 160,622
Cumulative Timesteps: 1,258,647,032
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.81960
Policy Entropy: 4.35583
Value Function Loss: 0.00245
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02826
Policy Update Magnitude: 0.90006
Value Function Update Magnitude: 0.71147
Collected Steps per Second: 13,481.38947
Overall Steps per Second: 7,335.73813
Timestep Collection Time: 3.71045
Timestep Consumption Time: 3.10850
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.81895
Cumulative Model Updates: 160,631
Cumulative Timesteps: 1,258,697,054
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1258697054...
Checkpoint 1258697054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64034
Policy Entropy: 4.35701
Value Function Loss: 0.00234
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.89079
Value Function Update Magnitude: 0.68161
Collected Steps per Second: 13,168.77800
Overall Steps per Second: 7,181.33958
Timestep Collection Time: 3.79929
Timestep Consumption Time: 3.16766
PPO Batch Consumption Time: 0.23048
Total Iteration Time: 6.96695
Cumulative Model Updates: 160,640
Cumulative Timesteps: 1,258,747,086
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09655
Policy Entropy: 4.35392
Value Function Loss: 0.00240
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.91050
Value Function Update Magnitude: 0.69663
Collected Steps per Second: 13,267.68229
Overall Steps per Second: 7,289.12928
Timestep Collection Time: 3.76991
Timestep Consumption Time: 3.09209
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.86200
Cumulative Model Updates: 160,649
Cumulative Timesteps: 1,258,797,104
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1258797104...
Checkpoint 1258797104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44302
Policy Entropy: 4.35381
Value Function Loss: 0.00230
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.91917
Value Function Update Magnitude: 0.66394
Collected Steps per Second: 13,622.16022
Overall Steps per Second: 7,362.50649
Timestep Collection Time: 3.67431
Timestep Consumption Time: 3.12392
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.79823
Cumulative Model Updates: 160,658
Cumulative Timesteps: 1,258,847,156
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.63396
Policy Entropy: 4.34969
Value Function Loss: 0.00230
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02994
Policy Update Magnitude: 0.90868
Value Function Update Magnitude: 0.63095
Collected Steps per Second: 13,252.53835
Overall Steps per Second: 7,261.45803
Timestep Collection Time: 3.77573
Timestep Consumption Time: 3.11517
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.89090
Cumulative Model Updates: 160,667
Cumulative Timesteps: 1,258,897,194
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1258897194...
Checkpoint 1258897194 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68505
Policy Entropy: 4.35173
Value Function Loss: 0.00225
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.89773
Value Function Update Magnitude: 0.59882
Collected Steps per Second: 13,167.01654
Overall Steps per Second: 7,340.17592
Timestep Collection Time: 3.79873
Timestep Consumption Time: 3.01554
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.81428
Cumulative Model Updates: 160,676
Cumulative Timesteps: 1,258,947,212
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62705
Policy Entropy: 4.35601
Value Function Loss: 0.00204
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.86561
Value Function Update Magnitude: 0.56396
Collected Steps per Second: 13,135.69501
Overall Steps per Second: 7,156.48353
Timestep Collection Time: 3.80718
Timestep Consumption Time: 3.18089
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 6.98807
Cumulative Model Updates: 160,685
Cumulative Timesteps: 1,258,997,222
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1258997222...
Checkpoint 1258997222 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.39940
Policy Entropy: 4.35635
Value Function Loss: 0.00214
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.85669
Value Function Update Magnitude: 0.55980
Collected Steps per Second: 13,244.21092
Overall Steps per Second: 7,260.31369
Timestep Collection Time: 3.77765
Timestep Consumption Time: 3.11351
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.89116
Cumulative Model Updates: 160,694
Cumulative Timesteps: 1,259,047,254
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73119
Policy Entropy: 4.35623
Value Function Loss: 0.00211
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02545
Policy Update Magnitude: 0.88196
Value Function Update Magnitude: 0.59716
Collected Steps per Second: 13,470.65425
Overall Steps per Second: 7,290.10701
Timestep Collection Time: 3.71281
Timestep Consumption Time: 3.14772
PPO Batch Consumption Time: 0.22995
Total Iteration Time: 6.86053
Cumulative Model Updates: 160,703
Cumulative Timesteps: 1,259,097,268
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1259097268...
Checkpoint 1259097268 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72954
Policy Entropy: 4.35258
Value Function Loss: 0.00258
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.92817
Value Function Update Magnitude: 0.61159
Collected Steps per Second: 13,113.13979
Overall Steps per Second: 7,235.49127
Timestep Collection Time: 3.81587
Timestep Consumption Time: 3.09977
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.91563
Cumulative Model Updates: 160,712
Cumulative Timesteps: 1,259,147,306
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.17769
Policy Entropy: 4.35273
Value Function Loss: 0.00257
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02905
Policy Update Magnitude: 0.93363
Value Function Update Magnitude: 0.63639
Collected Steps per Second: 13,135.74371
Overall Steps per Second: 7,256.09577
Timestep Collection Time: 3.80991
Timestep Consumption Time: 3.08719
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.89710
Cumulative Model Updates: 160,721
Cumulative Timesteps: 1,259,197,352
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1259197352...
Checkpoint 1259197352 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.26518
Policy Entropy: 4.35139
Value Function Loss: 0.00263
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02979
Policy Update Magnitude: 0.93670
Value Function Update Magnitude: 0.64581
Collected Steps per Second: 13,365.78904
Overall Steps per Second: 7,299.30149
Timestep Collection Time: 3.74299
Timestep Consumption Time: 3.11082
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.85381
Cumulative Model Updates: 160,730
Cumulative Timesteps: 1,259,247,380
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20750
Policy Entropy: 4.35668
Value Function Loss: 0.00242
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.92438
Value Function Update Magnitude: 0.65837
Collected Steps per Second: 13,335.42443
Overall Steps per Second: 7,278.56975
Timestep Collection Time: 3.74986
Timestep Consumption Time: 3.12044
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.87031
Cumulative Model Updates: 160,739
Cumulative Timesteps: 1,259,297,386
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1259297386...
Checkpoint 1259297386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09278
Policy Entropy: 4.35628
Value Function Loss: 0.00238
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.91345
Value Function Update Magnitude: 0.61921
Collected Steps per Second: 13,126.10427
Overall Steps per Second: 7,322.43251
Timestep Collection Time: 3.81027
Timestep Consumption Time: 3.01997
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.83024
Cumulative Model Updates: 160,748
Cumulative Timesteps: 1,259,347,400
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72900
Policy Entropy: 4.35757
Value Function Loss: 0.00235
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.89038
Value Function Update Magnitude: 0.62187
Collected Steps per Second: 13,271.30186
Overall Steps per Second: 7,231.88485
Timestep Collection Time: 3.76783
Timestep Consumption Time: 3.14655
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 6.91438
Cumulative Model Updates: 160,757
Cumulative Timesteps: 1,259,397,404
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1259397404...
Checkpoint 1259397404 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.52101
Policy Entropy: 4.35356
Value Function Loss: 0.00232
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.90038
Value Function Update Magnitude: 0.68390
Collected Steps per Second: 13,136.12292
Overall Steps per Second: 7,182.66895
Timestep Collection Time: 3.80858
Timestep Consumption Time: 3.15680
PPO Batch Consumption Time: 0.23065
Total Iteration Time: 6.96538
Cumulative Model Updates: 160,766
Cumulative Timesteps: 1,259,447,434
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42668
Policy Entropy: 4.35616
Value Function Loss: 0.00224
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02830
Policy Update Magnitude: 0.90156
Value Function Update Magnitude: 0.68441
Collected Steps per Second: 13,553.06121
Overall Steps per Second: 7,331.74599
Timestep Collection Time: 3.69215
Timestep Consumption Time: 3.13296
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.82511
Cumulative Model Updates: 160,775
Cumulative Timesteps: 1,259,497,474
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1259497474...
Checkpoint 1259497474 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.28131
Policy Entropy: 4.35312
Value Function Loss: 0.00234
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.91369
Value Function Update Magnitude: 0.72669
Collected Steps per Second: 13,210.63546
Overall Steps per Second: 7,221.95252
Timestep Collection Time: 3.78680
Timestep Consumption Time: 3.14014
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.92694
Cumulative Model Updates: 160,784
Cumulative Timesteps: 1,259,547,500
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09646
Policy Entropy: 4.35431
Value Function Loss: 0.00244
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02857
Policy Update Magnitude: 0.93537
Value Function Update Magnitude: 0.70150
Collected Steps per Second: 13,219.34202
Overall Steps per Second: 7,270.49882
Timestep Collection Time: 3.78264
Timestep Consumption Time: 3.09502
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.87766
Cumulative Model Updates: 160,793
Cumulative Timesteps: 1,259,597,504
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1259597504...
Checkpoint 1259597504 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28953
Policy Entropy: 4.35227
Value Function Loss: 0.00260
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03183
Policy Update Magnitude: 0.94607
Value Function Update Magnitude: 0.66208
Collected Steps per Second: 13,472.34060
Overall Steps per Second: 7,305.45141
Timestep Collection Time: 3.71472
Timestep Consumption Time: 3.13578
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 6.85050
Cumulative Model Updates: 160,802
Cumulative Timesteps: 1,259,647,550
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.10018
Policy Entropy: 4.35274
Value Function Loss: 0.00257
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.93895
Value Function Update Magnitude: 0.63832
Collected Steps per Second: 13,253.97804
Overall Steps per Second: 7,249.36100
Timestep Collection Time: 3.77275
Timestep Consumption Time: 3.12496
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.89771
Cumulative Model Updates: 160,811
Cumulative Timesteps: 1,259,697,554
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1259697554...
Checkpoint 1259697554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.11808
Policy Entropy: 4.34899
Value Function Loss: 0.00274
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02966
Policy Update Magnitude: 0.97148
Value Function Update Magnitude: 0.64489
Collected Steps per Second: 13,225.85431
Overall Steps per Second: 7,350.51417
Timestep Collection Time: 3.78108
Timestep Consumption Time: 3.02225
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.80333
Cumulative Model Updates: 160,820
Cumulative Timesteps: 1,259,747,562
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82596
Policy Entropy: 4.35088
Value Function Loss: 0.00275
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03147
Policy Update Magnitude: 0.98773
Value Function Update Magnitude: 0.64754
Collected Steps per Second: 13,302.18237
Overall Steps per Second: 7,234.34392
Timestep Collection Time: 3.76164
Timestep Consumption Time: 3.15509
PPO Batch Consumption Time: 0.23207
Total Iteration Time: 6.91673
Cumulative Model Updates: 160,829
Cumulative Timesteps: 1,259,797,600
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1259797600...
Checkpoint 1259797600 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02990
Policy Entropy: 4.35126
Value Function Loss: 0.00272
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02956
Policy Update Magnitude: 0.98245
Value Function Update Magnitude: 0.69328
Collected Steps per Second: 13,152.99948
Overall Steps per Second: 7,250.08533
Timestep Collection Time: 3.80309
Timestep Consumption Time: 3.09642
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.89950
Cumulative Model Updates: 160,838
Cumulative Timesteps: 1,259,847,622
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06718
Policy Entropy: 4.35368
Value Function Loss: 0.00242
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.96175
Value Function Update Magnitude: 0.69469
Collected Steps per Second: 13,116.01402
Overall Steps per Second: 7,327.87097
Timestep Collection Time: 3.81290
Timestep Consumption Time: 3.01173
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.82463
Cumulative Model Updates: 160,847
Cumulative Timesteps: 1,259,897,632
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1259897632...
Checkpoint 1259897632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.45002
Policy Entropy: 4.35480
Value Function Loss: 0.00233
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.92344
Value Function Update Magnitude: 0.66688
Collected Steps per Second: 13,352.22114
Overall Steps per Second: 7,292.17558
Timestep Collection Time: 3.74739
Timestep Consumption Time: 3.11421
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.86160
Cumulative Model Updates: 160,856
Cumulative Timesteps: 1,259,947,668
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.22752
Policy Entropy: 4.35528
Value Function Loss: 0.00229
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.91477
Value Function Update Magnitude: 0.66308
Collected Steps per Second: 13,307.84972
Overall Steps per Second: 7,307.42880
Timestep Collection Time: 3.75944
Timestep Consumption Time: 3.08702
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.84646
Cumulative Model Updates: 160,865
Cumulative Timesteps: 1,259,997,698
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1259997698...
Checkpoint 1259997698 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53398
Policy Entropy: 4.35346
Value Function Loss: 0.00243
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.91373
Value Function Update Magnitude: 0.65242
Collected Steps per Second: 13,471.43838
Overall Steps per Second: 7,311.09700
Timestep Collection Time: 3.71215
Timestep Consumption Time: 3.12786
PPO Batch Consumption Time: 0.22939
Total Iteration Time: 6.84001
Cumulative Model Updates: 160,874
Cumulative Timesteps: 1,260,047,706
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.52178
Policy Entropy: 4.35285
Value Function Loss: 0.00233
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02788
Policy Update Magnitude: 0.90633
Value Function Update Magnitude: 0.63312
Collected Steps per Second: 13,244.37398
Overall Steps per Second: 7,237.70020
Timestep Collection Time: 3.77579
Timestep Consumption Time: 3.13359
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.90938
Cumulative Model Updates: 160,883
Cumulative Timesteps: 1,260,097,714
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1260097714...
Checkpoint 1260097714 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84622
Policy Entropy: 4.35519
Value Function Loss: 0.00237
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02717
Policy Update Magnitude: 0.90877
Value Function Update Magnitude: 0.60654
Collected Steps per Second: 13,320.44863
Overall Steps per Second: 7,199.23605
Timestep Collection Time: 3.75453
Timestep Consumption Time: 3.19232
PPO Batch Consumption Time: 0.23611
Total Iteration Time: 6.94685
Cumulative Model Updates: 160,892
Cumulative Timesteps: 1,260,147,726
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.59515
Policy Entropy: 4.35802
Value Function Loss: 0.00229
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.89638
Value Function Update Magnitude: 0.64469
Collected Steps per Second: 13,560.01880
Overall Steps per Second: 7,355.57264
Timestep Collection Time: 3.68775
Timestep Consumption Time: 3.11063
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.79838
Cumulative Model Updates: 160,901
Cumulative Timesteps: 1,260,197,732
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1260197732...
Checkpoint 1260197732 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76349
Policy Entropy: 4.35737
Value Function Loss: 0.00231
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.89982
Value Function Update Magnitude: 0.67267
Collected Steps per Second: 13,303.19219
Overall Steps per Second: 7,256.36273
Timestep Collection Time: 3.76150
Timestep Consumption Time: 3.13451
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.89602
Cumulative Model Updates: 160,910
Cumulative Timesteps: 1,260,247,772
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73921
Policy Entropy: 4.35258
Value Function Loss: 0.00235
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02581
Policy Update Magnitude: 0.91769
Value Function Update Magnitude: 0.63890
Collected Steps per Second: 13,281.75023
Overall Steps per Second: 7,325.57496
Timestep Collection Time: 3.76622
Timestep Consumption Time: 3.06219
PPO Batch Consumption Time: 0.22935
Total Iteration Time: 6.82841
Cumulative Model Updates: 160,919
Cumulative Timesteps: 1,260,297,794
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1260297794...
Checkpoint 1260297794 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18668
Policy Entropy: 4.35297
Value Function Loss: 0.00223
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.90374
Value Function Update Magnitude: 0.65358
Collected Steps per Second: 13,126.18937
Overall Steps per Second: 7,200.52939
Timestep Collection Time: 3.81162
Timestep Consumption Time: 3.13676
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.94838
Cumulative Model Updates: 160,928
Cumulative Timesteps: 1,260,347,826
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.97529
Policy Entropy: 4.35443
Value Function Loss: 0.00236
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.90327
Value Function Update Magnitude: 0.63986
Collected Steps per Second: 13,180.01934
Overall Steps per Second: 7,274.83223
Timestep Collection Time: 3.79484
Timestep Consumption Time: 3.08038
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.87521
Cumulative Model Updates: 160,937
Cumulative Timesteps: 1,260,397,842
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1260397842...
Checkpoint 1260397842 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08590
Policy Entropy: 4.35676
Value Function Loss: 0.00233
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.92213
Value Function Update Magnitude: 0.66510
Collected Steps per Second: 13,155.39365
Overall Steps per Second: 7,321.23568
Timestep Collection Time: 3.80361
Timestep Consumption Time: 3.03103
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.83464
Cumulative Model Updates: 160,946
Cumulative Timesteps: 1,260,447,880
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87501
Policy Entropy: 4.35999
Value Function Loss: 0.00217
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.89873
Value Function Update Magnitude: 0.68387
Collected Steps per Second: 13,100.27400
Overall Steps per Second: 7,143.64951
Timestep Collection Time: 3.81702
Timestep Consumption Time: 3.18276
PPO Batch Consumption Time: 0.23128
Total Iteration Time: 6.99978
Cumulative Model Updates: 160,955
Cumulative Timesteps: 1,260,497,884
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1260497884...
Checkpoint 1260497884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.81516
Policy Entropy: 4.35706
Value Function Loss: 0.00213
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02441
Policy Update Magnitude: 0.88150
Value Function Update Magnitude: 0.63712
Collected Steps per Second: 13,246.56678
Overall Steps per Second: 7,274.24443
Timestep Collection Time: 3.77486
Timestep Consumption Time: 3.09925
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.87412
Cumulative Model Updates: 160,964
Cumulative Timesteps: 1,260,547,888
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64070
Policy Entropy: 4.35797
Value Function Loss: 0.00220
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02534
Policy Update Magnitude: 0.89385
Value Function Update Magnitude: 0.65032
Collected Steps per Second: 13,593.27979
Overall Steps per Second: 7,355.94508
Timestep Collection Time: 3.67991
Timestep Consumption Time: 3.12031
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.80021
Cumulative Model Updates: 160,973
Cumulative Timesteps: 1,260,597,910
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1260597910...
Checkpoint 1260597910 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57557
Policy Entropy: 4.35622
Value Function Loss: 0.00229
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.91799
Value Function Update Magnitude: 0.65568
Collected Steps per Second: 13,236.85399
Overall Steps per Second: 7,236.75940
Timestep Collection Time: 3.77945
Timestep Consumption Time: 3.13359
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.91304
Cumulative Model Updates: 160,982
Cumulative Timesteps: 1,260,647,938
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50029
Policy Entropy: 4.35205
Value Function Loss: 0.00243
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.92462
Value Function Update Magnitude: 0.65037
Collected Steps per Second: 13,026.41879
Overall Steps per Second: 7,271.53419
Timestep Collection Time: 3.84066
Timestep Consumption Time: 3.03960
PPO Batch Consumption Time: 0.22940
Total Iteration Time: 6.88025
Cumulative Model Updates: 160,991
Cumulative Timesteps: 1,260,697,968
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1260697968...
Checkpoint 1260697968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61887
Policy Entropy: 4.35289
Value Function Loss: 0.00237
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02804
Policy Update Magnitude: 0.91865
Value Function Update Magnitude: 0.65120
Collected Steps per Second: 13,246.18335
Overall Steps per Second: 7,245.79330
Timestep Collection Time: 3.77694
Timestep Consumption Time: 3.12776
PPO Batch Consumption Time: 0.22925
Total Iteration Time: 6.90470
Cumulative Model Updates: 161,000
Cumulative Timesteps: 1,260,747,998
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.32971
Policy Entropy: 4.34986
Value Function Loss: 0.00250
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02854
Policy Update Magnitude: 0.91623
Value Function Update Magnitude: 0.65287
Collected Steps per Second: 13,159.53475
Overall Steps per Second: 7,248.95548
Timestep Collection Time: 3.80211
Timestep Consumption Time: 3.10013
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.90224
Cumulative Model Updates: 161,009
Cumulative Timesteps: 1,260,798,032
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1260798032...
Checkpoint 1260798032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50385
Policy Entropy: 4.35126
Value Function Loss: 0.00237
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02752
Policy Update Magnitude: 0.92017
Value Function Update Magnitude: 0.63384
Collected Steps per Second: 13,153.35671
Overall Steps per Second: 7,165.35220
Timestep Collection Time: 3.80238
Timestep Consumption Time: 3.17760
PPO Batch Consumption Time: 0.24159
Total Iteration Time: 6.97998
Cumulative Model Updates: 161,018
Cumulative Timesteps: 1,260,848,046
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31932
Policy Entropy: 4.35549
Value Function Loss: 0.00215
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02877
Policy Update Magnitude: 0.88697
Value Function Update Magnitude: 0.63471
Collected Steps per Second: 13,345.53780
Overall Steps per Second: 7,273.40020
Timestep Collection Time: 3.74912
Timestep Consumption Time: 3.12992
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.87904
Cumulative Model Updates: 161,027
Cumulative Timesteps: 1,260,898,080
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1260898080...
Checkpoint 1260898080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.51534
Policy Entropy: 4.35757
Value Function Loss: 0.00233
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02752
Policy Update Magnitude: 0.89431
Value Function Update Magnitude: 0.65721
Collected Steps per Second: 13,160.17799
Overall Steps per Second: 7,279.01189
Timestep Collection Time: 3.80056
Timestep Consumption Time: 3.07071
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.87126
Cumulative Model Updates: 161,036
Cumulative Timesteps: 1,260,948,096
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34574
Policy Entropy: 4.35944
Value Function Loss: 0.00230
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.90768
Value Function Update Magnitude: 0.66404
Collected Steps per Second: 13,088.47591
Overall Steps per Second: 7,328.59758
Timestep Collection Time: 3.82290
Timestep Consumption Time: 3.00460
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.82750
Cumulative Model Updates: 161,045
Cumulative Timesteps: 1,260,998,132
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1260998132...
Checkpoint 1260998132 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.23188
Policy Entropy: 4.35694
Value Function Loss: 0.00236
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.90939
Value Function Update Magnitude: 0.67473
Collected Steps per Second: 13,313.89170
Overall Steps per Second: 7,288.54294
Timestep Collection Time: 3.75593
Timestep Consumption Time: 3.10498
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.86090
Cumulative Model Updates: 161,054
Cumulative Timesteps: 1,261,048,138
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41169
Policy Entropy: 4.35435
Value Function Loss: 0.00233
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.91131
Value Function Update Magnitude: 0.66554
Collected Steps per Second: 13,187.59034
Overall Steps per Second: 7,250.69366
Timestep Collection Time: 3.79296
Timestep Consumption Time: 3.10569
PPO Batch Consumption Time: 0.22948
Total Iteration Time: 6.89865
Cumulative Model Updates: 161,063
Cumulative Timesteps: 1,261,098,158
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1261098158...
Checkpoint 1261098158 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.83602
Policy Entropy: 4.35499
Value Function Loss: 0.00216
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.90788
Value Function Update Magnitude: 0.63032
Collected Steps per Second: 13,493.51077
Overall Steps per Second: 7,265.90513
Timestep Collection Time: 3.70800
Timestep Consumption Time: 3.17813
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.88613
Cumulative Model Updates: 161,072
Cumulative Timesteps: 1,261,148,192
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87584
Policy Entropy: 4.35328
Value Function Loss: 0.00232
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.90874
Value Function Update Magnitude: 0.60583
Collected Steps per Second: 13,170.52751
Overall Steps per Second: 7,093.67080
Timestep Collection Time: 3.79985
Timestep Consumption Time: 3.25517
PPO Batch Consumption Time: 0.23911
Total Iteration Time: 7.05502
Cumulative Model Updates: 161,081
Cumulative Timesteps: 1,261,198,238
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1261198238...
Checkpoint 1261198238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83750
Policy Entropy: 4.35409
Value Function Loss: 0.00236
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.92640
Value Function Update Magnitude: 0.62548
Collected Steps per Second: 13,132.72999
Overall Steps per Second: 7,336.08254
Timestep Collection Time: 3.80911
Timestep Consumption Time: 3.00979
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.81890
Cumulative Model Updates: 161,090
Cumulative Timesteps: 1,261,248,262
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32648
Policy Entropy: 4.35265
Value Function Loss: 0.00245
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.93530
Value Function Update Magnitude: 0.63984
Collected Steps per Second: 13,111.32565
Overall Steps per Second: 7,211.61397
Timestep Collection Time: 3.81380
Timestep Consumption Time: 3.12001
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.93382
Cumulative Model Updates: 161,099
Cumulative Timesteps: 1,261,298,266
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1261298266...
Checkpoint 1261298266 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.40950
Policy Entropy: 4.35470
Value Function Loss: 0.00228
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02752
Policy Update Magnitude: 0.92714
Value Function Update Magnitude: 0.61041
Collected Steps per Second: 13,241.86270
Overall Steps per Second: 7,270.20187
Timestep Collection Time: 3.77998
Timestep Consumption Time: 3.10483
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.88482
Cumulative Model Updates: 161,108
Cumulative Timesteps: 1,261,348,320
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18035
Policy Entropy: 4.35531
Value Function Loss: 0.00229
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.91451
Value Function Update Magnitude: 0.62343
Collected Steps per Second: 13,039.39862
Overall Steps per Second: 7,302.57636
Timestep Collection Time: 3.83591
Timestep Consumption Time: 3.01345
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.84936
Cumulative Model Updates: 161,117
Cumulative Timesteps: 1,261,398,338
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1261398338...
Checkpoint 1261398338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66546
Policy Entropy: 4.35847
Value Function Loss: 0.00219
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02651
Policy Update Magnitude: 0.92051
Value Function Update Magnitude: 0.66610
Collected Steps per Second: 13,093.90575
Overall Steps per Second: 7,222.80379
Timestep Collection Time: 3.82025
Timestep Consumption Time: 3.10531
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.92557
Cumulative Model Updates: 161,126
Cumulative Timesteps: 1,261,448,360
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04177
Policy Entropy: 4.35703
Value Function Loss: 0.00226
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02730
Policy Update Magnitude: 0.92255
Value Function Update Magnitude: 0.65930
Collected Steps per Second: 13,215.77358
Overall Steps per Second: 7,365.16545
Timestep Collection Time: 3.78381
Timestep Consumption Time: 3.00572
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.78953
Cumulative Model Updates: 161,135
Cumulative Timesteps: 1,261,498,366
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1261498366...
Checkpoint 1261498366 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72854
Policy Entropy: 4.35904
Value Function Loss: 0.00218
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.92837
Value Function Update Magnitude: 0.63101
Collected Steps per Second: 13,140.63000
Overall Steps per Second: 7,151.69401
Timestep Collection Time: 3.80788
Timestep Consumption Time: 3.18878
PPO Batch Consumption Time: 0.23019
Total Iteration Time: 6.99666
Cumulative Model Updates: 161,144
Cumulative Timesteps: 1,261,548,404
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41759
Policy Entropy: 4.35836
Value Function Loss: 0.00238
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.92046
Value Function Update Magnitude: 0.66707
Collected Steps per Second: 13,274.89197
Overall Steps per Second: 7,295.84606
Timestep Collection Time: 3.76877
Timestep Consumption Time: 3.08856
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.85733
Cumulative Model Updates: 161,153
Cumulative Timesteps: 1,261,598,434
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1261598434...
Checkpoint 1261598434 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14683
Policy Entropy: 4.35926
Value Function Loss: 0.00244
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.93764
Value Function Update Magnitude: 0.64048
Collected Steps per Second: 13,230.98474
Overall Steps per Second: 7,372.37106
Timestep Collection Time: 3.78173
Timestep Consumption Time: 3.00523
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.78696
Cumulative Model Updates: 161,162
Cumulative Timesteps: 1,261,648,470
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.60880
Policy Entropy: 4.35543
Value Function Loss: 0.00266
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02944
Policy Update Magnitude: 0.96918
Value Function Update Magnitude: 0.64283
Collected Steps per Second: 13,268.05009
Overall Steps per Second: 7,264.38508
Timestep Collection Time: 3.77101
Timestep Consumption Time: 3.11656
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.88758
Cumulative Model Updates: 161,171
Cumulative Timesteps: 1,261,698,504
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1261698504...
Checkpoint 1261698504 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.07326
Policy Entropy: 4.35720
Value Function Loss: 0.00253
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.95870
Value Function Update Magnitude: 0.63668
Collected Steps per Second: 13,243.13761
Overall Steps per Second: 7,299.68834
Timestep Collection Time: 3.77750
Timestep Consumption Time: 3.07567
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.85317
Cumulative Model Updates: 161,180
Cumulative Timesteps: 1,261,748,530
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.38899
Policy Entropy: 4.35925
Value Function Loss: 0.00238
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02631
Policy Update Magnitude: 0.92105
Value Function Update Magnitude: 0.64875
Collected Steps per Second: 13,332.03033
Overall Steps per Second: 7,301.17336
Timestep Collection Time: 3.75337
Timestep Consumption Time: 3.10033
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.85369
Cumulative Model Updates: 161,189
Cumulative Timesteps: 1,261,798,570
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1261798570...
Checkpoint 1261798570 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97911
Policy Entropy: 4.35959
Value Function Loss: 0.00234
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.91070
Value Function Update Magnitude: 0.64347
Collected Steps per Second: 13,192.54602
Overall Steps per Second: 7,243.32800
Timestep Collection Time: 3.79093
Timestep Consumption Time: 3.11363
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.90456
Cumulative Model Updates: 161,198
Cumulative Timesteps: 1,261,848,582
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96398
Policy Entropy: 4.36026
Value Function Loss: 0.00251
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.94332
Value Function Update Magnitude: 0.66627
Collected Steps per Second: 13,116.21135
Overall Steps per Second: 7,201.02590
Timestep Collection Time: 3.81406
Timestep Consumption Time: 3.13301
PPO Batch Consumption Time: 0.23024
Total Iteration Time: 6.94707
Cumulative Model Updates: 161,207
Cumulative Timesteps: 1,261,898,608
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1261898608...
Checkpoint 1261898608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.82809
Policy Entropy: 4.35526
Value Function Loss: 0.00257
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03170
Policy Update Magnitude: 0.96006
Value Function Update Magnitude: 0.68044
Collected Steps per Second: 13,513.63729
Overall Steps per Second: 7,353.37154
Timestep Collection Time: 3.70115
Timestep Consumption Time: 3.10063
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.80178
Cumulative Model Updates: 161,216
Cumulative Timesteps: 1,261,948,624
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.32442
Policy Entropy: 4.35592
Value Function Loss: 0.00262
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03000
Policy Update Magnitude: 0.96936
Value Function Update Magnitude: 0.70278
Collected Steps per Second: 13,196.43044
Overall Steps per Second: 7,248.40284
Timestep Collection Time: 3.78921
Timestep Consumption Time: 3.10942
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.89862
Cumulative Model Updates: 161,225
Cumulative Timesteps: 1,261,998,628
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1261998628...
Checkpoint 1261998628 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.58607
Policy Entropy: 4.35471
Value Function Loss: 0.00263
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.97920
Value Function Update Magnitude: 0.67418
Collected Steps per Second: 13,275.86967
Overall Steps per Second: 7,371.48200
Timestep Collection Time: 3.76834
Timestep Consumption Time: 3.01835
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.78669
Cumulative Model Updates: 161,234
Cumulative Timesteps: 1,262,048,656
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.88377
Policy Entropy: 4.35441
Value Function Loss: 0.00270
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02898
Policy Update Magnitude: 0.95473
Value Function Update Magnitude: 0.66054
Collected Steps per Second: 13,298.35146
Overall Steps per Second: 7,266.43325
Timestep Collection Time: 3.76077
Timestep Consumption Time: 3.12184
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.88261
Cumulative Model Updates: 161,243
Cumulative Timesteps: 1,262,098,668
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1262098668...
Checkpoint 1262098668 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91236
Policy Entropy: 4.35229
Value Function Loss: 0.00258
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 0.94531
Value Function Update Magnitude: 0.65359
Collected Steps per Second: 13,301.61939
Overall Steps per Second: 7,294.54703
Timestep Collection Time: 3.75969
Timestep Consumption Time: 3.09611
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.85581
Cumulative Model Updates: 161,252
Cumulative Timesteps: 1,262,148,678
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34023
Policy Entropy: 4.34900
Value Function Loss: 0.00279
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03076
Policy Update Magnitude: 0.97633
Value Function Update Magnitude: 0.67721
Collected Steps per Second: 13,574.72976
Overall Steps per Second: 7,365.83693
Timestep Collection Time: 3.68523
Timestep Consumption Time: 3.10639
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.79162
Cumulative Model Updates: 161,261
Cumulative Timesteps: 1,262,198,704
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1262198704...
Checkpoint 1262198704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.85414
Policy Entropy: 4.35240
Value Function Loss: 0.00275
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03058
Policy Update Magnitude: 0.99334
Value Function Update Magnitude: 0.68010
Collected Steps per Second: 13,197.19106
Overall Steps per Second: 7,081.41783
Timestep Collection Time: 3.78959
Timestep Consumption Time: 3.27283
PPO Batch Consumption Time: 0.24127
Total Iteration Time: 7.06243
Cumulative Model Updates: 161,270
Cumulative Timesteps: 1,262,248,716
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97304
Policy Entropy: 4.35419
Value Function Loss: 0.00273
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 0.96003
Value Function Update Magnitude: 0.68057
Collected Steps per Second: 13,200.22765
Overall Steps per Second: 7,258.97955
Timestep Collection Time: 3.79069
Timestep Consumption Time: 3.10256
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.89326
Cumulative Model Updates: 161,279
Cumulative Timesteps: 1,262,298,754
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1262298754...
Checkpoint 1262298754 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63492
Policy Entropy: 4.35639
Value Function Loss: 0.00250
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 0.93885
Value Function Update Magnitude: 0.69033
Collected Steps per Second: 13,464.88311
Overall Steps per Second: 7,325.25073
Timestep Collection Time: 3.71425
Timestep Consumption Time: 3.11309
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.82734
Cumulative Model Updates: 161,288
Cumulative Timesteps: 1,262,348,766
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65544
Policy Entropy: 4.35742
Value Function Loss: 0.00233
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03077
Policy Update Magnitude: 0.91009
Value Function Update Magnitude: 0.71763
Collected Steps per Second: 13,263.93718
Overall Steps per Second: 7,275.98535
Timestep Collection Time: 3.77143
Timestep Consumption Time: 3.10379
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.87522
Cumulative Model Updates: 161,297
Cumulative Timesteps: 1,262,398,790
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1262398790...
Checkpoint 1262398790 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.99805
Policy Entropy: 4.35728
Value Function Loss: 0.00238
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02929
Policy Update Magnitude: 0.92414
Value Function Update Magnitude: 0.68672
Collected Steps per Second: 13,067.91069
Overall Steps per Second: 7,306.23901
Timestep Collection Time: 3.82800
Timestep Consumption Time: 3.01875
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.84675
Cumulative Model Updates: 161,306
Cumulative Timesteps: 1,262,448,814
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58155
Policy Entropy: 4.35593
Value Function Loss: 0.00240
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02922
Policy Update Magnitude: 0.94054
Value Function Update Magnitude: 0.63813
Collected Steps per Second: 13,193.59645
Overall Steps per Second: 7,245.06766
Timestep Collection Time: 3.79032
Timestep Consumption Time: 3.11203
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.90235
Cumulative Model Updates: 161,315
Cumulative Timesteps: 1,262,498,822
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1262498822...
Checkpoint 1262498822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51153
Policy Entropy: 4.36131
Value Function Loss: 0.00228
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 0.91407
Value Function Update Magnitude: 0.62780
Collected Steps per Second: 13,107.80565
Overall Steps per Second: 7,241.70921
Timestep Collection Time: 3.81696
Timestep Consumption Time: 3.09190
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 6.90887
Cumulative Model Updates: 161,324
Cumulative Timesteps: 1,262,548,854
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.60672
Policy Entropy: 4.36175
Value Function Loss: 0.00213
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.87164
Value Function Update Magnitude: 0.63778
Collected Steps per Second: 13,206.68716
Overall Steps per Second: 7,281.21330
Timestep Collection Time: 3.78672
Timestep Consumption Time: 3.08164
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 6.86836
Cumulative Model Updates: 161,333
Cumulative Timesteps: 1,262,598,864
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1262598864...
Checkpoint 1262598864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24977
Policy Entropy: 4.36495
Value Function Loss: 0.00212
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.87585
Value Function Update Magnitude: 0.65846
Collected Steps per Second: 13,301.11661
Overall Steps per Second: 7,265.05854
Timestep Collection Time: 3.75908
Timestep Consumption Time: 3.12317
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 6.88226
Cumulative Model Updates: 161,342
Cumulative Timesteps: 1,262,648,864
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41414
Policy Entropy: 4.36392
Value Function Loss: 0.00218
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02614
Policy Update Magnitude: 0.88542
Value Function Update Magnitude: 0.67094
Collected Steps per Second: 13,155.49063
Overall Steps per Second: 7,254.85497
Timestep Collection Time: 3.80161
Timestep Consumption Time: 3.09198
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.89359
Cumulative Model Updates: 161,351
Cumulative Timesteps: 1,262,698,876
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1262698876...
Checkpoint 1262698876 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11655
Policy Entropy: 4.36227
Value Function Loss: 0.00233
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.90813
Value Function Update Magnitude: 0.70104
Collected Steps per Second: 13,519.82899
Overall Steps per Second: 7,345.71592
Timestep Collection Time: 3.70005
Timestep Consumption Time: 3.10991
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.80996
Cumulative Model Updates: 161,360
Cumulative Timesteps: 1,262,748,900
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.37125
Policy Entropy: 4.36073
Value Function Loss: 0.00227
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.91291
Value Function Update Magnitude: 0.70381
Collected Steps per Second: 13,267.17354
Overall Steps per Second: 7,264.98400
Timestep Collection Time: 3.77111
Timestep Consumption Time: 3.11562
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.88673
Cumulative Model Updates: 161,369
Cumulative Timesteps: 1,262,798,932
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1262798932...
Checkpoint 1262798932 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34438
Policy Entropy: 4.35994
Value Function Loss: 0.00218
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02775
Policy Update Magnitude: 0.89399
Value Function Update Magnitude: 0.67436
Collected Steps per Second: 13,274.42097
Overall Steps per Second: 7,363.85114
Timestep Collection Time: 3.76725
Timestep Consumption Time: 3.02377
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.79101
Cumulative Model Updates: 161,378
Cumulative Timesteps: 1,262,848,940
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.91560
Policy Entropy: 4.36400
Value Function Loss: 0.00215
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02618
Policy Update Magnitude: 0.89291
Value Function Update Magnitude: 0.63871
Collected Steps per Second: 12,129.63897
Overall Steps per Second: 6,801.49599
Timestep Collection Time: 4.12246
Timestep Consumption Time: 3.22945
PPO Batch Consumption Time: 0.23420
Total Iteration Time: 7.35191
Cumulative Model Updates: 161,387
Cumulative Timesteps: 1,262,898,944
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1262898944...
Checkpoint 1262898944 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.12642
Policy Entropy: 4.36555
Value Function Loss: 0.00237
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.91767
Value Function Update Magnitude: 0.64462
Collected Steps per Second: 12,922.47060
Overall Steps per Second: 7,052.04606
Timestep Collection Time: 3.87000
Timestep Consumption Time: 3.22156
PPO Batch Consumption Time: 0.24028
Total Iteration Time: 7.09156
Cumulative Model Updates: 161,396
Cumulative Timesteps: 1,262,948,954
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83442
Policy Entropy: 4.36046
Value Function Loss: 0.00259
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.95471
Value Function Update Magnitude: 0.69252
Collected Steps per Second: 13,154.70423
Overall Steps per Second: 7,320.19120
Timestep Collection Time: 3.80199
Timestep Consumption Time: 3.03035
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.83234
Cumulative Model Updates: 161,405
Cumulative Timesteps: 1,262,998,968
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1262998968...
Checkpoint 1262998968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.69774
Policy Entropy: 4.35949
Value Function Loss: 0.00245
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02800
Policy Update Magnitude: 0.93993
Value Function Update Magnitude: 0.70039
Collected Steps per Second: 12,935.28842
Overall Steps per Second: 7,039.81395
Timestep Collection Time: 3.86771
Timestep Consumption Time: 3.23901
PPO Batch Consumption Time: 0.23720
Total Iteration Time: 7.10672
Cumulative Model Updates: 161,414
Cumulative Timesteps: 1,263,048,998
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.42794
Policy Entropy: 4.35899
Value Function Loss: 0.00240
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02826
Policy Update Magnitude: 0.93532
Value Function Update Magnitude: 0.63804
Collected Steps per Second: 11,628.57314
Overall Steps per Second: 6,738.66582
Timestep Collection Time: 4.30268
Timestep Consumption Time: 3.12223
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 7.42491
Cumulative Model Updates: 161,423
Cumulative Timesteps: 1,263,099,032
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1263099032...
Checkpoint 1263099032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51179
Policy Entropy: 4.36040
Value Function Loss: 0.00239
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.94396
Value Function Update Magnitude: 0.64072
Collected Steps per Second: 13,155.81961
Overall Steps per Second: 7,236.24509
Timestep Collection Time: 3.80318
Timestep Consumption Time: 3.11118
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.91436
Cumulative Model Updates: 161,432
Cumulative Timesteps: 1,263,149,066
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98874
Policy Entropy: 4.35741
Value Function Loss: 0.00260
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02907
Policy Update Magnitude: 0.98217
Value Function Update Magnitude: 0.65992
Collected Steps per Second: 12,616.26649
Overall Steps per Second: 6,999.17172
Timestep Collection Time: 3.96567
Timestep Consumption Time: 3.18260
PPO Batch Consumption Time: 0.23319
Total Iteration Time: 7.14827
Cumulative Model Updates: 161,441
Cumulative Timesteps: 1,263,199,098
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1263199098...
Checkpoint 1263199098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.73551
Policy Entropy: 4.35822
Value Function Loss: 0.00275
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03109
Policy Update Magnitude: 0.96406
Value Function Update Magnitude: 0.66968
Collected Steps per Second: 13,322.56364
Overall Steps per Second: 7,307.51410
Timestep Collection Time: 3.75498
Timestep Consumption Time: 3.09085
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.84583
Cumulative Model Updates: 161,450
Cumulative Timesteps: 1,263,249,124
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41593
Policy Entropy: 4.35549
Value Function Loss: 0.00268
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.95572
Value Function Update Magnitude: 0.66847
Collected Steps per Second: 12,905.75402
Overall Steps per Second: 6,838.14781
Timestep Collection Time: 3.87626
Timestep Consumption Time: 3.43947
PPO Batch Consumption Time: 0.25132
Total Iteration Time: 7.31572
Cumulative Model Updates: 161,459
Cumulative Timesteps: 1,263,299,150
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1263299150...
Checkpoint 1263299150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01455
Policy Entropy: 4.35502
Value Function Loss: 0.00263
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.95460
Value Function Update Magnitude: 0.71031
Collected Steps per Second: 11,539.43041
Overall Steps per Second: 6,540.28371
Timestep Collection Time: 4.33297
Timestep Consumption Time: 3.31196
PPO Batch Consumption Time: 0.24424
Total Iteration Time: 7.64493
Cumulative Model Updates: 161,468
Cumulative Timesteps: 1,263,349,150
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.86299
Policy Entropy: 4.35611
Value Function Loss: 0.00241
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02837
Policy Update Magnitude: 0.93182
Value Function Update Magnitude: 0.70391
Collected Steps per Second: 11,492.61953
Overall Steps per Second: 6,756.66784
Timestep Collection Time: 4.35114
Timestep Consumption Time: 3.04985
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 7.40099
Cumulative Model Updates: 161,477
Cumulative Timesteps: 1,263,399,156
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1263399156...
Checkpoint 1263399156 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96623
Policy Entropy: 4.35448
Value Function Loss: 0.00232
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02946
Policy Update Magnitude: 0.91671
Value Function Update Magnitude: 0.67448
Collected Steps per Second: 13,012.95938
Overall Steps per Second: 7,180.50837
Timestep Collection Time: 3.84294
Timestep Consumption Time: 3.12147
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.96441
Cumulative Model Updates: 161,486
Cumulative Timesteps: 1,263,449,164
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81713
Policy Entropy: 4.35630
Value Function Loss: 0.00213
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.89562
Value Function Update Magnitude: 0.63823
Collected Steps per Second: 13,086.69453
Overall Steps per Second: 7,216.07024
Timestep Collection Time: 3.82297
Timestep Consumption Time: 3.11017
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.93314
Cumulative Model Updates: 161,495
Cumulative Timesteps: 1,263,499,194
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1263499194...
Checkpoint 1263499194 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.39357
Policy Entropy: 4.35633
Value Function Loss: 0.00228
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.90702
Value Function Update Magnitude: 0.62080
Collected Steps per Second: 13,254.31727
Overall Steps per Second: 7,330.37616
Timestep Collection Time: 3.77371
Timestep Consumption Time: 3.04967
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.82339
Cumulative Model Updates: 161,504
Cumulative Timesteps: 1,263,549,212
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.51011
Policy Entropy: 4.35483
Value Function Loss: 0.00230
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.92485
Value Function Update Magnitude: 0.64469
Collected Steps per Second: 13,299.88414
Overall Steps per Second: 7,257.81885
Timestep Collection Time: 3.75973
Timestep Consumption Time: 3.12994
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.88967
Cumulative Model Updates: 161,513
Cumulative Timesteps: 1,263,599,216
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1263599216...
Checkpoint 1263599216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.28351
Policy Entropy: 4.35858
Value Function Loss: 0.00224
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.89729
Value Function Update Magnitude: 0.66653
Collected Steps per Second: 13,039.98478
Overall Steps per Second: 7,171.40594
Timestep Collection Time: 3.83497
Timestep Consumption Time: 3.13828
PPO Batch Consumption Time: 0.23182
Total Iteration Time: 6.97325
Cumulative Model Updates: 161,522
Cumulative Timesteps: 1,263,649,224
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.65728
Policy Entropy: 4.36200
Value Function Loss: 0.00215
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.87895
Value Function Update Magnitude: 0.65644
Collected Steps per Second: 13,434.95252
Overall Steps per Second: 7,323.14553
Timestep Collection Time: 3.72327
Timestep Consumption Time: 3.10740
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.83067
Cumulative Model Updates: 161,531
Cumulative Timesteps: 1,263,699,246
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1263699246...
Checkpoint 1263699246 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.21321
Policy Entropy: 4.36373
Value Function Loss: 0.00215
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.87791
Value Function Update Magnitude: 0.64076
Collected Steps per Second: 13,107.00714
Overall Steps per Second: 7,221.43009
Timestep Collection Time: 3.81781
Timestep Consumption Time: 3.11157
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.92938
Cumulative Model Updates: 161,540
Cumulative Timesteps: 1,263,749,286
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83636
Policy Entropy: 4.35842
Value Function Loss: 0.00239
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.91824
Value Function Update Magnitude: 0.64580
Collected Steps per Second: 13,200.99030
Overall Steps per Second: 7,358.55106
Timestep Collection Time: 3.79032
Timestep Consumption Time: 3.00939
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.79971
Cumulative Model Updates: 161,549
Cumulative Timesteps: 1,263,799,322
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1263799322...
Checkpoint 1263799322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99064
Policy Entropy: 4.36154
Value Function Loss: 0.00227
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.92365
Value Function Update Magnitude: 0.61710
Collected Steps per Second: 13,024.46036
Overall Steps per Second: 7,190.87010
Timestep Collection Time: 3.83908
Timestep Consumption Time: 3.11446
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.95354
Cumulative Model Updates: 161,558
Cumulative Timesteps: 1,263,849,324
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75025
Policy Entropy: 4.35986
Value Function Loss: 0.00241
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.92527
Value Function Update Magnitude: 0.70958
Collected Steps per Second: 13,236.69001
Overall Steps per Second: 7,265.75875
Timestep Collection Time: 3.78010
Timestep Consumption Time: 3.10645
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.88655
Cumulative Model Updates: 161,567
Cumulative Timesteps: 1,263,899,360
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1263899360...
Checkpoint 1263899360 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11105
Policy Entropy: 4.36215
Value Function Loss: 0.00226
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02730
Policy Update Magnitude: 0.93288
Value Function Update Magnitude: 0.70045
Collected Steps per Second: 13,312.55561
Overall Steps per Second: 7,298.31369
Timestep Collection Time: 3.75781
Timestep Consumption Time: 3.09665
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.85446
Cumulative Model Updates: 161,576
Cumulative Timesteps: 1,263,949,386
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41937
Policy Entropy: 4.36154
Value Function Loss: 0.00223
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.91412
Value Function Update Magnitude: 0.66188
Collected Steps per Second: 13,193.22297
Overall Steps per Second: 7,182.57835
Timestep Collection Time: 3.79043
Timestep Consumption Time: 3.17197
PPO Batch Consumption Time: 0.23012
Total Iteration Time: 6.96240
Cumulative Model Updates: 161,585
Cumulative Timesteps: 1,263,999,394
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1263999394...
Checkpoint 1263999394 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.84389
Policy Entropy: 4.36071
Value Function Loss: 0.00230
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.92664
Value Function Update Magnitude: 0.60356
Collected Steps per Second: 13,212.86024
Overall Steps per Second: 7,275.39456
Timestep Collection Time: 3.78419
Timestep Consumption Time: 3.08829
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.87248
Cumulative Model Updates: 161,594
Cumulative Timesteps: 1,264,049,394
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19264
Policy Entropy: 4.36149
Value Function Loss: 0.00231
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.93042
Value Function Update Magnitude: 0.61027
Collected Steps per Second: 13,605.64097
Overall Steps per Second: 7,342.49753
Timestep Collection Time: 3.67524
Timestep Consumption Time: 3.13498
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.81022
Cumulative Model Updates: 161,603
Cumulative Timesteps: 1,264,099,398
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1264099398...
Checkpoint 1264099398 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.11224
Policy Entropy: 4.35850
Value Function Loss: 0.00235
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02674
Policy Update Magnitude: 0.93730
Value Function Update Magnitude: 0.60023
Collected Steps per Second: 13,201.03687
Overall Steps per Second: 7,252.00507
Timestep Collection Time: 3.78894
Timestep Consumption Time: 3.10818
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.89713
Cumulative Model Updates: 161,612
Cumulative Timesteps: 1,264,149,416
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.15734
Policy Entropy: 4.36274
Value Function Loss: 0.00222
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.94319
Value Function Update Magnitude: 0.61157
Collected Steps per Second: 13,080.22928
Overall Steps per Second: 7,328.75635
Timestep Collection Time: 3.82486
Timestep Consumption Time: 3.00168
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.82653
Cumulative Model Updates: 161,621
Cumulative Timesteps: 1,264,199,446
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1264199446...
Checkpoint 1264199446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83326
Policy Entropy: 4.35945
Value Function Loss: 0.00233
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.95397
Value Function Update Magnitude: 0.63924
Collected Steps per Second: 13,188.61098
Overall Steps per Second: 7,231.81582
Timestep Collection Time: 3.79145
Timestep Consumption Time: 3.12299
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.91445
Cumulative Model Updates: 161,630
Cumulative Timesteps: 1,264,249,450
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92713
Policy Entropy: 4.36069
Value Function Loss: 0.00239
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02674
Policy Update Magnitude: 0.95102
Value Function Update Magnitude: 0.66236
Collected Steps per Second: 13,255.02301
Overall Steps per Second: 7,290.86217
Timestep Collection Time: 3.77215
Timestep Consumption Time: 3.08574
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.85790
Cumulative Model Updates: 161,639
Cumulative Timesteps: 1,264,299,450
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1264299450...
Checkpoint 1264299450 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85582
Policy Entropy: 4.35645
Value Function Loss: 0.00257
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.95996
Value Function Update Magnitude: 0.66479
Collected Steps per Second: 13,350.58985
Overall Steps per Second: 7,253.61991
Timestep Collection Time: 3.74815
Timestep Consumption Time: 3.15048
PPO Batch Consumption Time: 0.23416
Total Iteration Time: 6.89862
Cumulative Model Updates: 161,648
Cumulative Timesteps: 1,264,349,490
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.60771
Policy Entropy: 4.35558
Value Function Loss: 0.00256
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.97328
Value Function Update Magnitude: 0.64032
Collected Steps per Second: 13,149.41775
Overall Steps per Second: 7,230.13313
Timestep Collection Time: 3.80488
Timestep Consumption Time: 3.11504
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.91993
Cumulative Model Updates: 161,657
Cumulative Timesteps: 1,264,399,522
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1264399522...
Checkpoint 1264399522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93052
Policy Entropy: 4.35572
Value Function Loss: 0.00240
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 0.97012
Value Function Update Magnitude: 0.64408
Collected Steps per Second: 13,223.31370
Overall Steps per Second: 7,286.39308
Timestep Collection Time: 3.78286
Timestep Consumption Time: 3.08226
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.86513
Cumulative Model Updates: 161,666
Cumulative Timesteps: 1,264,449,544
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.40734
Policy Entropy: 4.35410
Value Function Loss: 0.00231
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02732
Policy Update Magnitude: 0.95367
Value Function Update Magnitude: 0.64394
Collected Steps per Second: 13,551.89207
Overall Steps per Second: 7,352.43635
Timestep Collection Time: 3.69115
Timestep Consumption Time: 3.11231
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.80346
Cumulative Model Updates: 161,675
Cumulative Timesteps: 1,264,499,566
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1264499566...
Checkpoint 1264499566 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05362
Policy Entropy: 4.35505
Value Function Loss: 0.00224
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.95847
Value Function Update Magnitude: 0.68462
Collected Steps per Second: 13,317.07685
Overall Steps per Second: 7,264.67351
Timestep Collection Time: 3.75563
Timestep Consumption Time: 3.12892
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.88455
Cumulative Model Updates: 161,684
Cumulative Timesteps: 1,264,549,580
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.94735
Policy Entropy: 4.35307
Value Function Loss: 0.00233
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.97562
Value Function Update Magnitude: 0.69800
Collected Steps per Second: 13,044.51357
Overall Steps per Second: 7,310.32441
Timestep Collection Time: 3.83671
Timestep Consumption Time: 3.00950
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.84621
Cumulative Model Updates: 161,693
Cumulative Timesteps: 1,264,599,628
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1264599628...
Checkpoint 1264599628 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56082
Policy Entropy: 4.35585
Value Function Loss: 0.00247
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 0.98205
Value Function Update Magnitude: 0.64017
Collected Steps per Second: 13,136.28727
Overall Steps per Second: 7,212.16372
Timestep Collection Time: 3.80869
Timestep Consumption Time: 3.12848
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.93717
Cumulative Model Updates: 161,702
Cumulative Timesteps: 1,264,649,660
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.59073
Policy Entropy: 4.35800
Value Function Loss: 0.00243
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 0.97083
Value Function Update Magnitude: 0.63799
Collected Steps per Second: 13,043.58811
Overall Steps per Second: 7,128.99138
Timestep Collection Time: 3.83545
Timestep Consumption Time: 3.18209
PPO Batch Consumption Time: 0.23684
Total Iteration Time: 7.01754
Cumulative Model Updates: 161,711
Cumulative Timesteps: 1,264,699,688
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1264699688...
Checkpoint 1264699688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.46567
Policy Entropy: 4.36087
Value Function Loss: 0.00238
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03070
Policy Update Magnitude: 0.95433
Value Function Update Magnitude: 0.65610
Collected Steps per Second: 13,162.39920
Overall Steps per Second: 7,345.97468
Timestep Collection Time: 3.79916
Timestep Consumption Time: 3.00811
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.80727
Cumulative Model Updates: 161,720
Cumulative Timesteps: 1,264,749,694
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57815
Policy Entropy: 4.35873
Value Function Loss: 0.00237
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 0.95551
Value Function Update Magnitude: 0.69065
Collected Steps per Second: 13,210.83447
Overall Steps per Second: 7,234.13711
Timestep Collection Time: 3.78598
Timestep Consumption Time: 3.12790
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.91389
Cumulative Model Updates: 161,729
Cumulative Timesteps: 1,264,799,710
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1264799710...
Checkpoint 1264799710 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99571
Policy Entropy: 4.35873
Value Function Loss: 0.00240
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 0.98023
Value Function Update Magnitude: 0.70424
Collected Steps per Second: 13,208.75569
Overall Steps per Second: 7,262.97924
Timestep Collection Time: 3.78930
Timestep Consumption Time: 3.10208
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.89139
Cumulative Model Updates: 161,738
Cumulative Timesteps: 1,264,849,762
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82198
Policy Entropy: 4.35730
Value Function Loss: 0.00241
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.96366
Value Function Update Magnitude: 0.70630
Collected Steps per Second: 13,159.59635
Overall Steps per Second: 7,168.70599
Timestep Collection Time: 3.80057
Timestep Consumption Time: 3.17614
PPO Batch Consumption Time: 0.22976
Total Iteration Time: 6.97671
Cumulative Model Updates: 161,747
Cumulative Timesteps: 1,264,899,776
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1264899776...
Checkpoint 1264899776 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.10310
Policy Entropy: 4.36019
Value Function Loss: 0.00238
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.93664
Value Function Update Magnitude: 0.65456
Collected Steps per Second: 12,926.33840
Overall Steps per Second: 7,147.83134
Timestep Collection Time: 3.86869
Timestep Consumption Time: 3.12756
PPO Batch Consumption Time: 0.22956
Total Iteration Time: 6.99625
Cumulative Model Updates: 161,756
Cumulative Timesteps: 1,264,949,784
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.31817
Policy Entropy: 4.35771
Value Function Loss: 0.00233
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.95001
Value Function Update Magnitude: 0.68931
Collected Steps per Second: 12,998.77542
Overall Steps per Second: 7,211.27982
Timestep Collection Time: 3.85113
Timestep Consumption Time: 3.09077
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.94190
Cumulative Model Updates: 161,765
Cumulative Timesteps: 1,264,999,844
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 1264999844...
Checkpoint 1264999844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.84409
Policy Entropy: 4.35828
Value Function Loss: 0.00229
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.95010
Value Function Update Magnitude: 0.68439
Collected Steps per Second: 13,204.06308
Overall Steps per Second: 7,178.32830
Timestep Collection Time: 3.78914
Timestep Consumption Time: 3.18073
PPO Batch Consumption Time: 0.22992
Total Iteration Time: 6.96987
Cumulative Model Updates: 161,774
Cumulative Timesteps: 1,265,049,876
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24114
Policy Entropy: 4.35617
Value Function Loss: 0.00238
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.96879
Value Function Update Magnitude: 0.70942
Collected Steps per Second: 13,217.85199
Overall Steps per Second: 7,200.65770
Timestep Collection Time: 3.78291
Timestep Consumption Time: 3.16117
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.94409
Cumulative Model Updates: 161,783
Cumulative Timesteps: 1,265,099,878
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1265099878...
Checkpoint 1265099878 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61206
Policy Entropy: 4.35765
Value Function Loss: 0.00225
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.95665
Value Function Update Magnitude: 0.67263
Collected Steps per Second: 13,207.02015
Overall Steps per Second: 7,344.78999
Timestep Collection Time: 3.78738
Timestep Consumption Time: 3.02289
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.81027
Cumulative Model Updates: 161,792
Cumulative Timesteps: 1,265,149,898
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32438
Policy Entropy: 4.35795
Value Function Loss: 0.00221
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.91714
Value Function Update Magnitude: 0.64364
Collected Steps per Second: 13,086.76858
Overall Steps per Second: 7,204.26528
Timestep Collection Time: 3.82081
Timestep Consumption Time: 3.11980
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.94061
Cumulative Model Updates: 161,801
Cumulative Timesteps: 1,265,199,900
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1265199900...
Checkpoint 1265199900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33832
Policy Entropy: 4.36122
Value Function Loss: 0.00215
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02566
Policy Update Magnitude: 0.93397
Value Function Update Magnitude: 0.63118
Collected Steps per Second: 13,105.31156
Overall Steps per Second: 7,233.42888
Timestep Collection Time: 3.81754
Timestep Consumption Time: 3.09896
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.91650
Cumulative Model Updates: 161,810
Cumulative Timesteps: 1,265,249,930
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46682
Policy Entropy: 4.35929
Value Function Loss: 0.00228
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02761
Policy Update Magnitude: 0.94903
Value Function Update Magnitude: 0.62745
Collected Steps per Second: 13,123.75184
Overall Steps per Second: 7,309.59097
Timestep Collection Time: 3.81065
Timestep Consumption Time: 3.03105
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.84170
Cumulative Model Updates: 161,819
Cumulative Timesteps: 1,265,299,940
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1265299940...
Checkpoint 1265299940 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97233
Policy Entropy: 4.35872
Value Function Loss: 0.00242
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.97548
Value Function Update Magnitude: 0.64832
Collected Steps per Second: 12,003.98700
Overall Steps per Second: 6,806.60819
Timestep Collection Time: 4.16745
Timestep Consumption Time: 3.18217
PPO Batch Consumption Time: 0.22991
Total Iteration Time: 7.34962
Cumulative Model Updates: 161,828
Cumulative Timesteps: 1,265,349,966
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.92651
Policy Entropy: 4.35491
Value Function Loss: 0.00249
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.98065
Value Function Update Magnitude: 0.68418
Collected Steps per Second: 12,266.67338
Overall Steps per Second: 6,733.42218
Timestep Collection Time: 4.07674
Timestep Consumption Time: 3.35010
PPO Batch Consumption Time: 0.24819
Total Iteration Time: 7.42683
Cumulative Model Updates: 161,837
Cumulative Timesteps: 1,265,399,974
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1265399974...
Checkpoint 1265399974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81722
Policy Entropy: 4.35591
Value Function Loss: 0.00235
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.96444
Value Function Update Magnitude: 0.72973
Collected Steps per Second: 13,297.95083
Overall Steps per Second: 7,234.00504
Timestep Collection Time: 3.76133
Timestep Consumption Time: 3.15296
PPO Batch Consumption Time: 0.23063
Total Iteration Time: 6.91429
Cumulative Model Updates: 161,846
Cumulative Timesteps: 1,265,449,992
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32752
Policy Entropy: 4.35443
Value Function Loss: 0.00243
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.95845
Value Function Update Magnitude: 0.68444
Collected Steps per Second: 12,987.13436
Overall Steps per Second: 7,001.68687
Timestep Collection Time: 3.85212
Timestep Consumption Time: 3.29302
PPO Batch Consumption Time: 0.24604
Total Iteration Time: 7.14514
Cumulative Model Updates: 161,855
Cumulative Timesteps: 1,265,500,020
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1265500020...
Checkpoint 1265500020 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20734
Policy Entropy: 4.35266
Value Function Loss: 0.00246
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03081
Policy Update Magnitude: 0.97730
Value Function Update Magnitude: 0.66610
Collected Steps per Second: 11,107.17588
Overall Steps per Second: 6,551.53734
Timestep Collection Time: 4.50376
Timestep Consumption Time: 3.13170
PPO Batch Consumption Time: 0.23002
Total Iteration Time: 7.63546
Cumulative Model Updates: 161,864
Cumulative Timesteps: 1,265,550,044
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85774
Policy Entropy: 4.34842
Value Function Loss: 0.00266
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03079
Policy Update Magnitude: 0.98917
Value Function Update Magnitude: 0.68043
Collected Steps per Second: 11,372.16274
Overall Steps per Second: 6,366.34698
Timestep Collection Time: 4.39705
Timestep Consumption Time: 3.45737
PPO Batch Consumption Time: 0.25798
Total Iteration Time: 7.85443
Cumulative Model Updates: 161,873
Cumulative Timesteps: 1,265,600,048
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1265600048...
Checkpoint 1265600048 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.90856
Policy Entropy: 4.35414
Value Function Loss: 0.00252
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03013
Policy Update Magnitude: 0.97553
Value Function Update Magnitude: 0.70143
Collected Steps per Second: 10,829.89460
Overall Steps per Second: 6,321.00281
Timestep Collection Time: 4.61759
Timestep Consumption Time: 3.29381
PPO Batch Consumption Time: 0.23948
Total Iteration Time: 7.91140
Cumulative Model Updates: 161,882
Cumulative Timesteps: 1,265,650,056
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89226
Policy Entropy: 4.35390
Value Function Loss: 0.00234
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02981
Policy Update Magnitude: 0.93753
Value Function Update Magnitude: 0.69279
Collected Steps per Second: 9,734.67027
Overall Steps per Second: 5,788.02816
Timestep Collection Time: 5.13669
Timestep Consumption Time: 3.50252
PPO Batch Consumption Time: 0.26973
Total Iteration Time: 8.63921
Cumulative Model Updates: 161,891
Cumulative Timesteps: 1,265,700,060
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1265700060...
Checkpoint 1265700060 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00403
Policy Entropy: 4.35371
Value Function Loss: 0.00239
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.93367
Value Function Update Magnitude: 0.66058
Collected Steps per Second: 10,836.66460
Overall Steps per Second: 6,170.23572
Timestep Collection Time: 4.61581
Timestep Consumption Time: 3.49085
PPO Batch Consumption Time: 0.26204
Total Iteration Time: 8.10666
Cumulative Model Updates: 161,900
Cumulative Timesteps: 1,265,750,080
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55343
Policy Entropy: 4.35076
Value Function Loss: 0.00248
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02926
Policy Update Magnitude: 0.92857
Value Function Update Magnitude: 0.65646
Collected Steps per Second: 11,392.07127
Overall Steps per Second: 6,422.12909
Timestep Collection Time: 4.39253
Timestep Consumption Time: 3.39928
PPO Batch Consumption Time: 0.25563
Total Iteration Time: 7.79181
Cumulative Model Updates: 161,909
Cumulative Timesteps: 1,265,800,120
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1265800120...
Checkpoint 1265800120 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.21379
Policy Entropy: 4.34734
Value Function Loss: 0.00268
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.95583
Value Function Update Magnitude: 0.67173
Collected Steps per Second: 11,612.24031
Overall Steps per Second: 6,778.39382
Timestep Collection Time: 4.30821
Timestep Consumption Time: 3.07230
PPO Batch Consumption Time: 0.23001
Total Iteration Time: 7.38051
Cumulative Model Updates: 161,918
Cumulative Timesteps: 1,265,850,148
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24863
Policy Entropy: 4.34974
Value Function Loss: 0.00245
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02987
Policy Update Magnitude: 0.94943
Value Function Update Magnitude: 0.68769
Collected Steps per Second: 12,850.59005
Overall Steps per Second: 6,970.26761
Timestep Collection Time: 3.89212
Timestep Consumption Time: 3.28350
PPO Batch Consumption Time: 0.24011
Total Iteration Time: 7.17562
Cumulative Model Updates: 161,927
Cumulative Timesteps: 1,265,900,164
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1265900164...
Checkpoint 1265900164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93628
Policy Entropy: 4.35457
Value Function Loss: 0.00227
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.91104
Value Function Update Magnitude: 0.67995
Collected Steps per Second: 12,193.08685
Overall Steps per Second: 6,878.08667
Timestep Collection Time: 4.10298
Timestep Consumption Time: 3.17055
PPO Batch Consumption Time: 0.23562
Total Iteration Time: 7.27353
Cumulative Model Updates: 161,936
Cumulative Timesteps: 1,265,950,192
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72893
Policy Entropy: 4.35791
Value Function Loss: 0.00229
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.92559
Value Function Update Magnitude: 0.63962
Collected Steps per Second: 12,573.93536
Overall Steps per Second: 6,547.63319
Timestep Collection Time: 3.98077
Timestep Consumption Time: 3.66382
PPO Batch Consumption Time: 0.26827
Total Iteration Time: 7.64459
Cumulative Model Updates: 161,945
Cumulative Timesteps: 1,266,000,246
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1266000246...
Checkpoint 1266000246 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.82704
Policy Entropy: 4.35495
Value Function Loss: 0.00251
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.95801
Value Function Update Magnitude: 0.62433
Collected Steps per Second: 10,838.54131
Overall Steps per Second: 6,044.63876
Timestep Collection Time: 4.61317
Timestep Consumption Time: 3.65863
PPO Batch Consumption Time: 0.27268
Total Iteration Time: 8.27179
Cumulative Model Updates: 161,954
Cumulative Timesteps: 1,266,050,246
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43040
Policy Entropy: 4.35242
Value Function Loss: 0.00256
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02908
Policy Update Magnitude: 0.94611
Value Function Update Magnitude: 0.65951
Collected Steps per Second: 11,103.52401
Overall Steps per Second: 6,363.84770
Timestep Collection Time: 4.50326
Timestep Consumption Time: 3.35394
PPO Batch Consumption Time: 0.25782
Total Iteration Time: 7.85720
Cumulative Model Updates: 161,963
Cumulative Timesteps: 1,266,100,248
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1266100248...
Checkpoint 1266100248 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18085
Policy Entropy: 4.35401
Value Function Loss: 0.00235
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02981
Policy Update Magnitude: 0.91607
Value Function Update Magnitude: 0.67537
Collected Steps per Second: 10,778.66069
Overall Steps per Second: 6,129.42824
Timestep Collection Time: 4.63898
Timestep Consumption Time: 3.51871
PPO Batch Consumption Time: 0.25683
Total Iteration Time: 8.15769
Cumulative Model Updates: 161,972
Cumulative Timesteps: 1,266,150,250
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89134
Policy Entropy: 4.35535
Value Function Loss: 0.00232
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.91337
Value Function Update Magnitude: 0.71424
Collected Steps per Second: 11,264.40326
Overall Steps per Second: 6,350.37702
Timestep Collection Time: 4.44142
Timestep Consumption Time: 3.43685
PPO Batch Consumption Time: 0.25618
Total Iteration Time: 7.87827
Cumulative Model Updates: 161,981
Cumulative Timesteps: 1,266,200,280
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1266200280...
Checkpoint 1266200280 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43031
Policy Entropy: 4.35415
Value Function Loss: 0.00219
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02879
Policy Update Magnitude: 0.92178
Value Function Update Magnitude: 0.65659
Collected Steps per Second: 11,378.27056
Overall Steps per Second: 6,330.97283
Timestep Collection Time: 4.39452
Timestep Consumption Time: 3.50348
PPO Batch Consumption Time: 0.26081
Total Iteration Time: 7.89800
Cumulative Model Updates: 161,990
Cumulative Timesteps: 1,266,250,282
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02652
Policy Entropy: 4.35626
Value Function Loss: 0.00240
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02849
Policy Update Magnitude: 0.91680
Value Function Update Magnitude: 0.65004
Collected Steps per Second: 11,115.20663
Overall Steps per Second: 6,289.87982
Timestep Collection Time: 4.50194
Timestep Consumption Time: 3.45370
PPO Batch Consumption Time: 0.25516
Total Iteration Time: 7.95564
Cumulative Model Updates: 161,999
Cumulative Timesteps: 1,266,300,322
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1266300322...
Checkpoint 1266300322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.75220
Policy Entropy: 4.35680
Value Function Loss: 0.00225
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.90969
Value Function Update Magnitude: 0.68351
Collected Steps per Second: 11,979.81684
Overall Steps per Second: 6,722.09731
Timestep Collection Time: 4.17786
Timestep Consumption Time: 3.26773
PPO Batch Consumption Time: 0.24302
Total Iteration Time: 7.44559
Cumulative Model Updates: 162,008
Cumulative Timesteps: 1,266,350,372
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.87674
Policy Entropy: 4.35514
Value Function Loss: 0.00229
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.90601
Value Function Update Magnitude: 0.69274
Collected Steps per Second: 12,588.33501
Overall Steps per Second: 6,855.08544
Timestep Collection Time: 3.97511
Timestep Consumption Time: 3.32458
PPO Batch Consumption Time: 0.23504
Total Iteration Time: 7.29969
Cumulative Model Updates: 162,017
Cumulative Timesteps: 1,266,400,412
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1266400412...
Checkpoint 1266400412 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.58479
Policy Entropy: 4.35513
Value Function Loss: 0.00232
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.91681
Value Function Update Magnitude: 0.67189
Collected Steps per Second: 11,666.06447
Overall Steps per Second: 6,669.73911
Timestep Collection Time: 4.28679
Timestep Consumption Time: 3.21125
PPO Batch Consumption Time: 0.23614
Total Iteration Time: 7.49804
Cumulative Model Updates: 162,026
Cumulative Timesteps: 1,266,450,422
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.78172
Policy Entropy: 4.35376
Value Function Loss: 0.00230
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02922
Policy Update Magnitude: 0.91878
Value Function Update Magnitude: 0.64777
Collected Steps per Second: 12,089.53127
Overall Steps per Second: 6,837.37290
Timestep Collection Time: 4.13763
Timestep Consumption Time: 3.17834
PPO Batch Consumption Time: 0.24026
Total Iteration Time: 7.31597
Cumulative Model Updates: 162,035
Cumulative Timesteps: 1,266,500,444
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1266500444...
Checkpoint 1266500444 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.03006
Policy Entropy: 4.35364
Value Function Loss: 0.00239
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02823
Policy Update Magnitude: 0.91755
Value Function Update Magnitude: 0.65981
Collected Steps per Second: 12,575.13641
Overall Steps per Second: 6,990.57798
Timestep Collection Time: 3.97896
Timestep Consumption Time: 3.17867
PPO Batch Consumption Time: 0.23604
Total Iteration Time: 7.15763
Cumulative Model Updates: 162,044
Cumulative Timesteps: 1,266,550,480
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.94635
Policy Entropy: 4.35458
Value Function Loss: 0.00244
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.93633
Value Function Update Magnitude: 0.74818
Collected Steps per Second: 11,602.28212
Overall Steps per Second: 6,626.20968
Timestep Collection Time: 4.30950
Timestep Consumption Time: 3.23630
PPO Batch Consumption Time: 0.24059
Total Iteration Time: 7.54579
Cumulative Model Updates: 162,053
Cumulative Timesteps: 1,266,600,480
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1266600480...
Checkpoint 1266600480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54840
Policy Entropy: 4.35133
Value Function Loss: 0.00235
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.92664
Value Function Update Magnitude: 0.71742
Collected Steps per Second: 11,836.70386
Overall Steps per Second: 6,821.30045
Timestep Collection Time: 4.22432
Timestep Consumption Time: 3.10596
PPO Batch Consumption Time: 0.23690
Total Iteration Time: 7.33027
Cumulative Model Updates: 162,062
Cumulative Timesteps: 1,266,650,482
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.05706
Policy Entropy: 4.35432
Value Function Loss: 0.00224
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02708
Policy Update Magnitude: 0.90237
Value Function Update Magnitude: 0.68286
Collected Steps per Second: 12,588.62096
Overall Steps per Second: 6,766.54013
Timestep Collection Time: 3.97264
Timestep Consumption Time: 3.41814
PPO Batch Consumption Time: 0.25581
Total Iteration Time: 7.39078
Cumulative Model Updates: 162,071
Cumulative Timesteps: 1,266,700,492
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1266700492...
Checkpoint 1266700492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51224
Policy Entropy: 4.35692
Value Function Loss: 0.00228
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.89796
Value Function Update Magnitude: 0.63337
Collected Steps per Second: 11,793.66738
Overall Steps per Second: 6,548.42246
Timestep Collection Time: 4.24007
Timestep Consumption Time: 3.39627
PPO Batch Consumption Time: 0.25690
Total Iteration Time: 7.63634
Cumulative Model Updates: 162,080
Cumulative Timesteps: 1,266,750,498
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.79935
Policy Entropy: 4.35972
Value Function Loss: 0.00240
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.90127
Value Function Update Magnitude: 0.70645
Collected Steps per Second: 11,377.47371
Overall Steps per Second: 6,623.35326
Timestep Collection Time: 4.39711
Timestep Consumption Time: 3.15616
PPO Batch Consumption Time: 0.23619
Total Iteration Time: 7.55327
Cumulative Model Updates: 162,089
Cumulative Timesteps: 1,266,800,526
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1266800526...
Checkpoint 1266800526 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.74982
Policy Entropy: 4.36011
Value Function Loss: 0.00232
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.89756
Value Function Update Magnitude: 0.75993
Collected Steps per Second: 11,442.98544
Overall Steps per Second: 6,535.65626
Timestep Collection Time: 4.37281
Timestep Consumption Time: 3.28335
PPO Batch Consumption Time: 0.23905
Total Iteration Time: 7.65616
Cumulative Model Updates: 162,098
Cumulative Timesteps: 1,266,850,564
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83912
Policy Entropy: 4.36097
Value Function Loss: 0.00204
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.88211
Value Function Update Magnitude: 0.72806
Collected Steps per Second: 11,839.89463
Overall Steps per Second: 6,563.31079
Timestep Collection Time: 4.22504
Timestep Consumption Time: 3.39673
PPO Batch Consumption Time: 0.25396
Total Iteration Time: 7.62176
Cumulative Model Updates: 162,107
Cumulative Timesteps: 1,266,900,588
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1266900588...
Checkpoint 1266900588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38929
Policy Entropy: 4.36026
Value Function Loss: 0.00217
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.89020
Value Function Update Magnitude: 0.71456
Collected Steps per Second: 12,448.62089
Overall Steps per Second: 6,755.46925
Timestep Collection Time: 4.01924
Timestep Consumption Time: 3.38720
PPO Batch Consumption Time: 0.25290
Total Iteration Time: 7.40644
Cumulative Model Updates: 162,116
Cumulative Timesteps: 1,266,950,622
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98639
Policy Entropy: 4.35700
Value Function Loss: 0.00230
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02627
Policy Update Magnitude: 0.90810
Value Function Update Magnitude: 0.68698
Collected Steps per Second: 11,628.37832
Overall Steps per Second: 6,476.01652
Timestep Collection Time: 4.30241
Timestep Consumption Time: 3.42302
PPO Batch Consumption Time: 0.24821
Total Iteration Time: 7.72543
Cumulative Model Updates: 162,125
Cumulative Timesteps: 1,267,000,652
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1267000652...
Checkpoint 1267000652 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34701
Policy Entropy: 4.35880
Value Function Loss: 0.00235
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.91137
Value Function Update Magnitude: 0.73094
Collected Steps per Second: 11,411.14520
Overall Steps per Second: 6,527.65407
Timestep Collection Time: 4.38203
Timestep Consumption Time: 3.27830
PPO Batch Consumption Time: 0.23840
Total Iteration Time: 7.66033
Cumulative Model Updates: 162,134
Cumulative Timesteps: 1,267,050,656
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.50308
Policy Entropy: 4.35501
Value Function Loss: 0.00234
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02382
Policy Update Magnitude: 0.91932
Value Function Update Magnitude: 0.77400
Collected Steps per Second: 12,338.96271
Overall Steps per Second: 6,683.72616
Timestep Collection Time: 4.05334
Timestep Consumption Time: 3.42961
PPO Batch Consumption Time: 0.25324
Total Iteration Time: 7.48295
Cumulative Model Updates: 162,143
Cumulative Timesteps: 1,267,100,670
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1267100670...
Checkpoint 1267100670 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43324
Policy Entropy: 4.35768
Value Function Loss: 0.00215
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.90650
Value Function Update Magnitude: 0.73930
Collected Steps per Second: 12,063.83540
Overall Steps per Second: 6,645.21178
Timestep Collection Time: 4.14661
Timestep Consumption Time: 3.38122
PPO Batch Consumption Time: 0.25238
Total Iteration Time: 7.52783
Cumulative Model Updates: 162,152
Cumulative Timesteps: 1,267,150,694
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50164
Policy Entropy: 4.35721
Value Function Loss: 0.00227
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02753
Policy Update Magnitude: 0.91055
Value Function Update Magnitude: 0.68846
Collected Steps per Second: 11,632.41548
Overall Steps per Second: 6,696.45740
Timestep Collection Time: 4.30091
Timestep Consumption Time: 3.17020
PPO Batch Consumption Time: 0.23703
Total Iteration Time: 7.47111
Cumulative Model Updates: 162,161
Cumulative Timesteps: 1,267,200,724
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1267200724...
Checkpoint 1267200724 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53748
Policy Entropy: 4.36000
Value Function Loss: 0.00214
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.90871
Value Function Update Magnitude: 0.74005
Collected Steps per Second: 11,475.13424
Overall Steps per Second: 6,522.03659
Timestep Collection Time: 4.35725
Timestep Consumption Time: 3.30907
PPO Batch Consumption Time: 0.23985
Total Iteration Time: 7.66632
Cumulative Model Updates: 162,170
Cumulative Timesteps: 1,267,250,724
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.53898
Policy Entropy: 4.35959
Value Function Loss: 0.00225
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.89634
Value Function Update Magnitude: 0.73104
Collected Steps per Second: 12,184.94904
Overall Steps per Second: 6,678.15438
Timestep Collection Time: 4.10703
Timestep Consumption Time: 3.38665
PPO Batch Consumption Time: 0.25437
Total Iteration Time: 7.49369
Cumulative Model Updates: 162,179
Cumulative Timesteps: 1,267,300,768
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1267300768...
Checkpoint 1267300768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.69028
Policy Entropy: 4.35993
Value Function Loss: 0.00227
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.90263
Value Function Update Magnitude: 0.73193
Collected Steps per Second: 12,385.91096
Overall Steps per Second: 6,699.97091
Timestep Collection Time: 4.03733
Timestep Consumption Time: 3.42629
PPO Batch Consumption Time: 0.25886
Total Iteration Time: 7.46361
Cumulative Model Updates: 162,188
Cumulative Timesteps: 1,267,350,774
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.51381
Policy Entropy: 4.35802
Value Function Loss: 0.00220
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.91634
Value Function Update Magnitude: 0.74365
Collected Steps per Second: 11,662.64994
Overall Steps per Second: 6,640.16849
Timestep Collection Time: 4.28753
Timestep Consumption Time: 3.24300
PPO Batch Consumption Time: 0.23624
Total Iteration Time: 7.53053
Cumulative Model Updates: 162,197
Cumulative Timesteps: 1,267,400,778
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1267400778...
Checkpoint 1267400778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72589
Policy Entropy: 4.35846
Value Function Loss: 0.00230
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.90891
Value Function Update Magnitude: 0.73753
Collected Steps per Second: 11,479.11203
Overall Steps per Second: 6,550.23720
Timestep Collection Time: 4.35922
Timestep Consumption Time: 3.28020
PPO Batch Consumption Time: 0.24170
Total Iteration Time: 7.63942
Cumulative Model Updates: 162,206
Cumulative Timesteps: 1,267,450,818
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76990
Policy Entropy: 4.35849
Value Function Loss: 0.00231
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.92472
Value Function Update Magnitude: 0.68581
Collected Steps per Second: 12,570.96319
Overall Steps per Second: 6,752.76056
Timestep Collection Time: 3.98076
Timestep Consumption Time: 3.42984
PPO Batch Consumption Time: 0.25531
Total Iteration Time: 7.41060
Cumulative Model Updates: 162,215
Cumulative Timesteps: 1,267,500,860
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1267500860...
Checkpoint 1267500860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39717
Policy Entropy: 4.36108
Value Function Loss: 0.00218
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03033
Policy Update Magnitude: 0.90099
Value Function Update Magnitude: 0.65723
Collected Steps per Second: 12,148.32336
Overall Steps per Second: 6,725.94463
Timestep Collection Time: 4.11892
Timestep Consumption Time: 3.32063
PPO Batch Consumption Time: 0.24630
Total Iteration Time: 7.43955
Cumulative Model Updates: 162,224
Cumulative Timesteps: 1,267,550,898
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.57171
Policy Entropy: 4.36355
Value Function Loss: 0.00214
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02721
Policy Update Magnitude: 0.88788
Value Function Update Magnitude: 0.68028
Collected Steps per Second: 11,387.36124
Overall Steps per Second: 6,665.06531
Timestep Collection Time: 4.39312
Timestep Consumption Time: 3.11259
PPO Batch Consumption Time: 0.23662
Total Iteration Time: 7.50570
Cumulative Model Updates: 162,233
Cumulative Timesteps: 1,267,600,924
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1267600924...
Checkpoint 1267600924 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44700
Policy Entropy: 4.36672
Value Function Loss: 0.00206
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.87903
Value Function Update Magnitude: 0.68016
Collected Steps per Second: 11,757.97364
Overall Steps per Second: 6,512.01951
Timestep Collection Time: 4.25328
Timestep Consumption Time: 3.42636
PPO Batch Consumption Time: 0.25229
Total Iteration Time: 7.67965
Cumulative Model Updates: 162,242
Cumulative Timesteps: 1,267,650,934
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.60967
Policy Entropy: 4.36574
Value Function Loss: 0.00225
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.89550
Value Function Update Magnitude: 0.68821
Collected Steps per Second: 12,137.18435
Overall Steps per Second: 6,640.61635
Timestep Collection Time: 4.12155
Timestep Consumption Time: 3.41149
PPO Batch Consumption Time: 0.25390
Total Iteration Time: 7.53304
Cumulative Model Updates: 162,251
Cumulative Timesteps: 1,267,700,958
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1267700958...
Checkpoint 1267700958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.39751
Policy Entropy: 4.36519
Value Function Loss: 0.00225
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.91636
Value Function Update Magnitude: 0.69034
Collected Steps per Second: 12,200.91163
Overall Steps per Second: 6,727.73054
Timestep Collection Time: 4.09855
Timestep Consumption Time: 3.33427
PPO Batch Consumption Time: 0.24771
Total Iteration Time: 7.43282
Cumulative Model Updates: 162,260
Cumulative Timesteps: 1,267,750,964
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16537
Policy Entropy: 4.36236
Value Function Loss: 0.00230
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.93097
Value Function Update Magnitude: 0.68939
Collected Steps per Second: 11,415.83441
Overall Steps per Second: 6,576.58063
Timestep Collection Time: 4.38093
Timestep Consumption Time: 3.22363
PPO Batch Consumption Time: 0.23612
Total Iteration Time: 7.60456
Cumulative Model Updates: 162,269
Cumulative Timesteps: 1,267,800,976
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1267800976...
Checkpoint 1267800976 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.65130
Policy Entropy: 4.36230
Value Function Loss: 0.00227
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.94532
Value Function Update Magnitude: 0.67255
Collected Steps per Second: 11,584.84875
Overall Steps per Second: 6,560.15281
Timestep Collection Time: 4.31943
Timestep Consumption Time: 3.30844
PPO Batch Consumption Time: 0.24377
Total Iteration Time: 7.62787
Cumulative Model Updates: 162,278
Cumulative Timesteps: 1,267,851,016
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49562
Policy Entropy: 4.36422
Value Function Loss: 0.00214
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.92056
Value Function Update Magnitude: 0.68369
Collected Steps per Second: 12,758.54185
Overall Steps per Second: 6,778.58417
Timestep Collection Time: 3.92129
Timestep Consumption Time: 3.45930
PPO Batch Consumption Time: 0.25460
Total Iteration Time: 7.38060
Cumulative Model Updates: 162,287
Cumulative Timesteps: 1,267,901,046
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1267901046...
Checkpoint 1267901046 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91481
Policy Entropy: 4.36206
Value Function Loss: 0.00225
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02621
Policy Update Magnitude: 0.92784
Value Function Update Magnitude: 0.70924
Collected Steps per Second: 11,996.42425
Overall Steps per Second: 6,618.74778
Timestep Collection Time: 4.16874
Timestep Consumption Time: 3.38707
PPO Batch Consumption Time: 0.25033
Total Iteration Time: 7.55581
Cumulative Model Updates: 162,296
Cumulative Timesteps: 1,267,951,056
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86707
Policy Entropy: 4.36030
Value Function Loss: 0.00222
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02574
Policy Update Magnitude: 0.94686
Value Function Update Magnitude: 0.71612
Collected Steps per Second: 11,440.02445
Overall Steps per Second: 6,655.91220
Timestep Collection Time: 4.37324
Timestep Consumption Time: 3.14338
PPO Batch Consumption Time: 0.23781
Total Iteration Time: 7.51663
Cumulative Model Updates: 162,305
Cumulative Timesteps: 1,268,001,086
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1268001086...
Checkpoint 1268001086 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82551
Policy Entropy: 4.35806
Value Function Loss: 0.00221
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.92591
Value Function Update Magnitude: 0.68643
Collected Steps per Second: 11,754.32336
Overall Steps per Second: 6,569.73578
Timestep Collection Time: 4.25409
Timestep Consumption Time: 3.35717
PPO Batch Consumption Time: 0.24797
Total Iteration Time: 7.61127
Cumulative Model Updates: 162,314
Cumulative Timesteps: 1,268,051,090
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56393
Policy Entropy: 4.35624
Value Function Loss: 0.00222
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.93713
Value Function Update Magnitude: 0.63734
Collected Steps per Second: 12,296.39202
Overall Steps per Second: 6,667.96133
Timestep Collection Time: 4.06786
Timestep Consumption Time: 3.43368
PPO Batch Consumption Time: 0.25962
Total Iteration Time: 7.50154
Cumulative Model Updates: 162,323
Cumulative Timesteps: 1,268,101,110
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1268101110...
Checkpoint 1268101110 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.89497
Policy Entropy: 4.35642
Value Function Loss: 0.00230
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.94189
Value Function Update Magnitude: 0.67252
Collected Steps per Second: 12,104.33809
Overall Steps per Second: 6,736.46051
Timestep Collection Time: 4.13323
Timestep Consumption Time: 3.29352
PPO Batch Consumption Time: 0.24178
Total Iteration Time: 7.42675
Cumulative Model Updates: 162,332
Cumulative Timesteps: 1,268,151,140
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95845
Policy Entropy: 4.35544
Value Function Loss: 0.00245
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.94309
Value Function Update Magnitude: 0.64848
Collected Steps per Second: 11,326.46285
Overall Steps per Second: 6,548.33400
Timestep Collection Time: 4.41780
Timestep Consumption Time: 3.22354
PPO Batch Consumption Time: 0.23627
Total Iteration Time: 7.64133
Cumulative Model Updates: 162,341
Cumulative Timesteps: 1,268,201,178
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1268201178...
Checkpoint 1268201178 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33382
Policy Entropy: 4.35845
Value Function Loss: 0.00228
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.92678
Value Function Update Magnitude: 0.64952
Collected Steps per Second: 11,577.67388
Overall Steps per Second: 6,487.28618
Timestep Collection Time: 4.32315
Timestep Consumption Time: 3.39225
PPO Batch Consumption Time: 0.25530
Total Iteration Time: 7.71540
Cumulative Model Updates: 162,350
Cumulative Timesteps: 1,268,251,230
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.15310
Policy Entropy: 4.36161
Value Function Loss: 0.00228
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02633
Policy Update Magnitude: 0.89456
Value Function Update Magnitude: 0.63944
Collected Steps per Second: 12,588.48668
Overall Steps per Second: 6,725.17425
Timestep Collection Time: 3.97188
Timestep Consumption Time: 3.46287
PPO Batch Consumption Time: 0.25944
Total Iteration Time: 7.43475
Cumulative Model Updates: 162,359
Cumulative Timesteps: 1,268,301,230
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1268301230...
Checkpoint 1268301230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48826
Policy Entropy: 4.36044
Value Function Loss: 0.00222
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.90572
Value Function Update Magnitude: 0.65159
Collected Steps per Second: 11,672.93386
Overall Steps per Second: 6,599.24387
Timestep Collection Time: 4.28581
Timestep Consumption Time: 3.29506
PPO Batch Consumption Time: 0.24490
Total Iteration Time: 7.58087
Cumulative Model Updates: 162,368
Cumulative Timesteps: 1,268,351,258
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97729
Policy Entropy: 4.36244
Value Function Loss: 0.00228
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.91446
Value Function Update Magnitude: 0.64993
Collected Steps per Second: 11,304.20925
Overall Steps per Second: 6,622.68962
Timestep Collection Time: 4.42773
Timestep Consumption Time: 3.12992
PPO Batch Consumption Time: 0.23654
Total Iteration Time: 7.55765
Cumulative Model Updates: 162,377
Cumulative Timesteps: 1,268,401,310
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1268401310...
Checkpoint 1268401310 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.39058
Policy Entropy: 4.35997
Value Function Loss: 0.00238
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.93010
Value Function Update Magnitude: 0.62993
Collected Steps per Second: 11,653.93464
Overall Steps per Second: 6,521.72984
Timestep Collection Time: 4.29400
Timestep Consumption Time: 3.37912
PPO Batch Consumption Time: 0.24769
Total Iteration Time: 7.67312
Cumulative Model Updates: 162,386
Cumulative Timesteps: 1,268,451,352
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.43069
Policy Entropy: 4.35603
Value Function Loss: 0.00251
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.94294
Value Function Update Magnitude: 0.68094
Collected Steps per Second: 12,534.90221
Overall Steps per Second: 6,761.26415
Timestep Collection Time: 3.98918
Timestep Consumption Time: 3.40648
PPO Batch Consumption Time: 0.25405
Total Iteration Time: 7.39566
Cumulative Model Updates: 162,395
Cumulative Timesteps: 1,268,501,356
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1268501356...
Checkpoint 1268501356 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92204
Policy Entropy: 4.35295
Value Function Loss: 0.00252
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.95718
Value Function Update Magnitude: 0.71994
Collected Steps per Second: 11,960.13206
Overall Steps per Second: 6,805.40144
Timestep Collection Time: 4.18323
Timestep Consumption Time: 3.16858
PPO Batch Consumption Time: 0.24178
Total Iteration Time: 7.35181
Cumulative Model Updates: 162,404
Cumulative Timesteps: 1,268,551,388
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.90360
Policy Entropy: 4.35256
Value Function Loss: 0.00250
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 0.95936
Value Function Update Magnitude: 0.71276
Collected Steps per Second: 11,222.81075
Overall Steps per Second: 6,360.03925
Timestep Collection Time: 4.45521
Timestep Consumption Time: 3.40637
PPO Batch Consumption Time: 0.25039
Total Iteration Time: 7.86159
Cumulative Model Updates: 162,413
Cumulative Timesteps: 1,268,601,388
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1268601388...
Checkpoint 1268601388 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96325
Policy Entropy: 4.35412
Value Function Loss: 0.00223
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 0.93336
Value Function Update Magnitude: 0.67178
Collected Steps per Second: 11,550.25237
Overall Steps per Second: 6,535.99979
Timestep Collection Time: 4.33185
Timestep Consumption Time: 3.32329
PPO Batch Consumption Time: 0.24726
Total Iteration Time: 7.65514
Cumulative Model Updates: 162,422
Cumulative Timesteps: 1,268,651,422
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80426
Policy Entropy: 4.35371
Value Function Loss: 0.00224
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02924
Policy Update Magnitude: 0.92500
Value Function Update Magnitude: 0.65947
Collected Steps per Second: 12,803.87080
Overall Steps per Second: 6,799.63415
Timestep Collection Time: 3.90601
Timestep Consumption Time: 3.44910
PPO Batch Consumption Time: 0.25948
Total Iteration Time: 7.35510
Cumulative Model Updates: 162,431
Cumulative Timesteps: 1,268,701,434
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1268701434...
Checkpoint 1268701434 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32247
Policy Entropy: 4.35774
Value Function Loss: 0.00218
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.91412
Value Function Update Magnitude: 0.66076
Collected Steps per Second: 11,642.17606
Overall Steps per Second: 6,580.27657
Timestep Collection Time: 4.29731
Timestep Consumption Time: 3.30572
PPO Batch Consumption Time: 0.24205
Total Iteration Time: 7.60302
Cumulative Model Updates: 162,440
Cumulative Timesteps: 1,268,751,464
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.40651
Policy Entropy: 4.35893
Value Function Loss: 0.00229
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.92297
Value Function Update Magnitude: 0.73202
Collected Steps per Second: 10,932.51652
Overall Steps per Second: 6,503.38216
Timestep Collection Time: 4.57571
Timestep Consumption Time: 3.11629
PPO Batch Consumption Time: 0.23679
Total Iteration Time: 7.69200
Cumulative Model Updates: 162,449
Cumulative Timesteps: 1,268,801,488
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1268801488...
Checkpoint 1268801488 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.42887
Policy Entropy: 4.35819
Value Function Loss: 0.00240
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02904
Policy Update Magnitude: 0.94149
Value Function Update Magnitude: 0.69221
Collected Steps per Second: 11,764.10438
Overall Steps per Second: 6,569.72606
Timestep Collection Time: 4.25209
Timestep Consumption Time: 3.36193
PPO Batch Consumption Time: 0.24657
Total Iteration Time: 7.61402
Cumulative Model Updates: 162,458
Cumulative Timesteps: 1,268,851,510
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02398
Policy Entropy: 4.35552
Value Function Loss: 0.00244
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.95423
Value Function Update Magnitude: 0.67156
Collected Steps per Second: 11,232.06298
Overall Steps per Second: 6,213.06916
Timestep Collection Time: 4.45475
Timestep Consumption Time: 3.59860
PPO Batch Consumption Time: 0.26700
Total Iteration Time: 8.05335
Cumulative Model Updates: 162,467
Cumulative Timesteps: 1,268,901,546
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1268901546...
Checkpoint 1268901546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.32758
Policy Entropy: 4.35698
Value Function Loss: 0.00243
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02801
Policy Update Magnitude: 0.94034
Value Function Update Magnitude: 0.69873
Collected Steps per Second: 11,917.31791
Overall Steps per Second: 6,673.89423
Timestep Collection Time: 4.19625
Timestep Consumption Time: 3.29683
PPO Batch Consumption Time: 0.25330
Total Iteration Time: 7.49308
Cumulative Model Updates: 162,476
Cumulative Timesteps: 1,268,951,554
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.03073
Policy Entropy: 4.35924
Value Function Loss: 0.00243
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.95139
Value Function Update Magnitude: 0.72601
Collected Steps per Second: 10,173.96764
Overall Steps per Second: 5,908.34005
Timestep Collection Time: 4.91490
Timestep Consumption Time: 3.54839
PPO Batch Consumption Time: 0.25368
Total Iteration Time: 8.46329
Cumulative Model Updates: 162,485
Cumulative Timesteps: 1,269,001,558
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1269001558...
Checkpoint 1269001558 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61314
Policy Entropy: 4.35822
Value Function Loss: 0.00242
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.96333
Value Function Update Magnitude: 0.72672
Collected Steps per Second: 10,117.02248
Overall Steps per Second: 6,045.94008
Timestep Collection Time: 4.94592
Timestep Consumption Time: 3.33038
PPO Batch Consumption Time: 0.24009
Total Iteration Time: 8.27630
Cumulative Model Updates: 162,494
Cumulative Timesteps: 1,269,051,596
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30024
Policy Entropy: 4.35755
Value Function Loss: 0.00250
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02756
Policy Update Magnitude: 0.98802
Value Function Update Magnitude: 0.72757
Collected Steps per Second: 11,103.67261
Overall Steps per Second: 6,213.92082
Timestep Collection Time: 4.50554
Timestep Consumption Time: 3.54542
PPO Batch Consumption Time: 0.25279
Total Iteration Time: 8.05096
Cumulative Model Updates: 162,503
Cumulative Timesteps: 1,269,101,624
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1269101624...
Checkpoint 1269101624 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.75813
Policy Entropy: 4.35832
Value Function Loss: 0.00243
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02800
Policy Update Magnitude: 0.98413
Value Function Update Magnitude: 0.72256
Collected Steps per Second: 11,298.58505
Overall Steps per Second: 6,324.67098
Timestep Collection Time: 4.42551
Timestep Consumption Time: 3.48036
PPO Batch Consumption Time: 0.25761
Total Iteration Time: 7.90587
Cumulative Model Updates: 162,512
Cumulative Timesteps: 1,269,151,626
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48704
Policy Entropy: 4.36039
Value Function Loss: 0.00245
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.96612
Value Function Update Magnitude: 0.70271
Collected Steps per Second: 11,608.10334
Overall Steps per Second: 6,325.04815
Timestep Collection Time: 4.30940
Timestep Consumption Time: 3.59947
PPO Batch Consumption Time: 0.27609
Total Iteration Time: 7.90887
Cumulative Model Updates: 162,521
Cumulative Timesteps: 1,269,201,650
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1269201650...
Checkpoint 1269201650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05857
Policy Entropy: 4.35881
Value Function Loss: 0.00239
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.95510
Value Function Update Magnitude: 0.72767
Collected Steps per Second: 10,767.26236
Overall Steps per Second: 6,290.51567
Timestep Collection Time: 4.64631
Timestep Consumption Time: 3.30662
PPO Batch Consumption Time: 0.24372
Total Iteration Time: 7.95293
Cumulative Model Updates: 162,530
Cumulative Timesteps: 1,269,251,678
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.94305
Policy Entropy: 4.35851
Value Function Loss: 0.00235
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.94244
Value Function Update Magnitude: 0.68913
Collected Steps per Second: 10,683.86020
Overall Steps per Second: 6,153.57848
Timestep Collection Time: 4.68089
Timestep Consumption Time: 3.44609
PPO Batch Consumption Time: 0.24548
Total Iteration Time: 8.12698
Cumulative Model Updates: 162,539
Cumulative Timesteps: 1,269,301,688
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1269301688...
Checkpoint 1269301688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98512
Policy Entropy: 4.36258
Value Function Loss: 0.00222
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.93023
Value Function Update Magnitude: 0.68429
Collected Steps per Second: 10,779.18437
Overall Steps per Second: 6,159.61131
Timestep Collection Time: 4.63950
Timestep Consumption Time: 3.47952
PPO Batch Consumption Time: 0.26175
Total Iteration Time: 8.11902
Cumulative Model Updates: 162,548
Cumulative Timesteps: 1,269,351,698
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.84061
Policy Entropy: 4.36162
Value Function Loss: 0.00226
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02489
Policy Update Magnitude: 0.90939
Value Function Update Magnitude: 0.68278
Collected Steps per Second: 11,407.11035
Overall Steps per Second: 6,388.20080
Timestep Collection Time: 4.38726
Timestep Consumption Time: 3.44687
PPO Batch Consumption Time: 0.25603
Total Iteration Time: 7.83413
Cumulative Model Updates: 162,557
Cumulative Timesteps: 1,269,401,744
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1269401744...
Checkpoint 1269401744 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.69432
Policy Entropy: 4.35733
Value Function Loss: 0.00237
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.94105
Value Function Update Magnitude: 0.67195
Collected Steps per Second: 11,291.50449
Overall Steps per Second: 6,470.63971
Timestep Collection Time: 4.42899
Timestep Consumption Time: 3.29976
PPO Batch Consumption Time: 0.24397
Total Iteration Time: 7.72876
Cumulative Model Updates: 162,566
Cumulative Timesteps: 1,269,451,754
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87729
Policy Entropy: 4.35515
Value Function Loss: 0.00235
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02910
Policy Update Magnitude: 0.94348
Value Function Update Magnitude: 0.65198
Collected Steps per Second: 11,267.42414
Overall Steps per Second: 6,480.34458
Timestep Collection Time: 4.43899
Timestep Consumption Time: 3.27912
PPO Batch Consumption Time: 0.24917
Total Iteration Time: 7.71811
Cumulative Model Updates: 162,575
Cumulative Timesteps: 1,269,501,770
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1269501770...
Checkpoint 1269501770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57960
Policy Entropy: 4.35848
Value Function Loss: 0.00218
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.90868
Value Function Update Magnitude: 0.62655
Collected Steps per Second: 11,385.78443
Overall Steps per Second: 6,452.08453
Timestep Collection Time: 4.39372
Timestep Consumption Time: 3.35974
PPO Batch Consumption Time: 0.24338
Total Iteration Time: 7.75346
Cumulative Model Updates: 162,584
Cumulative Timesteps: 1,269,551,796
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.99798
Policy Entropy: 4.36240
Value Function Loss: 0.00203
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.90229
Value Function Update Magnitude: 0.62453
Collected Steps per Second: 12,299.34314
Overall Steps per Second: 6,667.87864
Timestep Collection Time: 4.06607
Timestep Consumption Time: 3.43407
PPO Batch Consumption Time: 0.25681
Total Iteration Time: 7.50014
Cumulative Model Updates: 162,593
Cumulative Timesteps: 1,269,601,806
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1269601806...
Checkpoint 1269601806 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.92134
Policy Entropy: 4.36445
Value Function Loss: 0.00207
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02583
Policy Update Magnitude: 0.89668
Value Function Update Magnitude: 0.62769
Collected Steps per Second: 12,091.75111
Overall Steps per Second: 6,731.09943
Timestep Collection Time: 4.13670
Timestep Consumption Time: 3.29447
PPO Batch Consumption Time: 0.24635
Total Iteration Time: 7.43118
Cumulative Model Updates: 162,602
Cumulative Timesteps: 1,269,651,826
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95110
Policy Entropy: 4.36048
Value Function Loss: 0.00228
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02702
Policy Update Magnitude: 0.91941
Value Function Update Magnitude: 0.67259
Collected Steps per Second: 11,334.44527
Overall Steps per Second: 6,554.21951
Timestep Collection Time: 4.41398
Timestep Consumption Time: 3.21927
PPO Batch Consumption Time: 0.23661
Total Iteration Time: 7.63325
Cumulative Model Updates: 162,611
Cumulative Timesteps: 1,269,701,856
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1269701856...
Checkpoint 1269701856 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39288
Policy Entropy: 4.35911
Value Function Loss: 0.00233
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.93206
Value Function Update Magnitude: 0.71347
Collected Steps per Second: 11,781.62526
Overall Steps per Second: 6,555.34842
Timestep Collection Time: 4.24525
Timestep Consumption Time: 3.38455
PPO Batch Consumption Time: 0.24720
Total Iteration Time: 7.62980
Cumulative Model Updates: 162,620
Cumulative Timesteps: 1,269,751,872
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89394
Policy Entropy: 4.35871
Value Function Loss: 0.00235
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 0.94156
Value Function Update Magnitude: 0.68838
Collected Steps per Second: 12,405.47138
Overall Steps per Second: 6,578.14394
Timestep Collection Time: 4.03338
Timestep Consumption Time: 3.57302
PPO Batch Consumption Time: 0.26679
Total Iteration Time: 7.60640
Cumulative Model Updates: 162,629
Cumulative Timesteps: 1,269,801,908
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1269801908...
Checkpoint 1269801908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43580
Policy Entropy: 4.35878
Value Function Loss: 0.00221
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.91619
Value Function Update Magnitude: 0.63623
Collected Steps per Second: 12,093.25665
Overall Steps per Second: 6,700.15261
Timestep Collection Time: 4.13801
Timestep Consumption Time: 3.33078
PPO Batch Consumption Time: 0.24584
Total Iteration Time: 7.46879
Cumulative Model Updates: 162,638
Cumulative Timesteps: 1,269,851,950
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.30082
Policy Entropy: 4.36310
Value Function Loss: 0.00209
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.89903
Value Function Update Magnitude: 0.60022
Collected Steps per Second: 11,354.37248
Overall Steps per Second: 6,641.42125
Timestep Collection Time: 4.40641
Timestep Consumption Time: 3.12692
PPO Batch Consumption Time: 0.23604
Total Iteration Time: 7.53333
Cumulative Model Updates: 162,647
Cumulative Timesteps: 1,269,901,982
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1269901982...
Checkpoint 1269901982 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87061
Policy Entropy: 4.36242
Value Function Loss: 0.00221
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.92245
Value Function Update Magnitude: 0.63630
Collected Steps per Second: 11,719.74444
Overall Steps per Second: 6,559.74226
Timestep Collection Time: 4.27142
Timestep Consumption Time: 3.35997
PPO Batch Consumption Time: 0.24845
Total Iteration Time: 7.63140
Cumulative Model Updates: 162,656
Cumulative Timesteps: 1,269,952,042
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.42302
Policy Entropy: 4.36207
Value Function Loss: 0.00219
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.92952
Value Function Update Magnitude: 0.63416
Collected Steps per Second: 12,496.10371
Overall Steps per Second: 6,748.73270
Timestep Collection Time: 4.00125
Timestep Consumption Time: 3.40755
PPO Batch Consumption Time: 0.25520
Total Iteration Time: 7.40880
Cumulative Model Updates: 162,665
Cumulative Timesteps: 1,270,002,042
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1270002042...
Checkpoint 1270002042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.10501
Policy Entropy: 4.36121
Value Function Loss: 0.00218
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.92995
Value Function Update Magnitude: 0.69309
Collected Steps per Second: 12,028.30193
Overall Steps per Second: 6,816.32742
Timestep Collection Time: 4.15836
Timestep Consumption Time: 3.17961
PPO Batch Consumption Time: 0.24248
Total Iteration Time: 7.33797
Cumulative Model Updates: 162,674
Cumulative Timesteps: 1,270,052,060
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.47949
Policy Entropy: 4.36137
Value Function Loss: 0.00217
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.93364
Value Function Update Magnitude: 0.71610
Collected Steps per Second: 11,326.12704
Overall Steps per Second: 6,435.85036
Timestep Collection Time: 4.41775
Timestep Consumption Time: 3.35682
PPO Batch Consumption Time: 0.24781
Total Iteration Time: 7.77457
Cumulative Model Updates: 162,683
Cumulative Timesteps: 1,270,102,096
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1270102096...
Checkpoint 1270102096 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61686
Policy Entropy: 4.36236
Value Function Loss: 0.00210
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02558
Policy Update Magnitude: 0.93076
Value Function Update Magnitude: 0.69095
Collected Steps per Second: 10,510.14270
Overall Steps per Second: 6,396.43233
Timestep Collection Time: 4.76321
Timestep Consumption Time: 3.06334
PPO Batch Consumption Time: 0.23233
Total Iteration Time: 7.82655
Cumulative Model Updates: 162,692
Cumulative Timesteps: 1,270,152,158
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45588
Policy Entropy: 4.35945
Value Function Loss: 0.00208
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.92098
Value Function Update Magnitude: 0.65941
Collected Steps per Second: 12,040.86352
Overall Steps per Second: 6,748.31697
Timestep Collection Time: 4.15319
Timestep Consumption Time: 3.25725
PPO Batch Consumption Time: 0.24095
Total Iteration Time: 7.41044
Cumulative Model Updates: 162,701
Cumulative Timesteps: 1,270,202,166
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1270202166...
Checkpoint 1270202166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55183
Policy Entropy: 4.36181
Value Function Loss: 0.00195
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.89395
Value Function Update Magnitude: 0.61797
Collected Steps per Second: 12,682.31461
Overall Steps per Second: 7,090.81217
Timestep Collection Time: 3.94471
Timestep Consumption Time: 3.11062
PPO Batch Consumption Time: 0.22974
Total Iteration Time: 7.05533
Cumulative Model Updates: 162,710
Cumulative Timesteps: 1,270,252,194
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25688
Policy Entropy: 4.36108
Value Function Loss: 0.00205
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02691
Policy Update Magnitude: 0.89796
Value Function Update Magnitude: 0.59997
Collected Steps per Second: 12,620.62192
Overall Steps per Second: 6,967.48748
Timestep Collection Time: 3.96446
Timestep Consumption Time: 3.21660
PPO Batch Consumption Time: 0.24686
Total Iteration Time: 7.18107
Cumulative Model Updates: 162,719
Cumulative Timesteps: 1,270,302,228
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1270302228...
Checkpoint 1270302228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30791
Policy Entropy: 4.36471
Value Function Loss: 0.00224
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.90884
Value Function Update Magnitude: 0.66210
Collected Steps per Second: 10,937.70454
Overall Steps per Second: 6,261.44675
Timestep Collection Time: 4.57207
Timestep Consumption Time: 3.41458
PPO Batch Consumption Time: 0.24464
Total Iteration Time: 7.98665
Cumulative Model Updates: 162,728
Cumulative Timesteps: 1,270,352,236
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85304
Policy Entropy: 4.36177
Value Function Loss: 0.00233
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.92845
Value Function Update Magnitude: 0.68083
Collected Steps per Second: 11,134.90295
Overall Steps per Second: 6,366.40036
Timestep Collection Time: 4.49164
Timestep Consumption Time: 3.36429
PPO Batch Consumption Time: 0.25040
Total Iteration Time: 7.85593
Cumulative Model Updates: 162,737
Cumulative Timesteps: 1,270,402,250
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1270402250...
Checkpoint 1270402250 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.54133
Policy Entropy: 4.36263
Value Function Loss: 0.00235
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.93423
Value Function Update Magnitude: 0.68091
Collected Steps per Second: 12,501.63668
Overall Steps per Second: 6,693.07404
Timestep Collection Time: 4.00124
Timestep Consumption Time: 3.47246
PPO Batch Consumption Time: 0.26026
Total Iteration Time: 7.47370
Cumulative Model Updates: 162,746
Cumulative Timesteps: 1,270,452,272
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.13032
Policy Entropy: 4.36147
Value Function Loss: 0.00233
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02780
Policy Update Magnitude: 0.91274
Value Function Update Magnitude: 0.67129
Collected Steps per Second: 11,521.89336
Overall Steps per Second: 6,450.39563
Timestep Collection Time: 4.34009
Timestep Consumption Time: 3.41231
PPO Batch Consumption Time: 0.25042
Total Iteration Time: 7.75239
Cumulative Model Updates: 162,755
Cumulative Timesteps: 1,270,502,278
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1270502278...
Checkpoint 1270502278 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.47720
Policy Entropy: 4.35953
Value Function Loss: 0.00256
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.94417
Value Function Update Magnitude: 0.68525
Collected Steps per Second: 11,125.75988
Overall Steps per Second: 6,539.50694
Timestep Collection Time: 4.49533
Timestep Consumption Time: 3.15264
PPO Batch Consumption Time: 0.23015
Total Iteration Time: 7.64798
Cumulative Model Updates: 162,764
Cumulative Timesteps: 1,270,552,292
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.65968
Policy Entropy: 4.35633
Value Function Loss: 0.00266
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 0.96767
Value Function Update Magnitude: 0.70876
Collected Steps per Second: 11,913.62586
Overall Steps per Second: 6,731.48331
Timestep Collection Time: 4.19973
Timestep Consumption Time: 3.23311
PPO Batch Consumption Time: 0.23747
Total Iteration Time: 7.43283
Cumulative Model Updates: 162,773
Cumulative Timesteps: 1,270,602,326
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1270602326...
Checkpoint 1270602326 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.08352
Policy Entropy: 4.35482
Value Function Loss: 0.00259
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03163
Policy Update Magnitude: 0.94797
Value Function Update Magnitude: 0.68017
Collected Steps per Second: 11,324.44718
Overall Steps per Second: 6,498.70361
Timestep Collection Time: 4.41593
Timestep Consumption Time: 3.27914
PPO Batch Consumption Time: 0.23547
Total Iteration Time: 7.69507
Cumulative Model Updates: 162,782
Cumulative Timesteps: 1,270,652,334
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97640
Policy Entropy: 4.35933
Value Function Loss: 0.00241
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.92872
Value Function Update Magnitude: 0.67398
Collected Steps per Second: 11,916.77274
Overall Steps per Second: 6,845.61294
Timestep Collection Time: 4.19879
Timestep Consumption Time: 3.11042
PPO Batch Consumption Time: 0.23624
Total Iteration Time: 7.30921
Cumulative Model Updates: 162,791
Cumulative Timesteps: 1,270,702,370
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1270702370...
Checkpoint 1270702370 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37800
Policy Entropy: 4.36048
Value Function Loss: 0.00226
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.91832
Value Function Update Magnitude: 0.69500
Collected Steps per Second: 11,932.16269
Overall Steps per Second: 6,778.09570
Timestep Collection Time: 4.19388
Timestep Consumption Time: 3.18902
PPO Batch Consumption Time: 0.23228
Total Iteration Time: 7.38290
Cumulative Model Updates: 162,800
Cumulative Timesteps: 1,270,752,412
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27545
Policy Entropy: 4.36001
Value Function Loss: 0.00218
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.90732
Value Function Update Magnitude: 0.68001
Collected Steps per Second: 13,030.34699
Overall Steps per Second: 6,914.95979
Timestep Collection Time: 3.83919
Timestep Consumption Time: 3.39527
PPO Batch Consumption Time: 0.25530
Total Iteration Time: 7.23446
Cumulative Model Updates: 162,809
Cumulative Timesteps: 1,270,802,438
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1270802438...
Checkpoint 1270802438 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.73522
Policy Entropy: 4.36062
Value Function Loss: 0.00213
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02574
Policy Update Magnitude: 0.88949
Value Function Update Magnitude: 0.66010
Collected Steps per Second: 11,881.51117
Overall Steps per Second: 6,601.98470
Timestep Collection Time: 4.21108
Timestep Consumption Time: 3.36755
PPO Batch Consumption Time: 0.25929
Total Iteration Time: 7.57863
Cumulative Model Updates: 162,818
Cumulative Timesteps: 1,270,852,472
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.26744
Policy Entropy: 4.36169
Value Function Loss: 0.00222
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02648
Policy Update Magnitude: 0.89940
Value Function Update Magnitude: 0.69649
Collected Steps per Second: 11,775.12562
Overall Steps per Second: 6,622.65619
Timestep Collection Time: 4.24658
Timestep Consumption Time: 3.30387
PPO Batch Consumption Time: 0.24262
Total Iteration Time: 7.55044
Cumulative Model Updates: 162,827
Cumulative Timesteps: 1,270,902,476
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1270902476...
Checkpoint 1270902476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.60273
Policy Entropy: 4.36265
Value Function Loss: 0.00222
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.90149
Value Function Update Magnitude: 0.72318
Collected Steps per Second: 11,414.75621
Overall Steps per Second: 6,594.67337
Timestep Collection Time: 4.38415
Timestep Consumption Time: 3.20440
PPO Batch Consumption Time: 0.23600
Total Iteration Time: 7.58855
Cumulative Model Updates: 162,836
Cumulative Timesteps: 1,270,952,520
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.14581
Policy Entropy: 4.35949
Value Function Loss: 0.00231
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.90783
Value Function Update Magnitude: 0.69323
Collected Steps per Second: 11,274.32338
Overall Steps per Second: 6,317.44497
Timestep Collection Time: 4.43911
Timestep Consumption Time: 3.48308
PPO Batch Consumption Time: 0.25832
Total Iteration Time: 7.92219
Cumulative Model Updates: 162,845
Cumulative Timesteps: 1,271,002,568
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1271002568...
Checkpoint 1271002568 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06117
Policy Entropy: 4.36059
Value Function Loss: 0.00214
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.90331
Value Function Update Magnitude: 0.64740
Collected Steps per Second: 11,860.17126
Overall Steps per Second: 6,594.06387
Timestep Collection Time: 4.21832
Timestep Consumption Time: 3.36881
PPO Batch Consumption Time: 0.25108
Total Iteration Time: 7.58713
Cumulative Model Updates: 162,854
Cumulative Timesteps: 1,271,052,598
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18363
Policy Entropy: 4.35806
Value Function Loss: 0.00223
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.88024
Value Function Update Magnitude: 0.67156
Collected Steps per Second: 11,977.91259
Overall Steps per Second: 6,803.25824
Timestep Collection Time: 4.17852
Timestep Consumption Time: 3.17824
PPO Batch Consumption Time: 0.24164
Total Iteration Time: 7.35677
Cumulative Model Updates: 162,863
Cumulative Timesteps: 1,271,102,648
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1271102648...
Checkpoint 1271102648 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.77397
Policy Entropy: 4.36111
Value Function Loss: 0.00212
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.87820
Value Function Update Magnitude: 0.63709
Collected Steps per Second: 11,379.04708
Overall Steps per Second: 6,552.90486
Timestep Collection Time: 4.39474
Timestep Consumption Time: 3.23668
PPO Batch Consumption Time: 0.23608
Total Iteration Time: 7.63142
Cumulative Model Updates: 162,872
Cumulative Timesteps: 1,271,152,656
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.21310
Policy Entropy: 4.35951
Value Function Loss: 0.00212
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.87928
Value Function Update Magnitude: 0.61728
Collected Steps per Second: 11,683.34627
Overall Steps per Second: 6,551.24746
Timestep Collection Time: 4.27994
Timestep Consumption Time: 3.35281
PPO Batch Consumption Time: 0.24626
Total Iteration Time: 7.63274
Cumulative Model Updates: 162,881
Cumulative Timesteps: 1,271,202,660
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1271202660...
Checkpoint 1271202660 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.40695
Policy Entropy: 4.35926
Value Function Loss: 0.00231
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.89889
Value Function Update Magnitude: 0.64665
Collected Steps per Second: 12,452.19677
Overall Steps per Second: 6,820.08630
Timestep Collection Time: 4.01809
Timestep Consumption Time: 3.31818
PPO Batch Consumption Time: 0.25470
Total Iteration Time: 7.33627
Cumulative Model Updates: 162,890
Cumulative Timesteps: 1,271,252,694
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09574
Policy Entropy: 4.35876
Value Function Loss: 0.00227
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.91377
Value Function Update Magnitude: 0.68183
Collected Steps per Second: 11,969.31773
Overall Steps per Second: 6,643.74693
Timestep Collection Time: 4.17852
Timestep Consumption Time: 3.34946
PPO Batch Consumption Time: 0.25048
Total Iteration Time: 7.52798
Cumulative Model Updates: 162,899
Cumulative Timesteps: 1,271,302,708
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1271302708...
Checkpoint 1271302708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.72920
Policy Entropy: 4.35500
Value Function Loss: 0.00239
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02722
Policy Update Magnitude: 0.89652
Value Function Update Magnitude: 0.69623
Collected Steps per Second: 11,272.67063
Overall Steps per Second: 6,502.58879
Timestep Collection Time: 4.43586
Timestep Consumption Time: 3.25400
PPO Batch Consumption Time: 0.23900
Total Iteration Time: 7.68986
Cumulative Model Updates: 162,908
Cumulative Timesteps: 1,271,352,712
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.03168
Policy Entropy: 4.35612
Value Function Loss: 0.00238
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.89588
Value Function Update Magnitude: 0.68845
Collected Steps per Second: 12,031.85229
Overall Steps per Second: 6,610.27536
Timestep Collection Time: 4.15613
Timestep Consumption Time: 3.40875
PPO Batch Consumption Time: 0.25172
Total Iteration Time: 7.56489
Cumulative Model Updates: 162,917
Cumulative Timesteps: 1,271,402,718
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1271402718...
Checkpoint 1271402718 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.60379
Policy Entropy: 4.35761
Value Function Loss: 0.00231
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.90114
Value Function Update Magnitude: 0.69906
Collected Steps per Second: 12,391.35700
Overall Steps per Second: 6,698.61058
Timestep Collection Time: 4.03652
Timestep Consumption Time: 3.43040
PPO Batch Consumption Time: 0.25831
Total Iteration Time: 7.46692
Cumulative Model Updates: 162,926
Cumulative Timesteps: 1,271,452,736
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.17368
Policy Entropy: 4.35797
Value Function Loss: 0.00213
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02723
Policy Update Magnitude: 0.89765
Value Function Update Magnitude: 0.63953
Collected Steps per Second: 11,884.53061
Overall Steps per Second: 6,741.58772
Timestep Collection Time: 4.21018
Timestep Consumption Time: 3.21181
PPO Batch Consumption Time: 0.23900
Total Iteration Time: 7.42199
Cumulative Model Updates: 162,935
Cumulative Timesteps: 1,271,502,772
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1271502772...
Checkpoint 1271502772 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75712
Policy Entropy: 4.36119
Value Function Loss: 0.00196
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.87623
Value Function Update Magnitude: 0.63828
Collected Steps per Second: 11,168.54060
Overall Steps per Second: 6,500.72794
Timestep Collection Time: 4.47865
Timestep Consumption Time: 3.21587
PPO Batch Consumption Time: 0.23781
Total Iteration Time: 7.69452
Cumulative Model Updates: 162,944
Cumulative Timesteps: 1,271,552,792
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.36616
Policy Entropy: 4.36265
Value Function Loss: 0.00205
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.87681
Value Function Update Magnitude: 0.63944
Collected Steps per Second: 11,766.97753
Overall Steps per Second: 6,486.11713
Timestep Collection Time: 4.25190
Timestep Consumption Time: 3.46181
PPO Batch Consumption Time: 0.25719
Total Iteration Time: 7.71371
Cumulative Model Updates: 162,953
Cumulative Timesteps: 1,271,602,824
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1271602824...
Checkpoint 1271602824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16526
Policy Entropy: 4.36165
Value Function Loss: 0.00221
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.89519
Value Function Update Magnitude: 0.68652
Collected Steps per Second: 12,025.90067
Overall Steps per Second: 6,712.38309
Timestep Collection Time: 4.15886
Timestep Consumption Time: 3.29215
PPO Batch Consumption Time: 0.25438
Total Iteration Time: 7.45100
Cumulative Model Updates: 162,962
Cumulative Timesteps: 1,271,652,838
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93145
Policy Entropy: 4.35739
Value Function Loss: 0.00222
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.91219
Value Function Update Magnitude: 0.67163
Collected Steps per Second: 12,005.47368
Overall Steps per Second: 6,752.99738
Timestep Collection Time: 4.16743
Timestep Consumption Time: 3.24143
PPO Batch Consumption Time: 0.23705
Total Iteration Time: 7.40886
Cumulative Model Updates: 162,971
Cumulative Timesteps: 1,271,702,870
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1271702870...
Checkpoint 1271702870 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.13127
Policy Entropy: 4.35862
Value Function Loss: 0.00227
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02816
Policy Update Magnitude: 0.90992
Value Function Update Magnitude: 0.70642
Collected Steps per Second: 11,328.79101
Overall Steps per Second: 6,555.36875
Timestep Collection Time: 4.41601
Timestep Consumption Time: 3.21560
PPO Batch Consumption Time: 0.23662
Total Iteration Time: 7.63161
Cumulative Model Updates: 162,980
Cumulative Timesteps: 1,271,752,898
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71031
Policy Entropy: 4.35733
Value Function Loss: 0.00230
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.91635
Value Function Update Magnitude: 0.68989
Collected Steps per Second: 12,295.27389
Overall Steps per Second: 6,682.10264
Timestep Collection Time: 4.07018
Timestep Consumption Time: 3.41908
PPO Batch Consumption Time: 0.25221
Total Iteration Time: 7.48926
Cumulative Model Updates: 162,989
Cumulative Timesteps: 1,271,802,942
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1271802942...
Checkpoint 1271802942 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27114
Policy Entropy: 4.35708
Value Function Loss: 0.00232
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.92284
Value Function Update Magnitude: 0.66878
Collected Steps per Second: 12,490.76042
Overall Steps per Second: 6,743.24627
Timestep Collection Time: 4.00600
Timestep Consumption Time: 3.41446
PPO Batch Consumption Time: 0.25430
Total Iteration Time: 7.42046
Cumulative Model Updates: 162,998
Cumulative Timesteps: 1,271,852,980
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57484
Policy Entropy: 4.35482
Value Function Loss: 0.00241
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.92754
Value Function Update Magnitude: 0.66841
Collected Steps per Second: 11,786.50596
Overall Steps per Second: 6,642.17585
Timestep Collection Time: 4.24316
Timestep Consumption Time: 3.28630
PPO Batch Consumption Time: 0.24628
Total Iteration Time: 7.52946
Cumulative Model Updates: 163,007
Cumulative Timesteps: 1,271,902,992
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1271902992...
Checkpoint 1271902992 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.79452
Policy Entropy: 4.35812
Value Function Loss: 0.00223
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.91131
Value Function Update Magnitude: 0.66506
Collected Steps per Second: 11,443.04635
Overall Steps per Second: 6,556.98751
Timestep Collection Time: 4.37051
Timestep Consumption Time: 3.25677
PPO Batch Consumption Time: 0.23638
Total Iteration Time: 7.62728
Cumulative Model Updates: 163,016
Cumulative Timesteps: 1,271,953,004
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32579
Policy Entropy: 4.36037
Value Function Loss: 0.00210
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.89311
Value Function Update Magnitude: 0.65837
Collected Steps per Second: 12,122.33733
Overall Steps per Second: 6,608.36761
Timestep Collection Time: 4.12907
Timestep Consumption Time: 3.44526
PPO Batch Consumption Time: 0.25392
Total Iteration Time: 7.57434
Cumulative Model Updates: 163,025
Cumulative Timesteps: 1,272,003,058
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1272003058...
Checkpoint 1272003058 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.94113
Policy Entropy: 4.36418
Value Function Loss: 0.00200
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.87018
Value Function Update Magnitude: 0.67265
Collected Steps per Second: 12,445.98630
Overall Steps per Second: 6,845.83309
Timestep Collection Time: 4.02009
Timestep Consumption Time: 3.28859
PPO Batch Consumption Time: 0.25681
Total Iteration Time: 7.30868
Cumulative Model Updates: 163,034
Cumulative Timesteps: 1,272,053,092
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76601
Policy Entropy: 4.36462
Value Function Loss: 0.00207
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.87923
Value Function Update Magnitude: 0.68004
Collected Steps per Second: 11,666.11998
Overall Steps per Second: 6,657.37660
Timestep Collection Time: 4.28677
Timestep Consumption Time: 3.22520
PPO Batch Consumption Time: 0.23582
Total Iteration Time: 7.51197
Cumulative Model Updates: 163,043
Cumulative Timesteps: 1,272,103,102
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1272103102...
Checkpoint 1272103102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51970
Policy Entropy: 4.36421
Value Function Loss: 0.00212
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.88131
Value Function Update Magnitude: 0.67883
Collected Steps per Second: 11,307.48747
Overall Steps per Second: 6,544.40902
Timestep Collection Time: 4.42326
Timestep Consumption Time: 3.21929
PPO Batch Consumption Time: 0.23691
Total Iteration Time: 7.64255
Cumulative Model Updates: 163,052
Cumulative Timesteps: 1,272,153,118
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90223
Policy Entropy: 4.36473
Value Function Loss: 0.00224
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02451
Policy Update Magnitude: 0.89450
Value Function Update Magnitude: 0.70236
Collected Steps per Second: 12,053.50326
Overall Steps per Second: 6,674.90230
Timestep Collection Time: 4.15182
Timestep Consumption Time: 3.34552
PPO Batch Consumption Time: 0.25765
Total Iteration Time: 7.49734
Cumulative Model Updates: 163,061
Cumulative Timesteps: 1,272,203,162
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1272203162...
Checkpoint 1272203162 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.73402
Policy Entropy: 4.36273
Value Function Loss: 0.00222
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.90182
Value Function Update Magnitude: 0.68463
Collected Steps per Second: 12,256.91338
Overall Steps per Second: 6,686.85731
Timestep Collection Time: 4.07966
Timestep Consumption Time: 3.39830
PPO Batch Consumption Time: 0.25076
Total Iteration Time: 7.47795
Cumulative Model Updates: 163,070
Cumulative Timesteps: 1,272,253,166
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18768
Policy Entropy: 4.36238
Value Function Loss: 0.00222
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.89350
Value Function Update Magnitude: 0.67537
Collected Steps per Second: 11,755.58084
Overall Steps per Second: 6,697.07117
Timestep Collection Time: 4.25500
Timestep Consumption Time: 3.21394
PPO Batch Consumption Time: 0.23649
Total Iteration Time: 7.46894
Cumulative Model Updates: 163,079
Cumulative Timesteps: 1,272,303,186
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1272303186...
Checkpoint 1272303186 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.89399
Policy Entropy: 4.36322
Value Function Loss: 0.00216
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.86987
Value Function Update Magnitude: 0.73570
Collected Steps per Second: 11,910.93969
Overall Steps per Second: 6,644.18489
Timestep Collection Time: 4.20034
Timestep Consumption Time: 3.32955
PPO Batch Consumption Time: 0.24001
Total Iteration Time: 7.52989
Cumulative Model Updates: 163,088
Cumulative Timesteps: 1,272,353,216
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.42042
Policy Entropy: 4.36550
Value Function Loss: 0.00235
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.89186
Value Function Update Magnitude: 0.70327
Collected Steps per Second: 12,434.93207
Overall Steps per Second: 6,701.89401
Timestep Collection Time: 4.02270
Timestep Consumption Time: 3.44116
PPO Batch Consumption Time: 0.25359
Total Iteration Time: 7.46386
Cumulative Model Updates: 163,097
Cumulative Timesteps: 1,272,403,238
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1272403238...
Checkpoint 1272403238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.71604
Policy Entropy: 4.36625
Value Function Loss: 0.00234
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02327
Policy Update Magnitude: 0.91737
Value Function Update Magnitude: 0.72854
Collected Steps per Second: 11,891.80907
Overall Steps per Second: 6,657.44807
Timestep Collection Time: 4.20592
Timestep Consumption Time: 3.30687
PPO Batch Consumption Time: 0.24791
Total Iteration Time: 7.51279
Cumulative Model Updates: 163,106
Cumulative Timesteps: 1,272,453,254
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.63073
Policy Entropy: 4.36279
Value Function Loss: 0.00239
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.92879
Value Function Update Magnitude: 0.77023
Collected Steps per Second: 11,531.55991
Overall Steps per Second: 6,464.43095
Timestep Collection Time: 4.33766
Timestep Consumption Time: 3.40007
PPO Batch Consumption Time: 0.25177
Total Iteration Time: 7.73773
Cumulative Model Updates: 163,115
Cumulative Timesteps: 1,272,503,274
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1272503274...
Checkpoint 1272503274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.53869
Policy Entropy: 4.36100
Value Function Loss: 0.00231
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.92937
Value Function Update Magnitude: 0.76203
Collected Steps per Second: 10,988.08275
Overall Steps per Second: 6,378.35890
Timestep Collection Time: 4.55311
Timestep Consumption Time: 3.29060
PPO Batch Consumption Time: 0.24011
Total Iteration Time: 7.84371
Cumulative Model Updates: 163,124
Cumulative Timesteps: 1,272,553,304
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97519
Policy Entropy: 4.36098
Value Function Loss: 0.00229
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.92781
Value Function Update Magnitude: 0.73122
Collected Steps per Second: 12,167.13260
Overall Steps per Second: 6,886.87241
Timestep Collection Time: 4.10992
Timestep Consumption Time: 3.15114
PPO Batch Consumption Time: 0.23785
Total Iteration Time: 7.26106
Cumulative Model Updates: 163,133
Cumulative Timesteps: 1,272,603,310
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1272603310...
Checkpoint 1272603310 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.86780
Policy Entropy: 4.36012
Value Function Loss: 0.00228
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.93753
Value Function Update Magnitude: 0.69089
Collected Steps per Second: 11,735.27009
Overall Steps per Second: 6,594.50963
Timestep Collection Time: 4.26356
Timestep Consumption Time: 3.32366
PPO Batch Consumption Time: 0.23817
Total Iteration Time: 7.58722
Cumulative Model Updates: 163,142
Cumulative Timesteps: 1,272,653,344
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.69854
Policy Entropy: 4.36212
Value Function Loss: 0.00232
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.93444
Value Function Update Magnitude: 0.74524
Collected Steps per Second: 11,992.80604
Overall Steps per Second: 6,795.35428
Timestep Collection Time: 4.17100
Timestep Consumption Time: 3.19021
PPO Batch Consumption Time: 0.23727
Total Iteration Time: 7.36121
Cumulative Model Updates: 163,151
Cumulative Timesteps: 1,272,703,366
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1272703366...
Checkpoint 1272703366 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22755
Policy Entropy: 4.35994
Value Function Loss: 0.00234
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.91829
Value Function Update Magnitude: 0.76771
Collected Steps per Second: 11,197.23323
Overall Steps per Second: 6,479.45627
Timestep Collection Time: 4.46753
Timestep Consumption Time: 3.25287
PPO Batch Consumption Time: 0.24048
Total Iteration Time: 7.72040
Cumulative Model Updates: 163,160
Cumulative Timesteps: 1,272,753,390
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54034
Policy Entropy: 4.36098
Value Function Loss: 0.00214
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.89615
Value Function Update Magnitude: 0.73775
Collected Steps per Second: 11,391.92225
Overall Steps per Second: 6,385.97505
Timestep Collection Time: 4.38907
Timestep Consumption Time: 3.44058
PPO Batch Consumption Time: 0.25277
Total Iteration Time: 7.82966
Cumulative Model Updates: 163,169
Cumulative Timesteps: 1,272,803,390
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1272803390...
Checkpoint 1272803390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.07938
Policy Entropy: 4.35988
Value Function Loss: 0.00210
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.89423
Value Function Update Magnitude: 0.72574
Collected Steps per Second: 11,489.00014
Overall Steps per Second: 6,619.26551
Timestep Collection Time: 4.35460
Timestep Consumption Time: 3.20364
PPO Batch Consumption Time: 0.23863
Total Iteration Time: 7.55824
Cumulative Model Updates: 163,178
Cumulative Timesteps: 1,272,853,420
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25256
Policy Entropy: 4.36279
Value Function Loss: 0.00203
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.89353
Value Function Update Magnitude: 0.72734
Collected Steps per Second: 11,441.82828
Overall Steps per Second: 6,522.69871
Timestep Collection Time: 4.37570
Timestep Consumption Time: 3.29996
PPO Batch Consumption Time: 0.24073
Total Iteration Time: 7.67566
Cumulative Model Updates: 163,187
Cumulative Timesteps: 1,272,903,486
Timesteps Collected: 50,066
--------END ITERATION REPORT--------
Saving checkpoint 1272903486...
Checkpoint 1272903486 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25507
Policy Entropy: 4.36123
Value Function Loss: 0.00219
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.90731
Value Function Update Magnitude: 0.68374
Collected Steps per Second: 11,301.72312
Overall Steps per Second: 6,547.01763
Timestep Collection Time: 4.42428
Timestep Consumption Time: 3.21309
PPO Batch Consumption Time: 0.23766
Total Iteration Time: 7.63737
Cumulative Model Updates: 163,196
Cumulative Timesteps: 1,272,953,488
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.62221
Policy Entropy: 4.35804
Value Function Loss: 0.00255
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.96220
Value Function Update Magnitude: 0.70031
Collected Steps per Second: 11,792.13334
Overall Steps per Second: 6,687.02306
Timestep Collection Time: 4.24096
Timestep Consumption Time: 3.23770
PPO Batch Consumption Time: 0.24430
Total Iteration Time: 7.47866
Cumulative Model Updates: 163,205
Cumulative Timesteps: 1,273,003,498
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1273003498...
Checkpoint 1273003498 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09384
Policy Entropy: 4.35505
Value Function Loss: 0.00252
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.95546
Value Function Update Magnitude: 0.74167
Collected Steps per Second: 11,846.61553
Overall Steps per Second: 6,745.50617
Timestep Collection Time: 4.22315
Timestep Consumption Time: 3.19364
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 7.41679
Cumulative Model Updates: 163,214
Cumulative Timesteps: 1,273,053,528
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.35384
Policy Entropy: 4.35531
Value Function Loss: 0.00238
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02745
Policy Update Magnitude: 0.93054
Value Function Update Magnitude: 0.75244
Collected Steps per Second: 12,501.90767
Overall Steps per Second: 6,973.18407
Timestep Collection Time: 4.00227
Timestep Consumption Time: 3.17322
PPO Batch Consumption Time: 0.23655
Total Iteration Time: 7.17549
Cumulative Model Updates: 163,223
Cumulative Timesteps: 1,273,103,564
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1273103564...
Checkpoint 1273103564 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85456
Policy Entropy: 4.35813
Value Function Loss: 0.00228
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.93017
Value Function Update Magnitude: 0.68004
Collected Steps per Second: 13,099.89334
Overall Steps per Second: 7,086.81516
Timestep Collection Time: 3.81835
Timestep Consumption Time: 3.23983
PPO Batch Consumption Time: 0.24015
Total Iteration Time: 7.05818
Cumulative Model Updates: 163,232
Cumulative Timesteps: 1,273,153,584
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.83011
Policy Entropy: 4.35853
Value Function Loss: 0.00244
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.93502
Value Function Update Magnitude: 0.67185
Collected Steps per Second: 12,815.21908
Overall Steps per Second: 7,124.24463
Timestep Collection Time: 3.90302
Timestep Consumption Time: 3.11780
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 7.02081
Cumulative Model Updates: 163,241
Cumulative Timesteps: 1,273,203,602
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1273203602...
Checkpoint 1273203602 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.93345
Policy Entropy: 4.35436
Value Function Loss: 0.00271
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02756
Policy Update Magnitude: 0.94523
Value Function Update Magnitude: 0.70854
Collected Steps per Second: 13,214.26791
Overall Steps per Second: 7,270.42574
Timestep Collection Time: 3.78561
Timestep Consumption Time: 3.09487
PPO Batch Consumption Time: 0.22951
Total Iteration Time: 6.88048
Cumulative Model Updates: 163,250
Cumulative Timesteps: 1,273,253,626
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84259
Policy Entropy: 4.35262
Value Function Loss: 0.00264
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02885
Policy Update Magnitude: 0.95760
Value Function Update Magnitude: 0.73513
Collected Steps per Second: 13,589.92774
Overall Steps per Second: 7,341.31138
Timestep Collection Time: 3.67978
Timestep Consumption Time: 3.13208
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.81186
Cumulative Model Updates: 163,259
Cumulative Timesteps: 1,273,303,634
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1273303634...
Checkpoint 1273303634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.91493
Policy Entropy: 4.35001
Value Function Loss: 0.00260
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 0.96206
Value Function Update Magnitude: 0.72100
Collected Steps per Second: 13,288.50682
Overall Steps per Second: 7,255.97611
Timestep Collection Time: 3.76551
Timestep Consumption Time: 3.13060
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.89611
Cumulative Model Updates: 163,268
Cumulative Timesteps: 1,273,353,672
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11319
Policy Entropy: 4.35183
Value Function Loss: 0.00252
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.96502
Value Function Update Magnitude: 0.68383
Collected Steps per Second: 13,055.80127
Overall Steps per Second: 7,289.88991
Timestep Collection Time: 3.83048
Timestep Consumption Time: 3.02970
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.86019
Cumulative Model Updates: 163,277
Cumulative Timesteps: 1,273,403,682
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1273403682...
Checkpoint 1273403682 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54669
Policy Entropy: 4.35425
Value Function Loss: 0.00247
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02960
Policy Update Magnitude: 0.94464
Value Function Update Magnitude: 0.64276
Collected Steps per Second: 13,259.55482
Overall Steps per Second: 7,248.48730
Timestep Collection Time: 3.77102
Timestep Consumption Time: 3.12725
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.89827
Cumulative Model Updates: 163,286
Cumulative Timesteps: 1,273,453,684
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.42964
Policy Entropy: 4.35410
Value Function Loss: 0.00241
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.93393
Value Function Update Magnitude: 0.62502
Collected Steps per Second: 13,214.68892
Overall Steps per Second: 7,122.73431
Timestep Collection Time: 3.78518
Timestep Consumption Time: 3.23740
PPO Batch Consumption Time: 0.24106
Total Iteration Time: 7.02258
Cumulative Model Updates: 163,295
Cumulative Timesteps: 1,273,503,704
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1273503704...
Checkpoint 1273503704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02514
Policy Entropy: 4.35597
Value Function Loss: 0.00228
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.91545
Value Function Update Magnitude: 0.59483
Collected Steps per Second: 13,219.92947
Overall Steps per Second: 7,333.00502
Timestep Collection Time: 3.78262
Timestep Consumption Time: 3.03668
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.81931
Cumulative Model Updates: 163,304
Cumulative Timesteps: 1,273,553,710
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.64839
Policy Entropy: 4.35430
Value Function Loss: 0.00235
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.92851
Value Function Update Magnitude: 0.64402
Collected Steps per Second: 13,142.45746
Overall Steps per Second: 7,215.69953
Timestep Collection Time: 3.80675
Timestep Consumption Time: 3.12675
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.93349
Cumulative Model Updates: 163,313
Cumulative Timesteps: 1,273,603,740
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1273603740...
Checkpoint 1273603740 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.90289
Policy Entropy: 4.35332
Value Function Loss: 0.00233
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.92510
Value Function Update Magnitude: 0.68007
Collected Steps per Second: 13,055.18493
Overall Steps per Second: 7,223.75317
Timestep Collection Time: 3.83204
Timestep Consumption Time: 3.09345
PPO Batch Consumption Time: 0.22975
Total Iteration Time: 6.92549
Cumulative Model Updates: 163,322
Cumulative Timesteps: 1,273,653,768
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96721
Policy Entropy: 4.35373
Value Function Loss: 0.00231
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.92687
Value Function Update Magnitude: 0.69388
Collected Steps per Second: 13,121.89792
Overall Steps per Second: 7,224.43234
Timestep Collection Time: 3.81042
Timestep Consumption Time: 3.11053
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.92096
Cumulative Model Updates: 163,331
Cumulative Timesteps: 1,273,703,768
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1273703768...
Checkpoint 1273703768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.62361
Policy Entropy: 4.35517
Value Function Loss: 0.00228
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.92069
Value Function Update Magnitude: 0.69478
Collected Steps per Second: 13,155.52033
Overall Steps per Second: 7,216.64917
Timestep Collection Time: 3.80373
Timestep Consumption Time: 3.13024
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.93397
Cumulative Model Updates: 163,340
Cumulative Timesteps: 1,273,753,808
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51092
Policy Entropy: 4.35878
Value Function Loss: 0.00223
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.91502
Value Function Update Magnitude: 0.66919
Collected Steps per Second: 13,254.16820
Overall Steps per Second: 7,284.44283
Timestep Collection Time: 3.77542
Timestep Consumption Time: 3.09402
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.86943
Cumulative Model Updates: 163,349
Cumulative Timesteps: 1,273,803,848
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1273803848...
Checkpoint 1273803848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88181
Policy Entropy: 4.35806
Value Function Loss: 0.00224
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.91988
Value Function Update Magnitude: 0.65893
Collected Steps per Second: 13,386.18317
Overall Steps per Second: 7,240.35548
Timestep Collection Time: 3.73579
Timestep Consumption Time: 3.17105
PPO Batch Consumption Time: 0.23346
Total Iteration Time: 6.90684
Cumulative Model Updates: 163,358
Cumulative Timesteps: 1,273,853,856
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.46791
Policy Entropy: 4.35937
Value Function Loss: 0.00214
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02614
Policy Update Magnitude: 0.91755
Value Function Update Magnitude: 0.63744
Collected Steps per Second: 13,188.28713
Overall Steps per Second: 7,222.82465
Timestep Collection Time: 3.79337
Timestep Consumption Time: 3.13301
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.92638
Cumulative Model Updates: 163,367
Cumulative Timesteps: 1,273,903,884
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1273903884...
Checkpoint 1273903884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.23369
Policy Entropy: 4.35651
Value Function Loss: 0.00229
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.93350
Value Function Update Magnitude: 0.63932
Collected Steps per Second: 13,278.43265
Overall Steps per Second: 7,360.89134
Timestep Collection Time: 3.76731
Timestep Consumption Time: 3.02860
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.79592
Cumulative Model Updates: 163,376
Cumulative Timesteps: 1,273,953,908
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92150
Policy Entropy: 4.35602
Value Function Loss: 0.00235
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.94090
Value Function Update Magnitude: 0.65922
Collected Steps per Second: 13,337.02595
Overall Steps per Second: 7,259.34304
Timestep Collection Time: 3.75091
Timestep Consumption Time: 3.14035
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.89126
Cumulative Model Updates: 163,385
Cumulative Timesteps: 1,274,003,934
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1274003934...
Checkpoint 1274003934 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.22338
Policy Entropy: 4.35288
Value Function Loss: 0.00252
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.94844
Value Function Update Magnitude: 0.62998
Collected Steps per Second: 13,315.19273
Overall Steps per Second: 7,270.07219
Timestep Collection Time: 3.75526
Timestep Consumption Time: 3.12253
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.87779
Cumulative Model Updates: 163,394
Cumulative Timesteps: 1,274,053,936
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32635
Policy Entropy: 4.35359
Value Function Loss: 0.00258
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.96514
Value Function Update Magnitude: 0.63983
Collected Steps per Second: 13,170.34277
Overall Steps per Second: 7,320.66554
Timestep Collection Time: 3.79747
Timestep Consumption Time: 3.03442
PPO Batch Consumption Time: 0.22926
Total Iteration Time: 6.83189
Cumulative Model Updates: 163,403
Cumulative Timesteps: 1,274,103,950
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1274103950...
Checkpoint 1274103950 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.25765
Policy Entropy: 4.34973
Value Function Loss: 0.00269
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.96413
Value Function Update Magnitude: 0.66118
Collected Steps per Second: 13,138.51833
Overall Steps per Second: 7,200.08812
Timestep Collection Time: 3.80713
Timestep Consumption Time: 3.14001
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.94714
Cumulative Model Updates: 163,412
Cumulative Timesteps: 1,274,153,970
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53882
Policy Entropy: 4.35139
Value Function Loss: 0.00271
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02721
Policy Update Magnitude: 0.98597
Value Function Update Magnitude: 0.71255
Collected Steps per Second: 13,056.33470
Overall Steps per Second: 7,110.85689
Timestep Collection Time: 3.83293
Timestep Consumption Time: 3.20476
PPO Batch Consumption Time: 0.24023
Total Iteration Time: 7.03769
Cumulative Model Updates: 163,421
Cumulative Timesteps: 1,274,204,014
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1274204014...
Checkpoint 1274204014 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.21514
Policy Entropy: 4.35012
Value Function Loss: 0.00259
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02939
Policy Update Magnitude: 0.97062
Value Function Update Magnitude: 0.74611
Collected Steps per Second: 13,371.13592
Overall Steps per Second: 7,307.24032
Timestep Collection Time: 3.74239
Timestep Consumption Time: 3.10561
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.84800
Cumulative Model Updates: 163,430
Cumulative Timesteps: 1,274,254,054
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99966
Policy Entropy: 4.35262
Value Function Loss: 0.00257
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.98439
Value Function Update Magnitude: 0.71891
Collected Steps per Second: 13,294.28559
Overall Steps per Second: 7,218.61658
Timestep Collection Time: 3.76237
Timestep Consumption Time: 3.16666
PPO Batch Consumption Time: 0.22925
Total Iteration Time: 6.92903
Cumulative Model Updates: 163,439
Cumulative Timesteps: 1,274,304,072
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1274304072...
Checkpoint 1274304072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16861
Policy Entropy: 4.35158
Value Function Loss: 0.00243
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.97796
Value Function Update Magnitude: 0.72587
Collected Steps per Second: 13,136.05525
Overall Steps per Second: 7,310.21473
Timestep Collection Time: 3.81028
Timestep Consumption Time: 3.03658
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.84686
Cumulative Model Updates: 163,448
Cumulative Timesteps: 1,274,354,124
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.49234
Policy Entropy: 4.34926
Value Function Loss: 0.00267
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 1.00023
Value Function Update Magnitude: 0.70946
Collected Steps per Second: 13,197.03295
Overall Steps per Second: 7,220.03753
Timestep Collection Time: 3.78964
Timestep Consumption Time: 3.13719
PPO Batch Consumption Time: 0.22980
Total Iteration Time: 6.92683
Cumulative Model Updates: 163,457
Cumulative Timesteps: 1,274,404,136
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1274404136...
Checkpoint 1274404136 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57276
Policy Entropy: 4.34761
Value Function Loss: 0.00265
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.99919
Value Function Update Magnitude: 0.71199
Collected Steps per Second: 13,269.14590
Overall Steps per Second: 7,285.84778
Timestep Collection Time: 3.76965
Timestep Consumption Time: 3.09572
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.86536
Cumulative Model Updates: 163,466
Cumulative Timesteps: 1,274,454,156
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.27306
Policy Entropy: 4.34803
Value Function Loss: 0.00265
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.96903
Value Function Update Magnitude: 0.74997
Collected Steps per Second: 13,585.06790
Overall Steps per Second: 7,347.80279
Timestep Collection Time: 3.68051
Timestep Consumption Time: 3.12424
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.80476
Cumulative Model Updates: 163,475
Cumulative Timesteps: 1,274,504,156
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1274504156...
Checkpoint 1274504156 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.92571
Policy Entropy: 4.34498
Value Function Loss: 0.00261
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02690
Policy Update Magnitude: 0.97742
Value Function Update Magnitude: 0.79153
Collected Steps per Second: 13,002.25865
Overall Steps per Second: 6,958.96693
Timestep Collection Time: 3.84610
Timestep Consumption Time: 3.34002
PPO Batch Consumption Time: 0.24569
Total Iteration Time: 7.18612
Cumulative Model Updates: 163,484
Cumulative Timesteps: 1,274,554,164
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.35972
Policy Entropy: 4.34766
Value Function Loss: 0.00238
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.96250
Value Function Update Magnitude: 0.71995
Collected Steps per Second: 13,322.30837
Overall Steps per Second: 7,304.54367
Timestep Collection Time: 3.75536
Timestep Consumption Time: 3.09381
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.84916
Cumulative Model Updates: 163,493
Cumulative Timesteps: 1,274,604,194
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1274604194...
Checkpoint 1274604194 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.55241
Policy Entropy: 4.34795
Value Function Loss: 0.00255
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02978
Policy Update Magnitude: 0.95585
Value Function Update Magnitude: 0.75184
Collected Steps per Second: 13,395.89860
Overall Steps per Second: 7,299.64993
Timestep Collection Time: 3.73293
Timestep Consumption Time: 3.11753
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.85047
Cumulative Model Updates: 163,502
Cumulative Timesteps: 1,274,654,200
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34819
Policy Entropy: 4.35176
Value Function Loss: 0.00235
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.94770
Value Function Update Magnitude: 0.79411
Collected Steps per Second: 13,481.84798
Overall Steps per Second: 7,323.85235
Timestep Collection Time: 3.71092
Timestep Consumption Time: 3.12019
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.83110
Cumulative Model Updates: 163,511
Cumulative Timesteps: 1,274,704,230
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1274704230...
Checkpoint 1274704230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50430
Policy Entropy: 4.35105
Value Function Loss: 0.00240
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02958
Policy Update Magnitude: 0.95274
Value Function Update Magnitude: 0.78867
Collected Steps per Second: 13,144.85145
Overall Steps per Second: 7,322.40333
Timestep Collection Time: 3.80605
Timestep Consumption Time: 3.02640
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.83246
Cumulative Model Updates: 163,520
Cumulative Timesteps: 1,274,754,260
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71340
Policy Entropy: 4.35070
Value Function Loss: 0.00229
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 0.96151
Value Function Update Magnitude: 0.72756
Collected Steps per Second: 13,099.51403
Overall Steps per Second: 7,199.40684
Timestep Collection Time: 3.81755
Timestep Consumption Time: 3.12858
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.94613
Cumulative Model Updates: 163,529
Cumulative Timesteps: 1,274,804,268
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1274804268...
Checkpoint 1274804268 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00168
Policy Entropy: 4.34816
Value Function Loss: 0.00238
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.94487
Value Function Update Magnitude: 0.68076
Collected Steps per Second: 13,123.03561
Overall Steps per Second: 7,194.72090
Timestep Collection Time: 3.81177
Timestep Consumption Time: 3.14083
PPO Batch Consumption Time: 0.23070
Total Iteration Time: 6.95260
Cumulative Model Updates: 163,538
Cumulative Timesteps: 1,274,854,290
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57743
Policy Entropy: 4.34996
Value Function Loss: 0.00220
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02893
Policy Update Magnitude: 0.93331
Value Function Update Magnitude: 0.64390
Collected Steps per Second: 12,817.31082
Overall Steps per Second: 7,130.09175
Timestep Collection Time: 3.90300
Timestep Consumption Time: 3.11318
PPO Batch Consumption Time: 0.23488
Total Iteration Time: 7.01618
Cumulative Model Updates: 163,547
Cumulative Timesteps: 1,274,904,316
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1274904316...
Checkpoint 1274904316 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88439
Policy Entropy: 4.35634
Value Function Loss: 0.00204
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.89591
Value Function Update Magnitude: 0.63792
Collected Steps per Second: 13,112.68957
Overall Steps per Second: 7,210.79542
Timestep Collection Time: 3.81463
Timestep Consumption Time: 3.12220
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.93682
Cumulative Model Updates: 163,556
Cumulative Timesteps: 1,274,954,336
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.34739
Policy Entropy: 4.35836
Value Function Loss: 0.00206
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.89928
Value Function Update Magnitude: 0.60193
Collected Steps per Second: 13,205.04420
Overall Steps per Second: 7,345.65279
Timestep Collection Time: 3.78840
Timestep Consumption Time: 3.02189
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.81029
Cumulative Model Updates: 163,565
Cumulative Timesteps: 1,275,004,362
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1275004362...
Checkpoint 1275004362 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.26055
Policy Entropy: 4.35715
Value Function Loss: 0.00229
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.91885
Value Function Update Magnitude: 0.63051
Collected Steps per Second: 13,343.82654
Overall Steps per Second: 7,267.32950
Timestep Collection Time: 3.74795
Timestep Consumption Time: 3.13381
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.88176
Cumulative Model Updates: 163,574
Cumulative Timesteps: 1,275,054,374
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44596
Policy Entropy: 4.35307
Value Function Loss: 0.00238
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.93508
Value Function Update Magnitude: 0.66849
Collected Steps per Second: 13,082.75016
Overall Steps per Second: 7,225.75181
Timestep Collection Time: 3.82412
Timestep Consumption Time: 3.09973
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.92385
Cumulative Model Updates: 163,583
Cumulative Timesteps: 1,275,104,404
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1275104404...
Checkpoint 1275104404 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.70210
Policy Entropy: 4.35197
Value Function Loss: 0.00239
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.92737
Value Function Update Magnitude: 0.69373
Collected Steps per Second: 12,897.25472
Overall Steps per Second: 7,231.84261
Timestep Collection Time: 3.87912
Timestep Consumption Time: 3.03890
PPO Batch Consumption Time: 0.22933
Total Iteration Time: 6.91802
Cumulative Model Updates: 163,592
Cumulative Timesteps: 1,275,154,434
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17552
Policy Entropy: 4.35198
Value Function Loss: 0.00240
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.92811
Value Function Update Magnitude: 0.70901
Collected Steps per Second: 13,066.77673
Overall Steps per Second: 7,190.83245
Timestep Collection Time: 3.82757
Timestep Consumption Time: 3.12767
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.95524
Cumulative Model Updates: 163,601
Cumulative Timesteps: 1,275,204,448
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1275204448...
Checkpoint 1275204448 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.08218
Policy Entropy: 4.34990
Value Function Loss: 0.00249
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.93942
Value Function Update Magnitude: 0.71674
Collected Steps per Second: 13,085.15718
Overall Steps per Second: 7,026.29505
Timestep Collection Time: 3.82494
Timestep Consumption Time: 3.29830
PPO Batch Consumption Time: 0.24636
Total Iteration Time: 7.12324
Cumulative Model Updates: 163,610
Cumulative Timesteps: 1,275,254,498
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75317
Policy Entropy: 4.35098
Value Function Loss: 0.00245
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.95852
Value Function Update Magnitude: 0.72152
Collected Steps per Second: 13,477.73401
Overall Steps per Second: 7,289.77462
Timestep Collection Time: 3.71056
Timestep Consumption Time: 3.14973
PPO Batch Consumption Time: 0.22966
Total Iteration Time: 6.86029
Cumulative Model Updates: 163,619
Cumulative Timesteps: 1,275,304,508
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1275304508...
Checkpoint 1275304508 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62365
Policy Entropy: 4.34476
Value Function Loss: 0.00260
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.97477
Value Function Update Magnitude: 0.74265
Collected Steps per Second: 13,081.38455
Overall Steps per Second: 7,181.50818
Timestep Collection Time: 3.82330
Timestep Consumption Time: 3.14098
PPO Batch Consumption Time: 0.22949
Total Iteration Time: 6.96428
Cumulative Model Updates: 163,628
Cumulative Timesteps: 1,275,354,522
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18794
Policy Entropy: 4.34614
Value Function Loss: 0.00242
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.97000
Value Function Update Magnitude: 0.75769
Collected Steps per Second: 13,167.70560
Overall Steps per Second: 7,246.42384
Timestep Collection Time: 3.79869
Timestep Consumption Time: 3.10403
PPO Batch Consumption Time: 0.22955
Total Iteration Time: 6.90272
Cumulative Model Updates: 163,637
Cumulative Timesteps: 1,275,404,542
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1275404542...
Checkpoint 1275404542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93417
Policy Entropy: 4.34519
Value Function Loss: 0.00232
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02962
Policy Update Magnitude: 0.92301
Value Function Update Magnitude: 0.71106
Collected Steps per Second: 13,478.73579
Overall Steps per Second: 7,304.46075
Timestep Collection Time: 3.71044
Timestep Consumption Time: 3.13634
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.84678
Cumulative Model Updates: 163,646
Cumulative Timesteps: 1,275,454,554
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.27817
Policy Entropy: 4.35261
Value Function Loss: 0.00222
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.90266
Value Function Update Magnitude: 0.67338
Collected Steps per Second: 13,107.50375
Overall Steps per Second: 7,210.26114
Timestep Collection Time: 3.81720
Timestep Consumption Time: 3.12207
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.93928
Cumulative Model Updates: 163,655
Cumulative Timesteps: 1,275,504,588
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1275504588...
Checkpoint 1275504588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57911
Policy Entropy: 4.35128
Value Function Loss: 0.00235
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02705
Policy Update Magnitude: 0.91657
Value Function Update Magnitude: 0.67376
Collected Steps per Second: 13,103.77166
Overall Steps per Second: 7,332.55377
Timestep Collection Time: 3.81951
Timestep Consumption Time: 3.00621
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.82573
Cumulative Model Updates: 163,664
Cumulative Timesteps: 1,275,554,638
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.78320
Policy Entropy: 4.35545
Value Function Loss: 0.00238
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02816
Policy Update Magnitude: 0.93948
Value Function Update Magnitude: 0.68266
Collected Steps per Second: 13,070.35637
Overall Steps per Second: 7,009.86272
Timestep Collection Time: 3.82545
Timestep Consumption Time: 3.30736
PPO Batch Consumption Time: 0.24237
Total Iteration Time: 7.13281
Cumulative Model Updates: 163,673
Cumulative Timesteps: 1,275,604,638
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1275604638...
Checkpoint 1275604638 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44067
Policy Entropy: 4.35411
Value Function Loss: 0.00232
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.94338
Value Function Update Magnitude: 0.68320
Collected Steps per Second: 13,225.84530
Overall Steps per Second: 7,208.08537
Timestep Collection Time: 3.78048
Timestep Consumption Time: 3.15618
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.93665
Cumulative Model Updates: 163,682
Cumulative Timesteps: 1,275,654,638
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.89769
Policy Entropy: 4.35348
Value Function Loss: 0.00239
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.94476
Value Function Update Magnitude: 0.68135
Collected Steps per Second: 13,487.61795
Overall Steps per Second: 7,336.46124
Timestep Collection Time: 3.71007
Timestep Consumption Time: 3.11066
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.82073
Cumulative Model Updates: 163,691
Cumulative Timesteps: 1,275,704,678
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1275704678...
Checkpoint 1275704678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.85295
Policy Entropy: 4.35003
Value Function Loss: 0.00250
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02880
Policy Update Magnitude: 0.94217
Value Function Update Magnitude: 0.70316
Collected Steps per Second: 13,245.02926
Overall Steps per Second: 7,210.60893
Timestep Collection Time: 3.77802
Timestep Consumption Time: 3.16175
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.93977
Cumulative Model Updates: 163,700
Cumulative Timesteps: 1,275,754,718
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48265
Policy Entropy: 4.34887
Value Function Loss: 0.00279
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.96861
Value Function Update Magnitude: 0.77022
Collected Steps per Second: 13,158.21313
Overall Steps per Second: 7,251.49560
Timestep Collection Time: 3.80204
Timestep Consumption Time: 3.09695
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.89899
Cumulative Model Updates: 163,709
Cumulative Timesteps: 1,275,804,746
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1275804746...
Checkpoint 1275804746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.94170
Policy Entropy: 4.35201
Value Function Loss: 0.00252
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02906
Policy Update Magnitude: 0.94847
Value Function Update Magnitude: 0.77402
Collected Steps per Second: 13,376.27956
Overall Steps per Second: 7,309.44904
Timestep Collection Time: 3.73916
Timestep Consumption Time: 3.10349
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.84265
Cumulative Model Updates: 163,718
Cumulative Timesteps: 1,275,854,762
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41640
Policy Entropy: 4.35358
Value Function Loss: 0.00250
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.92471
Value Function Update Magnitude: 0.71390
Collected Steps per Second: 13,076.03264
Overall Steps per Second: 7,188.16520
Timestep Collection Time: 3.82563
Timestep Consumption Time: 3.13359
PPO Batch Consumption Time: 0.23083
Total Iteration Time: 6.95922
Cumulative Model Updates: 163,727
Cumulative Timesteps: 1,275,904,786
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1275904786...
Checkpoint 1275904786 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16691
Policy Entropy: 4.35280
Value Function Loss: 0.00253
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02684
Policy Update Magnitude: 0.92709
Value Function Update Magnitude: 0.74920
Collected Steps per Second: 12,917.65078
Overall Steps per Second: 7,122.68058
Timestep Collection Time: 3.87160
Timestep Consumption Time: 3.14991
PPO Batch Consumption Time: 0.23999
Total Iteration Time: 7.02151
Cumulative Model Updates: 163,736
Cumulative Timesteps: 1,275,954,798
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46397
Policy Entropy: 4.34656
Value Function Loss: 0.00279
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03042
Policy Update Magnitude: 0.96719
Value Function Update Magnitude: 0.79688
Collected Steps per Second: 13,193.52193
Overall Steps per Second: 7,241.45235
Timestep Collection Time: 3.79050
Timestep Consumption Time: 3.11558
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.90607
Cumulative Model Updates: 163,745
Cumulative Timesteps: 1,276,004,808
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1276004808...
Checkpoint 1276004808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.47546
Policy Entropy: 4.34719
Value Function Loss: 0.00263
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 0.98262
Value Function Update Magnitude: 0.79840
Collected Steps per Second: 13,096.48914
Overall Steps per Second: 7,226.24645
Timestep Collection Time: 3.82041
Timestep Consumption Time: 3.10351
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.92393
Cumulative Model Updates: 163,754
Cumulative Timesteps: 1,276,054,842
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.69295
Policy Entropy: 4.34729
Value Function Loss: 0.00248
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.96783
Value Function Update Magnitude: 0.73722
Collected Steps per Second: 13,549.03326
Overall Steps per Second: 7,331.17955
Timestep Collection Time: 3.69045
Timestep Consumption Time: 3.13001
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 6.82046
Cumulative Model Updates: 163,763
Cumulative Timesteps: 1,276,104,844
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1276104844...
Checkpoint 1276104844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.00047
Policy Entropy: 4.34959
Value Function Loss: 0.00244
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02721
Policy Update Magnitude: 0.94575
Value Function Update Magnitude: 0.75117
Collected Steps per Second: 13,237.57613
Overall Steps per Second: 7,247.62509
Timestep Collection Time: 3.77743
Timestep Consumption Time: 3.12193
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.89936
Cumulative Model Updates: 163,772
Cumulative Timesteps: 1,276,154,848
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.59079
Policy Entropy: 4.35020
Value Function Loss: 0.00255
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.96665
Value Function Update Magnitude: 0.74928
Collected Steps per Second: 13,232.03256
Overall Steps per Second: 7,281.93213
Timestep Collection Time: 3.77977
Timestep Consumption Time: 3.08847
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.86823
Cumulative Model Updates: 163,781
Cumulative Timesteps: 1,276,204,862
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1276204862...
Checkpoint 1276204862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76926
Policy Entropy: 4.34893
Value Function Loss: 0.00254
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 0.97241
Value Function Update Magnitude: 0.73752
Collected Steps per Second: 13,586.25406
Overall Steps per Second: 7,324.88451
Timestep Collection Time: 3.68269
Timestep Consumption Time: 3.14800
PPO Batch Consumption Time: 0.22933
Total Iteration Time: 6.83069
Cumulative Model Updates: 163,790
Cumulative Timesteps: 1,276,254,896
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55400
Policy Entropy: 4.34959
Value Function Loss: 0.00241
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02832
Policy Update Magnitude: 0.94568
Value Function Update Magnitude: 0.72155
Collected Steps per Second: 13,200.19438
Overall Steps per Second: 7,023.56904
Timestep Collection Time: 3.78888
Timestep Consumption Time: 3.33200
PPO Batch Consumption Time: 0.24573
Total Iteration Time: 7.12088
Cumulative Model Updates: 163,799
Cumulative Timesteps: 1,276,304,910
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1276304910...
Checkpoint 1276304910 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49246
Policy Entropy: 4.35227
Value Function Loss: 0.00220
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03039
Policy Update Magnitude: 0.91501
Value Function Update Magnitude: 0.70059
Collected Steps per Second: 13,245.85764
Overall Steps per Second: 7,345.95151
Timestep Collection Time: 3.77658
Timestep Consumption Time: 3.03316
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.80974
Cumulative Model Updates: 163,808
Cumulative Timesteps: 1,276,354,934
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89337
Policy Entropy: 4.35492
Value Function Loss: 0.00218
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.89062
Value Function Update Magnitude: 0.69325
Collected Steps per Second: 13,258.75933
Overall Steps per Second: 7,247.19314
Timestep Collection Time: 3.77245
Timestep Consumption Time: 3.12926
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.90171
Cumulative Model Updates: 163,817
Cumulative Timesteps: 1,276,404,952
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1276404952...
Checkpoint 1276404952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83318
Policy Entropy: 4.35820
Value Function Loss: 0.00217
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02842
Policy Update Magnitude: 0.90274
Value Function Update Magnitude: 0.69595
Collected Steps per Second: 13,145.42023
Overall Steps per Second: 7,243.05305
Timestep Collection Time: 3.80513
Timestep Consumption Time: 3.10080
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.90593
Cumulative Model Updates: 163,826
Cumulative Timesteps: 1,276,454,972
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.19106
Policy Entropy: 4.35576
Value Function Loss: 0.00250
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.95275
Value Function Update Magnitude: 0.69691
Collected Steps per Second: 13,044.62264
Overall Steps per Second: 7,287.71274
Timestep Collection Time: 3.83576
Timestep Consumption Time: 3.03005
PPO Batch Consumption Time: 0.22916
Total Iteration Time: 6.86580
Cumulative Model Updates: 163,835
Cumulative Timesteps: 1,276,505,008
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1276505008...
Checkpoint 1276505008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.49592
Policy Entropy: 4.35018
Value Function Loss: 0.00264
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.98688
Value Function Update Magnitude: 0.72752
Collected Steps per Second: 13,256.01673
Overall Steps per Second: 7,238.84897
Timestep Collection Time: 3.77263
Timestep Consumption Time: 3.13593
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.90856
Cumulative Model Updates: 163,844
Cumulative Timesteps: 1,276,555,018
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81688
Policy Entropy: 4.34899
Value Function Loss: 0.00273
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03005
Policy Update Magnitude: 0.99149
Value Function Update Magnitude: 0.74613
Collected Steps per Second: 13,248.03784
Overall Steps per Second: 7,282.05321
Timestep Collection Time: 3.77550
Timestep Consumption Time: 3.09316
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.86867
Cumulative Model Updates: 163,853
Cumulative Timesteps: 1,276,605,036
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1276605036...
Checkpoint 1276605036 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.69372
Policy Entropy: 4.34413
Value Function Loss: 0.00272
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02990
Policy Update Magnitude: 0.99755
Value Function Update Magnitude: 0.76507
Collected Steps per Second: 13,436.79869
Overall Steps per Second: 7,291.19303
Timestep Collection Time: 3.72529
Timestep Consumption Time: 3.13998
PPO Batch Consumption Time: 0.23178
Total Iteration Time: 6.86527
Cumulative Model Updates: 163,862
Cumulative Timesteps: 1,276,655,092
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35621
Policy Entropy: 4.34480
Value Function Loss: 0.00268
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03112
Policy Update Magnitude: 0.98734
Value Function Update Magnitude: 0.77403
Collected Steps per Second: 13,266.13797
Overall Steps per Second: 7,260.51588
Timestep Collection Time: 3.77020
Timestep Consumption Time: 3.11857
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.88877
Cumulative Model Updates: 163,871
Cumulative Timesteps: 1,276,705,108
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1276705108...
Checkpoint 1276705108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.48223
Policy Entropy: 4.34217
Value Function Loss: 0.00258
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02937
Policy Update Magnitude: 0.96496
Value Function Update Magnitude: 0.74073
Collected Steps per Second: 13,209.98244
Overall Steps per Second: 7,230.86767
Timestep Collection Time: 3.78835
Timestep Consumption Time: 3.13254
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.92088
Cumulative Model Updates: 163,880
Cumulative Timesteps: 1,276,755,152
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.77955
Policy Entropy: 4.34685
Value Function Loss: 0.00248
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.95324
Value Function Update Magnitude: 0.68218
Collected Steps per Second: 13,440.71573
Overall Steps per Second: 7,324.86497
Timestep Collection Time: 3.72108
Timestep Consumption Time: 3.10689
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.82798
Cumulative Model Updates: 163,889
Cumulative Timesteps: 1,276,805,166
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1276805166...
Checkpoint 1276805166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.78482
Policy Entropy: 4.34857
Value Function Loss: 0.00254
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02717
Policy Update Magnitude: 0.94595
Value Function Update Magnitude: 0.69663
Collected Steps per Second: 13,162.36084
Overall Steps per Second: 7,232.15501
Timestep Collection Time: 3.80145
Timestep Consumption Time: 3.11710
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.91855
Cumulative Model Updates: 163,898
Cumulative Timesteps: 1,276,855,202
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.76663
Policy Entropy: 4.35240
Value Function Loss: 0.00233
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.92396
Value Function Update Magnitude: 0.71129
Collected Steps per Second: 13,266.91256
Overall Steps per Second: 7,328.72605
Timestep Collection Time: 3.77390
Timestep Consumption Time: 3.05785
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.83175
Cumulative Model Updates: 163,907
Cumulative Timesteps: 1,276,905,270
Timesteps Collected: 50,068
--------END ITERATION REPORT--------
Saving checkpoint 1276905270...
Checkpoint 1276905270 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.51033
Policy Entropy: 4.35426
Value Function Loss: 0.00224
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02432
Policy Update Magnitude: 0.89251
Value Function Update Magnitude: 0.72395
Collected Steps per Second: 13,160.05567
Overall Steps per Second: 7,200.29033
Timestep Collection Time: 3.80135
Timestep Consumption Time: 3.14642
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.94778
Cumulative Model Updates: 163,916
Cumulative Timesteps: 1,276,955,296
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85072
Policy Entropy: 4.35609
Value Function Loss: 0.00208
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.89076
Value Function Update Magnitude: 0.71291
Collected Steps per Second: 13,238.77014
Overall Steps per Second: 7,158.97895
Timestep Collection Time: 3.77981
Timestep Consumption Time: 3.21002
PPO Batch Consumption Time: 0.23842
Total Iteration Time: 6.98982
Cumulative Model Updates: 163,925
Cumulative Timesteps: 1,277,005,336
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1277005336...
Checkpoint 1277005336 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93131
Policy Entropy: 4.35505
Value Function Loss: 0.00217
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.90172
Value Function Update Magnitude: 0.68716
Collected Steps per Second: 13,273.97917
Overall Steps per Second: 7,364.02032
Timestep Collection Time: 3.77038
Timestep Consumption Time: 3.02590
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.79629
Cumulative Model Updates: 163,934
Cumulative Timesteps: 1,277,055,384
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.92797
Policy Entropy: 4.35398
Value Function Loss: 0.00219
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02383
Policy Update Magnitude: 0.90222
Value Function Update Magnitude: 0.69052
Collected Steps per Second: 13,379.80351
Overall Steps per Second: 7,303.03769
Timestep Collection Time: 3.73952
Timestep Consumption Time: 3.11160
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.85112
Cumulative Model Updates: 163,943
Cumulative Timesteps: 1,277,105,418
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1277105418...
Checkpoint 1277105418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80278
Policy Entropy: 4.35223
Value Function Loss: 0.00229
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.89838
Value Function Update Magnitude: 0.66255
Collected Steps per Second: 13,208.89340
Overall Steps per Second: 7,354.67621
Timestep Collection Time: 3.78821
Timestep Consumption Time: 3.01536
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.80356
Cumulative Model Updates: 163,952
Cumulative Timesteps: 1,277,155,456
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.46567
Policy Entropy: 4.35169
Value Function Loss: 0.00212
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.88913
Value Function Update Magnitude: 0.69738
Collected Steps per Second: 13,441.27363
Overall Steps per Second: 7,307.11771
Timestep Collection Time: 3.72256
Timestep Consumption Time: 3.12501
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.84757
Cumulative Model Updates: 163,961
Cumulative Timesteps: 1,277,205,492
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1277205492...
Checkpoint 1277205492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87410
Policy Entropy: 4.35268
Value Function Loss: 0.00210
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.89982
Value Function Update Magnitude: 0.73799
Collected Steps per Second: 12,976.00153
Overall Steps per Second: 7,198.67907
Timestep Collection Time: 3.85419
Timestep Consumption Time: 3.09319
PPO Batch Consumption Time: 0.22923
Total Iteration Time: 6.94739
Cumulative Model Updates: 163,970
Cumulative Timesteps: 1,277,255,504
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.50676
Policy Entropy: 4.35224
Value Function Loss: 0.00218
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.91226
Value Function Update Magnitude: 0.74117
Collected Steps per Second: 13,235.65838
Overall Steps per Second: 7,351.07908
Timestep Collection Time: 3.77964
Timestep Consumption Time: 3.02562
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.80526
Cumulative Model Updates: 163,979
Cumulative Timesteps: 1,277,305,530
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1277305530...
Checkpoint 1277305530 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85649
Policy Entropy: 4.35078
Value Function Loss: 0.00243
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02771
Policy Update Magnitude: 0.94307
Value Function Update Magnitude: 0.73477
Collected Steps per Second: 13,297.58170
Overall Steps per Second: 7,060.32501
Timestep Collection Time: 3.76098
Timestep Consumption Time: 3.32254
PPO Batch Consumption Time: 0.24149
Total Iteration Time: 7.08353
Cumulative Model Updates: 163,988
Cumulative Timesteps: 1,277,355,542
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02256
Policy Entropy: 4.34847
Value Function Loss: 0.00248
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02968
Policy Update Magnitude: 0.93664
Value Function Update Magnitude: 0.73384
Collected Steps per Second: 13,336.68764
Overall Steps per Second: 7,304.00843
Timestep Collection Time: 3.74921
Timestep Consumption Time: 3.09662
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.84583
Cumulative Model Updates: 163,997
Cumulative Timesteps: 1,277,405,544
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1277405544...
Checkpoint 1277405544 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.28292
Policy Entropy: 4.35021
Value Function Loss: 0.00250
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02878
Policy Update Magnitude: 0.92924
Value Function Update Magnitude: 0.75596
Collected Steps per Second: 13,442.53891
Overall Steps per Second: 7,321.18825
Timestep Collection Time: 3.72073
Timestep Consumption Time: 3.11095
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.83168
Cumulative Model Updates: 164,006
Cumulative Timesteps: 1,277,455,560
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49950
Policy Entropy: 4.35304
Value Function Loss: 0.00236
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.94347
Value Function Update Magnitude: 0.74911
Collected Steps per Second: 13,262.77255
Overall Steps per Second: 7,258.19663
Timestep Collection Time: 3.76995
Timestep Consumption Time: 3.11881
PPO Batch Consumption Time: 0.22784
Total Iteration Time: 6.88876
Cumulative Model Updates: 164,015
Cumulative Timesteps: 1,277,505,560
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1277505560...
Checkpoint 1277505560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.56184
Policy Entropy: 4.35388
Value Function Loss: 0.00237
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.92023
Value Function Update Magnitude: 0.71750
Collected Steps per Second: 13,085.92794
Overall Steps per Second: 7,228.32111
Timestep Collection Time: 3.82212
Timestep Consumption Time: 3.09733
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.91945
Cumulative Model Updates: 164,024
Cumulative Timesteps: 1,277,555,576
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.70915
Policy Entropy: 4.35556
Value Function Loss: 0.00227
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02876
Policy Update Magnitude: 0.90211
Value Function Update Magnitude: 0.66759
Collected Steps per Second: 13,597.35207
Overall Steps per Second: 7,364.52654
Timestep Collection Time: 3.67880
Timestep Consumption Time: 3.11349
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.79229
Cumulative Model Updates: 164,033
Cumulative Timesteps: 1,277,605,598
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1277605598...
Checkpoint 1277605598 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.59482
Policy Entropy: 4.35074
Value Function Loss: 0.00231
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02862
Policy Update Magnitude: 0.91343
Value Function Update Magnitude: 0.62681
Collected Steps per Second: 13,334.56078
Overall Steps per Second: 7,266.25597
Timestep Collection Time: 3.74980
Timestep Consumption Time: 3.13159
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.88140
Cumulative Model Updates: 164,042
Cumulative Timesteps: 1,277,655,600
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72826
Policy Entropy: 4.34942
Value Function Loss: 0.00237
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.92272
Value Function Update Magnitude: 0.64390
Collected Steps per Second: 13,276.21064
Overall Steps per Second: 7,187.02351
Timestep Collection Time: 3.76719
Timestep Consumption Time: 3.19174
PPO Batch Consumption Time: 0.24276
Total Iteration Time: 6.95893
Cumulative Model Updates: 164,051
Cumulative Timesteps: 1,277,705,614
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1277705614...
Checkpoint 1277705614 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11845
Policy Entropy: 4.34984
Value Function Loss: 0.00260
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03055
Policy Update Magnitude: 0.95349
Value Function Update Magnitude: 0.70963
Collected Steps per Second: 13,267.26851
Overall Steps per Second: 7,262.29620
Timestep Collection Time: 3.77139
Timestep Consumption Time: 3.11845
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.88983
Cumulative Model Updates: 164,060
Cumulative Timesteps: 1,277,755,650
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.18405
Policy Entropy: 4.34754
Value Function Loss: 0.00254
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.97273
Value Function Update Magnitude: 0.69946
Collected Steps per Second: 13,212.17019
Overall Steps per Second: 7,276.80339
Timestep Collection Time: 3.78651
Timestep Consumption Time: 3.08849
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.87500
Cumulative Model Updates: 164,069
Cumulative Timesteps: 1,277,805,678
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1277805678...
Checkpoint 1277805678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.66098
Policy Entropy: 4.34995
Value Function Loss: 0.00265
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.97247
Value Function Update Magnitude: 0.67948
Collected Steps per Second: 13,292.23799
Overall Steps per Second: 7,387.24800
Timestep Collection Time: 3.76325
Timestep Consumption Time: 3.00815
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.77140
Cumulative Model Updates: 164,078
Cumulative Timesteps: 1,277,855,700
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.53918
Policy Entropy: 4.34923
Value Function Loss: 0.00261
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.95916
Value Function Update Magnitude: 0.69730
Collected Steps per Second: 11,088.07358
Overall Steps per Second: 6,548.52716
Timestep Collection Time: 4.51133
Timestep Consumption Time: 3.12733
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 7.63866
Cumulative Model Updates: 164,087
Cumulative Timesteps: 1,277,905,722
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1277905722...
Checkpoint 1277905722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.63940
Policy Entropy: 4.34718
Value Function Loss: 0.00271
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02839
Policy Update Magnitude: 0.95037
Value Function Update Magnitude: 0.71274
Collected Steps per Second: 13,191.03648
Overall Steps per Second: 7,257.74889
Timestep Collection Time: 3.79455
Timestep Consumption Time: 3.10208
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.89663
Cumulative Model Updates: 164,096
Cumulative Timesteps: 1,277,955,776
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79993
Policy Entropy: 4.34311
Value Function Loss: 0.00259
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02995
Policy Update Magnitude: 0.95812
Value Function Update Magnitude: 0.71647
Collected Steps per Second: 13,569.60720
Overall Steps per Second: 7,342.54511
Timestep Collection Time: 3.68765
Timestep Consumption Time: 3.12742
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.81508
Cumulative Model Updates: 164,105
Cumulative Timesteps: 1,278,005,816
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1278005816...
Checkpoint 1278005816 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82349
Policy Entropy: 4.34390
Value Function Loss: 0.00255
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.95485
Value Function Update Magnitude: 0.68232
Collected Steps per Second: 13,214.59059
Overall Steps per Second: 7,163.54326
Timestep Collection Time: 3.78627
Timestep Consumption Time: 3.19826
PPO Batch Consumption Time: 0.23563
Total Iteration Time: 6.98453
Cumulative Model Updates: 164,114
Cumulative Timesteps: 1,278,055,850
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89840
Policy Entropy: 4.34505
Value Function Loss: 0.00242
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02777
Policy Update Magnitude: 0.93319
Value Function Update Magnitude: 0.65519
Collected Steps per Second: 13,190.76306
Overall Steps per Second: 7,248.91083
Timestep Collection Time: 3.79281
Timestep Consumption Time: 3.10892
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.90173
Cumulative Model Updates: 164,123
Cumulative Timesteps: 1,278,105,880
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1278105880...
Checkpoint 1278105880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33656
Policy Entropy: 4.34511
Value Function Loss: 0.00253
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03098
Policy Update Magnitude: 0.94792
Value Function Update Magnitude: 0.66856
Collected Steps per Second: 13,785.45106
Overall Steps per Second: 7,389.15335
Timestep Collection Time: 3.62745
Timestep Consumption Time: 3.14004
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.76749
Cumulative Model Updates: 164,132
Cumulative Timesteps: 1,278,155,886
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.58176
Policy Entropy: 4.34482
Value Function Loss: 0.00234
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03070
Policy Update Magnitude: 0.94651
Value Function Update Magnitude: 0.66694
Collected Steps per Second: 13,393.47529
Overall Steps per Second: 7,241.29952
Timestep Collection Time: 3.73525
Timestep Consumption Time: 3.17345
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.90870
Cumulative Model Updates: 164,141
Cumulative Timesteps: 1,278,205,914
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1278205914...
Checkpoint 1278205914 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.61777
Policy Entropy: 4.34746
Value Function Loss: 0.00243
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02934
Policy Update Magnitude: 0.94443
Value Function Update Magnitude: 0.66761
Collected Steps per Second: 13,251.68910
Overall Steps per Second: 7,340.83762
Timestep Collection Time: 3.77552
Timestep Consumption Time: 3.04005
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.81557
Cumulative Model Updates: 164,150
Cumulative Timesteps: 1,278,255,946
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50218
Policy Entropy: 4.35144
Value Function Loss: 0.00214
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02756
Policy Update Magnitude: 0.92521
Value Function Update Magnitude: 0.66957
Collected Steps per Second: 13,212.50555
Overall Steps per Second: 7,242.90032
Timestep Collection Time: 3.78475
Timestep Consumption Time: 3.11939
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.90414
Cumulative Model Updates: 164,159
Cumulative Timesteps: 1,278,305,952
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1278305952...
Checkpoint 1278305952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95855
Policy Entropy: 4.35273
Value Function Loss: 0.00222
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02816
Policy Update Magnitude: 0.89302
Value Function Update Magnitude: 0.68433
Collected Steps per Second: 13,204.84770
Overall Steps per Second: 7,242.97094
Timestep Collection Time: 3.78649
Timestep Consumption Time: 3.11676
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.90324
Cumulative Model Updates: 164,168
Cumulative Timesteps: 1,278,355,952
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46026
Policy Entropy: 4.35114
Value Function Loss: 0.00222
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02558
Policy Update Magnitude: 0.91762
Value Function Update Magnitude: 0.66956
Collected Steps per Second: 13,344.40279
Overall Steps per Second: 7,209.34457
Timestep Collection Time: 3.74749
Timestep Consumption Time: 3.18906
PPO Batch Consumption Time: 0.24231
Total Iteration Time: 6.93655
Cumulative Model Updates: 164,177
Cumulative Timesteps: 1,278,405,960
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1278405960...
Checkpoint 1278405960 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56443
Policy Entropy: 4.34817
Value Function Loss: 0.00243
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02775
Policy Update Magnitude: 0.95808
Value Function Update Magnitude: 0.70508
Collected Steps per Second: 13,245.24488
Overall Steps per Second: 7,270.84772
Timestep Collection Time: 3.77766
Timestep Consumption Time: 3.10407
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.88173
Cumulative Model Updates: 164,186
Cumulative Timesteps: 1,278,455,996
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18525
Policy Entropy: 4.34709
Value Function Loss: 0.00245
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03054
Policy Update Magnitude: 0.94611
Value Function Update Magnitude: 0.69199
Collected Steps per Second: 13,321.09451
Overall Steps per Second: 7,322.83594
Timestep Collection Time: 3.75690
Timestep Consumption Time: 3.07734
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.83424
Cumulative Model Updates: 164,195
Cumulative Timesteps: 1,278,506,042
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1278506042...
Checkpoint 1278506042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62481
Policy Entropy: 4.34927
Value Function Loss: 0.00230
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 0.90532
Value Function Update Magnitude: 0.65297
Collected Steps per Second: 13,487.08928
Overall Steps per Second: 7,341.69103
Timestep Collection Time: 3.70918
Timestep Consumption Time: 3.10478
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.81396
Cumulative Model Updates: 164,204
Cumulative Timesteps: 1,278,556,068
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99904
Policy Entropy: 4.34322
Value Function Loss: 0.00262
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02826
Policy Update Magnitude: 0.91878
Value Function Update Magnitude: 0.64238
Collected Steps per Second: 13,222.76416
Overall Steps per Second: 7,255.50905
Timestep Collection Time: 3.78242
Timestep Consumption Time: 3.11083
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.89324
Cumulative Model Updates: 164,213
Cumulative Timesteps: 1,278,606,082
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1278606082...
Checkpoint 1278606082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.95733
Policy Entropy: 4.34336
Value Function Loss: 0.00257
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.93673
Value Function Update Magnitude: 0.67226
Collected Steps per Second: 13,194.07033
Overall Steps per Second: 7,289.26702
Timestep Collection Time: 3.78988
Timestep Consumption Time: 3.07006
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.85995
Cumulative Model Updates: 164,222
Cumulative Timesteps: 1,278,656,086
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.99548
Policy Entropy: 4.34031
Value Function Loss: 0.00256
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 0.92285
Value Function Update Magnitude: 0.65917
Collected Steps per Second: 13,284.43857
Overall Steps per Second: 7,279.83494
Timestep Collection Time: 3.76621
Timestep Consumption Time: 3.10647
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.87268
Cumulative Model Updates: 164,231
Cumulative Timesteps: 1,278,706,118
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1278706118...
Checkpoint 1278706118 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02764
Policy Entropy: 4.34964
Value Function Loss: 0.00245
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02756
Policy Update Magnitude: 0.91998
Value Function Update Magnitude: 0.68731
Collected Steps per Second: 13,221.17493
Overall Steps per Second: 7,094.32427
Timestep Collection Time: 3.78484
Timestep Consumption Time: 3.26869
PPO Batch Consumption Time: 0.24473
Total Iteration Time: 7.05353
Cumulative Model Updates: 164,240
Cumulative Timesteps: 1,278,756,158
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11157
Policy Entropy: 4.34749
Value Function Loss: 0.00249
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.93387
Value Function Update Magnitude: 0.69589
Collected Steps per Second: 13,698.00683
Overall Steps per Second: 7,393.93291
Timestep Collection Time: 3.65046
Timestep Consumption Time: 3.11238
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.76284
Cumulative Model Updates: 164,249
Cumulative Timesteps: 1,278,806,162
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1278806162...
Checkpoint 1278806162 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28163
Policy Entropy: 4.34828
Value Function Loss: 0.00247
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02859
Policy Update Magnitude: 0.90772
Value Function Update Magnitude: 0.73249
Collected Steps per Second: 13,327.75106
Overall Steps per Second: 7,255.15614
Timestep Collection Time: 3.75307
Timestep Consumption Time: 3.14134
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.89441
Cumulative Model Updates: 164,258
Cumulative Timesteps: 1,278,856,182
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.86757
Policy Entropy: 4.34564
Value Function Loss: 0.00260
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02791
Policy Update Magnitude: 0.91584
Value Function Update Magnitude: 0.76335
Collected Steps per Second: 13,362.01412
Overall Steps per Second: 7,325.10671
Timestep Collection Time: 3.74360
Timestep Consumption Time: 3.08525
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.82884
Cumulative Model Updates: 164,267
Cumulative Timesteps: 1,278,906,204
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1278906204...
Checkpoint 1278906204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.66876
Policy Entropy: 4.34892
Value Function Loss: 0.00241
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.91334
Value Function Update Magnitude: 0.72814
Collected Steps per Second: 13,436.38571
Overall Steps per Second: 7,294.17435
Timestep Collection Time: 3.72511
Timestep Consumption Time: 3.13681
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.86191
Cumulative Model Updates: 164,276
Cumulative Timesteps: 1,278,956,256
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71681
Policy Entropy: 4.34912
Value Function Loss: 0.00245
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02718
Policy Update Magnitude: 0.90816
Value Function Update Magnitude: 0.68762
Collected Steps per Second: 13,334.82250
Overall Steps per Second: 7,186.21455
Timestep Collection Time: 3.75243
Timestep Consumption Time: 3.21062
PPO Batch Consumption Time: 0.23900
Total Iteration Time: 6.96305
Cumulative Model Updates: 164,285
Cumulative Timesteps: 1,279,006,294
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1279006294...
Checkpoint 1279006294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64785
Policy Entropy: 4.35262
Value Function Loss: 0.00224
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.88674
Value Function Update Magnitude: 0.67601
Collected Steps per Second: 13,242.58504
Overall Steps per Second: 7,333.83475
Timestep Collection Time: 3.77645
Timestep Consumption Time: 3.04263
PPO Batch Consumption Time: 0.23158
Total Iteration Time: 6.81908
Cumulative Model Updates: 164,294
Cumulative Timesteps: 1,279,056,304
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.17928
Policy Entropy: 4.35308
Value Function Loss: 0.00234
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.87525
Value Function Update Magnitude: 0.73244
Collected Steps per Second: 12,191.62892
Overall Steps per Second: 6,704.48346
Timestep Collection Time: 4.10364
Timestep Consumption Time: 3.35854
PPO Batch Consumption Time: 0.24996
Total Iteration Time: 7.46217
Cumulative Model Updates: 164,303
Cumulative Timesteps: 1,279,106,334
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1279106334...
Checkpoint 1279106334 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66998
Policy Entropy: 4.35470
Value Function Loss: 0.00244
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.90125
Value Function Update Magnitude: 0.72544
Collected Steps per Second: 12,738.04207
Overall Steps per Second: 7,082.62357
Timestep Collection Time: 3.92949
Timestep Consumption Time: 3.13767
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 7.06716
Cumulative Model Updates: 164,312
Cumulative Timesteps: 1,279,156,388
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.95488
Policy Entropy: 4.35380
Value Function Loss: 0.00240
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.91515
Value Function Update Magnitude: 0.71763
Collected Steps per Second: 13,042.68968
Overall Steps per Second: 7,265.20916
Timestep Collection Time: 3.83571
Timestep Consumption Time: 3.05026
PPO Batch Consumption Time: 0.23130
Total Iteration Time: 6.88597
Cumulative Model Updates: 164,321
Cumulative Timesteps: 1,279,206,416
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1279206416...
Checkpoint 1279206416 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12358
Policy Entropy: 4.35557
Value Function Loss: 0.00240
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.90023
Value Function Update Magnitude: 0.70484
Collected Steps per Second: 12,948.86382
Overall Steps per Second: 7,138.35675
Timestep Collection Time: 3.86181
Timestep Consumption Time: 3.14345
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 7.00525
Cumulative Model Updates: 164,330
Cumulative Timesteps: 1,279,256,422
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46821
Policy Entropy: 4.35716
Value Function Loss: 0.00231
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02545
Policy Update Magnitude: 0.89366
Value Function Update Magnitude: 0.68785
Collected Steps per Second: 13,179.91156
Overall Steps per Second: 7,261.75884
Timestep Collection Time: 3.79608
Timestep Consumption Time: 3.09371
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.88979
Cumulative Model Updates: 164,339
Cumulative Timesteps: 1,279,306,454
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1279306454...
Checkpoint 1279306454 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81861
Policy Entropy: 4.35433
Value Function Loss: 0.00238
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.90267
Value Function Update Magnitude: 0.69566
Collected Steps per Second: 13,557.96414
Overall Steps per Second: 7,306.83783
Timestep Collection Time: 3.69067
Timestep Consumption Time: 3.15743
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.84811
Cumulative Model Updates: 164,348
Cumulative Timesteps: 1,279,356,492
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.91916
Policy Entropy: 4.35328
Value Function Loss: 0.00237
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02617
Policy Update Magnitude: 0.90192
Value Function Update Magnitude: 0.71975
Collected Steps per Second: 13,093.49558
Overall Steps per Second: 7,174.50559
Timestep Collection Time: 3.81884
Timestep Consumption Time: 3.15056
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.96940
Cumulative Model Updates: 164,357
Cumulative Timesteps: 1,279,406,494
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1279406494...
Checkpoint 1279406494 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16096
Policy Entropy: 4.35156
Value Function Loss: 0.00249
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02787
Policy Update Magnitude: 0.91370
Value Function Update Magnitude: 0.73575
Collected Steps per Second: 12,986.18018
Overall Steps per Second: 7,044.12825
Timestep Collection Time: 3.85025
Timestep Consumption Time: 3.24786
PPO Batch Consumption Time: 0.24087
Total Iteration Time: 7.09811
Cumulative Model Updates: 164,366
Cumulative Timesteps: 1,279,456,494
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56020
Policy Entropy: 4.35095
Value Function Loss: 0.00233
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.90198
Value Function Update Magnitude: 0.71298
Collected Steps per Second: 13,321.12253
Overall Steps per Second: 7,257.15037
Timestep Collection Time: 3.75569
Timestep Consumption Time: 3.13820
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.89389
Cumulative Model Updates: 164,375
Cumulative Timesteps: 1,279,506,524
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1279506524...
Checkpoint 1279506524 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01547
Policy Entropy: 4.35190
Value Function Loss: 0.00247
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.91489
Value Function Update Magnitude: 0.68939
Collected Steps per Second: 13,218.07090
Overall Steps per Second: 7,232.33199
Timestep Collection Time: 3.78376
Timestep Consumption Time: 3.13158
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.91534
Cumulative Model Updates: 164,384
Cumulative Timesteps: 1,279,556,538
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.10442
Policy Entropy: 4.35507
Value Function Loss: 0.00235
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02702
Policy Update Magnitude: 0.92014
Value Function Update Magnitude: 0.69875
Collected Steps per Second: 13,156.21993
Overall Steps per Second: 7,290.30863
Timestep Collection Time: 3.80170
Timestep Consumption Time: 3.05892
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.86061
Cumulative Model Updates: 164,393
Cumulative Timesteps: 1,279,606,554
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1279606554...
Checkpoint 1279606554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.38463
Policy Entropy: 4.35571
Value Function Loss: 0.00245
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02774
Policy Update Magnitude: 0.91242
Value Function Update Magnitude: 0.72215
Collected Steps per Second: 13,139.73289
Overall Steps per Second: 7,235.10790
Timestep Collection Time: 3.80540
Timestep Consumption Time: 3.10562
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.91102
Cumulative Model Updates: 164,402
Cumulative Timesteps: 1,279,656,556
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.80341
Policy Entropy: 4.35243
Value Function Loss: 0.00250
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.92576
Value Function Update Magnitude: 0.74825
Collected Steps per Second: 13,235.96873
Overall Steps per Second: 7,272.44390
Timestep Collection Time: 3.78061
Timestep Consumption Time: 3.10016
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.88077
Cumulative Model Updates: 164,411
Cumulative Timesteps: 1,279,706,596
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1279706596...
Checkpoint 1279706596 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.55716
Policy Entropy: 4.35106
Value Function Loss: 0.00249
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.92969
Value Function Update Magnitude: 0.70936
Collected Steps per Second: 13,064.53482
Overall Steps per Second: 7,297.87347
Timestep Collection Time: 3.83068
Timestep Consumption Time: 3.02694
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.85761
Cumulative Model Updates: 164,420
Cumulative Timesteps: 1,279,756,642
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.13941
Policy Entropy: 4.34923
Value Function Loss: 0.00263
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02684
Policy Update Magnitude: 0.93772
Value Function Update Magnitude: 0.73512
Collected Steps per Second: 13,207.83723
Overall Steps per Second: 7,145.00481
Timestep Collection Time: 3.78836
Timestep Consumption Time: 3.21458
PPO Batch Consumption Time: 0.23747
Total Iteration Time: 7.00293
Cumulative Model Updates: 164,429
Cumulative Timesteps: 1,279,806,678
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1279806678...
Checkpoint 1279806678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62442
Policy Entropy: 4.34797
Value Function Loss: 0.00258
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.95265
Value Function Update Magnitude: 0.77642
Collected Steps per Second: 13,282.65226
Overall Steps per Second: 7,255.59062
Timestep Collection Time: 3.76506
Timestep Consumption Time: 3.12755
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.89262
Cumulative Model Updates: 164,438
Cumulative Timesteps: 1,279,856,688
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41456
Policy Entropy: 4.34668
Value Function Loss: 0.00274
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 0.95731
Value Function Update Magnitude: 0.78341
Collected Steps per Second: 13,436.60266
Overall Steps per Second: 7,318.30340
Timestep Collection Time: 3.72267
Timestep Consumption Time: 3.11225
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.83492
Cumulative Model Updates: 164,447
Cumulative Timesteps: 1,279,906,708
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1279906708...
Checkpoint 1279906708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95982
Policy Entropy: 4.34608
Value Function Loss: 0.00271
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.94340
Value Function Update Magnitude: 0.82852
Collected Steps per Second: 13,128.58041
Overall Steps per Second: 7,197.45480
Timestep Collection Time: 3.80894
Timestep Consumption Time: 3.13879
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.94773
Cumulative Model Updates: 164,456
Cumulative Timesteps: 1,279,956,714
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.40045
Policy Entropy: 4.34751
Value Function Loss: 0.00251
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.92130
Value Function Update Magnitude: 0.79780
Collected Steps per Second: 13,069.66346
Overall Steps per Second: 7,318.37823
Timestep Collection Time: 3.82734
Timestep Consumption Time: 3.00778
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.83512
Cumulative Model Updates: 164,465
Cumulative Timesteps: 1,280,006,736
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1280006736...
Checkpoint 1280006736 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62421
Policy Entropy: 4.34768
Value Function Loss: 0.00259
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02701
Policy Update Magnitude: 0.92126
Value Function Update Magnitude: 0.82507
Collected Steps per Second: 13,144.79496
Overall Steps per Second: 7,244.99924
Timestep Collection Time: 3.80531
Timestep Consumption Time: 3.09876
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.90407
Cumulative Model Updates: 164,474
Cumulative Timesteps: 1,280,056,756
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11418
Policy Entropy: 4.34524
Value Function Loss: 0.00267
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02936
Policy Update Magnitude: 0.95284
Value Function Update Magnitude: 0.85406
Collected Steps per Second: 13,178.15001
Overall Steps per Second: 7,273.21424
Timestep Collection Time: 3.79492
Timestep Consumption Time: 3.08100
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.87591
Cumulative Model Updates: 164,483
Cumulative Timesteps: 1,280,106,766
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1280106766...
Checkpoint 1280106766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.99550
Policy Entropy: 4.34605
Value Function Loss: 0.00270
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.96570
Value Function Update Magnitude: 0.86415
Collected Steps per Second: 12,891.77135
Overall Steps per Second: 7,186.84248
Timestep Collection Time: 3.88061
Timestep Consumption Time: 3.08044
PPO Batch Consumption Time: 0.23567
Total Iteration Time: 6.96105
Cumulative Model Updates: 164,492
Cumulative Timesteps: 1,280,156,794
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20317
Policy Entropy: 4.34436
Value Function Loss: 0.00260
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.96560
Value Function Update Magnitude: 0.80470
Collected Steps per Second: 13,146.32610
Overall Steps per Second: 7,223.26152
Timestep Collection Time: 3.80532
Timestep Consumption Time: 3.12036
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.92568
Cumulative Model Updates: 164,501
Cumulative Timesteps: 1,280,206,820
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1280206820...
Checkpoint 1280206820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.37704
Policy Entropy: 4.34773
Value Function Loss: 0.00241
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.93533
Value Function Update Magnitude: 0.72908
Collected Steps per Second: 13,158.35094
Overall Steps per Second: 7,235.63692
Timestep Collection Time: 3.80139
Timestep Consumption Time: 3.11162
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.91301
Cumulative Model Updates: 164,510
Cumulative Timesteps: 1,280,256,840
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02670
Policy Entropy: 4.34951
Value Function Loss: 0.00230
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.88363
Value Function Update Magnitude: 0.71249
Collected Steps per Second: 13,451.70338
Overall Steps per Second: 7,323.34548
Timestep Collection Time: 3.71908
Timestep Consumption Time: 3.11222
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.83130
Cumulative Model Updates: 164,519
Cumulative Timesteps: 1,280,306,868
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1280306868...
Checkpoint 1280306868 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.24437
Policy Entropy: 4.35169
Value Function Loss: 0.00221
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.86063
Value Function Update Magnitude: 0.74708
Collected Steps per Second: 13,203.32294
Overall Steps per Second: 7,213.04315
Timestep Collection Time: 3.78874
Timestep Consumption Time: 3.14647
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.93521
Cumulative Model Updates: 164,528
Cumulative Timesteps: 1,280,356,892
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.23648
Policy Entropy: 4.35521
Value Function Loss: 0.00221
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.87257
Value Function Update Magnitude: 0.75553
Collected Steps per Second: 13,146.42836
Overall Steps per Second: 7,318.44752
Timestep Collection Time: 3.80575
Timestep Consumption Time: 3.03067
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.83642
Cumulative Model Updates: 164,537
Cumulative Timesteps: 1,280,406,924
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1280406924...
Checkpoint 1280406924 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.48588
Policy Entropy: 4.35144
Value Function Loss: 0.00234
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.90364
Value Function Update Magnitude: 0.71807
Collected Steps per Second: 13,332.24190
Overall Steps per Second: 7,263.98226
Timestep Collection Time: 3.75166
Timestep Consumption Time: 3.13410
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.88575
Cumulative Model Updates: 164,546
Cumulative Timesteps: 1,280,456,942
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03821
Policy Entropy: 4.35592
Value Function Loss: 0.00218
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.88205
Value Function Update Magnitude: 0.66932
Collected Steps per Second: 13,300.63682
Overall Steps per Second: 7,130.62058
Timestep Collection Time: 3.76162
Timestep Consumption Time: 3.25488
PPO Batch Consumption Time: 0.24235
Total Iteration Time: 7.01650
Cumulative Model Updates: 164,555
Cumulative Timesteps: 1,280,506,974
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1280506974...
Checkpoint 1280506974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39097
Policy Entropy: 4.35480
Value Function Loss: 0.00227
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.86435
Value Function Update Magnitude: 0.69801
Collected Steps per Second: 13,108.69201
Overall Steps per Second: 7,305.05149
Timestep Collection Time: 3.81625
Timestep Consumption Time: 3.03189
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.84814
Cumulative Model Updates: 164,564
Cumulative Timesteps: 1,280,557,000
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.59723
Policy Entropy: 4.35763
Value Function Loss: 0.00210
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.86183
Value Function Update Magnitude: 0.67504
Collected Steps per Second: 13,257.17101
Overall Steps per Second: 7,259.79014
Timestep Collection Time: 3.77200
Timestep Consumption Time: 3.11608
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.88808
Cumulative Model Updates: 164,573
Cumulative Timesteps: 1,280,607,006
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1280607006...
Checkpoint 1280607006 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05279
Policy Entropy: 4.35356
Value Function Loss: 0.00226
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.87623
Value Function Update Magnitude: 0.67253
Collected Steps per Second: 13,323.61357
Overall Steps per Second: 7,250.06707
Timestep Collection Time: 3.75469
Timestep Consumption Time: 3.14539
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.90007
Cumulative Model Updates: 164,582
Cumulative Timesteps: 1,280,657,032
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.59261
Policy Entropy: 4.35564
Value Function Loss: 0.00226
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.89054
Value Function Update Magnitude: 0.71664
Collected Steps per Second: 13,502.98153
Overall Steps per Second: 7,336.02018
Timestep Collection Time: 3.70377
Timestep Consumption Time: 3.11355
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.81732
Cumulative Model Updates: 164,591
Cumulative Timesteps: 1,280,707,044
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1280707044...
Checkpoint 1280707044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44111
Policy Entropy: 4.35426
Value Function Loss: 0.00237
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.90048
Value Function Update Magnitude: 0.76595
Collected Steps per Second: 13,213.36188
Overall Steps per Second: 7,206.28698
Timestep Collection Time: 3.78617
Timestep Consumption Time: 3.15610
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.94227
Cumulative Model Updates: 164,600
Cumulative Timesteps: 1,280,757,072
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.47480
Policy Entropy: 4.35392
Value Function Loss: 0.00248
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.91371
Value Function Update Magnitude: 0.77269
Collected Steps per Second: 12,965.21779
Overall Steps per Second: 7,195.45067
Timestep Collection Time: 3.85740
Timestep Consumption Time: 3.09311
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.95050
Cumulative Model Updates: 164,609
Cumulative Timesteps: 1,280,807,084
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1280807084...
Checkpoint 1280807084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19838
Policy Entropy: 4.35172
Value Function Loss: 0.00255
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.93536
Value Function Update Magnitude: 0.72369
Collected Steps per Second: 13,400.33465
Overall Steps per Second: 7,229.56126
Timestep Collection Time: 3.73334
Timestep Consumption Time: 3.18658
PPO Batch Consumption Time: 0.23550
Total Iteration Time: 6.91992
Cumulative Model Updates: 164,618
Cumulative Timesteps: 1,280,857,112
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73697
Policy Entropy: 4.35223
Value Function Loss: 0.00244
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02804
Policy Update Magnitude: 0.90531
Value Function Update Magnitude: 0.70447
Collected Steps per Second: 13,204.14208
Overall Steps per Second: 7,232.51489
Timestep Collection Time: 3.78972
Timestep Consumption Time: 3.12904
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.91876
Cumulative Model Updates: 164,627
Cumulative Timesteps: 1,280,907,152
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1280907152...
Checkpoint 1280907152 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.48020
Policy Entropy: 4.35875
Value Function Loss: 0.00230
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.87178
Value Function Update Magnitude: 0.69947
Collected Steps per Second: 13,136.03729
Overall Steps per Second: 7,331.82328
Timestep Collection Time: 3.80708
Timestep Consumption Time: 3.01387
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.82095
Cumulative Model Updates: 164,636
Cumulative Timesteps: 1,280,957,162
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37598
Policy Entropy: 4.35512
Value Function Loss: 0.00225
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.86561
Value Function Update Magnitude: 0.69334
Collected Steps per Second: 13,236.79502
Overall Steps per Second: 7,199.27396
Timestep Collection Time: 3.78037
Timestep Consumption Time: 3.17033
PPO Batch Consumption Time: 0.22953
Total Iteration Time: 6.95070
Cumulative Model Updates: 164,645
Cumulative Timesteps: 1,281,007,202
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1281007202...
Checkpoint 1281007202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35216
Policy Entropy: 4.35563
Value Function Loss: 0.00229
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.88734
Value Function Update Magnitude: 0.67622
Collected Steps per Second: 13,158.42584
Overall Steps per Second: 7,257.91705
Timestep Collection Time: 3.80045
Timestep Consumption Time: 3.08968
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.89013
Cumulative Model Updates: 164,654
Cumulative Timesteps: 1,281,057,210
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81312
Policy Entropy: 4.35304
Value Function Loss: 0.00242
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.90334
Value Function Update Magnitude: 0.69931
Collected Steps per Second: 13,658.72809
Overall Steps per Second: 7,364.59980
Timestep Collection Time: 3.66198
Timestep Consumption Time: 3.12970
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.79168
Cumulative Model Updates: 164,663
Cumulative Timesteps: 1,281,107,228
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1281107228...
Checkpoint 1281107228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38438
Policy Entropy: 4.35541
Value Function Loss: 0.00237
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.91408
Value Function Update Magnitude: 0.73742
Collected Steps per Second: 13,071.15212
Overall Steps per Second: 7,195.44261
Timestep Collection Time: 3.82675
Timestep Consumption Time: 3.12487
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.95162
Cumulative Model Updates: 164,672
Cumulative Timesteps: 1,281,157,248
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55088
Policy Entropy: 4.35703
Value Function Loss: 0.00236
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02971
Policy Update Magnitude: 0.89923
Value Function Update Magnitude: 0.73159
Collected Steps per Second: 13,080.27604
Overall Steps per Second: 7,214.18475
Timestep Collection Time: 3.82270
Timestep Consumption Time: 3.10837
PPO Batch Consumption Time: 0.23008
Total Iteration Time: 6.93107
Cumulative Model Updates: 164,681
Cumulative Timesteps: 1,281,207,250
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1281207250...
Checkpoint 1281207250 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.94888
Policy Entropy: 4.35710
Value Function Loss: 0.00240
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.89890
Value Function Update Magnitude: 0.79587
Collected Steps per Second: 13,355.95949
Overall Steps per Second: 7,280.39947
Timestep Collection Time: 3.74634
Timestep Consumption Time: 3.12636
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.87270
Cumulative Model Updates: 164,690
Cumulative Timesteps: 1,281,257,286
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.66310
Policy Entropy: 4.35648
Value Function Loss: 0.00248
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02810
Policy Update Magnitude: 0.92954
Value Function Update Magnitude: 0.77613
Collected Steps per Second: 13,081.99305
Overall Steps per Second: 7,172.96703
Timestep Collection Time: 3.82281
Timestep Consumption Time: 3.14920
PPO Batch Consumption Time: 0.22962
Total Iteration Time: 6.97201
Cumulative Model Updates: 164,699
Cumulative Timesteps: 1,281,307,296
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1281307296...
Checkpoint 1281307296 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16213
Policy Entropy: 4.35558
Value Function Loss: 0.00249
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02856
Policy Update Magnitude: 0.94475
Value Function Update Magnitude: 0.77345
Collected Steps per Second: 12,812.44229
Overall Steps per Second: 7,226.61261
Timestep Collection Time: 3.90261
Timestep Consumption Time: 3.01653
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.91915
Cumulative Model Updates: 164,708
Cumulative Timesteps: 1,281,357,298
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76408
Policy Entropy: 4.35707
Value Function Loss: 0.00251
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02792
Policy Update Magnitude: 0.95004
Value Function Update Magnitude: 0.73965
Collected Steps per Second: 13,252.14353
Overall Steps per Second: 7,254.19854
Timestep Collection Time: 3.77433
Timestep Consumption Time: 3.12071
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.89504
Cumulative Model Updates: 164,717
Cumulative Timesteps: 1,281,407,316
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1281407316...
Checkpoint 1281407316 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.94489
Policy Entropy: 4.35881
Value Function Loss: 0.00236
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.91752
Value Function Update Magnitude: 0.72665
Collected Steps per Second: 12,865.45985
Overall Steps per Second: 7,168.37952
Timestep Collection Time: 3.89011
Timestep Consumption Time: 3.09167
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.98177
Cumulative Model Updates: 164,726
Cumulative Timesteps: 1,281,457,364
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.81754
Policy Entropy: 4.35713
Value Function Loss: 0.00239
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.92759
Value Function Update Magnitude: 0.68542
Collected Steps per Second: 13,538.66744
Overall Steps per Second: 7,342.00797
Timestep Collection Time: 3.69342
Timestep Consumption Time: 3.11725
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.81067
Cumulative Model Updates: 164,735
Cumulative Timesteps: 1,281,507,368
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1281507368...
Checkpoint 1281507368 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62529
Policy Entropy: 4.35566
Value Function Loss: 0.00227
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.90843
Value Function Update Magnitude: 0.67196
Collected Steps per Second: 13,137.35121
Overall Steps per Second: 7,060.00041
Timestep Collection Time: 3.80777
Timestep Consumption Time: 3.27778
PPO Batch Consumption Time: 0.24005
Total Iteration Time: 7.08555
Cumulative Model Updates: 164,744
Cumulative Timesteps: 1,281,557,392
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46284
Policy Entropy: 4.35435
Value Function Loss: 0.00236
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.89337
Value Function Update Magnitude: 0.65280
Collected Steps per Second: 13,137.25997
Overall Steps per Second: 7,231.48529
Timestep Collection Time: 3.80840
Timestep Consumption Time: 3.11023
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.91863
Cumulative Model Updates: 164,753
Cumulative Timesteps: 1,281,607,424
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1281607424...
Checkpoint 1281607424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49857
Policy Entropy: 4.35423
Value Function Loss: 0.00249
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02692
Policy Update Magnitude: 0.90411
Value Function Update Magnitude: 0.65562
Collected Steps per Second: 13,479.89250
Overall Steps per Second: 7,283.67934
Timestep Collection Time: 3.70967
Timestep Consumption Time: 3.15581
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.86549
Cumulative Model Updates: 164,762
Cumulative Timesteps: 1,281,657,430
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.37811
Policy Entropy: 4.35129
Value Function Loss: 0.00251
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.92166
Value Function Update Magnitude: 0.66207
Collected Steps per Second: 13,013.31389
Overall Steps per Second: 7,174.60817
Timestep Collection Time: 3.84299
Timestep Consumption Time: 3.12743
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.97042
Cumulative Model Updates: 164,771
Cumulative Timesteps: 1,281,707,440
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1281707440...
Checkpoint 1281707440 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81273
Policy Entropy: 4.35053
Value Function Loss: 0.00276
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02751
Policy Update Magnitude: 0.93931
Value Function Update Magnitude: 0.64573
Collected Steps per Second: 13,196.82012
Overall Steps per Second: 7,345.82953
Timestep Collection Time: 3.79258
Timestep Consumption Time: 3.02081
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.81339
Cumulative Model Updates: 164,780
Cumulative Timesteps: 1,281,757,490
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.59518
Policy Entropy: 4.35199
Value Function Loss: 0.00261
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.92016
Value Function Update Magnitude: 0.66602
Collected Steps per Second: 13,250.86327
Overall Steps per Second: 7,251.54657
Timestep Collection Time: 3.77485
Timestep Consumption Time: 3.12299
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.89784
Cumulative Model Updates: 164,789
Cumulative Timesteps: 1,281,807,510
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1281807510...
Checkpoint 1281807510 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55561
Policy Entropy: 4.35499
Value Function Loss: 0.00255
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.88323
Value Function Update Magnitude: 0.69526
Collected Steps per Second: 13,334.53040
Overall Steps per Second: 7,305.45419
Timestep Collection Time: 3.75026
Timestep Consumption Time: 3.09503
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.84530
Cumulative Model Updates: 164,798
Cumulative Timesteps: 1,281,857,518
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66648
Policy Entropy: 4.35798
Value Function Loss: 0.00249
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.89541
Value Function Update Magnitude: 0.64518
Collected Steps per Second: 13,137.32554
Overall Steps per Second: 7,173.53374
Timestep Collection Time: 3.80641
Timestep Consumption Time: 3.16450
PPO Batch Consumption Time: 0.23828
Total Iteration Time: 6.97090
Cumulative Model Updates: 164,807
Cumulative Timesteps: 1,281,907,524
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1281907524...
Checkpoint 1281907524 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11534
Policy Entropy: 4.35221
Value Function Loss: 0.00254
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.92046
Value Function Update Magnitude: 0.67932
Collected Steps per Second: 13,102.85622
Overall Steps per Second: 7,204.20427
Timestep Collection Time: 3.81917
Timestep Consumption Time: 3.12705
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.94622
Cumulative Model Updates: 164,816
Cumulative Timesteps: 1,281,957,566
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.51189
Policy Entropy: 4.35227
Value Function Loss: 0.00260
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.91666
Value Function Update Magnitude: 0.68552
Collected Steps per Second: 13,312.87353
Overall Steps per Second: 7,304.82484
Timestep Collection Time: 3.75742
Timestep Consumption Time: 3.09039
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.84780
Cumulative Model Updates: 164,825
Cumulative Timesteps: 1,282,007,588
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1282007588...
Checkpoint 1282007588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.98728
Policy Entropy: 4.35231
Value Function Loss: 0.00257
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02633
Policy Update Magnitude: 0.91049
Value Function Update Magnitude: 0.68017
Collected Steps per Second: 13,491.73407
Overall Steps per Second: 7,344.14477
Timestep Collection Time: 3.70849
Timestep Consumption Time: 3.10428
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.81277
Cumulative Model Updates: 164,834
Cumulative Timesteps: 1,282,057,622
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75873
Policy Entropy: 4.35511
Value Function Loss: 0.00262
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.91248
Value Function Update Magnitude: 0.74993
Collected Steps per Second: 12,992.01572
Overall Steps per Second: 7,165.02502
Timestep Collection Time: 3.85036
Timestep Consumption Time: 3.13133
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.98169
Cumulative Model Updates: 164,843
Cumulative Timesteps: 1,282,107,646
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1282107646...
Checkpoint 1282107646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.48560
Policy Entropy: 4.35510
Value Function Loss: 0.00253
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.93587
Value Function Update Magnitude: 0.78648
Collected Steps per Second: 13,184.45689
Overall Steps per Second: 7,333.23766
Timestep Collection Time: 3.79492
Timestep Consumption Time: 3.02798
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.82291
Cumulative Model Updates: 164,852
Cumulative Timesteps: 1,282,157,680
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84559
Policy Entropy: 4.35223
Value Function Loss: 0.00259
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.93191
Value Function Update Magnitude: 0.74148
Collected Steps per Second: 13,053.47475
Overall Steps per Second: 7,190.42388
Timestep Collection Time: 3.83208
Timestep Consumption Time: 3.12467
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.95675
Cumulative Model Updates: 164,861
Cumulative Timesteps: 1,282,207,702
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1282207702...
Checkpoint 1282207702 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95250
Policy Entropy: 4.34990
Value Function Loss: 0.00267
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02718
Policy Update Magnitude: 0.92542
Value Function Update Magnitude: 0.71175
Collected Steps per Second: 13,213.67935
Overall Steps per Second: 7,219.68168
Timestep Collection Time: 3.78547
Timestep Consumption Time: 3.14281
PPO Batch Consumption Time: 0.23338
Total Iteration Time: 6.92828
Cumulative Model Updates: 164,870
Cumulative Timesteps: 1,282,257,722
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35290
Policy Entropy: 4.34975
Value Function Loss: 0.00264
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.91955
Value Function Update Magnitude: 0.74072
Collected Steps per Second: 13,190.54166
Overall Steps per Second: 7,346.22791
Timestep Collection Time: 3.79120
Timestep Consumption Time: 3.01610
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.80730
Cumulative Model Updates: 164,879
Cumulative Timesteps: 1,282,307,730
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1282307730...
Checkpoint 1282307730 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81935
Policy Entropy: 4.34501
Value Function Loss: 0.00269
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02828
Policy Update Magnitude: 0.93068
Value Function Update Magnitude: 0.72366
Collected Steps per Second: 13,141.53547
Overall Steps per Second: 7,212.56635
Timestep Collection Time: 3.80808
Timestep Consumption Time: 3.13037
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.93845
Cumulative Model Updates: 164,888
Cumulative Timesteps: 1,282,357,774
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.04087
Policy Entropy: 4.34770
Value Function Loss: 0.00256
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02814
Policy Update Magnitude: 0.92559
Value Function Update Magnitude: 0.71333
Collected Steps per Second: 13,140.83263
Overall Steps per Second: 7,225.31487
Timestep Collection Time: 3.80691
Timestep Consumption Time: 3.11680
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.92371
Cumulative Model Updates: 164,897
Cumulative Timesteps: 1,282,407,800
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1282407800...
Checkpoint 1282407800 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66788
Policy Entropy: 4.34355
Value Function Loss: 0.00274
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.92710
Value Function Update Magnitude: 0.71526
Collected Steps per Second: 13,450.89311
Overall Steps per Second: 7,291.48366
Timestep Collection Time: 3.71841
Timestep Consumption Time: 3.14109
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.85951
Cumulative Model Updates: 164,906
Cumulative Timesteps: 1,282,457,816
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00090
Policy Entropy: 4.34488
Value Function Loss: 0.00256
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.92363
Value Function Update Magnitude: 0.71899
Collected Steps per Second: 13,243.38067
Overall Steps per Second: 7,245.15342
Timestep Collection Time: 3.77608
Timestep Consumption Time: 3.12619
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.90227
Cumulative Model Updates: 164,915
Cumulative Timesteps: 1,282,507,824
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1282507824...
Checkpoint 1282507824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.08912
Policy Entropy: 4.34603
Value Function Loss: 0.00245
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.91284
Value Function Update Magnitude: 0.68581
Collected Steps per Second: 13,178.57264
Overall Steps per Second: 7,256.10708
Timestep Collection Time: 3.79677
Timestep Consumption Time: 3.09894
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.89571
Cumulative Model Updates: 164,924
Cumulative Timesteps: 1,282,557,860
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.54761
Policy Entropy: 4.34642
Value Function Loss: 0.00235
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.88371
Value Function Update Magnitude: 0.64751
Collected Steps per Second: 13,685.42898
Overall Steps per Second: 7,149.88080
Timestep Collection Time: 3.65659
Timestep Consumption Time: 3.34241
PPO Batch Consumption Time: 0.24618
Total Iteration Time: 6.99900
Cumulative Model Updates: 164,933
Cumulative Timesteps: 1,282,607,902
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1282607902...
Checkpoint 1282607902 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56926
Policy Entropy: 4.34896
Value Function Loss: 0.00230
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.87890
Value Function Update Magnitude: 0.65269
Collected Steps per Second: 13,245.85153
Overall Steps per Second: 7,198.39558
Timestep Collection Time: 3.77567
Timestep Consumption Time: 3.17199
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.94766
Cumulative Model Updates: 164,942
Cumulative Timesteps: 1,282,657,914
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.36700
Policy Entropy: 4.34846
Value Function Loss: 0.00247
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02506
Policy Update Magnitude: 0.89941
Value Function Update Magnitude: 0.67187
Collected Steps per Second: 13,246.17486
Overall Steps per Second: 7,377.59789
Timestep Collection Time: 3.77603
Timestep Consumption Time: 3.00368
PPO Batch Consumption Time: 0.22794
Total Iteration Time: 6.77971
Cumulative Model Updates: 164,951
Cumulative Timesteps: 1,282,707,932
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1282707932...
Checkpoint 1282707932 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10426
Policy Entropy: 4.34793
Value Function Loss: 0.00243
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.91295
Value Function Update Magnitude: 0.74837
Collected Steps per Second: 12,927.35948
Overall Steps per Second: 7,156.18049
Timestep Collection Time: 3.87086
Timestep Consumption Time: 3.12170
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.99256
Cumulative Model Updates: 164,960
Cumulative Timesteps: 1,282,757,972
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83389
Policy Entropy: 4.34760
Value Function Loss: 0.00240
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.92613
Value Function Update Magnitude: 0.70381
Collected Steps per Second: 13,215.36832
Overall Steps per Second: 7,283.16353
Timestep Collection Time: 3.78574
Timestep Consumption Time: 3.08352
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.86927
Cumulative Model Updates: 164,969
Cumulative Timesteps: 1,282,808,002
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1282808002...
Checkpoint 1282808002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20046
Policy Entropy: 4.34790
Value Function Loss: 0.00243
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.91688
Value Function Update Magnitude: 0.70361
Collected Steps per Second: 12,893.84308
Overall Steps per Second: 7,245.12708
Timestep Collection Time: 3.87782
Timestep Consumption Time: 3.02337
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.90119
Cumulative Model Updates: 164,978
Cumulative Timesteps: 1,282,858,002
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22794
Policy Entropy: 4.35130
Value Function Loss: 0.00242
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02387
Policy Update Magnitude: 0.91270
Value Function Update Magnitude: 0.70185
Collected Steps per Second: 13,126.87847
Overall Steps per Second: 7,212.14779
Timestep Collection Time: 3.80959
Timestep Consumption Time: 3.12427
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.93386
Cumulative Model Updates: 164,987
Cumulative Timesteps: 1,282,908,010
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1282908010...
Checkpoint 1282908010 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93331
Policy Entropy: 4.35087
Value Function Loss: 0.00247
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02387
Policy Update Magnitude: 0.93487
Value Function Update Magnitude: 0.69518
Collected Steps per Second: 13,117.49475
Overall Steps per Second: 7,192.94610
Timestep Collection Time: 3.81338
Timestep Consumption Time: 3.14093
PPO Batch Consumption Time: 0.23253
Total Iteration Time: 6.95431
Cumulative Model Updates: 164,996
Cumulative Timesteps: 1,282,958,032
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73330
Policy Entropy: 4.35127
Value Function Loss: 0.00234
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.91391
Value Function Update Magnitude: 0.71018
Collected Steps per Second: 13,475.81800
Overall Steps per Second: 7,318.94066
Timestep Collection Time: 3.71139
Timestep Consumption Time: 3.12211
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.83350
Cumulative Model Updates: 165,005
Cumulative Timesteps: 1,283,008,046
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1283008046...
Checkpoint 1283008046 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.57920
Policy Entropy: 4.35064
Value Function Loss: 0.00239
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.90803
Value Function Update Magnitude: 0.67486
Collected Steps per Second: 13,291.84322
Overall Steps per Second: 7,235.08505
Timestep Collection Time: 3.76321
Timestep Consumption Time: 3.15032
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.91353
Cumulative Model Updates: 165,014
Cumulative Timesteps: 1,283,058,066
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02134
Policy Entropy: 4.35015
Value Function Loss: 0.00231
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.92217
Value Function Update Magnitude: 0.71748
Collected Steps per Second: 13,188.03239
Overall Steps per Second: 7,336.71776
Timestep Collection Time: 3.79207
Timestep Consumption Time: 3.02433
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.81640
Cumulative Model Updates: 165,023
Cumulative Timesteps: 1,283,108,076
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1283108076...
Checkpoint 1283108076 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56173
Policy Entropy: 4.35002
Value Function Loss: 0.00238
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.92978
Value Function Update Magnitude: 0.68192
Collected Steps per Second: 13,251.61118
Overall Steps per Second: 7,221.71486
Timestep Collection Time: 3.77313
Timestep Consumption Time: 3.15044
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.92356
Cumulative Model Updates: 165,032
Cumulative Timesteps: 1,283,158,076
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56312
Policy Entropy: 4.35150
Value Function Loss: 0.00244
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.93117
Value Function Update Magnitude: 0.70704
Collected Steps per Second: 13,257.03733
Overall Steps per Second: 7,313.18799
Timestep Collection Time: 3.77219
Timestep Consumption Time: 3.06587
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.83806
Cumulative Model Updates: 165,041
Cumulative Timesteps: 1,283,208,084
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1283208084...
Checkpoint 1283208084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75891
Policy Entropy: 4.34764
Value Function Loss: 0.00260
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.94029
Value Function Update Magnitude: 0.70504
Collected Steps per Second: 13,357.77941
Overall Steps per Second: 7,382.40418
Timestep Collection Time: 3.74359
Timestep Consumption Time: 3.03009
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.77367
Cumulative Model Updates: 165,050
Cumulative Timesteps: 1,283,258,090
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39361
Policy Entropy: 4.34666
Value Function Loss: 0.00252
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.92486
Value Function Update Magnitude: 0.64888
Collected Steps per Second: 13,197.99629
Overall Steps per Second: 7,187.88184
Timestep Collection Time: 3.79179
Timestep Consumption Time: 3.17049
PPO Batch Consumption Time: 0.23288
Total Iteration Time: 6.96227
Cumulative Model Updates: 165,059
Cumulative Timesteps: 1,283,308,134
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1283308134...
Checkpoint 1283308134 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.13831
Policy Entropy: 4.34509
Value Function Loss: 0.00275
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.94193
Value Function Update Magnitude: 0.68946
Collected Steps per Second: 13,226.29830
Overall Steps per Second: 7,271.27081
Timestep Collection Time: 3.78231
Timestep Consumption Time: 3.09764
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.87995
Cumulative Model Updates: 165,068
Cumulative Timesteps: 1,283,358,160
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.23416
Policy Entropy: 4.34518
Value Function Loss: 0.00277
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.96102
Value Function Update Magnitude: 0.70561
Collected Steps per Second: 13,346.96711
Overall Steps per Second: 7,262.43151
Timestep Collection Time: 3.74932
Timestep Consumption Time: 3.14121
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.89053
Cumulative Model Updates: 165,077
Cumulative Timesteps: 1,283,408,202
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1283408202...
Checkpoint 1283408202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17806
Policy Entropy: 4.34290
Value Function Loss: 0.00286
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.95929
Value Function Update Magnitude: 0.68934
Collected Steps per Second: 13,039.02088
Overall Steps per Second: 7,196.56116
Timestep Collection Time: 3.83740
Timestep Consumption Time: 3.11536
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.95277
Cumulative Model Updates: 165,086
Cumulative Timesteps: 1,283,458,238
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30816
Policy Entropy: 4.34452
Value Function Loss: 0.00287
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.95901
Value Function Update Magnitude: 0.70935
Collected Steps per Second: 13,197.56291
Overall Steps per Second: 7,266.87157
Timestep Collection Time: 3.79115
Timestep Consumption Time: 3.09406
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.88522
Cumulative Model Updates: 165,095
Cumulative Timesteps: 1,283,508,272
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1283508272...
Checkpoint 1283508272 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22373
Policy Entropy: 4.34572
Value Function Loss: 0.00273
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02896
Policy Update Magnitude: 0.94488
Value Function Update Magnitude: 0.72256
Collected Steps per Second: 13,462.85176
Overall Steps per Second: 7,339.62951
Timestep Collection Time: 3.71526
Timestep Consumption Time: 3.09952
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.81479
Cumulative Model Updates: 165,104
Cumulative Timesteps: 1,283,558,290
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10052
Policy Entropy: 4.34939
Value Function Loss: 0.00255
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.91950
Value Function Update Magnitude: 0.71580
Collected Steps per Second: 13,177.36178
Overall Steps per Second: 7,220.44609
Timestep Collection Time: 3.79454
Timestep Consumption Time: 3.13052
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.92506
Cumulative Model Updates: 165,113
Cumulative Timesteps: 1,283,608,292
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1283608292...
Checkpoint 1283608292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05479
Policy Entropy: 4.35085
Value Function Loss: 0.00253
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02585
Policy Update Magnitude: 0.89690
Value Function Update Magnitude: 0.71470
Collected Steps per Second: 13,043.45615
Overall Steps per Second: 7,280.36114
Timestep Collection Time: 3.83365
Timestep Consumption Time: 3.03469
PPO Batch Consumption Time: 0.23012
Total Iteration Time: 6.86834
Cumulative Model Updates: 165,122
Cumulative Timesteps: 1,283,658,296
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49907
Policy Entropy: 4.35436
Value Function Loss: 0.00241
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.90340
Value Function Update Magnitude: 0.73045
Collected Steps per Second: 13,162.36178
Overall Steps per Second: 7,227.70988
Timestep Collection Time: 3.79917
Timestep Consumption Time: 3.11948
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.91865
Cumulative Model Updates: 165,131
Cumulative Timesteps: 1,283,708,302
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1283708302...
Checkpoint 1283708302 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66594
Policy Entropy: 4.35129
Value Function Loss: 0.00253
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02568
Policy Update Magnitude: 0.91177
Value Function Update Magnitude: 0.72515
Collected Steps per Second: 13,351.10741
Overall Steps per Second: 7,323.48215
Timestep Collection Time: 3.74755
Timestep Consumption Time: 3.08444
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.83200
Cumulative Model Updates: 165,140
Cumulative Timesteps: 1,283,758,336
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48475
Policy Entropy: 4.35621
Value Function Loss: 0.00238
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.91040
Value Function Update Magnitude: 0.67247
Collected Steps per Second: 13,287.51204
Overall Steps per Second: 7,369.55715
Timestep Collection Time: 3.76399
Timestep Consumption Time: 3.02258
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.78657
Cumulative Model Updates: 165,149
Cumulative Timesteps: 1,283,808,350
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1283808350...
Checkpoint 1283808350 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89062
Policy Entropy: 4.35309
Value Function Loss: 0.00244
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.88553
Value Function Update Magnitude: 0.66027
Collected Steps per Second: 13,232.60285
Overall Steps per Second: 7,224.78431
Timestep Collection Time: 3.77960
Timestep Consumption Time: 3.14296
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.92256
Cumulative Model Updates: 165,158
Cumulative Timesteps: 1,283,858,364
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.40129
Policy Entropy: 4.34867
Value Function Loss: 0.00261
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.91716
Value Function Update Magnitude: 0.68052
Collected Steps per Second: 13,501.97887
Overall Steps per Second: 7,358.28365
Timestep Collection Time: 3.70494
Timestep Consumption Time: 3.09339
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.79832
Cumulative Model Updates: 165,167
Cumulative Timesteps: 1,283,908,388
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1283908388...
Checkpoint 1283908388 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.32079
Policy Entropy: 4.34472
Value Function Loss: 0.00279
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.93924
Value Function Update Magnitude: 0.72097
Collected Steps per Second: 13,533.62880
Overall Steps per Second: 7,341.81987
Timestep Collection Time: 3.69613
Timestep Consumption Time: 3.11717
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.81330
Cumulative Model Updates: 165,176
Cumulative Timesteps: 1,283,958,410
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.32032
Policy Entropy: 4.34098
Value Function Loss: 0.00293
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.95619
Value Function Update Magnitude: 0.72246
Collected Steps per Second: 13,249.92463
Overall Steps per Second: 7,061.13266
Timestep Collection Time: 3.77678
Timestep Consumption Time: 3.31019
PPO Batch Consumption Time: 0.24500
Total Iteration Time: 7.08696
Cumulative Model Updates: 165,185
Cumulative Timesteps: 1,284,008,452
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1284008452...
Checkpoint 1284008452 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20059
Policy Entropy: 4.34470
Value Function Loss: 0.00271
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.92645
Value Function Update Magnitude: 0.69494
Collected Steps per Second: 13,186.32359
Overall Steps per Second: 7,335.15637
Timestep Collection Time: 3.79317
Timestep Consumption Time: 3.02577
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.81894
Cumulative Model Updates: 165,194
Cumulative Timesteps: 1,284,058,470
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.14719
Policy Entropy: 4.34176
Value Function Loss: 0.00284
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.91737
Value Function Update Magnitude: 0.69379
Collected Steps per Second: 13,262.96986
Overall Steps per Second: 7,262.02176
Timestep Collection Time: 3.77050
Timestep Consumption Time: 3.11574
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.88624
Cumulative Model Updates: 165,203
Cumulative Timesteps: 1,284,108,478
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1284108478...
Checkpoint 1284108478 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45009
Policy Entropy: 4.34523
Value Function Loss: 0.00268
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02668
Policy Update Magnitude: 0.92887
Value Function Update Magnitude: 0.71516
Collected Steps per Second: 13,119.72669
Overall Steps per Second: 7,246.12372
Timestep Collection Time: 3.81106
Timestep Consumption Time: 3.08919
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.90024
Cumulative Model Updates: 165,212
Cumulative Timesteps: 1,284,158,478
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01834
Policy Entropy: 4.34463
Value Function Loss: 0.00263
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.92903
Value Function Update Magnitude: 0.72302
Collected Steps per Second: 13,566.49906
Overall Steps per Second: 7,356.69163
Timestep Collection Time: 3.68879
Timestep Consumption Time: 3.11372
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.80251
Cumulative Model Updates: 165,221
Cumulative Timesteps: 1,284,208,522
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1284208522...
Checkpoint 1284208522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.24415
Policy Entropy: 4.35052
Value Function Loss: 0.00248
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.90300
Value Function Update Magnitude: 0.72209
Collected Steps per Second: 13,299.31678
Overall Steps per Second: 7,268.65511
Timestep Collection Time: 3.76260
Timestep Consumption Time: 3.12176
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.88435
Cumulative Model Updates: 165,230
Cumulative Timesteps: 1,284,258,562
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.57815
Policy Entropy: 4.35003
Value Function Loss: 0.00254
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.90284
Value Function Update Magnitude: 0.69696
Collected Steps per Second: 13,147.92153
Overall Steps per Second: 7,267.07950
Timestep Collection Time: 3.80440
Timestep Consumption Time: 3.07869
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.88310
Cumulative Model Updates: 165,239
Cumulative Timesteps: 1,284,308,582
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1284308582...
Checkpoint 1284308582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27275
Policy Entropy: 4.34778
Value Function Loss: 0.00273
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.91326
Value Function Update Magnitude: 0.73425
Collected Steps per Second: 13,507.32304
Overall Steps per Second: 7,156.94016
Timestep Collection Time: 3.70229
Timestep Consumption Time: 3.28506
PPO Batch Consumption Time: 0.23813
Total Iteration Time: 6.98734
Cumulative Model Updates: 165,248
Cumulative Timesteps: 1,284,358,590
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96404
Policy Entropy: 4.35041
Value Function Loss: 0.00266
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.90484
Value Function Update Magnitude: 0.76173
Collected Steps per Second: 13,202.44770
Overall Steps per Second: 7,242.84710
Timestep Collection Time: 3.78748
Timestep Consumption Time: 3.11644
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.90391
Cumulative Model Updates: 165,257
Cumulative Timesteps: 1,284,408,594
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1284408594...
Checkpoint 1284408594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.41631
Policy Entropy: 4.34772
Value Function Loss: 0.00255
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02434
Policy Update Magnitude: 0.89588
Value Function Update Magnitude: 0.69589
Collected Steps per Second: 12,974.52857
Overall Steps per Second: 7,284.92765
Timestep Collection Time: 3.85509
Timestep Consumption Time: 3.01087
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.86596
Cumulative Model Updates: 165,266
Cumulative Timesteps: 1,284,458,612
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81377
Policy Entropy: 4.35195
Value Function Loss: 0.00262
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.89044
Value Function Update Magnitude: 0.69937
Collected Steps per Second: 13,352.37724
Overall Steps per Second: 7,281.78622
Timestep Collection Time: 3.74615
Timestep Consumption Time: 3.12304
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.86919
Cumulative Model Updates: 165,275
Cumulative Timesteps: 1,284,508,632
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1284508632...
Checkpoint 1284508632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53439
Policy Entropy: 4.34963
Value Function Loss: 0.00265
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02404
Policy Update Magnitude: 0.90896
Value Function Update Magnitude: 0.74104
Collected Steps per Second: 13,276.94111
Overall Steps per Second: 7,283.91947
Timestep Collection Time: 3.76683
Timestep Consumption Time: 3.09925
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.86608
Cumulative Model Updates: 165,284
Cumulative Timesteps: 1,284,558,644
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33092
Policy Entropy: 4.34708
Value Function Loss: 0.00265
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02668
Policy Update Magnitude: 0.90710
Value Function Update Magnitude: 0.73755
Collected Steps per Second: 13,193.39944
Overall Steps per Second: 7,345.72019
Timestep Collection Time: 3.79038
Timestep Consumption Time: 3.01739
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.80777
Cumulative Model Updates: 165,293
Cumulative Timesteps: 1,284,608,652
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1284608652...
Checkpoint 1284608652 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62559
Policy Entropy: 4.34821
Value Function Loss: 0.00242
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.90064
Value Function Update Magnitude: 0.69587
Collected Steps per Second: 13,334.40947
Overall Steps per Second: 7,264.50908
Timestep Collection Time: 3.75045
Timestep Consumption Time: 3.13371
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.88415
Cumulative Model Updates: 165,302
Cumulative Timesteps: 1,284,658,662
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11219
Policy Entropy: 4.34894
Value Function Loss: 0.00227
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.88897
Value Function Update Magnitude: 0.66906
Collected Steps per Second: 13,170.00907
Overall Steps per Second: 7,014.58386
Timestep Collection Time: 3.79802
Timestep Consumption Time: 3.33283
PPO Batch Consumption Time: 0.24497
Total Iteration Time: 7.13086
Cumulative Model Updates: 165,311
Cumulative Timesteps: 1,284,708,682
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1284708682...
Checkpoint 1284708682 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80915
Policy Entropy: 4.35577
Value Function Loss: 0.00216
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02451
Policy Update Magnitude: 0.88300
Value Function Update Magnitude: 0.64821
Collected Steps per Second: 13,442.27457
Overall Steps per Second: 7,298.50652
Timestep Collection Time: 3.72050
Timestep Consumption Time: 3.13186
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.85236
Cumulative Model Updates: 165,320
Cumulative Timesteps: 1,284,758,694
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05361
Policy Entropy: 4.35685
Value Function Loss: 0.00221
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.89442
Value Function Update Magnitude: 0.69282
Collected Steps per Second: 13,294.74768
Overall Steps per Second: 7,261.96887
Timestep Collection Time: 3.76254
Timestep Consumption Time: 3.12568
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.88821
Cumulative Model Updates: 165,329
Cumulative Timesteps: 1,284,808,716
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1284808716...
Checkpoint 1284808716 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.78448
Policy Entropy: 4.35403
Value Function Loss: 0.00242
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.91884
Value Function Update Magnitude: 0.72084
Collected Steps per Second: 13,092.87955
Overall Steps per Second: 7,345.93300
Timestep Collection Time: 3.82131
Timestep Consumption Time: 2.98953
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.81084
Cumulative Model Updates: 165,338
Cumulative Timesteps: 1,284,858,748
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69596
Policy Entropy: 4.34986
Value Function Loss: 0.00249
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.92790
Value Function Update Magnitude: 0.71138
Collected Steps per Second: 13,254.73321
Overall Steps per Second: 7,256.40193
Timestep Collection Time: 3.77329
Timestep Consumption Time: 3.11910
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.89240
Cumulative Model Updates: 165,347
Cumulative Timesteps: 1,284,908,762
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1284908762...
Checkpoint 1284908762 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.19013
Policy Entropy: 4.35110
Value Function Loss: 0.00249
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.90416
Value Function Update Magnitude: 0.74554
Collected Steps per Second: 13,202.73146
Overall Steps per Second: 7,264.02928
Timestep Collection Time: 3.78831
Timestep Consumption Time: 3.09713
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.88543
Cumulative Model Updates: 165,356
Cumulative Timesteps: 1,284,958,778
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01899
Policy Entropy: 4.35604
Value Function Loss: 0.00232
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.89379
Value Function Update Magnitude: 0.76580
Collected Steps per Second: 13,414.52775
Overall Steps per Second: 7,326.53015
Timestep Collection Time: 3.73088
Timestep Consumption Time: 3.10018
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.83106
Cumulative Model Updates: 165,365
Cumulative Timesteps: 1,285,008,826
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1285008826...
Checkpoint 1285008826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.40915
Policy Entropy: 4.35804
Value Function Loss: 0.00220
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.89360
Value Function Update Magnitude: 0.71826
Collected Steps per Second: 13,334.25246
Overall Steps per Second: 7,071.02701
Timestep Collection Time: 3.75139
Timestep Consumption Time: 3.32283
PPO Batch Consumption Time: 0.24587
Total Iteration Time: 7.07422
Cumulative Model Updates: 165,374
Cumulative Timesteps: 1,285,058,848
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68248
Policy Entropy: 4.35587
Value Function Loss: 0.00232
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.92014
Value Function Update Magnitude: 0.69747
Collected Steps per Second: 13,192.80273
Overall Steps per Second: 7,261.25388
Timestep Collection Time: 3.79313
Timestep Consumption Time: 3.09852
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.89165
Cumulative Model Updates: 165,383
Cumulative Timesteps: 1,285,108,890
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1285108890...
Checkpoint 1285108890 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.34816
Policy Entropy: 4.35188
Value Function Loss: 0.00251
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.95144
Value Function Update Magnitude: 0.70123
Collected Steps per Second: 13,570.89526
Overall Steps per Second: 7,346.47355
Timestep Collection Time: 3.68612
Timestep Consumption Time: 3.12313
PPO Batch Consumption Time: 0.22782
Total Iteration Time: 6.80925
Cumulative Model Updates: 165,392
Cumulative Timesteps: 1,285,158,914
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17824
Policy Entropy: 4.35205
Value Function Loss: 0.00271
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02506
Policy Update Magnitude: 0.96805
Value Function Update Magnitude: 0.72653
Collected Steps per Second: 13,248.04662
Overall Steps per Second: 7,233.75102
Timestep Collection Time: 3.77550
Timestep Consumption Time: 3.13903
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.91453
Cumulative Model Updates: 165,401
Cumulative Timesteps: 1,285,208,932
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1285208932...
Checkpoint 1285208932 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.69460
Policy Entropy: 4.35489
Value Function Loss: 0.00252
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.95207
Value Function Update Magnitude: 0.70192
Collected Steps per Second: 13,324.77655
Overall Steps per Second: 7,380.98646
Timestep Collection Time: 3.75406
Timestep Consumption Time: 3.02308
PPO Batch Consumption Time: 0.22946
Total Iteration Time: 6.77714
Cumulative Model Updates: 165,410
Cumulative Timesteps: 1,285,258,954
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.45218
Policy Entropy: 4.35552
Value Function Loss: 0.00239
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.92387
Value Function Update Magnitude: 0.68654
Collected Steps per Second: 13,459.28193
Overall Steps per Second: 7,314.97326
Timestep Collection Time: 3.71639
Timestep Consumption Time: 3.12163
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.83803
Cumulative Model Updates: 165,419
Cumulative Timesteps: 1,285,308,974
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1285308974...
Checkpoint 1285308974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54205
Policy Entropy: 4.35783
Value Function Loss: 0.00225
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.91380
Value Function Update Magnitude: 0.63675
Collected Steps per Second: 13,157.06060
Overall Steps per Second: 7,259.26821
Timestep Collection Time: 3.80161
Timestep Consumption Time: 3.08862
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.89023
Cumulative Model Updates: 165,428
Cumulative Timesteps: 1,285,358,992
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02324
Policy Entropy: 4.35420
Value Function Loss: 0.00245
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02506
Policy Update Magnitude: 0.92822
Value Function Update Magnitude: 0.62718
Collected Steps per Second: 13,321.70884
Overall Steps per Second: 7,331.78728
Timestep Collection Time: 3.75793
Timestep Consumption Time: 3.07015
PPO Batch Consumption Time: 0.23186
Total Iteration Time: 6.82808
Cumulative Model Updates: 165,437
Cumulative Timesteps: 1,285,409,054
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
Saving checkpoint 1285409054...
Checkpoint 1285409054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99945
Policy Entropy: 4.35540
Value Function Loss: 0.00243
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.92428
Value Function Update Magnitude: 0.67504
Collected Steps per Second: 13,323.81716
Overall Steps per Second: 7,280.55247
Timestep Collection Time: 3.75613
Timestep Consumption Time: 3.11780
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.87393
Cumulative Model Updates: 165,446
Cumulative Timesteps: 1,285,459,100
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87938
Policy Entropy: 4.35290
Value Function Loss: 0.00262
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.94133
Value Function Update Magnitude: 0.71286
Collected Steps per Second: 13,281.49653
Overall Steps per Second: 7,303.92964
Timestep Collection Time: 3.76569
Timestep Consumption Time: 3.08186
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.84755
Cumulative Model Updates: 165,455
Cumulative Timesteps: 1,285,509,114
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1285509114...
Checkpoint 1285509114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65868
Policy Entropy: 4.35226
Value Function Loss: 0.00271
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.95483
Value Function Update Magnitude: 0.70582
Collected Steps per Second: 13,448.32919
Overall Steps per Second: 7,304.10608
Timestep Collection Time: 3.71987
Timestep Consumption Time: 3.12916
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.84902
Cumulative Model Updates: 165,464
Cumulative Timesteps: 1,285,559,140
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24631
Policy Entropy: 4.34921
Value Function Loss: 0.00272
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02792
Policy Update Magnitude: 0.97428
Value Function Update Magnitude: 0.71071
Collected Steps per Second: 13,329.06631
Overall Steps per Second: 7,288.74802
Timestep Collection Time: 3.75375
Timestep Consumption Time: 3.11080
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.86455
Cumulative Model Updates: 165,473
Cumulative Timesteps: 1,285,609,174
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1285609174...
Checkpoint 1285609174 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10167
Policy Entropy: 4.35088
Value Function Loss: 0.00262
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.95981
Value Function Update Magnitude: 0.72502
Collected Steps per Second: 13,200.51025
Overall Steps per Second: 7,260.64542
Timestep Collection Time: 3.78819
Timestep Consumption Time: 3.09908
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.88727
Cumulative Model Updates: 165,482
Cumulative Timesteps: 1,285,659,180
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.54514
Policy Entropy: 4.35045
Value Function Loss: 0.00249
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.95558
Value Function Update Magnitude: 0.70898
Collected Steps per Second: 13,543.13872
Overall Steps per Second: 7,332.88120
Timestep Collection Time: 3.69353
Timestep Consumption Time: 3.12807
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.82160
Cumulative Model Updates: 165,491
Cumulative Timesteps: 1,285,709,202
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1285709202...
Checkpoint 1285709202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48260
Policy Entropy: 4.35215
Value Function Loss: 0.00250
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02766
Policy Update Magnitude: 0.93690
Value Function Update Magnitude: 0.67278
Collected Steps per Second: 13,400.48669
Overall Steps per Second: 7,157.50707
Timestep Collection Time: 3.73255
Timestep Consumption Time: 3.25564
PPO Batch Consumption Time: 0.23934
Total Iteration Time: 6.98819
Cumulative Model Updates: 165,500
Cumulative Timesteps: 1,285,759,220
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.14066
Policy Entropy: 4.35437
Value Function Loss: 0.00240
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.92737
Value Function Update Magnitude: 0.66542
Collected Steps per Second: 13,171.18564
Overall Steps per Second: 7,298.83310
Timestep Collection Time: 3.79890
Timestep Consumption Time: 3.05644
PPO Batch Consumption Time: 0.22920
Total Iteration Time: 6.85534
Cumulative Model Updates: 165,509
Cumulative Timesteps: 1,285,809,256
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1285809256...
Checkpoint 1285809256 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.05297
Policy Entropy: 4.35697
Value Function Loss: 0.00231
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.92077
Value Function Update Magnitude: 0.68094
Collected Steps per Second: 13,289.52254
Overall Steps per Second: 7,266.48025
Timestep Collection Time: 3.76251
Timestep Consumption Time: 3.11867
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.88119
Cumulative Model Updates: 165,518
Cumulative Timesteps: 1,285,859,258
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19058
Policy Entropy: 4.35520
Value Function Loss: 0.00233
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.93627
Value Function Update Magnitude: 0.67434
Collected Steps per Second: 13,208.71119
Overall Steps per Second: 7,271.79878
Timestep Collection Time: 3.78568
Timestep Consumption Time: 3.09074
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.87643
Cumulative Model Updates: 165,527
Cumulative Timesteps: 1,285,909,262
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1285909262...
Checkpoint 1285909262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.23621
Policy Entropy: 4.34952
Value Function Loss: 0.00257
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02785
Policy Update Magnitude: 0.96734
Value Function Update Magnitude: 0.68644
Collected Steps per Second: 13,290.77939
Overall Steps per Second: 7,385.07839
Timestep Collection Time: 3.76441
Timestep Consumption Time: 3.01033
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.77474
Cumulative Model Updates: 165,536
Cumulative Timesteps: 1,285,959,294
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61071
Policy Entropy: 4.34740
Value Function Loss: 0.00258
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02993
Policy Update Magnitude: 0.97629
Value Function Update Magnitude: 0.67322
Collected Steps per Second: 13,323.92276
Overall Steps per Second: 7,292.59167
Timestep Collection Time: 3.75535
Timestep Consumption Time: 3.10586
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.86121
Cumulative Model Updates: 165,545
Cumulative Timesteps: 1,286,009,330
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1286009330...
Checkpoint 1286009330 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18033
Policy Entropy: 4.35009
Value Function Loss: 0.00255
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.95681
Value Function Update Magnitude: 0.65617
Collected Steps per Second: 13,259.36907
Overall Steps per Second: 7,271.88627
Timestep Collection Time: 3.77137
Timestep Consumption Time: 3.10525
PPO Batch Consumption Time: 0.22920
Total Iteration Time: 6.87662
Cumulative Model Updates: 165,554
Cumulative Timesteps: 1,286,059,336
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14111
Policy Entropy: 4.35126
Value Function Loss: 0.00256
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02864
Policy Update Magnitude: 0.95794
Value Function Update Magnitude: 0.68017
Collected Steps per Second: 13,601.13299
Overall Steps per Second: 7,174.15983
Timestep Collection Time: 3.67763
Timestep Consumption Time: 3.29461
PPO Batch Consumption Time: 0.24441
Total Iteration Time: 6.97224
Cumulative Model Updates: 165,563
Cumulative Timesteps: 1,286,109,356
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1286109356...
Checkpoint 1286109356 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.35194
Policy Entropy: 4.34931
Value Function Loss: 0.00264
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02803
Policy Update Magnitude: 0.95841
Value Function Update Magnitude: 0.73195
Collected Steps per Second: 13,246.04501
Overall Steps per Second: 7,244.14374
Timestep Collection Time: 3.77758
Timestep Consumption Time: 3.12979
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.90737
Cumulative Model Updates: 165,572
Cumulative Timesteps: 1,286,159,394
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.98684
Policy Entropy: 4.34176
Value Function Loss: 0.00277
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02862
Policy Update Magnitude: 0.97516
Value Function Update Magnitude: 0.74779
Collected Steps per Second: 13,216.82566
Overall Steps per Second: 7,358.23717
Timestep Collection Time: 3.78351
Timestep Consumption Time: 3.01241
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.79592
Cumulative Model Updates: 165,581
Cumulative Timesteps: 1,286,209,400
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1286209400...
Checkpoint 1286209400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18305
Policy Entropy: 4.34398
Value Function Loss: 0.00270
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02838
Policy Update Magnitude: 0.98007
Value Function Update Magnitude: 0.71300
Collected Steps per Second: 13,318.28179
Overall Steps per Second: 7,274.68199
Timestep Collection Time: 3.75439
Timestep Consumption Time: 3.11904
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.87343
Cumulative Model Updates: 165,590
Cumulative Timesteps: 1,286,259,402
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.34241
Policy Entropy: 4.34863
Value Function Loss: 0.00259
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02834
Policy Update Magnitude: 0.96024
Value Function Update Magnitude: 0.71268
Collected Steps per Second: 13,131.08237
Overall Steps per Second: 7,249.64103
Timestep Collection Time: 3.81035
Timestep Consumption Time: 3.09123
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.90158
Cumulative Model Updates: 165,599
Cumulative Timesteps: 1,286,309,436
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1286309436...
Checkpoint 1286309436 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.94472
Policy Entropy: 4.35282
Value Function Loss: 0.00237
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02731
Policy Update Magnitude: 0.94059
Value Function Update Magnitude: 0.70583
Collected Steps per Second: 13,485.51145
Overall Steps per Second: 7,336.82454
Timestep Collection Time: 3.70798
Timestep Consumption Time: 3.10750
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.81548
Cumulative Model Updates: 165,608
Cumulative Timesteps: 1,286,359,440
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89658
Policy Entropy: 4.35506
Value Function Loss: 0.00224
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.90301
Value Function Update Magnitude: 0.69917
Collected Steps per Second: 13,182.83523
Overall Steps per Second: 7,198.30663
Timestep Collection Time: 3.79387
Timestep Consumption Time: 3.15415
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.94802
Cumulative Model Updates: 165,617
Cumulative Timesteps: 1,286,409,454
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1286409454...
Checkpoint 1286409454 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91793
Policy Entropy: 4.35442
Value Function Loss: 0.00241
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02714
Policy Update Magnitude: 0.92921
Value Function Update Magnitude: 0.70210
Collected Steps per Second: 13,173.82048
Overall Steps per Second: 7,227.69757
Timestep Collection Time: 3.79723
Timestep Consumption Time: 3.12392
PPO Batch Consumption Time: 0.23361
Total Iteration Time: 6.92115
Cumulative Model Updates: 165,626
Cumulative Timesteps: 1,286,459,478
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33962
Policy Entropy: 4.35310
Value Function Loss: 0.00246
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.93273
Value Function Update Magnitude: 0.73299
Collected Steps per Second: 13,567.23726
Overall Steps per Second: 7,375.86151
Timestep Collection Time: 3.68550
Timestep Consumption Time: 3.09364
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.77914
Cumulative Model Updates: 165,635
Cumulative Timesteps: 1,286,509,480
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1286509480...
Checkpoint 1286509480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76145
Policy Entropy: 4.34813
Value Function Loss: 0.00265
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02771
Policy Update Magnitude: 0.95535
Value Function Update Magnitude: 0.71317
Collected Steps per Second: 13,314.68500
Overall Steps per Second: 7,281.01671
Timestep Collection Time: 3.75540
Timestep Consumption Time: 3.11205
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.86745
Cumulative Model Updates: 165,644
Cumulative Timesteps: 1,286,559,482
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33621
Policy Entropy: 4.34645
Value Function Loss: 0.00263
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.97486
Value Function Update Magnitude: 0.71614
Collected Steps per Second: 13,148.49864
Overall Steps per Second: 7,330.77644
Timestep Collection Time: 3.80393
Timestep Consumption Time: 3.01881
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.82274
Cumulative Model Updates: 165,653
Cumulative Timesteps: 1,286,609,498
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1286609498...
Checkpoint 1286609498 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53365
Policy Entropy: 4.34430
Value Function Loss: 0.00271
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03024
Policy Update Magnitude: 0.99151
Value Function Update Magnitude: 0.69853
Collected Steps per Second: 13,319.34029
Overall Steps per Second: 7,264.67577
Timestep Collection Time: 3.75634
Timestep Consumption Time: 3.13068
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.88702
Cumulative Model Updates: 165,662
Cumulative Timesteps: 1,286,659,530
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18148
Policy Entropy: 4.34267
Value Function Loss: 0.00253
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.97003
Value Function Update Magnitude: 0.66970
Collected Steps per Second: 13,193.06616
Overall Steps per Second: 7,272.41095
Timestep Collection Time: 3.79199
Timestep Consumption Time: 3.08716
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.87915
Cumulative Model Updates: 165,671
Cumulative Timesteps: 1,286,709,558
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1286709558...
Checkpoint 1286709558 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75380
Policy Entropy: 4.34366
Value Function Loss: 0.00255
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.94627
Value Function Update Magnitude: 0.69508
Collected Steps per Second: 13,096.69883
Overall Steps per Second: 7,330.06673
Timestep Collection Time: 3.81837
Timestep Consumption Time: 3.00394
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.82231
Cumulative Model Updates: 165,680
Cumulative Timesteps: 1,286,759,566
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.77747
Policy Entropy: 4.34536
Value Function Loss: 0.00261
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02777
Policy Update Magnitude: 0.95965
Value Function Update Magnitude: 0.73325
Collected Steps per Second: 13,267.75482
Overall Steps per Second: 7,140.94077
Timestep Collection Time: 3.77065
Timestep Consumption Time: 3.23515
PPO Batch Consumption Time: 0.23875
Total Iteration Time: 7.00580
Cumulative Model Updates: 165,689
Cumulative Timesteps: 1,286,809,594
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1286809594...
Checkpoint 1286809594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90637
Policy Entropy: 4.34179
Value Function Loss: 0.00270
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02791
Policy Update Magnitude: 0.97725
Value Function Update Magnitude: 0.74802
Collected Steps per Second: 13,302.46042
Overall Steps per Second: 7,333.58417
Timestep Collection Time: 3.75945
Timestep Consumption Time: 3.05986
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.81931
Cumulative Model Updates: 165,698
Cumulative Timesteps: 1,286,859,604
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09454
Policy Entropy: 4.34169
Value Function Loss: 0.00277
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02960
Policy Update Magnitude: 0.98919
Value Function Update Magnitude: 0.75932
Collected Steps per Second: 13,132.36296
Overall Steps per Second: 7,353.27463
Timestep Collection Time: 3.80784
Timestep Consumption Time: 2.99266
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.80051
Cumulative Model Updates: 165,707
Cumulative Timesteps: 1,286,909,610
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1286909610...
Checkpoint 1286909610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.35120
Policy Entropy: 4.33748
Value Function Loss: 0.00279
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03108
Policy Update Magnitude: 0.99265
Value Function Update Magnitude: 0.74001
Collected Steps per Second: 13,341.70878
Overall Steps per Second: 7,247.54662
Timestep Collection Time: 3.75064
Timestep Consumption Time: 3.15376
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.90441
Cumulative Model Updates: 165,716
Cumulative Timesteps: 1,286,959,650
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.48847
Policy Entropy: 4.34201
Value Function Loss: 0.00278
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03175
Policy Update Magnitude: 0.98230
Value Function Update Magnitude: 0.72472
Collected Steps per Second: 13,183.82595
Overall Steps per Second: 7,276.49663
Timestep Collection Time: 3.79298
Timestep Consumption Time: 3.07928
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.87226
Cumulative Model Updates: 165,725
Cumulative Timesteps: 1,287,009,656
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1287009656...
Checkpoint 1287009656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.21565
Policy Entropy: 4.34346
Value Function Loss: 0.00255
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 0.94909
Value Function Update Magnitude: 0.70272
Collected Steps per Second: 13,420.85275
Overall Steps per Second: 7,316.19244
Timestep Collection Time: 3.72704
Timestep Consumption Time: 3.10985
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.83689
Cumulative Model Updates: 165,734
Cumulative Timesteps: 1,287,059,676
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77442
Policy Entropy: 4.34836
Value Function Loss: 0.00242
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.93384
Value Function Update Magnitude: 0.66754
Collected Steps per Second: 13,281.51231
Overall Steps per Second: 7,265.77403
Timestep Collection Time: 3.76493
Timestep Consumption Time: 3.11720
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.88213
Cumulative Model Updates: 165,743
Cumulative Timesteps: 1,287,109,680
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1287109680...
Checkpoint 1287109680 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62009
Policy Entropy: 4.34742
Value Function Loss: 0.00240
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.91355
Value Function Update Magnitude: 0.67741
Collected Steps per Second: 13,286.13201
Overall Steps per Second: 7,205.65382
Timestep Collection Time: 3.76362
Timestep Consumption Time: 3.17593
PPO Batch Consumption Time: 0.24030
Total Iteration Time: 6.93955
Cumulative Model Updates: 165,752
Cumulative Timesteps: 1,287,159,684
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.63290
Policy Entropy: 4.34641
Value Function Loss: 0.00248
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.92796
Value Function Update Magnitude: 0.66683
Collected Steps per Second: 13,310.09600
Overall Steps per Second: 7,266.46890
Timestep Collection Time: 3.75895
Timestep Consumption Time: 3.12637
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.88533
Cumulative Model Updates: 165,761
Cumulative Timesteps: 1,287,209,716
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1287209716...
Checkpoint 1287209716 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.56476
Policy Entropy: 4.34857
Value Function Loss: 0.00245
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.91532
Value Function Update Magnitude: 0.66851
Collected Steps per Second: 13,143.80277
Overall Steps per Second: 7,267.53722
Timestep Collection Time: 3.80499
Timestep Consumption Time: 3.07657
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.88156
Cumulative Model Updates: 165,770
Cumulative Timesteps: 1,287,259,728
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.76588
Policy Entropy: 4.34722
Value Function Loss: 0.00250
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.92974
Value Function Update Magnitude: 0.70619
Collected Steps per Second: 13,405.16019
Overall Steps per Second: 7,327.38346
Timestep Collection Time: 3.73140
Timestep Consumption Time: 3.09505
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.82645
Cumulative Model Updates: 165,779
Cumulative Timesteps: 1,287,309,748
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1287309748...
Checkpoint 1287309748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.15020
Policy Entropy: 4.34912
Value Function Loss: 0.00239
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.93013
Value Function Update Magnitude: 0.67010
Collected Steps per Second: 13,171.81041
Overall Steps per Second: 7,237.29223
Timestep Collection Time: 3.79599
Timestep Consumption Time: 3.11268
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.90866
Cumulative Model Updates: 165,788
Cumulative Timesteps: 1,287,359,748
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.60657
Policy Entropy: 4.34559
Value Function Loss: 0.00248
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02763
Policy Update Magnitude: 0.92218
Value Function Update Magnitude: 0.68381
Collected Steps per Second: 13,066.07206
Overall Steps per Second: 7,222.18257
Timestep Collection Time: 3.82839
Timestep Consumption Time: 3.09777
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.92616
Cumulative Model Updates: 165,797
Cumulative Timesteps: 1,287,409,770
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1287409770...
Checkpoint 1287409770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.06590
Policy Entropy: 4.34717
Value Function Loss: 0.00242
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.92098
Value Function Update Magnitude: 0.72841
Collected Steps per Second: 13,545.64815
Overall Steps per Second: 7,354.27263
Timestep Collection Time: 3.69240
Timestep Consumption Time: 3.10854
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.80094
Cumulative Model Updates: 165,806
Cumulative Timesteps: 1,287,459,786
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68321
Policy Entropy: 4.34613
Value Function Loss: 0.00245
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.91914
Value Function Update Magnitude: 0.70292
Collected Steps per Second: 13,151.82839
Overall Steps per Second: 7,015.43138
Timestep Collection Time: 3.80464
Timestep Consumption Time: 3.32792
PPO Batch Consumption Time: 0.24517
Total Iteration Time: 7.13256
Cumulative Model Updates: 165,815
Cumulative Timesteps: 1,287,509,824
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1287509824...
Checkpoint 1287509824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51611
Policy Entropy: 4.34306
Value Function Loss: 0.00244
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.92874
Value Function Update Magnitude: 0.64882
Collected Steps per Second: 13,327.23148
Overall Steps per Second: 7,375.86507
Timestep Collection Time: 3.75427
Timestep Consumption Time: 3.02921
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.78348
Cumulative Model Updates: 165,824
Cumulative Timesteps: 1,287,559,858
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.72008
Policy Entropy: 4.34213
Value Function Loss: 0.00243
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.92927
Value Function Update Magnitude: 0.64389
Collected Steps per Second: 13,366.24760
Overall Steps per Second: 7,262.79019
Timestep Collection Time: 3.74391
Timestep Consumption Time: 3.14628
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.89019
Cumulative Model Updates: 165,833
Cumulative Timesteps: 1,287,609,900
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1287609900...
Checkpoint 1287609900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79601
Policy Entropy: 4.34253
Value Function Loss: 0.00240
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.91670
Value Function Update Magnitude: 0.71505
Collected Steps per Second: 13,069.90603
Overall Steps per Second: 7,234.11543
Timestep Collection Time: 3.82880
Timestep Consumption Time: 3.08871
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.91750
Cumulative Model Updates: 165,842
Cumulative Timesteps: 1,287,659,942
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20806
Policy Entropy: 4.34086
Value Function Loss: 0.00252
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02722
Policy Update Magnitude: 0.94584
Value Function Update Magnitude: 0.69574
Collected Steps per Second: 13,204.60628
Overall Steps per Second: 7,341.64606
Timestep Collection Time: 3.78989
Timestep Consumption Time: 3.02657
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.81646
Cumulative Model Updates: 165,851
Cumulative Timesteps: 1,287,709,986
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1287709986...
Checkpoint 1287709986 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11127
Policy Entropy: 4.34594
Value Function Loss: 0.00245
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02725
Policy Update Magnitude: 0.94170
Value Function Update Magnitude: 0.71165
Collected Steps per Second: 13,192.71231
Overall Steps per Second: 7,243.69249
Timestep Collection Time: 3.79285
Timestep Consumption Time: 3.11495
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.90780
Cumulative Model Updates: 165,860
Cumulative Timesteps: 1,287,760,024
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.21318
Policy Entropy: 4.34772
Value Function Loss: 0.00234
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.89544
Value Function Update Magnitude: 0.67912
Collected Steps per Second: 13,279.66243
Overall Steps per Second: 7,313.61223
Timestep Collection Time: 3.76877
Timestep Consumption Time: 3.07436
PPO Batch Consumption Time: 0.22771
Total Iteration Time: 6.84313
Cumulative Model Updates: 165,869
Cumulative Timesteps: 1,287,810,072
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1287810072...
Checkpoint 1287810072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87829
Policy Entropy: 4.35111
Value Function Loss: 0.00231
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.88442
Value Function Update Magnitude: 0.64493
Collected Steps per Second: 13,285.00588
Overall Steps per Second: 7,076.08006
Timestep Collection Time: 3.76680
Timestep Consumption Time: 3.30519
PPO Batch Consumption Time: 0.24505
Total Iteration Time: 7.07199
Cumulative Model Updates: 165,878
Cumulative Timesteps: 1,287,860,114
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98596
Policy Entropy: 4.35104
Value Function Loss: 0.00242
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.90108
Value Function Update Magnitude: 0.63964
Collected Steps per Second: 13,292.63585
Overall Steps per Second: 7,270.44641
Timestep Collection Time: 3.76374
Timestep Consumption Time: 3.11755
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.88128
Cumulative Model Updates: 165,887
Cumulative Timesteps: 1,287,910,144
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1287910144...
Checkpoint 1287910144 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.12262
Policy Entropy: 4.34618
Value Function Loss: 0.00254
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.93516
Value Function Update Magnitude: 0.66876
Collected Steps per Second: 13,106.00398
Overall Steps per Second: 7,309.25826
Timestep Collection Time: 3.81627
Timestep Consumption Time: 3.02656
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.84283
Cumulative Model Updates: 165,896
Cumulative Timesteps: 1,287,960,160
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.12379
Policy Entropy: 4.34773
Value Function Loss: 0.00248
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.95422
Value Function Update Magnitude: 0.66957
Collected Steps per Second: 13,398.90608
Overall Steps per Second: 7,309.37960
Timestep Collection Time: 3.73568
Timestep Consumption Time: 3.11224
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.84791
Cumulative Model Updates: 165,905
Cumulative Timesteps: 1,288,010,214
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1288010214...
Checkpoint 1288010214 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58555
Policy Entropy: 4.35040
Value Function Loss: 0.00245
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.95582
Value Function Update Magnitude: 0.66463
Collected Steps per Second: 13,164.18946
Overall Steps per Second: 7,264.52032
Timestep Collection Time: 3.79955
Timestep Consumption Time: 3.08569
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.88524
Cumulative Model Updates: 165,914
Cumulative Timesteps: 1,288,060,232
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27459
Policy Entropy: 4.35220
Value Function Loss: 0.00249
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.94508
Value Function Update Magnitude: 0.70143
Collected Steps per Second: 13,130.35212
Overall Steps per Second: 7,327.05691
Timestep Collection Time: 3.80965
Timestep Consumption Time: 3.01738
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.82702
Cumulative Model Updates: 165,923
Cumulative Timesteps: 1,288,110,254
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1288110254...
Checkpoint 1288110254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57806
Policy Entropy: 4.35409
Value Function Loss: 0.00238
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.95216
Value Function Update Magnitude: 0.66495
Collected Steps per Second: 13,180.19994
Overall Steps per Second: 7,217.65867
Timestep Collection Time: 3.79478
Timestep Consumption Time: 3.13489
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.92967
Cumulative Model Updates: 165,932
Cumulative Timesteps: 1,288,160,270
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02225
Policy Entropy: 4.35070
Value Function Loss: 0.00260
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.99767
Value Function Update Magnitude: 0.71841
Collected Steps per Second: 13,234.18900
Overall Steps per Second: 7,104.74155
Timestep Collection Time: 3.77976
Timestep Consumption Time: 3.26089
PPO Batch Consumption Time: 0.24306
Total Iteration Time: 7.04065
Cumulative Model Updates: 165,941
Cumulative Timesteps: 1,288,210,292
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1288210292...
Checkpoint 1288210292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92247
Policy Entropy: 4.35003
Value Function Loss: 0.00264
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 1.01486
Value Function Update Magnitude: 0.72468
Collected Steps per Second: 13,666.88047
Overall Steps per Second: 7,377.73982
Timestep Collection Time: 3.66053
Timestep Consumption Time: 3.12041
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.78094
Cumulative Model Updates: 165,950
Cumulative Timesteps: 1,288,260,320
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61417
Policy Entropy: 4.34743
Value Function Loss: 0.00288
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 1.03510
Value Function Update Magnitude: 0.74601
Collected Steps per Second: 13,160.30515
Overall Steps per Second: 7,222.25187
Timestep Collection Time: 3.80204
Timestep Consumption Time: 3.12599
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.92803
Cumulative Model Updates: 165,959
Cumulative Timesteps: 1,288,310,356
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1288310356...
Checkpoint 1288310356 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.83524
Policy Entropy: 4.34714
Value Function Loss: 0.00272
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.99942
Value Function Update Magnitude: 0.73120
Collected Steps per Second: 13,218.32204
Overall Steps per Second: 7,344.88933
Timestep Collection Time: 3.78338
Timestep Consumption Time: 3.02543
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.80882
Cumulative Model Updates: 165,968
Cumulative Timesteps: 1,288,360,366
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.21619
Policy Entropy: 4.34644
Value Function Loss: 0.00260
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.98620
Value Function Update Magnitude: 0.71498
Collected Steps per Second: 13,092.00510
Overall Steps per Second: 7,197.42681
Timestep Collection Time: 3.82172
Timestep Consumption Time: 3.12993
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.95165
Cumulative Model Updates: 165,977
Cumulative Timesteps: 1,288,410,400
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1288410400...
Checkpoint 1288410400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.79266
Policy Entropy: 4.35042
Value Function Loss: 0.00245
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.95403
Value Function Update Magnitude: 0.70725
Collected Steps per Second: 13,100.45269
Overall Steps per Second: 7,261.96886
Timestep Collection Time: 3.81804
Timestep Consumption Time: 3.06963
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 6.88766
Cumulative Model Updates: 165,986
Cumulative Timesteps: 1,288,460,418
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.72542
Policy Entropy: 4.35086
Value Function Loss: 0.00256
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.97590
Value Function Update Magnitude: 0.71115
Collected Steps per Second: 13,136.79148
Overall Steps per Second: 7,339.99845
Timestep Collection Time: 3.80641
Timestep Consumption Time: 3.00613
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.81254
Cumulative Model Updates: 165,995
Cumulative Timesteps: 1,288,510,422
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1288510422...
Checkpoint 1288510422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46379
Policy Entropy: 4.34890
Value Function Loss: 0.00259
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 1.00007
Value Function Update Magnitude: 0.71879
Collected Steps per Second: 13,189.76256
Overall Steps per Second: 7,063.39182
Timestep Collection Time: 3.79309
Timestep Consumption Time: 3.28991
PPO Batch Consumption Time: 0.24536
Total Iteration Time: 7.08300
Cumulative Model Updates: 166,004
Cumulative Timesteps: 1,288,560,452
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57832
Policy Entropy: 4.34728
Value Function Loss: 0.00244
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02513
Policy Update Magnitude: 0.98081
Value Function Update Magnitude: 0.71516
Collected Steps per Second: 12,763.17476
Overall Steps per Second: 7,162.30335
Timestep Collection Time: 3.91846
Timestep Consumption Time: 3.06421
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.98267
Cumulative Model Updates: 166,013
Cumulative Timesteps: 1,288,610,464
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1288610464...
Checkpoint 1288610464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.04113
Policy Entropy: 4.35133
Value Function Loss: 0.00227
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.94229
Value Function Update Magnitude: 0.70111
Collected Steps per Second: 13,188.15103
Overall Steps per Second: 7,349.39200
Timestep Collection Time: 3.79386
Timestep Consumption Time: 3.01405
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.80791
Cumulative Model Updates: 166,022
Cumulative Timesteps: 1,288,660,498
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89506
Policy Entropy: 4.35128
Value Function Loss: 0.00228
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02363
Policy Update Magnitude: 0.92904
Value Function Update Magnitude: 0.72483
Collected Steps per Second: 13,219.70419
Overall Steps per Second: 7,261.01321
Timestep Collection Time: 3.78496
Timestep Consumption Time: 3.10609
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.89105
Cumulative Model Updates: 166,031
Cumulative Timesteps: 1,288,710,534
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1288710534...
Checkpoint 1288710534 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.92948
Policy Entropy: 4.35239
Value Function Loss: 0.00215
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02306
Policy Update Magnitude: 0.92565
Value Function Update Magnitude: 0.70804
Collected Steps per Second: 13,038.66401
Overall Steps per Second: 7,295.70718
Timestep Collection Time: 3.83644
Timestep Consumption Time: 3.01992
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.85636
Cumulative Model Updates: 166,040
Cumulative Timesteps: 1,288,760,556
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.03177
Policy Entropy: 4.35196
Value Function Loss: 0.00231
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.92548
Value Function Update Magnitude: 0.73452
Collected Steps per Second: 13,121.37672
Overall Steps per Second: 7,223.08632
Timestep Collection Time: 3.81088
Timestep Consumption Time: 3.11192
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.92280
Cumulative Model Updates: 166,049
Cumulative Timesteps: 1,288,810,560
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1288810560...
Checkpoint 1288810560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.74532
Policy Entropy: 4.35341
Value Function Loss: 0.00217
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.93554
Value Function Update Magnitude: 0.69708
Collected Steps per Second: 13,181.27784
Overall Steps per Second: 7,293.74431
Timestep Collection Time: 3.79356
Timestep Consumption Time: 3.06218
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.85574
Cumulative Model Updates: 166,058
Cumulative Timesteps: 1,288,860,564
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.57927
Policy Entropy: 4.35225
Value Function Loss: 0.00241
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.94174
Value Function Update Magnitude: 0.69125
Collected Steps per Second: 13,283.38681
Overall Steps per Second: 7,245.42365
Timestep Collection Time: 3.76485
Timestep Consumption Time: 3.13743
PPO Batch Consumption Time: 0.23824
Total Iteration Time: 6.90229
Cumulative Model Updates: 166,067
Cumulative Timesteps: 1,288,910,574
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1288910574...
Checkpoint 1288910574 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.30039
Policy Entropy: 4.35049
Value Function Loss: 0.00243
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.95366
Value Function Update Magnitude: 0.68301
Collected Steps per Second: 13,112.46144
Overall Steps per Second: 7,211.57053
Timestep Collection Time: 3.81317
Timestep Consumption Time: 3.12014
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.93330
Cumulative Model Updates: 166,076
Cumulative Timesteps: 1,288,960,574
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.59319
Policy Entropy: 4.34763
Value Function Loss: 0.00254
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02646
Policy Update Magnitude: 0.95574
Value Function Update Magnitude: 0.70480
Collected Steps per Second: 13,240.07756
Overall Steps per Second: 7,303.95718
Timestep Collection Time: 3.77823
Timestep Consumption Time: 3.07066
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.84889
Cumulative Model Updates: 166,085
Cumulative Timesteps: 1,289,010,598
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1289010598...
Checkpoint 1289010598 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.57267
Policy Entropy: 4.34877
Value Function Loss: 0.00242
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02541
Policy Update Magnitude: 0.96938
Value Function Update Magnitude: 0.72047
Collected Steps per Second: 13,556.64816
Overall Steps per Second: 7,376.95778
Timestep Collection Time: 3.68867
Timestep Consumption Time: 3.09001
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.77868
Cumulative Model Updates: 166,094
Cumulative Timesteps: 1,289,060,604
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.14414
Policy Entropy: 4.35398
Value Function Loss: 0.00227
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.95201
Value Function Update Magnitude: 0.68855
Collected Steps per Second: 13,222.89991
Overall Steps per Second: 7,268.66287
Timestep Collection Time: 3.78419
Timestep Consumption Time: 3.09988
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.88407
Cumulative Model Updates: 166,103
Cumulative Timesteps: 1,289,110,642
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1289110642...
Checkpoint 1289110642 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73881
Policy Entropy: 4.35872
Value Function Loss: 0.00227
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.92906
Value Function Update Magnitude: 0.69361
Collected Steps per Second: 13,140.59549
Overall Steps per Second: 7,269.12184
Timestep Collection Time: 3.80561
Timestep Consumption Time: 3.07390
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.87951
Cumulative Model Updates: 166,112
Cumulative Timesteps: 1,289,160,650
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87548
Policy Entropy: 4.35716
Value Function Loss: 0.00244
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.94291
Value Function Update Magnitude: 0.71765
Collected Steps per Second: 13,416.13536
Overall Steps per Second: 7,305.74968
Timestep Collection Time: 3.72894
Timestep Consumption Time: 3.11881
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.84776
Cumulative Model Updates: 166,121
Cumulative Timesteps: 1,289,210,678
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1289210678...
Checkpoint 1289210678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.28315
Policy Entropy: 4.35436
Value Function Loss: 0.00248
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.94831
Value Function Update Magnitude: 0.72305
Collected Steps per Second: 12,892.15340
Overall Steps per Second: 7,059.21054
Timestep Collection Time: 3.88097
Timestep Consumption Time: 3.20680
PPO Batch Consumption Time: 0.23621
Total Iteration Time: 7.08776
Cumulative Model Updates: 166,130
Cumulative Timesteps: 1,289,260,712
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.60395
Policy Entropy: 4.35239
Value Function Loss: 0.00248
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.95272
Value Function Update Magnitude: 0.77450
Collected Steps per Second: 13,295.11789
Overall Steps per Second: 7,282.12672
Timestep Collection Time: 3.76228
Timestep Consumption Time: 3.10659
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.86887
Cumulative Model Updates: 166,139
Cumulative Timesteps: 1,289,310,732
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1289310732...
Checkpoint 1289310732 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.58540
Policy Entropy: 4.35348
Value Function Loss: 0.00246
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.96859
Value Function Update Magnitude: 0.73387
Collected Steps per Second: 13,302.42468
Overall Steps per Second: 7,274.17864
Timestep Collection Time: 3.75947
Timestep Consumption Time: 3.11554
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.87500
Cumulative Model Updates: 166,148
Cumulative Timesteps: 1,289,360,742
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.57741
Policy Entropy: 4.34997
Value Function Loss: 0.00259
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.97334
Value Function Update Magnitude: 0.73584
Collected Steps per Second: 13,172.55411
Overall Steps per Second: 7,223.01105
Timestep Collection Time: 3.79683
Timestep Consumption Time: 3.12743
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.92426
Cumulative Model Updates: 166,157
Cumulative Timesteps: 1,289,410,756
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1289410756...
Checkpoint 1289410756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.04922
Policy Entropy: 4.35346
Value Function Loss: 0.00250
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02864
Policy Update Magnitude: 0.95340
Value Function Update Magnitude: 0.72317
Collected Steps per Second: 13,303.94913
Overall Steps per Second: 7,367.55517
Timestep Collection Time: 3.76279
Timestep Consumption Time: 3.03186
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.79466
Cumulative Model Updates: 166,166
Cumulative Timesteps: 1,289,460,816
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97072
Policy Entropy: 4.35607
Value Function Loss: 0.00238
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02883
Policy Update Magnitude: 0.94487
Value Function Update Magnitude: 0.70394
Collected Steps per Second: 13,301.43570
Overall Steps per Second: 7,259.54204
Timestep Collection Time: 3.76095
Timestep Consumption Time: 3.13012
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.89107
Cumulative Model Updates: 166,175
Cumulative Timesteps: 1,289,510,842
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1289510842...
Checkpoint 1289510842 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75162
Policy Entropy: 4.35390
Value Function Loss: 0.00235
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.94098
Value Function Update Magnitude: 0.67986
Collected Steps per Second: 13,261.91516
Overall Steps per Second: 7,305.58057
Timestep Collection Time: 3.77155
Timestep Consumption Time: 3.07500
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.84655
Cumulative Model Updates: 166,184
Cumulative Timesteps: 1,289,560,860
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06848
Policy Entropy: 4.34898
Value Function Loss: 0.00271
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.97816
Value Function Update Magnitude: 0.75997
Collected Steps per Second: 13,216.35659
Overall Steps per Second: 7,157.44811
Timestep Collection Time: 3.78319
Timestep Consumption Time: 3.20254
PPO Batch Consumption Time: 0.24497
Total Iteration Time: 6.98573
Cumulative Model Updates: 166,193
Cumulative Timesteps: 1,289,610,860
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1289610860...
Checkpoint 1289610860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.16649
Policy Entropy: 4.34775
Value Function Loss: 0.00268
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.98987
Value Function Update Magnitude: 0.79248
Collected Steps per Second: 13,322.87363
Overall Steps per Second: 7,290.57205
Timestep Collection Time: 3.75294
Timestep Consumption Time: 3.10523
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.85817
Cumulative Model Updates: 166,202
Cumulative Timesteps: 1,289,660,860
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.43471
Policy Entropy: 4.34905
Value Function Loss: 0.00260
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02725
Policy Update Magnitude: 0.96029
Value Function Update Magnitude: 0.78969
Collected Steps per Second: 13,231.82829
Overall Steps per Second: 7,268.10608
Timestep Collection Time: 3.77967
Timestep Consumption Time: 3.10135
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.88102
Cumulative Model Updates: 166,211
Cumulative Timesteps: 1,289,710,872
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1289710872...
Checkpoint 1289710872 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.67025
Policy Entropy: 4.35345
Value Function Loss: 0.00240
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.94037
Value Function Update Magnitude: 0.75921
Collected Steps per Second: 13,596.31431
Overall Steps per Second: 7,369.85836
Timestep Collection Time: 3.67806
Timestep Consumption Time: 3.10742
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.78548
Cumulative Model Updates: 166,220
Cumulative Timesteps: 1,289,760,880
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53701
Policy Entropy: 4.35436
Value Function Loss: 0.00233
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.92857
Value Function Update Magnitude: 0.74771
Collected Steps per Second: 13,308.06238
Overall Steps per Second: 7,273.65444
Timestep Collection Time: 3.75862
Timestep Consumption Time: 3.11825
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.87687
Cumulative Model Updates: 166,229
Cumulative Timesteps: 1,289,810,900
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1289810900...
Checkpoint 1289810900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.31927
Policy Entropy: 4.35463
Value Function Loss: 0.00229
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.92009
Value Function Update Magnitude: 0.70859
Collected Steps per Second: 13,201.18498
Overall Steps per Second: 7,275.61991
Timestep Collection Time: 3.78981
Timestep Consumption Time: 3.08658
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.87639
Cumulative Model Updates: 166,238
Cumulative Timesteps: 1,289,860,930
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48324
Policy Entropy: 4.35245
Value Function Loss: 0.00236
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.92451
Value Function Update Magnitude: 0.68319
Collected Steps per Second: 13,429.78193
Overall Steps per Second: 7,321.95565
Timestep Collection Time: 3.72605
Timestep Consumption Time: 3.10819
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.83424
Cumulative Model Updates: 166,247
Cumulative Timesteps: 1,289,910,970
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1289910970...
Checkpoint 1289910970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81344
Policy Entropy: 4.35043
Value Function Loss: 0.00233
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.93394
Value Function Update Magnitude: 0.69981
Collected Steps per Second: 13,258.29941
Overall Steps per Second: 7,244.36433
Timestep Collection Time: 3.77454
Timestep Consumption Time: 3.13345
PPO Batch Consumption Time: 0.23041
Total Iteration Time: 6.90799
Cumulative Model Updates: 166,256
Cumulative Timesteps: 1,289,961,014
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.59565
Policy Entropy: 4.34782
Value Function Loss: 0.00239
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02675
Policy Update Magnitude: 0.93390
Value Function Update Magnitude: 0.68537
Collected Steps per Second: 13,256.86036
Overall Steps per Second: 7,366.45951
Timestep Collection Time: 3.77465
Timestep Consumption Time: 3.01830
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.79295
Cumulative Model Updates: 166,265
Cumulative Timesteps: 1,290,011,054
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1290011054...
Checkpoint 1290011054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.98647
Policy Entropy: 4.34584
Value Function Loss: 0.00241
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02777
Policy Update Magnitude: 0.95900
Value Function Update Magnitude: 0.73579
Collected Steps per Second: 13,200.33835
Overall Steps per Second: 7,172.37159
Timestep Collection Time: 3.78915
Timestep Consumption Time: 3.18456
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.97370
Cumulative Model Updates: 166,274
Cumulative Timesteps: 1,290,061,072
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.10802
Policy Entropy: 4.34449
Value Function Loss: 0.00247
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02823
Policy Update Magnitude: 0.97154
Value Function Update Magnitude: 0.69807
Collected Steps per Second: 13,197.32068
Overall Steps per Second: 7,241.60980
Timestep Collection Time: 3.79062
Timestep Consumption Time: 3.11751
PPO Batch Consumption Time: 0.23074
Total Iteration Time: 6.90813
Cumulative Model Updates: 166,283
Cumulative Timesteps: 1,290,111,098
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1290111098...
Checkpoint 1290111098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.25184
Policy Entropy: 4.34516
Value Function Loss: 0.00256
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.95573
Value Function Update Magnitude: 0.65483
Collected Steps per Second: 12,871.59020
Overall Steps per Second: 7,226.30806
Timestep Collection Time: 3.88468
Timestep Consumption Time: 3.03476
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.91944
Cumulative Model Updates: 166,292
Cumulative Timesteps: 1,290,161,100
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.14643
Policy Entropy: 4.34783
Value Function Loss: 0.00251
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.94102
Value Function Update Magnitude: 0.72774
Collected Steps per Second: 13,365.80766
Overall Steps per Second: 7,276.71216
Timestep Collection Time: 3.74179
Timestep Consumption Time: 3.13110
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.87288
Cumulative Model Updates: 166,301
Cumulative Timesteps: 1,290,211,112
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1290211112...
Checkpoint 1290211112 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75529
Policy Entropy: 4.34630
Value Function Loss: 0.00248
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02488
Policy Update Magnitude: 0.95344
Value Function Update Magnitude: 0.73886
Collected Steps per Second: 13,097.99416
Overall Steps per Second: 7,248.75861
Timestep Collection Time: 3.81738
Timestep Consumption Time: 3.08035
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.89773
Cumulative Model Updates: 166,310
Cumulative Timesteps: 1,290,261,112
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.90921
Policy Entropy: 4.34785
Value Function Loss: 0.00242
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.96453
Value Function Update Magnitude: 0.71084
Collected Steps per Second: 13,621.22636
Overall Steps per Second: 7,175.83096
Timestep Collection Time: 3.67353
Timestep Consumption Time: 3.29960
PPO Batch Consumption Time: 0.24473
Total Iteration Time: 6.97313
Cumulative Model Updates: 166,319
Cumulative Timesteps: 1,290,311,150
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1290311150...
Checkpoint 1290311150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33191
Policy Entropy: 4.34817
Value Function Loss: 0.00233
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.95714
Value Function Update Magnitude: 0.71302
Collected Steps per Second: 13,156.91037
Overall Steps per Second: 7,183.12061
Timestep Collection Time: 3.80287
Timestep Consumption Time: 3.16263
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.96550
Cumulative Model Updates: 166,328
Cumulative Timesteps: 1,290,361,184
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.23170
Policy Entropy: 4.35390
Value Function Loss: 0.00216
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02439
Policy Update Magnitude: 0.92706
Value Function Update Magnitude: 0.66542
Collected Steps per Second: 13,295.04754
Overall Steps per Second: 7,366.67383
Timestep Collection Time: 3.76321
Timestep Consumption Time: 3.02846
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.79167
Cumulative Model Updates: 166,337
Cumulative Timesteps: 1,290,411,216
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1290411216...
Checkpoint 1290411216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.40398
Policy Entropy: 4.35628
Value Function Loss: 0.00205
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02376
Policy Update Magnitude: 0.91442
Value Function Update Magnitude: 0.69110
Collected Steps per Second: 13,312.10410
Overall Steps per Second: 7,286.57368
Timestep Collection Time: 3.75658
Timestep Consumption Time: 3.10645
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.86303
Cumulative Model Updates: 166,346
Cumulative Timesteps: 1,290,461,224
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22282
Policy Entropy: 4.35603
Value Function Loss: 0.00207
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.90667
Value Function Update Magnitude: 0.66231
Collected Steps per Second: 13,057.79212
Overall Steps per Second: 7,246.75504
Timestep Collection Time: 3.83204
Timestep Consumption Time: 3.07284
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.90488
Cumulative Model Updates: 166,355
Cumulative Timesteps: 1,290,511,262
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1290511262...
Checkpoint 1290511262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.47365
Policy Entropy: 4.35187
Value Function Loss: 0.00236
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.94710
Value Function Update Magnitude: 0.71069
Collected Steps per Second: 13,083.46040
Overall Steps per Second: 7,302.08260
Timestep Collection Time: 3.82437
Timestep Consumption Time: 3.02792
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.85229
Cumulative Model Updates: 166,364
Cumulative Timesteps: 1,290,561,298
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.12235
Policy Entropy: 4.34945
Value Function Loss: 0.00251
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.97758
Value Function Update Magnitude: 0.74916
Collected Steps per Second: 13,136.36559
Overall Steps per Second: 7,224.34791
Timestep Collection Time: 3.80775
Timestep Consumption Time: 3.11606
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.92381
Cumulative Model Updates: 166,373
Cumulative Timesteps: 1,290,611,318
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1290611318...
Checkpoint 1290611318 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.51149
Policy Entropy: 4.34808
Value Function Loss: 0.00267
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.97221
Value Function Update Magnitude: 0.77843
Collected Steps per Second: 13,199.11734
Overall Steps per Second: 7,068.91885
Timestep Collection Time: 3.79116
Timestep Consumption Time: 3.28771
PPO Batch Consumption Time: 0.24475
Total Iteration Time: 7.07888
Cumulative Model Updates: 166,382
Cumulative Timesteps: 1,290,661,358
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81410
Policy Entropy: 4.34538
Value Function Loss: 0.00276
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.97638
Value Function Update Magnitude: 0.79573
Collected Steps per Second: 13,522.16302
Overall Steps per Second: 7,339.34947
Timestep Collection Time: 3.69822
Timestep Consumption Time: 3.11546
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.81368
Cumulative Model Updates: 166,391
Cumulative Timesteps: 1,290,711,366
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1290711366...
Checkpoint 1290711366 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.39986
Policy Entropy: 4.33921
Value Function Loss: 0.00282
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.97965
Value Function Update Magnitude: 0.76976
Collected Steps per Second: 13,449.63069
Overall Steps per Second: 7,266.48669
Timestep Collection Time: 3.71772
Timestep Consumption Time: 3.16346
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.88118
Cumulative Model Updates: 166,400
Cumulative Timesteps: 1,290,761,368
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37520
Policy Entropy: 4.34334
Value Function Loss: 0.00270
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02753
Policy Update Magnitude: 0.97505
Value Function Update Magnitude: 0.73301
Collected Steps per Second: 13,226.90976
Overall Steps per Second: 7,273.27208
Timestep Collection Time: 3.78108
Timestep Consumption Time: 3.09506
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.87613
Cumulative Model Updates: 166,409
Cumulative Timesteps: 1,290,811,380
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1290811380...
Checkpoint 1290811380 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11670
Policy Entropy: 4.34481
Value Function Loss: 0.00270
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.97099
Value Function Update Magnitude: 0.72149
Collected Steps per Second: 13,569.46577
Overall Steps per Second: 7,358.91035
Timestep Collection Time: 3.68533
Timestep Consumption Time: 3.11024
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.79557
Cumulative Model Updates: 166,418
Cumulative Timesteps: 1,290,861,388
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.57861
Policy Entropy: 4.34688
Value Function Loss: 0.00261
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.96120
Value Function Update Magnitude: 0.71921
Collected Steps per Second: 13,371.40204
Overall Steps per Second: 7,289.67222
Timestep Collection Time: 3.74187
Timestep Consumption Time: 3.12182
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.86368
Cumulative Model Updates: 166,427
Cumulative Timesteps: 1,290,911,422
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1290911422...
Checkpoint 1290911422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45442
Policy Entropy: 4.34683
Value Function Loss: 0.00254
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02839
Policy Update Magnitude: 0.96286
Value Function Update Magnitude: 0.69634
Collected Steps per Second: 13,141.56857
Overall Steps per Second: 7,351.06044
Timestep Collection Time: 3.80548
Timestep Consumption Time: 2.99762
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.80310
Cumulative Model Updates: 166,436
Cumulative Timesteps: 1,290,961,432
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01075
Policy Entropy: 4.34852
Value Function Loss: 0.00249
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.94766
Value Function Update Magnitude: 0.69370
Collected Steps per Second: 13,284.75486
Overall Steps per Second: 7,090.40582
Timestep Collection Time: 3.76447
Timestep Consumption Time: 3.28873
PPO Batch Consumption Time: 0.24404
Total Iteration Time: 7.05319
Cumulative Model Updates: 166,445
Cumulative Timesteps: 1,291,011,442
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1291011442...
Checkpoint 1291011442 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.78131
Policy Entropy: 4.34698
Value Function Loss: 0.00265
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.96410
Value Function Update Magnitude: 0.75678
Collected Steps per Second: 13,285.86336
Overall Steps per Second: 7,293.47749
Timestep Collection Time: 3.76536
Timestep Consumption Time: 3.09365
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.85901
Cumulative Model Updates: 166,454
Cumulative Timesteps: 1,291,061,468
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.41353
Policy Entropy: 4.34552
Value Function Loss: 0.00263
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02791
Policy Update Magnitude: 0.98687
Value Function Update Magnitude: 0.79127
Collected Steps per Second: 13,133.11587
Overall Steps per Second: 7,328.80031
Timestep Collection Time: 3.80763
Timestep Consumption Time: 3.01559
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.82322
Cumulative Model Updates: 166,463
Cumulative Timesteps: 1,291,111,474
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1291111474...
Checkpoint 1291111474 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.42782
Policy Entropy: 4.34433
Value Function Loss: 0.00272
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02896
Policy Update Magnitude: 0.99064
Value Function Update Magnitude: 0.74915
Collected Steps per Second: 13,291.31628
Overall Steps per Second: 7,265.63201
Timestep Collection Time: 3.76276
Timestep Consumption Time: 3.12061
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.88337
Cumulative Model Updates: 166,472
Cumulative Timesteps: 1,291,161,486
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41149
Policy Entropy: 4.34584
Value Function Loss: 0.00257
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.96387
Value Function Update Magnitude: 0.72454
Collected Steps per Second: 13,083.06393
Overall Steps per Second: 7,240.19514
Timestep Collection Time: 3.82296
Timestep Consumption Time: 3.08514
PPO Batch Consumption Time: 0.22785
Total Iteration Time: 6.90810
Cumulative Model Updates: 166,481
Cumulative Timesteps: 1,291,211,502
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1291211502...
Checkpoint 1291211502 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44561
Policy Entropy: 4.34367
Value Function Loss: 0.00280
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.97036
Value Function Update Magnitude: 0.73538
Collected Steps per Second: 13,475.70865
Overall Steps per Second: 7,329.27300
Timestep Collection Time: 3.71320
Timestep Consumption Time: 3.11394
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.82714
Cumulative Model Updates: 166,490
Cumulative Timesteps: 1,291,261,540
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.98127
Policy Entropy: 4.34095
Value Function Loss: 0.00262
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02877
Policy Update Magnitude: 0.95902
Value Function Update Magnitude: 0.73332
Collected Steps per Second: 13,286.13295
Overall Steps per Second: 7,242.06595
Timestep Collection Time: 3.76392
Timestep Consumption Time: 3.14129
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.90521
Cumulative Model Updates: 166,499
Cumulative Timesteps: 1,291,311,548
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1291311548...
Checkpoint 1291311548 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68038
Policy Entropy: 4.34211
Value Function Loss: 0.00277
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03141
Policy Update Magnitude: 0.96888
Value Function Update Magnitude: 0.72391
Collected Steps per Second: 13,326.87676
Overall Steps per Second: 7,112.73476
Timestep Collection Time: 3.75452
Timestep Consumption Time: 3.28019
PPO Batch Consumption Time: 0.24554
Total Iteration Time: 7.03471
Cumulative Model Updates: 166,508
Cumulative Timesteps: 1,291,361,584
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.69812
Policy Entropy: 4.34255
Value Function Loss: 0.00269
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02814
Policy Update Magnitude: 0.96741
Value Function Update Magnitude: 0.74035
Collected Steps per Second: 13,488.65022
Overall Steps per Second: 7,310.13599
Timestep Collection Time: 3.70964
Timestep Consumption Time: 3.13538
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.84502
Cumulative Model Updates: 166,517
Cumulative Timesteps: 1,291,411,622
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1291411622...
Checkpoint 1291411622 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76865
Policy Entropy: 4.34500
Value Function Loss: 0.00263
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02810
Policy Update Magnitude: 0.95500
Value Function Update Magnitude: 0.76051
Collected Steps per Second: 13,057.15039
Overall Steps per Second: 7,186.21748
Timestep Collection Time: 3.83131
Timestep Consumption Time: 3.13007
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.96138
Cumulative Model Updates: 166,526
Cumulative Timesteps: 1,291,461,648
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89006
Policy Entropy: 4.34937
Value Function Loss: 0.00240
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.93636
Value Function Update Magnitude: 0.77862
Collected Steps per Second: 13,346.29347
Overall Steps per Second: 7,406.50662
Timestep Collection Time: 3.74801
Timestep Consumption Time: 3.00578
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.75379
Cumulative Model Updates: 166,535
Cumulative Timesteps: 1,291,511,670
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1291511670...
Checkpoint 1291511670 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.34018
Policy Entropy: 4.35086
Value Function Loss: 0.00234
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.92717
Value Function Update Magnitude: 0.71543
Collected Steps per Second: 13,318.22656
Overall Steps per Second: 7,283.87515
Timestep Collection Time: 3.75425
Timestep Consumption Time: 3.11022
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.86448
Cumulative Model Updates: 166,544
Cumulative Timesteps: 1,291,561,670
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.37690
Policy Entropy: 4.35074
Value Function Loss: 0.00238
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.91693
Value Function Update Magnitude: 0.67749
Collected Steps per Second: 13,318.38646
Overall Steps per Second: 7,311.92002
Timestep Collection Time: 3.75481
Timestep Consumption Time: 3.08443
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.83924
Cumulative Model Updates: 166,553
Cumulative Timesteps: 1,291,611,678
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1291611678...
Checkpoint 1291611678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.80810
Policy Entropy: 4.34780
Value Function Loss: 0.00253
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.94308
Value Function Update Magnitude: 0.70142
Collected Steps per Second: 13,188.76147
Overall Steps per Second: 7,348.46176
Timestep Collection Time: 3.79505
Timestep Consumption Time: 3.01617
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.81122
Cumulative Model Updates: 166,562
Cumulative Timesteps: 1,291,661,730
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.37379
Policy Entropy: 4.34574
Value Function Loss: 0.00264
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02892
Policy Update Magnitude: 0.95818
Value Function Update Magnitude: 0.69144
Collected Steps per Second: 13,313.16194
Overall Steps per Second: 7,165.58724
Timestep Collection Time: 3.75733
Timestep Consumption Time: 3.22353
PPO Batch Consumption Time: 0.23846
Total Iteration Time: 6.98087
Cumulative Model Updates: 166,571
Cumulative Timesteps: 1,291,711,752
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1291711752...
Checkpoint 1291711752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.22667
Policy Entropy: 4.34275
Value Function Loss: 0.00266
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02986
Policy Update Magnitude: 0.97669
Value Function Update Magnitude: 0.69808
Collected Steps per Second: 13,020.56008
Overall Steps per Second: 7,220.82525
Timestep Collection Time: 3.84069
Timestep Consumption Time: 3.08483
PPO Batch Consumption Time: 0.22765
Total Iteration Time: 6.92552
Cumulative Model Updates: 166,580
Cumulative Timesteps: 1,291,761,760
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.49106
Policy Entropy: 4.34155
Value Function Loss: 0.00261
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02880
Policy Update Magnitude: 0.96931
Value Function Update Magnitude: 0.68627
Collected Steps per Second: 13,598.28799
Overall Steps per Second: 7,364.97122
Timestep Collection Time: 3.67987
Timestep Consumption Time: 3.11445
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.79432
Cumulative Model Updates: 166,589
Cumulative Timesteps: 1,291,811,800
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1291811800...
Checkpoint 1291811800 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.29136
Policy Entropy: 4.34273
Value Function Loss: 0.00246
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02841
Policy Update Magnitude: 0.96629
Value Function Update Magnitude: 0.70981
Collected Steps per Second: 12,965.31915
Overall Steps per Second: 7,165.70869
Timestep Collection Time: 3.85644
Timestep Consumption Time: 3.12124
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.97768
Cumulative Model Updates: 166,598
Cumulative Timesteps: 1,291,861,800
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.77874
Policy Entropy: 4.34298
Value Function Loss: 0.00242
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.94744
Value Function Update Magnitude: 0.71747
Collected Steps per Second: 13,291.24528
Overall Steps per Second: 7,279.31964
Timestep Collection Time: 3.76278
Timestep Consumption Time: 3.10764
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.87042
Cumulative Model Updates: 166,607
Cumulative Timesteps: 1,291,911,812
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1291911812...
Checkpoint 1291911812 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09851
Policy Entropy: 4.34682
Value Function Loss: 0.00250
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.96178
Value Function Update Magnitude: 0.71091
Collected Steps per Second: 13,260.02880
Overall Steps per Second: 7,263.59092
Timestep Collection Time: 3.77345
Timestep Consumption Time: 3.11516
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.88860
Cumulative Model Updates: 166,616
Cumulative Timesteps: 1,291,961,848
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.26051
Policy Entropy: 4.34641
Value Function Loss: 0.00230
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.93713
Value Function Update Magnitude: 0.70117
Collected Steps per Second: 13,462.85724
Overall Steps per Second: 7,318.16399
Timestep Collection Time: 3.71556
Timestep Consumption Time: 3.11976
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.83532
Cumulative Model Updates: 166,625
Cumulative Timesteps: 1,292,011,870
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1292011870...
Checkpoint 1292011870 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.46483
Policy Entropy: 4.34968
Value Function Loss: 0.00227
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.89924
Value Function Update Magnitude: 0.68459
Collected Steps per Second: 13,181.10266
Overall Steps per Second: 7,229.36286
Timestep Collection Time: 3.79634
Timestep Consumption Time: 3.12543
PPO Batch Consumption Time: 0.23864
Total Iteration Time: 6.92177
Cumulative Model Updates: 166,634
Cumulative Timesteps: 1,292,061,910
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09246
Policy Entropy: 4.35155
Value Function Loss: 0.00205
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02333
Policy Update Magnitude: 0.87190
Value Function Update Magnitude: 0.65720
Collected Steps per Second: 13,427.64396
Overall Steps per Second: 7,319.63980
Timestep Collection Time: 3.72515
Timestep Consumption Time: 3.10852
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.83367
Cumulative Model Updates: 166,643
Cumulative Timesteps: 1,292,111,930
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1292111930...
Checkpoint 1292111930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87693
Policy Entropy: 4.35534
Value Function Loss: 0.00205
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.89236
Value Function Update Magnitude: 0.73636
Collected Steps per Second: 13,242.95935
Overall Steps per Second: 7,288.70748
Timestep Collection Time: 3.77725
Timestep Consumption Time: 3.08569
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.86295
Cumulative Model Updates: 166,652
Cumulative Timesteps: 1,292,161,952
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64884
Policy Entropy: 4.35340
Value Function Loss: 0.00217
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.92961
Value Function Update Magnitude: 0.75138
Collected Steps per Second: 13,312.21299
Overall Steps per Second: 7,369.92021
Timestep Collection Time: 3.75745
Timestep Consumption Time: 3.02960
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.78705
Cumulative Model Updates: 166,661
Cumulative Timesteps: 1,292,211,972
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1292211972...
Checkpoint 1292211972 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.64042
Policy Entropy: 4.35384
Value Function Loss: 0.00239
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.93850
Value Function Update Magnitude: 0.72768
Collected Steps per Second: 13,253.63554
Overall Steps per Second: 7,257.43706
Timestep Collection Time: 3.77315
Timestep Consumption Time: 3.11743
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.89059
Cumulative Model Updates: 166,670
Cumulative Timesteps: 1,292,261,980
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.59758
Policy Entropy: 4.35463
Value Function Loss: 0.00258
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.95447
Value Function Update Magnitude: 0.72092
Collected Steps per Second: 13,380.75226
Overall Steps per Second: 7,316.71096
Timestep Collection Time: 3.73761
Timestep Consumption Time: 3.09770
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.83531
Cumulative Model Updates: 166,679
Cumulative Timesteps: 1,292,311,992
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1292311992...
Checkpoint 1292311992 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18895
Policy Entropy: 4.35058
Value Function Loss: 0.00272
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.98649
Value Function Update Magnitude: 0.75291
Collected Steps per Second: 13,403.36116
Overall Steps per Second: 7,287.12975
Timestep Collection Time: 3.73339
Timestep Consumption Time: 3.13351
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.86690
Cumulative Model Updates: 166,688
Cumulative Timesteps: 1,292,362,032
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75159
Policy Entropy: 4.34813
Value Function Loss: 0.00281
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02651
Policy Update Magnitude: 1.00399
Value Function Update Magnitude: 0.71524
Collected Steps per Second: 13,256.44363
Overall Steps per Second: 7,049.10290
Timestep Collection Time: 3.77507
Timestep Consumption Time: 3.32427
PPO Batch Consumption Time: 0.24582
Total Iteration Time: 7.09934
Cumulative Model Updates: 166,697
Cumulative Timesteps: 1,292,412,076
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1292412076...
Checkpoint 1292412076 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.64557
Policy Entropy: 4.34281
Value Function Loss: 0.00284
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.98655
Value Function Update Magnitude: 0.69006
Collected Steps per Second: 13,098.99946
Overall Steps per Second: 7,327.67788
Timestep Collection Time: 3.82014
Timestep Consumption Time: 3.00876
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.82890
Cumulative Model Updates: 166,706
Cumulative Timesteps: 1,292,462,116
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61419
Policy Entropy: 4.34672
Value Function Loss: 0.00269
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.98967
Value Function Update Magnitude: 0.68840
Collected Steps per Second: 13,348.45162
Overall Steps per Second: 7,294.48159
Timestep Collection Time: 3.74875
Timestep Consumption Time: 3.11123
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.85998
Cumulative Model Updates: 166,715
Cumulative Timesteps: 1,292,512,156
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1292512156...
Checkpoint 1292512156 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.08936
Policy Entropy: 4.34445
Value Function Loss: 0.00266
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02894
Policy Update Magnitude: 0.99043
Value Function Update Magnitude: 0.67560
Collected Steps per Second: 13,186.78886
Overall Steps per Second: 7,269.72273
Timestep Collection Time: 3.79380
Timestep Consumption Time: 3.08790
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.88169
Cumulative Model Updates: 166,724
Cumulative Timesteps: 1,292,562,184
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.91434
Policy Entropy: 4.34887
Value Function Loss: 0.00246
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.94124
Value Function Update Magnitude: 0.66646
Collected Steps per Second: 13,538.31288
Overall Steps per Second: 7,338.97189
Timestep Collection Time: 3.69337
Timestep Consumption Time: 3.11985
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.81322
Cumulative Model Updates: 166,733
Cumulative Timesteps: 1,292,612,186
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1292612186...
Checkpoint 1292612186 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26277
Policy Entropy: 4.34976
Value Function Loss: 0.00247
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02506
Policy Update Magnitude: 0.90729
Value Function Update Magnitude: 0.69208
Collected Steps per Second: 13,390.64483
Overall Steps per Second: 7,282.08669
Timestep Collection Time: 3.73619
Timestep Consumption Time: 3.13409
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.87028
Cumulative Model Updates: 166,742
Cumulative Timesteps: 1,292,662,216
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.12252
Policy Entropy: 4.35296
Value Function Loss: 0.00236
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02409
Policy Update Magnitude: 0.89272
Value Function Update Magnitude: 0.76953
Collected Steps per Second: 13,167.89149
Overall Steps per Second: 7,241.36650
Timestep Collection Time: 3.79742
Timestep Consumption Time: 3.10791
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.90533
Cumulative Model Updates: 166,751
Cumulative Timesteps: 1,292,712,220
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1292712220...
Checkpoint 1292712220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44827
Policy Entropy: 4.35443
Value Function Loss: 0.00228
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.89010
Value Function Update Magnitude: 0.72674
Collected Steps per Second: 13,607.73940
Overall Steps per Second: 7,195.04815
Timestep Collection Time: 3.67732
Timestep Consumption Time: 3.27746
PPO Batch Consumption Time: 0.23940
Total Iteration Time: 6.95478
Cumulative Model Updates: 166,760
Cumulative Timesteps: 1,292,762,260
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12614
Policy Entropy: 4.35341
Value Function Loss: 0.00225
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02390
Policy Update Magnitude: 0.92184
Value Function Update Magnitude: 0.70492
Collected Steps per Second: 13,258.19912
Overall Steps per Second: 7,246.31414
Timestep Collection Time: 3.77291
Timestep Consumption Time: 3.13019
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.90310
Cumulative Model Updates: 166,769
Cumulative Timesteps: 1,292,812,282
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1292812282...
Checkpoint 1292812282 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.78936
Policy Entropy: 4.35212
Value Function Loss: 0.00223
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.93071
Value Function Update Magnitude: 0.65210
Collected Steps per Second: 13,218.92437
Overall Steps per Second: 7,344.11573
Timestep Collection Time: 3.78367
Timestep Consumption Time: 3.02668
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.81035
Cumulative Model Updates: 166,778
Cumulative Timesteps: 1,292,862,298
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95377
Policy Entropy: 4.34831
Value Function Loss: 0.00254
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.92366
Value Function Update Magnitude: 0.66010
Collected Steps per Second: 13,397.96919
Overall Steps per Second: 7,290.08023
Timestep Collection Time: 3.73295
Timestep Consumption Time: 3.12760
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.86056
Cumulative Model Updates: 166,787
Cumulative Timesteps: 1,292,912,312
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1292912312...
Checkpoint 1292912312 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64883
Policy Entropy: 4.34744
Value Function Loss: 0.00263
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.94574
Value Function Update Magnitude: 0.68851
Collected Steps per Second: 13,032.91887
Overall Steps per Second: 7,228.34986
Timestep Collection Time: 3.83874
Timestep Consumption Time: 3.08262
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.92136
Cumulative Model Updates: 166,796
Cumulative Timesteps: 1,292,962,342
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.01575
Policy Entropy: 4.34619
Value Function Loss: 0.00260
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.95307
Value Function Update Magnitude: 0.71355
Collected Steps per Second: 13,237.41497
Overall Steps per Second: 7,385.63816
Timestep Collection Time: 3.78080
Timestep Consumption Time: 2.99560
PPO Batch Consumption Time: 0.22789
Total Iteration Time: 6.77639
Cumulative Model Updates: 166,805
Cumulative Timesteps: 1,293,012,390
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1293012390...
Checkpoint 1293012390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64040
Policy Entropy: 4.34784
Value Function Loss: 0.00252
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.96226
Value Function Update Magnitude: 0.70270
Collected Steps per Second: 13,203.04178
Overall Steps per Second: 7,219.00358
Timestep Collection Time: 3.78791
Timestep Consumption Time: 3.13991
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.92783
Cumulative Model Updates: 166,814
Cumulative Timesteps: 1,293,062,402
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49974
Policy Entropy: 4.35028
Value Function Loss: 0.00250
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.98000
Value Function Update Magnitude: 0.70278
Collected Steps per Second: 13,089.03091
Overall Steps per Second: 7,172.75670
Timestep Collection Time: 3.82290
Timestep Consumption Time: 3.15322
PPO Batch Consumption Time: 0.23537
Total Iteration Time: 6.97612
Cumulative Model Updates: 166,823
Cumulative Timesteps: 1,293,112,440
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1293112440...
Checkpoint 1293112440 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48553
Policy Entropy: 4.35140
Value Function Loss: 0.00242
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.95178
Value Function Update Magnitude: 0.69782
Collected Steps per Second: 13,467.23138
Overall Steps per Second: 7,339.65964
Timestep Collection Time: 3.71450
Timestep Consumption Time: 3.10108
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.81557
Cumulative Model Updates: 166,832
Cumulative Timesteps: 1,293,162,464
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.98057
Policy Entropy: 4.35236
Value Function Loss: 0.00245
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.95453
Value Function Update Magnitude: 0.67516
Collected Steps per Second: 13,279.19960
Overall Steps per Second: 7,281.08348
Timestep Collection Time: 3.76950
Timestep Consumption Time: 3.10530
PPO Batch Consumption Time: 0.22767
Total Iteration Time: 6.87480
Cumulative Model Updates: 166,841
Cumulative Timesteps: 1,293,212,520
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1293212520...
Checkpoint 1293212520 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31620
Policy Entropy: 4.35060
Value Function Loss: 0.00251
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.96876
Value Function Update Magnitude: 0.66777
Collected Steps per Second: 13,013.69523
Overall Steps per Second: 7,315.05088
Timestep Collection Time: 3.84472
Timestep Consumption Time: 2.99515
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.83987
Cumulative Model Updates: 166,850
Cumulative Timesteps: 1,293,262,554
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76971
Policy Entropy: 4.34778
Value Function Loss: 0.00279
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02626
Policy Update Magnitude: 0.97059
Value Function Update Magnitude: 0.72202
Collected Steps per Second: 13,241.68111
Overall Steps per Second: 7,254.95012
Timestep Collection Time: 3.77792
Timestep Consumption Time: 3.11751
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.89543
Cumulative Model Updates: 166,859
Cumulative Timesteps: 1,293,312,580
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1293312580...
Checkpoint 1293312580 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49290
Policy Entropy: 4.34918
Value Function Loss: 0.00265
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.98004
Value Function Update Magnitude: 0.76383
Collected Steps per Second: 13,041.11672
Overall Steps per Second: 7,235.14471
Timestep Collection Time: 3.83556
Timestep Consumption Time: 3.07792
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.91348
Cumulative Model Updates: 166,868
Cumulative Timesteps: 1,293,362,600
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.49022
Policy Entropy: 4.34823
Value Function Loss: 0.00261
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02814
Policy Update Magnitude: 0.98457
Value Function Update Magnitude: 0.76241
Collected Steps per Second: 13,473.21735
Overall Steps per Second: 7,349.48264
Timestep Collection Time: 3.71285
Timestep Consumption Time: 3.09362
PPO Batch Consumption Time: 0.22791
Total Iteration Time: 6.80647
Cumulative Model Updates: 166,877
Cumulative Timesteps: 1,293,412,624
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1293412624...
Checkpoint 1293412624 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64410
Policy Entropy: 4.34826
Value Function Loss: 0.00246
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.97570
Value Function Update Magnitude: 0.68521
Collected Steps per Second: 13,258.24163
Overall Steps per Second: 7,182.23924
Timestep Collection Time: 3.77411
Timestep Consumption Time: 3.19280
PPO Batch Consumption Time: 0.23464
Total Iteration Time: 6.96691
Cumulative Model Updates: 166,886
Cumulative Timesteps: 1,293,462,662
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.45791
Policy Entropy: 4.34713
Value Function Loss: 0.00232
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.93897
Value Function Update Magnitude: 0.66445
Collected Steps per Second: 13,333.03294
Overall Steps per Second: 7,328.72051
Timestep Collection Time: 3.75068
Timestep Consumption Time: 3.07288
PPO Batch Consumption Time: 0.22785
Total Iteration Time: 6.82356
Cumulative Model Updates: 166,895
Cumulative Timesteps: 1,293,512,670
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1293512670...
Checkpoint 1293512670 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88458
Policy Entropy: 4.35129
Value Function Loss: 0.00226
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02512
Policy Update Magnitude: 0.90702
Value Function Update Magnitude: 0.69358
Collected Steps per Second: 13,496.35863
Overall Steps per Second: 7,336.56543
Timestep Collection Time: 3.70693
Timestep Consumption Time: 3.11234
PPO Batch Consumption Time: 0.22785
Total Iteration Time: 6.81927
Cumulative Model Updates: 166,904
Cumulative Timesteps: 1,293,562,700
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.63483
Policy Entropy: 4.34966
Value Function Loss: 0.00249
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.94059
Value Function Update Magnitude: 0.73090
Collected Steps per Second: 13,389.22614
Overall Steps per Second: 7,272.81596
Timestep Collection Time: 3.73703
Timestep Consumption Time: 3.14283
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.87987
Cumulative Model Updates: 166,913
Cumulative Timesteps: 1,293,612,736
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1293612736...
Checkpoint 1293612736 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.58418
Policy Entropy: 4.35030
Value Function Loss: 0.00248
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.95081
Value Function Update Magnitude: 0.71118
Collected Steps per Second: 13,255.27707
Overall Steps per Second: 7,270.51989
Timestep Collection Time: 3.77480
Timestep Consumption Time: 3.10724
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.88204
Cumulative Model Updates: 166,922
Cumulative Timesteps: 1,293,662,772
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06159
Policy Entropy: 4.35069
Value Function Loss: 0.00256
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.93115
Value Function Update Magnitude: 0.71531
Collected Steps per Second: 13,501.70710
Overall Steps per Second: 7,346.87951
Timestep Collection Time: 3.70412
Timestep Consumption Time: 3.10312
PPO Batch Consumption Time: 0.22777
Total Iteration Time: 6.80724
Cumulative Model Updates: 166,931
Cumulative Timesteps: 1,293,712,784
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1293712784...
Checkpoint 1293712784 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.17237
Policy Entropy: 4.35145
Value Function Loss: 0.00241
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.96904
Value Function Update Magnitude: 0.69495
Collected Steps per Second: 13,107.54144
Overall Steps per Second: 7,206.68897
Timestep Collection Time: 3.81551
Timestep Consumption Time: 3.12415
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.93966
Cumulative Model Updates: 166,940
Cumulative Timesteps: 1,293,762,796
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33660
Policy Entropy: 4.35128
Value Function Loss: 0.00261
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.97975
Value Function Update Magnitude: 0.68180
Collected Steps per Second: 13,228.72966
Overall Steps per Second: 7,162.66090
Timestep Collection Time: 3.77980
Timestep Consumption Time: 3.20112
PPO Batch Consumption Time: 0.24352
Total Iteration Time: 6.98093
Cumulative Model Updates: 166,949
Cumulative Timesteps: 1,293,812,798
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1293812798...
Checkpoint 1293812798 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31673
Policy Entropy: 4.34418
Value Function Loss: 0.00268
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.98689
Value Function Update Magnitude: 0.70562
Collected Steps per Second: 13,340.26623
Overall Steps per Second: 7,290.78161
Timestep Collection Time: 3.74985
Timestep Consumption Time: 3.11142
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.86127
Cumulative Model Updates: 166,958
Cumulative Timesteps: 1,293,862,822
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.94798
Policy Entropy: 4.34267
Value Function Loss: 0.00265
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02980
Policy Update Magnitude: 0.97615
Value Function Update Magnitude: 0.67308
Collected Steps per Second: 13,228.91814
Overall Steps per Second: 7,293.79613
Timestep Collection Time: 3.78020
Timestep Consumption Time: 3.07603
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.85624
Cumulative Model Updates: 166,967
Cumulative Timesteps: 1,293,912,830
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1293912830...
Checkpoint 1293912830 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68971
Policy Entropy: 4.34550
Value Function Loss: 0.00248
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.96644
Value Function Update Magnitude: 0.65246
Collected Steps per Second: 13,190.94953
Overall Steps per Second: 7,361.14413
Timestep Collection Time: 3.79366
Timestep Consumption Time: 3.00447
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.79813
Cumulative Model Updates: 166,976
Cumulative Timesteps: 1,293,962,872
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.23403
Policy Entropy: 4.34635
Value Function Loss: 0.00248
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.97034
Value Function Update Magnitude: 0.65942
Collected Steps per Second: 13,006.45676
Overall Steps per Second: 7,163.24509
Timestep Collection Time: 3.84532
Timestep Consumption Time: 3.13671
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.98203
Cumulative Model Updates: 166,985
Cumulative Timesteps: 1,294,012,886
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1294012886...
Checkpoint 1294012886 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.77762
Policy Entropy: 4.34815
Value Function Loss: 0.00247
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.94837
Value Function Update Magnitude: 0.70134
Collected Steps per Second: 13,061.25272
Overall Steps per Second: 7,225.14852
Timestep Collection Time: 3.82858
Timestep Consumption Time: 3.09253
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.92110
Cumulative Model Updates: 166,994
Cumulative Timesteps: 1,294,062,892
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72738
Policy Entropy: 4.34550
Value Function Loss: 0.00258
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.94014
Value Function Update Magnitude: 0.71792
Collected Steps per Second: 13,513.82419
Overall Steps per Second: 7,336.36139
Timestep Collection Time: 3.70154
Timestep Consumption Time: 3.11682
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.81837
Cumulative Model Updates: 167,003
Cumulative Timesteps: 1,294,112,914
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1294112914...
Checkpoint 1294112914 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16678
Policy Entropy: 4.34643
Value Function Loss: 0.00266
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.95193
Value Function Update Magnitude: 0.72793
Collected Steps per Second: 13,241.61036
Overall Steps per Second: 7,191.33296
Timestep Collection Time: 3.77915
Timestep Consumption Time: 3.17951
PPO Batch Consumption Time: 0.23431
Total Iteration Time: 6.95865
Cumulative Model Updates: 167,012
Cumulative Timesteps: 1,294,162,956
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.73649
Policy Entropy: 4.34719
Value Function Loss: 0.00271
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02827
Policy Update Magnitude: 0.96841
Value Function Update Magnitude: 0.72237
Collected Steps per Second: 13,176.24114
Overall Steps per Second: 7,264.13697
Timestep Collection Time: 3.79516
Timestep Consumption Time: 3.08879
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.88396
Cumulative Model Updates: 167,021
Cumulative Timesteps: 1,294,212,962
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1294212962...
Checkpoint 1294212962 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.78003
Policy Entropy: 4.34488
Value Function Loss: 0.00253
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.95582
Value Function Update Magnitude: 0.70989
Collected Steps per Second: 13,470.44710
Overall Steps per Second: 7,315.79262
Timestep Collection Time: 3.71450
Timestep Consumption Time: 3.12495
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.83945
Cumulative Model Updates: 167,030
Cumulative Timesteps: 1,294,262,998
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.61288
Policy Entropy: 4.34845
Value Function Loss: 0.00250
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.95286
Value Function Update Magnitude: 0.70291
Collected Steps per Second: 13,348.51362
Overall Steps per Second: 7,294.24919
Timestep Collection Time: 3.74828
Timestep Consumption Time: 3.11109
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.85938
Cumulative Model Updates: 167,039
Cumulative Timesteps: 1,294,313,032
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1294313032...
Checkpoint 1294313032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.36295
Policy Entropy: 4.34669
Value Function Loss: 0.00242
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.94390
Value Function Update Magnitude: 0.69783
Collected Steps per Second: 13,062.38510
Overall Steps per Second: 7,289.84953
Timestep Collection Time: 3.82824
Timestep Consumption Time: 3.03143
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.85968
Cumulative Model Updates: 167,048
Cumulative Timesteps: 1,294,363,038
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.30692
Policy Entropy: 4.34821
Value Function Loss: 0.00250
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.94569
Value Function Update Magnitude: 0.73181
Collected Steps per Second: 13,166.72022
Overall Steps per Second: 7,247.77152
Timestep Collection Time: 3.79806
Timestep Consumption Time: 3.10172
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.89978
Cumulative Model Updates: 167,057
Cumulative Timesteps: 1,294,413,046
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1294413046...
Checkpoint 1294413046 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.60825
Policy Entropy: 4.34764
Value Function Loss: 0.00239
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.95211
Value Function Update Magnitude: 0.74013
Collected Steps per Second: 13,197.21675
Overall Steps per Second: 7,274.64205
Timestep Collection Time: 3.79080
Timestep Consumption Time: 3.08624
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.87704
Cumulative Model Updates: 167,066
Cumulative Timesteps: 1,294,463,074
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03011
Policy Entropy: 4.34651
Value Function Loss: 0.00233
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.96036
Value Function Update Magnitude: 0.71864
Collected Steps per Second: 13,065.42416
Overall Steps per Second: 7,193.83758
Timestep Collection Time: 3.82950
Timestep Consumption Time: 3.12562
PPO Batch Consumption Time: 0.23789
Total Iteration Time: 6.95512
Cumulative Model Updates: 167,075
Cumulative Timesteps: 1,294,513,108
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1294513108...
Checkpoint 1294513108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.76045
Policy Entropy: 4.34648
Value Function Loss: 0.00239
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.95223
Value Function Update Magnitude: 0.69704
Collected Steps per Second: 13,186.28740
Overall Steps per Second: 7,223.68645
Timestep Collection Time: 3.79379
Timestep Consumption Time: 3.13148
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.92527
Cumulative Model Updates: 167,084
Cumulative Timesteps: 1,294,563,134
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84117
Policy Entropy: 4.34679
Value Function Loss: 0.00247
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.95589
Value Function Update Magnitude: 0.71741
Collected Steps per Second: 13,065.62782
Overall Steps per Second: 7,251.43596
Timestep Collection Time: 3.83005
Timestep Consumption Time: 3.07093
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.90098
Cumulative Model Updates: 167,093
Cumulative Timesteps: 1,294,613,176
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1294613176...
Checkpoint 1294613176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84732
Policy Entropy: 4.34593
Value Function Loss: 0.00246
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02722
Policy Update Magnitude: 0.93869
Value Function Update Magnitude: 0.68200
Collected Steps per Second: 13,467.39655
Overall Steps per Second: 7,305.52425
Timestep Collection Time: 3.71564
Timestep Consumption Time: 3.13397
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.84961
Cumulative Model Updates: 167,102
Cumulative Timesteps: 1,294,663,216
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.05461
Policy Entropy: 4.34545
Value Function Loss: 0.00259
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.94344
Value Function Update Magnitude: 0.71344
Collected Steps per Second: 13,348.57929
Overall Steps per Second: 7,282.13086
Timestep Collection Time: 3.74587
Timestep Consumption Time: 3.12053
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.86640
Cumulative Model Updates: 167,111
Cumulative Timesteps: 1,294,713,218
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1294713218...
Checkpoint 1294713218 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22229
Policy Entropy: 4.34582
Value Function Loss: 0.00253
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.96183
Value Function Update Magnitude: 0.72976
Collected Steps per Second: 13,014.60259
Overall Steps per Second: 7,316.44899
Timestep Collection Time: 3.84184
Timestep Consumption Time: 2.99208
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.83392
Cumulative Model Updates: 167,120
Cumulative Timesteps: 1,294,763,218
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35071
Policy Entropy: 4.34912
Value Function Loss: 0.00245
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.96625
Value Function Update Magnitude: 0.75370
Collected Steps per Second: 13,182.52527
Overall Steps per Second: 7,228.85250
Timestep Collection Time: 3.79487
Timestep Consumption Time: 3.12545
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.92032
Cumulative Model Updates: 167,129
Cumulative Timesteps: 1,294,813,244
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1294813244...
Checkpoint 1294813244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41858
Policy Entropy: 4.34959
Value Function Loss: 0.00233
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.96137
Value Function Update Magnitude: 0.75606
Collected Steps per Second: 13,032.79220
Overall Steps per Second: 7,059.69036
Timestep Collection Time: 3.83694
Timestep Consumption Time: 3.24638
PPO Batch Consumption Time: 0.24009
Total Iteration Time: 7.08331
Cumulative Model Updates: 167,138
Cumulative Timesteps: 1,294,863,250
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68301
Policy Entropy: 4.34881
Value Function Loss: 0.00231
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02812
Policy Update Magnitude: 0.95745
Value Function Update Magnitude: 0.72144
Collected Steps per Second: 13,419.93468
Overall Steps per Second: 7,320.32475
Timestep Collection Time: 3.72744
Timestep Consumption Time: 3.10586
PPO Batch Consumption Time: 0.22784
Total Iteration Time: 6.83330
Cumulative Model Updates: 167,147
Cumulative Timesteps: 1,294,913,272
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1294913272...
Checkpoint 1294913272 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93447
Policy Entropy: 4.34974
Value Function Loss: 0.00240
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02925
Policy Update Magnitude: 0.95047
Value Function Update Magnitude: 0.71444
Collected Steps per Second: 13,084.55875
Overall Steps per Second: 7,187.14151
Timestep Collection Time: 3.82206
Timestep Consumption Time: 3.13620
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.95826
Cumulative Model Updates: 167,156
Cumulative Timesteps: 1,294,963,282
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.68518
Policy Entropy: 4.34675
Value Function Loss: 0.00241
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.95826
Value Function Update Magnitude: 0.67581
Collected Steps per Second: 13,201.95996
Overall Steps per Second: 7,283.20108
Timestep Collection Time: 3.79019
Timestep Consumption Time: 3.08014
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.87033
Cumulative Model Updates: 167,165
Cumulative Timesteps: 1,295,013,320
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1295013320...
Checkpoint 1295013320 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80977
Policy Entropy: 4.35162
Value Function Loss: 0.00230
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02682
Policy Update Magnitude: 0.92658
Value Function Update Magnitude: 0.65362
Collected Steps per Second: 13,429.04050
Overall Steps per Second: 7,314.42548
Timestep Collection Time: 3.72521
Timestep Consumption Time: 3.11415
PPO Batch Consumption Time: 0.22757
Total Iteration Time: 6.83936
Cumulative Model Updates: 167,174
Cumulative Timesteps: 1,295,063,346
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24061
Policy Entropy: 4.35098
Value Function Loss: 0.00232
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.92364
Value Function Update Magnitude: 0.65256
Collected Steps per Second: 13,285.82525
Overall Steps per Second: 7,263.16093
Timestep Collection Time: 3.76537
Timestep Consumption Time: 3.12227
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.88763
Cumulative Model Updates: 167,183
Cumulative Timesteps: 1,295,113,372
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1295113372...
Checkpoint 1295113372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30767
Policy Entropy: 4.35431
Value Function Loss: 0.00228
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.93053
Value Function Update Magnitude: 0.71227
Collected Steps per Second: 12,980.64930
Overall Steps per Second: 7,291.59128
Timestep Collection Time: 3.85528
Timestep Consumption Time: 3.00797
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.86325
Cumulative Model Updates: 167,192
Cumulative Timesteps: 1,295,163,416
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22725
Policy Entropy: 4.35573
Value Function Loss: 0.00219
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.92468
Value Function Update Magnitude: 0.69469
Collected Steps per Second: 13,238.05534
Overall Steps per Second: 7,113.94272
Timestep Collection Time: 3.77775
Timestep Consumption Time: 3.25211
PPO Batch Consumption Time: 0.23816
Total Iteration Time: 7.02986
Cumulative Model Updates: 167,201
Cumulative Timesteps: 1,295,213,426
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1295213426...
Checkpoint 1295213426 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53525
Policy Entropy: 4.35480
Value Function Loss: 0.00227
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.92380
Value Function Update Magnitude: 0.69969
Collected Steps per Second: 12,956.54189
Overall Steps per Second: 7,200.78499
Timestep Collection Time: 3.85905
Timestep Consumption Time: 3.08463
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.94369
Cumulative Model Updates: 167,210
Cumulative Timesteps: 1,295,263,426
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81208
Policy Entropy: 4.35475
Value Function Loss: 0.00229
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02426
Policy Update Magnitude: 0.93237
Value Function Update Magnitude: 0.73325
Collected Steps per Second: 13,370.92789
Overall Steps per Second: 7,400.40516
Timestep Collection Time: 3.74125
Timestep Consumption Time: 3.01838
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.75963
Cumulative Model Updates: 167,219
Cumulative Timesteps: 1,295,313,450
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1295313450...
Checkpoint 1295313450 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05170
Policy Entropy: 4.35344
Value Function Loss: 0.00241
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.93661
Value Function Update Magnitude: 0.72251
Collected Steps per Second: 13,260.21023
Overall Steps per Second: 7,256.48677
Timestep Collection Time: 3.77355
Timestep Consumption Time: 3.12208
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.89562
Cumulative Model Updates: 167,228
Cumulative Timesteps: 1,295,363,488
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.12481
Policy Entropy: 4.35326
Value Function Loss: 0.00239
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02332
Policy Update Magnitude: 0.94557
Value Function Update Magnitude: 0.72872
Collected Steps per Second: 13,250.68733
Overall Steps per Second: 7,311.54262
Timestep Collection Time: 3.77354
Timestep Consumption Time: 3.06524
PPO Batch Consumption Time: 0.22784
Total Iteration Time: 6.83878
Cumulative Model Updates: 167,237
Cumulative Timesteps: 1,295,413,490
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1295413490...
Checkpoint 1295413490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14993
Policy Entropy: 4.34956
Value Function Loss: 0.00257
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.97662
Value Function Update Magnitude: 0.72589
Collected Steps per Second: 13,671.39580
Overall Steps per Second: 7,373.51611
Timestep Collection Time: 3.65800
Timestep Consumption Time: 3.12438
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.78238
Cumulative Model Updates: 167,246
Cumulative Timesteps: 1,295,463,500
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.06369
Policy Entropy: 4.34738
Value Function Loss: 0.00283
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.99653
Value Function Update Magnitude: 0.72723
Collected Steps per Second: 13,296.53585
Overall Steps per Second: 7,259.23399
Timestep Collection Time: 3.76203
Timestep Consumption Time: 3.12878
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.89081
Cumulative Model Updates: 167,255
Cumulative Timesteps: 1,295,513,522
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1295513522...
Checkpoint 1295513522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.23910
Policy Entropy: 4.34475
Value Function Loss: 0.00289
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 1.01330
Value Function Update Magnitude: 0.72055
Collected Steps per Second: 13,249.68721
Overall Steps per Second: 7,083.06638
Timestep Collection Time: 3.77564
Timestep Consumption Time: 3.28712
PPO Batch Consumption Time: 0.24298
Total Iteration Time: 7.06276
Cumulative Model Updates: 167,264
Cumulative Timesteps: 1,295,563,548
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95601
Policy Entropy: 4.34567
Value Function Loss: 0.00275
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02534
Policy Update Magnitude: 0.98964
Value Function Update Magnitude: 0.72907
Collected Steps per Second: 13,386.73576
Overall Steps per Second: 7,300.93363
Timestep Collection Time: 3.73668
Timestep Consumption Time: 3.11477
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.85145
Cumulative Model Updates: 167,273
Cumulative Timesteps: 1,295,613,570
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1295613570...
Checkpoint 1295613570 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11678
Policy Entropy: 4.35002
Value Function Loss: 0.00247
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02541
Policy Update Magnitude: 0.95264
Value Function Update Magnitude: 0.74826
Collected Steps per Second: 13,128.27380
Overall Steps per Second: 7,213.77694
Timestep Collection Time: 3.81025
Timestep Consumption Time: 3.12398
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.93423
Cumulative Model Updates: 167,282
Cumulative Timesteps: 1,295,663,592
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.58710
Policy Entropy: 4.34864
Value Function Loss: 0.00247
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.92514
Value Function Update Magnitude: 0.74814
Collected Steps per Second: 13,258.63289
Overall Steps per Second: 7,372.66589
Timestep Collection Time: 3.77324
Timestep Consumption Time: 3.01237
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.78561
Cumulative Model Updates: 167,291
Cumulative Timesteps: 1,295,713,620
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1295713620...
Checkpoint 1295713620 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.96309
Policy Entropy: 4.34678
Value Function Loss: 0.00252
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.93812
Value Function Update Magnitude: 0.73319
Collected Steps per Second: 13,200.32905
Overall Steps per Second: 7,246.82690
Timestep Collection Time: 3.78824
Timestep Consumption Time: 3.11216
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.90040
Cumulative Model Updates: 167,300
Cumulative Timesteps: 1,295,763,626
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61608
Policy Entropy: 4.34548
Value Function Loss: 0.00263
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.96826
Value Function Update Magnitude: 0.74350
Collected Steps per Second: 13,169.20792
Overall Steps per Second: 7,278.67380
Timestep Collection Time: 3.79901
Timestep Consumption Time: 3.07449
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.87350
Cumulative Model Updates: 167,309
Cumulative Timesteps: 1,295,813,656
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1295813656...
Checkpoint 1295813656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.27241
Policy Entropy: 4.34517
Value Function Loss: 0.00257
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.95136
Value Function Update Magnitude: 0.78833
Collected Steps per Second: 13,001.95014
Overall Steps per Second: 7,240.93789
Timestep Collection Time: 3.84911
Timestep Consumption Time: 3.06242
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.91154
Cumulative Model Updates: 167,318
Cumulative Timesteps: 1,295,863,702
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.54993
Policy Entropy: 4.34740
Value Function Loss: 0.00238
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.94461
Value Function Update Magnitude: 0.74354
Collected Steps per Second: 13,272.86312
Overall Steps per Second: 7,113.82911
Timestep Collection Time: 3.77010
Timestep Consumption Time: 3.26409
PPO Batch Consumption Time: 0.24009
Total Iteration Time: 7.03419
Cumulative Model Updates: 167,327
Cumulative Timesteps: 1,295,913,742
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1295913742...
Checkpoint 1295913742 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.78088
Policy Entropy: 4.34844
Value Function Loss: 0.00236
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.92217
Value Function Update Magnitude: 0.70170
Collected Steps per Second: 13,271.22020
Overall Steps per Second: 7,301.77086
Timestep Collection Time: 3.76906
Timestep Consumption Time: 3.08133
PPO Batch Consumption Time: 0.22773
Total Iteration Time: 6.85039
Cumulative Model Updates: 167,336
Cumulative Timesteps: 1,295,963,762
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03714
Policy Entropy: 4.34469
Value Function Loss: 0.00239
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.90655
Value Function Update Magnitude: 0.69117
Collected Steps per Second: 13,637.84868
Overall Steps per Second: 7,356.39488
Timestep Collection Time: 3.66685
Timestep Consumption Time: 3.13104
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.79789
Cumulative Model Updates: 167,345
Cumulative Timesteps: 1,296,013,770
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1296013770...
Checkpoint 1296013770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.07661
Policy Entropy: 4.34621
Value Function Loss: 0.00246
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.92654
Value Function Update Magnitude: 0.72200
Collected Steps per Second: 13,142.82353
Overall Steps per Second: 7,215.29540
Timestep Collection Time: 3.80588
Timestep Consumption Time: 3.12662
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.93250
Cumulative Model Updates: 167,354
Cumulative Timesteps: 1,296,063,790
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62826
Policy Entropy: 4.34890
Value Function Loss: 0.00235
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.91825
Value Function Update Magnitude: 0.72727
Collected Steps per Second: 13,288.99241
Overall Steps per Second: 7,303.85483
Timestep Collection Time: 3.76342
Timestep Consumption Time: 3.08393
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.84734
Cumulative Model Updates: 167,363
Cumulative Timesteps: 1,296,113,802
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1296113802...
Checkpoint 1296113802 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.21116
Policy Entropy: 4.35528
Value Function Loss: 0.00226
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.90702
Value Function Update Magnitude: 0.71320
Collected Steps per Second: 13,498.09011
Overall Steps per Second: 7,340.25630
Timestep Collection Time: 3.70497
Timestep Consumption Time: 3.10814
PPO Batch Consumption Time: 0.22786
Total Iteration Time: 6.81311
Cumulative Model Updates: 167,372
Cumulative Timesteps: 1,296,163,812
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51637
Policy Entropy: 4.35412
Value Function Loss: 0.00221
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.89120
Value Function Update Magnitude: 0.64675
Collected Steps per Second: 13,103.84419
Overall Steps per Second: 7,213.48839
Timestep Collection Time: 3.81690
Timestep Consumption Time: 3.11678
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.93368
Cumulative Model Updates: 167,381
Cumulative Timesteps: 1,296,213,828
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1296213828...
Checkpoint 1296213828 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.36581
Policy Entropy: 4.35306
Value Function Loss: 0.00234
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.90102
Value Function Update Magnitude: 0.64418
Collected Steps per Second: 13,278.35635
Overall Steps per Second: 7,219.57193
Timestep Collection Time: 3.76628
Timestep Consumption Time: 3.16072
PPO Batch Consumption Time: 0.23856
Total Iteration Time: 6.92700
Cumulative Model Updates: 167,390
Cumulative Timesteps: 1,296,263,838
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.07872
Policy Entropy: 4.35259
Value Function Loss: 0.00238
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.92315
Value Function Update Magnitude: 0.71126
Collected Steps per Second: 13,236.51431
Overall Steps per Second: 7,270.37399
Timestep Collection Time: 3.77894
Timestep Consumption Time: 3.10104
PPO Batch Consumption Time: 0.22757
Total Iteration Time: 6.87998
Cumulative Model Updates: 167,399
Cumulative Timesteps: 1,296,313,858
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1296313858...
Checkpoint 1296313858 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.60755
Policy Entropy: 4.35561
Value Function Loss: 0.00230
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02425
Policy Update Magnitude: 0.91545
Value Function Update Magnitude: 0.72272
Collected Steps per Second: 13,307.52944
Overall Steps per Second: 7,279.04752
Timestep Collection Time: 3.75757
Timestep Consumption Time: 3.11201
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.86958
Cumulative Model Updates: 167,408
Cumulative Timesteps: 1,296,363,862
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62839
Policy Entropy: 4.35401
Value Function Loss: 0.00250
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.93002
Value Function Update Magnitude: 0.71022
Collected Steps per Second: 13,361.42873
Overall Steps per Second: 7,386.17016
Timestep Collection Time: 3.74391
Timestep Consumption Time: 3.02875
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.77266
Cumulative Model Updates: 167,417
Cumulative Timesteps: 1,296,413,886
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1296413886...
Checkpoint 1296413886 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.23126
Policy Entropy: 4.35071
Value Function Loss: 0.00254
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.96011
Value Function Update Magnitude: 0.76264
Collected Steps per Second: 13,216.06354
Overall Steps per Second: 7,263.29985
Timestep Collection Time: 3.78479
Timestep Consumption Time: 3.10189
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.88668
Cumulative Model Updates: 167,426
Cumulative Timesteps: 1,296,463,906
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.08606
Policy Entropy: 4.34710
Value Function Loss: 0.00267
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.96840
Value Function Update Magnitude: 0.76468
Collected Steps per Second: 13,275.23037
Overall Steps per Second: 7,292.26199
Timestep Collection Time: 3.76912
Timestep Consumption Time: 3.09239
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.86152
Cumulative Model Updates: 167,435
Cumulative Timesteps: 1,296,513,942
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1296513942...
Checkpoint 1296513942 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73492
Policy Entropy: 4.34837
Value Function Loss: 0.00246
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02723
Policy Update Magnitude: 0.95877
Value Function Update Magnitude: 0.78866
Collected Steps per Second: 13,621.43845
Overall Steps per Second: 7,401.69830
Timestep Collection Time: 3.67186
Timestep Consumption Time: 3.08551
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.75737
Cumulative Model Updates: 167,444
Cumulative Timesteps: 1,296,563,958
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.40936
Policy Entropy: 4.35005
Value Function Loss: 0.00242
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02824
Policy Update Magnitude: 0.93624
Value Function Update Magnitude: 0.78145
Collected Steps per Second: 13,306.12275
Overall Steps per Second: 7,262.91213
Timestep Collection Time: 3.75932
Timestep Consumption Time: 3.12800
PPO Batch Consumption Time: 0.22948
Total Iteration Time: 6.88732
Cumulative Model Updates: 167,453
Cumulative Timesteps: 1,296,613,980
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1296613980...
Checkpoint 1296613980 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.00520
Policy Entropy: 4.35089
Value Function Loss: 0.00242
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02626
Policy Update Magnitude: 0.94901
Value Function Update Magnitude: 0.74775
Collected Steps per Second: 13,254.13051
Overall Steps per Second: 7,373.03021
Timestep Collection Time: 3.77271
Timestep Consumption Time: 3.00930
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.78201
Cumulative Model Updates: 167,462
Cumulative Timesteps: 1,296,663,984
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.36279
Policy Entropy: 4.35029
Value Function Loss: 0.00243
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.94015
Value Function Update Magnitude: 0.74140
Collected Steps per Second: 13,054.12600
Overall Steps per Second: 7,197.08525
Timestep Collection Time: 3.83143
Timestep Consumption Time: 3.11805
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.94948
Cumulative Model Updates: 167,471
Cumulative Timesteps: 1,296,714,000
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1296714000...
Checkpoint 1296714000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93909
Policy Entropy: 4.35151
Value Function Loss: 0.00229
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02451
Policy Update Magnitude: 0.92091
Value Function Update Magnitude: 0.72113
Collected Steps per Second: 13,123.12277
Overall Steps per Second: 7,253.43759
Timestep Collection Time: 3.81266
Timestep Consumption Time: 3.08531
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.89797
Cumulative Model Updates: 167,480
Cumulative Timesteps: 1,296,764,034
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.01625
Policy Entropy: 4.35251
Value Function Loss: 0.00225
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.90793
Value Function Update Magnitude: 0.68431
Collected Steps per Second: 13,710.89059
Overall Steps per Second: 7,403.02628
Timestep Collection Time: 3.64732
Timestep Consumption Time: 3.10776
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.75508
Cumulative Model Updates: 167,489
Cumulative Timesteps: 1,296,814,042
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1296814042...
Checkpoint 1296814042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57805
Policy Entropy: 4.35685
Value Function Loss: 0.00226
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02265
Policy Update Magnitude: 0.91154
Value Function Update Magnitude: 0.68723
Collected Steps per Second: 13,252.24335
Overall Steps per Second: 7,248.60442
Timestep Collection Time: 3.77370
Timestep Consumption Time: 3.12556
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.89926
Cumulative Model Updates: 167,498
Cumulative Timesteps: 1,296,864,052
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74733
Policy Entropy: 4.35739
Value Function Loss: 0.00233
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.92824
Value Function Update Magnitude: 0.72877
Collected Steps per Second: 13,281.06570
Overall Steps per Second: 7,288.97754
Timestep Collection Time: 3.76672
Timestep Consumption Time: 3.09652
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.86324
Cumulative Model Updates: 167,507
Cumulative Timesteps: 1,296,914,078
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1296914078...
Checkpoint 1296914078 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.18141
Policy Entropy: 4.35768
Value Function Loss: 0.00239
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02289
Policy Update Magnitude: 0.93864
Value Function Update Magnitude: 0.79010
Collected Steps per Second: 13,218.57220
Overall Steps per Second: 7,087.06355
Timestep Collection Time: 3.78346
Timestep Consumption Time: 3.27334
PPO Batch Consumption Time: 0.23977
Total Iteration Time: 7.05680
Cumulative Model Updates: 167,516
Cumulative Timesteps: 1,296,964,090
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14562
Policy Entropy: 4.35563
Value Function Loss: 0.00227
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02309
Policy Update Magnitude: 0.92925
Value Function Update Magnitude: 0.75423
Collected Steps per Second: 13,223.75500
Overall Steps per Second: 7,263.06716
Timestep Collection Time: 3.78183
Timestep Consumption Time: 3.10369
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.88552
Cumulative Model Updates: 167,525
Cumulative Timesteps: 1,297,014,100
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1297014100...
Checkpoint 1297014100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72120
Policy Entropy: 4.35565
Value Function Loss: 0.00218
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.90577
Value Function Update Magnitude: 0.68362
Collected Steps per Second: 13,302.14467
Overall Steps per Second: 7,406.56303
Timestep Collection Time: 3.76060
Timestep Consumption Time: 2.99341
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.75401
Cumulative Model Updates: 167,534
Cumulative Timesteps: 1,297,064,124
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68743
Policy Entropy: 4.36009
Value Function Loss: 0.00208
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02352
Policy Update Magnitude: 0.90170
Value Function Update Magnitude: 0.63959
Collected Steps per Second: 13,176.36415
Overall Steps per Second: 7,253.10623
Timestep Collection Time: 3.79710
Timestep Consumption Time: 3.10091
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.89801
Cumulative Model Updates: 167,543
Cumulative Timesteps: 1,297,114,156
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1297114156...
Checkpoint 1297114156 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56681
Policy Entropy: 4.35925
Value Function Loss: 0.00224
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.91371
Value Function Update Magnitude: 0.66342
Collected Steps per Second: 13,185.46795
Overall Steps per Second: 7,265.02903
Timestep Collection Time: 3.79296
Timestep Consumption Time: 3.09097
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.88394
Cumulative Model Updates: 167,552
Cumulative Timesteps: 1,297,164,168
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75994
Policy Entropy: 4.35741
Value Function Loss: 0.00239
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.92512
Value Function Update Magnitude: 0.69371
Collected Steps per Second: 13,561.34896
Overall Steps per Second: 7,356.63155
Timestep Collection Time: 3.68798
Timestep Consumption Time: 3.11051
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.79849
Cumulative Model Updates: 167,561
Cumulative Timesteps: 1,297,214,182
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1297214182...
Checkpoint 1297214182 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.10185
Policy Entropy: 4.35603
Value Function Loss: 0.00236
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02780
Policy Update Magnitude: 0.92699
Value Function Update Magnitude: 0.70461
Collected Steps per Second: 13,221.48024
Overall Steps per Second: 7,269.52363
Timestep Collection Time: 3.78475
Timestep Consumption Time: 3.09878
PPO Batch Consumption Time: 0.22782
Total Iteration Time: 6.88353
Cumulative Model Updates: 167,570
Cumulative Timesteps: 1,297,264,222
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35358
Policy Entropy: 4.35862
Value Function Loss: 0.00237
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.91895
Value Function Update Magnitude: 0.70813
Collected Steps per Second: 12,799.37269
Overall Steps per Second: 6,974.35537
Timestep Collection Time: 3.90847
Timestep Consumption Time: 3.26438
PPO Batch Consumption Time: 0.24245
Total Iteration Time: 7.17285
Cumulative Model Updates: 167,579
Cumulative Timesteps: 1,297,314,248
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1297314248...
Checkpoint 1297314248 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.07587
Policy Entropy: 4.36370
Value Function Loss: 0.00217
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.91521
Value Function Update Magnitude: 0.67994
Collected Steps per Second: 13,476.28258
Overall Steps per Second: 7,281.92944
Timestep Collection Time: 3.71200
Timestep Consumption Time: 3.15761
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.86961
Cumulative Model Updates: 167,588
Cumulative Timesteps: 1,297,364,272
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27018
Policy Entropy: 4.36214
Value Function Loss: 0.00240
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.91980
Value Function Update Magnitude: 0.74975
Collected Steps per Second: 13,261.60550
Overall Steps per Second: 7,254.73762
Timestep Collection Time: 3.77209
Timestep Consumption Time: 3.12326
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.89536
Cumulative Model Updates: 167,597
Cumulative Timesteps: 1,297,414,296
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1297414296...
Checkpoint 1297414296 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69869
Policy Entropy: 4.36112
Value Function Loss: 0.00239
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.95169
Value Function Update Magnitude: 0.79332
Collected Steps per Second: 13,310.60622
Overall Steps per Second: 7,383.50763
Timestep Collection Time: 3.75851
Timestep Consumption Time: 3.01713
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.77564
Cumulative Model Updates: 167,606
Cumulative Timesteps: 1,297,464,324
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09183
Policy Entropy: 4.36330
Value Function Loss: 0.00232
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.95140
Value Function Update Magnitude: 0.75051
Collected Steps per Second: 13,374.60212
Overall Steps per Second: 7,292.13385
Timestep Collection Time: 3.74097
Timestep Consumption Time: 3.12039
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.86137
Cumulative Model Updates: 167,615
Cumulative Timesteps: 1,297,514,358
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1297514358...
Checkpoint 1297514358 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.31869
Policy Entropy: 4.36017
Value Function Loss: 0.00237
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.95885
Value Function Update Magnitude: 0.72323
Collected Steps per Second: 13,295.98107
Overall Steps per Second: 7,275.61270
Timestep Collection Time: 3.76309
Timestep Consumption Time: 3.11385
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.87695
Cumulative Model Updates: 167,624
Cumulative Timesteps: 1,297,564,392
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.40220
Policy Entropy: 4.35915
Value Function Loss: 0.00253
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.99640
Value Function Update Magnitude: 0.69233
Collected Steps per Second: 13,473.75399
Overall Steps per Second: 7,316.18623
Timestep Collection Time: 3.71463
Timestep Consumption Time: 3.12637
PPO Batch Consumption Time: 0.22781
Total Iteration Time: 6.84100
Cumulative Model Updates: 167,633
Cumulative Timesteps: 1,297,614,442
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1297614442...
Checkpoint 1297614442 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54166
Policy Entropy: 4.35698
Value Function Loss: 0.00273
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 1.00802
Value Function Update Magnitude: 0.70299
Collected Steps per Second: 13,042.19192
Overall Steps per Second: 7,028.21100
Timestep Collection Time: 3.83494
Timestep Consumption Time: 3.28152
PPO Batch Consumption Time: 0.24185
Total Iteration Time: 7.11646
Cumulative Model Updates: 167,642
Cumulative Timesteps: 1,297,664,458
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.73731
Policy Entropy: 4.35747
Value Function Loss: 0.00266
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 1.00940
Value Function Update Magnitude: 0.70312
Collected Steps per Second: 13,327.34056
Overall Steps per Second: 7,302.03052
Timestep Collection Time: 3.75319
Timestep Consumption Time: 3.09696
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.85015
Cumulative Model Updates: 167,651
Cumulative Timesteps: 1,297,714,478
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1297714478...
Checkpoint 1297714478 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.70693
Policy Entropy: 4.35739
Value Function Loss: 0.00262
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.99988
Value Function Update Magnitude: 0.66315
Collected Steps per Second: 13,534.74307
Overall Steps per Second: 7,351.35817
Timestep Collection Time: 3.69449
Timestep Consumption Time: 3.10752
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.80201
Cumulative Model Updates: 167,660
Cumulative Timesteps: 1,297,764,482
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83548
Policy Entropy: 4.35525
Value Function Loss: 0.00246
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.99111
Value Function Update Magnitude: 0.66224
Collected Steps per Second: 13,372.37769
Overall Steps per Second: 7,269.03391
Timestep Collection Time: 3.73920
Timestep Consumption Time: 3.13957
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.87877
Cumulative Model Updates: 167,669
Cumulative Timesteps: 1,297,814,484
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1297814484...
Checkpoint 1297814484 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.38698
Policy Entropy: 4.35398
Value Function Loss: 0.00243
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.97334
Value Function Update Magnitude: 0.65101
Collected Steps per Second: 13,149.15612
Overall Steps per Second: 7,340.67362
Timestep Collection Time: 3.80420
Timestep Consumption Time: 3.01016
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.81436
Cumulative Model Updates: 167,678
Cumulative Timesteps: 1,297,864,506
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.72688
Policy Entropy: 4.35919
Value Function Loss: 0.00235
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.95474
Value Function Update Magnitude: 0.63915
Collected Steps per Second: 13,254.44868
Overall Steps per Second: 7,268.62574
Timestep Collection Time: 3.77337
Timestep Consumption Time: 3.10743
PPO Batch Consumption Time: 0.22784
Total Iteration Time: 6.88081
Cumulative Model Updates: 167,687
Cumulative Timesteps: 1,297,914,520
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1297914520...
Checkpoint 1297914520 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64998
Policy Entropy: 4.36424
Value Function Loss: 0.00223
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.94208
Value Function Update Magnitude: 0.66473
Collected Steps per Second: 13,126.72641
Overall Steps per Second: 7,286.82101
Timestep Collection Time: 3.81131
Timestep Consumption Time: 3.05451
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.86582
Cumulative Model Updates: 167,696
Cumulative Timesteps: 1,297,964,550
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56315
Policy Entropy: 4.36449
Value Function Loss: 0.00219
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02308
Policy Update Magnitude: 0.92615
Value Function Update Magnitude: 0.62845
Collected Steps per Second: 12,970.15347
Overall Steps per Second: 7,129.52106
Timestep Collection Time: 3.85562
Timestep Consumption Time: 3.15859
PPO Batch Consumption Time: 0.24281
Total Iteration Time: 7.01422
Cumulative Model Updates: 167,705
Cumulative Timesteps: 1,298,014,558
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1298014558...
Checkpoint 1298014558 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.80123
Policy Entropy: 4.35925
Value Function Loss: 0.00235
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02246
Policy Update Magnitude: 0.93835
Value Function Update Magnitude: 0.63355
Collected Steps per Second: 13,159.39652
Overall Steps per Second: 7,245.11941
Timestep Collection Time: 3.79987
Timestep Consumption Time: 3.10188
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.90175
Cumulative Model Updates: 167,714
Cumulative Timesteps: 1,298,064,562
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.08646
Policy Entropy: 4.35440
Value Function Loss: 0.00255
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.96032
Value Function Update Magnitude: 0.63671
Collected Steps per Second: 13,304.40019
Overall Steps per Second: 7,312.43004
Timestep Collection Time: 3.75906
Timestep Consumption Time: 3.08026
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.83931
Cumulative Model Updates: 167,723
Cumulative Timesteps: 1,298,114,574
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1298114574...
Checkpoint 1298114574 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22699
Policy Entropy: 4.34854
Value Function Loss: 0.00275
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02707
Policy Update Magnitude: 0.98231
Value Function Update Magnitude: 0.69506
Collected Steps per Second: 13,505.58158
Overall Steps per Second: 7,354.97577
Timestep Collection Time: 3.70262
Timestep Consumption Time: 3.09632
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.79893
Cumulative Model Updates: 167,732
Cumulative Timesteps: 1,298,164,580
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96380
Policy Entropy: 4.35168
Value Function Loss: 0.00250
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.96688
Value Function Update Magnitude: 0.72369
Collected Steps per Second: 13,315.35844
Overall Steps per Second: 7,271.07945
Timestep Collection Time: 3.75732
Timestep Consumption Time: 3.12337
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.88068
Cumulative Model Updates: 167,741
Cumulative Timesteps: 1,298,214,610
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1298214610...
Checkpoint 1298214610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75794
Policy Entropy: 4.35098
Value Function Loss: 0.00253
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.95589
Value Function Update Magnitude: 0.72890
Collected Steps per Second: 13,032.93448
Overall Steps per Second: 7,294.41121
Timestep Collection Time: 3.83766
Timestep Consumption Time: 3.01909
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.85676
Cumulative Model Updates: 167,750
Cumulative Timesteps: 1,298,264,626
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.57748
Policy Entropy: 4.34917
Value Function Loss: 0.00248
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.95955
Value Function Update Magnitude: 0.70988
Collected Steps per Second: 13,436.20397
Overall Steps per Second: 7,330.55817
Timestep Collection Time: 3.72174
Timestep Consumption Time: 3.09985
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.82158
Cumulative Model Updates: 167,759
Cumulative Timesteps: 1,298,314,632
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1298314632...
Checkpoint 1298314632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.45681
Policy Entropy: 4.35016
Value Function Loss: 0.00256
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.95483
Value Function Update Magnitude: 0.67511
Collected Steps per Second: 13,132.18453
Overall Steps per Second: 7,069.66878
Timestep Collection Time: 3.81018
Timestep Consumption Time: 3.26738
PPO Batch Consumption Time: 0.24568
Total Iteration Time: 7.07756
Cumulative Model Updates: 167,768
Cumulative Timesteps: 1,298,364,668
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35518
Policy Entropy: 4.35128
Value Function Loss: 0.00244
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.92884
Value Function Update Magnitude: 0.65212
Collected Steps per Second: 13,068.45779
Overall Steps per Second: 7,325.95784
Timestep Collection Time: 3.82616
Timestep Consumption Time: 2.99916
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.82532
Cumulative Model Updates: 167,777
Cumulative Timesteps: 1,298,414,670
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1298414670...
Checkpoint 1298414670 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20756
Policy Entropy: 4.35553
Value Function Loss: 0.00223
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.88091
Value Function Update Magnitude: 0.63306
Collected Steps per Second: 13,226.17491
Overall Steps per Second: 7,229.74739
Timestep Collection Time: 3.78447
Timestep Consumption Time: 3.13887
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.92334
Cumulative Model Updates: 167,786
Cumulative Timesteps: 1,298,464,724
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73988
Policy Entropy: 4.35279
Value Function Loss: 0.00219
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02208
Policy Update Magnitude: 0.89727
Value Function Update Magnitude: 0.61583
Collected Steps per Second: 13,285.91379
Overall Steps per Second: 7,302.25054
Timestep Collection Time: 3.76489
Timestep Consumption Time: 3.08505
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.84994
Cumulative Model Updates: 167,795
Cumulative Timesteps: 1,298,514,744
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1298514744...
Checkpoint 1298514744 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83543
Policy Entropy: 4.35263
Value Function Loss: 0.00223
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02390
Policy Update Magnitude: 0.93033
Value Function Update Magnitude: 0.62333
Collected Steps per Second: 13,310.96562
Overall Steps per Second: 7,299.77522
Timestep Collection Time: 3.75690
Timestep Consumption Time: 3.09372
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.85062
Cumulative Model Updates: 167,804
Cumulative Timesteps: 1,298,564,752
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.60572
Policy Entropy: 4.35385
Value Function Loss: 0.00234
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.93192
Value Function Update Magnitude: 0.61891
Collected Steps per Second: 13,236.38122
Overall Steps per Second: 7,294.39568
Timestep Collection Time: 3.77868
Timestep Consumption Time: 3.07809
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.85677
Cumulative Model Updates: 167,813
Cumulative Timesteps: 1,298,614,768
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1298614768...
Checkpoint 1298614768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86408
Policy Entropy: 4.35262
Value Function Loss: 0.00237
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.93057
Value Function Update Magnitude: 0.62329
Collected Steps per Second: 13,317.55611
Overall Steps per Second: 7,342.88973
Timestep Collection Time: 3.75715
Timestep Consumption Time: 3.05707
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.81421
Cumulative Model Updates: 167,822
Cumulative Timesteps: 1,298,664,804
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11660
Policy Entropy: 4.35243
Value Function Loss: 0.00234
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02446
Policy Update Magnitude: 0.90896
Value Function Update Magnitude: 0.67012
Collected Steps per Second: 13,491.61794
Overall Steps per Second: 7,293.68863
Timestep Collection Time: 3.70734
Timestep Consumption Time: 3.15037
PPO Batch Consumption Time: 0.23254
Total Iteration Time: 6.85771
Cumulative Model Updates: 167,831
Cumulative Timesteps: 1,298,714,822
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1298714822...
Checkpoint 1298714822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.18868
Policy Entropy: 4.35233
Value Function Loss: 0.00218
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02260
Policy Update Magnitude: 0.89438
Value Function Update Magnitude: 0.70590
Collected Steps per Second: 13,285.76920
Overall Steps per Second: 7,252.78801
Timestep Collection Time: 3.76463
Timestep Consumption Time: 3.13148
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.89611
Cumulative Model Updates: 167,840
Cumulative Timesteps: 1,298,764,838
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00526
Policy Entropy: 4.35725
Value Function Loss: 0.00209
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.90464
Value Function Update Magnitude: 0.71313
Collected Steps per Second: 13,105.24402
Overall Steps per Second: 7,254.30323
Timestep Collection Time: 3.81649
Timestep Consumption Time: 3.07818
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.89467
Cumulative Model Updates: 167,849
Cumulative Timesteps: 1,298,814,854
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1298814854...
Checkpoint 1298814854 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51389
Policy Entropy: 4.35605
Value Function Loss: 0.00218
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.91412
Value Function Update Magnitude: 0.67453
Collected Steps per Second: 13,510.15729
Overall Steps per Second: 7,330.51716
Timestep Collection Time: 3.70107
Timestep Consumption Time: 3.12001
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.82107
Cumulative Model Updates: 167,858
Cumulative Timesteps: 1,298,864,856
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09870
Policy Entropy: 4.35411
Value Function Loss: 0.00228
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02386
Policy Update Magnitude: 0.91391
Value Function Update Magnitude: 0.68286
Collected Steps per Second: 13,285.57218
Overall Steps per Second: 7,251.41388
Timestep Collection Time: 3.76649
Timestep Consumption Time: 3.13423
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.90072
Cumulative Model Updates: 167,867
Cumulative Timesteps: 1,298,914,896
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1298914896...
Checkpoint 1298914896 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46580
Policy Entropy: 4.35426
Value Function Loss: 0.00239
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.91485
Value Function Update Magnitude: 0.69186
Collected Steps per Second: 13,107.61363
Overall Steps per Second: 7,343.58242
Timestep Collection Time: 3.81717
Timestep Consumption Time: 2.99613
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.81330
Cumulative Model Updates: 167,876
Cumulative Timesteps: 1,298,964,930
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20340
Policy Entropy: 4.35557
Value Function Loss: 0.00226
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02414
Policy Update Magnitude: 0.90335
Value Function Update Magnitude: 0.69439
Collected Steps per Second: 13,308.22267
Overall Steps per Second: 7,300.79237
Timestep Collection Time: 3.75708
Timestep Consumption Time: 3.09150
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.84857
Cumulative Model Updates: 167,885
Cumulative Timesteps: 1,299,014,930
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1299014930...
Checkpoint 1299014930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09718
Policy Entropy: 4.35633
Value Function Loss: 0.00228
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.93088
Value Function Update Magnitude: 0.67358
Collected Steps per Second: 13,228.87951
Overall Steps per Second: 7,090.88380
Timestep Collection Time: 3.77961
Timestep Consumption Time: 3.27170
PPO Batch Consumption Time: 0.24572
Total Iteration Time: 7.05131
Cumulative Model Updates: 167,894
Cumulative Timesteps: 1,299,064,930
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.29366
Policy Entropy: 4.35443
Value Function Loss: 0.00216
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.93988
Value Function Update Magnitude: 0.63169
Collected Steps per Second: 13,582.78896
Overall Steps per Second: 7,338.55146
Timestep Collection Time: 3.68334
Timestep Consumption Time: 3.13408
PPO Batch Consumption Time: 0.22769
Total Iteration Time: 6.81742
Cumulative Model Updates: 167,903
Cumulative Timesteps: 1,299,114,960
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1299114960...
Checkpoint 1299114960 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.71622
Policy Entropy: 4.35339
Value Function Loss: 0.00233
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.92380
Value Function Update Magnitude: 0.63340
Collected Steps per Second: 13,153.58105
Overall Steps per Second: 7,207.79017
Timestep Collection Time: 3.80125
Timestep Consumption Time: 3.13569
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.93694
Cumulative Model Updates: 167,912
Cumulative Timesteps: 1,299,164,960
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.40923
Policy Entropy: 4.34986
Value Function Loss: 0.00259
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.94872
Value Function Update Magnitude: 0.68107
Collected Steps per Second: 13,177.85793
Overall Steps per Second: 7,298.82288
Timestep Collection Time: 3.79606
Timestep Consumption Time: 3.05764
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.85371
Cumulative Model Updates: 167,921
Cumulative Timesteps: 1,299,214,984
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1299214984...
Checkpoint 1299214984 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49205
Policy Entropy: 4.35071
Value Function Loss: 0.00267
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02583
Policy Update Magnitude: 0.96098
Value Function Update Magnitude: 0.70264
Collected Steps per Second: 13,631.68165
Overall Steps per Second: 7,366.28534
Timestep Collection Time: 3.66851
Timestep Consumption Time: 3.12025
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.78877
Cumulative Model Updates: 167,930
Cumulative Timesteps: 1,299,264,992
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31336
Policy Entropy: 4.35033
Value Function Loss: 0.00282
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02780
Policy Update Magnitude: 0.96829
Value Function Update Magnitude: 0.70689
Collected Steps per Second: 13,138.73650
Overall Steps per Second: 7,241.99524
Timestep Collection Time: 3.80859
Timestep Consumption Time: 3.10111
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.90970
Cumulative Model Updates: 167,939
Cumulative Timesteps: 1,299,315,032
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1299315032...
Checkpoint 1299315032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02968
Policy Entropy: 4.35040
Value Function Loss: 0.00268
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.98968
Value Function Update Magnitude: 0.73389
Collected Steps per Second: 13,169.66506
Overall Steps per Second: 7,354.57915
Timestep Collection Time: 3.80070
Timestep Consumption Time: 3.00512
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.80583
Cumulative Model Updates: 167,948
Cumulative Timesteps: 1,299,365,086
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.52133
Policy Entropy: 4.34947
Value Function Loss: 0.00276
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02939
Policy Update Magnitude: 0.99608
Value Function Update Magnitude: 0.73738
Collected Steps per Second: 13,254.54203
Overall Steps per Second: 7,107.52939
Timestep Collection Time: 3.77380
Timestep Consumption Time: 3.26381
PPO Batch Consumption Time: 0.24045
Total Iteration Time: 7.03761
Cumulative Model Updates: 167,957
Cumulative Timesteps: 1,299,415,106
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1299415106...
Checkpoint 1299415106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.59290
Policy Entropy: 4.34974
Value Function Loss: 0.00253
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.96003
Value Function Update Magnitude: 0.75917
Collected Steps per Second: 13,298.70224
Overall Steps per Second: 7,328.82956
Timestep Collection Time: 3.76232
Timestep Consumption Time: 3.06469
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.82701
Cumulative Model Updates: 167,966
Cumulative Timesteps: 1,299,465,140
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.04005
Policy Entropy: 4.34970
Value Function Loss: 0.00250
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02631
Policy Update Magnitude: 0.93933
Value Function Update Magnitude: 0.72942
Collected Steps per Second: 13,243.21693
Overall Steps per Second: 7,382.22821
Timestep Collection Time: 3.77839
Timestep Consumption Time: 2.99978
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.77817
Cumulative Model Updates: 167,975
Cumulative Timesteps: 1,299,515,178
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1299515178...
Checkpoint 1299515178 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.07892
Policy Entropy: 4.35177
Value Function Loss: 0.00244
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.95031
Value Function Update Magnitude: 0.69904
Collected Steps per Second: 13,426.65098
Overall Steps per Second: 7,307.94356
Timestep Collection Time: 3.72647
Timestep Consumption Time: 3.12005
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.84652
Cumulative Model Updates: 167,984
Cumulative Timesteps: 1,299,565,212
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12977
Policy Entropy: 4.34801
Value Function Loss: 0.00259
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.95308
Value Function Update Magnitude: 0.69463
Collected Steps per Second: 13,084.21700
Overall Steps per Second: 7,347.60504
Timestep Collection Time: 3.82400
Timestep Consumption Time: 2.98557
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.80957
Cumulative Model Updates: 167,993
Cumulative Timesteps: 1,299,615,246
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1299615246...
Checkpoint 1299615246 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.90028
Policy Entropy: 4.34637
Value Function Loss: 0.00251
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.95856
Value Function Update Magnitude: 0.70576
Collected Steps per Second: 13,115.30356
Overall Steps per Second: 7,244.30782
Timestep Collection Time: 3.81417
Timestep Consumption Time: 3.09111
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.90528
Cumulative Model Updates: 168,002
Cumulative Timesteps: 1,299,665,270
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34006
Policy Entropy: 4.34400
Value Function Loss: 0.00255
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.96461
Value Function Update Magnitude: 0.71580
Collected Steps per Second: 13,176.42374
Overall Steps per Second: 7,283.49199
Timestep Collection Time: 3.79739
Timestep Consumption Time: 3.07239
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.86978
Cumulative Model Updates: 168,011
Cumulative Timesteps: 1,299,715,306
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1299715306...
Checkpoint 1299715306 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.57184
Policy Entropy: 4.34560
Value Function Loss: 0.00251
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.96732
Value Function Update Magnitude: 0.69848
Collected Steps per Second: 13,064.42731
Overall Steps per Second: 7,257.15127
Timestep Collection Time: 3.82856
Timestep Consumption Time: 3.06367
PPO Batch Consumption Time: 0.23381
Total Iteration Time: 6.89224
Cumulative Model Updates: 168,020
Cumulative Timesteps: 1,299,765,324
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.56662
Policy Entropy: 4.34681
Value Function Loss: 0.00249
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.93467
Value Function Update Magnitude: 0.71270
Collected Steps per Second: 13,346.89198
Overall Steps per Second: 7,286.37709
Timestep Collection Time: 3.74649
Timestep Consumption Time: 3.11618
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.86267
Cumulative Model Updates: 168,029
Cumulative Timesteps: 1,299,815,328
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1299815328...
Checkpoint 1299815328 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69427
Policy Entropy: 4.34674
Value Function Loss: 0.00229
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.93275
Value Function Update Magnitude: 0.73411
Collected Steps per Second: 13,143.96116
Overall Steps per Second: 7,275.75566
Timestep Collection Time: 3.80631
Timestep Consumption Time: 3.06995
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.87626
Cumulative Model Updates: 168,038
Cumulative Timesteps: 1,299,865,358
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.24261
Policy Entropy: 4.34876
Value Function Loss: 0.00229
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.92399
Value Function Update Magnitude: 0.69361
Collected Steps per Second: 13,565.45393
Overall Steps per Second: 7,370.49147
Timestep Collection Time: 3.68687
Timestep Consumption Time: 3.09884
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.78571
Cumulative Model Updates: 168,047
Cumulative Timesteps: 1,299,915,372
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1299915372...
Checkpoint 1299915372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.67535
Policy Entropy: 4.34607
Value Function Loss: 0.00249
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.95845
Value Function Update Magnitude: 0.70089
Collected Steps per Second: 13,149.69683
Overall Steps per Second: 7,245.64930
Timestep Collection Time: 3.80617
Timestep Consumption Time: 3.10142
PPO Batch Consumption Time: 0.22757
Total Iteration Time: 6.90759
Cumulative Model Updates: 168,056
Cumulative Timesteps: 1,299,965,422
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.82010
Policy Entropy: 4.35027
Value Function Loss: 0.00257
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03032
Policy Update Magnitude: 0.98181
Value Function Update Magnitude: 0.76668
Collected Steps per Second: 13,156.31006
Overall Steps per Second: 7,283.35843
Timestep Collection Time: 3.80122
Timestep Consumption Time: 3.06512
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.86634
Cumulative Model Updates: 168,065
Cumulative Timesteps: 1,300,015,432
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1300015432...
Checkpoint 1300015432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.29880
Policy Entropy: 4.34769
Value Function Loss: 0.00269
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 1.00179
Value Function Update Magnitude: 0.75843
Collected Steps per Second: 13,410.85991
Overall Steps per Second: 7,319.59654
Timestep Collection Time: 3.72832
Timestep Consumption Time: 3.10266
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.83098
Cumulative Model Updates: 168,074
Cumulative Timesteps: 1,300,065,432
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.29484
Policy Entropy: 4.35147
Value Function Loss: 0.00260
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.99375
Value Function Update Magnitude: 0.75996
Collected Steps per Second: 13,213.07223
Overall Steps per Second: 7,139.50926
Timestep Collection Time: 3.78625
Timestep Consumption Time: 3.22095
PPO Batch Consumption Time: 0.23900
Total Iteration Time: 7.00720
Cumulative Model Updates: 168,083
Cumulative Timesteps: 1,300,115,460
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1300115460...
Checkpoint 1300115460 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.43066
Policy Entropy: 4.34889
Value Function Loss: 0.00262
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02939
Policy Update Magnitude: 0.99761
Value Function Update Magnitude: 0.72306
Collected Steps per Second: 13,220.41530
Overall Steps per Second: 7,311.06775
Timestep Collection Time: 3.78324
Timestep Consumption Time: 3.05790
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.84113
Cumulative Model Updates: 168,092
Cumulative Timesteps: 1,300,165,476
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.68034
Policy Entropy: 4.35361
Value Function Loss: 0.00233
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.95733
Value Function Update Magnitude: 0.67540
Collected Steps per Second: 13,146.42432
Overall Steps per Second: 7,230.45363
Timestep Collection Time: 3.80636
Timestep Consumption Time: 3.11437
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.92073
Cumulative Model Updates: 168,101
Cumulative Timesteps: 1,300,215,516
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1300215516...
Checkpoint 1300215516 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.21747
Policy Entropy: 4.35760
Value Function Loss: 0.00214
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.91778
Value Function Update Magnitude: 0.65323
Collected Steps per Second: 13,033.68882
Overall Steps per Second: 7,218.57903
Timestep Collection Time: 3.83652
Timestep Consumption Time: 3.09061
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.92713
Cumulative Model Updates: 168,110
Cumulative Timesteps: 1,300,265,520
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.63858
Policy Entropy: 4.35834
Value Function Loss: 0.00211
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.90163
Value Function Update Magnitude: 0.63772
Collected Steps per Second: 13,295.85617
Overall Steps per Second: 7,395.11319
Timestep Collection Time: 3.76478
Timestep Consumption Time: 3.00401
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.76879
Cumulative Model Updates: 168,119
Cumulative Timesteps: 1,300,315,576
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1300315576...
Checkpoint 1300315576 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17106
Policy Entropy: 4.35868
Value Function Loss: 0.00229
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.90688
Value Function Update Magnitude: 0.69199
Collected Steps per Second: 13,359.73167
Overall Steps per Second: 7,299.41894
Timestep Collection Time: 3.74514
Timestep Consumption Time: 3.10938
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.85452
Cumulative Model Updates: 168,128
Cumulative Timesteps: 1,300,365,610
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.94808
Policy Entropy: 4.35496
Value Function Loss: 0.00240
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.93897
Value Function Update Magnitude: 0.72729
Collected Steps per Second: 13,323.37744
Overall Steps per Second: 7,307.88428
Timestep Collection Time: 3.75295
Timestep Consumption Time: 3.08925
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.84220
Cumulative Model Updates: 168,137
Cumulative Timesteps: 1,300,415,612
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1300415612...
Checkpoint 1300415612 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.67940
Policy Entropy: 4.35569
Value Function Loss: 0.00226
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.93347
Value Function Update Magnitude: 0.73441
Collected Steps per Second: 13,538.92514
Overall Steps per Second: 7,190.69627
Timestep Collection Time: 3.69601
Timestep Consumption Time: 3.26298
PPO Batch Consumption Time: 0.24294
Total Iteration Time: 6.95899
Cumulative Model Updates: 168,146
Cumulative Timesteps: 1,300,465,652
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95150
Policy Entropy: 4.35315
Value Function Loss: 0.00246
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.95177
Value Function Update Magnitude: 0.69972
Collected Steps per Second: 13,364.88214
Overall Steps per Second: 7,314.57335
Timestep Collection Time: 3.74459
Timestep Consumption Time: 3.09737
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.84196
Cumulative Model Updates: 168,155
Cumulative Timesteps: 1,300,515,698
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1300515698...
Checkpoint 1300515698 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14182
Policy Entropy: 4.35491
Value Function Loss: 0.00260
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.96701
Value Function Update Magnitude: 0.77797
Collected Steps per Second: 13,178.41548
Overall Steps per Second: 7,334.43928
Timestep Collection Time: 3.79423
Timestep Consumption Time: 3.02319
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.81743
Cumulative Model Updates: 168,164
Cumulative Timesteps: 1,300,565,700
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.24848
Policy Entropy: 4.35129
Value Function Loss: 0.00271
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02689
Policy Update Magnitude: 0.97406
Value Function Update Magnitude: 0.82487
Collected Steps per Second: 13,308.56400
Overall Steps per Second: 7,278.64744
Timestep Collection Time: 3.75728
Timestep Consumption Time: 3.11268
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.86996
Cumulative Model Updates: 168,173
Cumulative Timesteps: 1,300,615,704
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1300615704...
Checkpoint 1300615704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.62641
Policy Entropy: 4.34690
Value Function Loss: 0.00281
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02865
Policy Update Magnitude: 0.99941
Value Function Update Magnitude: 0.73802
Collected Steps per Second: 13,200.18373
Overall Steps per Second: 7,282.81786
Timestep Collection Time: 3.79055
Timestep Consumption Time: 3.07986
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.87042
Cumulative Model Updates: 168,182
Cumulative Timesteps: 1,300,665,740
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99996
Policy Entropy: 4.34404
Value Function Loss: 0.00260
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02864
Policy Update Magnitude: 0.98493
Value Function Update Magnitude: 0.74830
Collected Steps per Second: 13,276.21310
Overall Steps per Second: 7,374.22728
Timestep Collection Time: 3.76885
Timestep Consumption Time: 3.01641
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.78525
Cumulative Model Updates: 168,191
Cumulative Timesteps: 1,300,715,776
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1300715776...
Checkpoint 1300715776 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.60733
Policy Entropy: 4.34724
Value Function Loss: 0.00261
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.96995
Value Function Update Magnitude: 0.75159
Collected Steps per Second: 13,295.14088
Overall Steps per Second: 7,285.03888
Timestep Collection Time: 3.76183
Timestep Consumption Time: 3.10348
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.86530
Cumulative Model Updates: 168,200
Cumulative Timesteps: 1,300,765,790
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89492
Policy Entropy: 4.35132
Value Function Loss: 0.00241
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.95884
Value Function Update Magnitude: 0.74360
Collected Steps per Second: 13,154.15981
Overall Steps per Second: 7,203.64029
Timestep Collection Time: 3.80336
Timestep Consumption Time: 3.14174
PPO Batch Consumption Time: 0.23533
Total Iteration Time: 6.94510
Cumulative Model Updates: 168,209
Cumulative Timesteps: 1,300,815,820
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1300815820...
Checkpoint 1300815820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81950
Policy Entropy: 4.35257
Value Function Loss: 0.00242
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.93406
Value Function Update Magnitude: 0.69894
Collected Steps per Second: 13,347.30967
Overall Steps per Second: 7,319.45589
Timestep Collection Time: 3.74652
Timestep Consumption Time: 3.08541
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.83193
Cumulative Model Updates: 168,218
Cumulative Timesteps: 1,300,865,826
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.32131
Policy Entropy: 4.35234
Value Function Loss: 0.00242
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.91440
Value Function Update Magnitude: 0.68715
Collected Steps per Second: 13,051.44584
Overall Steps per Second: 7,206.17691
Timestep Collection Time: 3.83145
Timestep Consumption Time: 3.10787
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.93932
Cumulative Model Updates: 168,227
Cumulative Timesteps: 1,300,915,832
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1300915832...
Checkpoint 1300915832 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35157
Policy Entropy: 4.34909
Value Function Loss: 0.00246
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.92465
Value Function Update Magnitude: 0.67681
Collected Steps per Second: 13,431.12965
Overall Steps per Second: 7,423.24677
Timestep Collection Time: 3.72344
Timestep Consumption Time: 3.01350
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.73694
Cumulative Model Updates: 168,236
Cumulative Timesteps: 1,300,965,842
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05504
Policy Entropy: 4.34911
Value Function Loss: 0.00235
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.90361
Value Function Update Magnitude: 0.71081
Collected Steps per Second: 13,392.60869
Overall Steps per Second: 7,313.03219
Timestep Collection Time: 3.73385
Timestep Consumption Time: 3.10408
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.83793
Cumulative Model Updates: 168,245
Cumulative Timesteps: 1,301,015,848
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1301015848...
Checkpoint 1301015848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.42948
Policy Entropy: 4.35156
Value Function Loss: 0.00239
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.90592
Value Function Update Magnitude: 0.70119
Collected Steps per Second: 13,187.64140
Overall Steps per Second: 7,282.09588
Timestep Collection Time: 3.79264
Timestep Consumption Time: 3.07571
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.86835
Cumulative Model Updates: 168,254
Cumulative Timesteps: 1,301,065,864
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.39853
Policy Entropy: 4.35399
Value Function Loss: 0.00229
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02432
Policy Update Magnitude: 0.90203
Value Function Update Magnitude: 0.75789
Collected Steps per Second: 13,031.96551
Overall Steps per Second: 7,297.54958
Timestep Collection Time: 3.83964
Timestep Consumption Time: 3.01719
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.85682
Cumulative Model Updates: 168,263
Cumulative Timesteps: 1,301,115,902
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1301115902...
Checkpoint 1301115902 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11044
Policy Entropy: 4.35371
Value Function Loss: 0.00236
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.90393
Value Function Update Magnitude: 0.78130
Collected Steps per Second: 13,362.77673
Overall Steps per Second: 7,086.70067
Timestep Collection Time: 3.74219
Timestep Consumption Time: 3.31413
PPO Batch Consumption Time: 0.24558
Total Iteration Time: 7.05632
Cumulative Model Updates: 168,272
Cumulative Timesteps: 1,301,165,908
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.64541
Policy Entropy: 4.35299
Value Function Loss: 0.00227
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.88618
Value Function Update Magnitude: 0.73905
Collected Steps per Second: 13,309.50825
Overall Steps per Second: 7,314.66065
Timestep Collection Time: 3.75671
Timestep Consumption Time: 3.07887
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.83559
Cumulative Model Updates: 168,281
Cumulative Timesteps: 1,301,215,908
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1301215908...
Checkpoint 1301215908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.74628
Policy Entropy: 4.35260
Value Function Loss: 0.00231
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.87114
Value Function Update Magnitude: 0.76009
Collected Steps per Second: 13,074.94554
Overall Steps per Second: 7,285.81100
Timestep Collection Time: 3.82671
Timestep Consumption Time: 3.04061
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.86732
Cumulative Model Updates: 168,290
Cumulative Timesteps: 1,301,265,942
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62232
Policy Entropy: 4.35356
Value Function Loss: 0.00234
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.87592
Value Function Update Magnitude: 0.76954
Collected Steps per Second: 13,248.16743
Overall Steps per Second: 7,270.85058
Timestep Collection Time: 3.77577
Timestep Consumption Time: 3.10403
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.87980
Cumulative Model Updates: 168,299
Cumulative Timesteps: 1,301,315,964
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1301315964...
Checkpoint 1301315964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64716
Policy Entropy: 4.35614
Value Function Loss: 0.00229
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.87407
Value Function Update Magnitude: 0.74613
Collected Steps per Second: 13,040.53681
Overall Steps per Second: 7,269.36121
Timestep Collection Time: 3.83558
Timestep Consumption Time: 3.04508
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.88066
Cumulative Model Updates: 168,308
Cumulative Timesteps: 1,301,365,982
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32779
Policy Entropy: 4.35445
Value Function Loss: 0.00238
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02548
Policy Update Magnitude: 0.88605
Value Function Update Magnitude: 0.78939
Collected Steps per Second: 13,587.80548
Overall Steps per Second: 7,403.22289
Timestep Collection Time: 3.68257
Timestep Consumption Time: 3.07638
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 6.75895
Cumulative Model Updates: 168,317
Cumulative Timesteps: 1,301,416,020
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1301416020...
Checkpoint 1301416020 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.57119
Policy Entropy: 4.35622
Value Function Loss: 0.00238
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.91920
Value Function Update Magnitude: 0.74981
Collected Steps per Second: 13,143.31022
Overall Steps per Second: 7,250.80125
Timestep Collection Time: 3.80559
Timestep Consumption Time: 3.09269
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.89827
Cumulative Model Updates: 168,326
Cumulative Timesteps: 1,301,466,038
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.95937
Policy Entropy: 4.35654
Value Function Loss: 0.00235
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02732
Policy Update Magnitude: 0.89567
Value Function Update Magnitude: 0.70158
Collected Steps per Second: 13,220.39619
Overall Steps per Second: 7,335.64255
Timestep Collection Time: 3.78461
Timestep Consumption Time: 3.03606
PPO Batch Consumption Time: 0.23204
Total Iteration Time: 6.82067
Cumulative Model Updates: 168,335
Cumulative Timesteps: 1,301,516,072
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1301516072...
Checkpoint 1301516072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20556
Policy Entropy: 4.36032
Value Function Loss: 0.00219
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.88829
Value Function Update Magnitude: 0.68375
Collected Steps per Second: 13,209.16660
Overall Steps per Second: 7,281.32766
Timestep Collection Time: 3.78737
Timestep Consumption Time: 3.08336
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.87072
Cumulative Model Updates: 168,344
Cumulative Timesteps: 1,301,566,100
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.55432
Policy Entropy: 4.35961
Value Function Loss: 0.00222
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.90131
Value Function Update Magnitude: 0.67531
Collected Steps per Second: 13,176.72878
Overall Steps per Second: 7,265.55105
Timestep Collection Time: 3.79548
Timestep Consumption Time: 3.08796
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.88344
Cumulative Model Updates: 168,353
Cumulative Timesteps: 1,301,616,112
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1301616112...
Checkpoint 1301616112 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.80546
Policy Entropy: 4.35748
Value Function Loss: 0.00224
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.90858
Value Function Update Magnitude: 0.67008
Collected Steps per Second: 13,525.29147
Overall Steps per Second: 7,333.92170
Timestep Collection Time: 3.69885
Timestep Consumption Time: 3.12260
PPO Batch Consumption Time: 0.22939
Total Iteration Time: 6.82145
Cumulative Model Updates: 168,362
Cumulative Timesteps: 1,301,666,140
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.21631
Policy Entropy: 4.35443
Value Function Loss: 0.00259
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.92733
Value Function Update Magnitude: 0.70159
Collected Steps per Second: 13,272.95753
Overall Steps per Second: 7,274.63469
Timestep Collection Time: 3.76992
Timestep Consumption Time: 3.10850
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.87842
Cumulative Model Updates: 168,371
Cumulative Timesteps: 1,301,716,178
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1301716178...
Checkpoint 1301716178 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14411
Policy Entropy: 4.35364
Value Function Loss: 0.00255
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.94769
Value Function Update Magnitude: 0.71543
Collected Steps per Second: 13,186.63879
Overall Steps per Second: 7,256.56484
Timestep Collection Time: 3.79323
Timestep Consumption Time: 3.09984
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.89307
Cumulative Model Updates: 168,380
Cumulative Timesteps: 1,301,766,198
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.61358
Policy Entropy: 4.35345
Value Function Loss: 0.00254
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.94533
Value Function Update Magnitude: 0.72439
Collected Steps per Second: 13,695.71231
Overall Steps per Second: 7,376.43447
Timestep Collection Time: 3.65209
Timestep Consumption Time: 3.12869
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.78078
Cumulative Model Updates: 168,389
Cumulative Timesteps: 1,301,816,216
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1301816216...
Checkpoint 1301816216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66516
Policy Entropy: 4.35500
Value Function Loss: 0.00236
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02651
Policy Update Magnitude: 0.92509
Value Function Update Magnitude: 0.72517
Collected Steps per Second: 13,295.19411
Overall Steps per Second: 7,222.35282
Timestep Collection Time: 3.76211
Timestep Consumption Time: 3.16333
PPO Batch Consumption Time: 0.23223
Total Iteration Time: 6.92544
Cumulative Model Updates: 168,398
Cumulative Timesteps: 1,301,866,234
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.07511
Policy Entropy: 4.35864
Value Function Loss: 0.00233
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.89774
Value Function Update Magnitude: 0.73834
Collected Steps per Second: 13,225.71687
Overall Steps per Second: 7,345.84302
Timestep Collection Time: 3.78263
Timestep Consumption Time: 3.02775
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.81038
Cumulative Model Updates: 168,407
Cumulative Timesteps: 1,301,916,262
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1301916262...
Checkpoint 1301916262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33686
Policy Entropy: 4.35480
Value Function Loss: 0.00236
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.91509
Value Function Update Magnitude: 0.77568
Collected Steps per Second: 13,218.26676
Overall Steps per Second: 7,258.18625
Timestep Collection Time: 3.78280
Timestep Consumption Time: 3.10625
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.88905
Cumulative Model Updates: 168,416
Cumulative Timesteps: 1,301,966,264
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76996
Policy Entropy: 4.35508
Value Function Loss: 0.00248
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.93485
Value Function Update Magnitude: 0.74041
Collected Steps per Second: 13,402.03053
Overall Steps per Second: 7,347.33879
Timestep Collection Time: 3.73197
Timestep Consumption Time: 3.07539
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.80736
Cumulative Model Updates: 168,425
Cumulative Timesteps: 1,302,016,280
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1302016280...
Checkpoint 1302016280 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19279
Policy Entropy: 4.35182
Value Function Loss: 0.00261
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.93678
Value Function Update Magnitude: 0.70691
Collected Steps per Second: 12,876.23124
Overall Steps per Second: 7,262.35988
Timestep Collection Time: 3.88561
Timestep Consumption Time: 3.00361
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.88922
Cumulative Model Updates: 168,434
Cumulative Timesteps: 1,302,066,312
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.77690
Policy Entropy: 4.35262
Value Function Loss: 0.00261
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02774
Policy Update Magnitude: 0.96080
Value Function Update Magnitude: 0.70954
Collected Steps per Second: 13,294.40777
Overall Steps per Second: 7,294.57592
Timestep Collection Time: 3.76263
Timestep Consumption Time: 3.09479
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.85742
Cumulative Model Updates: 168,443
Cumulative Timesteps: 1,302,116,334
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1302116334...
Checkpoint 1302116334 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20454
Policy Entropy: 4.35331
Value Function Loss: 0.00260
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.94338
Value Function Update Magnitude: 0.69349
Collected Steps per Second: 13,429.87330
Overall Steps per Second: 7,334.98144
Timestep Collection Time: 3.72364
Timestep Consumption Time: 3.09410
PPO Batch Consumption Time: 0.22782
Total Iteration Time: 6.81774
Cumulative Model Updates: 168,452
Cumulative Timesteps: 1,302,166,342
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.40663
Policy Entropy: 4.35463
Value Function Loss: 0.00249
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02783
Policy Update Magnitude: 0.92856
Value Function Update Magnitude: 0.69107
Collected Steps per Second: 13,458.32210
Overall Steps per Second: 7,186.28429
Timestep Collection Time: 3.71562
Timestep Consumption Time: 3.24291
PPO Batch Consumption Time: 0.24038
Total Iteration Time: 6.95853
Cumulative Model Updates: 168,461
Cumulative Timesteps: 1,302,216,348
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1302216348...
Checkpoint 1302216348 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.27878
Policy Entropy: 4.35509
Value Function Loss: 0.00260
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02574
Policy Update Magnitude: 0.92182
Value Function Update Magnitude: 0.70096
Collected Steps per Second: 13,027.82761
Overall Steps per Second: 7,215.12068
Timestep Collection Time: 3.83871
Timestep Consumption Time: 3.09257
PPO Batch Consumption Time: 0.22756
Total Iteration Time: 6.93128
Cumulative Model Updates: 168,470
Cumulative Timesteps: 1,302,266,358
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73130
Policy Entropy: 4.35206
Value Function Loss: 0.00249
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02723
Policy Update Magnitude: 0.93007
Value Function Update Magnitude: 0.73415
Collected Steps per Second: 13,157.58908
Overall Steps per Second: 7,279.30105
Timestep Collection Time: 3.80115
Timestep Consumption Time: 3.06956
PPO Batch Consumption Time: 0.22755
Total Iteration Time: 6.87071
Cumulative Model Updates: 168,479
Cumulative Timesteps: 1,302,316,372
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1302316372...
Checkpoint 1302316372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.54962
Policy Entropy: 4.35101
Value Function Loss: 0.00252
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02568
Policy Update Magnitude: 0.95189
Value Function Update Magnitude: 0.69701
Collected Steps per Second: 13,624.61178
Overall Steps per Second: 7,385.72146
Timestep Collection Time: 3.67277
Timestep Consumption Time: 3.10247
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.77524
Cumulative Model Updates: 168,488
Cumulative Timesteps: 1,302,366,412
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92621
Policy Entropy: 4.35475
Value Function Loss: 0.00228
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.91742
Value Function Update Magnitude: 0.68234
Collected Steps per Second: 13,146.58861
Overall Steps per Second: 7,234.56556
Timestep Collection Time: 3.80616
Timestep Consumption Time: 3.11036
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 6.91652
Cumulative Model Updates: 168,497
Cumulative Timesteps: 1,302,416,450
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1302416450...
Checkpoint 1302416450 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.40312
Policy Entropy: 4.35696
Value Function Loss: 0.00226
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.89845
Value Function Update Magnitude: 0.66108
Collected Steps per Second: 13,327.70761
Overall Steps per Second: 7,411.33138
Timestep Collection Time: 3.75323
Timestep Consumption Time: 2.99616
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.74939
Cumulative Model Updates: 168,506
Cumulative Timesteps: 1,302,466,472
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95336
Policy Entropy: 4.35667
Value Function Loss: 0.00237
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02413
Policy Update Magnitude: 0.91720
Value Function Update Magnitude: 0.65673
Collected Steps per Second: 13,376.88452
Overall Steps per Second: 7,316.22868
Timestep Collection Time: 3.73899
Timestep Consumption Time: 3.09732
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.83631
Cumulative Model Updates: 168,515
Cumulative Timesteps: 1,302,516,488
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1302516488...
Checkpoint 1302516488 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.39832
Policy Entropy: 4.35249
Value Function Loss: 0.00252
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.93008
Value Function Update Magnitude: 0.67271
Collected Steps per Second: 13,293.56320
Overall Steps per Second: 7,161.92069
Timestep Collection Time: 3.76272
Timestep Consumption Time: 3.22144
PPO Batch Consumption Time: 0.23991
Total Iteration Time: 6.98416
Cumulative Model Updates: 168,524
Cumulative Timesteps: 1,302,566,508
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.78581
Policy Entropy: 4.35169
Value Function Loss: 0.00263
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.94185
Value Function Update Magnitude: 0.70752
Collected Steps per Second: 13,392.62245
Overall Steps per Second: 7,389.31698
Timestep Collection Time: 3.73400
Timestep Consumption Time: 3.03361
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.76761
Cumulative Model Updates: 168,533
Cumulative Timesteps: 1,302,616,516
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1302616516...
Checkpoint 1302616516 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.93028
Policy Entropy: 4.35344
Value Function Loss: 0.00256
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02692
Policy Update Magnitude: 0.94329
Value Function Update Magnitude: 0.72964
Collected Steps per Second: 13,277.79088
Overall Steps per Second: 7,255.42663
Timestep Collection Time: 3.76810
Timestep Consumption Time: 3.12771
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.89580
Cumulative Model Updates: 168,542
Cumulative Timesteps: 1,302,666,548
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.86351
Policy Entropy: 4.35284
Value Function Loss: 0.00260
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.95916
Value Function Update Magnitude: 0.73762
Collected Steps per Second: 13,217.27348
Overall Steps per Second: 7,308.04377
Timestep Collection Time: 3.78505
Timestep Consumption Time: 3.06056
PPO Batch Consumption Time: 0.22770
Total Iteration Time: 6.84561
Cumulative Model Updates: 168,551
Cumulative Timesteps: 1,302,716,576
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1302716576...
Checkpoint 1302716576 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.92241
Policy Entropy: 4.35295
Value Function Loss: 0.00241
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.93951
Value Function Update Magnitude: 0.72198
Collected Steps per Second: 13,401.42635
Overall Steps per Second: 7,342.05166
Timestep Collection Time: 3.73274
Timestep Consumption Time: 3.08062
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.81335
Cumulative Model Updates: 168,560
Cumulative Timesteps: 1,302,766,600
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73159
Policy Entropy: 4.35053
Value Function Loss: 0.00232
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02756
Policy Update Magnitude: 0.91408
Value Function Update Magnitude: 0.76997
Collected Steps per Second: 13,216.90596
Overall Steps per Second: 7,268.65222
Timestep Collection Time: 3.78621
Timestep Consumption Time: 3.09842
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.88463
Cumulative Model Updates: 168,569
Cumulative Timesteps: 1,302,816,642
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1302816642...
Checkpoint 1302816642 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44624
Policy Entropy: 4.34820
Value Function Loss: 0.00224
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02668
Policy Update Magnitude: 0.91252
Value Function Update Magnitude: 0.72504
Collected Steps per Second: 13,133.74199
Overall Steps per Second: 7,343.64066
Timestep Collection Time: 3.80729
Timestep Consumption Time: 3.00186
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.80916
Cumulative Model Updates: 168,578
Cumulative Timesteps: 1,302,866,646
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63520
Policy Entropy: 4.34676
Value Function Loss: 0.00234
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.92902
Value Function Update Magnitude: 0.72656
Collected Steps per Second: 13,244.09719
Overall Steps per Second: 7,170.08381
Timestep Collection Time: 3.77572
Timestep Consumption Time: 3.19854
PPO Batch Consumption Time: 0.23808
Total Iteration Time: 6.97426
Cumulative Model Updates: 168,587
Cumulative Timesteps: 1,302,916,652
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1302916652...
Checkpoint 1302916652 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.94897
Policy Entropy: 4.34903
Value Function Loss: 0.00237
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.92410
Value Function Update Magnitude: 0.75790
Collected Steps per Second: 13,417.01750
Overall Steps per Second: 7,357.45054
Timestep Collection Time: 3.72840
Timestep Consumption Time: 3.07069
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.79909
Cumulative Model Updates: 168,596
Cumulative Timesteps: 1,302,966,676
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44105
Policy Entropy: 4.35163
Value Function Loss: 0.00218
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.90692
Value Function Update Magnitude: 0.73005
Collected Steps per Second: 13,240.65912
Overall Steps per Second: 7,375.53921
Timestep Collection Time: 3.78063
Timestep Consumption Time: 3.00640
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.78703
Cumulative Model Updates: 168,605
Cumulative Timesteps: 1,303,016,734
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 1303016734...
Checkpoint 1303016734 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83907
Policy Entropy: 4.35260
Value Function Loss: 0.00228
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.89573
Value Function Update Magnitude: 0.74551
Collected Steps per Second: 13,102.68233
Overall Steps per Second: 7,224.70134
Timestep Collection Time: 3.81815
Timestep Consumption Time: 3.10643
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.92458
Cumulative Model Updates: 168,614
Cumulative Timesteps: 1,303,066,762
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.07054
Policy Entropy: 4.35070
Value Function Loss: 0.00240
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.91451
Value Function Update Magnitude: 0.72777
Collected Steps per Second: 13,370.50732
Overall Steps per Second: 7,344.44514
Timestep Collection Time: 3.74032
Timestep Consumption Time: 3.06891
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.80923
Cumulative Model Updates: 168,623
Cumulative Timesteps: 1,303,116,772
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1303116772...
Checkpoint 1303116772 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.38459
Policy Entropy: 4.34588
Value Function Loss: 0.00261
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.95161
Value Function Update Magnitude: 0.74055
Collected Steps per Second: 13,470.61506
Overall Steps per Second: 7,348.13651
Timestep Collection Time: 3.71490
Timestep Consumption Time: 3.09526
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.81016
Cumulative Model Updates: 168,632
Cumulative Timesteps: 1,303,166,814
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.68217
Policy Entropy: 4.34476
Value Function Loss: 0.00270
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.95903
Value Function Update Magnitude: 0.79431
Collected Steps per Second: 13,269.58190
Overall Steps per Second: 7,254.63334
Timestep Collection Time: 3.76998
Timestep Consumption Time: 3.12576
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.89573
Cumulative Model Updates: 168,641
Cumulative Timesteps: 1,303,216,840
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1303216840...
Checkpoint 1303216840 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.36783
Policy Entropy: 4.34681
Value Function Loss: 0.00256
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.94604
Value Function Update Magnitude: 0.78203
Collected Steps per Second: 13,257.97582
Overall Steps per Second: 7,241.73677
Timestep Collection Time: 3.77313
Timestep Consumption Time: 3.13461
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 6.90774
Cumulative Model Updates: 168,650
Cumulative Timesteps: 1,303,266,864
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89246
Policy Entropy: 4.34972
Value Function Loss: 0.00240
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.91706
Value Function Update Magnitude: 0.71530
Collected Steps per Second: 13,489.90505
Overall Steps per Second: 7,341.99206
Timestep Collection Time: 3.70796
Timestep Consumption Time: 3.10491
PPO Batch Consumption Time: 0.22788
Total Iteration Time: 6.81286
Cumulative Model Updates: 168,659
Cumulative Timesteps: 1,303,316,884
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1303316884...
Checkpoint 1303316884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.79825
Policy Entropy: 4.35217
Value Function Loss: 0.00231
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.90244
Value Function Update Magnitude: 0.70246
Collected Steps per Second: 13,354.19603
Overall Steps per Second: 7,287.26200
Timestep Collection Time: 3.74429
Timestep Consumption Time: 3.11727
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.86156
Cumulative Model Updates: 168,668
Cumulative Timesteps: 1,303,366,886
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.89324
Policy Entropy: 4.35223
Value Function Loss: 0.00232
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.90183
Value Function Update Magnitude: 0.68651
Collected Steps per Second: 13,343.88522
Overall Steps per Second: 7,393.57236
Timestep Collection Time: 3.75048
Timestep Consumption Time: 3.01837
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.76885
Cumulative Model Updates: 168,677
Cumulative Timesteps: 1,303,416,932
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1303416932...
Checkpoint 1303416932 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.69536
Policy Entropy: 4.35188
Value Function Loss: 0.00250
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.91981
Value Function Update Magnitude: 0.69740
Collected Steps per Second: 13,319.90689
Overall Steps per Second: 7,287.75021
Timestep Collection Time: 3.75468
Timestep Consumption Time: 3.10779
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.86247
Cumulative Model Updates: 168,686
Cumulative Timesteps: 1,303,466,944
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88150
Policy Entropy: 4.35376
Value Function Loss: 0.00251
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.91968
Value Function Update Magnitude: 0.67355
Collected Steps per Second: 13,252.95582
Overall Steps per Second: 7,294.24150
Timestep Collection Time: 3.77305
Timestep Consumption Time: 3.08223
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.85527
Cumulative Model Updates: 168,695
Cumulative Timesteps: 1,303,516,948
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1303516948...
Checkpoint 1303516948 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19298
Policy Entropy: 4.35337
Value Function Loss: 0.00253
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.91648
Value Function Update Magnitude: 0.67767
Collected Steps per Second: 13,105.07654
Overall Steps per Second: 7,338.12668
Timestep Collection Time: 3.81684
Timestep Consumption Time: 2.99961
PPO Batch Consumption Time: 0.22789
Total Iteration Time: 6.81645
Cumulative Model Updates: 168,704
Cumulative Timesteps: 1,303,566,968
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.45023
Policy Entropy: 4.35274
Value Function Loss: 0.00251
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.92412
Value Function Update Magnitude: 0.71706
Collected Steps per Second: 13,160.13037
Overall Steps per Second: 7,185.90722
Timestep Collection Time: 3.80087
Timestep Consumption Time: 3.15997
PPO Batch Consumption Time: 0.23382
Total Iteration Time: 6.96085
Cumulative Model Updates: 168,713
Cumulative Timesteps: 1,303,616,988
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1303616988...
Checkpoint 1303616988 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.60713
Policy Entropy: 4.35255
Value Function Loss: 0.00246
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.90369
Value Function Update Magnitude: 0.73626
Collected Steps per Second: 13,210.03754
Overall Steps per Second: 7,292.13147
Timestep Collection Time: 3.78682
Timestep Consumption Time: 3.07318
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.86000
Cumulative Model Updates: 168,722
Cumulative Timesteps: 1,303,667,012
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04697
Policy Entropy: 4.35282
Value Function Loss: 0.00243
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.93221
Value Function Update Magnitude: 0.74510
Collected Steps per Second: 13,494.34339
Overall Steps per Second: 7,327.51073
Timestep Collection Time: 3.70763
Timestep Consumption Time: 3.12034
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.82797
Cumulative Model Updates: 168,731
Cumulative Timesteps: 1,303,717,044
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1303717044...
Checkpoint 1303717044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73455
Policy Entropy: 4.35692
Value Function Loss: 0.00247
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.94520
Value Function Update Magnitude: 0.78942
Collected Steps per Second: 13,394.68471
Overall Steps per Second: 7,319.88609
Timestep Collection Time: 3.73447
Timestep Consumption Time: 3.09925
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.83371
Cumulative Model Updates: 168,740
Cumulative Timesteps: 1,303,767,066
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01277
Policy Entropy: 4.35542
Value Function Loss: 0.00250
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.93163
Value Function Update Magnitude: 0.76809
Collected Steps per Second: 13,237.45546
Overall Steps per Second: 7,284.61026
Timestep Collection Time: 3.77897
Timestep Consumption Time: 3.08811
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.86708
Cumulative Model Updates: 168,749
Cumulative Timesteps: 1,303,817,090
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1303817090...
Checkpoint 1303817090 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.77287
Policy Entropy: 4.35741
Value Function Loss: 0.00231
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.90233
Value Function Update Magnitude: 0.75170
Collected Steps per Second: 13,464.29747
Overall Steps per Second: 7,290.58270
Timestep Collection Time: 3.71531
Timestep Consumption Time: 3.14615
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.86145
Cumulative Model Updates: 168,758
Cumulative Timesteps: 1,303,867,114
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.97952
Policy Entropy: 4.35861
Value Function Loss: 0.00205
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02409
Policy Update Magnitude: 0.86357
Value Function Update Magnitude: 0.68299
Collected Steps per Second: 13,253.37628
Overall Steps per Second: 7,270.58225
Timestep Collection Time: 3.77594
Timestep Consumption Time: 3.10714
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.88308
Cumulative Model Updates: 168,767
Cumulative Timesteps: 1,303,917,158
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1303917158...
Checkpoint 1303917158 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04585
Policy Entropy: 4.35884
Value Function Loss: 0.00212
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02260
Policy Update Magnitude: 0.88427
Value Function Update Magnitude: 0.65440
Collected Steps per Second: 13,096.14035
Overall Steps per Second: 7,248.35745
Timestep Collection Time: 3.82006
Timestep Consumption Time: 3.08192
PPO Batch Consumption Time: 0.23528
Total Iteration Time: 6.90198
Cumulative Model Updates: 168,776
Cumulative Timesteps: 1,303,967,186
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92193
Policy Entropy: 4.35665
Value Function Loss: 0.00235
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02434
Policy Update Magnitude: 0.91255
Value Function Update Magnitude: 0.70996
Collected Steps per Second: 13,308.20460
Overall Steps per Second: 7,290.86045
Timestep Collection Time: 3.75979
Timestep Consumption Time: 3.10305
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.86284
Cumulative Model Updates: 168,785
Cumulative Timesteps: 1,304,017,222
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1304017222...
Checkpoint 1304017222 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.65174
Policy Entropy: 4.35362
Value Function Loss: 0.00238
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02585
Policy Update Magnitude: 0.92034
Value Function Update Magnitude: 0.70066
Collected Steps per Second: 13,213.56974
Overall Steps per Second: 7,314.86263
Timestep Collection Time: 3.78626
Timestep Consumption Time: 3.05324
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.83950
Cumulative Model Updates: 168,794
Cumulative Timesteps: 1,304,067,252
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56630
Policy Entropy: 4.35072
Value Function Loss: 0.00260
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.94000
Value Function Update Magnitude: 0.71739
Collected Steps per Second: 13,326.88389
Overall Steps per Second: 7,415.24384
Timestep Collection Time: 3.75392
Timestep Consumption Time: 2.99273
PPO Batch Consumption Time: 0.22780
Total Iteration Time: 6.74664
Cumulative Model Updates: 168,803
Cumulative Timesteps: 1,304,117,280
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1304117280...
Checkpoint 1304117280 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14437
Policy Entropy: 4.34941
Value Function Loss: 0.00245
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02692
Policy Update Magnitude: 0.93766
Value Function Update Magnitude: 0.72916
Collected Steps per Second: 13,465.51920
Overall Steps per Second: 7,323.34838
Timestep Collection Time: 3.71438
Timestep Consumption Time: 3.11529
PPO Batch Consumption Time: 0.22788
Total Iteration Time: 6.82966
Cumulative Model Updates: 168,812
Cumulative Timesteps: 1,304,167,296
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.15945
Policy Entropy: 4.35536
Value Function Loss: 0.00234
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.91813
Value Function Update Magnitude: 0.74065
Collected Steps per Second: 13,314.43153
Overall Steps per Second: 7,312.12833
Timestep Collection Time: 3.75788
Timestep Consumption Time: 3.08473
PPO Batch Consumption Time: 0.22918
Total Iteration Time: 6.84260
Cumulative Model Updates: 168,821
Cumulative Timesteps: 1,304,217,330
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1304217330...
Checkpoint 1304217330 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.19811
Policy Entropy: 4.35309
Value Function Loss: 0.00216
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.87884
Value Function Update Magnitude: 0.67789
Collected Steps per Second: 13,549.98874
Overall Steps per Second: 7,346.42848
Timestep Collection Time: 3.69299
Timestep Consumption Time: 3.11848
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.81147
Cumulative Model Updates: 168,830
Cumulative Timesteps: 1,304,267,370
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64599
Policy Entropy: 4.35503
Value Function Loss: 0.00232
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.87451
Value Function Update Magnitude: 0.65227
Collected Steps per Second: 13,331.14159
Overall Steps per Second: 7,067.59136
Timestep Collection Time: 3.75287
Timestep Consumption Time: 3.32592
PPO Batch Consumption Time: 0.24515
Total Iteration Time: 7.07879
Cumulative Model Updates: 168,839
Cumulative Timesteps: 1,304,317,400
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1304317400...
Checkpoint 1304317400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.77897
Policy Entropy: 4.34685
Value Function Loss: 0.00239
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.87623
Value Function Update Magnitude: 0.68779
Collected Steps per Second: 13,138.71066
Overall Steps per Second: 7,359.99550
Timestep Collection Time: 3.80935
Timestep Consumption Time: 2.99092
PPO Batch Consumption Time: 0.22780
Total Iteration Time: 6.80028
Cumulative Model Updates: 168,848
Cumulative Timesteps: 1,304,367,450
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95045
Policy Entropy: 4.35115
Value Function Loss: 0.00226
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.88141
Value Function Update Magnitude: 0.68774
Collected Steps per Second: 13,228.36528
Overall Steps per Second: 7,271.42967
Timestep Collection Time: 3.78172
Timestep Consumption Time: 3.09808
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.87980
Cumulative Model Updates: 168,857
Cumulative Timesteps: 1,304,417,476
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1304417476...
Checkpoint 1304417476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.13356
Policy Entropy: 4.34905
Value Function Loss: 0.00228
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.89591
Value Function Update Magnitude: 0.69690
Collected Steps per Second: 13,189.38997
Overall Steps per Second: 7,289.28294
Timestep Collection Time: 3.79381
Timestep Consumption Time: 3.07079
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.86460
Cumulative Model Updates: 168,866
Cumulative Timesteps: 1,304,467,514
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.70861
Policy Entropy: 4.34866
Value Function Loss: 0.00240
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.90293
Value Function Update Magnitude: 0.72093
Collected Steps per Second: 13,239.61154
Overall Steps per Second: 7,392.61264
Timestep Collection Time: 3.77911
Timestep Consumption Time: 2.98899
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.76811
Cumulative Model Updates: 168,875
Cumulative Timesteps: 1,304,517,548
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1304517548...
Checkpoint 1304517548 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.57456
Policy Entropy: 4.34987
Value Function Loss: 0.00238
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02748
Policy Update Magnitude: 0.89186
Value Function Update Magnitude: 0.71592
Collected Steps per Second: 13,163.25537
Overall Steps per Second: 7,255.64503
Timestep Collection Time: 3.80012
Timestep Consumption Time: 3.09409
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.89422
Cumulative Model Updates: 168,884
Cumulative Timesteps: 1,304,567,570
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33706
Policy Entropy: 4.35455
Value Function Loss: 0.00218
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.87015
Value Function Update Magnitude: 0.70899
Collected Steps per Second: 13,146.43715
Overall Steps per Second: 7,264.50694
Timestep Collection Time: 3.80362
Timestep Consumption Time: 3.07971
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.88333
Cumulative Model Updates: 168,893
Cumulative Timesteps: 1,304,617,574
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1304617574...
Checkpoint 1304617574 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09824
Policy Entropy: 4.35459
Value Function Loss: 0.00211
Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.86623
Value Function Update Magnitude: 0.72112
Collected Steps per Second: 13,557.90237
Overall Steps per Second: 7,306.57444
Timestep Collection Time: 3.68862
Timestep Consumption Time: 3.15590
PPO Batch Consumption Time: 0.23384
Total Iteration Time: 6.84452
Cumulative Model Updates: 168,902
Cumulative Timesteps: 1,304,667,584
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.81283
Policy Entropy: 4.35628
Value Function Loss: 0.00210
Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02175
Policy Update Magnitude: 0.86394
Value Function Update Magnitude: 0.67302
Collected Steps per Second: 13,195.41232
Overall Steps per Second: 7,255.49235
Timestep Collection Time: 3.78980
Timestep Consumption Time: 3.10263
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.89243
Cumulative Model Updates: 168,911
Cumulative Timesteps: 1,304,717,592
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1304717592...
Checkpoint 1304717592 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26909
Policy Entropy: 4.35333
Value Function Loss: 0.00228
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02382
Policy Update Magnitude: 0.86647
Value Function Update Magnitude: 0.69712
Collected Steps per Second: 13,221.68706
Overall Steps per Second: 7,302.14705
Timestep Collection Time: 3.78288
Timestep Consumption Time: 3.06662
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.84949
Cumulative Model Updates: 168,920
Cumulative Timesteps: 1,304,767,608
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.07741
Policy Entropy: 4.34893
Value Function Loss: 0.00255
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02328
Policy Update Magnitude: 0.91125
Value Function Update Magnitude: 0.75103
Collected Steps per Second: 13,520.27617
Overall Steps per Second: 7,351.86672
Timestep Collection Time: 3.70037
Timestep Consumption Time: 3.10471
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.80507
Cumulative Model Updates: 168,929
Cumulative Timesteps: 1,304,817,638
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1304817638...
Checkpoint 1304817638 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71168
Policy Entropy: 4.34176
Value Function Loss: 0.00277
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.94440
Value Function Update Magnitude: 0.77166
Collected Steps per Second: 13,050.66800
Overall Steps per Second: 7,198.49620
Timestep Collection Time: 3.83306
Timestep Consumption Time: 3.11617
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.94923
Cumulative Model Updates: 168,938
Cumulative Timesteps: 1,304,867,662
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.87777
Policy Entropy: 4.34434
Value Function Loss: 0.00280
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.93706
Value Function Update Magnitude: 0.73164
Collected Steps per Second: 13,294.70367
Overall Steps per Second: 7,387.39389
Timestep Collection Time: 3.76315
Timestep Consumption Time: 3.00920
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.77235
Cumulative Model Updates: 168,947
Cumulative Timesteps: 1,304,917,692
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1304917692...
Checkpoint 1304917692 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61638
Policy Entropy: 4.34734
Value Function Loss: 0.00242
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.88888
Value Function Update Magnitude: 0.72496
Collected Steps per Second: 13,370.19006
Overall Steps per Second: 7,293.14689
Timestep Collection Time: 3.74101
Timestep Consumption Time: 3.11721
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.85822
Cumulative Model Updates: 168,956
Cumulative Timesteps: 1,304,967,710
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.69027
Policy Entropy: 4.35365
Value Function Loss: 0.00225
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02236
Policy Update Magnitude: 0.85285
Value Function Update Magnitude: 0.72228
Collected Steps per Second: 13,213.44215
Overall Steps per Second: 7,144.99240
Timestep Collection Time: 3.78614
Timestep Consumption Time: 3.21568
PPO Batch Consumption Time: 0.23926
Total Iteration Time: 7.00183
Cumulative Model Updates: 168,965
Cumulative Timesteps: 1,305,017,738
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1305017738...
Checkpoint 1305017738 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.74863
Policy Entropy: 4.34846
Value Function Loss: 0.00236
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.86574
Value Function Update Magnitude: 0.72312
Collected Steps per Second: 13,065.89888
Overall Steps per Second: 7,323.65827
Timestep Collection Time: 3.82813
Timestep Consumption Time: 3.00151
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.82965
Cumulative Model Updates: 168,974
Cumulative Timesteps: 1,305,067,756
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.83612
Policy Entropy: 4.34892
Value Function Loss: 0.00233
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.87893
Value Function Update Magnitude: 0.71541
Collected Steps per Second: 13,212.46690
Overall Steps per Second: 7,256.63035
Timestep Collection Time: 3.78461
Timestep Consumption Time: 3.10619
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.89080
Cumulative Model Updates: 168,983
Cumulative Timesteps: 1,305,117,760
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1305117760...
Checkpoint 1305117760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92330
Policy Entropy: 4.34776
Value Function Loss: 0.00234
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02404
Policy Update Magnitude: 0.86810
Value Function Update Magnitude: 0.76963
Collected Steps per Second: 13,227.03241
Overall Steps per Second: 7,302.84486
Timestep Collection Time: 3.78271
Timestep Consumption Time: 3.06859
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.85130
Cumulative Model Updates: 168,992
Cumulative Timesteps: 1,305,167,794
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50061
Policy Entropy: 4.34956
Value Function Loss: 0.00238
Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.88466
Value Function Update Magnitude: 0.77760
Collected Steps per Second: 13,510.28164
Overall Steps per Second: 7,356.72029
Timestep Collection Time: 3.70340
Timestep Consumption Time: 3.09773
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.80113
Cumulative Model Updates: 169,001
Cumulative Timesteps: 1,305,217,828
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1305217828...
Checkpoint 1305217828 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.78497
Policy Entropy: 4.34762
Value Function Loss: 0.00262
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.92269
Value Function Update Magnitude: 0.72902
Collected Steps per Second: 13,289.78441
Overall Steps per Second: 7,281.84352
Timestep Collection Time: 3.76530
Timestep Consumption Time: 3.10659
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.87189
Cumulative Model Updates: 169,010
Cumulative Timesteps: 1,305,267,868
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88616
Policy Entropy: 4.34615
Value Function Loss: 0.00271
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.93043
Value Function Update Magnitude: 0.72118
Collected Steps per Second: 13,305.55972
Overall Steps per Second: 7,324.18485
Timestep Collection Time: 3.75858
Timestep Consumption Time: 3.06948
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.82806
Cumulative Model Updates: 169,019
Cumulative Timesteps: 1,305,317,878
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1305317878...
Checkpoint 1305317878 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.82687
Policy Entropy: 4.34684
Value Function Loss: 0.00247
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.91996
Value Function Update Magnitude: 0.74554
Collected Steps per Second: 13,468.82534
Overall Steps per Second: 7,141.47752
Timestep Collection Time: 3.71257
Timestep Consumption Time: 3.28934
PPO Batch Consumption Time: 0.24036
Total Iteration Time: 7.00191
Cumulative Model Updates: 169,028
Cumulative Timesteps: 1,305,367,882
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.16722
Policy Entropy: 4.34512
Value Function Loss: 0.00239
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02849
Policy Update Magnitude: 0.90103
Value Function Update Magnitude: 0.77183
Collected Steps per Second: 13,193.32538
Overall Steps per Second: 7,267.15351
Timestep Collection Time: 3.78995
Timestep Consumption Time: 3.09060
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.88055
Cumulative Model Updates: 169,037
Cumulative Timesteps: 1,305,417,884
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1305417884...
Checkpoint 1305417884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86700
Policy Entropy: 4.34957
Value Function Loss: 0.00231
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.90947
Value Function Update Magnitude: 0.74497
Collected Steps per Second: 12,883.62994
Overall Steps per Second: 7,255.73447
Timestep Collection Time: 3.88291
Timestep Consumption Time: 3.01177
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.89468
Cumulative Model Updates: 169,046
Cumulative Timesteps: 1,305,467,910
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44070
Policy Entropy: 4.34910
Value Function Loss: 0.00223
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.89901
Value Function Update Magnitude: 0.71878
Collected Steps per Second: 13,219.94304
Overall Steps per Second: 7,280.58582
Timestep Collection Time: 3.78504
Timestep Consumption Time: 3.08776
PPO Batch Consumption Time: 0.22754
Total Iteration Time: 6.87280
Cumulative Model Updates: 169,055
Cumulative Timesteps: 1,305,517,948
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1305517948...
Checkpoint 1305517948 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50276
Policy Entropy: 4.34957
Value Function Loss: 0.00226
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.88563
Value Function Update Magnitude: 0.72700
Collected Steps per Second: 13,294.17279
Overall Steps per Second: 7,306.58568
Timestep Collection Time: 3.76375
Timestep Consumption Time: 3.08431
PPO Batch Consumption Time: 0.22774
Total Iteration Time: 6.84807
Cumulative Model Updates: 169,064
Cumulative Timesteps: 1,305,567,984
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26271
Policy Entropy: 4.34768
Value Function Loss: 0.00224
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02435
Policy Update Magnitude: 0.90207
Value Function Update Magnitude: 0.70666
Collected Steps per Second: 13,561.73447
Overall Steps per Second: 7,342.39086
Timestep Collection Time: 3.68935
Timestep Consumption Time: 3.12505
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.81440
Cumulative Model Updates: 169,073
Cumulative Timesteps: 1,305,618,018
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1305618018...
Checkpoint 1305618018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.65743
Policy Entropy: 4.34590
Value Function Loss: 0.00238
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.91712
Value Function Update Magnitude: 0.69242
Collected Steps per Second: 13,326.33851
Overall Steps per Second: 7,277.67893
Timestep Collection Time: 3.75287
Timestep Consumption Time: 3.11910
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.87197
Cumulative Model Updates: 169,082
Cumulative Timesteps: 1,305,668,030
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84377
Policy Entropy: 4.34886
Value Function Loss: 0.00231
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.91111
Value Function Update Magnitude: 0.69385
Collected Steps per Second: 13,241.62498
Overall Steps per Second: 7,162.34556
Timestep Collection Time: 3.77748
Timestep Consumption Time: 3.20626
PPO Batch Consumption Time: 0.23830
Total Iteration Time: 6.98375
Cumulative Model Updates: 169,091
Cumulative Timesteps: 1,305,718,050
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1305718050...
Checkpoint 1305718050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35560
Policy Entropy: 4.35063
Value Function Loss: 0.00238
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.89822
Value Function Update Magnitude: 0.70466
Collected Steps per Second: 13,641.87126
Overall Steps per Second: 7,368.78032
Timestep Collection Time: 3.66665
Timestep Consumption Time: 3.12145
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.78810
Cumulative Model Updates: 169,100
Cumulative Timesteps: 1,305,768,070
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.44014
Policy Entropy: 4.35102
Value Function Loss: 0.00231
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.89947
Value Function Update Magnitude: 0.70362
Collected Steps per Second: 13,395.99939
Overall Steps per Second: 7,269.88888
Timestep Collection Time: 3.73410
Timestep Consumption Time: 3.14661
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.88071
Cumulative Model Updates: 169,109
Cumulative Timesteps: 1,305,818,092
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1305818092...
Checkpoint 1305818092 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.60938
Policy Entropy: 4.35114
Value Function Loss: 0.00218
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.88982
Value Function Update Magnitude: 0.68487
Collected Steps per Second: 13,156.73081
Overall Steps per Second: 7,322.29902
Timestep Collection Time: 3.80292
Timestep Consumption Time: 3.03018
PPO Batch Consumption Time: 0.23209
Total Iteration Time: 6.83310
Cumulative Model Updates: 169,118
Cumulative Timesteps: 1,305,868,126
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85104
Policy Entropy: 4.35189
Value Function Loss: 0.00211
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.87443
Value Function Update Magnitude: 0.64939
Collected Steps per Second: 13,287.96857
Overall Steps per Second: 7,268.55290
Timestep Collection Time: 3.76657
Timestep Consumption Time: 3.11926
PPO Batch Consumption Time: 0.22786
Total Iteration Time: 6.88583
Cumulative Model Updates: 169,127
Cumulative Timesteps: 1,305,918,176
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1305918176...
Checkpoint 1305918176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.21082
Policy Entropy: 4.35082
Value Function Loss: 0.00227
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.89303
Value Function Update Magnitude: 0.66515
Collected Steps per Second: 13,236.26072
Overall Steps per Second: 7,303.56394
Timestep Collection Time: 3.77947
Timestep Consumption Time: 3.07007
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.84953
Cumulative Model Updates: 169,136
Cumulative Timesteps: 1,305,968,202
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64142
Policy Entropy: 4.34986
Value Function Loss: 0.00241
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.91878
Value Function Update Magnitude: 0.71349
Collected Steps per Second: 13,014.08918
Overall Steps per Second: 7,284.83019
Timestep Collection Time: 3.84245
Timestep Consumption Time: 3.02195
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.86440
Cumulative Model Updates: 169,145
Cumulative Timesteps: 1,306,018,208
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1306018208...
Checkpoint 1306018208 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31241
Policy Entropy: 4.34896
Value Function Loss: 0.00251
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02702
Policy Update Magnitude: 0.92022
Value Function Update Magnitude: 0.72591
Collected Steps per Second: 13,114.29196
Overall Steps per Second: 7,093.57762
Timestep Collection Time: 3.81690
Timestep Consumption Time: 3.23962
PPO Batch Consumption Time: 0.23775
Total Iteration Time: 7.05652
Cumulative Model Updates: 169,154
Cumulative Timesteps: 1,306,068,264
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08463
Policy Entropy: 4.34875
Value Function Loss: 0.00253
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02616
Policy Update Magnitude: 0.94101
Value Function Update Magnitude: 0.72434
Collected Steps per Second: 12,974.97082
Overall Steps per Second: 7,219.49805
Timestep Collection Time: 3.85388
Timestep Consumption Time: 3.07236
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.92624
Cumulative Model Updates: 169,163
Cumulative Timesteps: 1,306,118,268
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1306118268...
Checkpoint 1306118268 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02539
Policy Entropy: 4.35251
Value Function Loss: 0.00238
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.93630
Value Function Update Magnitude: 0.72447
Collected Steps per Second: 13,605.11623
Overall Steps per Second: 7,406.67412
Timestep Collection Time: 3.67744
Timestep Consumption Time: 3.07755
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.75499
Cumulative Model Updates: 169,172
Cumulative Timesteps: 1,306,168,300
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41725
Policy Entropy: 4.34971
Value Function Loss: 0.00248
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.93152
Value Function Update Magnitude: 0.72042
Collected Steps per Second: 13,239.29005
Overall Steps per Second: 7,273.78669
Timestep Collection Time: 3.77951
Timestep Consumption Time: 3.09972
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.87922
Cumulative Model Updates: 169,181
Cumulative Timesteps: 1,306,218,338
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1306218338...
Checkpoint 1306218338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.83196
Policy Entropy: 4.35244
Value Function Loss: 0.00238
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.92895
Value Function Update Magnitude: 0.72077
Collected Steps per Second: 13,052.74108
Overall Steps per Second: 7,322.07298
Timestep Collection Time: 3.83107
Timestep Consumption Time: 2.99841
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.82949
Cumulative Model Updates: 169,190
Cumulative Timesteps: 1,306,268,344
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79223
Policy Entropy: 4.35208
Value Function Loss: 0.00253
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.93211
Value Function Update Magnitude: 0.72333
Collected Steps per Second: 13,291.89177
Overall Steps per Second: 7,278.91609
Timestep Collection Time: 3.76485
Timestep Consumption Time: 3.11007
PPO Batch Consumption Time: 0.22771
Total Iteration Time: 6.87492
Cumulative Model Updates: 169,199
Cumulative Timesteps: 1,306,318,386
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1306318386...
Checkpoint 1306318386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.39061
Policy Entropy: 4.35229
Value Function Loss: 0.00253
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.94792
Value Function Update Magnitude: 0.71965
Collected Steps per Second: 13,082.29146
Overall Steps per Second: 7,247.81002
Timestep Collection Time: 3.82272
Timestep Consumption Time: 3.07729
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.90002
Cumulative Model Updates: 169,208
Cumulative Timesteps: 1,306,368,396
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.39984
Policy Entropy: 4.35360
Value Function Loss: 0.00247
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.92227
Value Function Update Magnitude: 0.67337
Collected Steps per Second: 13,537.43112
Overall Steps per Second: 7,185.12598
Timestep Collection Time: 3.69450
Timestep Consumption Time: 3.26627
PPO Batch Consumption Time: 0.24022
Total Iteration Time: 6.96077
Cumulative Model Updates: 169,217
Cumulative Timesteps: 1,306,418,410
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1306418410...
Checkpoint 1306418410 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.55309
Policy Entropy: 4.35192
Value Function Loss: 0.00251
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.90908
Value Function Update Magnitude: 0.67524
Collected Steps per Second: 13,295.81316
Overall Steps per Second: 7,269.49513
Timestep Collection Time: 3.76299
Timestep Consumption Time: 3.11947
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.88246
Cumulative Model Updates: 169,226
Cumulative Timesteps: 1,306,468,442
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.38806
Policy Entropy: 4.35550
Value Function Loss: 0.00233
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.90904
Value Function Update Magnitude: 0.76842
Collected Steps per Second: 13,221.28552
Overall Steps per Second: 7,291.43938
Timestep Collection Time: 3.78450
Timestep Consumption Time: 3.07779
PPO Batch Consumption Time: 0.22771
Total Iteration Time: 6.86229
Cumulative Model Updates: 169,235
Cumulative Timesteps: 1,306,518,478
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1306518478...
Checkpoint 1306518478 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84907
Policy Entropy: 4.35490
Value Function Loss: 0.00237
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02689
Policy Update Magnitude: 0.91201
Value Function Update Magnitude: 0.79080
Collected Steps per Second: 13,545.05802
Overall Steps per Second: 7,367.21969
Timestep Collection Time: 3.69478
Timestep Consumption Time: 3.09829
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.79306
Cumulative Model Updates: 169,244
Cumulative Timesteps: 1,306,568,524
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01601
Policy Entropy: 4.35485
Value Function Loss: 0.00235
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.93127
Value Function Update Magnitude: 0.75734
Collected Steps per Second: 13,327.56889
Overall Steps per Second: 7,292.17055
Timestep Collection Time: 3.75312
Timestep Consumption Time: 3.10629
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.85941
Cumulative Model Updates: 169,253
Cumulative Timesteps: 1,306,618,544
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1306618544...
Checkpoint 1306618544 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02088
Policy Entropy: 4.35516
Value Function Loss: 0.00240
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02756
Policy Update Magnitude: 0.92855
Value Function Update Magnitude: 0.76719
Collected Steps per Second: 13,080.83802
Overall Steps per Second: 7,310.66731
Timestep Collection Time: 3.82483
Timestep Consumption Time: 3.01887
PPO Batch Consumption Time: 0.22943
Total Iteration Time: 6.84370
Cumulative Model Updates: 169,262
Cumulative Timesteps: 1,306,668,576
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.91659
Policy Entropy: 4.35550
Value Function Loss: 0.00241
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.93634
Value Function Update Magnitude: 0.77970
Collected Steps per Second: 13,351.38752
Overall Steps per Second: 7,300.85203
Timestep Collection Time: 3.74628
Timestep Consumption Time: 3.10470
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.85098
Cumulative Model Updates: 169,271
Cumulative Timesteps: 1,306,718,594
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1306718594...
Checkpoint 1306718594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.73365
Policy Entropy: 4.35654
Value Function Loss: 0.00233
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.93623
Value Function Update Magnitude: 0.73955
Collected Steps per Second: 13,236.70206
Overall Steps per Second: 7,151.86407
Timestep Collection Time: 3.77889
Timestep Consumption Time: 3.21509
PPO Batch Consumption Time: 0.24078
Total Iteration Time: 6.99398
Cumulative Model Updates: 169,280
Cumulative Timesteps: 1,306,768,614
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09549
Policy Entropy: 4.35573
Value Function Loss: 0.00253
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 0.96793
Value Function Update Magnitude: 0.74771
Collected Steps per Second: 13,249.73965
Overall Steps per Second: 7,385.76138
Timestep Collection Time: 3.77804
Timestep Consumption Time: 2.99960
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.77764
Cumulative Model Updates: 169,289
Cumulative Timesteps: 1,306,818,672
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 1306818672...
Checkpoint 1306818672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.99520
Policy Entropy: 4.35379
Value Function Loss: 0.00260
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.99597
Value Function Update Magnitude: 0.77345
Collected Steps per Second: 13,286.03249
Overall Steps per Second: 7,277.87372
Timestep Collection Time: 3.76501
Timestep Consumption Time: 3.10815
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.87316
Cumulative Model Updates: 169,298
Cumulative Timesteps: 1,306,868,694
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46332
Policy Entropy: 4.35365
Value Function Loss: 0.00259
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.99681
Value Function Update Magnitude: 0.77526
Collected Steps per Second: 13,332.43285
Overall Steps per Second: 7,317.49019
Timestep Collection Time: 3.75355
Timestep Consumption Time: 3.08540
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.83896
Cumulative Model Updates: 169,307
Cumulative Timesteps: 1,306,918,738
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1306918738...
Checkpoint 1306918738 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.88278
Policy Entropy: 4.35639
Value Function Loss: 0.00236
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.94693
Value Function Update Magnitude: 0.71845
Collected Steps per Second: 13,530.75911
Overall Steps per Second: 7,356.58595
Timestep Collection Time: 3.69691
Timestep Consumption Time: 3.10271
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.79962
Cumulative Model Updates: 169,316
Cumulative Timesteps: 1,306,968,760
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95228
Policy Entropy: 4.35553
Value Function Loss: 0.00238
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.92297
Value Function Update Magnitude: 0.70949
Collected Steps per Second: 13,241.74403
Overall Steps per Second: 7,266.53807
Timestep Collection Time: 3.77851
Timestep Consumption Time: 3.10703
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.88553
Cumulative Model Updates: 169,325
Cumulative Timesteps: 1,307,018,794
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1307018794...
Checkpoint 1307018794 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.94162
Policy Entropy: 4.35739
Value Function Loss: 0.00239
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.92747
Value Function Update Magnitude: 0.71212
Collected Steps per Second: 13,214.82686
Overall Steps per Second: 7,295.95408
Timestep Collection Time: 3.78484
Timestep Consumption Time: 3.07047
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.85531
Cumulative Model Updates: 169,334
Cumulative Timesteps: 1,307,068,810
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.44829
Policy Entropy: 4.35392
Value Function Loss: 0.00264
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.97441
Value Function Update Magnitude: 0.74023
Collected Steps per Second: 13,592.26059
Overall Steps per Second: 7,264.59934
Timestep Collection Time: 3.68180
Timestep Consumption Time: 3.20695
PPO Batch Consumption Time: 0.23445
Total Iteration Time: 6.88875
Cumulative Model Updates: 169,343
Cumulative Timesteps: 1,307,118,854
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1307118854...
Checkpoint 1307118854 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.30611
Policy Entropy: 4.35217
Value Function Loss: 0.00268
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.99371
Value Function Update Magnitude: 0.77728
Collected Steps per Second: 13,226.19979
Overall Steps per Second: 7,238.84035
Timestep Collection Time: 3.78264
Timestep Consumption Time: 3.12868
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.91133
Cumulative Model Updates: 169,352
Cumulative Timesteps: 1,307,168,884
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49580
Policy Entropy: 4.35614
Value Function Loss: 0.00268
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.97465
Value Function Update Magnitude: 0.81437
Collected Steps per Second: 13,252.41674
Overall Steps per Second: 7,374.86042
Timestep Collection Time: 3.77531
Timestep Consumption Time: 3.00882
PPO Batch Consumption Time: 0.22794
Total Iteration Time: 6.78413
Cumulative Model Updates: 169,361
Cumulative Timesteps: 1,307,218,916
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1307218916...
Checkpoint 1307218916 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.78258
Policy Entropy: 4.35107
Value Function Loss: 0.00251
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.96456
Value Function Update Magnitude: 0.80768
Collected Steps per Second: 13,212.75458
Overall Steps per Second: 7,253.70913
Timestep Collection Time: 3.78695
Timestep Consumption Time: 3.11104
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.89799
Cumulative Model Updates: 169,370
Cumulative Timesteps: 1,307,268,952
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00757
Policy Entropy: 4.35680
Value Function Loss: 0.00231
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.95466
Value Function Update Magnitude: 0.76448
Collected Steps per Second: 13,224.40509
Overall Steps per Second: 7,309.92507
Timestep Collection Time: 3.78210
Timestep Consumption Time: 3.06011
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.84220
Cumulative Model Updates: 169,379
Cumulative Timesteps: 1,307,318,968
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1307318968...
Checkpoint 1307318968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54131
Policy Entropy: 4.35349
Value Function Loss: 0.00252
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.97313
Value Function Update Magnitude: 0.78117
Collected Steps per Second: 13,214.00294
Overall Steps per Second: 7,372.95845
Timestep Collection Time: 3.78538
Timestep Consumption Time: 2.99887
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.78425
Cumulative Model Updates: 169,388
Cumulative Timesteps: 1,307,368,988
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44392
Policy Entropy: 4.35252
Value Function Loss: 0.00264
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 1.00629
Value Function Update Magnitude: 0.77214
Collected Steps per Second: 13,234.03011
Overall Steps per Second: 7,280.22066
Timestep Collection Time: 3.77814
Timestep Consumption Time: 3.08979
PPO Batch Consumption Time: 0.22797
Total Iteration Time: 6.86792
Cumulative Model Updates: 169,397
Cumulative Timesteps: 1,307,418,988
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1307418988...
Checkpoint 1307418988 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18094
Policy Entropy: 4.35127
Value Function Loss: 0.00258
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.98852
Value Function Update Magnitude: 0.73346
Collected Steps per Second: 13,071.96373
Overall Steps per Second: 7,053.26298
Timestep Collection Time: 3.82743
Timestep Consumption Time: 3.26603
PPO Batch Consumption Time: 0.24557
Total Iteration Time: 7.09345
Cumulative Model Updates: 169,406
Cumulative Timesteps: 1,307,469,020
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80289
Policy Entropy: 4.34587
Value Function Loss: 0.00250
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.97015
Value Function Update Magnitude: 0.70157
Collected Steps per Second: 13,412.62033
Overall Steps per Second: 7,347.71180
Timestep Collection Time: 3.72947
Timestep Consumption Time: 3.07836
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.80783
Cumulative Model Updates: 169,415
Cumulative Timesteps: 1,307,519,042
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1307519042...
Checkpoint 1307519042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.60804
Policy Entropy: 4.34442
Value Function Loss: 0.00248
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.95463
Value Function Update Magnitude: 0.67611
Collected Steps per Second: 13,198.02803
Overall Steps per Second: 7,241.41398
Timestep Collection Time: 3.78905
Timestep Consumption Time: 3.11678
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 6.90583
Cumulative Model Updates: 169,424
Cumulative Timesteps: 1,307,569,050
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.59374
Policy Entropy: 4.34290
Value Function Loss: 0.00270
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.97280
Value Function Update Magnitude: 0.70199
Collected Steps per Second: 13,223.77154
Overall Steps per Second: 7,333.65466
Timestep Collection Time: 3.78228
Timestep Consumption Time: 3.03779
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.82006
Cumulative Model Updates: 169,433
Cumulative Timesteps: 1,307,619,066
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1307619066...
Checkpoint 1307619066 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.59450
Policy Entropy: 4.34187
Value Function Loss: 0.00278
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 1.00143
Value Function Update Magnitude: 0.73619
Collected Steps per Second: 13,050.10041
Overall Steps per Second: 7,209.59251
Timestep Collection Time: 3.83292
Timestep Consumption Time: 3.10506
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.93798
Cumulative Model Updates: 169,442
Cumulative Timesteps: 1,307,669,086
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32574
Policy Entropy: 4.34312
Value Function Loss: 0.00280
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03079
Policy Update Magnitude: 1.00740
Value Function Update Magnitude: 0.79346
Collected Steps per Second: 13,034.27510
Overall Steps per Second: 7,235.26485
Timestep Collection Time: 3.83696
Timestep Consumption Time: 3.07530
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.91226
Cumulative Model Updates: 169,451
Cumulative Timesteps: 1,307,719,098
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1307719098...
Checkpoint 1307719098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66260
Policy Entropy: 4.34453
Value Function Loss: 0.00268
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.98168
Value Function Update Magnitude: 0.75972
Collected Steps per Second: 13,665.95349
Overall Steps per Second: 7,382.63584
Timestep Collection Time: 3.66048
Timestep Consumption Time: 3.11542
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.77590
Cumulative Model Updates: 169,460
Cumulative Timesteps: 1,307,769,122
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72501
Policy Entropy: 4.34759
Value Function Loss: 0.00249
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.95162
Value Function Update Magnitude: 0.72911
Collected Steps per Second: 13,125.78440
Overall Steps per Second: 7,017.41768
Timestep Collection Time: 3.81173
Timestep Consumption Time: 3.31795
PPO Batch Consumption Time: 0.24522
Total Iteration Time: 7.12969
Cumulative Model Updates: 169,469
Cumulative Timesteps: 1,307,819,154
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1307819154...
Checkpoint 1307819154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.12311
Policy Entropy: 4.34895
Value Function Loss: 0.00247
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.94454
Value Function Update Magnitude: 0.73932
Collected Steps per Second: 13,101.45971
Overall Steps per Second: 7,239.98037
Timestep Collection Time: 3.81820
Timestep Consumption Time: 3.09121
PPO Batch Consumption Time: 0.22779
Total Iteration Time: 6.90941
Cumulative Model Updates: 169,478
Cumulative Timesteps: 1,307,869,178
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11583
Policy Entropy: 4.34795
Value Function Loss: 0.00247
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.95921
Value Function Update Magnitude: 0.72561
Collected Steps per Second: 13,625.53096
Overall Steps per Second: 7,392.27159
Timestep Collection Time: 3.67193
Timestep Consumption Time: 3.09622
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.76815
Cumulative Model Updates: 169,487
Cumulative Timesteps: 1,307,919,210
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1307919210...
Checkpoint 1307919210 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96121
Policy Entropy: 4.34773
Value Function Loss: 0.00249
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.95729
Value Function Update Magnitude: 0.73575
Collected Steps per Second: 13,179.71827
Overall Steps per Second: 7,248.21197
Timestep Collection Time: 3.79371
Timestep Consumption Time: 3.10455
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.89825
Cumulative Model Updates: 169,496
Cumulative Timesteps: 1,307,969,210
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25333
Policy Entropy: 4.35076
Value Function Loss: 0.00243
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.92910
Value Function Update Magnitude: 0.75555
Collected Steps per Second: 13,142.66379
Overall Steps per Second: 7,357.10247
Timestep Collection Time: 3.80501
Timestep Consumption Time: 2.99223
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.79724
Cumulative Model Updates: 169,505
Cumulative Timesteps: 1,308,019,218
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1308019218...
Checkpoint 1308019218 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69245
Policy Entropy: 4.35126
Value Function Loss: 0.00249
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02479
Policy Update Magnitude: 0.93232
Value Function Update Magnitude: 0.78080
Collected Steps per Second: 13,232.62529
Overall Steps per Second: 7,272.18538
Timestep Collection Time: 3.77854
Timestep Consumption Time: 3.09697
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.87551
Cumulative Model Updates: 169,514
Cumulative Timesteps: 1,308,069,218
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.67271
Policy Entropy: 4.34798
Value Function Loss: 0.00252
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.93613
Value Function Update Magnitude: 0.78089
Collected Steps per Second: 13,481.65307
Overall Steps per Second: 7,372.35512
Timestep Collection Time: 3.71112
Timestep Consumption Time: 3.07532
PPO Batch Consumption Time: 0.22785
Total Iteration Time: 6.78643
Cumulative Model Updates: 169,523
Cumulative Timesteps: 1,308,119,250
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1308119250...
Checkpoint 1308119250 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03652
Policy Entropy: 4.35026
Value Function Loss: 0.00253
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.93777
Value Function Update Magnitude: 0.73345
Collected Steps per Second: 13,099.15589
Overall Steps per Second: 7,117.25380
Timestep Collection Time: 3.81826
Timestep Consumption Time: 3.20917
PPO Batch Consumption Time: 0.24552
Total Iteration Time: 7.02743
Cumulative Model Updates: 169,532
Cumulative Timesteps: 1,308,169,266
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81141
Policy Entropy: 4.34754
Value Function Loss: 0.00254
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02812
Policy Update Magnitude: 0.95771
Value Function Update Magnitude: 0.72538
Collected Steps per Second: 13,363.38318
Overall Steps per Second: 7,304.09973
Timestep Collection Time: 3.74232
Timestep Consumption Time: 3.10452
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.84684
Cumulative Model Updates: 169,541
Cumulative Timesteps: 1,308,219,276
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1308219276...
Checkpoint 1308219276 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50750
Policy Entropy: 4.35123
Value Function Loss: 0.00234
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.92741
Value Function Update Magnitude: 0.69447
Collected Steps per Second: 13,139.76506
Overall Steps per Second: 7,221.45148
Timestep Collection Time: 3.80722
Timestep Consumption Time: 3.12019
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.92742
Cumulative Model Updates: 169,550
Cumulative Timesteps: 1,308,269,302
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71321
Policy Entropy: 4.35118
Value Function Loss: 0.00245
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.92752
Value Function Update Magnitude: 0.66986
Collected Steps per Second: 13,701.70270
Overall Steps per Second: 7,402.72450
Timestep Collection Time: 3.64918
Timestep Consumption Time: 3.10509
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.75427
Cumulative Model Updates: 169,559
Cumulative Timesteps: 1,308,319,302
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1308319302...
Checkpoint 1308319302 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18319
Policy Entropy: 4.35229
Value Function Loss: 0.00234
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.93396
Value Function Update Magnitude: 0.66318
Collected Steps per Second: 13,329.57571
Overall Steps per Second: 7,297.63982
Timestep Collection Time: 3.75166
Timestep Consumption Time: 3.10097
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.85263
Cumulative Model Updates: 169,568
Cumulative Timesteps: 1,308,369,310
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.67742
Policy Entropy: 4.34728
Value Function Loss: 0.00263
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02545
Policy Update Magnitude: 0.94483
Value Function Update Magnitude: 0.67419
Collected Steps per Second: 13,213.49951
Overall Steps per Second: 7,379.48798
Timestep Collection Time: 3.78446
Timestep Consumption Time: 2.99189
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.77635
Cumulative Model Updates: 169,577
Cumulative Timesteps: 1,308,419,316
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1308419316...
Checkpoint 1308419316 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85430
Policy Entropy: 4.34485
Value Function Loss: 0.00278
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.97676
Value Function Update Magnitude: 0.71827
Collected Steps per Second: 12,937.96728
Overall Steps per Second: 7,170.73071
Timestep Collection Time: 3.86475
Timestep Consumption Time: 3.10832
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.97307
Cumulative Model Updates: 169,586
Cumulative Timesteps: 1,308,469,318
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39370
Policy Entropy: 4.34344
Value Function Loss: 0.00282
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02834
Policy Update Magnitude: 0.98742
Value Function Update Magnitude: 0.70493
Collected Steps per Second: 13,183.45318
Overall Steps per Second: 7,119.02041
Timestep Collection Time: 3.79461
Timestep Consumption Time: 3.23249
PPO Batch Consumption Time: 0.24107
Total Iteration Time: 7.02709
Cumulative Model Updates: 169,595
Cumulative Timesteps: 1,308,519,344
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1308519344...
Checkpoint 1308519344 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.10063
Policy Entropy: 4.34857
Value Function Loss: 0.00260
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02880
Policy Update Magnitude: 0.96608
Value Function Update Magnitude: 0.65830
Collected Steps per Second: 13,690.46910
Overall Steps per Second: 7,422.72587
Timestep Collection Time: 3.65334
Timestep Consumption Time: 3.08488
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.73823
Cumulative Model Updates: 169,604
Cumulative Timesteps: 1,308,569,360
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11617
Policy Entropy: 4.34711
Value Function Loss: 0.00254
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.95793
Value Function Update Magnitude: 0.66586
Collected Steps per Second: 13,242.96418
Overall Steps per Second: 7,271.27032
Timestep Collection Time: 3.77710
Timestep Consumption Time: 3.10203
PPO Batch Consumption Time: 0.22788
Total Iteration Time: 6.87913
Cumulative Model Updates: 169,613
Cumulative Timesteps: 1,308,619,380
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1308619380...
Checkpoint 1308619380 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83267
Policy Entropy: 4.34915
Value Function Loss: 0.00246
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02503
Policy Update Magnitude: 0.95350
Value Function Update Magnitude: 0.69756
Collected Steps per Second: 13,250.38559
Overall Steps per Second: 7,321.69722
Timestep Collection Time: 3.77544
Timestep Consumption Time: 3.05713
PPO Batch Consumption Time: 0.22775
Total Iteration Time: 6.83257
Cumulative Model Updates: 169,622
Cumulative Timesteps: 1,308,669,406
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.40129
Policy Entropy: 4.34950
Value Function Loss: 0.00243
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.95982
Value Function Update Magnitude: 0.68607
Collected Steps per Second: 13,533.17240
Overall Steps per Second: 7,345.48033
Timestep Collection Time: 3.69773
Timestep Consumption Time: 3.11490
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.81262
Cumulative Model Updates: 169,631
Cumulative Timesteps: 1,308,719,448
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1308719448...
Checkpoint 1308719448 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46709
Policy Entropy: 4.35236
Value Function Loss: 0.00243
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.95077
Value Function Update Magnitude: 0.69729
Collected Steps per Second: 13,237.71071
Overall Steps per Second: 7,276.81249
Timestep Collection Time: 3.77920
Timestep Consumption Time: 3.09578
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.87499
Cumulative Model Updates: 169,640
Cumulative Timesteps: 1,308,769,476
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58715
Policy Entropy: 4.34986
Value Function Loss: 0.00245
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02707
Policy Update Magnitude: 0.93954
Value Function Update Magnitude: 0.69069
Collected Steps per Second: 13,316.92915
Overall Steps per Second: 7,387.01167
Timestep Collection Time: 3.75717
Timestep Consumption Time: 3.01607
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.77324
Cumulative Model Updates: 169,649
Cumulative Timesteps: 1,308,819,510
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1308819510...
Checkpoint 1308819510 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64605
Policy Entropy: 4.34955
Value Function Loss: 0.00258
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.93717
Value Function Update Magnitude: 0.67996
Collected Steps per Second: 13,181.92856
Overall Steps per Second: 7,236.60180
Timestep Collection Time: 3.79383
Timestep Consumption Time: 3.11687
PPO Batch Consumption Time: 0.22925
Total Iteration Time: 6.91070
Cumulative Model Updates: 169,658
Cumulative Timesteps: 1,308,869,520
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.24347
Policy Entropy: 4.35207
Value Function Loss: 0.00251
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02603
Policy Update Magnitude: 0.94674
Value Function Update Magnitude: 0.69656
Collected Steps per Second: 13,182.02383
Overall Steps per Second: 7,302.56011
Timestep Collection Time: 3.79532
Timestep Consumption Time: 3.05570
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.85102
Cumulative Model Updates: 169,667
Cumulative Timesteps: 1,308,919,550
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1308919550...
Checkpoint 1308919550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.78027
Policy Entropy: 4.35271
Value Function Loss: 0.00256
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.96432
Value Function Update Magnitude: 0.70981
Collected Steps per Second: 13,284.31149
Overall Steps per Second: 7,391.21007
Timestep Collection Time: 3.76504
Timestep Consumption Time: 3.00191
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.76696
Cumulative Model Updates: 169,676
Cumulative Timesteps: 1,308,969,566
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.88290
Policy Entropy: 4.35509
Value Function Loss: 0.00237
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.94499
Value Function Update Magnitude: 0.69894
Collected Steps per Second: 13,293.11975
Overall Steps per Second: 7,285.32237
Timestep Collection Time: 3.76390
Timestep Consumption Time: 3.10388
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.86778
Cumulative Model Updates: 169,685
Cumulative Timesteps: 1,309,019,600
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1309019600...
Checkpoint 1309019600 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.94416
Policy Entropy: 4.35421
Value Function Loss: 0.00234
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.92450
Value Function Update Magnitude: 0.74310
Collected Steps per Second: 13,236.30203
Overall Steps per Second: 7,302.39936
Timestep Collection Time: 3.78081
Timestep Consumption Time: 3.07228
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.85309
Cumulative Model Updates: 169,694
Cumulative Timesteps: 1,309,069,644
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99661
Policy Entropy: 4.35321
Value Function Loss: 0.00229
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02246
Policy Update Magnitude: 0.92281
Value Function Update Magnitude: 0.73123
Collected Steps per Second: 13,546.39042
Overall Steps per Second: 7,359.33568
Timestep Collection Time: 3.69264
Timestep Consumption Time: 3.10444
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.79708
Cumulative Model Updates: 169,703
Cumulative Timesteps: 1,309,119,666
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1309119666...
Checkpoint 1309119666 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37194
Policy Entropy: 4.35449
Value Function Loss: 0.00231
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.93646
Value Function Update Magnitude: 0.72535
Collected Steps per Second: 13,285.02124
Overall Steps per Second: 7,236.38538
Timestep Collection Time: 3.76665
Timestep Consumption Time: 3.14841
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.91505
Cumulative Model Updates: 169,712
Cumulative Timesteps: 1,309,169,706
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65087
Policy Entropy: 4.35065
Value Function Loss: 0.00245
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.95758
Value Function Update Magnitude: 0.69501
Collected Steps per Second: 13,182.98638
Overall Steps per Second: 7,138.11866
Timestep Collection Time: 3.79383
Timestep Consumption Time: 3.21278
PPO Batch Consumption Time: 0.23929
Total Iteration Time: 7.00661
Cumulative Model Updates: 169,721
Cumulative Timesteps: 1,309,219,720
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1309219720...
Checkpoint 1309219720 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.19317
Policy Entropy: 4.35107
Value Function Loss: 0.00244
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.96316
Value Function Update Magnitude: 0.68758
Collected Steps per Second: 13,457.37911
Overall Steps per Second: 7,324.84842
Timestep Collection Time: 3.71707
Timestep Consumption Time: 3.11201
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.82908
Cumulative Model Updates: 169,730
Cumulative Timesteps: 1,309,269,742
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.27035
Policy Entropy: 4.35033
Value Function Loss: 0.00249
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02646
Policy Update Magnitude: 0.96401
Value Function Update Magnitude: 0.69668
Collected Steps per Second: 13,155.89850
Overall Steps per Second: 7,233.30999
Timestep Collection Time: 3.80058
Timestep Consumption Time: 3.11189
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.91246
Cumulative Model Updates: 169,739
Cumulative Timesteps: 1,309,319,742
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1309319742...
Checkpoint 1309319742 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05544
Policy Entropy: 4.35045
Value Function Loss: 0.00243
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.96953
Value Function Update Magnitude: 0.70620
Collected Steps per Second: 13,203.23554
Overall Steps per Second: 7,350.95491
Timestep Collection Time: 3.78862
Timestep Consumption Time: 3.01621
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.80483
Cumulative Model Updates: 169,748
Cumulative Timesteps: 1,309,369,764
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.45560
Policy Entropy: 4.34709
Value Function Loss: 0.00257
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.98513
Value Function Update Magnitude: 0.72644
Collected Steps per Second: 13,449.30775
Overall Steps per Second: 7,332.74883
Timestep Collection Time: 3.71856
Timestep Consumption Time: 3.10181
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.82036
Cumulative Model Updates: 169,757
Cumulative Timesteps: 1,309,419,776
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1309419776...
Checkpoint 1309419776 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.37569
Policy Entropy: 4.34645
Value Function Loss: 0.00270
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02626
Policy Update Magnitude: 0.97545
Value Function Update Magnitude: 0.71381
Collected Steps per Second: 13,130.28890
Overall Steps per Second: 7,268.08895
Timestep Collection Time: 3.81088
Timestep Consumption Time: 3.07373
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.88462
Cumulative Model Updates: 169,766
Cumulative Timesteps: 1,309,469,814
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22611
Policy Entropy: 4.34880
Value Function Loss: 0.00264
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02730
Policy Update Magnitude: 0.96796
Value Function Update Magnitude: 0.70632
Collected Steps per Second: 13,613.23468
Overall Steps per Second: 7,378.59858
Timestep Collection Time: 3.67334
Timestep Consumption Time: 3.10383
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.77717
Cumulative Model Updates: 169,775
Cumulative Timesteps: 1,309,519,820
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1309519820...
Checkpoint 1309519820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.67262
Policy Entropy: 4.34970
Value Function Loss: 0.00248
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02745
Policy Update Magnitude: 0.94910
Value Function Update Magnitude: 0.71252
Collected Steps per Second: 13,258.80145
Overall Steps per Second: 7,237.40146
Timestep Collection Time: 3.77168
Timestep Consumption Time: 3.13798
PPO Batch Consumption Time: 0.22937
Total Iteration Time: 6.90966
Cumulative Model Updates: 169,784
Cumulative Timesteps: 1,309,569,828
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.36439
Policy Entropy: 4.35048
Value Function Loss: 0.00225
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02873
Policy Update Magnitude: 0.94285
Value Function Update Magnitude: 0.69445
Collected Steps per Second: 13,097.60129
Overall Steps per Second: 7,242.43368
Timestep Collection Time: 3.81963
Timestep Consumption Time: 3.08799
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.90762
Cumulative Model Updates: 169,793
Cumulative Timesteps: 1,309,619,856
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1309619856...
Checkpoint 1309619856 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49555
Policy Entropy: 4.35447
Value Function Loss: 0.00226
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02799
Policy Update Magnitude: 0.94633
Value Function Update Magnitude: 0.70668
Collected Steps per Second: 13,527.89952
Overall Steps per Second: 7,359.64462
Timestep Collection Time: 3.69607
Timestep Consumption Time: 3.09774
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.79381
Cumulative Model Updates: 169,802
Cumulative Timesteps: 1,309,669,856
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83282
Policy Entropy: 4.35688
Value Function Loss: 0.00216
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.91624
Value Function Update Magnitude: 0.66294
Collected Steps per Second: 13,270.54891
Overall Steps per Second: 7,263.24210
Timestep Collection Time: 3.76834
Timestep Consumption Time: 3.11674
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.88508
Cumulative Model Updates: 169,811
Cumulative Timesteps: 1,309,719,864
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1309719864...
Checkpoint 1309719864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92516
Policy Entropy: 4.35601
Value Function Loss: 0.00241
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.93670
Value Function Update Magnitude: 0.71546
Collected Steps per Second: 13,255.77069
Overall Steps per Second: 7,399.41286
Timestep Collection Time: 3.77556
Timestep Consumption Time: 2.98822
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.76378
Cumulative Model Updates: 169,820
Cumulative Timesteps: 1,309,769,912
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81081
Policy Entropy: 4.35125
Value Function Loss: 0.00256
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02691
Policy Update Magnitude: 0.98126
Value Function Update Magnitude: 0.78210
Collected Steps per Second: 13,214.30197
Overall Steps per Second: 7,226.90849
Timestep Collection Time: 3.78665
Timestep Consumption Time: 3.13719
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.92385
Cumulative Model Updates: 169,829
Cumulative Timesteps: 1,309,819,950
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1309819950...
Checkpoint 1309819950 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82266
Policy Entropy: 4.35466
Value Function Loss: 0.00252
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02826
Policy Update Magnitude: 0.98950
Value Function Update Magnitude: 0.73408
Collected Steps per Second: 13,152.23338
Overall Steps per Second: 7,261.09096
Timestep Collection Time: 3.80209
Timestep Consumption Time: 3.08475
PPO Batch Consumption Time: 0.22938
Total Iteration Time: 6.88684
Cumulative Model Updates: 169,838
Cumulative Timesteps: 1,309,869,956
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.39367
Policy Entropy: 4.35039
Value Function Loss: 0.00268
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 1.01415
Value Function Update Magnitude: 0.71978
Collected Steps per Second: 13,208.56668
Overall Steps per Second: 7,124.85448
Timestep Collection Time: 3.78557
Timestep Consumption Time: 3.23239
PPO Batch Consumption Time: 0.24528
Total Iteration Time: 7.01797
Cumulative Model Updates: 169,847
Cumulative Timesteps: 1,309,919,958
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1309919958...
Checkpoint 1309919958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.46490
Policy Entropy: 4.35259
Value Function Loss: 0.00275
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02856
Policy Update Magnitude: 1.01503
Value Function Update Magnitude: 0.72949
Collected Steps per Second: 13,095.05399
Overall Steps per Second: 7,251.44696
Timestep Collection Time: 3.82083
Timestep Consumption Time: 3.07903
PPO Batch Consumption Time: 0.22774
Total Iteration Time: 6.89986
Cumulative Model Updates: 169,856
Cumulative Timesteps: 1,309,969,992
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66834
Policy Entropy: 4.34635
Value Function Loss: 0.00281
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03202
Policy Update Magnitude: 1.02701
Value Function Update Magnitude: 0.71793
Collected Steps per Second: 13,412.77690
Overall Steps per Second: 7,346.00255
Timestep Collection Time: 3.72988
Timestep Consumption Time: 3.08036
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 6.81023
Cumulative Model Updates: 169,865
Cumulative Timesteps: 1,310,020,020
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1310020020...
Checkpoint 1310020020 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22346
Policy Entropy: 4.34920
Value Function Loss: 0.00277
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02846
Policy Update Magnitude: 1.02949
Value Function Update Magnitude: 0.69886
Collected Steps per Second: 13,454.32274
Overall Steps per Second: 7,350.75737
Timestep Collection Time: 3.71851
Timestep Consumption Time: 3.08759
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.80610
Cumulative Model Updates: 169,874
Cumulative Timesteps: 1,310,070,050
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.38624
Policy Entropy: 4.34968
Value Function Loss: 0.00255
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 1.00852
Value Function Update Magnitude: 0.72498
Collected Steps per Second: 13,267.94247
Overall Steps per Second: 7,252.44683
Timestep Collection Time: 3.76878
Timestep Consumption Time: 3.12599
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.89478
Cumulative Model Updates: 169,883
Cumulative Timesteps: 1,310,120,054
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1310120054...
Checkpoint 1310120054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02290
Policy Entropy: 4.34896
Value Function Loss: 0.00254
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02898
Policy Update Magnitude: 0.98176
Value Function Update Magnitude: 0.72929
Collected Steps per Second: 13,240.26049
Overall Steps per Second: 7,374.42688
Timestep Collection Time: 3.77817
Timestep Consumption Time: 3.00527
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.78344
Cumulative Model Updates: 169,892
Cumulative Timesteps: 1,310,170,078
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.10156
Policy Entropy: 4.34831
Value Function Loss: 0.00253
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.97305
Value Function Update Magnitude: 0.72964
Collected Steps per Second: 13,347.92724
Overall Steps per Second: 7,290.95160
Timestep Collection Time: 3.74860
Timestep Consumption Time: 3.11416
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.86275
Cumulative Model Updates: 169,901
Cumulative Timesteps: 1,310,220,114
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1310220114...
Checkpoint 1310220114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.75195
Policy Entropy: 4.35011
Value Function Loss: 0.00246
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.95871
Value Function Update Magnitude: 0.71276
Collected Steps per Second: 13,275.98841
Overall Steps per Second: 7,216.79941
Timestep Collection Time: 3.76801
Timestep Consumption Time: 3.16360
PPO Batch Consumption Time: 0.23664
Total Iteration Time: 6.93160
Cumulative Model Updates: 169,910
Cumulative Timesteps: 1,310,270,138
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75125
Policy Entropy: 4.35066
Value Function Loss: 0.00242
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.95303
Value Function Update Magnitude: 0.71432
Collected Steps per Second: 13,254.53849
Overall Steps per Second: 7,364.07346
Timestep Collection Time: 3.77395
Timestep Consumption Time: 3.01876
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.79271
Cumulative Model Updates: 169,919
Cumulative Timesteps: 1,310,320,160
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1310320160...
Checkpoint 1310320160 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51231
Policy Entropy: 4.34979
Value Function Loss: 0.00232
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02819
Policy Update Magnitude: 0.94916
Value Function Update Magnitude: 0.69953
Collected Steps per Second: 13,142.89678
Overall Steps per Second: 7,231.27853
Timestep Collection Time: 3.80692
Timestep Consumption Time: 3.11219
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.91911
Cumulative Model Updates: 169,928
Cumulative Timesteps: 1,310,370,194
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.46251
Policy Entropy: 4.34898
Value Function Loss: 0.00235
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02908
Policy Update Magnitude: 0.94031
Value Function Update Magnitude: 0.70139
Collected Steps per Second: 13,336.15958
Overall Steps per Second: 7,326.52831
Timestep Collection Time: 3.75055
Timestep Consumption Time: 3.07642
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.82697
Cumulative Model Updates: 169,937
Cumulative Timesteps: 1,310,420,212
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1310420212...
Checkpoint 1310420212 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95674
Policy Entropy: 4.34979
Value Function Loss: 0.00233
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.92519
Value Function Update Magnitude: 0.70099
Collected Steps per Second: 13,338.60939
Overall Steps per Second: 7,289.24474
Timestep Collection Time: 3.74927
Timestep Consumption Time: 3.11153
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.86079
Cumulative Model Updates: 169,946
Cumulative Timesteps: 1,310,470,222
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.15147
Policy Entropy: 4.35358
Value Function Loss: 0.00233
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.92145
Value Function Update Magnitude: 0.73226
Collected Steps per Second: 13,234.47800
Overall Steps per Second: 7,267.87841
Timestep Collection Time: 3.77846
Timestep Consumption Time: 3.10195
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.88041
Cumulative Model Updates: 169,955
Cumulative Timesteps: 1,310,520,228
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1310520228...
Checkpoint 1310520228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.21670
Policy Entropy: 4.35240
Value Function Loss: 0.00241
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.94020
Value Function Update Magnitude: 0.74032
Collected Steps per Second: 13,181.28466
Overall Steps per Second: 7,372.40351
Timestep Collection Time: 3.79538
Timestep Consumption Time: 2.99047
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.78585
Cumulative Model Updates: 169,964
Cumulative Timesteps: 1,310,570,256
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.79477
Policy Entropy: 4.35152
Value Function Loss: 0.00250
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.94886
Value Function Update Magnitude: 0.75835
Collected Steps per Second: 13,299.34812
Overall Steps per Second: 7,056.86924
Timestep Collection Time: 3.76018
Timestep Consumption Time: 3.32624
PPO Batch Consumption Time: 0.24486
Total Iteration Time: 7.08643
Cumulative Model Updates: 169,973
Cumulative Timesteps: 1,310,620,264
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1310620264...
Checkpoint 1310620264 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46683
Policy Entropy: 4.35072
Value Function Loss: 0.00252
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.94878
Value Function Update Magnitude: 0.75668
Collected Steps per Second: 13,210.89309
Overall Steps per Second: 7,288.60488
Timestep Collection Time: 3.78597
Timestep Consumption Time: 3.07625
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.86222
Cumulative Model Updates: 169,982
Cumulative Timesteps: 1,310,670,280
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53882
Policy Entropy: 4.35416
Value Function Loss: 0.00256
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.97253
Value Function Update Magnitude: 0.75252
Collected Steps per Second: 13,562.67645
Overall Steps per Second: 7,367.01944
Timestep Collection Time: 3.68733
Timestep Consumption Time: 3.10104
PPO Batch Consumption Time: 0.22743
Total Iteration Time: 6.78836
Cumulative Model Updates: 169,991
Cumulative Timesteps: 1,310,720,290
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1310720290...
Checkpoint 1310720290 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98258
Policy Entropy: 4.35002
Value Function Loss: 0.00254
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02708
Policy Update Magnitude: 0.97261
Value Function Update Magnitude: 0.73336
Collected Steps per Second: 13,212.60806
Overall Steps per Second: 7,269.64070
Timestep Collection Time: 3.78593
Timestep Consumption Time: 3.09502
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.88095
Cumulative Model Updates: 170,000
Cumulative Timesteps: 1,310,770,312
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33828
Policy Entropy: 4.35313
Value Function Loss: 0.00244
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02748
Policy Update Magnitude: 0.94577
Value Function Update Magnitude: 0.73722
Collected Steps per Second: 12,926.68764
Overall Steps per Second: 7,210.66701
Timestep Collection Time: 3.86874
Timestep Consumption Time: 3.06682
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.93556
Cumulative Model Updates: 170,009
Cumulative Timesteps: 1,310,820,322
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1310820322...
Checkpoint 1310820322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96729
Policy Entropy: 4.35501
Value Function Loss: 0.00228
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02617
Policy Update Magnitude: 0.93101
Value Function Update Magnitude: 0.72937
Collected Steps per Second: 13,512.94204
Overall Steps per Second: 7,343.28999
Timestep Collection Time: 3.70312
Timestep Consumption Time: 3.11127
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.81438
Cumulative Model Updates: 170,018
Cumulative Timesteps: 1,310,870,362
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39700
Policy Entropy: 4.35725
Value Function Loss: 0.00211
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.91253
Value Function Update Magnitude: 0.72176
Collected Steps per Second: 13,324.81076
Overall Steps per Second: 7,265.18825
Timestep Collection Time: 3.75270
Timestep Consumption Time: 3.12999
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.88268
Cumulative Model Updates: 170,027
Cumulative Timesteps: 1,310,920,366
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1310920366...
Checkpoint 1310920366 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88681
Policy Entropy: 4.35744
Value Function Loss: 0.00217
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.90792
Value Function Update Magnitude: 0.71380
Collected Steps per Second: 13,029.99839
Overall Steps per Second: 7,052.92772
Timestep Collection Time: 3.83761
Timestep Consumption Time: 3.25222
PPO Batch Consumption Time: 0.24366
Total Iteration Time: 7.08982
Cumulative Model Updates: 170,036
Cumulative Timesteps: 1,310,970,370
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05241
Policy Entropy: 4.35429
Value Function Loss: 0.00225
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.94438
Value Function Update Magnitude: 0.69473
Collected Steps per Second: 13,492.28042
Overall Steps per Second: 7,319.25219
Timestep Collection Time: 3.70731
Timestep Consumption Time: 3.12673
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.83403
Cumulative Model Updates: 170,045
Cumulative Timesteps: 1,311,020,390
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1311020390...
Checkpoint 1311020390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.59014
Policy Entropy: 4.35429
Value Function Loss: 0.00241
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.94023
Value Function Update Magnitude: 0.71269
Collected Steps per Second: 13,312.33254
Overall Steps per Second: 7,282.42906
Timestep Collection Time: 3.75637
Timestep Consumption Time: 3.11030
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.86666
Cumulative Model Updates: 170,054
Cumulative Timesteps: 1,311,070,396
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09353
Policy Entropy: 4.35031
Value Function Loss: 0.00260
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.97763
Value Function Update Magnitude: 0.67768
Collected Steps per Second: 13,332.79886
Overall Steps per Second: 7,417.59066
Timestep Collection Time: 3.75195
Timestep Consumption Time: 2.99202
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.74397
Cumulative Model Updates: 170,063
Cumulative Timesteps: 1,311,120,420
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1311120420...
Checkpoint 1311120420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02939
Policy Entropy: 4.34956
Value Function Loss: 0.00268
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.99651
Value Function Update Magnitude: 0.68233
Collected Steps per Second: 13,168.21826
Overall Steps per Second: 7,251.30314
Timestep Collection Time: 3.80021
Timestep Consumption Time: 3.10089
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.90110
Cumulative Model Updates: 170,072
Cumulative Timesteps: 1,311,170,462
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57800
Policy Entropy: 4.34867
Value Function Loss: 0.00251
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.96235
Value Function Update Magnitude: 0.68669
Collected Steps per Second: 13,156.13363
Overall Steps per Second: 7,283.17687
Timestep Collection Time: 3.80218
Timestep Consumption Time: 3.06598
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.86816
Cumulative Model Updates: 170,081
Cumulative Timesteps: 1,311,220,484
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1311220484...
Checkpoint 1311220484 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.80271
Policy Entropy: 4.35032
Value Function Loss: 0.00241
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.95838
Value Function Update Magnitude: 0.70410
Collected Steps per Second: 13,076.39572
Overall Steps per Second: 7,344.27233
Timestep Collection Time: 3.82430
Timestep Consumption Time: 2.98482
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.80912
Cumulative Model Updates: 170,090
Cumulative Timesteps: 1,311,270,492
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.39390
Policy Entropy: 4.34926
Value Function Loss: 0.00241
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.97365
Value Function Update Magnitude: 0.69919
Collected Steps per Second: 13,347.83206
Overall Steps per Second: 7,165.49398
Timestep Collection Time: 3.74608
Timestep Consumption Time: 3.23209
PPO Batch Consumption Time: 0.23763
Total Iteration Time: 6.97817
Cumulative Model Updates: 170,099
Cumulative Timesteps: 1,311,320,494
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1311320494...
Checkpoint 1311320494 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.08879
Policy Entropy: 4.34913
Value Function Loss: 0.00254
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.96723
Value Function Update Magnitude: 0.68431
Collected Steps per Second: 13,196.01310
Overall Steps per Second: 7,227.81842
Timestep Collection Time: 3.78948
Timestep Consumption Time: 3.12907
PPO Batch Consumption Time: 0.22768
Total Iteration Time: 6.91855
Cumulative Model Updates: 170,108
Cumulative Timesteps: 1,311,370,500
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.91346
Policy Entropy: 4.35072
Value Function Loss: 0.00241
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02804
Policy Update Magnitude: 0.98828
Value Function Update Magnitude: 0.68499
Collected Steps per Second: 13,461.71320
Overall Steps per Second: 7,329.63939
Timestep Collection Time: 3.71424
Timestep Consumption Time: 3.10738
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.82162
Cumulative Model Updates: 170,117
Cumulative Timesteps: 1,311,420,500
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1311420500...
Checkpoint 1311420500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02987
Policy Entropy: 4.35357
Value Function Loss: 0.00248
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02826
Policy Update Magnitude: 0.99196
Value Function Update Magnitude: 0.72395
Collected Steps per Second: 13,139.07078
Overall Steps per Second: 7,229.87864
Timestep Collection Time: 3.80590
Timestep Consumption Time: 3.11067
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.91658
Cumulative Model Updates: 170,126
Cumulative Timesteps: 1,311,470,506
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86038
Policy Entropy: 4.35108
Value Function Loss: 0.00244
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.98853
Value Function Update Magnitude: 0.78766
Collected Steps per Second: 13,399.59002
Overall Steps per Second: 7,414.07089
Timestep Collection Time: 3.73235
Timestep Consumption Time: 3.01320
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.74555
Cumulative Model Updates: 170,135
Cumulative Timesteps: 1,311,520,518
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1311520518...
Checkpoint 1311520518 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.55758
Policy Entropy: 4.35210
Value Function Loss: 0.00250
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02968
Policy Update Magnitude: 0.97358
Value Function Update Magnitude: 0.74553
Collected Steps per Second: 13,226.76614
Overall Steps per Second: 7,233.19064
Timestep Collection Time: 3.78188
Timestep Consumption Time: 3.13374
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.91562
Cumulative Model Updates: 170,144
Cumulative Timesteps: 1,311,570,540
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97492
Policy Entropy: 4.35070
Value Function Loss: 0.00251
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.98191
Value Function Update Magnitude: 0.73634
Collected Steps per Second: 13,267.05394
Overall Steps per Second: 7,294.33381
Timestep Collection Time: 3.77054
Timestep Consumption Time: 3.08738
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.85793
Cumulative Model Updates: 170,153
Cumulative Timesteps: 1,311,620,564
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1311620564...
Checkpoint 1311620564 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.97372
Policy Entropy: 4.34955
Value Function Loss: 0.00241
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.97243
Value Function Update Magnitude: 0.73803
Collected Steps per Second: 13,331.34434
Overall Steps per Second: 7,338.85803
Timestep Collection Time: 3.75131
Timestep Consumption Time: 3.06310
PPO Batch Consumption Time: 0.23379
Total Iteration Time: 6.81441
Cumulative Model Updates: 170,162
Cumulative Timesteps: 1,311,670,574
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64909
Policy Entropy: 4.35152
Value Function Loss: 0.00235
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.97553
Value Function Update Magnitude: 0.67747
Collected Steps per Second: 13,292.37548
Overall Steps per Second: 7,281.88964
Timestep Collection Time: 3.76351
Timestep Consumption Time: 3.10641
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.86992
Cumulative Model Updates: 170,171
Cumulative Timesteps: 1,311,720,600
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1311720600...
Checkpoint 1311720600 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10313
Policy Entropy: 4.34856
Value Function Loss: 0.00233
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02830
Policy Update Magnitude: 0.95673
Value Function Update Magnitude: 0.66858
Collected Steps per Second: 12,883.68425
Overall Steps per Second: 7,186.78723
Timestep Collection Time: 3.88321
Timestep Consumption Time: 3.07818
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.96139
Cumulative Model Updates: 170,180
Cumulative Timesteps: 1,311,770,630
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.12336
Policy Entropy: 4.35106
Value Function Loss: 0.00251
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02857
Policy Update Magnitude: 0.95264
Value Function Update Magnitude: 0.69742
Collected Steps per Second: 13,320.07027
Overall Steps per Second: 7,292.72477
Timestep Collection Time: 3.75388
Timestep Consumption Time: 3.10254
PPO Batch Consumption Time: 0.22771
Total Iteration Time: 6.85642
Cumulative Model Updates: 170,189
Cumulative Timesteps: 1,311,820,632
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1311820632...
Checkpoint 1311820632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.96520
Policy Entropy: 4.34579
Value Function Loss: 0.00255
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02841
Policy Update Magnitude: 0.97591
Value Function Update Magnitude: 0.68629
Collected Steps per Second: 13,310.44734
Overall Steps per Second: 7,276.10395
Timestep Collection Time: 3.75735
Timestep Consumption Time: 3.11611
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.87346
Cumulative Model Updates: 170,198
Cumulative Timesteps: 1,311,870,644
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73653
Policy Entropy: 4.35058
Value Function Loss: 0.00237
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.95910
Value Function Update Magnitude: 0.68306
Collected Steps per Second: 13,107.40560
Overall Steps per Second: 7,328.39719
Timestep Collection Time: 3.81601
Timestep Consumption Time: 3.00922
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.82523
Cumulative Model Updates: 170,207
Cumulative Timesteps: 1,311,920,662
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1311920662...
Checkpoint 1311920662 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.36558
Policy Entropy: 4.34984
Value Function Loss: 0.00242
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.95072
Value Function Update Magnitude: 0.70454
Collected Steps per Second: 13,233.73944
Overall Steps per Second: 7,243.42123
Timestep Collection Time: 3.77883
Timestep Consumption Time: 3.12509
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.90392
Cumulative Model Updates: 170,216
Cumulative Timesteps: 1,311,970,670
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.91316
Policy Entropy: 4.35469
Value Function Loss: 0.00223
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.95464
Value Function Update Magnitude: 0.69443
Collected Steps per Second: 13,186.39093
Overall Steps per Second: 7,130.29767
Timestep Collection Time: 3.79330
Timestep Consumption Time: 3.22183
PPO Batch Consumption Time: 0.24066
Total Iteration Time: 7.01513
Cumulative Model Updates: 170,225
Cumulative Timesteps: 1,312,020,690
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1312020690...
Checkpoint 1312020690 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.23676
Policy Entropy: 4.35268
Value Function Loss: 0.00255
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.96387
Value Function Update Magnitude: 0.72494
Collected Steps per Second: 13,537.24277
Overall Steps per Second: 7,366.71692
Timestep Collection Time: 3.69381
Timestep Consumption Time: 3.09402
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.78783
Cumulative Model Updates: 170,234
Cumulative Timesteps: 1,312,070,694
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.45103
Policy Entropy: 4.35248
Value Function Loss: 0.00245
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02938
Policy Update Magnitude: 0.97100
Value Function Update Magnitude: 0.77373
Collected Steps per Second: 13,353.81391
Overall Steps per Second: 7,304.64445
Timestep Collection Time: 3.74709
Timestep Consumption Time: 3.10307
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.85016
Cumulative Model Updates: 170,243
Cumulative Timesteps: 1,312,120,732
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1312120732...
Checkpoint 1312120732 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84408
Policy Entropy: 4.35016
Value Function Loss: 0.00252
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03015
Policy Update Magnitude: 0.95332
Value Function Update Magnitude: 0.72364
Collected Steps per Second: 13,218.34653
Overall Steps per Second: 7,317.78497
Timestep Collection Time: 3.78368
Timestep Consumption Time: 3.05090
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.83458
Cumulative Model Updates: 170,252
Cumulative Timesteps: 1,312,170,746
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.79157
Policy Entropy: 4.35069
Value Function Loss: 0.00254
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02965
Policy Update Magnitude: 0.96042
Value Function Update Magnitude: 0.69815
Collected Steps per Second: 13,568.35872
Overall Steps per Second: 7,376.47411
Timestep Collection Time: 3.68652
Timestep Consumption Time: 3.09450
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.78102
Cumulative Model Updates: 170,261
Cumulative Timesteps: 1,312,220,766
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1312220766...
Checkpoint 1312220766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73192
Policy Entropy: 4.34878
Value Function Loss: 0.00267
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.97283
Value Function Update Magnitude: 0.69993
Collected Steps per Second: 13,103.22367
Overall Steps per Second: 7,221.60282
Timestep Collection Time: 3.81906
Timestep Consumption Time: 3.11043
PPO Batch Consumption Time: 0.22942
Total Iteration Time: 6.92949
Cumulative Model Updates: 170,270
Cumulative Timesteps: 1,312,270,808
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41465
Policy Entropy: 4.34861
Value Function Loss: 0.00258
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02980
Policy Update Magnitude: 0.96619
Value Function Update Magnitude: 0.67960
Collected Steps per Second: 13,280.17794
Overall Steps per Second: 7,386.55393
Timestep Collection Time: 3.76772
Timestep Consumption Time: 3.00621
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.77393
Cumulative Model Updates: 170,279
Cumulative Timesteps: 1,312,320,844
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1312320844...
Checkpoint 1312320844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62890
Policy Entropy: 4.34819
Value Function Loss: 0.00270
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02883
Policy Update Magnitude: 0.96385
Value Function Update Magnitude: 0.72565
Collected Steps per Second: 13,140.18597
Overall Steps per Second: 7,062.33101
Timestep Collection Time: 3.80558
Timestep Consumption Time: 3.27509
PPO Batch Consumption Time: 0.24250
Total Iteration Time: 7.08066
Cumulative Model Updates: 170,288
Cumulative Timesteps: 1,312,370,850
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.01972
Policy Entropy: 4.34992
Value Function Loss: 0.00252
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.96549
Value Function Update Magnitude: 0.74936
Collected Steps per Second: 13,419.79644
Overall Steps per Second: 7,362.89218
Timestep Collection Time: 3.72882
Timestep Consumption Time: 3.06742
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.79624
Cumulative Model Updates: 170,297
Cumulative Timesteps: 1,312,420,890
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1312420890...
Checkpoint 1312420890 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05354
Policy Entropy: 4.35158
Value Function Loss: 0.00247
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02856
Policy Update Magnitude: 0.97601
Value Function Update Magnitude: 0.73491
Collected Steps per Second: 13,270.15692
Overall Steps per Second: 7,384.93501
Timestep Collection Time: 3.76936
Timestep Consumption Time: 3.00389
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.77325
Cumulative Model Updates: 170,306
Cumulative Timesteps: 1,312,470,910
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28350
Policy Entropy: 4.35208
Value Function Loss: 0.00243
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.96193
Value Function Update Magnitude: 0.72309
Collected Steps per Second: 13,341.95984
Overall Steps per Second: 7,284.07396
Timestep Collection Time: 3.74937
Timestep Consumption Time: 3.11821
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.86759
Cumulative Model Updates: 170,315
Cumulative Timesteps: 1,312,520,934
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1312520934...
Checkpoint 1312520934 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.15994
Policy Entropy: 4.35128
Value Function Loss: 0.00252
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.96194
Value Function Update Magnitude: 0.67960
Collected Steps per Second: 12,912.07139
Overall Steps per Second: 7,179.76286
Timestep Collection Time: 3.87436
Timestep Consumption Time: 3.09328
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.96764
Cumulative Model Updates: 170,324
Cumulative Timesteps: 1,312,570,960
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11468
Policy Entropy: 4.34542
Value Function Loss: 0.00270
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03095
Policy Update Magnitude: 0.96688
Value Function Update Magnitude: 0.63549
Collected Steps per Second: 13,534.69055
Overall Steps per Second: 7,344.07390
Timestep Collection Time: 3.69702
Timestep Consumption Time: 3.11637
PPO Batch Consumption Time: 0.22791
Total Iteration Time: 6.81338
Cumulative Model Updates: 170,333
Cumulative Timesteps: 1,312,620,998
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1312620998...
Checkpoint 1312620998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31830
Policy Entropy: 4.34883
Value Function Loss: 0.00266
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03057
Policy Update Magnitude: 0.95504
Value Function Update Magnitude: 0.65969
Collected Steps per Second: 13,175.53974
Overall Steps per Second: 7,223.42162
Timestep Collection Time: 3.79688
Timestep Consumption Time: 3.12864
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.92553
Cumulative Model Updates: 170,342
Cumulative Timesteps: 1,312,671,024
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.85011
Policy Entropy: 4.35272
Value Function Loss: 0.00257
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.93973
Value Function Update Magnitude: 0.69168
Collected Steps per Second: 13,105.80992
Overall Steps per Second: 7,123.24372
Timestep Collection Time: 3.81602
Timestep Consumption Time: 3.20494
PPO Batch Consumption Time: 0.23806
Total Iteration Time: 7.02096
Cumulative Model Updates: 170,351
Cumulative Timesteps: 1,312,721,036
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1312721036...
Checkpoint 1312721036 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04474
Policy Entropy: 4.35460
Value Function Loss: 0.00247
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.92808
Value Function Update Magnitude: 0.71371
Collected Steps per Second: 13,616.78208
Overall Steps per Second: 7,381.89775
Timestep Collection Time: 3.67326
Timestep Consumption Time: 3.10250
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.77576
Cumulative Model Updates: 170,360
Cumulative Timesteps: 1,312,771,054
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75969
Policy Entropy: 4.35323
Value Function Loss: 0.00247
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02566
Policy Update Magnitude: 0.95210
Value Function Update Magnitude: 0.72239
Collected Steps per Second: 13,311.59399
Overall Steps per Second: 7,292.04037
Timestep Collection Time: 3.75688
Timestep Consumption Time: 3.10129
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.85816
Cumulative Model Updates: 170,369
Cumulative Timesteps: 1,312,821,064
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1312821064...
Checkpoint 1312821064 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.29297
Policy Entropy: 4.34945
Value Function Loss: 0.00251
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.95741
Value Function Update Magnitude: 0.71854
Collected Steps per Second: 13,259.11538
Overall Steps per Second: 7,375.99876
Timestep Collection Time: 3.77159
Timestep Consumption Time: 3.00823
PPO Batch Consumption Time: 0.22770
Total Iteration Time: 6.77983
Cumulative Model Updates: 170,378
Cumulative Timesteps: 1,312,871,072
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89478
Policy Entropy: 4.35132
Value Function Loss: 0.00250
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.95613
Value Function Update Magnitude: 0.69047
Collected Steps per Second: 13,325.97460
Overall Steps per Second: 7,286.80808
Timestep Collection Time: 3.75282
Timestep Consumption Time: 3.11027
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.86309
Cumulative Model Updates: 170,387
Cumulative Timesteps: 1,312,921,082
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1312921082...
Checkpoint 1312921082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.90931
Policy Entropy: 4.34859
Value Function Loss: 0.00262
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.95804
Value Function Update Magnitude: 0.63638
Collected Steps per Second: 13,020.60317
Overall Steps per Second: 7,248.89274
Timestep Collection Time: 3.84130
Timestep Consumption Time: 3.05852
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.89981
Cumulative Model Updates: 170,396
Cumulative Timesteps: 1,312,971,098
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41378
Policy Entropy: 4.35114
Value Function Loss: 0.00248
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02949
Policy Update Magnitude: 0.92521
Value Function Update Magnitude: 0.63453
Collected Steps per Second: 13,061.57364
Overall Steps per Second: 7,289.98416
Timestep Collection Time: 3.82971
Timestep Consumption Time: 3.03204
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.86174
Cumulative Model Updates: 170,405
Cumulative Timesteps: 1,313,021,120
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1313021120...
Checkpoint 1313021120 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75595
Policy Entropy: 4.35421
Value Function Loss: 0.00250
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.91107
Value Function Update Magnitude: 0.66052
Collected Steps per Second: 13,263.39850
Overall Steps per Second: 7,251.21633
Timestep Collection Time: 3.77279
Timestep Consumption Time: 3.12812
PPO Batch Consumption Time: 0.22967
Total Iteration Time: 6.90091
Cumulative Model Updates: 170,414
Cumulative Timesteps: 1,313,071,160
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20465
Policy Entropy: 4.35187
Value Function Loss: 0.00245
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.93143
Value Function Update Magnitude: 0.69370
Collected Steps per Second: 13,287.16470
Overall Steps per Second: 7,318.35123
Timestep Collection Time: 3.76484
Timestep Consumption Time: 3.07058
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.83542
Cumulative Model Updates: 170,423
Cumulative Timesteps: 1,313,121,184
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1313121184...
Checkpoint 1313121184 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05783
Policy Entropy: 4.34968
Value Function Loss: 0.00250
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.92734
Value Function Update Magnitude: 0.66036
Collected Steps per Second: 13,578.71137
Overall Steps per Second: 7,372.83543
Timestep Collection Time: 3.68415
Timestep Consumption Time: 3.10103
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.78518
Cumulative Model Updates: 170,432
Cumulative Timesteps: 1,313,171,210
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.10869
Policy Entropy: 4.34767
Value Function Loss: 0.00242
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.92930
Value Function Update Magnitude: 0.63833
Collected Steps per Second: 13,258.80441
Overall Steps per Second: 7,260.84889
Timestep Collection Time: 3.77183
Timestep Consumption Time: 3.11579
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.88762
Cumulative Model Updates: 170,441
Cumulative Timesteps: 1,313,221,220
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1313221220...
Checkpoint 1313221220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.21703
Policy Entropy: 4.34938
Value Function Loss: 0.00244
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02352
Policy Update Magnitude: 0.92959
Value Function Update Magnitude: 0.66584
Collected Steps per Second: 12,988.28429
Overall Steps per Second: 7,214.36323
Timestep Collection Time: 3.85024
Timestep Consumption Time: 3.08149
PPO Batch Consumption Time: 0.22773
Total Iteration Time: 6.93173
Cumulative Model Updates: 170,450
Cumulative Timesteps: 1,313,271,228
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.87783
Policy Entropy: 4.34840
Value Function Loss: 0.00256
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.96316
Value Function Update Magnitude: 0.72945
Collected Steps per Second: 13,698.82363
Overall Steps per Second: 7,380.64667
Timestep Collection Time: 3.65301
Timestep Consumption Time: 3.12715
PPO Batch Consumption Time: 0.22985
Total Iteration Time: 6.78016
Cumulative Model Updates: 170,459
Cumulative Timesteps: 1,313,321,270
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1313321270...
Checkpoint 1313321270 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61725
Policy Entropy: 4.35170
Value Function Loss: 0.00262
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02907
Policy Update Magnitude: 0.95959
Value Function Update Magnitude: 0.77430
Collected Steps per Second: 13,144.75795
Overall Steps per Second: 7,169.11849
Timestep Collection Time: 3.80410
Timestep Consumption Time: 3.17081
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.97492
Cumulative Model Updates: 170,468
Cumulative Timesteps: 1,313,371,274
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64157
Policy Entropy: 4.35345
Value Function Loss: 0.00245
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.94142
Value Function Update Magnitude: 0.77964
Collected Steps per Second: 13,199.04189
Overall Steps per Second: 7,148.69287
Timestep Collection Time: 3.78846
Timestep Consumption Time: 3.20639
PPO Batch Consumption Time: 0.24584
Total Iteration Time: 6.99485
Cumulative Model Updates: 170,477
Cumulative Timesteps: 1,313,421,278
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1313421278...
Checkpoint 1313421278 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57049
Policy Entropy: 4.35605
Value Function Loss: 0.00234
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.91471
Value Function Update Magnitude: 0.74358
Collected Steps per Second: 13,336.86559
Overall Steps per Second: 7,272.70221
Timestep Collection Time: 3.75096
Timestep Consumption Time: 3.12764
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.87860
Cumulative Model Updates: 170,486
Cumulative Timesteps: 1,313,471,304
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13227
Policy Entropy: 4.35349
Value Function Loss: 0.00242
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02386
Policy Update Magnitude: 0.90566
Value Function Update Magnitude: 0.74752
Collected Steps per Second: 13,113.59697
Overall Steps per Second: 7,245.10260
Timestep Collection Time: 3.81497
Timestep Consumption Time: 3.09011
PPO Batch Consumption Time: 0.23107
Total Iteration Time: 6.90508
Cumulative Model Updates: 170,495
Cumulative Timesteps: 1,313,521,332
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1313521332...
Checkpoint 1313521332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85660
Policy Entropy: 4.35221
Value Function Loss: 0.00233
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.90159
Value Function Update Magnitude: 0.72933
Collected Steps per Second: 13,175.92614
Overall Steps per Second: 7,329.40797
Timestep Collection Time: 3.79586
Timestep Consumption Time: 3.02788
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.82374
Cumulative Model Updates: 170,504
Cumulative Timesteps: 1,313,571,346
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50090
Policy Entropy: 4.35496
Value Function Loss: 0.00244
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.90858
Value Function Update Magnitude: 0.69373
Collected Steps per Second: 13,107.13256
Overall Steps per Second: 7,214.40611
Timestep Collection Time: 3.81731
Timestep Consumption Time: 3.11798
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 6.93529
Cumulative Model Updates: 170,513
Cumulative Timesteps: 1,313,621,380
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1313621380...
Checkpoint 1313621380 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.63203
Policy Entropy: 4.35015
Value Function Loss: 0.00258
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02690
Policy Update Magnitude: 0.95236
Value Function Update Magnitude: 0.68755
Collected Steps per Second: 13,142.40271
Overall Steps per Second: 7,260.92582
Timestep Collection Time: 3.80646
Timestep Consumption Time: 3.08330
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.88976
Cumulative Model Updates: 170,522
Cumulative Timesteps: 1,313,671,406
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.37775
Policy Entropy: 4.34873
Value Function Loss: 0.00262
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02877
Policy Update Magnitude: 0.96766
Value Function Update Magnitude: 0.70312
Collected Steps per Second: 13,369.69410
Overall Steps per Second: 7,309.59023
Timestep Collection Time: 3.74070
Timestep Consumption Time: 3.10127
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.84197
Cumulative Model Updates: 170,531
Cumulative Timesteps: 1,313,721,418
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1313721418...
Checkpoint 1313721418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79714
Policy Entropy: 4.34910
Value Function Loss: 0.00264
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.94872
Value Function Update Magnitude: 0.66942
Collected Steps per Second: 13,215.58472
Overall Steps per Second: 7,043.40701
Timestep Collection Time: 3.78356
Timestep Consumption Time: 3.31556
PPO Batch Consumption Time: 0.24491
Total Iteration Time: 7.09912
Cumulative Model Updates: 170,540
Cumulative Timesteps: 1,313,771,420
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.65432
Policy Entropy: 4.35229
Value Function Loss: 0.00245
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.93291
Value Function Update Magnitude: 0.64846
Collected Steps per Second: 13,306.97681
Overall Steps per Second: 7,314.13829
Timestep Collection Time: 3.76028
Timestep Consumption Time: 3.08099
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.84127
Cumulative Model Updates: 170,549
Cumulative Timesteps: 1,313,821,458
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1313821458...
Checkpoint 1313821458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58850
Policy Entropy: 4.35631
Value Function Loss: 0.00245
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.93544
Value Function Update Magnitude: 0.64780
Collected Steps per Second: 13,565.64482
Overall Steps per Second: 7,368.40656
Timestep Collection Time: 3.68814
Timestep Consumption Time: 3.10193
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.79007
Cumulative Model Updates: 170,558
Cumulative Timesteps: 1,313,871,490
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53481
Policy Entropy: 4.35269
Value Function Loss: 0.00247
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.95404
Value Function Update Magnitude: 0.67621
Collected Steps per Second: 13,309.38329
Overall Steps per Second: 7,279.60765
Timestep Collection Time: 3.75810
Timestep Consumption Time: 3.11287
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.87097
Cumulative Model Updates: 170,567
Cumulative Timesteps: 1,313,921,508
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1313921508...
Checkpoint 1313921508 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25634
Policy Entropy: 4.35429
Value Function Loss: 0.00252
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.94970
Value Function Update Magnitude: 0.70014
Collected Steps per Second: 13,094.35173
Overall Steps per Second: 7,334.28113
Timestep Collection Time: 3.82058
Timestep Consumption Time: 3.00054
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.82112
Cumulative Model Updates: 170,576
Cumulative Timesteps: 1,313,971,536
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.83642
Policy Entropy: 4.35084
Value Function Loss: 0.00241
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.95345
Value Function Update Magnitude: 0.71868
Collected Steps per Second: 13,398.23187
Overall Steps per Second: 7,291.33802
Timestep Collection Time: 3.73407
Timestep Consumption Time: 3.12749
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.86157
Cumulative Model Updates: 170,585
Cumulative Timesteps: 1,314,021,566
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1314021566...
Checkpoint 1314021566 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.83036
Policy Entropy: 4.35025
Value Function Loss: 0.00240
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.93042
Value Function Update Magnitude: 0.68924
Collected Steps per Second: 13,145.87121
Overall Steps per Second: 7,280.88897
Timestep Collection Time: 3.80515
Timestep Consumption Time: 3.06517
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.87031
Cumulative Model Updates: 170,594
Cumulative Timesteps: 1,314,071,588
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33078
Policy Entropy: 4.34697
Value Function Loss: 0.00233
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.93384
Value Function Update Magnitude: 0.73050
Collected Steps per Second: 13,624.76667
Overall Steps per Second: 7,323.88416
Timestep Collection Time: 3.67008
Timestep Consumption Time: 3.15744
PPO Batch Consumption Time: 0.23501
Total Iteration Time: 6.82752
Cumulative Model Updates: 170,603
Cumulative Timesteps: 1,314,121,592
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1314121592...
Checkpoint 1314121592 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26166
Policy Entropy: 4.34533
Value Function Loss: 0.00243
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02836
Policy Update Magnitude: 0.94065
Value Function Update Magnitude: 0.75662
Collected Steps per Second: 13,142.27216
Overall Steps per Second: 7,200.76897
Timestep Collection Time: 3.80817
Timestep Consumption Time: 3.14220
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.95037
Cumulative Model Updates: 170,612
Cumulative Timesteps: 1,314,171,640
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71430
Policy Entropy: 4.34896
Value Function Loss: 0.00245
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.95222
Value Function Update Magnitude: 0.78612
Collected Steps per Second: 13,150.84666
Overall Steps per Second: 7,284.54478
Timestep Collection Time: 3.80264
Timestep Consumption Time: 3.06230
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.86495
Cumulative Model Updates: 170,621
Cumulative Timesteps: 1,314,221,648
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1314221648...
Checkpoint 1314221648 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.35219
Policy Entropy: 4.34984
Value Function Loss: 0.00250
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02489
Policy Update Magnitude: 0.94759
Value Function Update Magnitude: 0.70703
Collected Steps per Second: 13,428.58226
Overall Steps per Second: 7,361.75681
Timestep Collection Time: 3.72608
Timestep Consumption Time: 3.07067
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.79675
Cumulative Model Updates: 170,630
Cumulative Timesteps: 1,314,271,684
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19768
Policy Entropy: 4.35338
Value Function Loss: 0.00257
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.95046
Value Function Update Magnitude: 0.71345
Collected Steps per Second: 12,770.63015
Overall Steps per Second: 7,114.84985
Timestep Collection Time: 3.91555
Timestep Consumption Time: 3.11257
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 7.02812
Cumulative Model Updates: 170,639
Cumulative Timesteps: 1,314,321,688
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1314321688...
Checkpoint 1314321688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16733
Policy Entropy: 4.35135
Value Function Loss: 0.00255
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.94754
Value Function Update Magnitude: 0.69699
Collected Steps per Second: 12,422.00850
Overall Steps per Second: 7,058.93495
Timestep Collection Time: 4.02608
Timestep Consumption Time: 3.05884
PPO Batch Consumption Time: 0.22939
Total Iteration Time: 7.08492
Cumulative Model Updates: 170,648
Cumulative Timesteps: 1,314,371,700
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71292
Policy Entropy: 4.34571
Value Function Loss: 0.00262
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.93737
Value Function Update Magnitude: 0.68274
Collected Steps per Second: 12,843.55779
Overall Steps per Second: 7,120.30885
Timestep Collection Time: 3.89534
Timestep Consumption Time: 3.13104
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 7.02638
Cumulative Model Updates: 170,657
Cumulative Timesteps: 1,314,421,730
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1314421730...
Checkpoint 1314421730 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.91636
Policy Entropy: 4.35156
Value Function Loss: 0.00242
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02633
Policy Update Magnitude: 0.93589
Value Function Update Magnitude: 0.68319
Collected Steps per Second: 13,212.83632
Overall Steps per Second: 7,134.18744
Timestep Collection Time: 3.78632
Timestep Consumption Time: 3.22611
PPO Batch Consumption Time: 0.24158
Total Iteration Time: 7.01243
Cumulative Model Updates: 170,666
Cumulative Timesteps: 1,314,471,758
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.07846
Policy Entropy: 4.35326
Value Function Loss: 0.00255
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.94245
Value Function Update Magnitude: 0.72951
Collected Steps per Second: 13,572.93696
Overall Steps per Second: 7,362.84175
Timestep Collection Time: 3.68439
Timestep Consumption Time: 3.10755
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.79194
Cumulative Model Updates: 170,675
Cumulative Timesteps: 1,314,521,766
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1314521766...
Checkpoint 1314521766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03524
Policy Entropy: 4.35474
Value Function Loss: 0.00250
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 0.96110
Value Function Update Magnitude: 0.71175
Collected Steps per Second: 13,279.35142
Overall Steps per Second: 7,275.64920
Timestep Collection Time: 3.76630
Timestep Consumption Time: 3.10786
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 6.87416
Cumulative Model Updates: 170,684
Cumulative Timesteps: 1,314,571,780
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.24480
Policy Entropy: 4.35477
Value Function Loss: 0.00251
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.94522
Value Function Update Magnitude: 0.68035
Collected Steps per Second: 13,327.93354
Overall Steps per Second: 7,318.67795
Timestep Collection Time: 3.75422
Timestep Consumption Time: 3.08253
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.83675
Cumulative Model Updates: 170,693
Cumulative Timesteps: 1,314,621,816
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1314621816...
Checkpoint 1314621816 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66906
Policy Entropy: 4.35522
Value Function Loss: 0.00232
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.93424
Value Function Update Magnitude: 0.66971
Collected Steps per Second: 13,543.39243
Overall Steps per Second: 7,355.77791
Timestep Collection Time: 3.69184
Timestep Consumption Time: 3.10554
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.79738
Cumulative Model Updates: 170,702
Cumulative Timesteps: 1,314,671,816
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.52014
Policy Entropy: 4.35659
Value Function Loss: 0.00236
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.93961
Value Function Update Magnitude: 0.62479
Collected Steps per Second: 13,215.63527
Overall Steps per Second: 7,273.01842
Timestep Collection Time: 3.78597
Timestep Consumption Time: 3.09343
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.87940
Cumulative Model Updates: 170,711
Cumulative Timesteps: 1,314,721,850
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1314721850...
Checkpoint 1314721850 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01863
Policy Entropy: 4.35387
Value Function Loss: 0.00236
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.95235
Value Function Update Magnitude: 0.66469
Collected Steps per Second: 13,231.90146
Overall Steps per Second: 7,309.95723
Timestep Collection Time: 3.77965
Timestep Consumption Time: 3.06197
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.84163
Cumulative Model Updates: 170,720
Cumulative Timesteps: 1,314,771,862
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33247
Policy Entropy: 4.35138
Value Function Loss: 0.00268
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.95774
Value Function Update Magnitude: 0.70376
Collected Steps per Second: 13,272.19594
Overall Steps per Second: 7,147.08669
Timestep Collection Time: 3.76727
Timestep Consumption Time: 3.22858
PPO Batch Consumption Time: 0.23780
Total Iteration Time: 6.99586
Cumulative Model Updates: 170,729
Cumulative Timesteps: 1,314,821,862
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1314821862...
Checkpoint 1314821862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.13008
Policy Entropy: 4.35418
Value Function Loss: 0.00246
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.95815
Value Function Update Magnitude: 0.71316
Collected Steps per Second: 13,250.21978
Overall Steps per Second: 7,288.01362
Timestep Collection Time: 3.77458
Timestep Consumption Time: 3.08792
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.86250
Cumulative Model Updates: 170,738
Cumulative Timesteps: 1,314,871,876
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.70079
Policy Entropy: 4.35513
Value Function Loss: 0.00244
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02916
Policy Update Magnitude: 0.93946
Value Function Update Magnitude: 0.74115
Collected Steps per Second: 13,053.31837
Overall Steps per Second: 7,247.51720
Timestep Collection Time: 3.83290
Timestep Consumption Time: 3.07043
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.90333
Cumulative Model Updates: 170,747
Cumulative Timesteps: 1,314,921,908
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1314921908...
Checkpoint 1314921908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79902
Policy Entropy: 4.35487
Value Function Loss: 0.00235
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.94279
Value Function Update Magnitude: 0.70750
Collected Steps per Second: 13,321.19914
Overall Steps per Second: 7,293.60129
Timestep Collection Time: 3.75567
Timestep Consumption Time: 3.10377
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.85944
Cumulative Model Updates: 170,756
Cumulative Timesteps: 1,314,971,938
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09165
Policy Entropy: 4.35178
Value Function Loss: 0.00256
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.96831
Value Function Update Magnitude: 0.72557
Collected Steps per Second: 13,275.97348
Overall Steps per Second: 7,414.94816
Timestep Collection Time: 3.76696
Timestep Consumption Time: 2.97753
PPO Batch Consumption Time: 0.22782
Total Iteration Time: 6.74448
Cumulative Model Updates: 170,765
Cumulative Timesteps: 1,315,021,948
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1315021948...
Checkpoint 1315021948 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11072
Policy Entropy: 4.35274
Value Function Loss: 0.00248
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.95849
Value Function Update Magnitude: 0.71475
Collected Steps per Second: 13,134.20439
Overall Steps per Second: 7,253.99631
Timestep Collection Time: 3.80929
Timestep Consumption Time: 3.08787
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.89716
Cumulative Model Updates: 170,774
Cumulative Timesteps: 1,315,071,980
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10596
Policy Entropy: 4.35257
Value Function Loss: 0.00254
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.95710
Value Function Update Magnitude: 0.72303
Collected Steps per Second: 13,263.33778
Overall Steps per Second: 7,323.22280
Timestep Collection Time: 3.77054
Timestep Consumption Time: 3.05842
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.82896
Cumulative Model Updates: 170,783
Cumulative Timesteps: 1,315,121,990
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1315121990...
Checkpoint 1315121990 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.52789
Policy Entropy: 4.35201
Value Function Loss: 0.00252
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02824
Policy Update Magnitude: 0.97983
Value Function Update Magnitude: 0.74122
Collected Steps per Second: 13,212.64184
Overall Steps per Second: 7,207.52765
Timestep Collection Time: 3.78501
Timestep Consumption Time: 3.15357
PPO Batch Consumption Time: 0.23990
Total Iteration Time: 6.93858
Cumulative Model Updates: 170,792
Cumulative Timesteps: 1,315,172,000
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58327
Policy Entropy: 4.34951
Value Function Loss: 0.00247
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02960
Policy Update Magnitude: 0.96058
Value Function Update Magnitude: 0.74329
Collected Steps per Second: 13,289.76553
Overall Steps per Second: 7,247.87795
Timestep Collection Time: 3.76259
Timestep Consumption Time: 3.13653
PPO Batch Consumption Time: 0.23136
Total Iteration Time: 6.89912
Cumulative Model Updates: 170,801
Cumulative Timesteps: 1,315,222,004
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1315222004...
Checkpoint 1315222004 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32855
Policy Entropy: 4.35110
Value Function Loss: 0.00233
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.92184
Value Function Update Magnitude: 0.73038
Collected Steps per Second: 11,977.60212
Overall Steps per Second: 6,868.68479
Timestep Collection Time: 4.17563
Timestep Consumption Time: 3.10583
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 7.28145
Cumulative Model Updates: 170,810
Cumulative Timesteps: 1,315,272,018
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64705
Policy Entropy: 4.35399
Value Function Loss: 0.00222
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.90854
Value Function Update Magnitude: 0.68812
Collected Steps per Second: 13,557.16037
Overall Steps per Second: 7,332.67723
Timestep Collection Time: 3.68956
Timestep Consumption Time: 3.13196
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.82152
Cumulative Model Updates: 170,819
Cumulative Timesteps: 1,315,322,038
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1315322038...
Checkpoint 1315322038 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75930
Policy Entropy: 4.35460
Value Function Loss: 0.00227
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02305
Policy Update Magnitude: 0.90581
Value Function Update Magnitude: 0.69073
Collected Steps per Second: 13,215.85135
Overall Steps per Second: 7,242.95460
Timestep Collection Time: 3.78500
Timestep Consumption Time: 3.12130
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.90630
Cumulative Model Updates: 170,828
Cumulative Timesteps: 1,315,372,060
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33896
Policy Entropy: 4.35345
Value Function Loss: 0.00223
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.91925
Value Function Update Magnitude: 0.69322
Collected Steps per Second: 13,113.17746
Overall Steps per Second: 7,263.05404
Timestep Collection Time: 3.81387
Timestep Consumption Time: 3.07194
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.88581
Cumulative Model Updates: 170,837
Cumulative Timesteps: 1,315,422,072
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1315422072...
Checkpoint 1315422072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.47843
Policy Entropy: 4.35064
Value Function Loss: 0.00216
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.91440
Value Function Update Magnitude: 0.70700
Collected Steps per Second: 13,507.99569
Overall Steps per Second: 7,354.82201
Timestep Collection Time: 3.70225
Timestep Consumption Time: 3.09737
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.79962
Cumulative Model Updates: 170,846
Cumulative Timesteps: 1,315,472,082
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.15730
Policy Entropy: 4.35094
Value Function Loss: 0.00229
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.92578
Value Function Update Magnitude: 0.70725
Collected Steps per Second: 13,315.63453
Overall Steps per Second: 7,131.28469
Timestep Collection Time: 3.75634
Timestep Consumption Time: 3.25755
PPO Batch Consumption Time: 0.24007
Total Iteration Time: 7.01388
Cumulative Model Updates: 170,855
Cumulative Timesteps: 1,315,522,100
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1315522100...
Checkpoint 1315522100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.89526
Policy Entropy: 4.35093
Value Function Loss: 0.00240
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.94475
Value Function Update Magnitude: 0.68174
Collected Steps per Second: 13,233.55167
Overall Steps per Second: 7,373.25657
Timestep Collection Time: 3.78220
Timestep Consumption Time: 3.00611
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.78832
Cumulative Model Updates: 170,864
Cumulative Timesteps: 1,315,572,152
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26388
Policy Entropy: 4.35297
Value Function Loss: 0.00237
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02714
Policy Update Magnitude: 0.91670
Value Function Update Magnitude: 0.70543
Collected Steps per Second: 13,289.94304
Overall Steps per Second: 7,281.78658
Timestep Collection Time: 3.76465
Timestep Consumption Time: 3.10619
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.87084
Cumulative Model Updates: 170,873
Cumulative Timesteps: 1,315,622,184
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1315622184...
Checkpoint 1315622184 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.06558
Policy Entropy: 4.35239
Value Function Loss: 0.00217
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.88327
Value Function Update Magnitude: 0.69569
Collected Steps per Second: 13,255.64943
Overall Steps per Second: 7,300.92360
Timestep Collection Time: 3.77515
Timestep Consumption Time: 3.07906
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.85420
Cumulative Model Updates: 170,882
Cumulative Timesteps: 1,315,672,226
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.86466
Policy Entropy: 4.34941
Value Function Loss: 0.00221
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02383
Policy Update Magnitude: 0.90059
Value Function Update Magnitude: 0.69820
Collected Steps per Second: 13,074.10069
Overall Steps per Second: 7,328.37826
Timestep Collection Time: 3.82803
Timestep Consumption Time: 3.00132
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.82934
Cumulative Model Updates: 170,891
Cumulative Timesteps: 1,315,722,274
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1315722274...
Checkpoint 1315722274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.25583
Policy Entropy: 4.34857
Value Function Loss: 0.00233
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.91328
Value Function Update Magnitude: 0.67609
Collected Steps per Second: 13,238.23561
Overall Steps per Second: 7,275.75976
Timestep Collection Time: 3.77739
Timestep Consumption Time: 3.09557
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.87296
Cumulative Model Updates: 170,900
Cumulative Timesteps: 1,315,772,280
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86057
Policy Entropy: 4.35173
Value Function Loss: 0.00242
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.92125
Value Function Update Magnitude: 0.65919
Collected Steps per Second: 13,161.98226
Overall Steps per Second: 7,359.08590
Timestep Collection Time: 3.79943
Timestep Consumption Time: 2.99598
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.79541
Cumulative Model Updates: 170,909
Cumulative Timesteps: 1,315,822,288
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1315822288...
Checkpoint 1315822288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.34306
Policy Entropy: 4.34737
Value Function Loss: 0.00241
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02690
Policy Update Magnitude: 0.91456
Value Function Update Magnitude: 0.66604
Collected Steps per Second: 13,248.99724
Overall Steps per Second: 7,096.17642
Timestep Collection Time: 3.77659
Timestep Consumption Time: 3.27453
PPO Batch Consumption Time: 0.24275
Total Iteration Time: 7.05112
Cumulative Model Updates: 170,918
Cumulative Timesteps: 1,315,872,324
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37406
Policy Entropy: 4.34706
Value Function Loss: 0.00255
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02581
Policy Update Magnitude: 0.94606
Value Function Update Magnitude: 0.71165
Collected Steps per Second: 13,192.44098
Overall Steps per Second: 7,275.31637
Timestep Collection Time: 3.79232
Timestep Consumption Time: 3.08435
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.87668
Cumulative Model Updates: 170,927
Cumulative Timesteps: 1,315,922,354
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1315922354...
Checkpoint 1315922354 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.00201
Policy Entropy: 4.33882
Value Function Loss: 0.00267
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.97083
Value Function Update Magnitude: 0.70483
Collected Steps per Second: 13,349.47257
Overall Steps per Second: 7,391.07154
Timestep Collection Time: 3.74846
Timestep Consumption Time: 3.02187
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.77033
Cumulative Model Updates: 170,936
Cumulative Timesteps: 1,315,972,394
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.36661
Policy Entropy: 4.34471
Value Function Loss: 0.00259
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.94869
Value Function Update Magnitude: 0.73692
Collected Steps per Second: 13,340.65820
Overall Steps per Second: 7,278.43083
Timestep Collection Time: 3.74869
Timestep Consumption Time: 3.12230
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.87099
Cumulative Model Updates: 170,945
Cumulative Timesteps: 1,316,022,404
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1316022404...
Checkpoint 1316022404 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20987
Policy Entropy: 4.34473
Value Function Loss: 0.00240
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02594
Policy Update Magnitude: 0.93156
Value Function Update Magnitude: 0.76544
Collected Steps per Second: 13,184.63853
Overall Steps per Second: 7,271.74071
Timestep Collection Time: 3.79335
Timestep Consumption Time: 3.08450
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.87786
Cumulative Model Updates: 170,954
Cumulative Timesteps: 1,316,072,418
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61390
Policy Entropy: 4.35054
Value Function Loss: 0.00236
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02412
Policy Update Magnitude: 0.90133
Value Function Update Magnitude: 0.72912
Collected Steps per Second: 13,091.44674
Overall Steps per Second: 7,346.57921
Timestep Collection Time: 3.82082
Timestep Consumption Time: 2.98780
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.80861
Cumulative Model Updates: 170,963
Cumulative Timesteps: 1,316,122,438
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1316122438...
Checkpoint 1316122438 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.22027
Policy Entropy: 4.34859
Value Function Loss: 0.00253
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.89988
Value Function Update Magnitude: 0.73723
Collected Steps per Second: 12,488.57491
Overall Steps per Second: 7,013.57671
Timestep Collection Time: 4.00686
Timestep Consumption Time: 3.12787
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 7.13473
Cumulative Model Updates: 170,972
Cumulative Timesteps: 1,316,172,478
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.65661
Policy Entropy: 4.35277
Value Function Loss: 0.00267
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.91498
Value Function Update Magnitude: 0.74218
Collected Steps per Second: 13,000.91700
Overall Steps per Second: 7,180.32071
Timestep Collection Time: 3.84604
Timestep Consumption Time: 3.11772
PPO Batch Consumption Time: 0.23827
Total Iteration Time: 6.96376
Cumulative Model Updates: 170,981
Cumulative Timesteps: 1,316,222,480
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1316222480...
Checkpoint 1316222480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98661
Policy Entropy: 4.34393
Value Function Loss: 0.00277
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02675
Policy Update Magnitude: 0.93808
Value Function Update Magnitude: 0.81417
Collected Steps per Second: 13,135.68205
Overall Steps per Second: 7,257.28339
Timestep Collection Time: 3.80703
Timestep Consumption Time: 3.08370
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.89073
Cumulative Model Updates: 170,990
Cumulative Timesteps: 1,316,272,488
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.69533
Policy Entropy: 4.34515
Value Function Loss: 0.00273
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02692
Policy Update Magnitude: 0.95047
Value Function Update Magnitude: 0.74765
Collected Steps per Second: 13,217.52760
Overall Steps per Second: 7,298.80603
Timestep Collection Time: 3.78361
Timestep Consumption Time: 3.06819
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.85181
Cumulative Model Updates: 170,999
Cumulative Timesteps: 1,316,322,498
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1316322498...
Checkpoint 1316322498 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04950
Policy Entropy: 4.34345
Value Function Loss: 0.00248
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.93794
Value Function Update Magnitude: 0.71929
Collected Steps per Second: 13,209.16845
Overall Steps per Second: 7,351.13791
Timestep Collection Time: 3.78782
Timestep Consumption Time: 3.01847
PPO Batch Consumption Time: 0.22774
Total Iteration Time: 6.80629
Cumulative Model Updates: 171,008
Cumulative Timesteps: 1,316,372,532
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.21984
Policy Entropy: 4.34857
Value Function Loss: 0.00244
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.92414
Value Function Update Magnitude: 0.67752
Collected Steps per Second: 13,375.68503
Overall Steps per Second: 7,322.44520
Timestep Collection Time: 3.73932
Timestep Consumption Time: 3.09118
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.83051
Cumulative Model Updates: 171,017
Cumulative Timesteps: 1,316,422,548
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1316422548...
Checkpoint 1316422548 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.27578
Policy Entropy: 4.35043
Value Function Loss: 0.00257
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.92857
Value Function Update Magnitude: 0.68585
Collected Steps per Second: 13,213.89531
Overall Steps per Second: 7,274.54047
Timestep Collection Time: 3.78586
Timestep Consumption Time: 3.09100
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.87686
Cumulative Model Updates: 171,026
Cumulative Timesteps: 1,316,472,574
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64939
Policy Entropy: 4.34455
Value Function Loss: 0.00273
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.95016
Value Function Update Magnitude: 0.74041
Collected Steps per Second: 13,505.43727
Overall Steps per Second: 7,366.01374
Timestep Collection Time: 3.70606
Timestep Consumption Time: 3.08893
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.79499
Cumulative Model Updates: 171,035
Cumulative Timesteps: 1,316,522,626
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1316522626...
Checkpoint 1316522626 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.98898
Policy Entropy: 4.34602
Value Function Loss: 0.00262
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 0.96309
Value Function Update Magnitude: 0.77239
Collected Steps per Second: 13,312.84799
Overall Steps per Second: 7,261.36050
Timestep Collection Time: 3.75787
Timestep Consumption Time: 3.13174
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.88962
Cumulative Model Updates: 171,044
Cumulative Timesteps: 1,316,572,654
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95024
Policy Entropy: 4.34372
Value Function Loss: 0.00267
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.97849
Value Function Update Magnitude: 0.75920
Collected Steps per Second: 13,258.67908
Overall Steps per Second: 7,281.06494
Timestep Collection Time: 3.77338
Timestep Consumption Time: 3.09787
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.87125
Cumulative Model Updates: 171,053
Cumulative Timesteps: 1,316,622,684
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1316622684...
Checkpoint 1316622684 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73629
Policy Entropy: 4.34576
Value Function Loss: 0.00278
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.98105
Value Function Update Magnitude: 0.73953
Collected Steps per Second: 13,482.54026
Overall Steps per Second: 7,339.37516
Timestep Collection Time: 3.71162
Timestep Consumption Time: 3.10668
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.81829
Cumulative Model Updates: 171,062
Cumulative Timesteps: 1,316,672,726
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56450
Policy Entropy: 4.33920
Value Function Loss: 0.00283
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.97185
Value Function Update Magnitude: 0.74356
Collected Steps per Second: 13,165.53303
Overall Steps per Second: 7,234.05988
Timestep Collection Time: 3.79855
Timestep Consumption Time: 3.11458
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.91313
Cumulative Model Updates: 171,071
Cumulative Timesteps: 1,316,722,736
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1316722736...
Checkpoint 1316722736 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48369
Policy Entropy: 4.34052
Value Function Loss: 0.00286
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.97207
Value Function Update Magnitude: 0.70810
Collected Steps per Second: 13,228.48658
Overall Steps per Second: 7,370.08845
Timestep Collection Time: 3.78063
Timestep Consumption Time: 3.00518
PPO Batch Consumption Time: 0.22788
Total Iteration Time: 6.78581
Cumulative Model Updates: 171,080
Cumulative Timesteps: 1,316,772,748
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99570
Policy Entropy: 4.33922
Value Function Loss: 0.00274
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02714
Policy Update Magnitude: 0.96791
Value Function Update Magnitude: 0.70041
Collected Steps per Second: 13,324.01203
Overall Steps per Second: 7,313.66572
Timestep Collection Time: 3.75412
Timestep Consumption Time: 3.08513
PPO Batch Consumption Time: 0.22749
Total Iteration Time: 6.83925
Cumulative Model Updates: 171,089
Cumulative Timesteps: 1,316,822,768
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1316822768...
Checkpoint 1316822768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74173
Policy Entropy: 4.34386
Value Function Loss: 0.00270
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.95388
Value Function Update Magnitude: 0.73157
Collected Steps per Second: 13,141.62093
Overall Steps per Second: 7,278.71487
Timestep Collection Time: 3.80592
Timestep Consumption Time: 3.06562
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.87154
Cumulative Model Updates: 171,098
Cumulative Timesteps: 1,316,872,784
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.63144
Policy Entropy: 4.34446
Value Function Loss: 0.00259
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.95409
Value Function Update Magnitude: 0.69294
Collected Steps per Second: 13,492.38346
Overall Steps per Second: 7,203.31908
Timestep Collection Time: 3.70594
Timestep Consumption Time: 3.23558
PPO Batch Consumption Time: 0.23919
Total Iteration Time: 6.94152
Cumulative Model Updates: 171,107
Cumulative Timesteps: 1,316,922,786
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1316922786...
Checkpoint 1316922786 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37154
Policy Entropy: 4.34946
Value Function Loss: 0.00249
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.92568
Value Function Update Magnitude: 0.67075
Collected Steps per Second: 13,222.27510
Overall Steps per Second: 7,268.73672
Timestep Collection Time: 3.78331
Timestep Consumption Time: 3.09876
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.88208
Cumulative Model Updates: 171,116
Cumulative Timesteps: 1,316,972,810
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.78184
Policy Entropy: 4.35051
Value Function Loss: 0.00246
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.92612
Value Function Update Magnitude: 0.66047
Collected Steps per Second: 12,740.67149
Overall Steps per Second: 7,159.17518
Timestep Collection Time: 3.92679
Timestep Consumption Time: 3.06144
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.98824
Cumulative Model Updates: 171,125
Cumulative Timesteps: 1,317,022,840
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1317022840...
Checkpoint 1317022840 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02341
Policy Entropy: 4.34997
Value Function Loss: 0.00247
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.93644
Value Function Update Magnitude: 0.70180
Collected Steps per Second: 13,553.44975
Overall Steps per Second: 7,379.43626
Timestep Collection Time: 3.69146
Timestep Consumption Time: 3.08846
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.77992
Cumulative Model Updates: 171,134
Cumulative Timesteps: 1,317,072,872
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35918
Policy Entropy: 4.34584
Value Function Loss: 0.00257
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.95600
Value Function Update Magnitude: 0.70773
Collected Steps per Second: 13,245.85856
Overall Steps per Second: 7,274.63428
Timestep Collection Time: 3.77718
Timestep Consumption Time: 3.10042
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.87760
Cumulative Model Updates: 171,143
Cumulative Timesteps: 1,317,122,904
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1317122904...
Checkpoint 1317122904 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89468
Policy Entropy: 4.34471
Value Function Loss: 0.00256
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.96197
Value Function Update Magnitude: 0.75549
Collected Steps per Second: 13,154.78630
Overall Steps per Second: 7,329.84485
Timestep Collection Time: 3.80120
Timestep Consumption Time: 3.02077
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.82197
Cumulative Model Updates: 171,152
Cumulative Timesteps: 1,317,172,908
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19037
Policy Entropy: 4.34341
Value Function Loss: 0.00243
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.94497
Value Function Update Magnitude: 0.72297
Collected Steps per Second: 13,248.67147
Overall Steps per Second: 7,257.10456
Timestep Collection Time: 3.77472
Timestep Consumption Time: 3.11646
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.89118
Cumulative Model Updates: 171,161
Cumulative Timesteps: 1,317,222,918
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1317222918...
Checkpoint 1317222918 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34969
Policy Entropy: 4.34663
Value Function Loss: 0.00234
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.92986
Value Function Update Magnitude: 0.68668
Collected Steps per Second: 13,072.14215
Overall Steps per Second: 7,047.00789
Timestep Collection Time: 3.82523
Timestep Consumption Time: 3.27054
PPO Batch Consumption Time: 0.24505
Total Iteration Time: 7.09578
Cumulative Model Updates: 171,170
Cumulative Timesteps: 1,317,272,922
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72004
Policy Entropy: 4.34575
Value Function Loss: 0.00255
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.93462
Value Function Update Magnitude: 0.68319
Collected Steps per Second: 13,553.55461
Overall Steps per Second: 7,366.29558
Timestep Collection Time: 3.69040
Timestep Consumption Time: 3.09972
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.79012
Cumulative Model Updates: 171,179
Cumulative Timesteps: 1,317,322,940
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1317322940...
Checkpoint 1317322940 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.59305
Policy Entropy: 4.34379
Value Function Loss: 0.00264
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02812
Policy Update Magnitude: 0.93937
Value Function Update Magnitude: 0.66995
Collected Steps per Second: 13,281.47043
Overall Steps per Second: 7,270.96056
Timestep Collection Time: 3.76464
Timestep Consumption Time: 3.11203
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.87667
Cumulative Model Updates: 171,188
Cumulative Timesteps: 1,317,372,940
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62685
Policy Entropy: 4.34673
Value Function Loss: 0.00254
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.96369
Value Function Update Magnitude: 0.68317
Collected Steps per Second: 13,322.23493
Overall Steps per Second: 7,324.57772
Timestep Collection Time: 3.75538
Timestep Consumption Time: 3.07505
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.83043
Cumulative Model Updates: 171,197
Cumulative Timesteps: 1,317,422,970
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1317422970...
Checkpoint 1317422970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14500
Policy Entropy: 4.35028
Value Function Loss: 0.00245
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.93711
Value Function Update Magnitude: 0.67489
Collected Steps per Second: 13,481.58422
Overall Steps per Second: 7,304.62580
Timestep Collection Time: 3.70980
Timestep Consumption Time: 3.13709
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.84689
Cumulative Model Updates: 171,206
Cumulative Timesteps: 1,317,472,984
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00439
Policy Entropy: 4.34992
Value Function Loss: 0.00245
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.96365
Value Function Update Magnitude: 0.71707
Collected Steps per Second: 13,341.88150
Overall Steps per Second: 7,289.73273
Timestep Collection Time: 3.74880
Timestep Consumption Time: 3.11236
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.86116
Cumulative Model Updates: 171,215
Cumulative Timesteps: 1,317,523,000
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1317523000...
Checkpoint 1317523000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.29608
Policy Entropy: 4.34680
Value Function Loss: 0.00256
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.99517
Value Function Update Magnitude: 0.69014
Collected Steps per Second: 13,197.34324
Overall Steps per Second: 7,333.30138
Timestep Collection Time: 3.78955
Timestep Consumption Time: 3.03030
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.81985
Cumulative Model Updates: 171,224
Cumulative Timesteps: 1,317,573,012
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.57113
Policy Entropy: 4.34384
Value Function Loss: 0.00257
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.99181
Value Function Update Magnitude: 0.66739
Collected Steps per Second: 13,317.61506
Overall Steps per Second: 7,149.97428
Timestep Collection Time: 3.75758
Timestep Consumption Time: 3.24133
PPO Batch Consumption Time: 0.23920
Total Iteration Time: 6.99891
Cumulative Model Updates: 171,233
Cumulative Timesteps: 1,317,623,054
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1317623054...
Checkpoint 1317623054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38336
Policy Entropy: 4.34115
Value Function Loss: 0.00260
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02816
Policy Update Magnitude: 1.00108
Value Function Update Magnitude: 0.67226
Collected Steps per Second: 13,324.84390
Overall Steps per Second: 7,326.52836
Timestep Collection Time: 3.75494
Timestep Consumption Time: 3.07421
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.82916
Cumulative Model Updates: 171,242
Cumulative Timesteps: 1,317,673,088
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.90692
Policy Entropy: 4.34402
Value Function Loss: 0.00239
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02814
Policy Update Magnitude: 0.98739
Value Function Update Magnitude: 0.64242
Collected Steps per Second: 13,219.58414
Overall Steps per Second: 7,404.91646
Timestep Collection Time: 3.78287
Timestep Consumption Time: 2.97048
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.75335
Cumulative Model Updates: 171,251
Cumulative Timesteps: 1,317,723,096
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1317723096...
Checkpoint 1317723096 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13253
Policy Entropy: 4.34195
Value Function Loss: 0.00255
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.97948
Value Function Update Magnitude: 0.66754
Collected Steps per Second: 13,124.17971
Overall Steps per Second: 7,225.63026
Timestep Collection Time: 3.81159
Timestep Consumption Time: 3.11154
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.92313
Cumulative Model Updates: 171,260
Cumulative Timesteps: 1,317,773,120
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09474
Policy Entropy: 4.34537
Value Function Loss: 0.00248
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.96768
Value Function Update Magnitude: 0.71096
Collected Steps per Second: 13,156.38777
Overall Steps per Second: 7,267.56478
Timestep Collection Time: 3.80165
Timestep Consumption Time: 3.08043
PPO Batch Consumption Time: 0.22791
Total Iteration Time: 6.88209
Cumulative Model Updates: 171,269
Cumulative Timesteps: 1,317,823,136
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1317823136...
Checkpoint 1317823136 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28264
Policy Entropy: 4.34288
Value Function Loss: 0.00265
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.98185
Value Function Update Magnitude: 0.69860
Collected Steps per Second: 13,292.73183
Overall Steps per Second: 7,278.94849
Timestep Collection Time: 3.76416
Timestep Consumption Time: 3.10991
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.87407
Cumulative Model Updates: 171,278
Cumulative Timesteps: 1,317,873,172
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.61893
Policy Entropy: 4.34928
Value Function Loss: 0.00250
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.96122
Value Function Update Magnitude: 0.66509
Collected Steps per Second: 13,312.08862
Overall Steps per Second: 7,287.77777
Timestep Collection Time: 3.75899
Timestep Consumption Time: 3.10730
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.86629
Cumulative Model Updates: 171,287
Cumulative Timesteps: 1,317,923,212
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1317923212...
Checkpoint 1317923212 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.74035
Policy Entropy: 4.34916
Value Function Loss: 0.00245
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02682
Policy Update Magnitude: 0.94819
Value Function Update Magnitude: 0.69751
Collected Steps per Second: 13,199.17392
Overall Steps per Second: 7,216.58159
Timestep Collection Time: 3.79024
Timestep Consumption Time: 3.14213
PPO Batch Consumption Time: 0.23978
Total Iteration Time: 6.93237
Cumulative Model Updates: 171,296
Cumulative Timesteps: 1,317,973,240
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.37378
Policy Entropy: 4.34882
Value Function Loss: 0.00247
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.93714
Value Function Update Magnitude: 0.72882
Collected Steps per Second: 13,359.27055
Overall Steps per Second: 7,287.90546
Timestep Collection Time: 3.74407
Timestep Consumption Time: 3.11908
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.86315
Cumulative Model Updates: 171,305
Cumulative Timesteps: 1,318,023,258
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1318023258...
Checkpoint 1318023258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11901
Policy Entropy: 4.34860
Value Function Loss: 0.00241
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.93712
Value Function Update Magnitude: 0.71028
Collected Steps per Second: 13,290.24170
Overall Steps per Second: 7,290.37151
Timestep Collection Time: 3.76457
Timestep Consumption Time: 3.09818
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.86275
Cumulative Model Updates: 171,314
Cumulative Timesteps: 1,318,073,290
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.73943
Policy Entropy: 4.34479
Value Function Loss: 0.00254
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.94320
Value Function Update Magnitude: 0.67304
Collected Steps per Second: 13,242.64933
Overall Steps per Second: 7,378.09041
Timestep Collection Time: 3.77885
Timestep Consumption Time: 3.00366
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.78251
Cumulative Model Updates: 171,323
Cumulative Timesteps: 1,318,123,332
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1318123332...
Checkpoint 1318123332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41459
Policy Entropy: 4.34445
Value Function Loss: 0.00245
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02924
Policy Update Magnitude: 0.94765
Value Function Update Magnitude: 0.70488
Collected Steps per Second: 13,347.10203
Overall Steps per Second: 7,301.64575
Timestep Collection Time: 3.74928
Timestep Consumption Time: 3.10425
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.85352
Cumulative Model Updates: 171,332
Cumulative Timesteps: 1,318,173,374
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05205
Policy Entropy: 4.34349
Value Function Loss: 0.00265
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02787
Policy Update Magnitude: 0.93856
Value Function Update Magnitude: 0.69422
Collected Steps per Second: 13,344.10601
Overall Steps per Second: 7,336.56712
Timestep Collection Time: 3.74862
Timestep Consumption Time: 3.06955
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.81818
Cumulative Model Updates: 171,341
Cumulative Timesteps: 1,318,223,396
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1318223396...
Checkpoint 1318223396 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.12521
Policy Entropy: 4.34769
Value Function Loss: 0.00254
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.94705
Value Function Update Magnitude: 0.67057
Collected Steps per Second: 13,349.76093
Overall Steps per Second: 7,313.37513
Timestep Collection Time: 3.74613
Timestep Consumption Time: 3.09202
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.83816
Cumulative Model Updates: 171,350
Cumulative Timesteps: 1,318,273,406
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64110
Policy Entropy: 4.34750
Value Function Loss: 0.00249
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.93015
Value Function Update Magnitude: 0.63797
Collected Steps per Second: 13,283.30211
Overall Steps per Second: 7,185.65321
Timestep Collection Time: 3.76533
Timestep Consumption Time: 3.19521
PPO Batch Consumption Time: 0.23428
Total Iteration Time: 6.96054
Cumulative Model Updates: 171,359
Cumulative Timesteps: 1,318,323,422
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1318323422...
Checkpoint 1318323422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08658
Policy Entropy: 4.34920
Value Function Loss: 0.00234
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.91721
Value Function Update Magnitude: 0.70192
Collected Steps per Second: 13,323.26850
Overall Steps per Second: 7,399.38021
Timestep Collection Time: 3.75538
Timestep Consumption Time: 3.00653
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.76192
Cumulative Model Updates: 171,368
Cumulative Timesteps: 1,318,373,456
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89163
Policy Entropy: 4.34990
Value Function Loss: 0.00238
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.93360
Value Function Update Magnitude: 0.71703
Collected Steps per Second: 13,344.16132
Overall Steps per Second: 7,290.31501
Timestep Collection Time: 3.74696
Timestep Consumption Time: 3.11146
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.85841
Cumulative Model Updates: 171,377
Cumulative Timesteps: 1,318,423,456
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1318423456...
Checkpoint 1318423456 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81213
Policy Entropy: 4.35118
Value Function Loss: 0.00249
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.94794
Value Function Update Magnitude: 0.71830
Collected Steps per Second: 13,157.42490
Overall Steps per Second: 7,247.47660
Timestep Collection Time: 3.80029
Timestep Consumption Time: 3.09894
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.89923
Cumulative Model Updates: 171,386
Cumulative Timesteps: 1,318,473,458
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63164
Policy Entropy: 4.34933
Value Function Loss: 0.00239
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.94571
Value Function Update Magnitude: 0.72464
Collected Steps per Second: 13,338.52492
Overall Steps per Second: 7,297.26158
Timestep Collection Time: 3.75094
Timestep Consumption Time: 3.10533
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.85627
Cumulative Model Updates: 171,395
Cumulative Timesteps: 1,318,523,490
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1318523490...
Checkpoint 1318523490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.96654
Policy Entropy: 4.34859
Value Function Loss: 0.00236
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.92904
Value Function Update Magnitude: 0.73026
Collected Steps per Second: 13,183.78780
Overall Steps per Second: 7,240.20861
Timestep Collection Time: 3.79572
Timestep Consumption Time: 3.11596
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 6.91168
Cumulative Model Updates: 171,404
Cumulative Timesteps: 1,318,573,532
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51864
Policy Entropy: 4.34755
Value Function Loss: 0.00261
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.93437
Value Function Update Magnitude: 0.78124
Collected Steps per Second: 13,255.04420
Overall Steps per Second: 7,302.33282
Timestep Collection Time: 3.77290
Timestep Consumption Time: 3.07559
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.84850
Cumulative Model Updates: 171,413
Cumulative Timesteps: 1,318,623,542
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1318623542...
Checkpoint 1318623542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88165
Policy Entropy: 4.34602
Value Function Loss: 0.00270
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.96321
Value Function Update Magnitude: 0.76616
Collected Steps per Second: 13,426.78437
Overall Steps per Second: 7,212.61217
Timestep Collection Time: 3.72569
Timestep Consumption Time: 3.20994
PPO Batch Consumption Time: 0.23867
Total Iteration Time: 6.93563
Cumulative Model Updates: 171,422
Cumulative Timesteps: 1,318,673,566
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.84564
Policy Entropy: 4.34355
Value Function Loss: 0.00279
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02904
Policy Update Magnitude: 0.97070
Value Function Update Magnitude: 0.75449
Collected Steps per Second: 13,240.03371
Overall Steps per Second: 7,276.27738
Timestep Collection Time: 3.77899
Timestep Consumption Time: 3.09733
PPO Batch Consumption Time: 0.22764
Total Iteration Time: 6.87632
Cumulative Model Updates: 171,431
Cumulative Timesteps: 1,318,723,600
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1318723600...
Checkpoint 1318723600 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51170
Policy Entropy: 4.34571
Value Function Loss: 0.00260
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02926
Policy Update Magnitude: 0.95043
Value Function Update Magnitude: 0.75199
Collected Steps per Second: 13,137.98768
Overall Steps per Second: 7,335.32018
Timestep Collection Time: 3.80591
Timestep Consumption Time: 3.01070
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.81661
Cumulative Model Updates: 171,440
Cumulative Timesteps: 1,318,773,602
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71422
Policy Entropy: 4.34912
Value Function Loss: 0.00248
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02818
Policy Update Magnitude: 0.92621
Value Function Update Magnitude: 0.71540
Collected Steps per Second: 13,461.81242
Overall Steps per Second: 7,309.77280
Timestep Collection Time: 3.71480
Timestep Consumption Time: 3.12645
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.84125
Cumulative Model Updates: 171,449
Cumulative Timesteps: 1,318,823,610
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1318823610...
Checkpoint 1318823610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.75755
Policy Entropy: 4.35126
Value Function Loss: 0.00245
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02566
Policy Update Magnitude: 0.92330
Value Function Update Magnitude: 0.72298
Collected Steps per Second: 13,336.70076
Overall Steps per Second: 7,324.54383
Timestep Collection Time: 3.74965
Timestep Consumption Time: 3.07780
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.82746
Cumulative Model Updates: 171,458
Cumulative Timesteps: 1,318,873,618
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.41945
Policy Entropy: 4.34853
Value Function Loss: 0.00261
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.94250
Value Function Update Magnitude: 0.75948
Collected Steps per Second: 13,265.61096
Overall Steps per Second: 7,397.61260
Timestep Collection Time: 3.77246
Timestep Consumption Time: 2.99242
PPO Batch Consumption Time: 0.22730
Total Iteration Time: 6.76489
Cumulative Model Updates: 171,467
Cumulative Timesteps: 1,318,923,662
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1318923662...
Checkpoint 1318923662 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.21121
Policy Entropy: 4.34675
Value Function Loss: 0.00263
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.95674
Value Function Update Magnitude: 0.77299
Collected Steps per Second: 13,327.65546
Overall Steps per Second: 7,284.03495
Timestep Collection Time: 3.75610
Timestep Consumption Time: 3.11647
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.87256
Cumulative Model Updates: 171,476
Cumulative Timesteps: 1,318,973,722
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44858
Policy Entropy: 4.34720
Value Function Loss: 0.00257
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 0.93529
Value Function Update Magnitude: 0.73627
Collected Steps per Second: 13,171.73852
Overall Steps per Second: 7,099.58424
Timestep Collection Time: 3.79783
Timestep Consumption Time: 3.24822
PPO Batch Consumption Time: 0.24090
Total Iteration Time: 7.04605
Cumulative Model Updates: 171,485
Cumulative Timesteps: 1,319,023,746
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1319023746...
Checkpoint 1319023746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87584
Policy Entropy: 4.34977
Value Function Loss: 0.00231
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02613
Policy Update Magnitude: 0.88959
Value Function Update Magnitude: 0.68725
Collected Steps per Second: 13,647.45281
Overall Steps per Second: 7,380.22611
Timestep Collection Time: 3.66574
Timestep Consumption Time: 3.11292
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.77865
Cumulative Model Updates: 171,494
Cumulative Timesteps: 1,319,073,774
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89957
Policy Entropy: 4.34815
Value Function Loss: 0.00251
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.89092
Value Function Update Magnitude: 0.67122
Collected Steps per Second: 13,287.74279
Overall Steps per Second: 7,258.90694
Timestep Collection Time: 3.76663
Timestep Consumption Time: 3.12835
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.89498
Cumulative Model Updates: 171,503
Cumulative Timesteps: 1,319,123,824
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1319123824...
Checkpoint 1319123824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77231
Policy Entropy: 4.34770
Value Function Loss: 0.00259
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02410
Policy Update Magnitude: 0.91194
Value Function Update Magnitude: 0.73666
Collected Steps per Second: 13,134.40999
Overall Steps per Second: 7,346.26030
Timestep Collection Time: 3.80908
Timestep Consumption Time: 3.00119
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.81027
Cumulative Model Updates: 171,512
Cumulative Timesteps: 1,319,173,854
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32646
Policy Entropy: 4.34587
Value Function Loss: 0.00278
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.94691
Value Function Update Magnitude: 0.74663
Collected Steps per Second: 13,048.35382
Overall Steps per Second: 7,211.07838
Timestep Collection Time: 3.83251
Timestep Consumption Time: 3.10237
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.93489
Cumulative Model Updates: 171,521
Cumulative Timesteps: 1,319,223,862
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1319223862...
Checkpoint 1319223862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.56898
Policy Entropy: 4.34551
Value Function Loss: 0.00280
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.97178
Value Function Update Magnitude: 0.80686
Collected Steps per Second: 13,147.29161
Overall Steps per Second: 7,279.79716
Timestep Collection Time: 3.80474
Timestep Consumption Time: 3.06661
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.87135
Cumulative Model Updates: 171,530
Cumulative Timesteps: 1,319,273,884
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62745
Policy Entropy: 4.34963
Value Function Loss: 0.00255
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.96274
Value Function Update Magnitude: 0.77271
Collected Steps per Second: 13,089.05970
Overall Steps per Second: 7,336.75468
Timestep Collection Time: 3.82105
Timestep Consumption Time: 2.99586
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.81691
Cumulative Model Updates: 171,539
Cumulative Timesteps: 1,319,323,898
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1319323898...
Checkpoint 1319323898 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.06855
Policy Entropy: 4.35113
Value Function Loss: 0.00239
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02566
Policy Update Magnitude: 0.91805
Value Function Update Magnitude: 0.70865
Collected Steps per Second: 12,885.24148
Overall Steps per Second: 7,024.27648
Timestep Collection Time: 3.88367
Timestep Consumption Time: 3.24048
PPO Batch Consumption Time: 0.23991
Total Iteration Time: 7.12415
Cumulative Model Updates: 171,548
Cumulative Timesteps: 1,319,373,940
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01736
Policy Entropy: 4.35349
Value Function Loss: 0.00239
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.91099
Value Function Update Magnitude: 0.67900
Collected Steps per Second: 13,230.81987
Overall Steps per Second: 7,296.95645
Timestep Collection Time: 3.78147
Timestep Consumption Time: 3.07508
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.85656
Cumulative Model Updates: 171,557
Cumulative Timesteps: 1,319,423,972
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1319423972...
Checkpoint 1319423972 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72163
Policy Entropy: 4.35076
Value Function Loss: 0.00231
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02616
Policy Update Magnitude: 0.90119
Value Function Update Magnitude: 0.67622
Collected Steps per Second: 13,616.29419
Overall Steps per Second: 7,358.04313
Timestep Collection Time: 3.67354
Timestep Consumption Time: 3.12446
PPO Batch Consumption Time: 0.22936
Total Iteration Time: 6.79800
Cumulative Model Updates: 171,566
Cumulative Timesteps: 1,319,473,992
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.54023
Policy Entropy: 4.35171
Value Function Loss: 0.00234
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.89888
Value Function Update Magnitude: 0.65507
Collected Steps per Second: 13,205.65735
Overall Steps per Second: 7,249.03540
Timestep Collection Time: 3.78883
Timestep Consumption Time: 3.11333
PPO Batch Consumption Time: 0.22770
Total Iteration Time: 6.90216
Cumulative Model Updates: 171,575
Cumulative Timesteps: 1,319,524,026
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1319524026...
Checkpoint 1319524026 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.40262
Policy Entropy: 4.34910
Value Function Loss: 0.00247
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.91943
Value Function Update Magnitude: 0.67109
Collected Steps per Second: 13,080.02880
Overall Steps per Second: 7,262.57545
Timestep Collection Time: 3.82415
Timestep Consumption Time: 3.06321
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.88736
Cumulative Model Updates: 171,584
Cumulative Timesteps: 1,319,574,046
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.07749
Policy Entropy: 4.35033
Value Function Loss: 0.00260
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.93780
Value Function Update Magnitude: 0.72834
Collected Steps per Second: 13,311.42291
Overall Steps per Second: 7,290.57176
Timestep Collection Time: 3.75858
Timestep Consumption Time: 3.10399
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.86256
Cumulative Model Updates: 171,593
Cumulative Timesteps: 1,319,624,078
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1319624078...
Checkpoint 1319624078 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98919
Policy Entropy: 4.34735
Value Function Loss: 0.00263
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.93590
Value Function Update Magnitude: 0.74159
Collected Steps per Second: 13,238.97221
Overall Steps per Second: 7,253.10880
Timestep Collection Time: 3.77930
Timestep Consumption Time: 3.11899
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.89828
Cumulative Model Updates: 171,602
Cumulative Timesteps: 1,319,674,112
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11518
Policy Entropy: 4.34995
Value Function Loss: 0.00256
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.93415
Value Function Update Magnitude: 0.76241
Collected Steps per Second: 13,249.84253
Overall Steps per Second: 7,381.26304
Timestep Collection Time: 3.77378
Timestep Consumption Time: 3.00040
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.77418
Cumulative Model Updates: 171,611
Cumulative Timesteps: 1,319,724,114
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1319724114...
Checkpoint 1319724114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.40288
Policy Entropy: 4.34664
Value Function Loss: 0.00264
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.94945
Value Function Update Magnitude: 0.74446
Collected Steps per Second: 13,345.00437
Overall Steps per Second: 7,243.42888
Timestep Collection Time: 3.74957
Timestep Consumption Time: 3.15849
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.90805
Cumulative Model Updates: 171,620
Cumulative Timesteps: 1,319,774,152
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.24427
Policy Entropy: 4.34767
Value Function Loss: 0.00266
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.96283
Value Function Update Magnitude: 0.74918
Collected Steps per Second: 13,135.50190
Overall Steps per Second: 7,272.19583
Timestep Collection Time: 3.80937
Timestep Consumption Time: 3.07136
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.88073
Cumulative Model Updates: 171,629
Cumulative Timesteps: 1,319,824,190
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1319824190...
Checkpoint 1319824190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13777
Policy Entropy: 4.34562
Value Function Loss: 0.00279
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.99026
Value Function Update Magnitude: 0.76126
Collected Steps per Second: 13,251.22100
Overall Steps per Second: 7,386.83391
Timestep Collection Time: 3.77580
Timestep Consumption Time: 2.99760
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.77340
Cumulative Model Updates: 171,638
Cumulative Timesteps: 1,319,874,224
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50946
Policy Entropy: 4.34591
Value Function Loss: 0.00264
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02868
Policy Update Magnitude: 0.97190
Value Function Update Magnitude: 0.76060
Collected Steps per Second: 13,294.35930
Overall Steps per Second: 7,282.55786
Timestep Collection Time: 3.76220
Timestep Consumption Time: 3.10572
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.86792
Cumulative Model Updates: 171,647
Cumulative Timesteps: 1,319,924,240
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1319924240...
Checkpoint 1319924240 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85499
Policy Entropy: 4.34625
Value Function Loss: 0.00265
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02870
Policy Update Magnitude: 0.95165
Value Function Update Magnitude: 0.76702
Collected Steps per Second: 12,840.59967
Overall Steps per Second: 7,173.08925
Timestep Collection Time: 3.89546
Timestep Consumption Time: 3.07783
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.97329
Cumulative Model Updates: 171,656
Cumulative Timesteps: 1,319,974,260
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46156
Policy Entropy: 4.34984
Value Function Loss: 0.00240
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.92248
Value Function Update Magnitude: 0.70795
Collected Steps per Second: 13,581.54600
Overall Steps per Second: 7,356.61098
Timestep Collection Time: 3.68294
Timestep Consumption Time: 3.11639
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.79933
Cumulative Model Updates: 171,665
Cumulative Timesteps: 1,320,024,280
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1320024280...
Checkpoint 1320024280 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.83368
Policy Entropy: 4.35285
Value Function Loss: 0.00226
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02425
Policy Update Magnitude: 0.90118
Value Function Update Magnitude: 0.68153
Collected Steps per Second: 13,007.79165
Overall Steps per Second: 7,028.84512
Timestep Collection Time: 3.84554
Timestep Consumption Time: 3.27113
PPO Batch Consumption Time: 0.24121
Total Iteration Time: 7.11667
Cumulative Model Updates: 171,674
Cumulative Timesteps: 1,320,074,302
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08166
Policy Entropy: 4.35081
Value Function Loss: 0.00244
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02488
Policy Update Magnitude: 0.91172
Value Function Update Magnitude: 0.71201
Collected Steps per Second: 13,171.33868
Overall Steps per Second: 7,363.51409
Timestep Collection Time: 3.79764
Timestep Consumption Time: 2.99531
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.79295
Cumulative Model Updates: 171,683
Cumulative Timesteps: 1,320,124,322
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1320124322...
Checkpoint 1320124322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.48251
Policy Entropy: 4.34803
Value Function Loss: 0.00251
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.92887
Value Function Update Magnitude: 0.74755
Collected Steps per Second: 13,165.64828
Overall Steps per Second: 7,174.59078
Timestep Collection Time: 3.79928
Timestep Consumption Time: 3.17255
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.97183
Cumulative Model Updates: 171,692
Cumulative Timesteps: 1,320,174,342
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.68870
Policy Entropy: 4.34316
Value Function Loss: 0.00285
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.95949
Value Function Update Magnitude: 0.84423
Collected Steps per Second: 13,321.17168
Overall Steps per Second: 7,272.04879
Timestep Collection Time: 3.75673
Timestep Consumption Time: 3.12497
PPO Batch Consumption Time: 0.23183
Total Iteration Time: 6.88169
Cumulative Model Updates: 171,701
Cumulative Timesteps: 1,320,224,386
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1320224386...
Checkpoint 1320224386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.68261
Policy Entropy: 4.34511
Value Function Loss: 0.00273
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.98524
Value Function Update Magnitude: 0.83947
Collected Steps per Second: 13,486.96595
Overall Steps per Second: 7,312.25686
Timestep Collection Time: 3.70951
Timestep Consumption Time: 3.13243
PPO Batch Consumption Time: 0.22951
Total Iteration Time: 6.84194
Cumulative Model Updates: 171,710
Cumulative Timesteps: 1,320,274,416
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.62451
Policy Entropy: 4.34583
Value Function Loss: 0.00282
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02825
Policy Update Magnitude: 0.96433
Value Function Update Magnitude: 0.78735
Collected Steps per Second: 13,304.75995
Overall Steps per Second: 7,283.64055
Timestep Collection Time: 3.76061
Timestep Consumption Time: 3.10876
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.86937
Cumulative Model Updates: 171,719
Cumulative Timesteps: 1,320,324,450
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1320324450...
Checkpoint 1320324450 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51286
Policy Entropy: 4.34772
Value Function Loss: 0.00274
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.94836
Value Function Update Magnitude: 0.79221
Collected Steps per Second: 13,133.67645
Overall Steps per Second: 7,282.17005
Timestep Collection Time: 3.80807
Timestep Consumption Time: 3.05993
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.86801
Cumulative Model Updates: 171,728
Cumulative Timesteps: 1,320,374,464
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.47865
Policy Entropy: 4.34970
Value Function Loss: 0.00250
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.93753
Value Function Update Magnitude: 0.74453
Collected Steps per Second: 13,565.47612
Overall Steps per Second: 7,328.49489
Timestep Collection Time: 3.68701
Timestep Consumption Time: 3.13786
PPO Batch Consumption Time: 0.23314
Total Iteration Time: 6.82487
Cumulative Model Updates: 171,737
Cumulative Timesteps: 1,320,424,480
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1320424480...
Checkpoint 1320424480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.42425
Policy Entropy: 4.35030
Value Function Loss: 0.00247
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.92764
Value Function Update Magnitude: 0.74349
Collected Steps per Second: 12,879.15150
Overall Steps per Second: 7,136.55469
Timestep Collection Time: 3.88271
Timestep Consumption Time: 3.12431
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 7.00702
Cumulative Model Updates: 171,746
Cumulative Timesteps: 1,320,474,486
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88315
Policy Entropy: 4.35224
Value Function Loss: 0.00248
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.95022
Value Function Update Magnitude: 0.78129
Collected Steps per Second: 13,175.05231
Overall Steps per Second: 7,298.93967
Timestep Collection Time: 3.79900
Timestep Consumption Time: 3.05844
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.85743
Cumulative Model Updates: 171,755
Cumulative Timesteps: 1,320,524,538
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1320524538...
Checkpoint 1320524538 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.07823
Policy Entropy: 4.34806
Value Function Loss: 0.00261
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.96368
Value Function Update Magnitude: 0.78561
Collected Steps per Second: 13,240.35523
Overall Steps per Second: 7,265.48326
Timestep Collection Time: 3.77739
Timestep Consumption Time: 3.10639
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.88378
Cumulative Model Updates: 171,764
Cumulative Timesteps: 1,320,574,552
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.31594
Policy Entropy: 4.35125
Value Function Loss: 0.00258
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.92540
Value Function Update Magnitude: 0.75979
Collected Steps per Second: 13,215.95067
Overall Steps per Second: 7,289.79494
Timestep Collection Time: 3.78331
Timestep Consumption Time: 3.07560
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.85890
Cumulative Model Updates: 171,773
Cumulative Timesteps: 1,320,624,552
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1320624552...
Checkpoint 1320624552 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.69263
Policy Entropy: 4.35117
Value Function Loss: 0.00247
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.89862
Value Function Update Magnitude: 0.76625
Collected Steps per Second: 13,085.50573
Overall Steps per Second: 7,304.42789
Timestep Collection Time: 3.82179
Timestep Consumption Time: 3.02475
PPO Batch Consumption Time: 0.22920
Total Iteration Time: 6.84653
Cumulative Model Updates: 171,782
Cumulative Timesteps: 1,320,674,562
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87526
Policy Entropy: 4.35706
Value Function Loss: 0.00226
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.87963
Value Function Update Magnitude: 0.71960
Collected Steps per Second: 13,273.05730
Overall Steps per Second: 7,275.99041
Timestep Collection Time: 3.76959
Timestep Consumption Time: 3.10700
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.87659
Cumulative Model Updates: 171,791
Cumulative Timesteps: 1,320,724,596
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1320724596...
Checkpoint 1320724596 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70506
Policy Entropy: 4.35468
Value Function Loss: 0.00224
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.87471
Value Function Update Magnitude: 0.67443
Collected Steps per Second: 12,936.77486
Overall Steps per Second: 7,013.52748
Timestep Collection Time: 3.86712
Timestep Consumption Time: 3.26596
PPO Batch Consumption Time: 0.24163
Total Iteration Time: 7.13307
Cumulative Model Updates: 171,800
Cumulative Timesteps: 1,320,774,624
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44315
Policy Entropy: 4.35166
Value Function Loss: 0.00241
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.87963
Value Function Update Magnitude: 0.66695
Collected Steps per Second: 13,394.49682
Overall Steps per Second: 7,317.53345
Timestep Collection Time: 3.73467
Timestep Consumption Time: 3.10152
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.83618
Cumulative Model Updates: 171,809
Cumulative Timesteps: 1,320,824,648
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1320824648...
Checkpoint 1320824648 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58071
Policy Entropy: 4.34968
Value Function Loss: 0.00252
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02648
Policy Update Magnitude: 0.91064
Value Function Update Magnitude: 0.65068
Collected Steps per Second: 12,823.50931
Overall Steps per Second: 7,103.68672
Timestep Collection Time: 3.89987
Timestep Consumption Time: 3.14014
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 7.04001
Cumulative Model Updates: 171,818
Cumulative Timesteps: 1,320,874,658
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34165
Policy Entropy: 4.34571
Value Function Loss: 0.00253
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.92700
Value Function Update Magnitude: 0.67953
Collected Steps per Second: 13,241.49696
Overall Steps per Second: 7,371.08381
Timestep Collection Time: 3.77707
Timestep Consumption Time: 3.00810
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.78516
Cumulative Model Updates: 171,827
Cumulative Timesteps: 1,320,924,672
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1320924672...
Checkpoint 1320924672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43008
Policy Entropy: 4.34963
Value Function Loss: 0.00247
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.91322
Value Function Update Magnitude: 0.71322
Collected Steps per Second: 13,208.68972
Overall Steps per Second: 7,262.51299
Timestep Collection Time: 3.78614
Timestep Consumption Time: 3.09990
PPO Batch Consumption Time: 0.22952
Total Iteration Time: 6.88605
Cumulative Model Updates: 171,836
Cumulative Timesteps: 1,320,974,682
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86007
Policy Entropy: 4.35216
Value Function Loss: 0.00235
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.90853
Value Function Update Magnitude: 0.70007
Collected Steps per Second: 13,150.13889
Overall Steps per Second: 7,249.64102
Timestep Collection Time: 3.80239
Timestep Consumption Time: 3.09478
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.89717
Cumulative Model Updates: 171,845
Cumulative Timesteps: 1,321,024,684
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1321024684...
Checkpoint 1321024684 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.44881
Policy Entropy: 4.35431
Value Function Loss: 0.00242
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.89635
Value Function Update Magnitude: 0.69862
Collected Steps per Second: 13,229.44865
Overall Steps per Second: 7,363.52590
Timestep Collection Time: 3.78081
Timestep Consumption Time: 3.01186
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.79267
Cumulative Model Updates: 171,854
Cumulative Timesteps: 1,321,074,702
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09773
Policy Entropy: 4.35421
Value Function Loss: 0.00260
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.91472
Value Function Update Magnitude: 0.72442
Collected Steps per Second: 13,206.13161
Overall Steps per Second: 7,232.12671
Timestep Collection Time: 3.78688
Timestep Consumption Time: 3.12810
PPO Batch Consumption Time: 0.23131
Total Iteration Time: 6.91498
Cumulative Model Updates: 171,863
Cumulative Timesteps: 1,321,124,712
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1321124712...
Checkpoint 1321124712 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.65433
Policy Entropy: 4.35316
Value Function Loss: 0.00256
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02691
Policy Update Magnitude: 0.92933
Value Function Update Magnitude: 0.70451
Collected Steps per Second: 12,963.93731
Overall Steps per Second: 7,192.83467
Timestep Collection Time: 3.85901
Timestep Consumption Time: 3.09624
PPO Batch Consumption Time: 0.22926
Total Iteration Time: 6.95526
Cumulative Model Updates: 171,872
Cumulative Timesteps: 1,321,174,740
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62818
Policy Entropy: 4.35382
Value Function Loss: 0.00252
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.91827
Value Function Update Magnitude: 0.70259
Collected Steps per Second: 12,985.13151
Overall Steps per Second: 7,320.98745
Timestep Collection Time: 3.85164
Timestep Consumption Time: 2.97996
PPO Batch Consumption Time: 0.22784
Total Iteration Time: 6.83159
Cumulative Model Updates: 171,881
Cumulative Timesteps: 1,321,224,754
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1321224754...
Checkpoint 1321224754 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.86892
Policy Entropy: 4.35278
Value Function Loss: 0.00235
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.89654
Value Function Update Magnitude: 0.67486
Collected Steps per Second: 13,224.48128
Overall Steps per Second: 7,267.93955
Timestep Collection Time: 3.78465
Timestep Consumption Time: 3.10176
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.88641
Cumulative Model Updates: 171,890
Cumulative Timesteps: 1,321,274,804
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.36407
Policy Entropy: 4.34876
Value Function Loss: 0.00250
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02701
Policy Update Magnitude: 0.90312
Value Function Update Magnitude: 0.71136
Collected Steps per Second: 13,157.24659
Overall Steps per Second: 7,246.67197
Timestep Collection Time: 3.80232
Timestep Consumption Time: 3.10127
PPO Batch Consumption Time: 0.22954
Total Iteration Time: 6.90358
Cumulative Model Updates: 171,899
Cumulative Timesteps: 1,321,324,832
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1321324832...
Checkpoint 1321324832 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73402
Policy Entropy: 4.34961
Value Function Loss: 0.00258
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02830
Policy Update Magnitude: 0.93590
Value Function Update Magnitude: 0.69733
Collected Steps per Second: 13,402.19000
Overall Steps per Second: 7,316.99252
Timestep Collection Time: 3.73297
Timestep Consumption Time: 3.10454
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.83751
Cumulative Model Updates: 171,908
Cumulative Timesteps: 1,321,374,862
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66223
Policy Entropy: 4.34982
Value Function Loss: 0.00250
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.91820
Value Function Update Magnitude: 0.69956
Collected Steps per Second: 13,282.64004
Overall Steps per Second: 7,271.92798
Timestep Collection Time: 3.76597
Timestep Consumption Time: 3.11281
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.87878
Cumulative Model Updates: 171,917
Cumulative Timesteps: 1,321,424,884
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1321424884...
Checkpoint 1321424884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49031
Policy Entropy: 4.35353
Value Function Loss: 0.00241
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.89549
Value Function Update Magnitude: 0.70508
Collected Steps per Second: 12,975.93636
Overall Steps per Second: 7,096.62217
Timestep Collection Time: 3.85344
Timestep Consumption Time: 3.19245
PPO Batch Consumption Time: 0.24360
Total Iteration Time: 7.04589
Cumulative Model Updates: 171,926
Cumulative Timesteps: 1,321,474,886
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02322
Policy Entropy: 4.35318
Value Function Loss: 0.00221
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02309
Policy Update Magnitude: 0.89613
Value Function Update Magnitude: 0.68900
Collected Steps per Second: 13,331.73947
Overall Steps per Second: 7,284.99557
Timestep Collection Time: 3.75105
Timestep Consumption Time: 3.11347
PPO Batch Consumption Time: 0.22959
Total Iteration Time: 6.86452
Cumulative Model Updates: 171,935
Cumulative Timesteps: 1,321,524,894
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1321524894...
Checkpoint 1321524894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.52922
Policy Entropy: 4.35260
Value Function Loss: 0.00225
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02303
Policy Update Magnitude: 0.88800
Value Function Update Magnitude: 0.65959
Collected Steps per Second: 13,168.16032
Overall Steps per Second: 7,214.31666
Timestep Collection Time: 3.79795
Timestep Consumption Time: 3.13438
PPO Batch Consumption Time: 0.22925
Total Iteration Time: 6.93233
Cumulative Model Updates: 171,944
Cumulative Timesteps: 1,321,574,906
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.25039
Policy Entropy: 4.35092
Value Function Loss: 0.00216
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.87046
Value Function Update Magnitude: 0.63362
Collected Steps per Second: 13,083.78769
Overall Steps per Second: 7,307.18709
Timestep Collection Time: 3.82519
Timestep Consumption Time: 3.02396
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.84915
Cumulative Model Updates: 171,953
Cumulative Timesteps: 1,321,624,954
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1321624954...
Checkpoint 1321624954 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11144
Policy Entropy: 4.35096
Value Function Loss: 0.00225
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.87017
Value Function Update Magnitude: 0.62994
Collected Steps per Second: 13,346.76725
Overall Steps per Second: 7,249.05536
Timestep Collection Time: 3.74832
Timestep Consumption Time: 3.15299
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.90131
Cumulative Model Updates: 171,962
Cumulative Timesteps: 1,321,674,982
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99323
Policy Entropy: 4.34705
Value Function Loss: 0.00232
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.87760
Value Function Update Magnitude: 0.66718
Collected Steps per Second: 13,342.46020
Overall Steps per Second: 7,292.01410
Timestep Collection Time: 3.74878
Timestep Consumption Time: 3.11050
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.85928
Cumulative Model Updates: 171,971
Cumulative Timesteps: 1,321,725,000
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1321725000...
Checkpoint 1321725000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.13589
Policy Entropy: 4.34435
Value Function Loss: 0.00232
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02336
Policy Update Magnitude: 0.87263
Value Function Update Magnitude: 0.63927
Collected Steps per Second: 13,446.92615
Overall Steps per Second: 7,324.29618
Timestep Collection Time: 3.71832
Timestep Consumption Time: 3.10827
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.82659
Cumulative Model Updates: 171,980
Cumulative Timesteps: 1,321,775,000
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.83887
Policy Entropy: 4.34551
Value Function Loss: 0.00226
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.85902
Value Function Update Magnitude: 0.64427
Collected Steps per Second: 13,212.01707
Overall Steps per Second: 7,203.21274
Timestep Collection Time: 3.78776
Timestep Consumption Time: 3.15969
PPO Batch Consumption Time: 0.23374
Total Iteration Time: 6.94746
Cumulative Model Updates: 171,989
Cumulative Timesteps: 1,321,825,044
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1321825044...
Checkpoint 1321825044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95020
Policy Entropy: 4.34955
Value Function Loss: 0.00228
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.87538
Value Function Update Magnitude: 0.66376
Collected Steps per Second: 13,063.11857
Overall Steps per Second: 7,314.67377
Timestep Collection Time: 3.83063
Timestep Consumption Time: 3.01041
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.84104
Cumulative Model Updates: 171,998
Cumulative Timesteps: 1,321,875,084
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50624
Policy Entropy: 4.34991
Value Function Loss: 0.00225
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.87800
Value Function Update Magnitude: 0.65031
Collected Steps per Second: 13,268.40348
Overall Steps per Second: 7,293.25005
Timestep Collection Time: 3.77152
Timestep Consumption Time: 3.08990
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.86141
Cumulative Model Updates: 172,007
Cumulative Timesteps: 1,321,925,126
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1321925126...
Checkpoint 1321925126 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.65169
Policy Entropy: 4.34955
Value Function Loss: 0.00237
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.89871
Value Function Update Magnitude: 0.62503
Collected Steps per Second: 12,986.58652
Overall Steps per Second: 7,191.35271
Timestep Collection Time: 3.85228
Timestep Consumption Time: 3.10441
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.95669
Cumulative Model Updates: 172,016
Cumulative Timesteps: 1,321,975,154
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.07902
Policy Entropy: 4.34982
Value Function Loss: 0.00242
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.89790
Value Function Update Magnitude: 0.61990
Collected Steps per Second: 13,122.12683
Overall Steps per Second: 7,343.37228
Timestep Collection Time: 3.81219
Timestep Consumption Time: 2.99994
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.81213
Cumulative Model Updates: 172,025
Cumulative Timesteps: 1,322,025,178
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1322025178...
Checkpoint 1322025178 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02506
Policy Entropy: 4.35129
Value Function Loss: 0.00244
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.89607
Value Function Update Magnitude: 0.62131
Collected Steps per Second: 13,153.86946
Overall Steps per Second: 7,234.73100
Timestep Collection Time: 3.80360
Timestep Consumption Time: 3.11193
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.91553
Cumulative Model Updates: 172,034
Cumulative Timesteps: 1,322,075,210
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91126
Policy Entropy: 4.35274
Value Function Loss: 0.00230
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.88160
Value Function Update Magnitude: 0.59064
Collected Steps per Second: 13,271.05108
Overall Steps per Second: 7,303.45805
Timestep Collection Time: 3.77167
Timestep Consumption Time: 3.08180
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 6.85347
Cumulative Model Updates: 172,043
Cumulative Timesteps: 1,322,125,264
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1322125264...
Checkpoint 1322125264 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.34475
Policy Entropy: 4.34966
Value Function Loss: 0.00246
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.87014
Value Function Update Magnitude: 0.62325
Collected Steps per Second: 13,507.33595
Overall Steps per Second: 7,205.75827
Timestep Collection Time: 3.70302
Timestep Consumption Time: 3.23837
PPO Batch Consumption Time: 0.24107
Total Iteration Time: 6.94139
Cumulative Model Updates: 172,052
Cumulative Timesteps: 1,322,175,282
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.88071
Policy Entropy: 4.34970
Value Function Loss: 0.00252
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.91910
Value Function Update Magnitude: 0.68969
Collected Steps per Second: 13,263.80258
Overall Steps per Second: 7,286.21637
Timestep Collection Time: 3.77117
Timestep Consumption Time: 3.09385
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.86502
Cumulative Model Updates: 172,061
Cumulative Timesteps: 1,322,225,302
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1322225302...
Checkpoint 1322225302 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.97595
Policy Entropy: 4.34932
Value Function Loss: 0.00261
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.93236
Value Function Update Magnitude: 0.72107
Collected Steps per Second: 13,165.23921
Overall Steps per Second: 7,358.69513
Timestep Collection Time: 3.79788
Timestep Consumption Time: 2.99680
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.79468
Cumulative Model Updates: 172,070
Cumulative Timesteps: 1,322,275,302
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.47630
Policy Entropy: 4.34755
Value Function Loss: 0.00248
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.91280
Value Function Update Magnitude: 0.72173
Collected Steps per Second: 13,357.13907
Overall Steps per Second: 7,301.27254
Timestep Collection Time: 3.74392
Timestep Consumption Time: 3.10530
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.84922
Cumulative Model Updates: 172,079
Cumulative Timesteps: 1,322,325,310
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1322325310...
Checkpoint 1322325310 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.45353
Policy Entropy: 4.34880
Value Function Loss: 0.00236
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.89936
Value Function Update Magnitude: 0.73434
Collected Steps per Second: 13,131.46699
Overall Steps per Second: 7,207.14824
Timestep Collection Time: 3.81039
Timestep Consumption Time: 3.13216
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.94255
Cumulative Model Updates: 172,088
Cumulative Timesteps: 1,322,375,346
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.80476
Policy Entropy: 4.34979
Value Function Loss: 0.00233
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.90465
Value Function Update Magnitude: 0.69628
Collected Steps per Second: 13,177.05116
Overall Steps per Second: 7,364.27648
Timestep Collection Time: 3.79569
Timestep Consumption Time: 2.99602
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.79171
Cumulative Model Updates: 172,097
Cumulative Timesteps: 1,322,425,362
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1322425362...
Checkpoint 1322425362 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98801
Policy Entropy: 4.34419
Value Function Loss: 0.00266
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.94202
Value Function Update Magnitude: 0.70623
Collected Steps per Second: 13,258.80321
Overall Steps per Second: 7,260.73749
Timestep Collection Time: 3.77274
Timestep Consumption Time: 3.11664
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.88938
Cumulative Model Updates: 172,106
Cumulative Timesteps: 1,322,475,384
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83842
Policy Entropy: 4.34577
Value Function Loss: 0.00280
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02992
Policy Update Magnitude: 0.96216
Value Function Update Magnitude: 0.71238
Collected Steps per Second: 13,202.35046
Overall Steps per Second: 7,145.96103
Timestep Collection Time: 3.78872
Timestep Consumption Time: 3.21104
PPO Batch Consumption Time: 0.23856
Total Iteration Time: 6.99976
Cumulative Model Updates: 172,115
Cumulative Timesteps: 1,322,525,404
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1322525404...
Checkpoint 1322525404 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65679
Policy Entropy: 4.34117
Value Function Loss: 0.00285
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.96855
Value Function Update Magnitude: 0.74064
Collected Steps per Second: 13,480.71392
Overall Steps per Second: 7,335.51460
Timestep Collection Time: 3.71227
Timestep Consumption Time: 3.10989
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.82215
Cumulative Model Updates: 172,124
Cumulative Timesteps: 1,322,575,448
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56617
Policy Entropy: 4.34939
Value Function Loss: 0.00258
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.94005
Value Function Update Magnitude: 0.74764
Collected Steps per Second: 13,360.60184
Overall Steps per Second: 7,316.50077
Timestep Collection Time: 3.74444
Timestep Consumption Time: 3.09325
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.83769
Cumulative Model Updates: 172,133
Cumulative Timesteps: 1,322,625,476
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1322625476...
Checkpoint 1322625476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04399
Policy Entropy: 4.34401
Value Function Loss: 0.00265
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.93395
Value Function Update Magnitude: 0.77093
Collected Steps per Second: 13,132.04119
Overall Steps per Second: 7,273.94028
Timestep Collection Time: 3.80855
Timestep Consumption Time: 3.06723
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.87578
Cumulative Model Updates: 172,142
Cumulative Timesteps: 1,322,675,490
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41092
Policy Entropy: 4.34434
Value Function Loss: 0.00264
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02803
Policy Update Magnitude: 0.95038
Value Function Update Magnitude: 0.76536
Collected Steps per Second: 13,565.47723
Overall Steps per Second: 7,362.30907
Timestep Collection Time: 3.68612
Timestep Consumption Time: 3.10577
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.79189
Cumulative Model Updates: 172,151
Cumulative Timesteps: 1,322,725,494
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1322725494...
Checkpoint 1322725494 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63727
Policy Entropy: 4.34316
Value Function Loss: 0.00250
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 0.93372
Value Function Update Magnitude: 0.74008
Collected Steps per Second: 13,298.01125
Overall Steps per Second: 7,204.09524
Timestep Collection Time: 3.76222
Timestep Consumption Time: 3.18244
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.94466
Cumulative Model Updates: 172,160
Cumulative Timesteps: 1,322,775,524
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.27687
Policy Entropy: 4.34430
Value Function Loss: 0.00261
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.93176
Value Function Update Magnitude: 0.72229
Collected Steps per Second: 12,985.13848
Overall Steps per Second: 7,288.99003
Timestep Collection Time: 3.85071
Timestep Consumption Time: 3.00923
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.85994
Cumulative Model Updates: 172,169
Cumulative Timesteps: 1,322,825,526
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1322825526...
Checkpoint 1322825526 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72186
Policy Entropy: 4.34555
Value Function Loss: 0.00244
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02458
Policy Update Magnitude: 0.92851
Value Function Update Magnitude: 0.73056
Collected Steps per Second: 13,119.12958
Overall Steps per Second: 7,096.99132
Timestep Collection Time: 3.81291
Timestep Consumption Time: 3.23543
PPO Batch Consumption Time: 0.23915
Total Iteration Time: 7.04834
Cumulative Model Updates: 172,178
Cumulative Timesteps: 1,322,875,548
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.39766
Policy Entropy: 4.34445
Value Function Loss: 0.00269
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.93132
Value Function Update Magnitude: 0.76181
Collected Steps per Second: 13,237.35475
Overall Steps per Second: 7,298.24332
Timestep Collection Time: 3.77840
Timestep Consumption Time: 3.07476
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.85316
Cumulative Model Updates: 172,187
Cumulative Timesteps: 1,322,925,564
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1322925564...
Checkpoint 1322925564 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83948
Policy Entropy: 4.34643
Value Function Loss: 0.00260
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.95107
Value Function Update Magnitude: 0.78138
Collected Steps per Second: 13,165.71978
Overall Steps per Second: 7,351.19245
Timestep Collection Time: 3.79820
Timestep Consumption Time: 3.00424
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.80243
Cumulative Model Updates: 172,196
Cumulative Timesteps: 1,322,975,570
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.94333
Policy Entropy: 4.34544
Value Function Loss: 0.00261
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.94485
Value Function Update Magnitude: 0.78723
Collected Steps per Second: 13,241.70428
Overall Steps per Second: 7,274.12441
Timestep Collection Time: 3.77716
Timestep Consumption Time: 3.09872
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.87588
Cumulative Model Updates: 172,205
Cumulative Timesteps: 1,323,025,586
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1323025586...
Checkpoint 1323025586 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20039
Policy Entropy: 4.34552
Value Function Loss: 0.00255
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.94745
Value Function Update Magnitude: 0.79248
Collected Steps per Second: 13,314.40791
Overall Steps per Second: 7,326.31086
Timestep Collection Time: 3.75713
Timestep Consumption Time: 3.07086
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.82799
Cumulative Model Updates: 172,214
Cumulative Timesteps: 1,323,075,610
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.57944
Policy Entropy: 4.34555
Value Function Loss: 0.00261
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.96601
Value Function Update Magnitude: 0.81561
Collected Steps per Second: 13,643.40700
Overall Steps per Second: 7,292.41574
Timestep Collection Time: 3.66580
Timestep Consumption Time: 3.19256
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.85836
Cumulative Model Updates: 172,223
Cumulative Timesteps: 1,323,125,624
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1323125624...
Checkpoint 1323125624 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.15873
Policy Entropy: 4.34506
Value Function Loss: 0.00270
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02722
Policy Update Magnitude: 0.97156
Value Function Update Magnitude: 0.82124
Collected Steps per Second: 13,306.66466
Overall Steps per Second: 7,267.67168
Timestep Collection Time: 3.75827
Timestep Consumption Time: 3.12289
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.88116
Cumulative Model Updates: 172,232
Cumulative Timesteps: 1,323,175,634
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98683
Policy Entropy: 4.34862
Value Function Loss: 0.00253
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.94800
Value Function Update Magnitude: 0.76406
Collected Steps per Second: 13,313.56139
Overall Steps per Second: 7,239.88471
Timestep Collection Time: 3.75677
Timestep Consumption Time: 3.15163
PPO Batch Consumption Time: 0.23965
Total Iteration Time: 6.90840
Cumulative Model Updates: 172,241
Cumulative Timesteps: 1,323,225,650
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1323225650...
Checkpoint 1323225650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.22305
Policy Entropy: 4.34737
Value Function Loss: 0.00253
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02653
Policy Update Magnitude: 0.92268
Value Function Update Magnitude: 0.71945
Collected Steps per Second: 13,244.26628
Overall Steps per Second: 7,261.67735
Timestep Collection Time: 3.77748
Timestep Consumption Time: 3.11211
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.88959
Cumulative Model Updates: 172,250
Cumulative Timesteps: 1,323,275,680
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.74249
Policy Entropy: 4.34621
Value Function Loss: 0.00258
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02618
Policy Update Magnitude: 0.94402
Value Function Update Magnitude: 0.75192
Collected Steps per Second: 13,244.18795
Overall Steps per Second: 7,320.05386
Timestep Collection Time: 3.77841
Timestep Consumption Time: 3.05788
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.83629
Cumulative Model Updates: 172,259
Cumulative Timesteps: 1,323,325,722
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1323325722...
Checkpoint 1323325722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93062
Policy Entropy: 4.34500
Value Function Loss: 0.00244
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02944
Policy Update Magnitude: 0.94443
Value Function Update Magnitude: 0.77648
Collected Steps per Second: 12,840.40516
Overall Steps per Second: 7,230.90160
Timestep Collection Time: 3.89443
Timestep Consumption Time: 3.02117
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.91560
Cumulative Model Updates: 172,268
Cumulative Timesteps: 1,323,375,728
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.21692
Policy Entropy: 4.34347
Value Function Loss: 0.00243
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.93293
Value Function Update Magnitude: 0.72128
Collected Steps per Second: 13,284.41010
Overall Steps per Second: 7,289.83945
Timestep Collection Time: 3.76486
Timestep Consumption Time: 3.09592
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.86078
Cumulative Model Updates: 172,277
Cumulative Timesteps: 1,323,425,742
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1323425742...
Checkpoint 1323425742 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.79348
Policy Entropy: 4.34193
Value Function Loss: 0.00258
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.93283
Value Function Update Magnitude: 0.71177
Collected Steps per Second: 13,045.37426
Overall Steps per Second: 7,243.04583
Timestep Collection Time: 3.83554
Timestep Consumption Time: 3.07261
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.90814
Cumulative Model Updates: 172,286
Cumulative Timesteps: 1,323,475,778
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22210
Policy Entropy: 4.33805
Value Function Loss: 0.00283
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.96699
Value Function Update Magnitude: 0.78712
Collected Steps per Second: 13,613.27385
Overall Steps per Second: 7,393.69491
Timestep Collection Time: 3.67494
Timestep Consumption Time: 3.09136
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.76631
Cumulative Model Updates: 172,295
Cumulative Timesteps: 1,323,525,806
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1323525806...
Checkpoint 1323525806 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00029
Policy Entropy: 4.33876
Value Function Loss: 0.00269
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.98778
Value Function Update Magnitude: 0.78596
Collected Steps per Second: 13,229.35970
Overall Steps per Second: 7,234.92295
Timestep Collection Time: 3.78098
Timestep Consumption Time: 3.13270
PPO Batch Consumption Time: 0.23278
Total Iteration Time: 6.91369
Cumulative Model Updates: 172,304
Cumulative Timesteps: 1,323,575,826
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73332
Policy Entropy: 4.33960
Value Function Loss: 0.00257
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.96175
Value Function Update Magnitude: 0.76377
Collected Steps per Second: 13,287.62422
Overall Steps per Second: 7,309.56210
Timestep Collection Time: 3.76561
Timestep Consumption Time: 3.07967
PPO Batch Consumption Time: 0.22776
Total Iteration Time: 6.84528
Cumulative Model Updates: 172,313
Cumulative Timesteps: 1,323,625,862
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1323625862...
Checkpoint 1323625862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68150
Policy Entropy: 4.34125
Value Function Loss: 0.00254
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.94363
Value Function Update Magnitude: 0.77472
Collected Steps per Second: 13,340.09710
Overall Steps per Second: 7,269.09677
Timestep Collection Time: 3.74900
Timestep Consumption Time: 3.13109
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.88008
Cumulative Model Updates: 172,322
Cumulative Timesteps: 1,323,675,874
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.01381
Policy Entropy: 4.34134
Value Function Loss: 0.00247
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.93206
Value Function Update Magnitude: 0.74750
Collected Steps per Second: 13,143.38633
Overall Steps per Second: 7,235.73071
Timestep Collection Time: 3.80587
Timestep Consumption Time: 3.10732
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.91319
Cumulative Model Updates: 172,331
Cumulative Timesteps: 1,323,725,896
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1323725896...
Checkpoint 1323725896 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35850
Policy Entropy: 4.34402
Value Function Loss: 0.00245
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.93272
Value Function Update Magnitude: 0.71853
Collected Steps per Second: 13,220.82891
Overall Steps per Second: 7,306.74543
Timestep Collection Time: 3.78403
Timestep Consumption Time: 3.06279
PPO Batch Consumption Time: 0.22921
Total Iteration Time: 6.84682
Cumulative Model Updates: 172,340
Cumulative Timesteps: 1,323,775,924
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30137
Policy Entropy: 4.34303
Value Function Loss: 0.00251
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.92524
Value Function Update Magnitude: 0.70906
Collected Steps per Second: 13,263.46431
Overall Steps per Second: 7,286.54639
Timestep Collection Time: 3.77247
Timestep Consumption Time: 3.09443
PPO Batch Consumption Time: 0.22789
Total Iteration Time: 6.86690
Cumulative Model Updates: 172,349
Cumulative Timesteps: 1,323,825,960
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1323825960...
Checkpoint 1323825960 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.63647
Policy Entropy: 4.34324
Value Function Loss: 0.00278
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.94582
Value Function Update Magnitude: 0.73175
Collected Steps per Second: 13,193.62721
Overall Steps per Second: 7,277.84718
Timestep Collection Time: 3.78986
Timestep Consumption Time: 3.08058
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.87044
Cumulative Model Updates: 172,358
Cumulative Timesteps: 1,323,875,962
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62174
Policy Entropy: 4.34027
Value Function Loss: 0.00285
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02718
Policy Update Magnitude: 0.96836
Value Function Update Magnitude: 0.79398
Collected Steps per Second: 13,240.64283
Overall Steps per Second: 7,172.97235
Timestep Collection Time: 3.77686
Timestep Consumption Time: 3.19487
PPO Batch Consumption Time: 0.24357
Total Iteration Time: 6.97173
Cumulative Model Updates: 172,367
Cumulative Timesteps: 1,323,925,970
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1323925970...
Checkpoint 1323925970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96016
Policy Entropy: 4.33696
Value Function Loss: 0.00287
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.96467
Value Function Update Magnitude: 0.79428
Collected Steps per Second: 13,160.82648
Overall Steps per Second: 7,256.07850
Timestep Collection Time: 3.79961
Timestep Consumption Time: 3.09199
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.89160
Cumulative Model Updates: 172,376
Cumulative Timesteps: 1,323,975,976
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95346
Policy Entropy: 4.34270
Value Function Loss: 0.00261
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.94315
Value Function Update Magnitude: 0.78363
Collected Steps per Second: 13,351.46793
Overall Steps per Second: 7,337.51821
Timestep Collection Time: 3.74775
Timestep Consumption Time: 3.07172
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.81947
Cumulative Model Updates: 172,385
Cumulative Timesteps: 1,324,026,014
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1324026014...
Checkpoint 1324026014 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.29438
Policy Entropy: 4.34515
Value Function Loss: 0.00255
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.92286
Value Function Update Magnitude: 0.75922
Collected Steps per Second: 13,282.82406
Overall Steps per Second: 7,259.92074
Timestep Collection Time: 3.76757
Timestep Consumption Time: 3.12562
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.89319
Cumulative Model Updates: 172,394
Cumulative Timesteps: 1,324,076,058
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46396
Policy Entropy: 4.34898
Value Function Loss: 0.00247
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.90733
Value Function Update Magnitude: 0.75603
Collected Steps per Second: 13,163.24793
Overall Steps per Second: 7,248.78953
Timestep Collection Time: 3.80073
Timestep Consumption Time: 3.10111
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.90184
Cumulative Model Updates: 172,403
Cumulative Timesteps: 1,324,126,088
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1324126088...
Checkpoint 1324126088 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.68886
Policy Entropy: 4.34496
Value Function Loss: 0.00258
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.92495
Value Function Update Magnitude: 0.73584
Collected Steps per Second: 13,247.51574
Overall Steps per Second: 7,314.19279
Timestep Collection Time: 3.77671
Timestep Consumption Time: 3.06369
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.84040
Cumulative Model Updates: 172,412
Cumulative Timesteps: 1,324,176,120
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87924
Policy Entropy: 4.34320
Value Function Loss: 0.00256
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.92551
Value Function Update Magnitude: 0.72505
Collected Steps per Second: 13,678.85197
Overall Steps per Second: 7,407.73916
Timestep Collection Time: 3.65776
Timestep Consumption Time: 3.09652
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.75429
Cumulative Model Updates: 172,421
Cumulative Timesteps: 1,324,226,154
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1324226154...
Checkpoint 1324226154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.53031
Policy Entropy: 4.34042
Value Function Loss: 0.00273
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.94156
Value Function Update Magnitude: 0.71463
Collected Steps per Second: 13,207.65645
Overall Steps per Second: 7,037.40720
Timestep Collection Time: 3.78644
Timestep Consumption Time: 3.31987
PPO Batch Consumption Time: 0.24546
Total Iteration Time: 7.10631
Cumulative Model Updates: 172,430
Cumulative Timesteps: 1,324,276,164
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.47712
Policy Entropy: 4.34312
Value Function Loss: 0.00266
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.94740
Value Function Update Magnitude: 0.69984
Collected Steps per Second: 13,124.69107
Overall Steps per Second: 7,361.90520
Timestep Collection Time: 3.81236
Timestep Consumption Time: 2.98425
PPO Batch Consumption Time: 0.22781
Total Iteration Time: 6.79661
Cumulative Model Updates: 172,439
Cumulative Timesteps: 1,324,326,200
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1324326200...
Checkpoint 1324326200 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84008
Policy Entropy: 4.34007
Value Function Loss: 0.00270
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.93349
Value Function Update Magnitude: 0.65511
Collected Steps per Second: 13,075.64762
Overall Steps per Second: 7,213.45132
Timestep Collection Time: 3.82451
Timestep Consumption Time: 3.10809
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.93260
Cumulative Model Updates: 172,448
Cumulative Timesteps: 1,324,376,208
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.61581
Policy Entropy: 4.34411
Value Function Loss: 0.00257
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.93753
Value Function Update Magnitude: 0.65278
Collected Steps per Second: 13,393.14849
Overall Steps per Second: 7,321.46246
Timestep Collection Time: 3.73415
Timestep Consumption Time: 3.09673
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.83088
Cumulative Model Updates: 172,457
Cumulative Timesteps: 1,324,426,220
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1324426220...
Checkpoint 1324426220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.43011
Policy Entropy: 4.34194
Value Function Loss: 0.00258
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02838
Policy Update Magnitude: 0.92562
Value Function Update Magnitude: 0.70849
Collected Steps per Second: 12,963.42031
Overall Steps per Second: 7,231.32538
Timestep Collection Time: 3.85762
Timestep Consumption Time: 3.05784
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.91547
Cumulative Model Updates: 172,466
Cumulative Timesteps: 1,324,476,228
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87797
Policy Entropy: 4.34377
Value Function Loss: 0.00271
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.94450
Value Function Update Magnitude: 0.73803
Collected Steps per Second: 13,247.67342
Overall Steps per Second: 7,262.33363
Timestep Collection Time: 3.77440
Timestep Consumption Time: 3.11072
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.88511
Cumulative Model Updates: 172,475
Cumulative Timesteps: 1,324,526,230
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1324526230...
Checkpoint 1324526230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16194
Policy Entropy: 4.34260
Value Function Loss: 0.00261
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02764
Policy Update Magnitude: 0.94319
Value Function Update Magnitude: 0.73176
Collected Steps per Second: 13,217.53039
Overall Steps per Second: 7,229.68233
Timestep Collection Time: 3.78573
Timestep Consumption Time: 3.13546
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.92119
Cumulative Model Updates: 172,484
Cumulative Timesteps: 1,324,576,268
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.23100
Policy Entropy: 4.34502
Value Function Loss: 0.00256
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.93158
Value Function Update Magnitude: 0.75369
Collected Steps per Second: 13,410.19032
Overall Steps per Second: 7,128.30352
Timestep Collection Time: 3.72940
Timestep Consumption Time: 3.28657
PPO Batch Consumption Time: 0.24463
Total Iteration Time: 7.01598
Cumulative Model Updates: 172,493
Cumulative Timesteps: 1,324,626,280
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1324626280...
Checkpoint 1324626280 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87811
Policy Entropy: 4.34719
Value Function Loss: 0.00236
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.90583
Value Function Update Magnitude: 0.69775
Collected Steps per Second: 13,241.67487
Overall Steps per Second: 7,283.05155
Timestep Collection Time: 3.77641
Timestep Consumption Time: 3.08967
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.86608
Cumulative Model Updates: 172,502
Cumulative Timesteps: 1,324,676,286
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33136
Policy Entropy: 4.34794
Value Function Loss: 0.00246
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02299
Policy Update Magnitude: 0.88427
Value Function Update Magnitude: 0.70057
Collected Steps per Second: 13,198.32030
Overall Steps per Second: 7,377.95731
Timestep Collection Time: 3.78988
Timestep Consumption Time: 2.98978
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.77965
Cumulative Model Updates: 172,511
Cumulative Timesteps: 1,324,726,306
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1324726306...
Checkpoint 1324726306 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.43902
Policy Entropy: 4.34300
Value Function Loss: 0.00258
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.92291
Value Function Update Magnitude: 0.72813
Collected Steps per Second: 13,293.02172
Overall Steps per Second: 7,272.58688
Timestep Collection Time: 3.76378
Timestep Consumption Time: 3.11575
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.87953
Cumulative Model Updates: 172,520
Cumulative Timesteps: 1,324,776,338
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43726
Policy Entropy: 4.34266
Value Function Loss: 0.00263
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.95841
Value Function Update Magnitude: 0.76944
Collected Steps per Second: 13,250.66256
Overall Steps per Second: 7,305.60802
Timestep Collection Time: 3.77626
Timestep Consumption Time: 3.07299
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.84926
Cumulative Model Updates: 172,529
Cumulative Timesteps: 1,324,826,376
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1324826376...
Checkpoint 1324826376 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.17407
Policy Entropy: 4.34496
Value Function Loss: 0.00253
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02633
Policy Update Magnitude: 0.93673
Value Function Update Magnitude: 0.76820
Collected Steps per Second: 13,549.85683
Overall Steps per Second: 7,364.08885
Timestep Collection Time: 3.69052
Timestep Consumption Time: 3.10000
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.79052
Cumulative Model Updates: 172,538
Cumulative Timesteps: 1,324,876,382
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.19610
Policy Entropy: 4.34741
Value Function Loss: 0.00250
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.89784
Value Function Update Magnitude: 0.73414
Collected Steps per Second: 13,111.30427
Overall Steps per Second: 7,247.53130
Timestep Collection Time: 3.81411
Timestep Consumption Time: 3.08589
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.90000
Cumulative Model Updates: 172,547
Cumulative Timesteps: 1,324,926,390
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1324926390...
Checkpoint 1324926390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.11948
Policy Entropy: 4.35050
Value Function Loss: 0.00235
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.87856
Value Function Update Magnitude: 0.71539
Collected Steps per Second: 13,116.55112
Overall Steps per Second: 7,161.24964
Timestep Collection Time: 3.81396
Timestep Consumption Time: 3.17169
PPO Batch Consumption Time: 0.23539
Total Iteration Time: 6.98565
Cumulative Model Updates: 172,556
Cumulative Timesteps: 1,324,976,416
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11913
Policy Entropy: 4.35423
Value Function Loss: 0.00233
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.88207
Value Function Update Magnitude: 0.70488
Collected Steps per Second: 13,509.11828
Overall Steps per Second: 7,338.49065
Timestep Collection Time: 3.70180
Timestep Consumption Time: 3.11268
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.81448
Cumulative Model Updates: 172,565
Cumulative Timesteps: 1,325,026,424
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1325026424...
Checkpoint 1325026424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.30446
Policy Entropy: 4.35337
Value Function Loss: 0.00229
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.87557
Value Function Update Magnitude: 0.69903
Collected Steps per Second: 13,250.75188
Overall Steps per Second: 7,284.61886
Timestep Collection Time: 3.77518
Timestep Consumption Time: 3.09189
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.86707
Cumulative Model Updates: 172,574
Cumulative Timesteps: 1,325,076,448
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.89462
Policy Entropy: 4.35309
Value Function Loss: 0.00227
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.87820
Value Function Update Magnitude: 0.67953
Collected Steps per Second: 13,207.53217
Overall Steps per Second: 7,386.92662
Timestep Collection Time: 3.78738
Timestep Consumption Time: 2.98431
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.77169
Cumulative Model Updates: 172,583
Cumulative Timesteps: 1,325,126,470
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1325126470...
Checkpoint 1325126470 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.74993
Policy Entropy: 4.34984
Value Function Loss: 0.00242
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.89099
Value Function Update Magnitude: 0.68719
Collected Steps per Second: 13,211.13046
Overall Steps per Second: 7,262.57531
Timestep Collection Time: 3.78560
Timestep Consumption Time: 3.10067
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.88626
Cumulative Model Updates: 172,592
Cumulative Timesteps: 1,325,176,482
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49850
Policy Entropy: 4.34950
Value Function Loss: 0.00242
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.91687
Value Function Update Magnitude: 0.68839
Collected Steps per Second: 13,201.20272
Overall Steps per Second: 7,267.53531
Timestep Collection Time: 3.78905
Timestep Consumption Time: 3.09361
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.88266
Cumulative Model Updates: 172,601
Cumulative Timesteps: 1,325,226,502
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1325226502...
Checkpoint 1325226502 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82109
Policy Entropy: 4.34892
Value Function Loss: 0.00250
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.92488
Value Function Update Magnitude: 0.68033
Collected Steps per Second: 13,440.10984
Overall Steps per Second: 7,343.98630
Timestep Collection Time: 3.72036
Timestep Consumption Time: 3.08821
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.80856
Cumulative Model Updates: 172,610
Cumulative Timesteps: 1,325,276,504
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56628
Policy Entropy: 4.35023
Value Function Loss: 0.00247
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.91411
Value Function Update Magnitude: 0.68108
Collected Steps per Second: 13,219.03466
Overall Steps per Second: 7,080.57498
Timestep Collection Time: 3.78530
Timestep Consumption Time: 3.28164
PPO Batch Consumption Time: 0.24264
Total Iteration Time: 7.06694
Cumulative Model Updates: 172,619
Cumulative Timesteps: 1,325,326,542
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1325326542...
Checkpoint 1325326542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.58856
Policy Entropy: 4.35286
Value Function Loss: 0.00255
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.91668
Value Function Update Magnitude: 0.67893
Collected Steps per Second: 13,059.04620
Overall Steps per Second: 7,265.91957
Timestep Collection Time: 3.83106
Timestep Consumption Time: 3.05451
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.88557
Cumulative Model Updates: 172,628
Cumulative Timesteps: 1,325,376,572
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.23188
Policy Entropy: 4.34869
Value Function Loss: 0.00266
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.93772
Value Function Update Magnitude: 0.65350
Collected Steps per Second: 13,561.07279
Overall Steps per Second: 7,354.51986
Timestep Collection Time: 3.69042
Timestep Consumption Time: 3.11438
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.80480
Cumulative Model Updates: 172,637
Cumulative Timesteps: 1,325,426,618
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1325426618...
Checkpoint 1325426618 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69834
Policy Entropy: 4.34912
Value Function Loss: 0.00254
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.93951
Value Function Update Magnitude: 0.74894
Collected Steps per Second: 13,326.13888
Overall Steps per Second: 7,317.15742
Timestep Collection Time: 3.75623
Timestep Consumption Time: 3.08468
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.84091
Cumulative Model Updates: 172,646
Cumulative Timesteps: 1,325,476,674
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.63286
Policy Entropy: 4.35246
Value Function Loss: 0.00230
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.92312
Value Function Update Magnitude: 0.70710
Collected Steps per Second: 13,121.62395
Overall Steps per Second: 7,323.45551
Timestep Collection Time: 3.81157
Timestep Consumption Time: 3.01772
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.82929
Cumulative Model Updates: 172,655
Cumulative Timesteps: 1,325,526,688
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1325526688...
Checkpoint 1325526688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.45708
Policy Entropy: 4.35187
Value Function Loss: 0.00238
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.91687
Value Function Update Magnitude: 0.65197
Collected Steps per Second: 13,137.03044
Overall Steps per Second: 7,226.71466
Timestep Collection Time: 3.80832
Timestep Consumption Time: 3.11461
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.92292
Cumulative Model Updates: 172,664
Cumulative Timesteps: 1,325,576,718
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.03556
Policy Entropy: 4.35242
Value Function Loss: 0.00253
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.92184
Value Function Update Magnitude: 0.67377
Collected Steps per Second: 13,308.69690
Overall Steps per Second: 7,299.78110
Timestep Collection Time: 3.75980
Timestep Consumption Time: 3.09493
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.85473
Cumulative Model Updates: 172,673
Cumulative Timesteps: 1,325,626,756
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1325626756...
Checkpoint 1325626756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85900
Policy Entropy: 4.35275
Value Function Loss: 0.00241
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02701
Policy Update Magnitude: 0.89594
Value Function Update Magnitude: 0.69506
Collected Steps per Second: 13,372.31547
Overall Steps per Second: 7,162.89809
Timestep Collection Time: 3.74161
Timestep Consumption Time: 3.24355
PPO Batch Consumption Time: 0.23985
Total Iteration Time: 6.98516
Cumulative Model Updates: 172,682
Cumulative Timesteps: 1,325,676,790
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32738
Policy Entropy: 4.35343
Value Function Loss: 0.00236
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.87350
Value Function Update Magnitude: 0.71793
Collected Steps per Second: 13,343.36210
Overall Steps per Second: 7,284.21015
Timestep Collection Time: 3.74988
Timestep Consumption Time: 3.11922
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.86910
Cumulative Model Updates: 172,691
Cumulative Timesteps: 1,325,726,826
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1325726826...
Checkpoint 1325726826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.80658
Policy Entropy: 4.35209
Value Function Loss: 0.00221
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02260
Policy Update Magnitude: 0.89165
Value Function Update Magnitude: 0.71574
Collected Steps per Second: 13,158.36990
Overall Steps per Second: 7,276.30627
Timestep Collection Time: 3.80199
Timestep Consumption Time: 3.07348
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.87547
Cumulative Model Updates: 172,700
Cumulative Timesteps: 1,325,776,854
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64800
Policy Entropy: 4.34978
Value Function Loss: 0.00237
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.91345
Value Function Update Magnitude: 0.76376
Collected Steps per Second: 13,514.35475
Overall Steps per Second: 7,370.47649
Timestep Collection Time: 3.70110
Timestep Consumption Time: 3.08516
PPO Batch Consumption Time: 0.22761
Total Iteration Time: 6.78626
Cumulative Model Updates: 172,709
Cumulative Timesteps: 1,325,826,872
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1325826872...
Checkpoint 1325826872 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09027
Policy Entropy: 4.34759
Value Function Loss: 0.00261
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02770
Policy Update Magnitude: 0.92895
Value Function Update Magnitude: 0.74491
Collected Steps per Second: 13,225.29379
Overall Steps per Second: 7,230.13295
Timestep Collection Time: 3.78094
Timestep Consumption Time: 3.13512
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.91606
Cumulative Model Updates: 172,718
Cumulative Timesteps: 1,325,876,876
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20334
Policy Entropy: 4.34829
Value Function Loss: 0.00283
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.95138
Value Function Update Magnitude: 0.74626
Collected Steps per Second: 13,257.48906
Overall Steps per Second: 7,375.11137
Timestep Collection Time: 3.77266
Timestep Consumption Time: 3.00907
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.78173
Cumulative Model Updates: 172,727
Cumulative Timesteps: 1,325,926,892
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1325926892...
Checkpoint 1325926892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18273
Policy Entropy: 4.34575
Value Function Loss: 0.00288
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.97105
Value Function Update Magnitude: 0.77987
Collected Steps per Second: 13,283.79538
Overall Steps per Second: 7,286.73297
Timestep Collection Time: 3.76549
Timestep Consumption Time: 3.09904
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.86453
Cumulative Model Updates: 172,736
Cumulative Timesteps: 1,325,976,912
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.96783
Policy Entropy: 4.34863
Value Function Loss: 0.00284
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.98387
Value Function Update Magnitude: 0.76342
Collected Steps per Second: 13,176.98812
Overall Steps per Second: 7,119.70626
Timestep Collection Time: 3.79540
Timestep Consumption Time: 3.22904
PPO Batch Consumption Time: 0.24049
Total Iteration Time: 7.02445
Cumulative Model Updates: 172,745
Cumulative Timesteps: 1,326,026,924
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1326026924...
Checkpoint 1326026924 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73390
Policy Entropy: 4.34744
Value Function Loss: 0.00285
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02875
Policy Update Magnitude: 0.97755
Value Function Update Magnitude: 0.75822
Collected Steps per Second: 13,116.35273
Overall Steps per Second: 7,325.09058
Timestep Collection Time: 3.81310
Timestep Consumption Time: 3.01466
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.82777
Cumulative Model Updates: 172,754
Cumulative Timesteps: 1,326,076,938
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.93883
Policy Entropy: 4.34759
Value Function Loss: 0.00287
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.97031
Value Function Update Magnitude: 0.72663
Collected Steps per Second: 13,077.46437
Overall Steps per Second: 7,226.59558
Timestep Collection Time: 3.82490
Timestep Consumption Time: 3.09675
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.92165
Cumulative Model Updates: 172,763
Cumulative Timesteps: 1,326,126,958
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1326126958...
Checkpoint 1326126958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.34060
Policy Entropy: 4.34882
Value Function Loss: 0.00264
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02668
Policy Update Magnitude: 0.93292
Value Function Update Magnitude: 0.76700
Collected Steps per Second: 13,031.43919
Overall Steps per Second: 7,312.76564
Timestep Collection Time: 3.83841
Timestep Consumption Time: 3.00168
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.84009
Cumulative Model Updates: 172,772
Cumulative Timesteps: 1,326,176,978
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.37826
Policy Entropy: 4.35019
Value Function Loss: 0.00238
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.88985
Value Function Update Magnitude: 0.73622
Collected Steps per Second: 13,208.47580
Overall Steps per Second: 7,262.59253
Timestep Collection Time: 3.78605
Timestep Consumption Time: 3.09964
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.88570
Cumulative Model Updates: 172,781
Cumulative Timesteps: 1,326,226,986
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1326226986...
Checkpoint 1326226986 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.36284
Policy Entropy: 4.34783
Value Function Loss: 0.00250
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.91426
Value Function Update Magnitude: 0.79923
Collected Steps per Second: 13,119.21166
Overall Steps per Second: 7,274.35198
Timestep Collection Time: 3.81242
Timestep Consumption Time: 3.06324
PPO Batch Consumption Time: 0.22754
Total Iteration Time: 6.87566
Cumulative Model Updates: 172,790
Cumulative Timesteps: 1,326,277,002
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26454
Policy Entropy: 4.34691
Value Function Loss: 0.00265
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.92863
Value Function Update Magnitude: 0.73252
Collected Steps per Second: 13,292.90023
Overall Steps per Second: 7,388.90723
Timestep Collection Time: 3.76141
Timestep Consumption Time: 3.00549
PPO Batch Consumption Time: 0.22787
Total Iteration Time: 6.76690
Cumulative Model Updates: 172,799
Cumulative Timesteps: 1,326,327,002
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1326327002...
Checkpoint 1326327002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.89254
Policy Entropy: 4.34616
Value Function Loss: 0.00273
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.94151
Value Function Update Magnitude: 0.71831
Collected Steps per Second: 13,217.77762
Overall Steps per Second: 7,069.16914
Timestep Collection Time: 3.78445
Timestep Consumption Time: 3.29163
PPO Batch Consumption Time: 0.24366
Total Iteration Time: 7.07608
Cumulative Model Updates: 172,808
Cumulative Timesteps: 1,326,377,024
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.50525
Policy Entropy: 4.34612
Value Function Loss: 0.00268
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02691
Policy Update Magnitude: 0.93872
Value Function Update Magnitude: 0.71515
Collected Steps per Second: 13,156.94927
Overall Steps per Second: 7,272.56176
Timestep Collection Time: 3.80347
Timestep Consumption Time: 3.07747
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.88093
Cumulative Model Updates: 172,817
Cumulative Timesteps: 1,326,427,066
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1326427066...
Checkpoint 1326427066 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.81875
Policy Entropy: 4.34303
Value Function Loss: 0.00270
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.95661
Value Function Update Magnitude: 0.75360
Collected Steps per Second: 13,381.91539
Overall Steps per Second: 7,315.89820
Timestep Collection Time: 3.73773
Timestep Consumption Time: 3.09916
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.83689
Cumulative Model Updates: 172,826
Cumulative Timesteps: 1,326,477,084
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49675
Policy Entropy: 4.34626
Value Function Loss: 0.00256
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.94463
Value Function Update Magnitude: 0.75471
Collected Steps per Second: 13,329.22310
Overall Steps per Second: 7,271.95636
Timestep Collection Time: 3.75356
Timestep Consumption Time: 3.12657
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.88013
Cumulative Model Updates: 172,835
Cumulative Timesteps: 1,326,527,116
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1326527116...
Checkpoint 1326527116 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.36731
Policy Entropy: 4.34202
Value Function Loss: 0.00272
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.96334
Value Function Update Magnitude: 0.75925
Collected Steps per Second: 13,306.37043
Overall Steps per Second: 7,313.81170
Timestep Collection Time: 3.76211
Timestep Consumption Time: 3.08248
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.84458
Cumulative Model Updates: 172,844
Cumulative Timesteps: 1,326,577,176
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91950
Policy Entropy: 4.34381
Value Function Loss: 0.00272
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02761
Policy Update Magnitude: 0.98673
Value Function Update Magnitude: 0.72349
Collected Steps per Second: 13,635.31100
Overall Steps per Second: 7,362.61255
Timestep Collection Time: 3.66915
Timestep Consumption Time: 3.12599
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.79514
Cumulative Model Updates: 172,853
Cumulative Timesteps: 1,326,627,206
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1326627206...
Checkpoint 1326627206 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42239
Policy Entropy: 4.34230
Value Function Loss: 0.00269
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03094
Policy Update Magnitude: 0.97539
Value Function Update Magnitude: 0.70779
Collected Steps per Second: 13,263.24885
Overall Steps per Second: 7,261.54911
Timestep Collection Time: 3.77223
Timestep Consumption Time: 3.11776
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.88999
Cumulative Model Updates: 172,862
Cumulative Timesteps: 1,326,677,238
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.37186
Policy Entropy: 4.34241
Value Function Loss: 0.00252
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.95541
Value Function Update Magnitude: 0.68486
Collected Steps per Second: 13,202.08677
Overall Steps per Second: 7,153.09864
Timestep Collection Time: 3.78834
Timestep Consumption Time: 3.20359
PPO Batch Consumption Time: 0.24538
Total Iteration Time: 6.99193
Cumulative Model Updates: 172,871
Cumulative Timesteps: 1,326,727,252
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1326727252...
Checkpoint 1326727252 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.18908
Policy Entropy: 4.34944
Value Function Loss: 0.00243
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.95071
Value Function Update Magnitude: 0.72450
Collected Steps per Second: 13,188.00000
Overall Steps per Second: 7,271.38865
Timestep Collection Time: 3.79148
Timestep Consumption Time: 3.08506
PPO Batch Consumption Time: 0.22797
Total Iteration Time: 6.87654
Cumulative Model Updates: 172,880
Cumulative Timesteps: 1,326,777,254
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.56778
Policy Entropy: 4.34770
Value Function Loss: 0.00259
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02933
Policy Update Magnitude: 0.95891
Value Function Update Magnitude: 0.72306
Collected Steps per Second: 13,320.28920
Overall Steps per Second: 7,330.13458
Timestep Collection Time: 3.75637
Timestep Consumption Time: 3.06969
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.82607
Cumulative Model Updates: 172,889
Cumulative Timesteps: 1,326,827,290
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1326827290...
Checkpoint 1326827290 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97111
Policy Entropy: 4.35073
Value Function Loss: 0.00250
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.94922
Value Function Update Magnitude: 0.74063
Collected Steps per Second: 13,529.81244
Overall Steps per Second: 7,379.47350
Timestep Collection Time: 3.69806
Timestep Consumption Time: 3.08210
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.78016
Cumulative Model Updates: 172,898
Cumulative Timesteps: 1,326,877,324
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87663
Policy Entropy: 4.34945
Value Function Loss: 0.00269
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.94500
Value Function Update Magnitude: 0.70232
Collected Steps per Second: 13,000.22828
Overall Steps per Second: 7,198.49754
Timestep Collection Time: 3.84747
Timestep Consumption Time: 3.10092
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.94839
Cumulative Model Updates: 172,907
Cumulative Timesteps: 1,326,927,342
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1326927342...
Checkpoint 1326927342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00676
Policy Entropy: 4.34812
Value Function Loss: 0.00280
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.97600
Value Function Update Magnitude: 0.70072
Collected Steps per Second: 13,114.05880
Overall Steps per Second: 7,250.15997
Timestep Collection Time: 3.81392
Timestep Consumption Time: 3.08468
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.89861
Cumulative Model Updates: 172,916
Cumulative Timesteps: 1,326,977,358
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66164
Policy Entropy: 4.34301
Value Function Loss: 0.00307
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 1.01985
Value Function Update Magnitude: 0.72586
Collected Steps per Second: 13,537.55134
Overall Steps per Second: 7,364.63939
Timestep Collection Time: 3.69609
Timestep Consumption Time: 3.09800
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.79409
Cumulative Model Updates: 172,925
Cumulative Timesteps: 1,327,027,394
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1327027394...
Checkpoint 1327027394 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.17330
Policy Entropy: 4.34427
Value Function Loss: 0.00292
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03060
Policy Update Magnitude: 1.01164
Value Function Update Magnitude: 0.69691
Collected Steps per Second: 13,184.21268
Overall Steps per Second: 7,047.95120
Timestep Collection Time: 3.79469
Timestep Consumption Time: 3.30383
PPO Batch Consumption Time: 0.24561
Total Iteration Time: 7.09852
Cumulative Model Updates: 172,934
Cumulative Timesteps: 1,327,077,424
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77380
Policy Entropy: 4.34513
Value Function Loss: 0.00266
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.99340
Value Function Update Magnitude: 0.70439
Collected Steps per Second: 13,262.60685
Overall Steps per Second: 7,351.71060
Timestep Collection Time: 3.77256
Timestep Consumption Time: 3.03320
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.80576
Cumulative Model Updates: 172,943
Cumulative Timesteps: 1,327,127,458
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1327127458...
Checkpoint 1327127458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85323
Policy Entropy: 4.34888
Value Function Loss: 0.00255
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.97544
Value Function Update Magnitude: 0.72833
Collected Steps per Second: 13,192.89996
Overall Steps per Second: 7,251.17434
Timestep Collection Time: 3.79068
Timestep Consumption Time: 3.10614
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.89681
Cumulative Model Updates: 172,952
Cumulative Timesteps: 1,327,177,468
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.94230
Policy Entropy: 4.34870
Value Function Loss: 0.00244
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.94810
Value Function Update Magnitude: 0.71389
Collected Steps per Second: 13,227.42924
Overall Steps per Second: 7,292.82747
Timestep Collection Time: 3.78002
Timestep Consumption Time: 3.07603
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.85605
Cumulative Model Updates: 172,961
Cumulative Timesteps: 1,327,227,468
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1327227468...
Checkpoint 1327227468 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.01840
Policy Entropy: 4.34886
Value Function Loss: 0.00246
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02627
Policy Update Magnitude: 0.96295
Value Function Update Magnitude: 0.75947
Collected Steps per Second: 13,308.07023
Overall Steps per Second: 7,396.21116
Timestep Collection Time: 3.75847
Timestep Consumption Time: 3.00418
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.76265
Cumulative Model Updates: 172,970
Cumulative Timesteps: 1,327,277,486
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37324
Policy Entropy: 4.34907
Value Function Loss: 0.00244
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02613
Policy Update Magnitude: 0.96353
Value Function Update Magnitude: 0.72441
Collected Steps per Second: 13,371.43586
Overall Steps per Second: 7,297.95143
Timestep Collection Time: 3.73931
Timestep Consumption Time: 3.11192
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.85124
Cumulative Model Updates: 172,979
Cumulative Timesteps: 1,327,327,486
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1327327486...
Checkpoint 1327327486 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74803
Policy Entropy: 4.34993
Value Function Loss: 0.00242
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.93778
Value Function Update Magnitude: 0.70834
Collected Steps per Second: 13,175.63342
Overall Steps per Second: 7,282.59727
Timestep Collection Time: 3.79701
Timestep Consumption Time: 3.07252
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.86953
Cumulative Model Updates: 172,988
Cumulative Timesteps: 1,327,377,514
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.18630
Policy Entropy: 4.35057
Value Function Loss: 0.00232
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.93162
Value Function Update Magnitude: 0.71475
Collected Steps per Second: 13,472.76584
Overall Steps per Second: 7,196.69036
Timestep Collection Time: 3.71164
Timestep Consumption Time: 3.23684
PPO Batch Consumption Time: 0.23817
Total Iteration Time: 6.94847
Cumulative Model Updates: 172,997
Cumulative Timesteps: 1,327,427,520
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1327427520...
Checkpoint 1327427520 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.22604
Policy Entropy: 4.35319
Value Function Loss: 0.00217
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02357
Policy Update Magnitude: 0.91274
Value Function Update Magnitude: 0.69244
Collected Steps per Second: 13,236.98402
Overall Steps per Second: 7,242.88769
Timestep Collection Time: 3.78077
Timestep Consumption Time: 3.12890
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.90968
Cumulative Model Updates: 173,006
Cumulative Timesteps: 1,327,477,566
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.26021
Policy Entropy: 4.35472
Value Function Loss: 0.00235
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.93172
Value Function Update Magnitude: 0.67969
Collected Steps per Second: 13,240.76689
Overall Steps per Second: 7,369.72977
Timestep Collection Time: 3.77833
Timestep Consumption Time: 3.00998
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.78831
Cumulative Model Updates: 173,015
Cumulative Timesteps: 1,327,527,594
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1327527594...
Checkpoint 1327527594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.80446
Policy Entropy: 4.35270
Value Function Loss: 0.00235
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.90994
Value Function Update Magnitude: 0.73114
Collected Steps per Second: 13,076.44448
Overall Steps per Second: 7,213.29004
Timestep Collection Time: 3.82382
Timestep Consumption Time: 3.10810
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.93193
Cumulative Model Updates: 173,024
Cumulative Timesteps: 1,327,577,596
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.50707
Policy Entropy: 4.35231
Value Function Loss: 0.00239
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.90120
Value Function Update Magnitude: 0.69761
Collected Steps per Second: 13,293.91184
Overall Steps per Second: 7,323.12636
Timestep Collection Time: 3.76323
Timestep Consumption Time: 3.06828
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.83151
Cumulative Model Updates: 173,033
Cumulative Timesteps: 1,327,627,624
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1327627624...
Checkpoint 1327627624 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.70359
Policy Entropy: 4.35252
Value Function Loss: 0.00232
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02224
Policy Update Magnitude: 0.89527
Value Function Update Magnitude: 0.68584
Collected Steps per Second: 13,013.12783
Overall Steps per Second: 7,265.92391
Timestep Collection Time: 3.84381
Timestep Consumption Time: 3.04038
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.88419
Cumulative Model Updates: 173,042
Cumulative Timesteps: 1,327,677,644
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.39348
Policy Entropy: 4.35319
Value Function Loss: 0.00232
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02352
Policy Update Magnitude: 0.88737
Value Function Update Magnitude: 0.69307
Collected Steps per Second: 13,223.73472
Overall Steps per Second: 7,246.62661
Timestep Collection Time: 3.78184
Timestep Consumption Time: 3.11931
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.90114
Cumulative Model Updates: 173,051
Cumulative Timesteps: 1,327,727,654
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1327727654...
Checkpoint 1327727654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19388
Policy Entropy: 4.35092
Value Function Loss: 0.00238
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.88329
Value Function Update Magnitude: 0.70748
Collected Steps per Second: 13,115.98035
Overall Steps per Second: 7,061.27126
Timestep Collection Time: 3.81275
Timestep Consumption Time: 3.26926
PPO Batch Consumption Time: 0.24581
Total Iteration Time: 7.08201
Cumulative Model Updates: 173,060
Cumulative Timesteps: 1,327,777,662
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.01085
Policy Entropy: 4.34697
Value Function Loss: 0.00255
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.90637
Value Function Update Magnitude: 0.71847
Collected Steps per Second: 13,642.42489
Overall Steps per Second: 7,386.82063
Timestep Collection Time: 3.66621
Timestep Consumption Time: 3.10477
PPO Batch Consumption Time: 0.22773
Total Iteration Time: 6.77098
Cumulative Model Updates: 173,069
Cumulative Timesteps: 1,327,827,678
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1327827678...
Checkpoint 1327827678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.52802
Policy Entropy: 4.34554
Value Function Loss: 0.00257
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.92740
Value Function Update Magnitude: 0.71410
Collected Steps per Second: 13,180.79410
Overall Steps per Second: 7,219.61935
Timestep Collection Time: 3.79613
Timestep Consumption Time: 3.13443
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.93056
Cumulative Model Updates: 173,078
Cumulative Timesteps: 1,327,877,714
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.69912
Policy Entropy: 4.34381
Value Function Loss: 0.00269
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.93983
Value Function Update Magnitude: 0.72066
Collected Steps per Second: 13,119.06386
Overall Steps per Second: 7,249.66319
Timestep Collection Time: 3.81140
Timestep Consumption Time: 3.08575
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.89715
Cumulative Model Updates: 173,087
Cumulative Timesteps: 1,327,927,716
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1327927716...
Checkpoint 1327927716 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.27453
Policy Entropy: 4.34651
Value Function Loss: 0.00255
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.94576
Value Function Update Magnitude: 0.67874
Collected Steps per Second: 13,409.37589
Overall Steps per Second: 7,319.15587
Timestep Collection Time: 3.73202
Timestep Consumption Time: 3.10538
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.83740
Cumulative Model Updates: 173,096
Cumulative Timesteps: 1,327,977,760
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49985
Policy Entropy: 4.34856
Value Function Loss: 0.00251
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.91916
Value Function Update Magnitude: 0.66717
Collected Steps per Second: 13,207.98444
Overall Steps per Second: 7,286.07886
Timestep Collection Time: 3.78589
Timestep Consumption Time: 3.07706
PPO Batch Consumption Time: 0.22776
Total Iteration Time: 6.86295
Cumulative Model Updates: 173,105
Cumulative Timesteps: 1,328,027,764
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1328027764...
Checkpoint 1328027764 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.99816
Policy Entropy: 4.34982
Value Function Loss: 0.00250
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.89363
Value Function Update Magnitude: 0.70972
Collected Steps per Second: 13,202.50119
Overall Steps per Second: 7,358.14387
Timestep Collection Time: 3.78807
Timestep Consumption Time: 3.00875
PPO Batch Consumption Time: 0.22797
Total Iteration Time: 6.79682
Cumulative Model Updates: 173,114
Cumulative Timesteps: 1,328,077,776
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.15353
Policy Entropy: 4.35260
Value Function Loss: 0.00220
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02478
Policy Update Magnitude: 0.87907
Value Function Update Magnitude: 0.69851
Collected Steps per Second: 13,203.36119
Overall Steps per Second: 7,184.01823
Timestep Collection Time: 3.78888
Timestep Consumption Time: 3.17463
PPO Batch Consumption Time: 0.23660
Total Iteration Time: 6.96351
Cumulative Model Updates: 173,123
Cumulative Timesteps: 1,328,127,802
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1328127802...
Checkpoint 1328127802 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.59088
Policy Entropy: 4.35006
Value Function Loss: 0.00230
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.88631
Value Function Update Magnitude: 0.69093
Collected Steps per Second: 13,155.56000
Overall Steps per Second: 7,299.65130
Timestep Collection Time: 3.80128
Timestep Consumption Time: 3.04946
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.85074
Cumulative Model Updates: 173,132
Cumulative Timesteps: 1,328,177,810
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.11134
Policy Entropy: 4.35089
Value Function Loss: 0.00230
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02357
Policy Update Magnitude: 0.89960
Value Function Update Magnitude: 0.72607
Collected Steps per Second: 13,505.74751
Overall Steps per Second: 7,328.21020
Timestep Collection Time: 3.70464
Timestep Consumption Time: 3.12294
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.82759
Cumulative Model Updates: 173,141
Cumulative Timesteps: 1,328,227,844
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1328227844...
Checkpoint 1328227844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.35051
Policy Entropy: 4.35096
Value Function Loss: 0.00223
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.88947
Value Function Update Magnitude: 0.70444
Collected Steps per Second: 13,280.36942
Overall Steps per Second: 7,309.59748
Timestep Collection Time: 3.76571
Timestep Consumption Time: 3.07598
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.84169
Cumulative Model Updates: 173,150
Cumulative Timesteps: 1,328,277,854
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.74001
Policy Entropy: 4.35479
Value Function Loss: 0.00216
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02305
Policy Update Magnitude: 0.86855
Value Function Update Magnitude: 0.63437
Collected Steps per Second: 13,154.91827
Overall Steps per Second: 7,287.98771
Timestep Collection Time: 3.80132
Timestep Consumption Time: 3.06011
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.86143
Cumulative Model Updates: 173,159
Cumulative Timesteps: 1,328,327,860
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1328327860...
Checkpoint 1328327860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.41313
Policy Entropy: 4.35551
Value Function Loss: 0.00216
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02314
Policy Update Magnitude: 0.86761
Value Function Update Magnitude: 0.68188
Collected Steps per Second: 13,482.79032
Overall Steps per Second: 7,343.15305
Timestep Collection Time: 3.71051
Timestep Consumption Time: 3.10237
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.81288
Cumulative Model Updates: 173,168
Cumulative Timesteps: 1,328,377,888
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.96994
Policy Entropy: 4.35348
Value Function Loss: 0.00240
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.89128
Value Function Update Magnitude: 0.69842
Collected Steps per Second: 13,278.43745
Overall Steps per Second: 7,284.50977
Timestep Collection Time: 3.76776
Timestep Consumption Time: 3.10024
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.86800
Cumulative Model Updates: 173,177
Cumulative Timesteps: 1,328,427,918
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1328427918...
Checkpoint 1328427918 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.21016
Policy Entropy: 4.35153
Value Function Loss: 0.00232
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02446
Policy Update Magnitude: 0.90801
Value Function Update Magnitude: 0.73259
Collected Steps per Second: 12,958.00333
Overall Steps per Second: 7,164.76826
Timestep Collection Time: 3.85908
Timestep Consumption Time: 3.12035
PPO Batch Consumption Time: 0.23777
Total Iteration Time: 6.97943
Cumulative Model Updates: 173,186
Cumulative Timesteps: 1,328,477,924
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81467
Policy Entropy: 4.35011
Value Function Loss: 0.00249
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.91377
Value Function Update Magnitude: 0.71573
Collected Steps per Second: 13,303.28490
Overall Steps per Second: 7,304.50878
Timestep Collection Time: 3.75997
Timestep Consumption Time: 3.08785
PPO Batch Consumption Time: 0.22755
Total Iteration Time: 6.84783
Cumulative Model Updates: 173,195
Cumulative Timesteps: 1,328,527,944
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1328527944...
Checkpoint 1328527944 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.91843
Policy Entropy: 4.34917
Value Function Loss: 0.00235
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.91088
Value Function Update Magnitude: 0.69771
Collected Steps per Second: 13,116.57273
Overall Steps per Second: 7,257.26594
Timestep Collection Time: 3.81334
Timestep Consumption Time: 3.07878
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.89213
Cumulative Model Updates: 173,204
Cumulative Timesteps: 1,328,577,962
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85812
Policy Entropy: 4.34613
Value Function Loss: 0.00252
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.90759
Value Function Update Magnitude: 0.71469
Collected Steps per Second: 13,353.47544
Overall Steps per Second: 7,386.30208
Timestep Collection Time: 3.74479
Timestep Consumption Time: 3.02531
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.77010
Cumulative Model Updates: 173,213
Cumulative Timesteps: 1,328,627,968
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1328627968...
Checkpoint 1328627968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.92367
Policy Entropy: 4.34698
Value Function Loss: 0.00243
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.92798
Value Function Update Magnitude: 0.73054
Collected Steps per Second: 13,242.02064
Overall Steps per Second: 7,245.40387
Timestep Collection Time: 3.77767
Timestep Consumption Time: 3.12657
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.90424
Cumulative Model Updates: 173,222
Cumulative Timesteps: 1,328,677,992
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.37648
Policy Entropy: 4.34435
Value Function Loss: 0.00256
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.94509
Value Function Update Magnitude: 0.69261
Collected Steps per Second: 13,267.82827
Overall Steps per Second: 7,404.68610
Timestep Collection Time: 3.76942
Timestep Consumption Time: 2.98468
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.75410
Cumulative Model Updates: 173,231
Cumulative Timesteps: 1,328,728,004
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1328728004...
Checkpoint 1328728004 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.84863
Policy Entropy: 4.34938
Value Function Loss: 0.00248
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.93400
Value Function Update Magnitude: 0.68968
Collected Steps per Second: 13,323.69060
Overall Steps per Second: 7,255.57036
Timestep Collection Time: 3.75482
Timestep Consumption Time: 3.14030
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.89512
Cumulative Model Updates: 173,240
Cumulative Timesteps: 1,328,778,032
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62449
Policy Entropy: 4.35010
Value Function Loss: 0.00250
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.91532
Value Function Update Magnitude: 0.69232
Collected Steps per Second: 13,233.43312
Overall Steps per Second: 7,131.02262
Timestep Collection Time: 3.77952
Timestep Consumption Time: 3.23434
PPO Batch Consumption Time: 0.23987
Total Iteration Time: 7.01386
Cumulative Model Updates: 173,249
Cumulative Timesteps: 1,328,828,048
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1328828048...
Checkpoint 1328828048 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.75598
Policy Entropy: 4.35226
Value Function Loss: 0.00230
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02305
Policy Update Magnitude: 0.91887
Value Function Update Magnitude: 0.71344
Collected Steps per Second: 13,068.52362
Overall Steps per Second: 7,329.30858
Timestep Collection Time: 3.82798
Timestep Consumption Time: 2.99750
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.82547
Cumulative Model Updates: 173,258
Cumulative Timesteps: 1,328,878,074
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.72575
Policy Entropy: 4.35051
Value Function Loss: 0.00238
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.93469
Value Function Update Magnitude: 0.73163
Collected Steps per Second: 13,264.60977
Overall Steps per Second: 7,274.68027
Timestep Collection Time: 3.77169
Timestep Consumption Time: 3.10559
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.87728
Cumulative Model Updates: 173,267
Cumulative Timesteps: 1,328,928,104
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1328928104...
Checkpoint 1328928104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.42612
Policy Entropy: 4.34621
Value Function Loss: 0.00239
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.93865
Value Function Update Magnitude: 0.73081
Collected Steps per Second: 13,179.89353
Overall Steps per Second: 7,278.23045
Timestep Collection Time: 3.79578
Timestep Consumption Time: 3.07787
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.87365
Cumulative Model Updates: 173,276
Cumulative Timesteps: 1,328,978,132
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09041
Policy Entropy: 4.34610
Value Function Loss: 0.00259
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.95643
Value Function Update Magnitude: 0.72563
Collected Steps per Second: 13,537.93239
Overall Steps per Second: 7,355.20681
Timestep Collection Time: 3.69613
Timestep Consumption Time: 3.10694
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.80307
Cumulative Model Updates: 173,285
Cumulative Timesteps: 1,329,028,170
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1329028170...
Checkpoint 1329028170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83714
Policy Entropy: 4.34655
Value Function Loss: 0.00266
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.95726
Value Function Update Magnitude: 0.74593
Collected Steps per Second: 13,142.66213
Overall Steps per Second: 7,240.65445
Timestep Collection Time: 3.80745
Timestep Consumption Time: 3.10353
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.91098
Cumulative Model Updates: 173,294
Cumulative Timesteps: 1,329,078,210
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.24522
Policy Entropy: 4.34784
Value Function Loss: 0.00251
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.93206
Value Function Update Magnitude: 0.78044
Collected Steps per Second: 13,122.03154
Overall Steps per Second: 7,277.40630
Timestep Collection Time: 3.81237
Timestep Consumption Time: 3.06179
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.87415
Cumulative Model Updates: 173,303
Cumulative Timesteps: 1,329,128,236
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1329128236...
Checkpoint 1329128236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.41709
Policy Entropy: 4.34805
Value Function Loss: 0.00266
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02690
Policy Update Magnitude: 0.94649
Value Function Update Magnitude: 0.70975
Collected Steps per Second: 13,396.25835
Overall Steps per Second: 7,103.22110
Timestep Collection Time: 3.73462
Timestep Consumption Time: 3.30866
PPO Batch Consumption Time: 0.24523
Total Iteration Time: 7.04328
Cumulative Model Updates: 173,312
Cumulative Timesteps: 1,329,178,266
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.58827
Policy Entropy: 4.34640
Value Function Loss: 0.00266
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.95687
Value Function Update Magnitude: 0.77294
Collected Steps per Second: 13,203.19723
Overall Steps per Second: 7,256.61096
Timestep Collection Time: 3.78999
Timestep Consumption Time: 3.10579
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.89578
Cumulative Model Updates: 173,321
Cumulative Timesteps: 1,329,228,306
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1329228306...
Checkpoint 1329228306 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.58709
Policy Entropy: 4.34651
Value Function Loss: 0.00260
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02682
Policy Update Magnitude: 0.95699
Value Function Update Magnitude: 0.76516
Collected Steps per Second: 13,172.96135
Overall Steps per Second: 7,330.47815
Timestep Collection Time: 3.79717
Timestep Consumption Time: 3.02639
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.82357
Cumulative Model Updates: 173,330
Cumulative Timesteps: 1,329,278,326
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.72668
Policy Entropy: 4.34539
Value Function Loss: 0.00257
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.97003
Value Function Update Magnitude: 0.71780
Collected Steps per Second: 13,310.43725
Overall Steps per Second: 7,262.76635
Timestep Collection Time: 3.75645
Timestep Consumption Time: 3.12798
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.88443
Cumulative Model Updates: 173,339
Cumulative Timesteps: 1,329,328,326
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1329328326...
Checkpoint 1329328326 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.47104
Policy Entropy: 4.34645
Value Function Loss: 0.00262
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.98800
Value Function Update Magnitude: 0.71936
Collected Steps per Second: 13,068.53080
Overall Steps per Second: 7,254.11910
Timestep Collection Time: 3.82721
Timestep Consumption Time: 3.06763
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.89484
Cumulative Model Updates: 173,348
Cumulative Timesteps: 1,329,378,342
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63740
Policy Entropy: 4.34606
Value Function Loss: 0.00267
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.97822
Value Function Update Magnitude: 0.73232
Collected Steps per Second: 13,537.48906
Overall Steps per Second: 7,354.94211
Timestep Collection Time: 3.69492
Timestep Consumption Time: 3.10594
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.80087
Cumulative Model Updates: 173,357
Cumulative Timesteps: 1,329,428,362
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1329428362...
Checkpoint 1329428362 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87588
Policy Entropy: 4.34499
Value Function Loss: 0.00249
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02682
Policy Update Magnitude: 0.95754
Value Function Update Magnitude: 0.71564
Collected Steps per Second: 13,199.99879
Overall Steps per Second: 7,225.75420
Timestep Collection Time: 3.79152
Timestep Consumption Time: 3.13482
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.92634
Cumulative Model Updates: 173,366
Cumulative Timesteps: 1,329,478,410
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72799
Policy Entropy: 4.34692
Value Function Loss: 0.00263
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.96957
Value Function Update Magnitude: 0.72176
Collected Steps per Second: 13,347.82332
Overall Steps per Second: 7,276.53645
Timestep Collection Time: 3.74668
Timestep Consumption Time: 3.12610
PPO Batch Consumption Time: 0.23277
Total Iteration Time: 6.87278
Cumulative Model Updates: 173,375
Cumulative Timesteps: 1,329,528,420
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1329528420...
Checkpoint 1329528420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.75289
Policy Entropy: 4.34437
Value Function Loss: 0.00279
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.98893
Value Function Update Magnitude: 0.78396
Collected Steps per Second: 13,395.82182
Overall Steps per Second: 7,331.50303
Timestep Collection Time: 3.73490
Timestep Consumption Time: 3.08935
PPO Batch Consumption Time: 0.22774
Total Iteration Time: 6.82425
Cumulative Model Updates: 173,384
Cumulative Timesteps: 1,329,578,452
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06147
Policy Entropy: 4.34289
Value Function Loss: 0.00273
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.98424
Value Function Update Magnitude: 0.75018
Collected Steps per Second: 13,116.33309
Overall Steps per Second: 7,208.46215
Timestep Collection Time: 3.81402
Timestep Consumption Time: 3.12588
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.93990
Cumulative Model Updates: 173,393
Cumulative Timesteps: 1,329,628,478
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1329628478...
Checkpoint 1329628478 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.10704
Policy Entropy: 4.34207
Value Function Loss: 0.00245
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02761
Policy Update Magnitude: 0.94879
Value Function Update Magnitude: 0.71325
Collected Steps per Second: 13,212.55567
Overall Steps per Second: 7,355.26362
Timestep Collection Time: 3.78443
Timestep Consumption Time: 3.01369
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.79812
Cumulative Model Updates: 173,402
Cumulative Timesteps: 1,329,678,480
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82264
Policy Entropy: 4.34480
Value Function Loss: 0.00247
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.94435
Value Function Update Magnitude: 0.70491
Collected Steps per Second: 13,264.78746
Overall Steps per Second: 7,265.47569
Timestep Collection Time: 3.77028
Timestep Consumption Time: 3.11323
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.88351
Cumulative Model Updates: 173,411
Cumulative Timesteps: 1,329,728,492
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1329728492...
Checkpoint 1329728492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.58141
Policy Entropy: 4.34880
Value Function Loss: 0.00236
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02567
Policy Update Magnitude: 0.92985
Value Function Update Magnitude: 0.68991
Collected Steps per Second: 13,271.26419
Overall Steps per Second: 7,310.82281
Timestep Collection Time: 3.76829
Timestep Consumption Time: 3.07225
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.84054
Cumulative Model Updates: 173,420
Cumulative Timesteps: 1,329,778,502
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72658
Policy Entropy: 4.34959
Value Function Loss: 0.00246
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.90797
Value Function Update Magnitude: 0.66122
Collected Steps per Second: 13,241.44299
Overall Steps per Second: 7,364.67252
Timestep Collection Time: 3.78116
Timestep Consumption Time: 3.01724
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.79840
Cumulative Model Updates: 173,429
Cumulative Timesteps: 1,329,828,570
Timesteps Collected: 50,068
--------END ITERATION REPORT--------
Saving checkpoint 1329828570...
Checkpoint 1329828570 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.77374
Policy Entropy: 4.34960
Value Function Loss: 0.00242
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.90574
Value Function Update Magnitude: 0.66236
Collected Steps per Second: 13,179.62809
Overall Steps per Second: 7,167.02140
Timestep Collection Time: 3.79571
Timestep Consumption Time: 3.18432
PPO Batch Consumption Time: 0.23291
Total Iteration Time: 6.98003
Cumulative Model Updates: 173,438
Cumulative Timesteps: 1,329,878,596
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13067
Policy Entropy: 4.34676
Value Function Loss: 0.00248
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.91539
Value Function Update Magnitude: 0.70159
Collected Steps per Second: 13,234.18604
Overall Steps per Second: 7,288.90727
Timestep Collection Time: 3.77945
Timestep Consumption Time: 3.08275
PPO Batch Consumption Time: 0.22763
Total Iteration Time: 6.86221
Cumulative Model Updates: 173,447
Cumulative Timesteps: 1,329,928,614
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1329928614...
Checkpoint 1329928614 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.50462
Policy Entropy: 4.34604
Value Function Loss: 0.00261
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.93208
Value Function Update Magnitude: 0.70971
Collected Steps per Second: 13,253.07557
Overall Steps per Second: 7,275.67940
Timestep Collection Time: 3.77467
Timestep Consumption Time: 3.10111
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.87578
Cumulative Model Updates: 173,456
Cumulative Timesteps: 1,329,978,640
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.16129
Policy Entropy: 4.34856
Value Function Loss: 0.00250
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.93029
Value Function Update Magnitude: 0.68184
Collected Steps per Second: 13,268.79606
Overall Steps per Second: 7,271.96982
Timestep Collection Time: 3.76929
Timestep Consumption Time: 3.10835
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.87764
Cumulative Model Updates: 173,465
Cumulative Timesteps: 1,330,028,654
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1330028654...
Checkpoint 1330028654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.11869
Policy Entropy: 4.34658
Value Function Loss: 0.00263
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02425
Policy Update Magnitude: 0.94387
Value Function Update Magnitude: 0.70873
Collected Steps per Second: 13,176.41621
Overall Steps per Second: 7,347.03448
Timestep Collection Time: 3.79709
Timestep Consumption Time: 3.01274
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.80982
Cumulative Model Updates: 173,474
Cumulative Timesteps: 1,330,078,686
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.06076
Policy Entropy: 4.34578
Value Function Loss: 0.00262
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02548
Policy Update Magnitude: 0.96152
Value Function Update Magnitude: 0.71994
Collected Steps per Second: 13,459.39880
Overall Steps per Second: 7,333.00890
Timestep Collection Time: 3.71725
Timestep Consumption Time: 3.10559
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.82285
Cumulative Model Updates: 173,483
Cumulative Timesteps: 1,330,128,718
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1330128718...
Checkpoint 1330128718 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.29060
Policy Entropy: 4.34510
Value Function Loss: 0.00257
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02702
Policy Update Magnitude: 0.96554
Value Function Update Magnitude: 0.73711
Collected Steps per Second: 13,109.37457
Overall Steps per Second: 7,256.45559
Timestep Collection Time: 3.81483
Timestep Consumption Time: 3.07697
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.89179
Cumulative Model Updates: 173,492
Cumulative Timesteps: 1,330,178,728
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.37484
Policy Entropy: 4.34554
Value Function Loss: 0.00263
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.96772
Value Function Update Magnitude: 0.78058
Collected Steps per Second: 13,189.66024
Overall Steps per Second: 7,171.06901
Timestep Collection Time: 3.79479
Timestep Consumption Time: 3.18492
PPO Batch Consumption Time: 0.24102
Total Iteration Time: 6.97971
Cumulative Model Updates: 173,501
Cumulative Timesteps: 1,330,228,780
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1330228780...
Checkpoint 1330228780 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58779
Policy Entropy: 4.34369
Value Function Loss: 0.00269
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.98644
Value Function Update Magnitude: 0.77743
Collected Steps per Second: 13,165.20791
Overall Steps per Second: 7,224.17403
Timestep Collection Time: 3.79956
Timestep Consumption Time: 3.12469
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.92425
Cumulative Model Updates: 173,510
Cumulative Timesteps: 1,330,278,802
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49549
Policy Entropy: 4.34031
Value Function Loss: 0.00266
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02878
Policy Update Magnitude: 0.96292
Value Function Update Magnitude: 0.78517
Collected Steps per Second: 13,260.94770
Overall Steps per Second: 7,296.16563
Timestep Collection Time: 3.77137
Timestep Consumption Time: 3.08318
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.85456
Cumulative Model Updates: 173,519
Cumulative Timesteps: 1,330,328,814
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1330328814...
Checkpoint 1330328814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.98505
Policy Entropy: 4.34228
Value Function Loss: 0.00261
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.94339
Value Function Update Magnitude: 0.74624
Collected Steps per Second: 13,563.74800
Overall Steps per Second: 7,352.83491
Timestep Collection Time: 3.68733
Timestep Consumption Time: 3.11467
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.80200
Cumulative Model Updates: 173,528
Cumulative Timesteps: 1,330,378,828
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.61565
Policy Entropy: 4.34213
Value Function Loss: 0.00259
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.94288
Value Function Update Magnitude: 0.76062
Collected Steps per Second: 13,450.93355
Overall Steps per Second: 7,304.61673
Timestep Collection Time: 3.71736
Timestep Consumption Time: 3.12790
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.84526
Cumulative Model Updates: 173,537
Cumulative Timesteps: 1,330,428,830
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1330428830...
Checkpoint 1330428830 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87808
Policy Entropy: 4.33883
Value Function Loss: 0.00275
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 0.96291
Value Function Update Magnitude: 0.78711
Collected Steps per Second: 13,219.11454
Overall Steps per Second: 7,363.73490
Timestep Collection Time: 3.78240
Timestep Consumption Time: 3.00763
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.79003
Cumulative Model Updates: 173,546
Cumulative Timesteps: 1,330,478,830
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.27009
Policy Entropy: 4.33723
Value Function Loss: 0.00262
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02799
Policy Update Magnitude: 0.96760
Value Function Update Magnitude: 0.79209
Collected Steps per Second: 13,244.59925
Overall Steps per Second: 7,252.54476
Timestep Collection Time: 3.77633
Timestep Consumption Time: 3.12001
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.89634
Cumulative Model Updates: 173,555
Cumulative Timesteps: 1,330,528,846
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1330528846...
Checkpoint 1330528846 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80857
Policy Entropy: 4.33766
Value Function Loss: 0.00255
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02965
Policy Update Magnitude: 0.94023
Value Function Update Magnitude: 0.77712
Collected Steps per Second: 13,277.37984
Overall Steps per Second: 7,095.08475
Timestep Collection Time: 3.76656
Timestep Consumption Time: 3.28199
PPO Batch Consumption Time: 0.24519
Total Iteration Time: 7.04854
Cumulative Model Updates: 173,564
Cumulative Timesteps: 1,330,578,856
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99647
Policy Entropy: 4.34312
Value Function Loss: 0.00240
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02690
Policy Update Magnitude: 0.93116
Value Function Update Magnitude: 0.74526
Collected Steps per Second: 13,562.00739
Overall Steps per Second: 7,410.29216
Timestep Collection Time: 3.68957
Timestep Consumption Time: 3.06293
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.75250
Cumulative Model Updates: 173,573
Cumulative Timesteps: 1,330,628,894
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1330628894...
Checkpoint 1330628894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.52127
Policy Entropy: 4.34000
Value Function Loss: 0.00248
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.93651
Value Function Update Magnitude: 0.73405
Collected Steps per Second: 13,081.80611
Overall Steps per Second: 7,217.56578
Timestep Collection Time: 3.82409
Timestep Consumption Time: 3.10706
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.93115
Cumulative Model Updates: 173,582
Cumulative Timesteps: 1,330,678,920
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.52669
Policy Entropy: 4.33906
Value Function Loss: 0.00263
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.95480
Value Function Update Magnitude: 0.77475
Collected Steps per Second: 13,302.29429
Overall Steps per Second: 7,310.97308
Timestep Collection Time: 3.76146
Timestep Consumption Time: 3.08250
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.84396
Cumulative Model Updates: 173,591
Cumulative Timesteps: 1,330,728,956
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1330728956...
Checkpoint 1330728956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.34853
Policy Entropy: 4.33709
Value Function Loss: 0.00258
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02771
Policy Update Magnitude: 0.95749
Value Function Update Magnitude: 0.78158
Collected Steps per Second: 13,445.68793
Overall Steps per Second: 7,339.19885
Timestep Collection Time: 3.72179
Timestep Consumption Time: 3.09667
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.81846
Cumulative Model Updates: 173,600
Cumulative Timesteps: 1,330,778,998
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66682
Policy Entropy: 4.33935
Value Function Loss: 0.00256
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02975
Policy Update Magnitude: 0.94854
Value Function Update Magnitude: 0.71685
Collected Steps per Second: 13,290.64966
Overall Steps per Second: 7,274.52296
Timestep Collection Time: 3.76234
Timestep Consumption Time: 3.11151
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.87385
Cumulative Model Updates: 173,609
Cumulative Timesteps: 1,330,829,002
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1330829002...
Checkpoint 1330829002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.15298
Policy Entropy: 4.34510
Value Function Loss: 0.00253
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.95049
Value Function Update Magnitude: 0.71735
Collected Steps per Second: 13,103.87163
Overall Steps per Second: 7,321.94424
Timestep Collection Time: 3.81857
Timestep Consumption Time: 3.01541
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.83398
Cumulative Model Updates: 173,618
Cumulative Timesteps: 1,330,879,040
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00233
Policy Entropy: 4.34679
Value Function Loss: 0.00263
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.95812
Value Function Update Magnitude: 0.75599
Collected Steps per Second: 13,171.48990
Overall Steps per Second: 7,085.20522
Timestep Collection Time: 3.79760
Timestep Consumption Time: 3.26219
PPO Batch Consumption Time: 0.24223
Total Iteration Time: 7.05978
Cumulative Model Updates: 173,627
Cumulative Timesteps: 1,330,929,060
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1330929060...
Checkpoint 1330929060 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58388
Policy Entropy: 4.34685
Value Function Loss: 0.00258
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.96114
Value Function Update Magnitude: 0.76435
Collected Steps per Second: 13,091.32550
Overall Steps per Second: 7,246.33859
Timestep Collection Time: 3.81963
Timestep Consumption Time: 3.08096
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.90059
Cumulative Model Updates: 173,636
Cumulative Timesteps: 1,330,979,064
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87962
Policy Entropy: 4.35196
Value Function Loss: 0.00256
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.93621
Value Function Update Magnitude: 0.75938
Collected Steps per Second: 13,201.29087
Overall Steps per Second: 7,377.73008
Timestep Collection Time: 3.79024
Timestep Consumption Time: 2.99180
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.78203
Cumulative Model Updates: 173,645
Cumulative Timesteps: 1,331,029,100
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1331029100...
Checkpoint 1331029100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.31549
Policy Entropy: 4.35256
Value Function Loss: 0.00241
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.92017
Value Function Update Magnitude: 0.75961
Collected Steps per Second: 13,189.48036
Overall Steps per Second: 7,237.72842
Timestep Collection Time: 3.79378
Timestep Consumption Time: 3.11971
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.91350
Cumulative Model Updates: 173,654
Cumulative Timesteps: 1,331,079,138
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.25534
Policy Entropy: 4.35415
Value Function Loss: 0.00253
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.93096
Value Function Update Magnitude: 0.78552
Collected Steps per Second: 13,132.59787
Overall Steps per Second: 7,268.81908
Timestep Collection Time: 3.80747
Timestep Consumption Time: 3.07150
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.87897
Cumulative Model Updates: 173,663
Cumulative Timesteps: 1,331,129,140
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1331129140...
Checkpoint 1331129140 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72752
Policy Entropy: 4.35221
Value Function Loss: 0.00249
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.94447
Value Function Update Magnitude: 0.78301
Collected Steps per Second: 13,515.15175
Overall Steps per Second: 7,354.23367
Timestep Collection Time: 3.70207
Timestep Consumption Time: 3.10136
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.80343
Cumulative Model Updates: 173,672
Cumulative Timesteps: 1,331,179,174
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.21688
Policy Entropy: 4.34960
Value Function Loss: 0.00252
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.92997
Value Function Update Magnitude: 0.74927
Collected Steps per Second: 13,333.71392
Overall Steps per Second: 7,299.74539
Timestep Collection Time: 3.75214
Timestep Consumption Time: 3.10152
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.85366
Cumulative Model Updates: 173,681
Cumulative Timesteps: 1,331,229,204
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1331229204...
Checkpoint 1331229204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89658
Policy Entropy: 4.34672
Value Function Loss: 0.00262
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.93344
Value Function Update Magnitude: 0.73030
Collected Steps per Second: 13,139.26768
Overall Steps per Second: 7,258.40943
Timestep Collection Time: 3.80813
Timestep Consumption Time: 3.08539
PPO Batch Consumption Time: 0.23034
Total Iteration Time: 6.89352
Cumulative Model Updates: 173,690
Cumulative Timesteps: 1,331,279,240
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33553
Policy Entropy: 4.34488
Value Function Loss: 0.00267
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.93906
Value Function Update Magnitude: 0.73803
Collected Steps per Second: 13,538.40059
Overall Steps per Second: 7,342.25559
Timestep Collection Time: 3.69349
Timestep Consumption Time: 3.11695
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.81044
Cumulative Model Updates: 173,699
Cumulative Timesteps: 1,331,329,244
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1331329244...
Checkpoint 1331329244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.30224
Policy Entropy: 4.34433
Value Function Loss: 0.00270
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.96245
Value Function Update Magnitude: 0.71115
Collected Steps per Second: 13,176.80146
Overall Steps per Second: 7,217.87214
Timestep Collection Time: 3.79515
Timestep Consumption Time: 3.13320
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.92836
Cumulative Model Updates: 173,708
Cumulative Timesteps: 1,331,379,252
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.94255
Policy Entropy: 4.34494
Value Function Loss: 0.00258
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.95370
Value Function Update Magnitude: 0.70030
Collected Steps per Second: 13,114.98713
Overall Steps per Second: 7,338.45863
Timestep Collection Time: 3.81579
Timestep Consumption Time: 3.00363
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.81942
Cumulative Model Updates: 173,717
Cumulative Timesteps: 1,331,429,296
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1331429296...
Checkpoint 1331429296 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.68303
Policy Entropy: 4.34541
Value Function Loss: 0.00253
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.93923
Value Function Update Magnitude: 0.69740
Collected Steps per Second: 13,304.95630
Overall Steps per Second: 7,234.24662
Timestep Collection Time: 3.76055
Timestep Consumption Time: 3.15572
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.91627
Cumulative Model Updates: 173,726
Cumulative Timesteps: 1,331,479,330
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02606
Policy Entropy: 4.34987
Value Function Loss: 0.00238
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.93732
Value Function Update Magnitude: 0.70344
Collected Steps per Second: 13,299.49008
Overall Steps per Second: 7,309.57431
Timestep Collection Time: 3.76150
Timestep Consumption Time: 3.08240
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.84390
Cumulative Model Updates: 173,735
Cumulative Timesteps: 1,331,529,356
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1331529356...
Checkpoint 1331529356 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.76499
Policy Entropy: 4.34662
Value Function Loss: 0.00244
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.94480
Value Function Update Magnitude: 0.68547
Collected Steps per Second: 13,157.33506
Overall Steps per Second: 7,338.01262
Timestep Collection Time: 3.80153
Timestep Consumption Time: 3.01476
PPO Batch Consumption Time: 0.22797
Total Iteration Time: 6.81629
Cumulative Model Updates: 173,744
Cumulative Timesteps: 1,331,579,374
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.68139
Policy Entropy: 4.34473
Value Function Loss: 0.00239
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02774
Policy Update Magnitude: 0.94251
Value Function Update Magnitude: 0.69203
Collected Steps per Second: 13,307.20237
Overall Steps per Second: 7,186.58345
Timestep Collection Time: 3.75917
Timestep Consumption Time: 3.20158
PPO Batch Consumption Time: 0.23610
Total Iteration Time: 6.96075
Cumulative Model Updates: 173,753
Cumulative Timesteps: 1,331,629,398
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1331629398...
Checkpoint 1331629398 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85256
Policy Entropy: 4.34130
Value Function Loss: 0.00240
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.92095
Value Function Update Magnitude: 0.68811
Collected Steps per Second: 13,263.31676
Overall Steps per Second: 7,306.86786
Timestep Collection Time: 3.77010
Timestep Consumption Time: 3.07333
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.84342
Cumulative Model Updates: 173,762
Cumulative Timesteps: 1,331,679,402
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.55115
Policy Entropy: 4.34519
Value Function Loss: 0.00241
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.91135
Value Function Update Magnitude: 0.71818
Collected Steps per Second: 13,484.55207
Overall Steps per Second: 7,341.83921
Timestep Collection Time: 3.70898
Timestep Consumption Time: 3.10320
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.81219
Cumulative Model Updates: 173,771
Cumulative Timesteps: 1,331,729,416
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1331729416...
Checkpoint 1331729416 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35492
Policy Entropy: 4.34824
Value Function Loss: 0.00242
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.92828
Value Function Update Magnitude: 0.67567
Collected Steps per Second: 13,251.89104
Overall Steps per Second: 7,243.34647
Timestep Collection Time: 3.77501
Timestep Consumption Time: 3.13147
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.90648
Cumulative Model Updates: 173,780
Cumulative Timesteps: 1,331,779,442
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30471
Policy Entropy: 4.34721
Value Function Loss: 0.00260
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.94898
Value Function Update Magnitude: 0.66767
Collected Steps per Second: 13,061.37362
Overall Steps per Second: 7,236.06221
Timestep Collection Time: 3.82946
Timestep Consumption Time: 3.08286
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.91232
Cumulative Model Updates: 173,789
Cumulative Timesteps: 1,331,829,460
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1331829460...
Checkpoint 1331829460 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.27049
Policy Entropy: 4.34584
Value Function Loss: 0.00266
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02827
Policy Update Magnitude: 0.95300
Value Function Update Magnitude: 0.72349
Collected Steps per Second: 13,450.23957
Overall Steps per Second: 7,340.41752
Timestep Collection Time: 3.71755
Timestep Consumption Time: 3.09432
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.81187
Cumulative Model Updates: 173,798
Cumulative Timesteps: 1,331,879,462
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.84659
Policy Entropy: 4.34178
Value Function Loss: 0.00269
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.95902
Value Function Update Magnitude: 0.71341
Collected Steps per Second: 13,201.84486
Overall Steps per Second: 7,267.53636
Timestep Collection Time: 3.78886
Timestep Consumption Time: 3.09380
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.88266
Cumulative Model Updates: 173,807
Cumulative Timesteps: 1,331,929,482
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1331929482...
Checkpoint 1331929482 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75581
Policy Entropy: 4.34238
Value Function Loss: 0.00252
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.95059
Value Function Update Magnitude: 0.67390
Collected Steps per Second: 13,229.70741
Overall Steps per Second: 7,266.08335
Timestep Collection Time: 3.78164
Timestep Consumption Time: 3.10377
PPO Batch Consumption Time: 0.23636
Total Iteration Time: 6.88542
Cumulative Model Updates: 173,816
Cumulative Timesteps: 1,331,979,512
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.30002
Policy Entropy: 4.34180
Value Function Loss: 0.00252
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.95466
Value Function Update Magnitude: 0.68653
Collected Steps per Second: 13,217.59975
Overall Steps per Second: 7,269.35035
Timestep Collection Time: 3.78647
Timestep Consumption Time: 3.09833
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 6.88480
Cumulative Model Updates: 173,825
Cumulative Timesteps: 1,332,029,560
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1332029560...
Checkpoint 1332029560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.49479
Policy Entropy: 4.34458
Value Function Loss: 0.00247
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.95352
Value Function Update Magnitude: 0.68497
Collected Steps per Second: 13,171.73298
Overall Steps per Second: 7,238.73565
Timestep Collection Time: 3.79935
Timestep Consumption Time: 3.11401
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.91336
Cumulative Model Updates: 173,834
Cumulative Timesteps: 1,332,079,604
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.61294
Policy Entropy: 4.34750
Value Function Loss: 0.00230
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.93322
Value Function Update Magnitude: 0.68793
Collected Steps per Second: 13,202.99550
Overall Steps per Second: 7,350.44313
Timestep Collection Time: 3.78853
Timestep Consumption Time: 3.01650
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.80503
Cumulative Model Updates: 173,843
Cumulative Timesteps: 1,332,129,624
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1332129624...
Checkpoint 1332129624 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.07748
Policy Entropy: 4.35369
Value Function Loss: 0.00210
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.89903
Value Function Update Magnitude: 0.65487
Collected Steps per Second: 13,131.61906
Overall Steps per Second: 7,239.80716
Timestep Collection Time: 3.80760
Timestep Consumption Time: 3.09866
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.90626
Cumulative Model Updates: 173,852
Cumulative Timesteps: 1,332,179,624
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09692
Policy Entropy: 4.35112
Value Function Loss: 0.00225
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.89662
Value Function Update Magnitude: 0.64438
Collected Steps per Second: 13,001.10775
Overall Steps per Second: 7,232.36759
Timestep Collection Time: 3.84752
Timestep Consumption Time: 3.06889
PPO Batch Consumption Time: 0.22791
Total Iteration Time: 6.91641
Cumulative Model Updates: 173,861
Cumulative Timesteps: 1,332,229,646
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1332229646...
Checkpoint 1332229646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.94486
Policy Entropy: 4.35016
Value Function Loss: 0.00253
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.95184
Value Function Update Magnitude: 0.65205
Collected Steps per Second: 13,487.03472
Overall Steps per Second: 7,336.34824
Timestep Collection Time: 3.70771
Timestep Consumption Time: 3.10849
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.81620
Cumulative Model Updates: 173,870
Cumulative Timesteps: 1,332,279,652
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.59175
Policy Entropy: 4.34874
Value Function Loss: 0.00265
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.95601
Value Function Update Magnitude: 0.70026
Collected Steps per Second: 13,256.02639
Overall Steps per Second: 7,121.24077
Timestep Collection Time: 3.77353
Timestep Consumption Time: 3.25081
PPO Batch Consumption Time: 0.23968
Total Iteration Time: 7.02434
Cumulative Model Updates: 173,879
Cumulative Timesteps: 1,332,329,674
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1332329674...
Checkpoint 1332329674 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22702
Policy Entropy: 4.35527
Value Function Loss: 0.00232
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.91733
Value Function Update Magnitude: 0.72432
Collected Steps per Second: 13,156.98290
Overall Steps per Second: 7,272.75517
Timestep Collection Time: 3.80376
Timestep Consumption Time: 3.07754
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.88130
Cumulative Model Updates: 173,888
Cumulative Timesteps: 1,332,379,720
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61926
Policy Entropy: 4.35522
Value Function Loss: 0.00227
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.91761
Value Function Update Magnitude: 0.69077
Collected Steps per Second: 13,377.80116
Overall Steps per Second: 7,306.31433
Timestep Collection Time: 3.73798
Timestep Consumption Time: 3.10623
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.84422
Cumulative Model Updates: 173,897
Cumulative Timesteps: 1,332,429,726
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1332429726...
Checkpoint 1332429726 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.77324
Policy Entropy: 4.35419
Value Function Loss: 0.00238
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.93885
Value Function Update Magnitude: 0.67760
Collected Steps per Second: 13,303.88720
Overall Steps per Second: 7,268.97259
Timestep Collection Time: 3.76086
Timestep Consumption Time: 3.12237
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.88323
Cumulative Model Updates: 173,906
Cumulative Timesteps: 1,332,479,760
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97884
Policy Entropy: 4.35414
Value Function Loss: 0.00242
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.92151
Value Function Update Magnitude: 0.69818
Collected Steps per Second: 13,205.84656
Overall Steps per Second: 7,367.44497
Timestep Collection Time: 3.78620
Timestep Consumption Time: 3.00041
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.78661
Cumulative Model Updates: 173,915
Cumulative Timesteps: 1,332,529,760
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1332529760...
Checkpoint 1332529760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.65338
Policy Entropy: 4.35130
Value Function Loss: 0.00263
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.95033
Value Function Update Magnitude: 0.69610
Collected Steps per Second: 13,201.11345
Overall Steps per Second: 7,268.23056
Timestep Collection Time: 3.78771
Timestep Consumption Time: 3.09182
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.87953
Cumulative Model Updates: 173,924
Cumulative Timesteps: 1,332,579,762
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27116
Policy Entropy: 4.34936
Value Function Loss: 0.00252
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02441
Policy Update Magnitude: 0.96207
Value Function Update Magnitude: 0.72363
Collected Steps per Second: 13,209.13849
Overall Steps per Second: 7,301.09796
Timestep Collection Time: 3.78647
Timestep Consumption Time: 3.06401
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.85048
Cumulative Model Updates: 173,933
Cumulative Timesteps: 1,332,629,778
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1332629778...
Checkpoint 1332629778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85159
Policy Entropy: 4.34426
Value Function Loss: 0.00257
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.96224
Value Function Update Magnitude: 0.71518
Collected Steps per Second: 13,361.38032
Overall Steps per Second: 7,109.22571
Timestep Collection Time: 3.74258
Timestep Consumption Time: 3.29138
PPO Batch Consumption Time: 0.24532
Total Iteration Time: 7.03396
Cumulative Model Updates: 173,942
Cumulative Timesteps: 1,332,679,784
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.79496
Policy Entropy: 4.34436
Value Function Loss: 0.00245
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.96433
Value Function Update Magnitude: 0.71980
Collected Steps per Second: 13,177.28889
Overall Steps per Second: 7,252.02726
Timestep Collection Time: 3.79577
Timestep Consumption Time: 3.10133
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.89711
Cumulative Model Updates: 173,951
Cumulative Timesteps: 1,332,729,802
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1332729802...
Checkpoint 1332729802 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61713
Policy Entropy: 4.34952
Value Function Loss: 0.00253
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02360
Policy Update Magnitude: 0.93049
Value Function Update Magnitude: 0.74017
Collected Steps per Second: 13,146.82306
Overall Steps per Second: 7,268.15463
Timestep Collection Time: 3.80487
Timestep Consumption Time: 3.07748
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.88235
Cumulative Model Updates: 173,960
Cumulative Timesteps: 1,332,779,824
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.15694
Policy Entropy: 4.35057
Value Function Loss: 0.00255
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02270
Policy Update Magnitude: 0.91535
Value Function Update Magnitude: 0.73351
Collected Steps per Second: 13,502.95794
Overall Steps per Second: 7,351.94693
Timestep Collection Time: 3.70408
Timestep Consumption Time: 3.09902
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.80310
Cumulative Model Updates: 173,969
Cumulative Timesteps: 1,332,829,840
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1332829840...
Checkpoint 1332829840 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88323
Policy Entropy: 4.35059
Value Function Loss: 0.00261
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02411
Policy Update Magnitude: 0.92463
Value Function Update Magnitude: 0.73067
Collected Steps per Second: 13,062.71975
Overall Steps per Second: 7,212.08976
Timestep Collection Time: 3.82968
Timestep Consumption Time: 3.10673
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.93641
Cumulative Model Updates: 173,978
Cumulative Timesteps: 1,332,879,866
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.46163
Policy Entropy: 4.34653
Value Function Loss: 0.00266
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.92361
Value Function Update Magnitude: 0.76344
Collected Steps per Second: 13,062.46810
Overall Steps per Second: 7,346.59839
Timestep Collection Time: 3.83006
Timestep Consumption Time: 2.97990
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.80995
Cumulative Model Updates: 173,987
Cumulative Timesteps: 1,332,929,896
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1332929896...
Checkpoint 1332929896 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37083
Policy Entropy: 4.34489
Value Function Loss: 0.00255
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02618
Policy Update Magnitude: 0.94210
Value Function Update Magnitude: 0.70665
Collected Steps per Second: 13,249.08629
Overall Steps per Second: 7,234.24193
Timestep Collection Time: 3.77596
Timestep Consumption Time: 3.13949
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.91544
Cumulative Model Updates: 173,996
Cumulative Timesteps: 1,332,979,924
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97000
Policy Entropy: 4.34719
Value Function Loss: 0.00254
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.92483
Value Function Update Magnitude: 0.65997
Collected Steps per Second: 13,224.43962
Overall Steps per Second: 7,241.81065
Timestep Collection Time: 3.78284
Timestep Consumption Time: 3.12510
PPO Batch Consumption Time: 0.23298
Total Iteration Time: 6.90794
Cumulative Model Updates: 174,005
Cumulative Timesteps: 1,333,029,950
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1333029950...
Checkpoint 1333029950 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49933
Policy Entropy: 4.35070
Value Function Loss: 0.00224
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02567
Policy Update Magnitude: 0.89614
Value Function Update Magnitude: 0.64530
Collected Steps per Second: 13,569.07074
Overall Steps per Second: 7,369.20859
Timestep Collection Time: 3.68765
Timestep Consumption Time: 3.10249
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.79015
Cumulative Model Updates: 174,014
Cumulative Timesteps: 1,333,079,988
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.59353
Policy Entropy: 4.35375
Value Function Loss: 0.00234
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.90669
Value Function Update Magnitude: 0.65931
Collected Steps per Second: 13,263.96186
Overall Steps per Second: 7,230.61765
Timestep Collection Time: 3.77127
Timestep Consumption Time: 3.14681
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.91808
Cumulative Model Updates: 174,023
Cumulative Timesteps: 1,333,130,010
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1333130010...
Checkpoint 1333130010 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.87679
Policy Entropy: 4.35361
Value Function Loss: 0.00226
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.90762
Value Function Update Magnitude: 0.65086
Collected Steps per Second: 13,197.24645
Overall Steps per Second: 7,290.34057
Timestep Collection Time: 3.78928
Timestep Consumption Time: 3.07021
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.85949
Cumulative Model Updates: 174,032
Cumulative Timesteps: 1,333,180,018
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54661
Policy Entropy: 4.35158
Value Function Loss: 0.00232
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.88379
Value Function Update Magnitude: 0.65694
Collected Steps per Second: 13,568.82325
Overall Steps per Second: 7,366.40439
Timestep Collection Time: 3.68595
Timestep Consumption Time: 3.10352
PPO Batch Consumption Time: 0.22763
Total Iteration Time: 6.78947
Cumulative Model Updates: 174,041
Cumulative Timesteps: 1,333,230,032
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1333230032...
Checkpoint 1333230032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.40151
Policy Entropy: 4.34993
Value Function Loss: 0.00224
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.87644
Value Function Update Magnitude: 0.64155
Collected Steps per Second: 13,196.19856
Overall Steps per Second: 7,266.39503
Timestep Collection Time: 3.79215
Timestep Consumption Time: 3.09462
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.88677
Cumulative Model Updates: 174,050
Cumulative Timesteps: 1,333,280,074
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13679
Policy Entropy: 4.34911
Value Function Loss: 0.00226
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.89175
Value Function Update Magnitude: 0.69367
Collected Steps per Second: 13,168.47214
Overall Steps per Second: 7,335.62199
Timestep Collection Time: 3.79695
Timestep Consumption Time: 3.01911
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.81605
Cumulative Model Updates: 174,059
Cumulative Timesteps: 1,333,330,074
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1333330074...
Checkpoint 1333330074 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92036
Policy Entropy: 4.34763
Value Function Loss: 0.00233
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.89157
Value Function Update Magnitude: 0.72013
Collected Steps per Second: 13,162.73246
Overall Steps per Second: 7,166.82107
Timestep Collection Time: 3.79936
Timestep Consumption Time: 3.17863
PPO Batch Consumption Time: 0.23448
Total Iteration Time: 6.97799
Cumulative Model Updates: 174,068
Cumulative Timesteps: 1,333,380,084
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.35078
Policy Entropy: 4.34807
Value Function Loss: 0.00244
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.90204
Value Function Update Magnitude: 0.70743
Collected Steps per Second: 13,257.64863
Overall Steps per Second: 7,310.37664
Timestep Collection Time: 3.77397
Timestep Consumption Time: 3.07027
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.84424
Cumulative Model Updates: 174,077
Cumulative Timesteps: 1,333,430,118
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1333430118...
Checkpoint 1333430118 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99447
Policy Entropy: 4.34884
Value Function Loss: 0.00243
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.91041
Value Function Update Magnitude: 0.63042
Collected Steps per Second: 13,185.31314
Overall Steps per Second: 7,373.33103
Timestep Collection Time: 3.79240
Timestep Consumption Time: 2.98934
PPO Batch Consumption Time: 0.22778
Total Iteration Time: 6.78174
Cumulative Model Updates: 174,086
Cumulative Timesteps: 1,333,480,122
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77530
Policy Entropy: 4.34941
Value Function Loss: 0.00240
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.90541
Value Function Update Magnitude: 0.67923
Collected Steps per Second: 13,147.76171
Overall Steps per Second: 7,250.31599
Timestep Collection Time: 3.80582
Timestep Consumption Time: 3.09567
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.90149
Cumulative Model Updates: 174,095
Cumulative Timesteps: 1,333,530,160
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1333530160...
Checkpoint 1333530160 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.14664
Policy Entropy: 4.34991
Value Function Loss: 0.00234
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.91649
Value Function Update Magnitude: 0.69885
Collected Steps per Second: 13,168.32285
Overall Steps per Second: 7,365.45406
Timestep Collection Time: 3.79881
Timestep Consumption Time: 2.99289
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.79171
Cumulative Model Updates: 174,104
Cumulative Timesteps: 1,333,580,184
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08498
Policy Entropy: 4.34820
Value Function Loss: 0.00237
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.90702
Value Function Update Magnitude: 0.68100
Collected Steps per Second: 13,341.13499
Overall Steps per Second: 7,311.00060
Timestep Collection Time: 3.75066
Timestep Consumption Time: 3.09355
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.84421
Cumulative Model Updates: 174,113
Cumulative Timesteps: 1,333,630,222
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1333630222...
Checkpoint 1333630222 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30485
Policy Entropy: 4.34517
Value Function Loss: 0.00254
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.92505
Value Function Update Magnitude: 0.65362
Collected Steps per Second: 13,066.10713
Overall Steps per Second: 7,273.76250
Timestep Collection Time: 3.82991
Timestep Consumption Time: 3.04989
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.87980
Cumulative Model Updates: 174,122
Cumulative Timesteps: 1,333,680,264
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.66562
Policy Entropy: 4.34643
Value Function Loss: 0.00249
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.93677
Value Function Update Magnitude: 0.63942
Collected Steps per Second: 13,066.06992
Overall Steps per Second: 7,174.09594
Timestep Collection Time: 3.82900
Timestep Consumption Time: 3.14470
PPO Batch Consumption Time: 0.23995
Total Iteration Time: 6.97370
Cumulative Model Updates: 174,131
Cumulative Timesteps: 1,333,730,294
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1333730294...
Checkpoint 1333730294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87192
Policy Entropy: 4.34870
Value Function Loss: 0.00238
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.90401
Value Function Update Magnitude: 0.61392
Collected Steps per Second: 13,192.23760
Overall Steps per Second: 7,254.29061
Timestep Collection Time: 3.79011
Timestep Consumption Time: 3.10237
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.89247
Cumulative Model Updates: 174,140
Cumulative Timesteps: 1,333,780,294
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69953
Policy Entropy: 4.35054
Value Function Loss: 0.00248
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.92340
Value Function Update Magnitude: 0.63643
Collected Steps per Second: 13,224.59169
Overall Steps per Second: 7,291.34262
Timestep Collection Time: 3.78144
Timestep Consumption Time: 3.07710
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.85854
Cumulative Model Updates: 174,149
Cumulative Timesteps: 1,333,830,302
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1333830302...
Checkpoint 1333830302 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14358
Policy Entropy: 4.34999
Value Function Loss: 0.00246
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.94155
Value Function Update Magnitude: 0.65804
Collected Steps per Second: 13,495.00832
Overall Steps per Second: 7,331.51971
Timestep Collection Time: 3.70656
Timestep Consumption Time: 3.11604
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.82260
Cumulative Model Updates: 174,158
Cumulative Timesteps: 1,333,880,322
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.36481
Policy Entropy: 4.34779
Value Function Loss: 0.00261
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.95644
Value Function Update Magnitude: 0.65033
Collected Steps per Second: 13,412.97107
Overall Steps per Second: 7,320.11280
Timestep Collection Time: 3.72818
Timestep Consumption Time: 3.10313
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.83132
Cumulative Model Updates: 174,167
Cumulative Timesteps: 1,333,930,328
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1333930328...
Checkpoint 1333930328 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.61602
Policy Entropy: 4.34788
Value Function Loss: 0.00251
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.93177
Value Function Update Magnitude: 0.64849
Collected Steps per Second: 13,234.67313
Overall Steps per Second: 7,272.38224
Timestep Collection Time: 3.77932
Timestep Consumption Time: 3.09849
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.87780
Cumulative Model Updates: 174,176
Cumulative Timesteps: 1,333,980,346
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.86441
Policy Entropy: 4.34839
Value Function Loss: 0.00250
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.93112
Value Function Update Magnitude: 0.68152
Collected Steps per Second: 13,518.56270
Overall Steps per Second: 7,329.74593
Timestep Collection Time: 3.70143
Timestep Consumption Time: 3.12527
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.82670
Cumulative Model Updates: 174,185
Cumulative Timesteps: 1,334,030,384
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1334030384...
Checkpoint 1334030384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.25199
Policy Entropy: 4.34986
Value Function Loss: 0.00255
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.93245
Value Function Update Magnitude: 0.71926
Collected Steps per Second: 13,208.55925
Overall Steps per Second: 7,068.54047
Timestep Collection Time: 3.78800
Timestep Consumption Time: 3.29041
PPO Batch Consumption Time: 0.24404
Total Iteration Time: 7.07841
Cumulative Model Updates: 174,194
Cumulative Timesteps: 1,334,080,418
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.04318
Policy Entropy: 4.34993
Value Function Loss: 0.00261
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.95884
Value Function Update Magnitude: 0.75174
Collected Steps per Second: 13,296.78495
Overall Steps per Second: 7,377.95981
Timestep Collection Time: 3.76046
Timestep Consumption Time: 3.01675
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.77721
Cumulative Model Updates: 174,203
Cumulative Timesteps: 1,334,130,420
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1334130420...
Checkpoint 1334130420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03011
Policy Entropy: 4.34765
Value Function Loss: 0.00270
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.97104
Value Function Update Magnitude: 0.74155
Collected Steps per Second: 13,126.49340
Overall Steps per Second: 7,225.26542
Timestep Collection Time: 3.80909
Timestep Consumption Time: 3.11107
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.92016
Cumulative Model Updates: 174,212
Cumulative Timesteps: 1,334,180,420
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.48330
Policy Entropy: 4.34881
Value Function Loss: 0.00249
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.95023
Value Function Update Magnitude: 0.71049
Collected Steps per Second: 13,168.00921
Overall Steps per Second: 7,288.43098
Timestep Collection Time: 3.79966
Timestep Consumption Time: 3.06519
PPO Batch Consumption Time: 0.22791
Total Iteration Time: 6.86485
Cumulative Model Updates: 174,221
Cumulative Timesteps: 1,334,230,454
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1334230454...
Checkpoint 1334230454 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42086
Policy Entropy: 4.35044
Value Function Loss: 0.00253
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.94468
Value Function Update Magnitude: 0.67625
Collected Steps per Second: 13,245.59721
Overall Steps per Second: 7,366.28079
Timestep Collection Time: 3.77559
Timestep Consumption Time: 3.01345
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.78904
Cumulative Model Updates: 174,230
Cumulative Timesteps: 1,334,280,464
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.65370
Policy Entropy: 4.35197
Value Function Loss: 0.00243
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02509
Policy Update Magnitude: 0.95313
Value Function Update Magnitude: 0.71729
Collected Steps per Second: 13,185.37143
Overall Steps per Second: 7,244.89031
Timestep Collection Time: 3.79360
Timestep Consumption Time: 3.11058
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.90418
Cumulative Model Updates: 174,239
Cumulative Timesteps: 1,334,330,484
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1334330484...
Checkpoint 1334330484 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70594
Policy Entropy: 4.35003
Value Function Loss: 0.00260
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.96117
Value Function Update Magnitude: 0.68895
Collected Steps per Second: 13,200.26807
Overall Steps per Second: 7,305.26266
Timestep Collection Time: 3.78826
Timestep Consumption Time: 3.05695
PPO Batch Consumption Time: 0.22773
Total Iteration Time: 6.84520
Cumulative Model Updates: 174,248
Cumulative Timesteps: 1,334,380,490
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99025
Policy Entropy: 4.34891
Value Function Loss: 0.00248
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.94427
Value Function Update Magnitude: 0.70946
Collected Steps per Second: 13,058.30682
Overall Steps per Second: 6,989.01459
Timestep Collection Time: 3.83174
Timestep Consumption Time: 3.32750
PPO Batch Consumption Time: 0.24598
Total Iteration Time: 7.15924
Cumulative Model Updates: 174,257
Cumulative Timesteps: 1,334,430,526
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1334430526...
Checkpoint 1334430526 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62443
Policy Entropy: 4.34740
Value Function Loss: 0.00243
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02618
Policy Update Magnitude: 0.94552
Value Function Update Magnitude: 0.71177
Collected Steps per Second: 13,157.91897
Overall Steps per Second: 7,249.62749
Timestep Collection Time: 3.80121
Timestep Consumption Time: 3.09790
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.89911
Cumulative Model Updates: 174,266
Cumulative Timesteps: 1,334,480,542
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89939
Policy Entropy: 4.34771
Value Function Loss: 0.00237
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02581
Policy Update Magnitude: 0.95864
Value Function Update Magnitude: 0.69898
Collected Steps per Second: 13,252.53684
Overall Steps per Second: 7,354.65975
Timestep Collection Time: 3.77437
Timestep Consumption Time: 3.02676
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.80113
Cumulative Model Updates: 174,275
Cumulative Timesteps: 1,334,530,562
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1334530562...
Checkpoint 1334530562 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72296
Policy Entropy: 4.34760
Value Function Loss: 0.00253
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02585
Policy Update Magnitude: 0.94303
Value Function Update Magnitude: 0.70926
Collected Steps per Second: 13,393.40289
Overall Steps per Second: 7,312.35158
Timestep Collection Time: 3.73587
Timestep Consumption Time: 3.10680
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.84267
Cumulative Model Updates: 174,284
Cumulative Timesteps: 1,334,580,598
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57274
Policy Entropy: 4.34568
Value Function Loss: 0.00251
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.92614
Value Function Update Magnitude: 0.67220
Collected Steps per Second: 13,222.29650
Overall Steps per Second: 7,252.52306
Timestep Collection Time: 3.78285
Timestep Consumption Time: 3.11378
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.89663
Cumulative Model Updates: 174,293
Cumulative Timesteps: 1,334,630,616
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1334630616...
Checkpoint 1334630616 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.36346
Policy Entropy: 4.34938
Value Function Loss: 0.00272
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02649
Policy Update Magnitude: 0.95369
Value Function Update Magnitude: 0.67408
Collected Steps per Second: 13,125.29602
Overall Steps per Second: 7,350.97538
Timestep Collection Time: 3.81142
Timestep Consumption Time: 2.99394
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.80536
Cumulative Model Updates: 174,302
Cumulative Timesteps: 1,334,680,642
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.54043
Policy Entropy: 4.34931
Value Function Loss: 0.00249
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.95497
Value Function Update Magnitude: 0.69088
Collected Steps per Second: 13,284.71036
Overall Steps per Second: 7,295.43701
Timestep Collection Time: 3.76568
Timestep Consumption Time: 3.09148
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.85716
Cumulative Model Updates: 174,311
Cumulative Timesteps: 1,334,730,668
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1334730668...
Checkpoint 1334730668 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08674
Policy Entropy: 4.35245
Value Function Loss: 0.00251
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02558
Policy Update Magnitude: 0.94050
Value Function Update Magnitude: 0.65379
Collected Steps per Second: 13,206.96130
Overall Steps per Second: 7,157.84339
Timestep Collection Time: 3.78664
Timestep Consumption Time: 3.20010
PPO Batch Consumption Time: 0.23876
Total Iteration Time: 6.98674
Cumulative Model Updates: 174,320
Cumulative Timesteps: 1,334,780,678
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.36960
Policy Entropy: 4.35264
Value Function Loss: 0.00238
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.92398
Value Function Update Magnitude: 0.69306
Collected Steps per Second: 13,153.60233
Overall Steps per Second: 7,359.90409
Timestep Collection Time: 3.80200
Timestep Consumption Time: 2.99293
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.79493
Cumulative Model Updates: 174,329
Cumulative Timesteps: 1,334,830,688
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1334830688...
Checkpoint 1334830688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.52393
Policy Entropy: 4.35314
Value Function Loss: 0.00232
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.91676
Value Function Update Magnitude: 0.72514
Collected Steps per Second: 13,184.88520
Overall Steps per Second: 7,251.35618
Timestep Collection Time: 3.79510
Timestep Consumption Time: 3.10540
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.90050
Cumulative Model Updates: 174,338
Cumulative Timesteps: 1,334,880,726
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58545
Policy Entropy: 4.35151
Value Function Loss: 0.00246
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.94680
Value Function Update Magnitude: 0.71600
Collected Steps per Second: 13,260.69708
Overall Steps per Second: 7,313.84912
Timestep Collection Time: 3.77371
Timestep Consumption Time: 3.06838
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.84209
Cumulative Model Updates: 174,347
Cumulative Timesteps: 1,334,930,768
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1334930768...
Checkpoint 1334930768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38014
Policy Entropy: 4.34960
Value Function Loss: 0.00263
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.96237
Value Function Update Magnitude: 0.75881
Collected Steps per Second: 13,401.47311
Overall Steps per Second: 7,326.97336
Timestep Collection Time: 3.73362
Timestep Consumption Time: 3.09539
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.82901
Cumulative Model Updates: 174,356
Cumulative Timesteps: 1,334,980,804
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85309
Policy Entropy: 4.34808
Value Function Loss: 0.00272
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.97232
Value Function Update Magnitude: 0.75896
Collected Steps per Second: 13,138.01322
Overall Steps per Second: 7,234.60332
Timestep Collection Time: 3.80743
Timestep Consumption Time: 3.10684
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.91427
Cumulative Model Updates: 174,365
Cumulative Timesteps: 1,335,030,826
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1335030826...
Checkpoint 1335030826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.65000
Policy Entropy: 4.34666
Value Function Loss: 0.00282
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.97590
Value Function Update Magnitude: 0.79866
Collected Steps per Second: 13,195.14388
Overall Steps per Second: 7,357.57387
Timestep Collection Time: 3.78988
Timestep Consumption Time: 3.00693
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.79681
Cumulative Model Updates: 174,374
Cumulative Timesteps: 1,335,080,834
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93352
Policy Entropy: 4.34804
Value Function Loss: 0.00259
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.95990
Value Function Update Magnitude: 0.76449
Collected Steps per Second: 13,125.84112
Overall Steps per Second: 7,124.95659
Timestep Collection Time: 3.81294
Timestep Consumption Time: 3.21139
PPO Batch Consumption Time: 0.23556
Total Iteration Time: 7.02432
Cumulative Model Updates: 174,383
Cumulative Timesteps: 1,335,130,882
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1335130882...
Checkpoint 1335130882 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28447
Policy Entropy: 4.34601
Value Function Loss: 0.00257
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.95559
Value Function Update Magnitude: 0.76122
Collected Steps per Second: 13,366.70565
Overall Steps per Second: 7,330.97928
Timestep Collection Time: 3.74258
Timestep Consumption Time: 3.08134
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.82392
Cumulative Model Updates: 174,392
Cumulative Timesteps: 1,335,180,908
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.00875
Policy Entropy: 4.34593
Value Function Loss: 0.00245
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.93727
Value Function Update Magnitude: 0.74484
Collected Steps per Second: 13,202.93062
Overall Steps per Second: 7,371.39352
Timestep Collection Time: 3.78870
Timestep Consumption Time: 2.99726
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.78596
Cumulative Model Updates: 174,401
Cumulative Timesteps: 1,335,230,930
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1335230930...
Checkpoint 1335230930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97969
Policy Entropy: 4.34725
Value Function Loss: 0.00255
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.92811
Value Function Update Magnitude: 0.74364
Collected Steps per Second: 13,071.47864
Overall Steps per Second: 7,173.79757
Timestep Collection Time: 3.82635
Timestep Consumption Time: 3.14569
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.97204
Cumulative Model Updates: 174,410
Cumulative Timesteps: 1,335,280,946
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95875
Policy Entropy: 4.34615
Value Function Loss: 0.00265
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02585
Policy Update Magnitude: 0.93880
Value Function Update Magnitude: 0.73777
Collected Steps per Second: 13,104.76913
Overall Steps per Second: 7,263.44445
Timestep Collection Time: 3.81754
Timestep Consumption Time: 3.07010
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.88764
Cumulative Model Updates: 174,419
Cumulative Timesteps: 1,335,330,974
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1335330974...
Checkpoint 1335330974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72092
Policy Entropy: 4.34598
Value Function Loss: 0.00261
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.92992
Value Function Update Magnitude: 0.70734
Collected Steps per Second: 13,519.07546
Overall Steps per Second: 7,373.75131
Timestep Collection Time: 3.69937
Timestep Consumption Time: 3.08307
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.78244
Cumulative Model Updates: 174,428
Cumulative Timesteps: 1,335,380,986
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66281
Policy Entropy: 4.34330
Value Function Loss: 0.00255
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.92219
Value Function Update Magnitude: 0.68157
Collected Steps per Second: 13,178.26450
Overall Steps per Second: 7,266.68930
Timestep Collection Time: 3.79458
Timestep Consumption Time: 3.08696
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.88154
Cumulative Model Updates: 174,437
Cumulative Timesteps: 1,335,430,992
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1335430992...
Checkpoint 1335430992 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.52928
Policy Entropy: 4.34343
Value Function Loss: 0.00257
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.94003
Value Function Update Magnitude: 0.65630
Collected Steps per Second: 13,117.74886
Overall Steps per Second: 7,287.39993
Timestep Collection Time: 3.81300
Timestep Consumption Time: 3.05063
PPO Batch Consumption Time: 0.23370
Total Iteration Time: 6.86363
Cumulative Model Updates: 174,446
Cumulative Timesteps: 1,335,481,010
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83042
Policy Entropy: 4.34837
Value Function Loss: 0.00243
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02478
Policy Update Magnitude: 0.92451
Value Function Update Magnitude: 0.64436
Collected Steps per Second: 13,216.35292
Overall Steps per Second: 7,262.00766
Timestep Collection Time: 3.78455
Timestep Consumption Time: 3.10307
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.88763
Cumulative Model Updates: 174,455
Cumulative Timesteps: 1,335,531,028
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1335531028...
Checkpoint 1335531028 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17465
Policy Entropy: 4.34980
Value Function Loss: 0.00238
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02410
Policy Update Magnitude: 0.88208
Value Function Update Magnitude: 0.68332
Collected Steps per Second: 13,016.03066
Overall Steps per Second: 7,246.93294
Timestep Collection Time: 3.84280
Timestep Consumption Time: 3.05915
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.90195
Cumulative Model Updates: 174,464
Cumulative Timesteps: 1,335,581,046
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85868
Policy Entropy: 4.35250
Value Function Loss: 0.00225
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02267
Policy Update Magnitude: 0.88929
Value Function Update Magnitude: 0.63718
Collected Steps per Second: 13,487.58407
Overall Steps per Second: 7,364.35697
Timestep Collection Time: 3.70741
Timestep Consumption Time: 3.08259
PPO Batch Consumption Time: 0.22782
Total Iteration Time: 6.79000
Cumulative Model Updates: 174,473
Cumulative Timesteps: 1,335,631,050
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1335631050...
Checkpoint 1335631050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18375
Policy Entropy: 4.34923
Value Function Loss: 0.00237
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.89224
Value Function Update Magnitude: 0.65032
Collected Steps per Second: 13,223.30288
Overall Steps per Second: 7,260.74181
Timestep Collection Time: 3.78256
Timestep Consumption Time: 3.10626
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.88883
Cumulative Model Updates: 174,482
Cumulative Timesteps: 1,335,681,068
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16905
Policy Entropy: 4.35020
Value Function Loss: 0.00245
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.90745
Value Function Update Magnitude: 0.66573
Collected Steps per Second: 13,111.52630
Overall Steps per Second: 7,255.96408
Timestep Collection Time: 3.81359
Timestep Consumption Time: 3.07757
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.89116
Cumulative Model Updates: 174,491
Cumulative Timesteps: 1,335,731,070
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1335731070...
Checkpoint 1335731070 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80659
Policy Entropy: 4.34656
Value Function Loss: 0.00262
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.91968
Value Function Update Magnitude: 0.68500
Collected Steps per Second: 13,331.72069
Overall Steps per Second: 7,300.38786
Timestep Collection Time: 3.75285
Timestep Consumption Time: 3.10048
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.85333
Cumulative Model Updates: 174,500
Cumulative Timesteps: 1,335,781,102
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00508
Policy Entropy: 4.34448
Value Function Loss: 0.00258
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.92713
Value Function Update Magnitude: 0.68512
Collected Steps per Second: 13,054.08504
Overall Steps per Second: 7,087.02786
Timestep Collection Time: 3.83282
Timestep Consumption Time: 3.22712
PPO Batch Consumption Time: 0.23831
Total Iteration Time: 7.05994
Cumulative Model Updates: 174,509
Cumulative Timesteps: 1,335,831,136
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1335831136...
Checkpoint 1335831136 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76771
Policy Entropy: 4.34596
Value Function Loss: 0.00242
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.91102
Value Function Update Magnitude: 0.72982
Collected Steps per Second: 13,253.99281
Overall Steps per Second: 7,374.26734
Timestep Collection Time: 3.77245
Timestep Consumption Time: 3.00789
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.78033
Cumulative Model Updates: 174,518
Cumulative Timesteps: 1,335,881,136
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09822
Policy Entropy: 4.34662
Value Function Loss: 0.00237
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.90718
Value Function Update Magnitude: 0.70522
Collected Steps per Second: 13,376.14591
Overall Steps per Second: 7,307.01150
Timestep Collection Time: 3.74024
Timestep Consumption Time: 3.10661
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.84685
Cumulative Model Updates: 174,527
Cumulative Timesteps: 1,335,931,166
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1335931166...
Checkpoint 1335931166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35583
Policy Entropy: 4.35163
Value Function Loss: 0.00230
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.88449
Value Function Update Magnitude: 0.72683
Collected Steps per Second: 13,127.36138
Overall Steps per Second: 7,280.50169
Timestep Collection Time: 3.81128
Timestep Consumption Time: 3.06078
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.87205
Cumulative Model Updates: 174,536
Cumulative Timesteps: 1,335,981,198
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.91965
Policy Entropy: 4.35427
Value Function Loss: 0.00224
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.86574
Value Function Update Magnitude: 0.67965
Collected Steps per Second: 13,075.69218
Overall Steps per Second: 7,298.12936
Timestep Collection Time: 3.82542
Timestep Consumption Time: 3.02839
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.85381
Cumulative Model Updates: 174,545
Cumulative Timesteps: 1,336,031,218
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1336031218...
Checkpoint 1336031218 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33982
Policy Entropy: 4.35097
Value Function Loss: 0.00233
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.87820
Value Function Update Magnitude: 0.65419
Collected Steps per Second: 13,113.60439
Overall Steps per Second: 7,221.73683
Timestep Collection Time: 3.81451
Timestep Consumption Time: 3.11208
PPO Batch Consumption Time: 0.22772
Total Iteration Time: 6.92659
Cumulative Model Updates: 174,554
Cumulative Timesteps: 1,336,081,240
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92143
Policy Entropy: 4.35460
Value Function Loss: 0.00214
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.88164
Value Function Update Magnitude: 0.63599
Collected Steps per Second: 13,213.70208
Overall Steps per Second: 7,264.36789
Timestep Collection Time: 3.78471
Timestep Consumption Time: 3.09958
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.88429
Cumulative Model Updates: 174,563
Cumulative Timesteps: 1,336,131,250
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1336131250...
Checkpoint 1336131250 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.79094
Policy Entropy: 4.35086
Value Function Loss: 0.00220
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02668
Policy Update Magnitude: 0.89069
Value Function Update Magnitude: 0.64988
Collected Steps per Second: 13,362.80746
Overall Steps per Second: 7,196.72683
Timestep Collection Time: 3.74263
Timestep Consumption Time: 3.20664
PPO Batch Consumption Time: 0.23784
Total Iteration Time: 6.94927
Cumulative Model Updates: 174,572
Cumulative Timesteps: 1,336,181,262
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53506
Policy Entropy: 4.35546
Value Function Loss: 0.00214
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02210
Policy Update Magnitude: 0.90830
Value Function Update Magnitude: 0.64252
Collected Steps per Second: 13,137.73695
Overall Steps per Second: 7,235.51834
Timestep Collection Time: 3.80629
Timestep Consumption Time: 3.10490
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.91118
Cumulative Model Updates: 174,581
Cumulative Timesteps: 1,336,231,268
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1336231268...
Checkpoint 1336231268 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.60418
Policy Entropy: 4.35039
Value Function Loss: 0.00245
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.94872
Value Function Update Magnitude: 0.72687
Collected Steps per Second: 12,967.62152
Overall Steps per Second: 7,300.19901
Timestep Collection Time: 3.85730
Timestep Consumption Time: 2.99457
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.85187
Cumulative Model Updates: 174,590
Cumulative Timesteps: 1,336,281,288
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.72339
Policy Entropy: 4.35229
Value Function Loss: 0.00232
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.92995
Value Function Update Magnitude: 0.69267
Collected Steps per Second: 13,188.64998
Overall Steps per Second: 7,235.23473
Timestep Collection Time: 3.79281
Timestep Consumption Time: 3.12086
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.91367
Cumulative Model Updates: 174,599
Cumulative Timesteps: 1,336,331,310
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1336331310...
Checkpoint 1336331310 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44329
Policy Entropy: 4.35186
Value Function Loss: 0.00238
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02280
Policy Update Magnitude: 0.90511
Value Function Update Magnitude: 0.67288
Collected Steps per Second: 13,135.93498
Overall Steps per Second: 7,231.30455
Timestep Collection Time: 3.80894
Timestep Consumption Time: 3.11014
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.91908
Cumulative Model Updates: 174,608
Cumulative Timesteps: 1,336,381,344
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.08652
Policy Entropy: 4.35267
Value Function Loss: 0.00233
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.92035
Value Function Update Magnitude: 0.66803
Collected Steps per Second: 13,574.24984
Overall Steps per Second: 7,373.86278
Timestep Collection Time: 3.68344
Timestep Consumption Time: 3.09726
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.78071
Cumulative Model Updates: 174,617
Cumulative Timesteps: 1,336,431,344
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1336431344...
Checkpoint 1336431344 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.25256
Policy Entropy: 4.34792
Value Function Loss: 0.00251
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.95101
Value Function Update Magnitude: 0.67268
Collected Steps per Second: 13,138.65929
Overall Steps per Second: 7,235.82711
Timestep Collection Time: 3.80739
Timestep Consumption Time: 3.10599
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.91338
Cumulative Model Updates: 174,626
Cumulative Timesteps: 1,336,481,368
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.40301
Policy Entropy: 4.34960
Value Function Loss: 0.00247
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02489
Policy Update Magnitude: 0.93872
Value Function Update Magnitude: 0.70657
Collected Steps per Second: 13,219.64023
Overall Steps per Second: 7,231.67278
Timestep Collection Time: 3.78361
Timestep Consumption Time: 3.13291
PPO Batch Consumption Time: 0.23378
Total Iteration Time: 6.91652
Cumulative Model Updates: 174,635
Cumulative Timesteps: 1,336,531,386
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1336531386...
Checkpoint 1336531386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88955
Policy Entropy: 4.35422
Value Function Loss: 0.00235
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.90391
Value Function Update Magnitude: 0.78804
Collected Steps per Second: 13,551.28378
Overall Steps per Second: 7,365.50560
Timestep Collection Time: 3.69116
Timestep Consumption Time: 3.09995
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.79112
Cumulative Model Updates: 174,644
Cumulative Timesteps: 1,336,581,406
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.22767
Policy Entropy: 4.35464
Value Function Loss: 0.00217
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02230
Policy Update Magnitude: 0.89865
Value Function Update Magnitude: 0.76850
Collected Steps per Second: 13,317.62065
Overall Steps per Second: 7,279.58773
Timestep Collection Time: 3.75578
Timestep Consumption Time: 3.11522
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.87099
Cumulative Model Updates: 174,653
Cumulative Timesteps: 1,336,631,424
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1336631424...
Checkpoint 1336631424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.69934
Policy Entropy: 4.35285
Value Function Loss: 0.00227
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.91769
Value Function Update Magnitude: 0.74090
Collected Steps per Second: 13,013.67159
Overall Steps per Second: 7,304.26442
Timestep Collection Time: 3.84257
Timestep Consumption Time: 3.00356
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.84614
Cumulative Model Updates: 174,662
Cumulative Timesteps: 1,336,681,430
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62232
Policy Entropy: 4.35070
Value Function Loss: 0.00226
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.89433
Value Function Update Magnitude: 0.70027
Collected Steps per Second: 13,338.83823
Overall Steps per Second: 7,270.53379
Timestep Collection Time: 3.74890
Timestep Consumption Time: 3.12900
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.87790
Cumulative Model Updates: 174,671
Cumulative Timesteps: 1,336,731,436
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1336731436...
Checkpoint 1336731436 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.55863
Policy Entropy: 4.35289
Value Function Loss: 0.00227
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02458
Policy Update Magnitude: 0.88863
Value Function Update Magnitude: 0.65365
Collected Steps per Second: 13,102.63918
Overall Steps per Second: 7,262.74261
Timestep Collection Time: 3.81603
Timestep Consumption Time: 3.06843
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.88445
Cumulative Model Updates: 174,680
Cumulative Timesteps: 1,336,781,436
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25249
Policy Entropy: 4.35605
Value Function Loss: 0.00224
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02276
Policy Update Magnitude: 0.90147
Value Function Update Magnitude: 0.66160
Collected Steps per Second: 13,566.10896
Overall Steps per Second: 7,342.51888
Timestep Collection Time: 3.68905
Timestep Consumption Time: 3.12687
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.81592
Cumulative Model Updates: 174,689
Cumulative Timesteps: 1,336,831,482
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1336831482...
Checkpoint 1336831482 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82193
Policy Entropy: 4.35254
Value Function Loss: 0.00245
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.94329
Value Function Update Magnitude: 0.69922
Collected Steps per Second: 13,348.66565
Overall Steps per Second: 7,152.89735
Timestep Collection Time: 3.74764
Timestep Consumption Time: 3.24617
PPO Batch Consumption Time: 0.23869
Total Iteration Time: 6.99381
Cumulative Model Updates: 174,698
Cumulative Timesteps: 1,336,881,508
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58959
Policy Entropy: 4.34991
Value Function Loss: 0.00248
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.95501
Value Function Update Magnitude: 0.68299
Collected Steps per Second: 13,221.77720
Overall Steps per Second: 7,290.63659
Timestep Collection Time: 3.78421
Timestep Consumption Time: 3.07856
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.86278
Cumulative Model Updates: 174,707
Cumulative Timesteps: 1,336,931,542
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1336931542...
Checkpoint 1336931542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28384
Policy Entropy: 4.34860
Value Function Loss: 0.00254
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.94267
Value Function Update Magnitude: 0.77276
Collected Steps per Second: 13,408.10126
Overall Steps per Second: 7,326.18441
Timestep Collection Time: 3.72983
Timestep Consumption Time: 3.09637
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.82620
Cumulative Model Updates: 174,716
Cumulative Timesteps: 1,336,981,552
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.29977
Policy Entropy: 4.34875
Value Function Loss: 0.00244
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.93703
Value Function Update Magnitude: 0.76337
Collected Steps per Second: 13,244.63974
Overall Steps per Second: 7,245.78665
Timestep Collection Time: 3.77783
Timestep Consumption Time: 3.12770
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.90553
Cumulative Model Updates: 174,725
Cumulative Timesteps: 1,337,031,588
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1337031588...
Checkpoint 1337031588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49097
Policy Entropy: 4.34764
Value Function Loss: 0.00256
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.94108
Value Function Update Magnitude: 0.76501
Collected Steps per Second: 12,919.92668
Overall Steps per Second: 7,270.77727
Timestep Collection Time: 3.87092
Timestep Consumption Time: 3.00757
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.87849
Cumulative Model Updates: 174,734
Cumulative Timesteps: 1,337,081,600
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91838
Policy Entropy: 4.34809
Value Function Loss: 0.00255
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02646
Policy Update Magnitude: 0.94158
Value Function Update Magnitude: 0.76322
Collected Steps per Second: 13,158.98204
Overall Steps per Second: 7,252.57133
Timestep Collection Time: 3.80105
Timestep Consumption Time: 3.09553
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.89659
Cumulative Model Updates: 174,743
Cumulative Timesteps: 1,337,131,618
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1337131618...
Checkpoint 1337131618 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.67473
Policy Entropy: 4.34872
Value Function Loss: 0.00258
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.95269
Value Function Update Magnitude: 0.74276
Collected Steps per Second: 13,229.85876
Overall Steps per Second: 7,307.53080
Timestep Collection Time: 3.78069
Timestep Consumption Time: 3.06403
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.84472
Cumulative Model Updates: 174,752
Cumulative Timesteps: 1,337,181,636
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20519
Policy Entropy: 4.34929
Value Function Loss: 0.00243
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.93910
Value Function Update Magnitude: 0.69319
Collected Steps per Second: 13,526.69588
Overall Steps per Second: 7,147.33665
Timestep Collection Time: 3.69802
Timestep Consumption Time: 3.30067
PPO Batch Consumption Time: 0.24530
Total Iteration Time: 6.99869
Cumulative Model Updates: 174,761
Cumulative Timesteps: 1,337,231,658
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1337231658...
Checkpoint 1337231658 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.44372
Policy Entropy: 4.35005
Value Function Loss: 0.00228
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.92201
Value Function Update Magnitude: 0.68531
Collected Steps per Second: 13,197.75127
Overall Steps per Second: 7,245.64840
Timestep Collection Time: 3.78928
Timestep Consumption Time: 3.11279
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.90207
Cumulative Model Updates: 174,770
Cumulative Timesteps: 1,337,281,668
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51518
Policy Entropy: 4.35183
Value Function Loss: 0.00223
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02323
Policy Update Magnitude: 0.91725
Value Function Update Magnitude: 0.69570
Collected Steps per Second: 13,179.86606
Overall Steps per Second: 7,248.95566
Timestep Collection Time: 3.79412
Timestep Consumption Time: 3.10425
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.89837
Cumulative Model Updates: 174,779
Cumulative Timesteps: 1,337,331,674
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1337331674...
Checkpoint 1337331674 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.84492
Policy Entropy: 4.35675
Value Function Loss: 0.00222
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.89810
Value Function Update Magnitude: 0.70270
Collected Steps per Second: 13,441.91897
Overall Steps per Second: 7,305.77141
Timestep Collection Time: 3.72090
Timestep Consumption Time: 3.12520
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.84609
Cumulative Model Updates: 174,788
Cumulative Timesteps: 1,337,381,690
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.63413
Policy Entropy: 4.35943
Value Function Loss: 0.00221
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02322
Policy Update Magnitude: 0.88460
Value Function Update Magnitude: 0.66949
Collected Steps per Second: 13,134.82066
Overall Steps per Second: 7,234.85381
Timestep Collection Time: 3.80713
Timestep Consumption Time: 3.10469
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.91182
Cumulative Model Updates: 174,797
Cumulative Timesteps: 1,337,431,696
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1337431696...
Checkpoint 1337431696 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.96807
Policy Entropy: 4.35938
Value Function Loss: 0.00218
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02342
Policy Update Magnitude: 0.88739
Value Function Update Magnitude: 0.69833
Collected Steps per Second: 13,092.70629
Overall Steps per Second: 7,324.81246
Timestep Collection Time: 3.81984
Timestep Consumption Time: 3.00791
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.82775
Cumulative Model Updates: 174,806
Cumulative Timesteps: 1,337,481,708
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.96567
Policy Entropy: 4.35891
Value Function Loss: 0.00223
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02336
Policy Update Magnitude: 0.90274
Value Function Update Magnitude: 0.75459
Collected Steps per Second: 13,268.28566
Overall Steps per Second: 7,277.56812
Timestep Collection Time: 3.76989
Timestep Consumption Time: 3.10328
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.87318
Cumulative Model Updates: 174,815
Cumulative Timesteps: 1,337,531,728
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1337531728...
Checkpoint 1337531728 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.13776
Policy Entropy: 4.35881
Value Function Loss: 0.00214
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.91025
Value Function Update Magnitude: 0.70947
Collected Steps per Second: 13,115.20911
Overall Steps per Second: 7,207.55267
Timestep Collection Time: 3.81328
Timestep Consumption Time: 3.12555
PPO Batch Consumption Time: 0.23305
Total Iteration Time: 6.93883
Cumulative Model Updates: 174,824
Cumulative Timesteps: 1,337,581,740
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.04957
Policy Entropy: 4.35957
Value Function Loss: 0.00215
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.91779
Value Function Update Magnitude: 0.71147
Collected Steps per Second: 13,188.56071
Overall Steps per Second: 7,352.42322
Timestep Collection Time: 3.79162
Timestep Consumption Time: 3.00968
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.80130
Cumulative Model Updates: 174,833
Cumulative Timesteps: 1,337,631,746
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1337631746...
Checkpoint 1337631746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.65083
Policy Entropy: 4.36238
Value Function Loss: 0.00219
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.91800
Value Function Update Magnitude: 0.76342
Collected Steps per Second: 13,205.56389
Overall Steps per Second: 7,257.58891
Timestep Collection Time: 3.78704
Timestep Consumption Time: 3.10368
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.89072
Cumulative Model Updates: 174,842
Cumulative Timesteps: 1,337,681,756
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.79840
Policy Entropy: 4.35755
Value Function Loss: 0.00229
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.93537
Value Function Update Magnitude: 0.74211
Collected Steps per Second: 13,242.85662
Overall Steps per Second: 7,388.20948
Timestep Collection Time: 3.77849
Timestep Consumption Time: 2.99419
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.77268
Cumulative Model Updates: 174,851
Cumulative Timesteps: 1,337,731,794
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1337731794...
Checkpoint 1337731794 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53646
Policy Entropy: 4.35842
Value Function Loss: 0.00218
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.93207
Value Function Update Magnitude: 0.68029
Collected Steps per Second: 13,134.41831
Overall Steps per Second: 7,244.64239
Timestep Collection Time: 3.80953
Timestep Consumption Time: 3.09709
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.90662
Cumulative Model Updates: 174,860
Cumulative Timesteps: 1,337,781,830
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.09935
Policy Entropy: 4.35664
Value Function Loss: 0.00243
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.96028
Value Function Update Magnitude: 0.74548
Collected Steps per Second: 13,230.07887
Overall Steps per Second: 7,283.17611
Timestep Collection Time: 3.78063
Timestep Consumption Time: 3.08698
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.86761
Cumulative Model Updates: 174,869
Cumulative Timesteps: 1,337,831,848
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1337831848...
Checkpoint 1337831848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.78580
Policy Entropy: 4.35713
Value Function Loss: 0.00260
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 1.00138
Value Function Update Magnitude: 0.72226
Collected Steps per Second: 13,164.76774
Overall Steps per Second: 7,313.64523
Timestep Collection Time: 3.79938
Timestep Consumption Time: 3.03961
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.83900
Cumulative Model Updates: 174,878
Cumulative Timesteps: 1,337,881,866
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54852
Policy Entropy: 4.35572
Value Function Loss: 0.00271
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 1.00034
Value Function Update Magnitude: 0.74537
Collected Steps per Second: 13,270.37361
Overall Steps per Second: 7,091.00728
Timestep Collection Time: 3.77126
Timestep Consumption Time: 3.28641
PPO Batch Consumption Time: 0.24377
Total Iteration Time: 7.05767
Cumulative Model Updates: 174,887
Cumulative Timesteps: 1,337,931,912
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1337931912...
Checkpoint 1337931912 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30261
Policy Entropy: 4.35651
Value Function Loss: 0.00246
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.96089
Value Function Update Magnitude: 0.75374
Collected Steps per Second: 13,211.08462
Overall Steps per Second: 7,275.12768
Timestep Collection Time: 3.78606
Timestep Consumption Time: 3.08914
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.87521
Cumulative Model Updates: 174,896
Cumulative Timesteps: 1,337,981,930
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95055
Policy Entropy: 4.35934
Value Function Loss: 0.00235
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.96316
Value Function Update Magnitude: 0.72464
Collected Steps per Second: 13,624.49851
Overall Steps per Second: 7,369.92928
Timestep Collection Time: 3.67103
Timestep Consumption Time: 3.11546
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.78650
Cumulative Model Updates: 174,905
Cumulative Timesteps: 1,338,031,946
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1338031946...
Checkpoint 1338031946 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.61552
Policy Entropy: 4.36013
Value Function Loss: 0.00221
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.94969
Value Function Update Magnitude: 0.71572
Collected Steps per Second: 13,197.13807
Overall Steps per Second: 7,234.24015
Timestep Collection Time: 3.79082
Timestep Consumption Time: 3.12462
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.91545
Cumulative Model Updates: 174,914
Cumulative Timesteps: 1,338,081,974
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.31966
Policy Entropy: 4.35795
Value Function Loss: 0.00224
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.93885
Value Function Update Magnitude: 0.71262
Collected Steps per Second: 13,228.67689
Overall Steps per Second: 7,293.00212
Timestep Collection Time: 3.78299
Timestep Consumption Time: 3.07893
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.86192
Cumulative Model Updates: 174,923
Cumulative Timesteps: 1,338,132,018
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1338132018...
Checkpoint 1338132018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57504
Policy Entropy: 4.36148
Value Function Loss: 0.00210
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.94662
Value Function Update Magnitude: 0.69386
Collected Steps per Second: 13,455.45148
Overall Steps per Second: 7,333.20998
Timestep Collection Time: 3.71641
Timestep Consumption Time: 3.10270
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.81911
Cumulative Model Updates: 174,932
Cumulative Timesteps: 1,338,182,024
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34049
Policy Entropy: 4.35922
Value Function Loss: 0.00222
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.95337
Value Function Update Magnitude: 0.67618
Collected Steps per Second: 13,027.15524
Overall Steps per Second: 7,194.64827
Timestep Collection Time: 3.83875
Timestep Consumption Time: 3.11197
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.95072
Cumulative Model Updates: 174,941
Cumulative Timesteps: 1,338,232,032
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1338232032...
Checkpoint 1338232032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42804
Policy Entropy: 4.35670
Value Function Loss: 0.00237
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02509
Policy Update Magnitude: 0.95851
Value Function Update Magnitude: 0.71569
Collected Steps per Second: 13,201.92475
Overall Steps per Second: 7,211.54099
Timestep Collection Time: 3.78824
Timestep Consumption Time: 3.14676
PPO Batch Consumption Time: 0.23908
Total Iteration Time: 6.93499
Cumulative Model Updates: 174,950
Cumulative Timesteps: 1,338,282,044
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18295
Policy Entropy: 4.35326
Value Function Loss: 0.00239
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.93810
Value Function Update Magnitude: 0.72387
Collected Steps per Second: 13,205.64638
Overall Steps per Second: 7,251.39778
Timestep Collection Time: 3.78899
Timestep Consumption Time: 3.11120
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.90019
Cumulative Model Updates: 174,959
Cumulative Timesteps: 1,338,332,080
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1338332080...
Checkpoint 1338332080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.95614
Policy Entropy: 4.35340
Value Function Loss: 0.00241
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02440
Policy Update Magnitude: 0.94351
Value Function Update Magnitude: 0.73758
Collected Steps per Second: 13,041.29895
Overall Steps per Second: 7,262.46910
Timestep Collection Time: 3.83627
Timestep Consumption Time: 3.05257
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.88884
Cumulative Model Updates: 174,968
Cumulative Timesteps: 1,338,382,110
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.36311
Policy Entropy: 4.35711
Value Function Loss: 0.00219
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.93546
Value Function Update Magnitude: 0.72327
Collected Steps per Second: 13,249.25767
Overall Steps per Second: 7,375.11994
Timestep Collection Time: 3.77515
Timestep Consumption Time: 3.00684
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.78199
Cumulative Model Updates: 174,977
Cumulative Timesteps: 1,338,432,128
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1338432128...
Checkpoint 1338432128 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.52932
Policy Entropy: 4.35615
Value Function Loss: 0.00237
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.93787
Value Function Update Magnitude: 0.66910
Collected Steps per Second: 13,110.36520
Overall Steps per Second: 7,233.93470
Timestep Collection Time: 3.81469
Timestep Consumption Time: 3.09883
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.91353
Cumulative Model Updates: 174,986
Cumulative Timesteps: 1,338,482,140
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10941
Policy Entropy: 4.35728
Value Function Loss: 0.00220
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.93283
Value Function Update Magnitude: 0.67422
Collected Steps per Second: 13,086.16544
Overall Steps per Second: 7,222.66495
Timestep Collection Time: 3.82190
Timestep Consumption Time: 3.10269
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.92459
Cumulative Model Updates: 174,995
Cumulative Timesteps: 1,338,532,154
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1338532154...
Checkpoint 1338532154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55950
Policy Entropy: 4.35876
Value Function Loss: 0.00220
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02440
Policy Update Magnitude: 0.90103
Value Function Update Magnitude: 0.68334
Collected Steps per Second: 13,397.69174
Overall Steps per Second: 7,263.44008
Timestep Collection Time: 3.73452
Timestep Consumption Time: 3.15395
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.88847
Cumulative Model Updates: 175,004
Cumulative Timesteps: 1,338,582,188
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.58924
Policy Entropy: 4.36166
Value Function Loss: 0.00209
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.91247
Value Function Update Magnitude: 0.65947
Collected Steps per Second: 13,212.78861
Overall Steps per Second: 7,048.74364
Timestep Collection Time: 3.78860
Timestep Consumption Time: 3.31309
PPO Batch Consumption Time: 0.24561
Total Iteration Time: 7.10169
Cumulative Model Updates: 175,013
Cumulative Timesteps: 1,338,632,246
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 1338632246...
Checkpoint 1338632246 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69423
Policy Entropy: 4.35733
Value Function Loss: 0.00228
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.91867
Value Function Update Magnitude: 0.66283
Collected Steps per Second: 12,964.79632
Overall Steps per Second: 7,284.35328
Timestep Collection Time: 3.85752
Timestep Consumption Time: 3.00815
PPO Batch Consumption Time: 0.22943
Total Iteration Time: 6.86567
Cumulative Model Updates: 175,022
Cumulative Timesteps: 1,338,682,258
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.07373
Policy Entropy: 4.35416
Value Function Loss: 0.00241
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.92837
Value Function Update Magnitude: 0.69340
Collected Steps per Second: 13,209.65819
Overall Steps per Second: 7,244.82197
Timestep Collection Time: 3.78526
Timestep Consumption Time: 3.11650
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.90176
Cumulative Model Updates: 175,031
Cumulative Timesteps: 1,338,732,260
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1338732260...
Checkpoint 1338732260 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33126
Policy Entropy: 4.35199
Value Function Loss: 0.00247
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02617
Policy Update Magnitude: 0.93506
Value Function Update Magnitude: 0.69944
Collected Steps per Second: 13,221.43076
Overall Steps per Second: 7,306.47881
Timestep Collection Time: 3.78310
Timestep Consumption Time: 3.06260
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.84571
Cumulative Model Updates: 175,040
Cumulative Timesteps: 1,338,782,278
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.86126
Policy Entropy: 4.35269
Value Function Loss: 0.00236
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.91693
Value Function Update Magnitude: 0.67061
Collected Steps per Second: 13,129.12616
Overall Steps per Second: 7,348.94461
Timestep Collection Time: 3.81076
Timestep Consumption Time: 2.99729
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.80805
Cumulative Model Updates: 175,049
Cumulative Timesteps: 1,338,832,310
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1338832310...
Checkpoint 1338832310 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49669
Policy Entropy: 4.35599
Value Function Loss: 0.00249
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02411
Policy Update Magnitude: 0.91017
Value Function Update Magnitude: 0.63470
Collected Steps per Second: 13,164.91786
Overall Steps per Second: 7,245.32708
Timestep Collection Time: 3.79873
Timestep Consumption Time: 3.10365
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.90238
Cumulative Model Updates: 175,058
Cumulative Timesteps: 1,338,882,320
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.58010
Policy Entropy: 4.35704
Value Function Loss: 0.00253
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.91043
Value Function Update Magnitude: 0.68006
Collected Steps per Second: 13,246.57872
Overall Steps per Second: 7,279.08928
Timestep Collection Time: 3.77743
Timestep Consumption Time: 3.09678
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.87421
Cumulative Model Updates: 175,067
Cumulative Timesteps: 1,338,932,358
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1338932358...
Checkpoint 1338932358 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.53622
Policy Entropy: 4.35925
Value Function Loss: 0.00229
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02470
Policy Update Magnitude: 0.86943
Value Function Update Magnitude: 0.66349
Collected Steps per Second: 13,414.56206
Overall Steps per Second: 7,141.38561
Timestep Collection Time: 3.72834
Timestep Consumption Time: 3.27507
PPO Batch Consumption Time: 0.24315
Total Iteration Time: 7.00340
Cumulative Model Updates: 175,076
Cumulative Timesteps: 1,338,982,372
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.65276
Policy Entropy: 4.35847
Value Function Loss: 0.00218
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02293
Policy Update Magnitude: 0.85661
Value Function Update Magnitude: 0.68204
Collected Steps per Second: 13,183.36681
Overall Steps per Second: 7,258.64775
Timestep Collection Time: 3.79554
Timestep Consumption Time: 3.09803
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.89357
Cumulative Model Updates: 175,085
Cumulative Timesteps: 1,339,032,410
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1339032410...
Checkpoint 1339032410 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72661
Policy Entropy: 4.36189
Value Function Loss: 0.00201
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.85389
Value Function Update Magnitude: 0.68583
Collected Steps per Second: 13,160.14667
Overall Steps per Second: 7,268.11189
Timestep Collection Time: 3.79965
Timestep Consumption Time: 3.08026
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.87992
Cumulative Model Updates: 175,094
Cumulative Timesteps: 1,339,082,414
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.10027
Policy Entropy: 4.36307
Value Function Loss: 0.00207
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02231
Policy Update Magnitude: 0.85658
Value Function Update Magnitude: 0.70188
Collected Steps per Second: 13,591.24477
Overall Steps per Second: 7,368.37054
Timestep Collection Time: 3.68075
Timestep Consumption Time: 3.10854
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.78929
Cumulative Model Updates: 175,103
Cumulative Timesteps: 1,339,132,440
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1339132440...
Checkpoint 1339132440 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.65807
Policy Entropy: 4.36541
Value Function Loss: 0.00202
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02213
Policy Update Magnitude: 0.87529
Value Function Update Magnitude: 0.69994
Collected Steps per Second: 13,055.30658
Overall Steps per Second: 7,203.92527
Timestep Collection Time: 3.83185
Timestep Consumption Time: 3.11242
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.94427
Cumulative Model Updates: 175,112
Cumulative Timesteps: 1,339,182,466
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04546
Policy Entropy: 4.36145
Value Function Loss: 0.00228
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02276
Policy Update Magnitude: 0.90499
Value Function Update Magnitude: 0.75603
Collected Steps per Second: 13,259.07368
Overall Steps per Second: 7,370.60955
Timestep Collection Time: 3.77176
Timestep Consumption Time: 3.01330
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.78506
Cumulative Model Updates: 175,121
Cumulative Timesteps: 1,339,232,476
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1339232476...
Checkpoint 1339232476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96442
Policy Entropy: 4.35814
Value Function Loss: 0.00244
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.92996
Value Function Update Magnitude: 0.81584
Collected Steps per Second: 13,328.43153
Overall Steps per Second: 7,285.87220
Timestep Collection Time: 3.75318
Timestep Consumption Time: 3.11271
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.86589
Cumulative Model Updates: 175,130
Cumulative Timesteps: 1,339,282,500
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96381
Policy Entropy: 4.35516
Value Function Loss: 0.00240
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02633
Policy Update Magnitude: 0.92546
Value Function Update Magnitude: 0.77546
Collected Steps per Second: 13,124.43890
Overall Steps per Second: 7,108.56564
Timestep Collection Time: 3.81182
Timestep Consumption Time: 3.22589
PPO Batch Consumption Time: 0.23844
Total Iteration Time: 7.03771
Cumulative Model Updates: 175,139
Cumulative Timesteps: 1,339,332,528
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1339332528...
Checkpoint 1339332528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57975
Policy Entropy: 4.35645
Value Function Loss: 0.00228
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02541
Policy Update Magnitude: 0.92094
Value Function Update Magnitude: 0.74384
Collected Steps per Second: 13,109.88510
Overall Steps per Second: 7,338.79544
Timestep Collection Time: 3.81834
Timestep Consumption Time: 3.00267
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.82101
Cumulative Model Updates: 175,148
Cumulative Timesteps: 1,339,382,586
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37465
Policy Entropy: 4.35684
Value Function Loss: 0.00218
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.90318
Value Function Update Magnitude: 0.67590
Collected Steps per Second: 13,164.78639
Overall Steps per Second: 7,244.94911
Timestep Collection Time: 3.80075
Timestep Consumption Time: 3.10558
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.90633
Cumulative Model Updates: 175,157
Cumulative Timesteps: 1,339,432,622
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1339432622...
Checkpoint 1339432622 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.68333
Policy Entropy: 4.35680
Value Function Loss: 0.00225
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02304
Policy Update Magnitude: 0.89589
Value Function Update Magnitude: 0.68806
Collected Steps per Second: 13,078.04696
Overall Steps per Second: 7,252.77643
Timestep Collection Time: 3.82412
Timestep Consumption Time: 3.07145
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.89557
Cumulative Model Updates: 175,166
Cumulative Timesteps: 1,339,482,634
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28690
Policy Entropy: 4.35951
Value Function Loss: 0.00221
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02443
Policy Update Magnitude: 0.89185
Value Function Update Magnitude: 0.65282
Collected Steps per Second: 13,420.43366
Overall Steps per Second: 7,318.32106
Timestep Collection Time: 3.72611
Timestep Consumption Time: 3.10688
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.83299
Cumulative Model Updates: 175,175
Cumulative Timesteps: 1,339,532,640
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1339532640...
Checkpoint 1339532640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.54595
Policy Entropy: 4.35646
Value Function Loss: 0.00235
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.91250
Value Function Update Magnitude: 0.67528
Collected Steps per Second: 13,330.61822
Overall Steps per Second: 7,287.63224
Timestep Collection Time: 3.75331
Timestep Consumption Time: 3.11229
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.86560
Cumulative Model Updates: 175,184
Cumulative Timesteps: 1,339,582,674
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.41461
Policy Entropy: 4.35774
Value Function Loss: 0.00233
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.92015
Value Function Update Magnitude: 0.67952
Collected Steps per Second: 13,180.42918
Overall Steps per Second: 7,377.15621
Timestep Collection Time: 3.79472
Timestep Consumption Time: 2.98513
PPO Batch Consumption Time: 0.22789
Total Iteration Time: 6.77985
Cumulative Model Updates: 175,193
Cumulative Timesteps: 1,339,632,690
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1339632690...
Checkpoint 1339632690 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33480
Policy Entropy: 4.35280
Value Function Loss: 0.00251
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02723
Policy Update Magnitude: 0.92722
Value Function Update Magnitude: 0.66431
Collected Steps per Second: 13,196.36771
Overall Steps per Second: 7,063.94860
Timestep Collection Time: 3.78892
Timestep Consumption Time: 3.28927
PPO Batch Consumption Time: 0.24372
Total Iteration Time: 7.07819
Cumulative Model Updates: 175,202
Cumulative Timesteps: 1,339,682,690
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54007
Policy Entropy: 4.35794
Value Function Loss: 0.00244
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.91603
Value Function Update Magnitude: 0.70778
Collected Steps per Second: 13,197.53043
Overall Steps per Second: 7,287.17917
Timestep Collection Time: 3.79071
Timestep Consumption Time: 3.07450
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.86521
Cumulative Model Updates: 175,211
Cumulative Timesteps: 1,339,732,718
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1339732718...
Checkpoint 1339732718 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09459
Policy Entropy: 4.35615
Value Function Loss: 0.00239
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.93176
Value Function Update Magnitude: 0.73108
Collected Steps per Second: 13,505.45347
Overall Steps per Second: 7,336.93560
Timestep Collection Time: 3.70547
Timestep Consumption Time: 3.11537
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.82083
Cumulative Model Updates: 175,220
Cumulative Timesteps: 1,339,782,762
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28185
Policy Entropy: 4.36130
Value Function Loss: 0.00223
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.92936
Value Function Update Magnitude: 0.71400
Collected Steps per Second: 13,187.12365
Overall Steps per Second: 7,223.83829
Timestep Collection Time: 3.79446
Timestep Consumption Time: 3.13233
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.92679
Cumulative Model Updates: 175,229
Cumulative Timesteps: 1,339,832,800
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1339832800...
Checkpoint 1339832800 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.16929
Policy Entropy: 4.35897
Value Function Loss: 0.00232
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02501
Policy Update Magnitude: 0.91511
Value Function Update Magnitude: 0.68698
Collected Steps per Second: 13,169.79595
Overall Steps per Second: 7,287.16412
Timestep Collection Time: 3.79793
Timestep Consumption Time: 3.06592
PPO Batch Consumption Time: 0.22794
Total Iteration Time: 6.86385
Cumulative Model Updates: 175,238
Cumulative Timesteps: 1,339,882,818
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.27548
Policy Entropy: 4.36208
Value Function Loss: 0.00221
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.90100
Value Function Update Magnitude: 0.69320
Collected Steps per Second: 13,561.98025
Overall Steps per Second: 7,386.85500
Timestep Collection Time: 3.68796
Timestep Consumption Time: 3.08299
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.77095
Cumulative Model Updates: 175,247
Cumulative Timesteps: 1,339,932,834
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1339932834...
Checkpoint 1339932834 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53815
Policy Entropy: 4.35995
Value Function Loss: 0.00230
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.91442
Value Function Update Magnitude: 0.66680
Collected Steps per Second: 13,274.11347
Overall Steps per Second: 7,249.72494
Timestep Collection Time: 3.76718
Timestep Consumption Time: 3.13046
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.89764
Cumulative Model Updates: 175,256
Cumulative Timesteps: 1,339,982,840
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76445
Policy Entropy: 4.35912
Value Function Loss: 0.00238
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.94665
Value Function Update Magnitude: 0.66508
Collected Steps per Second: 13,178.43934
Overall Steps per Second: 7,178.37229
Timestep Collection Time: 3.79559
Timestep Consumption Time: 3.17256
PPO Batch Consumption Time: 0.24353
Total Iteration Time: 6.96815
Cumulative Model Updates: 175,265
Cumulative Timesteps: 1,340,032,860
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1340032860...
Checkpoint 1340032860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.12330
Policy Entropy: 4.35955
Value Function Loss: 0.00254
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.97317
Value Function Update Magnitude: 0.65587
Collected Steps per Second: 13,273.22673
Overall Steps per Second: 7,264.21348
Timestep Collection Time: 3.77015
Timestep Consumption Time: 3.11869
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.88884
Cumulative Model Updates: 175,274
Cumulative Timesteps: 1,340,082,902
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69292
Policy Entropy: 4.35884
Value Function Loss: 0.00243
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.94806
Value Function Update Magnitude: 0.67347
Collected Steps per Second: 13,189.08305
Overall Steps per Second: 7,279.12655
Timestep Collection Time: 3.79283
Timestep Consumption Time: 3.07942
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.87225
Cumulative Model Updates: 175,283
Cumulative Timesteps: 1,340,132,926
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1340132926...
Checkpoint 1340132926 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22078
Policy Entropy: 4.35860
Value Function Loss: 0.00243
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02748
Policy Update Magnitude: 0.93148
Value Function Update Magnitude: 0.70341
Collected Steps per Second: 13,408.53252
Overall Steps per Second: 7,290.73616
Timestep Collection Time: 3.73165
Timestep Consumption Time: 3.13130
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.86296
Cumulative Model Updates: 175,292
Cumulative Timesteps: 1,340,182,962
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16360
Policy Entropy: 4.35986
Value Function Loss: 0.00237
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.94251
Value Function Update Magnitude: 0.71741
Collected Steps per Second: 13,150.06300
Overall Steps per Second: 7,250.22275
Timestep Collection Time: 3.80470
Timestep Consumption Time: 3.09606
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.90075
Cumulative Model Updates: 175,301
Cumulative Timesteps: 1,340,232,994
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1340232994...
Checkpoint 1340232994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76178
Policy Entropy: 4.36222
Value Function Loss: 0.00220
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.91822
Value Function Update Magnitude: 0.67846
Collected Steps per Second: 13,105.81613
Overall Steps per Second: 7,283.78354
Timestep Collection Time: 3.81632
Timestep Consumption Time: 3.05044
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.86676
Cumulative Model Updates: 175,310
Cumulative Timesteps: 1,340,283,010
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.61854
Policy Entropy: 4.36062
Value Function Loss: 0.00216
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.91155
Value Function Update Magnitude: 0.68596
Collected Steps per Second: 13,538.65105
Overall Steps per Second: 7,394.42413
Timestep Collection Time: 3.69535
Timestep Consumption Time: 3.07056
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.76591
Cumulative Model Updates: 175,319
Cumulative Timesteps: 1,340,333,040
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1340333040...
Checkpoint 1340333040 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18471
Policy Entropy: 4.35885
Value Function Loss: 0.00218
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.92348
Value Function Update Magnitude: 0.66364
Collected Steps per Second: 13,127.62867
Overall Steps per Second: 7,062.42998
Timestep Collection Time: 3.81150
Timestep Consumption Time: 3.27331
PPO Batch Consumption Time: 0.23996
Total Iteration Time: 7.08481
Cumulative Model Updates: 175,328
Cumulative Timesteps: 1,340,383,076
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71773
Policy Entropy: 4.35455
Value Function Loss: 0.00257
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.97660
Value Function Update Magnitude: 0.69904
Collected Steps per Second: 13,104.30704
Overall Steps per Second: 7,337.24770
Timestep Collection Time: 3.81615
Timestep Consumption Time: 2.99948
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.81563
Cumulative Model Updates: 175,337
Cumulative Timesteps: 1,340,433,084
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1340433084...
Checkpoint 1340433084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.50821
Policy Entropy: 4.35379
Value Function Loss: 0.00271
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02774
Policy Update Magnitude: 1.02440
Value Function Update Magnitude: 0.76120
Collected Steps per Second: 13,210.65405
Overall Steps per Second: 7,229.76792
Timestep Collection Time: 3.78831
Timestep Consumption Time: 3.13391
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.92221
Cumulative Model Updates: 175,346
Cumulative Timesteps: 1,340,483,130
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.82596
Policy Entropy: 4.35381
Value Function Loss: 0.00276
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02886
Policy Update Magnitude: 0.98940
Value Function Update Magnitude: 0.82666
Collected Steps per Second: 13,300.08047
Overall Steps per Second: 7,310.99739
Timestep Collection Time: 3.76148
Timestep Consumption Time: 3.08136
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.84284
Cumulative Model Updates: 175,355
Cumulative Timesteps: 1,340,533,158
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1340533158...
Checkpoint 1340533158 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85720
Policy Entropy: 4.35241
Value Function Loss: 0.00270
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.99626
Value Function Update Magnitude: 0.78604
Collected Steps per Second: 12,950.72640
Overall Steps per Second: 7,154.75796
Timestep Collection Time: 3.86079
Timestep Consumption Time: 3.12757
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.98836
Cumulative Model Updates: 175,364
Cumulative Timesteps: 1,340,583,158
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.07575
Policy Entropy: 4.35253
Value Function Loss: 0.00257
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.98002
Value Function Update Magnitude: 0.74381
Collected Steps per Second: 13,189.31197
Overall Steps per Second: 7,221.68033
Timestep Collection Time: 3.79368
Timestep Consumption Time: 3.13490
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.92858
Cumulative Model Updates: 175,373
Cumulative Timesteps: 1,340,633,194
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1340633194...
Checkpoint 1340633194 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31587
Policy Entropy: 4.35271
Value Function Loss: 0.00240
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.96612
Value Function Update Magnitude: 0.73238
Collected Steps per Second: 13,042.64441
Overall Steps per Second: 7,235.47449
Timestep Collection Time: 3.83711
Timestep Consumption Time: 3.07965
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.91675
Cumulative Model Updates: 175,382
Cumulative Timesteps: 1,340,683,240
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90346
Policy Entropy: 4.35437
Value Function Loss: 0.00225
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.95710
Value Function Update Magnitude: 0.68702
Collected Steps per Second: 13,451.25274
Overall Steps per Second: 7,140.57830
Timestep Collection Time: 3.71817
Timestep Consumption Time: 3.28603
PPO Batch Consumption Time: 0.24281
Total Iteration Time: 7.00419
Cumulative Model Updates: 175,391
Cumulative Timesteps: 1,340,733,254
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1340733254...
Checkpoint 1340733254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.31197
Policy Entropy: 4.35801
Value Function Loss: 0.00219
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.92655
Value Function Update Magnitude: 0.69080
Collected Steps per Second: 13,192.16803
Overall Steps per Second: 7,250.91452
Timestep Collection Time: 3.79346
Timestep Consumption Time: 3.10829
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.90175
Cumulative Model Updates: 175,400
Cumulative Timesteps: 1,340,783,298
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.92080
Policy Entropy: 4.35826
Value Function Loss: 0.00213
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.89846
Value Function Update Magnitude: 0.69591
Collected Steps per Second: 13,128.74417
Overall Steps per Second: 7,346.57914
Timestep Collection Time: 3.81057
Timestep Consumption Time: 2.99913
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.80970
Cumulative Model Updates: 175,409
Cumulative Timesteps: 1,340,833,326
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1340833326...
Checkpoint 1340833326 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.43394
Policy Entropy: 4.36280
Value Function Loss: 0.00207
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.87495
Value Function Update Magnitude: 0.69360
Collected Steps per Second: 13,154.59173
Overall Steps per Second: 7,246.02601
Timestep Collection Time: 3.80156
Timestep Consumption Time: 3.09988
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.90144
Cumulative Model Updates: 175,418
Cumulative Timesteps: 1,340,883,334
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41546
Policy Entropy: 4.35864
Value Function Loss: 0.00220
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.89261
Value Function Update Magnitude: 0.67525
Collected Steps per Second: 13,215.02817
Overall Steps per Second: 7,290.12272
Timestep Collection Time: 3.78357
Timestep Consumption Time: 3.07502
PPO Batch Consumption Time: 0.22776
Total Iteration Time: 6.85860
Cumulative Model Updates: 175,427
Cumulative Timesteps: 1,340,933,334
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1340933334...
Checkpoint 1340933334 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74516
Policy Entropy: 4.35655
Value Function Loss: 0.00220
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.92570
Value Function Update Magnitude: 0.65104
Collected Steps per Second: 12,917.17257
Overall Steps per Second: 7,266.09499
Timestep Collection Time: 3.87113
Timestep Consumption Time: 3.01070
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.88183
Cumulative Model Updates: 175,436
Cumulative Timesteps: 1,340,983,338
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.12050
Policy Entropy: 4.35160
Value Function Loss: 0.00231
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.92734
Value Function Update Magnitude: 0.67514
Collected Steps per Second: 13,039.63478
Overall Steps per Second: 7,189.30216
Timestep Collection Time: 3.83676
Timestep Consumption Time: 3.12219
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.95895
Cumulative Model Updates: 175,445
Cumulative Timesteps: 1,341,033,368
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1341033368...
Checkpoint 1341033368 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.23516
Policy Entropy: 4.35368
Value Function Loss: 0.00220
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.92423
Value Function Update Magnitude: 0.68960
Collected Steps per Second: 13,162.80443
Overall Steps per Second: 7,065.35978
Timestep Collection Time: 3.79995
Timestep Consumption Time: 3.27938
PPO Batch Consumption Time: 0.24652
Total Iteration Time: 7.07933
Cumulative Model Updates: 175,454
Cumulative Timesteps: 1,341,083,386
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63593
Policy Entropy: 4.35395
Value Function Loss: 0.00225
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.92203
Value Function Update Magnitude: 0.70204
Collected Steps per Second: 13,584.43267
Overall Steps per Second: 7,355.84778
Timestep Collection Time: 3.68333
Timestep Consumption Time: 3.11887
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.80221
Cumulative Model Updates: 175,463
Cumulative Timesteps: 1,341,133,422
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1341133422...
Checkpoint 1341133422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84698
Policy Entropy: 4.35574
Value Function Loss: 0.00221
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.92217
Value Function Update Magnitude: 0.64864
Collected Steps per Second: 13,196.95721
Overall Steps per Second: 7,238.28538
Timestep Collection Time: 3.79103
Timestep Consumption Time: 3.12083
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.91186
Cumulative Model Updates: 175,472
Cumulative Timesteps: 1,341,183,452
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24476
Policy Entropy: 4.35749
Value Function Loss: 0.00224
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.91869
Value Function Update Magnitude: 0.64379
Collected Steps per Second: 13,250.80252
Overall Steps per Second: 7,347.56006
Timestep Collection Time: 3.77396
Timestep Consumption Time: 3.03211
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.80607
Cumulative Model Updates: 175,481
Cumulative Timesteps: 1,341,233,460
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1341233460...
Checkpoint 1341233460 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.70587
Policy Entropy: 4.35494
Value Function Loss: 0.00231
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.90086
Value Function Update Magnitude: 0.66091
Collected Steps per Second: 12,971.22204
Overall Steps per Second: 7,185.17526
Timestep Collection Time: 3.85500
Timestep Consumption Time: 3.10433
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.95933
Cumulative Model Updates: 175,490
Cumulative Timesteps: 1,341,283,464
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44734
Policy Entropy: 4.35376
Value Function Loss: 0.00227
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02674
Policy Update Magnitude: 0.89588
Value Function Update Magnitude: 0.70037
Collected Steps per Second: 13,156.58490
Overall Steps per Second: 7,280.87222
Timestep Collection Time: 3.80220
Timestep Consumption Time: 3.06840
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.87061
Cumulative Model Updates: 175,499
Cumulative Timesteps: 1,341,333,488
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1341333488...
Checkpoint 1341333488 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20826
Policy Entropy: 4.35533
Value Function Loss: 0.00220
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.87900
Value Function Update Magnitude: 0.65789
Collected Steps per Second: 13,041.88989
Overall Steps per Second: 7,272.61409
Timestep Collection Time: 3.83411
Timestep Consumption Time: 3.04155
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.87566
Cumulative Model Updates: 175,508
Cumulative Timesteps: 1,341,383,492
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50841
Policy Entropy: 4.36115
Value Function Loss: 0.00224
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.89129
Value Function Update Magnitude: 0.65086
Collected Steps per Second: 13,002.82088
Overall Steps per Second: 7,093.00539
Timestep Collection Time: 3.84717
Timestep Consumption Time: 3.20542
PPO Batch Consumption Time: 0.23728
Total Iteration Time: 7.05258
Cumulative Model Updates: 175,517
Cumulative Timesteps: 1,341,433,516
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1341433516...
Checkpoint 1341433516 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.59054
Policy Entropy: 4.35688
Value Function Loss: 0.00236
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.91807
Value Function Update Magnitude: 0.69915
Collected Steps per Second: 13,185.35880
Overall Steps per Second: 7,291.78135
Timestep Collection Time: 3.79299
Timestep Consumption Time: 3.06569
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.85868
Cumulative Model Updates: 175,526
Cumulative Timesteps: 1,341,483,528
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.78481
Policy Entropy: 4.35265
Value Function Loss: 0.00257
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.95013
Value Function Update Magnitude: 0.74906
Collected Steps per Second: 13,488.92625
Overall Steps per Second: 7,336.59403
Timestep Collection Time: 3.70852
Timestep Consumption Time: 3.10990
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.81842
Cumulative Model Updates: 175,535
Cumulative Timesteps: 1,341,533,552
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1341533552...
Checkpoint 1341533552 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39900
Policy Entropy: 4.35212
Value Function Loss: 0.00244
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.94334
Value Function Update Magnitude: 0.72432
Collected Steps per Second: 13,080.05746
Overall Steps per Second: 7,216.90437
Timestep Collection Time: 3.82338
Timestep Consumption Time: 3.10619
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.92956
Cumulative Model Updates: 175,544
Cumulative Timesteps: 1,341,583,562
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.86932
Policy Entropy: 4.35553
Value Function Loss: 0.00240
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.91708
Value Function Update Magnitude: 0.67723
Collected Steps per Second: 13,228.10375
Overall Steps per Second: 7,295.06541
Timestep Collection Time: 3.78104
Timestep Consumption Time: 3.07510
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.85614
Cumulative Model Updates: 175,553
Cumulative Timesteps: 1,341,633,578
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1341633578...
Checkpoint 1341633578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11966
Policy Entropy: 4.35771
Value Function Loss: 0.00219
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.89512
Value Function Update Magnitude: 0.65620
Collected Steps per Second: 13,503.44548
Overall Steps per Second: 7,354.37591
Timestep Collection Time: 3.70587
Timestep Consumption Time: 3.09852
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.80438
Cumulative Model Updates: 175,562
Cumulative Timesteps: 1,341,683,620
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.41966
Policy Entropy: 4.35428
Value Function Loss: 0.00237
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02426
Policy Update Magnitude: 0.89997
Value Function Update Magnitude: 0.65074
Collected Steps per Second: 13,289.10432
Overall Steps per Second: 7,285.72717
Timestep Collection Time: 3.76474
Timestep Consumption Time: 3.10211
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.86685
Cumulative Model Updates: 175,571
Cumulative Timesteps: 1,341,733,650
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1341733650...
Checkpoint 1341733650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33335
Policy Entropy: 4.35177
Value Function Loss: 0.00236
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.90377
Value Function Update Magnitude: 0.65579
Collected Steps per Second: 13,177.76370
Overall Steps per Second: 7,173.75975
Timestep Collection Time: 3.79685
Timestep Consumption Time: 3.17773
PPO Batch Consumption Time: 0.23963
Total Iteration Time: 6.97459
Cumulative Model Updates: 175,580
Cumulative Timesteps: 1,341,783,684
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.45824
Policy Entropy: 4.34866
Value Function Loss: 0.00242
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.91020
Value Function Update Magnitude: 0.69647
Collected Steps per Second: 13,345.12346
Overall Steps per Second: 7,292.60538
Timestep Collection Time: 3.74879
Timestep Consumption Time: 3.11131
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.86010
Cumulative Model Updates: 175,589
Cumulative Timesteps: 1,341,833,712
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1341833712...
Checkpoint 1341833712 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.16572
Policy Entropy: 4.35556
Value Function Loss: 0.00232
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02780
Policy Update Magnitude: 0.90181
Value Function Update Magnitude: 0.69205
Collected Steps per Second: 13,226.90519
Overall Steps per Second: 7,272.01111
Timestep Collection Time: 3.78093
Timestep Consumption Time: 3.09612
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.87705
Cumulative Model Updates: 175,598
Cumulative Timesteps: 1,341,883,722
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95887
Policy Entropy: 4.35563
Value Function Loss: 0.00250
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.89968
Value Function Update Magnitude: 0.68463
Collected Steps per Second: 13,213.90397
Overall Steps per Second: 7,356.97736
Timestep Collection Time: 3.78662
Timestep Consumption Time: 3.01455
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.80116
Cumulative Model Updates: 175,607
Cumulative Timesteps: 1,341,933,758
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1341933758...
Checkpoint 1341933758 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.02224
Policy Entropy: 4.35479
Value Function Loss: 0.00251
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.89544
Value Function Update Magnitude: 0.76554
Collected Steps per Second: 13,117.13189
Overall Steps per Second: 7,239.22342
Timestep Collection Time: 3.81288
Timestep Consumption Time: 3.09588
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.90875
Cumulative Model Updates: 175,616
Cumulative Timesteps: 1,341,983,772
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16505
Policy Entropy: 4.35336
Value Function Loss: 0.00251
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.90129
Value Function Update Magnitude: 0.73302
Collected Steps per Second: 13,289.27422
Overall Steps per Second: 7,312.26919
Timestep Collection Time: 3.76288
Timestep Consumption Time: 3.07576
PPO Batch Consumption Time: 0.22785
Total Iteration Time: 6.83864
Cumulative Model Updates: 175,625
Cumulative Timesteps: 1,342,033,778
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1342033778...
Checkpoint 1342033778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.54870
Policy Entropy: 4.35251
Value Function Loss: 0.00255
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.93136
Value Function Update Magnitude: 0.70736
Collected Steps per Second: 13,382.80094
Overall Steps per Second: 7,315.55511
Timestep Collection Time: 3.73659
Timestep Consumption Time: 3.09898
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.83557
Cumulative Model Updates: 175,634
Cumulative Timesteps: 1,342,083,784
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75272
Policy Entropy: 4.35497
Value Function Loss: 0.00251
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02583
Policy Update Magnitude: 0.92851
Value Function Update Magnitude: 0.71079
Collected Steps per Second: 13,313.86946
Overall Steps per Second: 7,050.71356
Timestep Collection Time: 3.75924
Timestep Consumption Time: 3.33933
PPO Batch Consumption Time: 0.24497
Total Iteration Time: 7.09857
Cumulative Model Updates: 175,643
Cumulative Timesteps: 1,342,133,834
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1342133834...
Checkpoint 1342133834 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68343
Policy Entropy: 4.35394
Value Function Loss: 0.00250
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02614
Policy Update Magnitude: 0.92046
Value Function Update Magnitude: 0.67321
Collected Steps per Second: 13,052.98689
Overall Steps per Second: 7,139.33798
Timestep Collection Time: 3.83345
Timestep Consumption Time: 3.17532
PPO Batch Consumption Time: 0.22965
Total Iteration Time: 7.00877
Cumulative Model Updates: 175,652
Cumulative Timesteps: 1,342,183,872
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00535
Policy Entropy: 4.35217
Value Function Loss: 0.00246
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.93882
Value Function Update Magnitude: 0.70098
Collected Steps per Second: 13,351.45797
Overall Steps per Second: 7,300.69444
Timestep Collection Time: 3.74761
Timestep Consumption Time: 3.10599
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.85359
Cumulative Model Updates: 175,661
Cumulative Timesteps: 1,342,233,908
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1342233908...
Checkpoint 1342233908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43367
Policy Entropy: 4.35260
Value Function Loss: 0.00243
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.92411
Value Function Update Magnitude: 0.68459
Collected Steps per Second: 13,323.02898
Overall Steps per Second: 7,289.98188
Timestep Collection Time: 3.75440
Timestep Consumption Time: 3.10707
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.86147
Cumulative Model Updates: 175,670
Cumulative Timesteps: 1,342,283,928
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.60192
Policy Entropy: 4.34890
Value Function Loss: 0.00235
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.91709
Value Function Update Magnitude: 0.68670
Collected Steps per Second: 13,180.18451
Overall Steps per Second: 7,323.98993
Timestep Collection Time: 3.79570
Timestep Consumption Time: 3.03500
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.83070
Cumulative Model Updates: 175,679
Cumulative Timesteps: 1,342,333,956
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1342333956...
Checkpoint 1342333956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.67302
Policy Entropy: 4.35202
Value Function Loss: 0.00243
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.93447
Value Function Update Magnitude: 0.73287
Collected Steps per Second: 13,138.99953
Overall Steps per Second: 7,220.70124
Timestep Collection Time: 3.80805
Timestep Consumption Time: 3.12119
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.92924
Cumulative Model Updates: 175,688
Cumulative Timesteps: 1,342,383,990
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.19006
Policy Entropy: 4.35146
Value Function Loss: 0.00237
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.92719
Value Function Update Magnitude: 0.68153
Collected Steps per Second: 13,119.99675
Overall Steps per Second: 7,268.36394
Timestep Collection Time: 3.81311
Timestep Consumption Time: 3.06987
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.88298
Cumulative Model Updates: 175,697
Cumulative Timesteps: 1,342,434,018
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1342434018...
Checkpoint 1342434018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09096
Policy Entropy: 4.35878
Value Function Loss: 0.00223
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.89893
Value Function Update Magnitude: 0.67814
Collected Steps per Second: 13,436.61968
Overall Steps per Second: 7,121.61686
Timestep Collection Time: 3.72430
Timestep Consumption Time: 3.30248
PPO Batch Consumption Time: 0.24551
Total Iteration Time: 7.02678
Cumulative Model Updates: 175,706
Cumulative Timesteps: 1,342,484,060
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02618
Policy Entropy: 4.35906
Value Function Loss: 0.00211
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.87748
Value Function Update Magnitude: 0.63290
Collected Steps per Second: 13,374.25559
Overall Steps per Second: 7,279.70449
Timestep Collection Time: 3.73987
Timestep Consumption Time: 3.13101
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.87088
Cumulative Model Updates: 175,715
Cumulative Timesteps: 1,342,534,078
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1342534078...
Checkpoint 1342534078 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80653
Policy Entropy: 4.36176
Value Function Loss: 0.00208
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.87813
Value Function Update Magnitude: 0.61665
Collected Steps per Second: 13,116.82851
Overall Steps per Second: 7,278.78815
Timestep Collection Time: 3.81479
Timestep Consumption Time: 3.05970
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.87450
Cumulative Model Updates: 175,724
Cumulative Timesteps: 1,342,584,116
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.35850
Policy Entropy: 4.36020
Value Function Loss: 0.00213
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.89328
Value Function Update Magnitude: 0.60236
Collected Steps per Second: 13,487.14317
Overall Steps per Second: 7,328.88908
Timestep Collection Time: 3.70887
Timestep Consumption Time: 3.11645
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.82532
Cumulative Model Updates: 175,733
Cumulative Timesteps: 1,342,634,138
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1342634138...
Checkpoint 1342634138 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16906
Policy Entropy: 4.36017
Value Function Loss: 0.00218
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02439
Policy Update Magnitude: 0.88402
Value Function Update Magnitude: 0.62149
Collected Steps per Second: 13,240.72873
Overall Steps per Second: 7,251.49775
Timestep Collection Time: 3.77653
Timestep Consumption Time: 3.11915
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.89568
Cumulative Model Updates: 175,742
Cumulative Timesteps: 1,342,684,142
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.25502
Policy Entropy: 4.35662
Value Function Loss: 0.00227
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02558
Policy Update Magnitude: 0.89438
Value Function Update Magnitude: 0.66685
Collected Steps per Second: 13,331.15473
Overall Steps per Second: 7,402.26959
Timestep Collection Time: 3.75286
Timestep Consumption Time: 3.00587
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.75874
Cumulative Model Updates: 175,751
Cumulative Timesteps: 1,342,734,172
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1342734172...
Checkpoint 1342734172 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.66440
Policy Entropy: 4.35384
Value Function Loss: 0.00236
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.89797
Value Function Update Magnitude: 0.66328
Collected Steps per Second: 13,127.64295
Overall Steps per Second: 7,243.98508
Timestep Collection Time: 3.80982
Timestep Consumption Time: 3.09439
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.90421
Cumulative Model Updates: 175,760
Cumulative Timesteps: 1,342,784,186
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09204
Policy Entropy: 4.35436
Value Function Loss: 0.00230
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.91168
Value Function Update Magnitude: 0.65711
Collected Steps per Second: 13,228.16831
Overall Steps per Second: 7,112.45495
Timestep Collection Time: 3.77996
Timestep Consumption Time: 3.25024
PPO Batch Consumption Time: 0.24205
Total Iteration Time: 7.03020
Cumulative Model Updates: 175,769
Cumulative Timesteps: 1,342,834,188
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1342834188...
Checkpoint 1342834188 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.34216
Policy Entropy: 4.35382
Value Function Loss: 0.00236
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.91610
Value Function Update Magnitude: 0.66846
Collected Steps per Second: 13,081.83212
Overall Steps per Second: 7,332.75800
Timestep Collection Time: 3.82500
Timestep Consumption Time: 2.99890
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.82390
Cumulative Model Updates: 175,778
Cumulative Timesteps: 1,342,884,226
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.86669
Policy Entropy: 4.35361
Value Function Loss: 0.00235
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.92430
Value Function Update Magnitude: 0.70126
Collected Steps per Second: 13,385.93087
Overall Steps per Second: 7,295.63558
Timestep Collection Time: 3.73571
Timestep Consumption Time: 3.11852
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.85423
Cumulative Model Updates: 175,787
Cumulative Timesteps: 1,342,934,232
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1342934232...
Checkpoint 1342934232 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.32944
Policy Entropy: 4.35512
Value Function Loss: 0.00242
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.92190
Value Function Update Magnitude: 0.78539
Collected Steps per Second: 13,056.66856
Overall Steps per Second: 7,241.38931
Timestep Collection Time: 3.83206
Timestep Consumption Time: 3.07738
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.90945
Cumulative Model Updates: 175,796
Cumulative Timesteps: 1,342,984,266
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.48730
Policy Entropy: 4.35805
Value Function Loss: 0.00219
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.89421
Value Function Update Magnitude: 0.72457
Collected Steps per Second: 13,526.89744
Overall Steps per Second: 7,353.03839
Timestep Collection Time: 3.70018
Timestep Consumption Time: 3.10680
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.80698
Cumulative Model Updates: 175,805
Cumulative Timesteps: 1,343,034,318
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1343034318...
Checkpoint 1343034318 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.83554
Policy Entropy: 4.35783
Value Function Loss: 0.00233
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02309
Policy Update Magnitude: 0.88225
Value Function Update Magnitude: 0.68591
Collected Steps per Second: 13,253.12547
Overall Steps per Second: 7,235.96415
Timestep Collection Time: 3.77300
Timestep Consumption Time: 3.13749
PPO Batch Consumption Time: 0.22918
Total Iteration Time: 6.91048
Cumulative Model Updates: 175,814
Cumulative Timesteps: 1,343,084,322
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.14337
Policy Entropy: 4.35398
Value Function Loss: 0.00237
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02236
Policy Update Magnitude: 0.91219
Value Function Update Magnitude: 0.68837
Collected Steps per Second: 13,464.48703
Overall Steps per Second: 7,420.57012
Timestep Collection Time: 3.71451
Timestep Consumption Time: 3.02540
PPO Batch Consumption Time: 0.22772
Total Iteration Time: 6.73991
Cumulative Model Updates: 175,823
Cumulative Timesteps: 1,343,134,336
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1343134336...
Checkpoint 1343134336 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71136
Policy Entropy: 4.35200
Value Function Loss: 0.00248
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.92123
Value Function Update Magnitude: 0.70778
Collected Steps per Second: 13,282.57536
Overall Steps per Second: 7,199.27833
Timestep Collection Time: 3.76508
Timestep Consumption Time: 3.18145
PPO Batch Consumption Time: 0.23542
Total Iteration Time: 6.94653
Cumulative Model Updates: 175,832
Cumulative Timesteps: 1,343,184,346
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.08882
Policy Entropy: 4.35199
Value Function Loss: 0.00238
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.91962
Value Function Update Magnitude: 0.71718
Collected Steps per Second: 13,220.81919
Overall Steps per Second: 7,304.63508
Timestep Collection Time: 3.78328
Timestep Consumption Time: 3.06416
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.84743
Cumulative Model Updates: 175,841
Cumulative Timesteps: 1,343,234,364
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1343234364...
Checkpoint 1343234364 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.13899
Policy Entropy: 4.35398
Value Function Loss: 0.00238
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.90901
Value Function Update Magnitude: 0.71012
Collected Steps per Second: 13,126.69508
Overall Steps per Second: 7,297.86090
Timestep Collection Time: 3.80934
Timestep Consumption Time: 3.04253
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.85187
Cumulative Model Updates: 175,850
Cumulative Timesteps: 1,343,284,368
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17625
Policy Entropy: 4.35374
Value Function Loss: 0.00242
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.93662
Value Function Update Magnitude: 0.67720
Collected Steps per Second: 13,220.64569
Overall Steps per Second: 7,263.71157
Timestep Collection Time: 3.78438
Timestep Consumption Time: 3.10355
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.88794
Cumulative Model Updates: 175,859
Cumulative Timesteps: 1,343,334,400
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1343334400...
Checkpoint 1343334400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.74339
Policy Entropy: 4.35220
Value Function Loss: 0.00248
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.93470
Value Function Update Magnitude: 0.67967
Collected Steps per Second: 13,234.16627
Overall Steps per Second: 7,372.47198
Timestep Collection Time: 3.77855
Timestep Consumption Time: 3.00425
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.78280
Cumulative Model Updates: 175,868
Cumulative Timesteps: 1,343,384,406
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95552
Policy Entropy: 4.35318
Value Function Loss: 0.00247
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.93473
Value Function Update Magnitude: 0.67301
Collected Steps per Second: 13,380.50273
Overall Steps per Second: 7,318.84534
Timestep Collection Time: 3.73872
Timestep Consumption Time: 3.09651
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.83523
Cumulative Model Updates: 175,877
Cumulative Timesteps: 1,343,434,432
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1343434432...
Checkpoint 1343434432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09401
Policy Entropy: 4.35717
Value Function Loss: 0.00245
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02512
Policy Update Magnitude: 0.92395
Value Function Update Magnitude: 0.69925
Collected Steps per Second: 13,172.45017
Overall Steps per Second: 7,280.07612
Timestep Collection Time: 3.79610
Timestep Consumption Time: 3.07250
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.86861
Cumulative Model Updates: 175,886
Cumulative Timesteps: 1,343,484,436
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.04953
Policy Entropy: 4.35633
Value Function Loss: 0.00252
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.93450
Value Function Update Magnitude: 0.75267
Collected Steps per Second: 13,126.03759
Overall Steps per Second: 7,181.68908
Timestep Collection Time: 3.81105
Timestep Consumption Time: 3.15444
PPO Batch Consumption Time: 0.24142
Total Iteration Time: 6.96549
Cumulative Model Updates: 175,895
Cumulative Timesteps: 1,343,534,460
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1343534460...
Checkpoint 1343534460 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09429
Policy Entropy: 4.35467
Value Function Loss: 0.00249
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.94551
Value Function Update Magnitude: 0.76284
Collected Steps per Second: 13,166.24615
Overall Steps per Second: 7,221.32094
Timestep Collection Time: 3.80002
Timestep Consumption Time: 3.12835
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.92837
Cumulative Model Updates: 175,904
Cumulative Timesteps: 1,343,584,492
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65489
Policy Entropy: 4.34890
Value Function Loss: 0.00262
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02788
Policy Update Magnitude: 0.96245
Value Function Update Magnitude: 0.76391
Collected Steps per Second: 13,324.93251
Overall Steps per Second: 7,324.74810
Timestep Collection Time: 3.75296
Timestep Consumption Time: 3.07430
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.82727
Cumulative Model Updates: 175,913
Cumulative Timesteps: 1,343,634,500
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1343634500...
Checkpoint 1343634500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.86723
Policy Entropy: 4.35446
Value Function Loss: 0.00232
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.93562
Value Function Update Magnitude: 0.75070
Collected Steps per Second: 13,438.50800
Overall Steps per Second: 7,331.28474
Timestep Collection Time: 3.72333
Timestep Consumption Time: 3.10167
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.82500
Cumulative Model Updates: 175,922
Cumulative Timesteps: 1,343,684,536
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25976
Policy Entropy: 4.35610
Value Function Loss: 0.00231
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.90996
Value Function Update Magnitude: 0.69709
Collected Steps per Second: 13,138.30822
Overall Steps per Second: 7,220.14697
Timestep Collection Time: 3.80612
Timestep Consumption Time: 3.11978
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.92590
Cumulative Model Updates: 175,931
Cumulative Timesteps: 1,343,734,542
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1343734542...
Checkpoint 1343734542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64567
Policy Entropy: 4.35752
Value Function Loss: 0.00219
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.91563
Value Function Update Magnitude: 0.66543
Collected Steps per Second: 13,364.34818
Overall Steps per Second: 7,283.13884
Timestep Collection Time: 3.74384
Timestep Consumption Time: 3.12600
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.86984
Cumulative Model Updates: 175,940
Cumulative Timesteps: 1,343,784,576
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88859
Policy Entropy: 4.35434
Value Function Loss: 0.00231
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.92044
Value Function Update Magnitude: 0.67664
Collected Steps per Second: 13,642.56964
Overall Steps per Second: 7,368.81427
Timestep Collection Time: 3.66515
Timestep Consumption Time: 3.12048
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.78562
Cumulative Model Updates: 175,949
Cumulative Timesteps: 1,343,834,578
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1343834578...
Checkpoint 1343834578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19312
Policy Entropy: 4.35520
Value Function Loss: 0.00237
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.93381
Value Function Update Magnitude: 0.70282
Collected Steps per Second: 13,102.84819
Overall Steps per Second: 7,080.46965
Timestep Collection Time: 3.81902
Timestep Consumption Time: 3.24831
PPO Batch Consumption Time: 0.23862
Total Iteration Time: 7.06733
Cumulative Model Updates: 175,958
Cumulative Timesteps: 1,343,884,618
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.80436
Policy Entropy: 4.35259
Value Function Loss: 0.00257
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.94254
Value Function Update Magnitude: 0.71089
Collected Steps per Second: 13,284.41588
Overall Steps per Second: 7,386.22170
Timestep Collection Time: 3.76411
Timestep Consumption Time: 3.00579
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.76990
Cumulative Model Updates: 175,967
Cumulative Timesteps: 1,343,934,622
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1343934622...
Checkpoint 1343934622 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46480
Policy Entropy: 4.35298
Value Function Loss: 0.00248
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.93606
Value Function Update Magnitude: 0.68565
Collected Steps per Second: 13,176.39863
Overall Steps per Second: 7,247.55011
Timestep Collection Time: 3.79557
Timestep Consumption Time: 3.10496
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.90054
Cumulative Model Updates: 175,976
Cumulative Timesteps: 1,343,984,634
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88815
Policy Entropy: 4.35201
Value Function Loss: 0.00241
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02701
Policy Update Magnitude: 0.91161
Value Function Update Magnitude: 0.70001
Collected Steps per Second: 13,366.52994
Overall Steps per Second: 7,328.07690
Timestep Collection Time: 3.74263
Timestep Consumption Time: 3.08399
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.82662
Cumulative Model Updates: 175,985
Cumulative Timesteps: 1,344,034,660
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1344034660...
Checkpoint 1344034660 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.21803
Policy Entropy: 4.35337
Value Function Loss: 0.00234
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.88900
Value Function Update Magnitude: 0.70806
Collected Steps per Second: 12,814.41153
Overall Steps per Second: 7,247.67621
Timestep Collection Time: 3.90670
Timestep Consumption Time: 3.00062
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.90732
Cumulative Model Updates: 175,994
Cumulative Timesteps: 1,344,084,722
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.27726
Policy Entropy: 4.35122
Value Function Loss: 0.00243
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.90762
Value Function Update Magnitude: 0.76268
Collected Steps per Second: 13,302.28616
Overall Steps per Second: 7,290.46178
Timestep Collection Time: 3.76056
Timestep Consumption Time: 3.10101
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.86157
Cumulative Model Updates: 176,003
Cumulative Timesteps: 1,344,134,746
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1344134746...
Checkpoint 1344134746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97727
Policy Entropy: 4.35197
Value Function Loss: 0.00242
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.91713
Value Function Update Magnitude: 0.75398
Collected Steps per Second: 13,242.72198
Overall Steps per Second: 7,331.36626
Timestep Collection Time: 3.77672
Timestep Consumption Time: 3.04520
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.82192
Cumulative Model Updates: 176,012
Cumulative Timesteps: 1,344,184,760
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.84639
Policy Entropy: 4.35325
Value Function Loss: 0.00254
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.92064
Value Function Update Magnitude: 0.76286
Collected Steps per Second: 13,562.14262
Overall Steps per Second: 7,379.37810
Timestep Collection Time: 3.68718
Timestep Consumption Time: 3.08928
PPO Batch Consumption Time: 0.22944
Total Iteration Time: 6.77645
Cumulative Model Updates: 176,021
Cumulative Timesteps: 1,344,234,766
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1344234766...
Checkpoint 1344234766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14628
Policy Entropy: 4.35410
Value Function Loss: 0.00249
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.91903
Value Function Update Magnitude: 0.75349
Collected Steps per Second: 13,174.38473
Overall Steps per Second: 7,253.78923
Timestep Collection Time: 3.79600
Timestep Consumption Time: 3.09833
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.89433
Cumulative Model Updates: 176,030
Cumulative Timesteps: 1,344,284,776
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.06976
Policy Entropy: 4.35567
Value Function Loss: 0.00234
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.90070
Value Function Update Magnitude: 0.70551
Collected Steps per Second: 13,223.80111
Overall Steps per Second: 7,372.24368
Timestep Collection Time: 3.78212
Timestep Consumption Time: 3.00198
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.78409
Cumulative Model Updates: 176,039
Cumulative Timesteps: 1,344,334,790
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1344334790...
Checkpoint 1344334790 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63188
Policy Entropy: 4.35431
Value Function Loss: 0.00222
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.87982
Value Function Update Magnitude: 0.70845
Collected Steps per Second: 13,239.67888
Overall Steps per Second: 7,264.84844
Timestep Collection Time: 3.77940
Timestep Consumption Time: 3.10829
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.88769
Cumulative Model Updates: 176,048
Cumulative Timesteps: 1,344,384,828
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.36794
Policy Entropy: 4.35451
Value Function Loss: 0.00212
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.86795
Value Function Update Magnitude: 0.73568
Collected Steps per Second: 13,249.91726
Overall Steps per Second: 7,316.28820
Timestep Collection Time: 3.77678
Timestep Consumption Time: 3.06303
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.83981
Cumulative Model Updates: 176,057
Cumulative Timesteps: 1,344,434,870
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1344434870...
Checkpoint 1344434870 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27340
Policy Entropy: 4.35375
Value Function Loss: 0.00240
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02507
Policy Update Magnitude: 0.89667
Value Function Update Magnitude: 0.74438
Collected Steps per Second: 13,519.82297
Overall Steps per Second: 7,269.26375
Timestep Collection Time: 3.69887
Timestep Consumption Time: 3.18051
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.87938
Cumulative Model Updates: 176,066
Cumulative Timesteps: 1,344,484,878
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70323
Policy Entropy: 4.35891
Value Function Loss: 0.00238
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.91511
Value Function Update Magnitude: 0.76050
Collected Steps per Second: 13,192.28894
Overall Steps per Second: 7,255.79583
Timestep Collection Time: 3.79206
Timestep Consumption Time: 3.10256
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.89463
Cumulative Model Updates: 176,075
Cumulative Timesteps: 1,344,534,904
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1344534904...
Checkpoint 1344534904 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28736
Policy Entropy: 4.35881
Value Function Loss: 0.00243
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.91268
Value Function Update Magnitude: 0.72566
Collected Steps per Second: 13,059.39329
Overall Steps per Second: 7,217.86261
Timestep Collection Time: 3.83004
Timestep Consumption Time: 3.09971
PPO Batch Consumption Time: 0.23024
Total Iteration Time: 6.92975
Cumulative Model Updates: 176,084
Cumulative Timesteps: 1,344,584,922
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.63462
Policy Entropy: 4.36015
Value Function Loss: 0.00229
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.90561
Value Function Update Magnitude: 0.69520
Collected Steps per Second: 13,515.85986
Overall Steps per Second: 7,362.41514
Timestep Collection Time: 3.70099
Timestep Consumption Time: 3.09325
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.79424
Cumulative Model Updates: 176,093
Cumulative Timesteps: 1,344,634,944
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1344634944...
Checkpoint 1344634944 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.03703
Policy Entropy: 4.35212
Value Function Loss: 0.00249
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.92473
Value Function Update Magnitude: 0.65423
Collected Steps per Second: 13,348.94323
Overall Steps per Second: 7,282.97463
Timestep Collection Time: 3.74591
Timestep Consumption Time: 3.11996
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.86588
Cumulative Model Updates: 176,102
Cumulative Timesteps: 1,344,684,948
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90462
Policy Entropy: 4.35386
Value Function Loss: 0.00248
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.91808
Value Function Update Magnitude: 0.65303
Collected Steps per Second: 13,202.13491
Overall Steps per Second: 7,356.94174
Timestep Collection Time: 3.79136
Timestep Consumption Time: 3.01229
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.80364
Cumulative Model Updates: 176,111
Cumulative Timesteps: 1,344,735,002
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1344735002...
Checkpoint 1344735002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.23944
Policy Entropy: 4.34972
Value Function Loss: 0.00255
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.91747
Value Function Update Magnitude: 0.69854
Collected Steps per Second: 13,188.40819
Overall Steps per Second: 7,228.12464
Timestep Collection Time: 3.79151
Timestep Consumption Time: 3.12647
PPO Batch Consumption Time: 0.22949
Total Iteration Time: 6.91798
Cumulative Model Updates: 176,120
Cumulative Timesteps: 1,344,785,006
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.89833
Policy Entropy: 4.35341
Value Function Loss: 0.00249
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.92793
Value Function Update Magnitude: 0.71881
Collected Steps per Second: 13,177.14078
Overall Steps per Second: 7,287.13904
Timestep Collection Time: 3.79764
Timestep Consumption Time: 3.06953
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.86717
Cumulative Model Updates: 176,129
Cumulative Timesteps: 1,344,835,048
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1344835048...
Checkpoint 1344835048 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.36863
Policy Entropy: 4.35155
Value Function Loss: 0.00242
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.92936
Value Function Update Magnitude: 0.72250
Collected Steps per Second: 13,237.59646
Overall Steps per Second: 7,378.73528
Timestep Collection Time: 3.77742
Timestep Consumption Time: 2.99935
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.77677
Cumulative Model Updates: 176,138
Cumulative Timesteps: 1,344,885,052
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56885
Policy Entropy: 4.35265
Value Function Loss: 0.00229
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02507
Policy Update Magnitude: 0.90686
Value Function Update Magnitude: 0.69264
Collected Steps per Second: 13,361.36856
Overall Steps per Second: 7,132.78385
Timestep Collection Time: 3.74453
Timestep Consumption Time: 3.26985
PPO Batch Consumption Time: 0.24086
Total Iteration Time: 7.01437
Cumulative Model Updates: 176,147
Cumulative Timesteps: 1,344,935,084
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1344935084...
Checkpoint 1344935084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89613
Policy Entropy: 4.35637
Value Function Loss: 0.00220
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.88532
Value Function Update Magnitude: 0.66788
Collected Steps per Second: 13,213.72765
Overall Steps per Second: 7,292.55740
Timestep Collection Time: 3.78712
Timestep Consumption Time: 3.07494
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.86206
Cumulative Model Updates: 176,156
Cumulative Timesteps: 1,344,985,126
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.94860
Policy Entropy: 4.35855
Value Function Loss: 0.00228
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.89179
Value Function Update Magnitude: 0.70499
Collected Steps per Second: 13,542.87366
Overall Steps per Second: 7,350.01826
Timestep Collection Time: 3.69213
Timestep Consumption Time: 3.11085
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.80298
Cumulative Model Updates: 176,165
Cumulative Timesteps: 1,345,035,128
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1345035128...
Checkpoint 1345035128 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71982
Policy Entropy: 4.36033
Value Function Loss: 0.00233
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.89682
Value Function Update Magnitude: 0.70296
Collected Steps per Second: 13,293.21023
Overall Steps per Second: 7,261.67686
Timestep Collection Time: 3.76222
Timestep Consumption Time: 3.12489
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.88711
Cumulative Model Updates: 176,174
Cumulative Timesteps: 1,345,085,140
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82653
Policy Entropy: 4.36017
Value Function Loss: 0.00240
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.89725
Value Function Update Magnitude: 0.70158
Collected Steps per Second: 13,164.12146
Overall Steps per Second: 7,276.05179
Timestep Collection Time: 3.79835
Timestep Consumption Time: 3.07378
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.87213
Cumulative Model Updates: 176,183
Cumulative Timesteps: 1,345,135,142
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1345135142...
Checkpoint 1345135142 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.55422
Policy Entropy: 4.35711
Value Function Loss: 0.00239
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.89945
Value Function Update Magnitude: 0.71411
Collected Steps per Second: 13,441.97660
Overall Steps per Second: 7,336.86871
Timestep Collection Time: 3.72267
Timestep Consumption Time: 3.09768
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.82035
Cumulative Model Updates: 176,192
Cumulative Timesteps: 1,345,185,182
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46001
Policy Entropy: 4.35367
Value Function Loss: 0.00251
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.91469
Value Function Update Magnitude: 0.71610
Collected Steps per Second: 13,247.97269
Overall Steps per Second: 7,250.91357
Timestep Collection Time: 3.77582
Timestep Consumption Time: 3.12289
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.89872
Cumulative Model Updates: 176,201
Cumulative Timesteps: 1,345,235,204
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1345235204...
Checkpoint 1345235204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16716
Policy Entropy: 4.35537
Value Function Loss: 0.00271
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.92554
Value Function Update Magnitude: 0.73652
Collected Steps per Second: 13,150.34380
Overall Steps per Second: 7,147.87609
Timestep Collection Time: 3.80294
Timestep Consumption Time: 3.19354
PPO Batch Consumption Time: 0.24133
Total Iteration Time: 6.99648
Cumulative Model Updates: 176,210
Cumulative Timesteps: 1,345,285,214
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.74991
Policy Entropy: 4.35660
Value Function Loss: 0.00269
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02770
Policy Update Magnitude: 0.92185
Value Function Update Magnitude: 0.76513
Collected Steps per Second: 13,241.75354
Overall Steps per Second: 7,243.79494
Timestep Collection Time: 3.77896
Timestep Consumption Time: 3.12903
PPO Batch Consumption Time: 0.22935
Total Iteration Time: 6.90798
Cumulative Model Updates: 176,219
Cumulative Timesteps: 1,345,335,254
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1345335254...
Checkpoint 1345335254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85063
Policy Entropy: 4.36166
Value Function Loss: 0.00259
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.91984
Value Function Update Magnitude: 0.77618
Collected Steps per Second: 13,269.70414
Overall Steps per Second: 7,318.68563
Timestep Collection Time: 3.76858
Timestep Consumption Time: 3.06434
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.83292
Cumulative Model Updates: 176,228
Cumulative Timesteps: 1,345,385,262
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.10387
Policy Entropy: 4.35645
Value Function Loss: 0.00256
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.93266
Value Function Update Magnitude: 0.77157
Collected Steps per Second: 13,248.37237
Overall Steps per Second: 7,389.33732
Timestep Collection Time: 3.77646
Timestep Consumption Time: 2.99437
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.77084
Cumulative Model Updates: 176,237
Cumulative Timesteps: 1,345,435,294
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1345435294...
Checkpoint 1345435294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98440
Policy Entropy: 4.35825
Value Function Loss: 0.00251
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.91887
Value Function Update Magnitude: 0.76246
Collected Steps per Second: 13,240.17132
Overall Steps per Second: 7,272.62197
Timestep Collection Time: 3.77835
Timestep Consumption Time: 3.10032
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.87867
Cumulative Model Updates: 176,246
Cumulative Timesteps: 1,345,485,320
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84493
Policy Entropy: 4.35615
Value Function Loss: 0.00242
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.90260
Value Function Update Magnitude: 0.75811
Collected Steps per Second: 13,249.46597
Overall Steps per Second: 7,315.38986
Timestep Collection Time: 3.77464
Timestep Consumption Time: 3.06190
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.83655
Cumulative Model Updates: 176,255
Cumulative Timesteps: 1,345,535,332
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1345535332...
Checkpoint 1345535332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61937
Policy Entropy: 4.35820
Value Function Loss: 0.00256
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02443
Policy Update Magnitude: 0.92528
Value Function Update Magnitude: 0.71399
Collected Steps per Second: 13,525.63802
Overall Steps per Second: 7,371.05084
Timestep Collection Time: 3.69979
Timestep Consumption Time: 3.08920
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.78899
Cumulative Model Updates: 176,264
Cumulative Timesteps: 1,345,585,374
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93313
Policy Entropy: 4.35399
Value Function Loss: 0.00253
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.91639
Value Function Update Magnitude: 0.71415
Collected Steps per Second: 13,162.66623
Overall Steps per Second: 7,048.04235
Timestep Collection Time: 3.80136
Timestep Consumption Time: 3.29792
PPO Batch Consumption Time: 0.24505
Total Iteration Time: 7.09928
Cumulative Model Updates: 176,273
Cumulative Timesteps: 1,345,635,410
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1345635410...
Checkpoint 1345635410 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09878
Policy Entropy: 4.35120
Value Function Loss: 0.00268
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.91441
Value Function Update Magnitude: 0.72983
Collected Steps per Second: 13,314.29229
Overall Steps per Second: 7,372.45374
Timestep Collection Time: 3.75792
Timestep Consumption Time: 3.02870
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.78661
Cumulative Model Updates: 176,282
Cumulative Timesteps: 1,345,685,444
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.25244
Policy Entropy: 4.34831
Value Function Loss: 0.00269
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.94113
Value Function Update Magnitude: 0.73578
Collected Steps per Second: 13,397.82937
Overall Steps per Second: 7,324.19258
Timestep Collection Time: 3.73269
Timestep Consumption Time: 3.09536
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.82806
Cumulative Model Updates: 176,291
Cumulative Timesteps: 1,345,735,454
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1345735454...
Checkpoint 1345735454 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66866
Policy Entropy: 4.34987
Value Function Loss: 0.00252
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.92754
Value Function Update Magnitude: 0.76518
Collected Steps per Second: 13,184.73814
Overall Steps per Second: 7,286.29153
Timestep Collection Time: 3.79242
Timestep Consumption Time: 3.07006
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.86248
Cumulative Model Updates: 176,300
Cumulative Timesteps: 1,345,785,456
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.27942
Policy Entropy: 4.35181
Value Function Loss: 0.00253
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.91999
Value Function Update Magnitude: 0.74979
Collected Steps per Second: 13,190.84638
Overall Steps per Second: 7,378.34317
Timestep Collection Time: 3.79096
Timestep Consumption Time: 2.98644
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.77740
Cumulative Model Updates: 176,309
Cumulative Timesteps: 1,345,835,462
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1345835462...
Checkpoint 1345835462 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54213
Policy Entropy: 4.35089
Value Function Loss: 0.00233
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.91282
Value Function Update Magnitude: 0.73836
Collected Steps per Second: 13,276.54154
Overall Steps per Second: 7,275.69086
Timestep Collection Time: 3.76634
Timestep Consumption Time: 3.10641
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.87275
Cumulative Model Updates: 176,318
Cumulative Timesteps: 1,345,885,466
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.93052
Policy Entropy: 4.34865
Value Function Loss: 0.00244
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.90261
Value Function Update Magnitude: 0.76262
Collected Steps per Second: 13,332.41985
Overall Steps per Second: 7,321.27807
Timestep Collection Time: 3.75266
Timestep Consumption Time: 3.08112
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.83378
Cumulative Model Updates: 176,327
Cumulative Timesteps: 1,345,935,498
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1345935498...
Checkpoint 1345935498 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51767
Policy Entropy: 4.34844
Value Function Loss: 0.00251
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.92237
Value Function Update Magnitude: 0.72626
Collected Steps per Second: 13,391.96589
Overall Steps per Second: 7,298.73787
Timestep Collection Time: 3.73672
Timestep Consumption Time: 3.11954
PPO Batch Consumption Time: 0.23030
Total Iteration Time: 6.85625
Cumulative Model Updates: 176,336
Cumulative Timesteps: 1,345,985,540
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02056
Policy Entropy: 4.35181
Value Function Loss: 0.00249
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.91458
Value Function Update Magnitude: 0.76457
Collected Steps per Second: 13,321.98771
Overall Steps per Second: 7,267.06591
Timestep Collection Time: 3.75605
Timestep Consumption Time: 3.12954
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.88558
Cumulative Model Updates: 176,345
Cumulative Timesteps: 1,346,035,578
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1346035578...
Checkpoint 1346035578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18590
Policy Entropy: 4.35332
Value Function Loss: 0.00246
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.89061
Value Function Update Magnitude: 0.75953
Collected Steps per Second: 13,231.32153
Overall Steps per Second: 7,296.16478
Timestep Collection Time: 3.78073
Timestep Consumption Time: 3.07548
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.85620
Cumulative Model Updates: 176,354
Cumulative Timesteps: 1,346,085,602
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.92499
Policy Entropy: 4.35301
Value Function Loss: 0.00231
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.88847
Value Function Update Magnitude: 0.74965
Collected Steps per Second: 13,443.58532
Overall Steps per Second: 7,340.24662
Timestep Collection Time: 3.71939
Timestep Consumption Time: 3.09264
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.81203
Cumulative Model Updates: 176,363
Cumulative Timesteps: 1,346,135,604
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1346135604...
Checkpoint 1346135604 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.56637
Policy Entropy: 4.35511
Value Function Loss: 0.00229
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.91575
Value Function Update Magnitude: 0.70975
Collected Steps per Second: 13,153.29631
Overall Steps per Second: 7,254.46139
Timestep Collection Time: 3.80422
Timestep Consumption Time: 3.09333
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.89755
Cumulative Model Updates: 176,372
Cumulative Timesteps: 1,346,185,642
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32928
Policy Entropy: 4.35287
Value Function Loss: 0.00248
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.92791
Value Function Update Magnitude: 0.70688
Collected Steps per Second: 13,379.28395
Overall Steps per Second: 7,413.21096
Timestep Collection Time: 3.73787
Timestep Consumption Time: 3.00820
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.74606
Cumulative Model Updates: 176,381
Cumulative Timesteps: 1,346,235,652
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1346235652...
Checkpoint 1346235652 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85114
Policy Entropy: 4.35573
Value Function Loss: 0.00241
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.91992
Value Function Update Magnitude: 0.76653
Collected Steps per Second: 13,234.04903
Overall Steps per Second: 7,272.93927
Timestep Collection Time: 3.77813
Timestep Consumption Time: 3.09667
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.87480
Cumulative Model Updates: 176,390
Cumulative Timesteps: 1,346,285,652
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76130
Policy Entropy: 4.35775
Value Function Loss: 0.00238
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02618
Policy Update Magnitude: 0.91435
Value Function Update Magnitude: 0.77760
Collected Steps per Second: 13,249.01988
Overall Steps per Second: 7,130.12630
Timestep Collection Time: 3.77673
Timestep Consumption Time: 3.24110
PPO Batch Consumption Time: 0.24106
Total Iteration Time: 7.01783
Cumulative Model Updates: 176,399
Cumulative Timesteps: 1,346,335,690
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1346335690...
Checkpoint 1346335690 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11667
Policy Entropy: 4.35985
Value Function Loss: 0.00240
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.93153
Value Function Update Magnitude: 0.74839
Collected Steps per Second: 13,545.75117
Overall Steps per Second: 7,340.09140
Timestep Collection Time: 3.69356
Timestep Consumption Time: 3.12271
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.81626
Cumulative Model Updates: 176,408
Cumulative Timesteps: 1,346,385,722
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12903
Policy Entropy: 4.35928
Value Function Loss: 0.00247
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.92096
Value Function Update Magnitude: 0.71708
Collected Steps per Second: 13,318.93572
Overall Steps per Second: 7,279.93440
Timestep Collection Time: 3.75646
Timestep Consumption Time: 3.11613
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.87259
Cumulative Model Updates: 176,417
Cumulative Timesteps: 1,346,435,754
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1346435754...
Checkpoint 1346435754 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43625
Policy Entropy: 4.35783
Value Function Loss: 0.00239
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.88495
Value Function Update Magnitude: 0.68716
Collected Steps per Second: 13,263.78223
Overall Steps per Second: 7,300.57539
Timestep Collection Time: 3.77102
Timestep Consumption Time: 3.08022
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.85124
Cumulative Model Updates: 176,426
Cumulative Timesteps: 1,346,485,772
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.10157
Policy Entropy: 4.35874
Value Function Loss: 0.00238
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.88696
Value Function Update Magnitude: 0.71466
Collected Steps per Second: 13,546.41360
Overall Steps per Second: 7,352.37233
Timestep Collection Time: 3.69234
Timestep Consumption Time: 3.11063
PPO Batch Consumption Time: 0.22797
Total Iteration Time: 6.80297
Cumulative Model Updates: 176,435
Cumulative Timesteps: 1,346,535,790
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1346535790...
Checkpoint 1346535790 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.02898
Policy Entropy: 4.35701
Value Function Loss: 0.00254
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.92433
Value Function Update Magnitude: 0.76892
Collected Steps per Second: 13,100.86593
Overall Steps per Second: 7,209.16444
Timestep Collection Time: 3.81700
Timestep Consumption Time: 3.11945
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.93645
Cumulative Model Updates: 176,444
Cumulative Timesteps: 1,346,585,796
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.79258
Policy Entropy: 4.35236
Value Function Loss: 0.00261
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.94359
Value Function Update Magnitude: 0.76959
Collected Steps per Second: 13,150.00915
Overall Steps per Second: 7,346.68735
Timestep Collection Time: 3.80441
Timestep Consumption Time: 3.00519
PPO Batch Consumption Time: 0.22794
Total Iteration Time: 6.80960
Cumulative Model Updates: 176,453
Cumulative Timesteps: 1,346,635,824
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1346635824...
Checkpoint 1346635824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.81445
Policy Entropy: 4.35553
Value Function Loss: 0.00254
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.93616
Value Function Update Magnitude: 0.75662
Collected Steps per Second: 12,979.39176
Overall Steps per Second: 7,028.56980
Timestep Collection Time: 3.85288
Timestep Consumption Time: 3.26208
PPO Batch Consumption Time: 0.24232
Total Iteration Time: 7.11496
Cumulative Model Updates: 176,462
Cumulative Timesteps: 1,346,685,832
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61592
Policy Entropy: 4.35253
Value Function Loss: 0.00242
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.92610
Value Function Update Magnitude: 0.72830
Collected Steps per Second: 13,252.80228
Overall Steps per Second: 7,299.75035
Timestep Collection Time: 3.77294
Timestep Consumption Time: 3.07689
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.84982
Cumulative Model Updates: 176,471
Cumulative Timesteps: 1,346,735,834
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1346735834...
Checkpoint 1346735834 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87538
Policy Entropy: 4.35159
Value Function Loss: 0.00246
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02439
Policy Update Magnitude: 0.93374
Value Function Update Magnitude: 0.70970
Collected Steps per Second: 13,112.49036
Overall Steps per Second: 7,330.51547
Timestep Collection Time: 3.81438
Timestep Consumption Time: 3.00861
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.82299
Cumulative Model Updates: 176,480
Cumulative Timesteps: 1,346,785,850
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74042
Policy Entropy: 4.35022
Value Function Loss: 0.00246
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.92274
Value Function Update Magnitude: 0.71671
Collected Steps per Second: 13,207.11570
Overall Steps per Second: 7,243.69069
Timestep Collection Time: 3.78781
Timestep Consumption Time: 3.11834
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.90615
Cumulative Model Updates: 176,489
Cumulative Timesteps: 1,346,835,876
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1346835876...
Checkpoint 1346835876 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.50367
Policy Entropy: 4.35347
Value Function Loss: 0.00228
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.89157
Value Function Update Magnitude: 0.71985
Collected Steps per Second: 13,172.58147
Overall Steps per Second: 7,258.03321
Timestep Collection Time: 3.79576
Timestep Consumption Time: 3.09316
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.88892
Cumulative Model Updates: 176,498
Cumulative Timesteps: 1,346,885,876
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72067
Policy Entropy: 4.35623
Value Function Loss: 0.00228
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02512
Policy Update Magnitude: 0.87895
Value Function Update Magnitude: 0.69955
Collected Steps per Second: 13,597.06940
Overall Steps per Second: 7,387.18104
Timestep Collection Time: 3.67859
Timestep Consumption Time: 3.09233
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.77092
Cumulative Model Updates: 176,507
Cumulative Timesteps: 1,346,935,894
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1346935894...
Checkpoint 1346935894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.05295
Policy Entropy: 4.35427
Value Function Loss: 0.00250
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.92234
Value Function Update Magnitude: 0.67185
Collected Steps per Second: 13,281.42125
Overall Steps per Second: 7,274.94282
Timestep Collection Time: 3.76511
Timestep Consumption Time: 3.10862
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.87373
Cumulative Model Updates: 176,516
Cumulative Timesteps: 1,346,985,900
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.56426
Policy Entropy: 4.35288
Value Function Loss: 0.00270
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02627
Policy Update Magnitude: 0.94907
Value Function Update Magnitude: 0.68871
Collected Steps per Second: 13,222.91258
Overall Steps per Second: 7,139.36229
Timestep Collection Time: 3.78283
Timestep Consumption Time: 3.22340
PPO Batch Consumption Time: 0.23993
Total Iteration Time: 7.00623
Cumulative Model Updates: 176,525
Cumulative Timesteps: 1,347,035,920
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1347035920...
Checkpoint 1347035920 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.07086
Policy Entropy: 4.34990
Value Function Loss: 0.00279
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.96020
Value Function Update Magnitude: 0.73793
Collected Steps per Second: 13,374.69690
Overall Steps per Second: 7,273.29253
Timestep Collection Time: 3.73975
Timestep Consumption Time: 3.13719
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.87694
Cumulative Model Updates: 176,534
Cumulative Timesteps: 1,347,085,938
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.59035
Policy Entropy: 4.34780
Value Function Loss: 0.00284
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.97594
Value Function Update Magnitude: 0.77069
Collected Steps per Second: 13,232.83250
Overall Steps per Second: 7,278.82823
Timestep Collection Time: 3.78105
Timestep Consumption Time: 3.09286
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.87391
Cumulative Model Updates: 176,543
Cumulative Timesteps: 1,347,135,972
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1347135972...
Checkpoint 1347135972 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20628
Policy Entropy: 4.34390
Value Function Loss: 0.00284
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02978
Policy Update Magnitude: 0.98878
Value Function Update Magnitude: 0.80212
Collected Steps per Second: 13,072.14204
Overall Steps per Second: 7,343.49242
Timestep Collection Time: 3.82692
Timestep Consumption Time: 2.98537
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.81229
Cumulative Model Updates: 176,552
Cumulative Timesteps: 1,347,185,998
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.52301
Policy Entropy: 4.34547
Value Function Loss: 0.00283
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02956
Policy Update Magnitude: 0.96930
Value Function Update Magnitude: 0.74430
Collected Steps per Second: 13,222.26078
Overall Steps per Second: 7,255.75675
Timestep Collection Time: 3.78407
Timestep Consumption Time: 3.11169
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.89577
Cumulative Model Updates: 176,561
Cumulative Timesteps: 1,347,236,032
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1347236032...
Checkpoint 1347236032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26472
Policy Entropy: 4.34750
Value Function Loss: 0.00270
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.94556
Value Function Update Magnitude: 0.71405
Collected Steps per Second: 13,145.50141
Overall Steps per Second: 7,269.67618
Timestep Collection Time: 3.80510
Timestep Consumption Time: 3.07553
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.88064
Cumulative Model Updates: 176,570
Cumulative Timesteps: 1,347,286,052
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.86411
Policy Entropy: 4.34804
Value Function Loss: 0.00273
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02854
Policy Update Magnitude: 0.94461
Value Function Update Magnitude: 0.77675
Collected Steps per Second: 13,480.01780
Overall Steps per Second: 7,348.67929
Timestep Collection Time: 3.71157
Timestep Consumption Time: 3.09673
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.80830
Cumulative Model Updates: 176,579
Cumulative Timesteps: 1,347,336,084
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1347336084...
Checkpoint 1347336084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.17573
Policy Entropy: 4.34677
Value Function Loss: 0.00272
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02633
Policy Update Magnitude: 0.95450
Value Function Update Magnitude: 0.75877
Collected Steps per Second: 13,196.02636
Overall Steps per Second: 7,074.27176
Timestep Collection Time: 3.79099
Timestep Consumption Time: 3.28055
PPO Batch Consumption Time: 0.24318
Total Iteration Time: 7.07154
Cumulative Model Updates: 176,588
Cumulative Timesteps: 1,347,386,110
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.55268
Policy Entropy: 4.34590
Value Function Loss: 0.00259
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02880
Policy Update Magnitude: 0.95092
Value Function Update Magnitude: 0.73966
Collected Steps per Second: 13,152.70011
Overall Steps per Second: 7,282.96272
Timestep Collection Time: 3.80378
Timestep Consumption Time: 3.06568
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.86946
Cumulative Model Updates: 176,597
Cumulative Timesteps: 1,347,436,140
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1347436140...
Checkpoint 1347436140 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.07738
Policy Entropy: 4.34783
Value Function Loss: 0.00257
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.94224
Value Function Update Magnitude: 0.70864
Collected Steps per Second: 13,398.09983
Overall Steps per Second: 7,308.32517
Timestep Collection Time: 3.73292
Timestep Consumption Time: 3.11051
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.84343
Cumulative Model Updates: 176,606
Cumulative Timesteps: 1,347,486,154
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33260
Policy Entropy: 4.34797
Value Function Loss: 0.00246
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.92380
Value Function Update Magnitude: 0.69083
Collected Steps per Second: 13,327.57232
Overall Steps per Second: 7,291.43858
Timestep Collection Time: 3.75327
Timestep Consumption Time: 3.10710
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.86037
Cumulative Model Updates: 176,615
Cumulative Timesteps: 1,347,536,176
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1347536176...
Checkpoint 1347536176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00105
Policy Entropy: 4.34850
Value Function Loss: 0.00251
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.92056
Value Function Update Magnitude: 0.77806
Collected Steps per Second: 13,282.94359
Overall Steps per Second: 7,381.45110
Timestep Collection Time: 3.76558
Timestep Consumption Time: 3.01059
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.77617
Cumulative Model Updates: 176,624
Cumulative Timesteps: 1,347,586,194
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.89068
Policy Entropy: 4.34592
Value Function Loss: 0.00251
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.92587
Value Function Update Magnitude: 0.81887
Collected Steps per Second: 13,313.31783
Overall Steps per Second: 7,261.19661
Timestep Collection Time: 3.75609
Timestep Consumption Time: 3.13066
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.88674
Cumulative Model Updates: 176,633
Cumulative Timesteps: 1,347,636,200
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1347636200...
Checkpoint 1347636200 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.32357
Policy Entropy: 4.34458
Value Function Loss: 0.00255
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.94462
Value Function Update Magnitude: 0.78844
Collected Steps per Second: 13,288.63890
Overall Steps per Second: 7,315.75064
Timestep Collection Time: 3.76306
Timestep Consumption Time: 3.07232
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.83539
Cumulative Model Updates: 176,642
Cumulative Timesteps: 1,347,686,206
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43483
Policy Entropy: 4.34672
Value Function Loss: 0.00251
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.91944
Value Function Update Magnitude: 0.75367
Collected Steps per Second: 13,124.38750
Overall Steps per Second: 7,263.65151
Timestep Collection Time: 3.81092
Timestep Consumption Time: 3.07487
PPO Batch Consumption Time: 0.23356
Total Iteration Time: 6.88579
Cumulative Model Updates: 176,651
Cumulative Timesteps: 1,347,736,222
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1347736222...
Checkpoint 1347736222 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96566
Policy Entropy: 4.34299
Value Function Loss: 0.00266
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02594
Policy Update Magnitude: 0.95254
Value Function Update Magnitude: 0.76932
Collected Steps per Second: 13,319.99045
Overall Steps per Second: 7,271.27168
Timestep Collection Time: 3.75631
Timestep Consumption Time: 3.12474
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.88105
Cumulative Model Updates: 176,660
Cumulative Timesteps: 1,347,786,256
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83482
Policy Entropy: 4.34299
Value Function Loss: 0.00260
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02501
Policy Update Magnitude: 0.95501
Value Function Update Magnitude: 0.76336
Collected Steps per Second: 13,107.30926
Overall Steps per Second: 7,353.62298
Timestep Collection Time: 3.81543
Timestep Consumption Time: 2.98530
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.80073
Cumulative Model Updates: 176,669
Cumulative Timesteps: 1,347,836,266
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1347836266...
Checkpoint 1347836266 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28685
Policy Entropy: 4.34200
Value Function Loss: 0.00270
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.96200
Value Function Update Magnitude: 0.74297
Collected Steps per Second: 13,160.07662
Overall Steps per Second: 7,238.27899
Timestep Collection Time: 3.80165
Timestep Consumption Time: 3.11021
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.91186
Cumulative Model Updates: 176,678
Cumulative Timesteps: 1,347,886,296
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09550
Policy Entropy: 4.34444
Value Function Loss: 0.00254
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02426
Policy Update Magnitude: 0.92822
Value Function Update Magnitude: 0.70602
Collected Steps per Second: 13,247.49705
Overall Steps per Second: 7,324.93877
Timestep Collection Time: 3.77686
Timestep Consumption Time: 3.05377
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.83064
Cumulative Model Updates: 176,687
Cumulative Timesteps: 1,347,936,330
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1347936330...
Checkpoint 1347936330 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.65089
Policy Entropy: 4.34361
Value Function Loss: 0.00254
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02443
Policy Update Magnitude: 0.91916
Value Function Update Magnitude: 0.73090
Collected Steps per Second: 13,143.95893
Overall Steps per Second: 7,319.14558
Timestep Collection Time: 3.80570
Timestep Consumption Time: 3.02870
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.83440
Cumulative Model Updates: 176,696
Cumulative Timesteps: 1,347,986,352
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44789
Policy Entropy: 4.34322
Value Function Loss: 0.00249
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.91739
Value Function Update Magnitude: 0.76353
Collected Steps per Second: 13,302.87958
Overall Steps per Second: 7,277.78503
Timestep Collection Time: 3.75919
Timestep Consumption Time: 3.11214
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.87132
Cumulative Model Updates: 176,705
Cumulative Timesteps: 1,348,036,360
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1348036360...
Checkpoint 1348036360 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.07025
Policy Entropy: 4.34482
Value Function Loss: 0.00253
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.94476
Value Function Update Magnitude: 0.74863
Collected Steps per Second: 12,871.69774
Overall Steps per Second: 7,031.46959
Timestep Collection Time: 3.88651
Timestep Consumption Time: 3.22808
PPO Batch Consumption Time: 0.24055
Total Iteration Time: 7.11459
Cumulative Model Updates: 176,714
Cumulative Timesteps: 1,348,086,386
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73624
Policy Entropy: 4.34788
Value Function Loss: 0.00249
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.93157
Value Function Update Magnitude: 0.69282
Collected Steps per Second: 13,390.73417
Overall Steps per Second: 7,315.07464
Timestep Collection Time: 3.73676
Timestep Consumption Time: 3.10363
PPO Batch Consumption Time: 0.22788
Total Iteration Time: 6.84039
Cumulative Model Updates: 176,723
Cumulative Timesteps: 1,348,136,424
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1348136424...
Checkpoint 1348136424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62531
Policy Entropy: 4.34826
Value Function Loss: 0.00256
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.92993
Value Function Update Magnitude: 0.69732
Collected Steps per Second: 13,082.65926
Overall Steps per Second: 7,219.84278
Timestep Collection Time: 3.82338
Timestep Consumption Time: 3.10475
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.92813
Cumulative Model Updates: 176,732
Cumulative Timesteps: 1,348,186,444
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.23910
Policy Entropy: 4.35015
Value Function Loss: 0.00241
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.93398
Value Function Update Magnitude: 0.72382
Collected Steps per Second: 13,069.87185
Overall Steps per Second: 7,248.63478
Timestep Collection Time: 3.82743
Timestep Consumption Time: 3.07373
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.90116
Cumulative Model Updates: 176,741
Cumulative Timesteps: 1,348,236,468
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1348236468...
Checkpoint 1348236468 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.23718
Policy Entropy: 4.35209
Value Function Loss: 0.00233
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02566
Policy Update Magnitude: 0.92464
Value Function Update Magnitude: 0.71539
Collected Steps per Second: 13,458.90603
Overall Steps per Second: 7,323.12850
Timestep Collection Time: 3.71694
Timestep Consumption Time: 3.11429
PPO Batch Consumption Time: 0.22920
Total Iteration Time: 6.83123
Cumulative Model Updates: 176,750
Cumulative Timesteps: 1,348,286,494
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42195
Policy Entropy: 4.34778
Value Function Loss: 0.00250
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.93858
Value Function Update Magnitude: 0.72220
Collected Steps per Second: 13,314.69376
Overall Steps per Second: 7,304.94441
Timestep Collection Time: 3.75946
Timestep Consumption Time: 3.09289
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.85235
Cumulative Model Updates: 176,759
Cumulative Timesteps: 1,348,336,550
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1348336550...
Checkpoint 1348336550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11775
Policy Entropy: 4.34501
Value Function Loss: 0.00265
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.96469
Value Function Update Magnitude: 0.72008
Collected Steps per Second: 13,116.58942
Overall Steps per Second: 7,343.33134
Timestep Collection Time: 3.81441
Timestep Consumption Time: 2.99885
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.81326
Cumulative Model Updates: 176,768
Cumulative Timesteps: 1,348,386,582
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.94975
Policy Entropy: 4.34078
Value Function Loss: 0.00279
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02812
Policy Update Magnitude: 0.97674
Value Function Update Magnitude: 0.72131
Collected Steps per Second: 13,288.58950
Overall Steps per Second: 7,049.04059
Timestep Collection Time: 3.76338
Timestep Consumption Time: 3.33120
PPO Batch Consumption Time: 0.24533
Total Iteration Time: 7.09458
Cumulative Model Updates: 176,777
Cumulative Timesteps: 1,348,436,592
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1348436592...
Checkpoint 1348436592 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34838
Policy Entropy: 4.34483
Value Function Loss: 0.00259
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02890
Policy Update Magnitude: 0.95944
Value Function Update Magnitude: 0.71135
Collected Steps per Second: 13,145.60405
Overall Steps per Second: 7,269.72464
Timestep Collection Time: 3.80583
Timestep Consumption Time: 3.07613
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.88197
Cumulative Model Updates: 176,786
Cumulative Timesteps: 1,348,486,622
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34306
Policy Entropy: 4.34736
Value Function Loss: 0.00242
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02832
Policy Update Magnitude: 0.92706
Value Function Update Magnitude: 0.70787
Collected Steps per Second: 13,205.67670
Overall Steps per Second: 7,365.52964
Timestep Collection Time: 3.78716
Timestep Consumption Time: 3.00285
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.79001
Cumulative Model Updates: 176,795
Cumulative Timesteps: 1,348,536,634
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1348536634...
Checkpoint 1348536634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70587
Policy Entropy: 4.34726
Value Function Loss: 0.00235
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.92987
Value Function Update Magnitude: 0.73725
Collected Steps per Second: 13,015.95008
Overall Steps per Second: 7,186.65237
Timestep Collection Time: 3.84206
Timestep Consumption Time: 3.11640
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.95846
Cumulative Model Updates: 176,804
Cumulative Timesteps: 1,348,586,642
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73054
Policy Entropy: 4.34609
Value Function Loss: 0.00243
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02413
Policy Update Magnitude: 0.94044
Value Function Update Magnitude: 0.71209
Collected Steps per Second: 13,221.77945
Overall Steps per Second: 7,297.83158
Timestep Collection Time: 3.78270
Timestep Consumption Time: 3.07057
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.85327
Cumulative Model Updates: 176,813
Cumulative Timesteps: 1,348,636,656
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1348636656...
Checkpoint 1348636656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.50433
Policy Entropy: 4.34738
Value Function Loss: 0.00226
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02458
Policy Update Magnitude: 0.89267
Value Function Update Magnitude: 0.68134
Collected Steps per Second: 13,523.24573
Overall Steps per Second: 7,340.47737
Timestep Collection Time: 3.70044
Timestep Consumption Time: 3.11682
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.81727
Cumulative Model Updates: 176,822
Cumulative Timesteps: 1,348,686,698
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.48209
Policy Entropy: 4.35139
Value Function Loss: 0.00221
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.86392
Value Function Update Magnitude: 0.66624
Collected Steps per Second: 13,217.28918
Overall Steps per Second: 7,245.26717
Timestep Collection Time: 3.78413
Timestep Consumption Time: 3.11913
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.90327
Cumulative Model Updates: 176,831
Cumulative Timesteps: 1,348,736,714
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1348736714...
Checkpoint 1348736714 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53280
Policy Entropy: 4.35352
Value Function Loss: 0.00218
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.87682
Value Function Update Magnitude: 0.68529
Collected Steps per Second: 13,147.52569
Overall Steps per Second: 7,134.15606
Timestep Collection Time: 3.80497
Timestep Consumption Time: 3.20721
PPO Batch Consumption Time: 0.24535
Total Iteration Time: 7.01218
Cumulative Model Updates: 176,840
Cumulative Timesteps: 1,348,786,740
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33109
Policy Entropy: 4.35338
Value Function Loss: 0.00241
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.89384
Value Function Update Magnitude: 0.66861
Collected Steps per Second: 13,202.35579
Overall Steps per Second: 7,272.16754
Timestep Collection Time: 3.78963
Timestep Consumption Time: 3.09030
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.87993
Cumulative Model Updates: 176,849
Cumulative Timesteps: 1,348,836,772
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1348836772...
Checkpoint 1348836772 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99837
Policy Entropy: 4.35003
Value Function Loss: 0.00252
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02440
Policy Update Magnitude: 0.90943
Value Function Update Magnitude: 0.68457
Collected Steps per Second: 13,166.24283
Overall Steps per Second: 7,296.94070
Timestep Collection Time: 3.79759
Timestep Consumption Time: 3.05460
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.85219
Cumulative Model Updates: 176,858
Cumulative Timesteps: 1,348,886,772
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.93081
Policy Entropy: 4.34621
Value Function Loss: 0.00271
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.92620
Value Function Update Magnitude: 0.74685
Collected Steps per Second: 13,072.09600
Overall Steps per Second: 7,339.70441
Timestep Collection Time: 3.82555
Timestep Consumption Time: 2.98780
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.81335
Cumulative Model Updates: 176,867
Cumulative Timesteps: 1,348,936,780
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1348936780...
Checkpoint 1348936780 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98093
Policy Entropy: 4.34474
Value Function Loss: 0.00248
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.92897
Value Function Update Magnitude: 0.75662
Collected Steps per Second: 13,165.58537
Overall Steps per Second: 7,212.61899
Timestep Collection Time: 3.79854
Timestep Consumption Time: 3.13514
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.93368
Cumulative Model Updates: 176,876
Cumulative Timesteps: 1,348,986,790
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51546
Policy Entropy: 4.34662
Value Function Loss: 0.00257
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.91774
Value Function Update Magnitude: 0.71508
Collected Steps per Second: 13,326.70851
Overall Steps per Second: 7,301.82430
Timestep Collection Time: 3.75457
Timestep Consumption Time: 3.09797
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.85253
Cumulative Model Updates: 176,885
Cumulative Timesteps: 1,349,036,826
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1349036826...
Checkpoint 1349036826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02268
Policy Entropy: 4.34365
Value Function Loss: 0.00247
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.91039
Value Function Update Magnitude: 0.66702
Collected Steps per Second: 13,375.96027
Overall Steps per Second: 7,314.64325
Timestep Collection Time: 3.73954
Timestep Consumption Time: 3.09879
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.83834
Cumulative Model Updates: 176,894
Cumulative Timesteps: 1,349,086,846
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.79608
Policy Entropy: 4.34116
Value Function Loss: 0.00273
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02426
Policy Update Magnitude: 0.91136
Value Function Update Magnitude: 0.69434
Collected Steps per Second: 13,222.40942
Overall Steps per Second: 7,112.99294
Timestep Collection Time: 3.78206
Timestep Consumption Time: 3.24845
PPO Batch Consumption Time: 0.23786
Total Iteration Time: 7.03051
Cumulative Model Updates: 176,903
Cumulative Timesteps: 1,349,136,854
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1349136854...
Checkpoint 1349136854 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13623
Policy Entropy: 4.34250
Value Function Loss: 0.00260
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02613
Policy Update Magnitude: 0.92313
Value Function Update Magnitude: 0.70743
Collected Steps per Second: 13,158.97931
Overall Steps per Second: 7,266.50788
Timestep Collection Time: 3.79969
Timestep Consumption Time: 3.08120
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.88088
Cumulative Model Updates: 176,912
Cumulative Timesteps: 1,349,186,854
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18382
Policy Entropy: 4.34701
Value Function Loss: 0.00251
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.90288
Value Function Update Magnitude: 0.69907
Collected Steps per Second: 13,504.84860
Overall Steps per Second: 7,350.04527
Timestep Collection Time: 3.70460
Timestep Consumption Time: 3.10217
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.80676
Cumulative Model Updates: 176,921
Cumulative Timesteps: 1,349,236,884
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1349236884...
Checkpoint 1349236884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30822
Policy Entropy: 4.35243
Value Function Loss: 0.00227
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02367
Policy Update Magnitude: 0.86420
Value Function Update Magnitude: 0.70825
Collected Steps per Second: 13,230.77984
Overall Steps per Second: 7,249.09406
Timestep Collection Time: 3.77922
Timestep Consumption Time: 3.11847
PPO Batch Consumption Time: 0.22923
Total Iteration Time: 6.89769
Cumulative Model Updates: 176,930
Cumulative Timesteps: 1,349,286,886
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65171
Policy Entropy: 4.35072
Value Function Loss: 0.00234
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.87871
Value Function Update Magnitude: 0.71569
Collected Steps per Second: 13,220.36507
Overall Steps per Second: 7,360.98717
Timestep Collection Time: 3.78220
Timestep Consumption Time: 3.01064
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.79284
Cumulative Model Updates: 176,939
Cumulative Timesteps: 1,349,336,888
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1349336888...
Checkpoint 1349336888 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53147
Policy Entropy: 4.34853
Value Function Loss: 0.00242
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.90078
Value Function Update Magnitude: 0.70555
Collected Steps per Second: 13,201.59049
Overall Steps per Second: 7,230.14630
Timestep Collection Time: 3.78909
Timestep Consumption Time: 3.12944
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.91853
Cumulative Model Updates: 176,948
Cumulative Timesteps: 1,349,386,910
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.86312
Policy Entropy: 4.35020
Value Function Loss: 0.00238
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.91960
Value Function Update Magnitude: 0.71388
Collected Steps per Second: 13,239.74599
Overall Steps per Second: 7,305.68350
Timestep Collection Time: 3.77802
Timestep Consumption Time: 3.06871
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.84672
Cumulative Model Updates: 176,957
Cumulative Timesteps: 1,349,436,930
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1349436930...
Checkpoint 1349436930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19593
Policy Entropy: 4.35296
Value Function Loss: 0.00219
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.88056
Value Function Update Magnitude: 0.68594
Collected Steps per Second: 13,060.65848
Overall Steps per Second: 7,199.61102
Timestep Collection Time: 3.83120
Timestep Consumption Time: 3.11890
PPO Batch Consumption Time: 0.23973
Total Iteration Time: 6.95010
Cumulative Model Updates: 176,966
Cumulative Timesteps: 1,349,486,968
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45067
Policy Entropy: 4.35371
Value Function Loss: 0.00217
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02282
Policy Update Magnitude: 0.87150
Value Function Update Magnitude: 0.67999
Collected Steps per Second: 13,196.52371
Overall Steps per Second: 7,264.20191
Timestep Collection Time: 3.79160
Timestep Consumption Time: 3.09642
PPO Batch Consumption Time: 0.22773
Total Iteration Time: 6.88802
Cumulative Model Updates: 176,975
Cumulative Timesteps: 1,349,537,004
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1349537004...
Checkpoint 1349537004 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63784
Policy Entropy: 4.35282
Value Function Loss: 0.00228
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.87887
Value Function Update Magnitude: 0.72607
Collected Steps per Second: 13,207.48934
Overall Steps per Second: 7,284.70419
Timestep Collection Time: 3.78800
Timestep Consumption Time: 3.07981
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.86781
Cumulative Model Updates: 176,984
Cumulative Timesteps: 1,349,587,034
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.97195
Policy Entropy: 4.35114
Value Function Loss: 0.00232
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02316
Policy Update Magnitude: 0.89795
Value Function Update Magnitude: 0.73723
Collected Steps per Second: 13,538.36999
Overall Steps per Second: 7,348.26089
Timestep Collection Time: 3.69587
Timestep Consumption Time: 3.11336
PPO Batch Consumption Time: 0.22789
Total Iteration Time: 6.80923
Cumulative Model Updates: 176,993
Cumulative Timesteps: 1,349,637,070
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1349637070...
Checkpoint 1349637070 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08332
Policy Entropy: 4.34765
Value Function Loss: 0.00236
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.90994
Value Function Update Magnitude: 0.68972
Collected Steps per Second: 13,117.79673
Overall Steps per Second: 7,218.81081
Timestep Collection Time: 3.81421
Timestep Consumption Time: 3.11685
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.93106
Cumulative Model Updates: 177,002
Cumulative Timesteps: 1,349,687,104
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72463
Policy Entropy: 4.34866
Value Function Loss: 0.00225
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.89421
Value Function Update Magnitude: 0.69814
Collected Steps per Second: 13,244.31812
Overall Steps per Second: 7,362.60475
Timestep Collection Time: 3.77535
Timestep Consumption Time: 3.01599
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.79135
Cumulative Model Updates: 177,011
Cumulative Timesteps: 1,349,737,106
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1349737106...
Checkpoint 1349737106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32663
Policy Entropy: 4.34906
Value Function Loss: 0.00227
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.89112
Value Function Update Magnitude: 0.67663
Collected Steps per Second: 13,296.92134
Overall Steps per Second: 7,250.51068
Timestep Collection Time: 3.76283
Timestep Consumption Time: 3.13793
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.90076
Cumulative Model Updates: 177,020
Cumulative Timesteps: 1,349,787,140
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.84863
Policy Entropy: 4.35069
Value Function Loss: 0.00233
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.91042
Value Function Update Magnitude: 0.67955
Collected Steps per Second: 13,210.46970
Overall Steps per Second: 7,107.56559
Timestep Collection Time: 3.78730
Timestep Consumption Time: 3.25196
PPO Batch Consumption Time: 0.24068
Total Iteration Time: 7.03926
Cumulative Model Updates: 177,029
Cumulative Timesteps: 1,349,837,172
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1349837172...
Checkpoint 1349837172 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.95597
Policy Entropy: 4.35229
Value Function Loss: 0.00236
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.91265
Value Function Update Magnitude: 0.68194
Collected Steps per Second: 13,499.22534
Overall Steps per Second: 7,342.96044
Timestep Collection Time: 3.70406
Timestep Consumption Time: 3.10545
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.80952
Cumulative Model Updates: 177,038
Cumulative Timesteps: 1,349,887,174
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77044
Policy Entropy: 4.35276
Value Function Loss: 0.00249
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.92434
Value Function Update Magnitude: 0.71165
Collected Steps per Second: 13,331.42496
Overall Steps per Second: 7,265.99668
Timestep Collection Time: 3.75189
Timestep Consumption Time: 3.13196
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.88385
Cumulative Model Updates: 177,047
Cumulative Timesteps: 1,349,937,192
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1349937192...
Checkpoint 1349937192 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.78668
Policy Entropy: 4.35470
Value Function Loss: 0.00245
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02771
Policy Update Magnitude: 0.94995
Value Function Update Magnitude: 0.72898
Collected Steps per Second: 13,018.37699
Overall Steps per Second: 7,232.05231
Timestep Collection Time: 3.84103
Timestep Consumption Time: 3.07319
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.91422
Cumulative Model Updates: 177,056
Cumulative Timesteps: 1,349,987,196
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75067
Policy Entropy: 4.35070
Value Function Loss: 0.00250
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.94140
Value Function Update Magnitude: 0.70444
Collected Steps per Second: 13,534.51218
Overall Steps per Second: 7,336.01554
Timestep Collection Time: 3.69618
Timestep Consumption Time: 3.12305
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.81923
Cumulative Model Updates: 177,065
Cumulative Timesteps: 1,350,037,222
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1350037222...
Checkpoint 1350037222 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87622
Policy Entropy: 4.34928
Value Function Loss: 0.00248
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.95853
Value Function Update Magnitude: 0.77605
Collected Steps per Second: 13,089.86988
Overall Steps per Second: 7,223.46485
Timestep Collection Time: 3.82082
Timestep Consumption Time: 3.10301
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.92382
Cumulative Model Updates: 177,074
Cumulative Timesteps: 1,350,087,236
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.91037
Policy Entropy: 4.34699
Value Function Loss: 0.00247
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.95980
Value Function Update Magnitude: 0.79978
Collected Steps per Second: 13,172.27299
Overall Steps per Second: 7,313.33394
Timestep Collection Time: 3.79722
Timestep Consumption Time: 3.04207
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.83929
Cumulative Model Updates: 177,083
Cumulative Timesteps: 1,350,137,254
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1350137254...
Checkpoint 1350137254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71733
Policy Entropy: 4.35000
Value Function Loss: 0.00232
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.94643
Value Function Update Magnitude: 0.77835
Collected Steps per Second: 13,077.01301
Overall Steps per Second: 7,119.35667
Timestep Collection Time: 3.82610
Timestep Consumption Time: 3.20178
PPO Batch Consumption Time: 0.23507
Total Iteration Time: 7.02788
Cumulative Model Updates: 177,092
Cumulative Timesteps: 1,350,187,288
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.47906
Policy Entropy: 4.35395
Value Function Loss: 0.00227
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.92093
Value Function Update Magnitude: 0.75715
Collected Steps per Second: 13,250.97477
Overall Steps per Second: 7,296.70915
Timestep Collection Time: 3.77512
Timestep Consumption Time: 3.08057
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.85569
Cumulative Model Updates: 177,101
Cumulative Timesteps: 1,350,237,312
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1350237312...
Checkpoint 1350237312 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92571
Policy Entropy: 4.35342
Value Function Loss: 0.00234
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.92099
Value Function Update Magnitude: 0.74471
Collected Steps per Second: 13,542.81034
Overall Steps per Second: 7,344.23697
Timestep Collection Time: 3.69406
Timestep Consumption Time: 3.11781
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.81187
Cumulative Model Updates: 177,110
Cumulative Timesteps: 1,350,287,340
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91232
Policy Entropy: 4.35341
Value Function Loss: 0.00246
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.93670
Value Function Update Magnitude: 0.68318
Collected Steps per Second: 13,235.24319
Overall Steps per Second: 7,267.61351
Timestep Collection Time: 3.78021
Timestep Consumption Time: 3.10403
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.88424
Cumulative Model Updates: 177,119
Cumulative Timesteps: 1,350,337,372
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1350337372...
Checkpoint 1350337372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.55462
Policy Entropy: 4.35151
Value Function Loss: 0.00248
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.93546
Value Function Update Magnitude: 0.67389
Collected Steps per Second: 13,132.61129
Overall Steps per Second: 7,234.66279
Timestep Collection Time: 3.80975
Timestep Consumption Time: 3.10584
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.91560
Cumulative Model Updates: 177,128
Cumulative Timesteps: 1,350,387,404
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.18811
Policy Entropy: 4.35125
Value Function Loss: 0.00255
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.94357
Value Function Update Magnitude: 0.66917
Collected Steps per Second: 13,519.17203
Overall Steps per Second: 7,341.64603
Timestep Collection Time: 3.69904
Timestep Consumption Time: 3.11251
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.81155
Cumulative Model Updates: 177,137
Cumulative Timesteps: 1,350,437,412
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1350437412...
Checkpoint 1350437412 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.83322
Policy Entropy: 4.34791
Value Function Loss: 0.00261
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.97863
Value Function Update Magnitude: 0.74548
Collected Steps per Second: 13,144.49094
Overall Steps per Second: 7,225.03141
Timestep Collection Time: 3.80646
Timestep Consumption Time: 3.11863
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.92509
Cumulative Model Updates: 177,146
Cumulative Timesteps: 1,350,487,446
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83016
Policy Entropy: 4.34463
Value Function Loss: 0.00248
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02909
Policy Update Magnitude: 0.95860
Value Function Update Magnitude: 0.74640
Collected Steps per Second: 13,223.42698
Overall Steps per Second: 7,272.87955
Timestep Collection Time: 3.78253
Timestep Consumption Time: 3.09480
PPO Batch Consumption Time: 0.23589
Total Iteration Time: 6.87733
Cumulative Model Updates: 177,155
Cumulative Timesteps: 1,350,537,464
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1350537464...
Checkpoint 1350537464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.67617
Policy Entropy: 4.34494
Value Function Loss: 0.00242
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.92671
Value Function Update Magnitude: 0.72887
Collected Steps per Second: 13,059.53965
Overall Steps per Second: 7,200.02511
Timestep Collection Time: 3.83076
Timestep Consumption Time: 3.11755
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.94831
Cumulative Model Updates: 177,164
Cumulative Timesteps: 1,350,587,492
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.80674
Policy Entropy: 4.34197
Value Function Loss: 0.00251
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.92883
Value Function Update Magnitude: 0.70719
Collected Steps per Second: 13,069.45101
Overall Steps per Second: 7,259.41931
Timestep Collection Time: 3.82786
Timestep Consumption Time: 3.06360
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.89146
Cumulative Model Updates: 177,173
Cumulative Timesteps: 1,350,637,520
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1350637520...
Checkpoint 1350637520 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.56264
Policy Entropy: 4.33636
Value Function Loss: 0.00262
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.93358
Value Function Update Magnitude: 0.69071
Collected Steps per Second: 13,238.66452
Overall Steps per Second: 7,375.93813
Timestep Collection Time: 3.77848
Timestep Consumption Time: 3.00330
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.78178
Cumulative Model Updates: 177,182
Cumulative Timesteps: 1,350,687,542
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85872
Policy Entropy: 4.33828
Value Function Loss: 0.00277
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 0.95026
Value Function Update Magnitude: 0.70113
Collected Steps per Second: 13,306.42007
Overall Steps per Second: 7,282.93943
Timestep Collection Time: 3.75909
Timestep Consumption Time: 3.10902
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.86811
Cumulative Model Updates: 177,191
Cumulative Timesteps: 1,350,737,562
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1350737562...
Checkpoint 1350737562 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02600
Policy Entropy: 4.34113
Value Function Loss: 0.00258
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.93693
Value Function Update Magnitude: 0.71167
Collected Steps per Second: 13,140.69978
Overall Steps per Second: 7,353.72259
Timestep Collection Time: 3.80512
Timestep Consumption Time: 2.99442
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.79955
Cumulative Model Updates: 177,200
Cumulative Timesteps: 1,350,787,564
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93814
Policy Entropy: 4.34586
Value Function Loss: 0.00258
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02649
Policy Update Magnitude: 0.92370
Value Function Update Magnitude: 0.71278
Collected Steps per Second: 13,313.85169
Overall Steps per Second: 7,299.44587
Timestep Collection Time: 3.75834
Timestep Consumption Time: 3.09670
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.85504
Cumulative Model Updates: 177,209
Cumulative Timesteps: 1,350,837,602
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1350837602...
Checkpoint 1350837602 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04706
Policy Entropy: 4.34568
Value Function Loss: 0.00254
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.91787
Value Function Update Magnitude: 0.68899
Collected Steps per Second: 13,151.02021
Overall Steps per Second: 7,074.84684
Timestep Collection Time: 3.80199
Timestep Consumption Time: 3.26530
PPO Batch Consumption Time: 0.24570
Total Iteration Time: 7.06729
Cumulative Model Updates: 177,218
Cumulative Timesteps: 1,350,887,602
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82104
Policy Entropy: 4.34978
Value Function Loss: 0.00245
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.90037
Value Function Update Magnitude: 0.78496
Collected Steps per Second: 13,260.73082
Overall Steps per Second: 7,412.38106
Timestep Collection Time: 3.77370
Timestep Consumption Time: 2.97744
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.75114
Cumulative Model Updates: 177,227
Cumulative Timesteps: 1,350,937,644
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1350937644...
Checkpoint 1350937644 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05387
Policy Entropy: 4.34932
Value Function Loss: 0.00239
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.88028
Value Function Update Magnitude: 0.75015
Collected Steps per Second: 13,297.96881
Overall Steps per Second: 7,256.43376
Timestep Collection Time: 3.76298
Timestep Consumption Time: 3.13297
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.89595
Cumulative Model Updates: 177,236
Cumulative Timesteps: 1,350,987,684
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.84495
Policy Entropy: 4.34959
Value Function Loss: 0.00245
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.89631
Value Function Update Magnitude: 0.73360
Collected Steps per Second: 13,183.23444
Overall Steps per Second: 7,288.00359
Timestep Collection Time: 3.79543
Timestep Consumption Time: 3.07010
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.86553
Cumulative Model Updates: 177,245
Cumulative Timesteps: 1,351,037,720
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1351037720...
Checkpoint 1351037720 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.12755
Policy Entropy: 4.34976
Value Function Loss: 0.00243
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02506
Policy Update Magnitude: 0.90571
Value Function Update Magnitude: 0.75858
Collected Steps per Second: 13,565.17814
Overall Steps per Second: 7,359.53101
Timestep Collection Time: 3.68753
Timestep Consumption Time: 3.10937
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.79690
Cumulative Model Updates: 177,254
Cumulative Timesteps: 1,351,087,742
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09059
Policy Entropy: 4.35042
Value Function Loss: 0.00244
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.89497
Value Function Update Magnitude: 0.74087
Collected Steps per Second: 13,319.08783
Overall Steps per Second: 7,271.07085
Timestep Collection Time: 3.75641
Timestep Consumption Time: 3.12455
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.88097
Cumulative Model Updates: 177,263
Cumulative Timesteps: 1,351,137,774
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1351137774...
Checkpoint 1351137774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99266
Policy Entropy: 4.34751
Value Function Loss: 0.00246
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02311
Policy Update Magnitude: 0.89933
Value Function Update Magnitude: 0.73094
Collected Steps per Second: 13,332.55705
Overall Steps per Second: 7,328.82515
Timestep Collection Time: 3.75292
Timestep Consumption Time: 3.07437
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.82729
Cumulative Model Updates: 177,272
Cumulative Timesteps: 1,351,187,810
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03733
Policy Entropy: 4.34559
Value Function Loss: 0.00254
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.90344
Value Function Update Magnitude: 0.74289
Collected Steps per Second: 13,496.21770
Overall Steps per Second: 7,179.32274
Timestep Collection Time: 3.70563
Timestep Consumption Time: 3.26049
PPO Batch Consumption Time: 0.24148
Total Iteration Time: 6.96612
Cumulative Model Updates: 177,281
Cumulative Timesteps: 1,351,237,822
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1351237822...
Checkpoint 1351237822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90863
Policy Entropy: 4.34756
Value Function Loss: 0.00269
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.91924
Value Function Update Magnitude: 0.74960
Collected Steps per Second: 13,117.55184
Overall Steps per Second: 7,215.30729
Timestep Collection Time: 3.81291
Timestep Consumption Time: 3.11902
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.93193
Cumulative Model Updates: 177,290
Cumulative Timesteps: 1,351,287,838
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90654
Policy Entropy: 4.35025
Value Function Loss: 0.00273
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.93752
Value Function Update Magnitude: 0.81466
Collected Steps per Second: 13,103.00483
Overall Steps per Second: 7,328.46801
Timestep Collection Time: 3.81836
Timestep Consumption Time: 3.00871
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.82707
Cumulative Model Updates: 177,299
Cumulative Timesteps: 1,351,337,870
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1351337870...
Checkpoint 1351337870 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.27734
Policy Entropy: 4.35080
Value Function Loss: 0.00270
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.92371
Value Function Update Magnitude: 0.84126
Collected Steps per Second: 13,148.60920
Overall Steps per Second: 7,252.48520
Timestep Collection Time: 3.80360
Timestep Consumption Time: 3.09225
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.89584
Cumulative Model Updates: 177,308
Cumulative Timesteps: 1,351,387,882
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.21987
Policy Entropy: 4.34561
Value Function Loss: 0.00269
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 0.92724
Value Function Update Magnitude: 0.84514
Collected Steps per Second: 13,298.68283
Overall Steps per Second: 7,322.53475
Timestep Collection Time: 3.76218
Timestep Consumption Time: 3.07043
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.83261
Cumulative Model Updates: 177,317
Cumulative Timesteps: 1,351,437,914
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1351437914...
Checkpoint 1351437914 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.24462
Policy Entropy: 4.34732
Value Function Loss: 0.00259
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.92706
Value Function Update Magnitude: 0.83542
Collected Steps per Second: 13,113.34198
Overall Steps per Second: 7,347.31117
Timestep Collection Time: 3.81428
Timestep Consumption Time: 2.99338
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.80766
Cumulative Model Updates: 177,326
Cumulative Timesteps: 1,351,487,932
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.56413
Policy Entropy: 4.34842
Value Function Loss: 0.00257
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02617
Policy Update Magnitude: 0.93297
Value Function Update Magnitude: 0.82339
Collected Steps per Second: 13,129.14843
Overall Steps per Second: 7,236.29280
Timestep Collection Time: 3.81106
Timestep Consumption Time: 3.10353
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.91459
Cumulative Model Updates: 177,335
Cumulative Timesteps: 1,351,537,968
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1351537968...
Checkpoint 1351537968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.47854
Policy Entropy: 4.34820
Value Function Loss: 0.00245
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.93643
Value Function Update Magnitude: 0.75957
Collected Steps per Second: 13,057.42772
Overall Steps per Second: 7,161.78855
Timestep Collection Time: 3.82985
Timestep Consumption Time: 3.15276
PPO Batch Consumption Time: 0.23626
Total Iteration Time: 6.98261
Cumulative Model Updates: 177,344
Cumulative Timesteps: 1,351,587,976
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54280
Policy Entropy: 4.34547
Value Function Loss: 0.00257
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.92617
Value Function Update Magnitude: 0.74759
Collected Steps per Second: 13,387.01592
Overall Steps per Second: 7,319.50301
Timestep Collection Time: 3.73676
Timestep Consumption Time: 3.09759
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.83434
Cumulative Model Updates: 177,353
Cumulative Timesteps: 1,351,638,000
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1351638000...
Checkpoint 1351638000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.70614
Policy Entropy: 4.34105
Value Function Loss: 0.00276
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.94166
Value Function Update Magnitude: 0.80884
Collected Steps per Second: 13,149.24530
Overall Steps per Second: 7,241.53056
Timestep Collection Time: 3.80341
Timestep Consumption Time: 3.10286
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.90627
Cumulative Model Updates: 177,362
Cumulative Timesteps: 1,351,688,012
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18836
Policy Entropy: 4.34179
Value Function Loss: 0.00269
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.93806
Value Function Update Magnitude: 0.80494
Collected Steps per Second: 13,236.63416
Overall Steps per Second: 7,374.18120
Timestep Collection Time: 3.77830
Timestep Consumption Time: 3.00374
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.78204
Cumulative Model Updates: 177,371
Cumulative Timesteps: 1,351,738,024
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1351738024...
Checkpoint 1351738024 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16959
Policy Entropy: 4.34489
Value Function Loss: 0.00275
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02770
Policy Update Magnitude: 0.94769
Value Function Update Magnitude: 0.75384
Collected Steps per Second: 13,075.50653
Overall Steps per Second: 7,221.74358
Timestep Collection Time: 3.82517
Timestep Consumption Time: 3.10058
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.92575
Cumulative Model Updates: 177,380
Cumulative Timesteps: 1,351,788,040
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80038
Policy Entropy: 4.35240
Value Function Loss: 0.00236
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02491
Policy Update Magnitude: 0.91120
Value Function Update Magnitude: 0.74019
Collected Steps per Second: 13,243.38966
Overall Steps per Second: 7,284.26911
Timestep Collection Time: 3.77819
Timestep Consumption Time: 3.09086
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.86905
Cumulative Model Updates: 177,389
Cumulative Timesteps: 1,351,838,076
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1351838076...
Checkpoint 1351838076 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.15890
Policy Entropy: 4.35541
Value Function Loss: 0.00233
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02347
Policy Update Magnitude: 0.87836
Value Function Update Magnitude: 0.72996
Collected Steps per Second: 13,545.68172
Overall Steps per Second: 7,360.38488
Timestep Collection Time: 3.69225
Timestep Consumption Time: 3.10278
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.79503
Cumulative Model Updates: 177,398
Cumulative Timesteps: 1,351,888,090
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96355
Policy Entropy: 4.35415
Value Function Loss: 0.00220
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02367
Policy Update Magnitude: 0.88655
Value Function Update Magnitude: 0.70423
Collected Steps per Second: 13,175.42420
Overall Steps per Second: 7,079.69862
Timestep Collection Time: 3.79677
Timestep Consumption Time: 3.26907
PPO Batch Consumption Time: 0.24049
Total Iteration Time: 7.06584
Cumulative Model Updates: 177,407
Cumulative Timesteps: 1,351,938,114
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1351938114...
Checkpoint 1351938114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91533
Policy Entropy: 4.35050
Value Function Loss: 0.00241
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.90000
Value Function Update Magnitude: 0.70165
Collected Steps per Second: 13,123.51379
Overall Steps per Second: 7,257.40585
Timestep Collection Time: 3.81239
Timestep Consumption Time: 3.08153
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.89392
Cumulative Model Updates: 177,416
Cumulative Timesteps: 1,351,988,146
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51644
Policy Entropy: 4.34912
Value Function Loss: 0.00245
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.91713
Value Function Update Magnitude: 0.77900
Collected Steps per Second: 13,497.98077
Overall Steps per Second: 7,355.95406
Timestep Collection Time: 3.70455
Timestep Consumption Time: 3.09320
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.79776
Cumulative Model Updates: 177,425
Cumulative Timesteps: 1,352,038,150
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1352038150...
Checkpoint 1352038150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75574
Policy Entropy: 4.34545
Value Function Loss: 0.00253
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.92640
Value Function Update Magnitude: 0.77390
Collected Steps per Second: 13,210.32260
Overall Steps per Second: 7,256.00115
Timestep Collection Time: 3.78598
Timestep Consumption Time: 3.10680
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.89278
Cumulative Model Updates: 177,434
Cumulative Timesteps: 1,352,088,164
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54298
Policy Entropy: 4.34656
Value Function Loss: 0.00245
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.92801
Value Function Update Magnitude: 0.70756
Collected Steps per Second: 13,054.05361
Overall Steps per Second: 7,313.23266
Timestep Collection Time: 3.83237
Timestep Consumption Time: 3.00838
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.84075
Cumulative Model Updates: 177,443
Cumulative Timesteps: 1,352,138,192
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1352138192...
Checkpoint 1352138192 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76240
Policy Entropy: 4.34769
Value Function Loss: 0.00235
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.90589
Value Function Update Magnitude: 0.69129
Collected Steps per Second: 13,120.98500
Overall Steps per Second: 7,224.19199
Timestep Collection Time: 3.81115
Timestep Consumption Time: 3.11087
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.92202
Cumulative Model Updates: 177,452
Cumulative Timesteps: 1,352,188,198
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43502
Policy Entropy: 4.35106
Value Function Loss: 0.00237
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02332
Policy Update Magnitude: 0.90053
Value Function Update Magnitude: 0.72868
Collected Steps per Second: 13,247.39701
Overall Steps per Second: 7,318.81805
Timestep Collection Time: 3.77478
Timestep Consumption Time: 3.05774
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.83252
Cumulative Model Updates: 177,461
Cumulative Timesteps: 1,352,238,204
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1352238204...
Checkpoint 1352238204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97748
Policy Entropy: 4.35068
Value Function Loss: 0.00230
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02214
Policy Update Magnitude: 0.87863
Value Function Update Magnitude: 0.75108
Collected Steps per Second: 13,155.40615
Overall Steps per Second: 7,308.24914
Timestep Collection Time: 3.80422
Timestep Consumption Time: 3.04366
PPO Batch Consumption Time: 0.23227
Total Iteration Time: 6.84788
Cumulative Model Updates: 177,470
Cumulative Timesteps: 1,352,288,250
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72704
Policy Entropy: 4.35312
Value Function Loss: 0.00231
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.87276
Value Function Update Magnitude: 0.69762
Collected Steps per Second: 13,160.80270
Overall Steps per Second: 7,232.38756
Timestep Collection Time: 3.79946
Timestep Consumption Time: 3.11444
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.91390
Cumulative Model Updates: 177,479
Cumulative Timesteps: 1,352,338,254
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1352338254...
Checkpoint 1352338254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.19900
Policy Entropy: 4.35164
Value Function Loss: 0.00233
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.89465
Value Function Update Magnitude: 0.70202
Collected Steps per Second: 13,145.63174
Overall Steps per Second: 7,271.84601
Timestep Collection Time: 3.80370
Timestep Consumption Time: 3.07241
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.87611
Cumulative Model Updates: 177,488
Cumulative Timesteps: 1,352,388,256
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.37295
Policy Entropy: 4.35258
Value Function Loss: 0.00231
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.90603
Value Function Update Magnitude: 0.71176
Collected Steps per Second: 13,348.15383
Overall Steps per Second: 7,303.50627
Timestep Collection Time: 3.74823
Timestep Consumption Time: 3.10217
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.85041
Cumulative Model Updates: 177,497
Cumulative Timesteps: 1,352,438,288
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1352438288...
Checkpoint 1352438288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53044
Policy Entropy: 4.35232
Value Function Loss: 0.00236
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02470
Policy Update Magnitude: 0.91158
Value Function Update Magnitude: 0.69149
Collected Steps per Second: 12,907.06913
Overall Steps per Second: 7,167.87798
Timestep Collection Time: 3.87400
Timestep Consumption Time: 3.10184
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.97584
Cumulative Model Updates: 177,506
Cumulative Timesteps: 1,352,488,290
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53560
Policy Entropy: 4.35016
Value Function Loss: 0.00254
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.93889
Value Function Update Magnitude: 0.73593
Collected Steps per Second: 13,290.09042
Overall Steps per Second: 7,320.36065
Timestep Collection Time: 3.76401
Timestep Consumption Time: 3.06954
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.83354
Cumulative Model Updates: 177,515
Cumulative Timesteps: 1,352,538,314
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1352538314...
Checkpoint 1352538314 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.04355
Policy Entropy: 4.35195
Value Function Loss: 0.00232
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02548
Policy Update Magnitude: 0.91707
Value Function Update Magnitude: 0.72900
Collected Steps per Second: 13,496.10533
Overall Steps per Second: 7,359.51375
Timestep Collection Time: 3.70655
Timestep Consumption Time: 3.09064
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.79719
Cumulative Model Updates: 177,524
Cumulative Timesteps: 1,352,588,338
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.26990
Policy Entropy: 4.35291
Value Function Loss: 0.00230
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.89208
Value Function Update Magnitude: 0.68530
Collected Steps per Second: 13,173.38054
Overall Steps per Second: 7,094.59133
Timestep Collection Time: 3.79584
Timestep Consumption Time: 3.25235
PPO Batch Consumption Time: 0.24007
Total Iteration Time: 7.04819
Cumulative Model Updates: 177,533
Cumulative Timesteps: 1,352,638,342
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1352638342...
Checkpoint 1352638342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.29158
Policy Entropy: 4.35749
Value Function Loss: 0.00212
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02275
Policy Update Magnitude: 0.88073
Value Function Update Magnitude: 0.67987
Collected Steps per Second: 13,045.11068
Overall Steps per Second: 7,332.44394
Timestep Collection Time: 3.83454
Timestep Consumption Time: 2.98747
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.82201
Cumulative Model Updates: 177,542
Cumulative Timesteps: 1,352,688,364
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39451
Policy Entropy: 4.35620
Value Function Loss: 0.00214
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02192
Policy Update Magnitude: 0.85946
Value Function Update Magnitude: 0.71858
Collected Steps per Second: 13,200.76322
Overall Steps per Second: 7,275.45554
Timestep Collection Time: 3.78796
Timestep Consumption Time: 3.08501
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.87297
Cumulative Model Updates: 177,551
Cumulative Timesteps: 1,352,738,368
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1352738368...
Checkpoint 1352738368 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87905
Policy Entropy: 4.35175
Value Function Loss: 0.00224
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02232
Policy Update Magnitude: 0.87620
Value Function Update Magnitude: 0.73790
Collected Steps per Second: 13,236.80723
Overall Steps per Second: 7,327.73883
Timestep Collection Time: 3.77825
Timestep Consumption Time: 3.04677
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.82502
Cumulative Model Updates: 177,560
Cumulative Timesteps: 1,352,788,380
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.59971
Policy Entropy: 4.34762
Value Function Loss: 0.00239
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.91768
Value Function Update Magnitude: 0.74948
Collected Steps per Second: 13,481.37434
Overall Steps per Second: 7,363.15530
Timestep Collection Time: 3.71223
Timestep Consumption Time: 3.08458
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.79681
Cumulative Model Updates: 177,569
Cumulative Timesteps: 1,352,838,426
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1352838426...
Checkpoint 1352838426 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.22886
Policy Entropy: 4.34888
Value Function Loss: 0.00249
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.92311
Value Function Update Magnitude: 0.74705
Collected Steps per Second: 13,215.37066
Overall Steps per Second: 7,223.33638
Timestep Collection Time: 3.78408
Timestep Consumption Time: 3.13904
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.92312
Cumulative Model Updates: 177,578
Cumulative Timesteps: 1,352,888,434
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.21594
Policy Entropy: 4.34989
Value Function Loss: 0.00241
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.89490
Value Function Update Magnitude: 0.76165
Collected Steps per Second: 12,505.81936
Overall Steps per Second: 6,997.68824
Timestep Collection Time: 3.99894
Timestep Consumption Time: 3.14771
PPO Batch Consumption Time: 0.23032
Total Iteration Time: 7.14665
Cumulative Model Updates: 177,587
Cumulative Timesteps: 1,352,938,444
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1352938444...
Checkpoint 1352938444 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.43759
Policy Entropy: 4.35512
Value Function Loss: 0.00227
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.88390
Value Function Update Magnitude: 0.71593
Collected Steps per Second: 12,672.10302
Overall Steps per Second: 7,000.41440
Timestep Collection Time: 3.94631
Timestep Consumption Time: 3.19727
PPO Batch Consumption Time: 0.23333
Total Iteration Time: 7.14358
Cumulative Model Updates: 177,596
Cumulative Timesteps: 1,352,988,452
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51485
Policy Entropy: 4.35424
Value Function Loss: 0.00236
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02408
Policy Update Magnitude: 0.89295
Value Function Update Magnitude: 0.72089
Collected Steps per Second: 12,704.01858
Overall Steps per Second: 7,036.11114
Timestep Collection Time: 3.93986
Timestep Consumption Time: 3.17373
PPO Batch Consumption Time: 0.23074
Total Iteration Time: 7.11359
Cumulative Model Updates: 177,605
Cumulative Timesteps: 1,353,038,504
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1353038504...
Checkpoint 1353038504 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.91485
Policy Entropy: 4.34957
Value Function Loss: 0.00238
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.90892
Value Function Update Magnitude: 0.76865
Collected Steps per Second: 12,338.97331
Overall Steps per Second: 7,023.93875
Timestep Collection Time: 4.05220
Timestep Consumption Time: 3.06631
PPO Batch Consumption Time: 0.22946
Total Iteration Time: 7.11851
Cumulative Model Updates: 177,614
Cumulative Timesteps: 1,353,088,504
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89905
Policy Entropy: 4.34932
Value Function Loss: 0.00248
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.90947
Value Function Update Magnitude: 0.74726
Collected Steps per Second: 12,385.97526
Overall Steps per Second: 6,963.57387
Timestep Collection Time: 4.03876
Timestep Consumption Time: 3.14491
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 7.18367
Cumulative Model Updates: 177,623
Cumulative Timesteps: 1,353,138,528
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1353138528...
Checkpoint 1353138528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69000
Policy Entropy: 4.34599
Value Function Loss: 0.00251
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.91085
Value Function Update Magnitude: 0.70598
Collected Steps per Second: 13,229.64870
Overall Steps per Second: 7,265.89650
Timestep Collection Time: 3.77969
Timestep Consumption Time: 3.10232
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.88201
Cumulative Model Updates: 177,632
Cumulative Timesteps: 1,353,188,532
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20412
Policy Entropy: 4.34537
Value Function Loss: 0.00266
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.92548
Value Function Update Magnitude: 0.74849
Collected Steps per Second: 13,244.89980
Overall Steps per Second: 7,371.70284
Timestep Collection Time: 3.77549
Timestep Consumption Time: 3.00802
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.78351
Cumulative Model Updates: 177,641
Cumulative Timesteps: 1,353,238,538
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1353238538...
Checkpoint 1353238538 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44096
Policy Entropy: 4.34346
Value Function Loss: 0.00262
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02774
Policy Update Magnitude: 0.95290
Value Function Update Magnitude: 0.77610
Collected Steps per Second: 13,075.74909
Overall Steps per Second: 7,199.85756
Timestep Collection Time: 3.82693
Timestep Consumption Time: 3.12321
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.95014
Cumulative Model Updates: 177,650
Cumulative Timesteps: 1,353,288,578
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69618
Policy Entropy: 4.34623
Value Function Loss: 0.00242
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.93071
Value Function Update Magnitude: 0.74897
Collected Steps per Second: 13,140.90587
Overall Steps per Second: 7,064.37705
Timestep Collection Time: 3.80613
Timestep Consumption Time: 3.27390
PPO Batch Consumption Time: 0.24544
Total Iteration Time: 7.08003
Cumulative Model Updates: 177,659
Cumulative Timesteps: 1,353,338,594
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1353338594...
Checkpoint 1353338594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73941
Policy Entropy: 4.34815
Value Function Loss: 0.00235
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02361
Policy Update Magnitude: 0.89580
Value Function Update Magnitude: 0.71343
Collected Steps per Second: 12,949.62956
Overall Steps per Second: 7,197.46908
Timestep Collection Time: 3.86420
Timestep Consumption Time: 3.08824
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.95244
Cumulative Model Updates: 177,668
Cumulative Timesteps: 1,353,388,634
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.05992
Policy Entropy: 4.35143
Value Function Loss: 0.00228
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02386
Policy Update Magnitude: 0.87486
Value Function Update Magnitude: 0.69382
Collected Steps per Second: 13,186.44752
Overall Steps per Second: 7,241.67661
Timestep Collection Time: 3.79496
Timestep Consumption Time: 3.11532
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.91028
Cumulative Model Updates: 177,677
Cumulative Timesteps: 1,353,438,676
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1353438676...
Checkpoint 1353438676 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.30600
Policy Entropy: 4.35413
Value Function Loss: 0.00229
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.86153
Value Function Update Magnitude: 0.71423
Collected Steps per Second: 13,034.51296
Overall Steps per Second: 7,229.59795
Timestep Collection Time: 3.83935
Timestep Consumption Time: 3.08275
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.92210
Cumulative Model Updates: 177,686
Cumulative Timesteps: 1,353,488,720
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87452
Policy Entropy: 4.35501
Value Function Loss: 0.00242
Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02172
Policy Update Magnitude: 0.87513
Value Function Update Magnitude: 0.71727
Collected Steps per Second: 13,623.26514
Overall Steps per Second: 7,378.83671
Timestep Collection Time: 3.67034
Timestep Consumption Time: 3.10607
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.77641
Cumulative Model Updates: 177,695
Cumulative Timesteps: 1,353,538,722
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1353538722...
Checkpoint 1353538722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.72656
Policy Entropy: 4.34694
Value Function Loss: 0.00254
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.91739
Value Function Update Magnitude: 0.77969
Collected Steps per Second: 13,191.63079
Overall Steps per Second: 7,241.44155
Timestep Collection Time: 3.79104
Timestep Consumption Time: 3.11504
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.90608
Cumulative Model Updates: 177,704
Cumulative Timesteps: 1,353,588,732
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.56631
Policy Entropy: 4.34828
Value Function Loss: 0.00252
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.92100
Value Function Update Magnitude: 0.78697
Collected Steps per Second: 13,275.27079
Overall Steps per Second: 7,373.05640
Timestep Collection Time: 3.76851
Timestep Consumption Time: 3.01674
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.78525
Cumulative Model Updates: 177,713
Cumulative Timesteps: 1,353,638,760
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1353638760...
Checkpoint 1353638760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05661
Policy Entropy: 4.34877
Value Function Loss: 0.00253
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.90839
Value Function Update Magnitude: 0.76133
Collected Steps per Second: 13,315.05655
Overall Steps per Second: 7,187.15555
Timestep Collection Time: 3.75770
Timestep Consumption Time: 3.20388
PPO Batch Consumption Time: 0.23733
Total Iteration Time: 6.96159
Cumulative Model Updates: 177,722
Cumulative Timesteps: 1,353,688,794
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.96800
Policy Entropy: 4.35029
Value Function Loss: 0.00252
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.90584
Value Function Update Magnitude: 0.77933
Collected Steps per Second: 13,133.84870
Overall Steps per Second: 7,270.90372
Timestep Collection Time: 3.80772
Timestep Consumption Time: 3.07038
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.87810
Cumulative Model Updates: 177,731
Cumulative Timesteps: 1,353,738,804
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1353738804...
Checkpoint 1353738804 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.01399
Policy Entropy: 4.34822
Value Function Loss: 0.00257
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.90935
Value Function Update Magnitude: 0.77289
Collected Steps per Second: 13,034.05195
Overall Steps per Second: 7,331.51733
Timestep Collection Time: 3.83810
Timestep Consumption Time: 2.98532
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.82342
Cumulative Model Updates: 177,740
Cumulative Timesteps: 1,353,788,830
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97924
Policy Entropy: 4.35231
Value Function Loss: 0.00249
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.88930
Value Function Update Magnitude: 0.77497
Collected Steps per Second: 13,171.86882
Overall Steps per Second: 7,245.17734
Timestep Collection Time: 3.79688
Timestep Consumption Time: 3.10592
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.90280
Cumulative Model Updates: 177,749
Cumulative Timesteps: 1,353,838,842
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1353838842...
Checkpoint 1353838842 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.31623
Policy Entropy: 4.35470
Value Function Loss: 0.00246
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02489
Policy Update Magnitude: 0.89800
Value Function Update Magnitude: 0.73013
Collected Steps per Second: 13,249.48176
Overall Steps per Second: 7,286.42610
Timestep Collection Time: 3.77524
Timestep Consumption Time: 3.08958
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.86482
Cumulative Model Updates: 177,758
Cumulative Timesteps: 1,353,888,862
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81538
Policy Entropy: 4.35517
Value Function Loss: 0.00250
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.93257
Value Function Update Magnitude: 0.72076
Collected Steps per Second: 13,440.53922
Overall Steps per Second: 7,329.41362
Timestep Collection Time: 3.72247
Timestep Consumption Time: 3.10372
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.82619
Cumulative Model Updates: 177,767
Cumulative Timesteps: 1,353,938,894
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1353938894...
Checkpoint 1353938894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85633
Policy Entropy: 4.35306
Value Function Loss: 0.00256
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.92255
Value Function Update Magnitude: 0.71024
Collected Steps per Second: 13,299.39444
Overall Steps per Second: 7,281.96378
Timestep Collection Time: 3.76107
Timestep Consumption Time: 3.10795
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.86903
Cumulative Model Updates: 177,776
Cumulative Timesteps: 1,353,988,914
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89518
Policy Entropy: 4.35458
Value Function Loss: 0.00267
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.96936
Value Function Update Magnitude: 0.71749
Collected Steps per Second: 13,157.63462
Overall Steps per Second: 7,122.97673
Timestep Collection Time: 3.80403
Timestep Consumption Time: 3.22281
PPO Batch Consumption Time: 0.23975
Total Iteration Time: 7.02684
Cumulative Model Updates: 177,785
Cumulative Timesteps: 1,354,038,966
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1354038966...
Checkpoint 1354038966 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.40250
Policy Entropy: 4.35122
Value Function Loss: 0.00258
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.98444
Value Function Update Magnitude: 0.73017
Collected Steps per Second: 13,326.33673
Overall Steps per Second: 7,294.27773
Timestep Collection Time: 3.75287
Timestep Consumption Time: 3.10346
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.85633
Cumulative Model Updates: 177,794
Cumulative Timesteps: 1,354,088,978
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.20219
Policy Entropy: 4.35059
Value Function Loss: 0.00266
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.98335
Value Function Update Magnitude: 0.76020
Collected Steps per Second: 13,253.09951
Overall Steps per Second: 7,255.73759
Timestep Collection Time: 3.77316
Timestep Consumption Time: 3.11877
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.89193
Cumulative Model Updates: 177,803
Cumulative Timesteps: 1,354,138,984
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1354138984...
Checkpoint 1354138984 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.64449
Policy Entropy: 4.35338
Value Function Loss: 0.00244
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.93394
Value Function Update Magnitude: 0.77028
Collected Steps per Second: 13,142.79348
Overall Steps per Second: 7,342.84685
Timestep Collection Time: 3.80650
Timestep Consumption Time: 3.00666
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.81316
Cumulative Model Updates: 177,812
Cumulative Timesteps: 1,354,189,012
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02267
Policy Entropy: 4.35686
Value Function Loss: 0.00251
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02332
Policy Update Magnitude: 0.91535
Value Function Update Magnitude: 0.72572
Collected Steps per Second: 13,242.14287
Overall Steps per Second: 7,248.63989
Timestep Collection Time: 3.77613
Timestep Consumption Time: 3.12227
PPO Batch Consumption Time: 0.22944
Total Iteration Time: 6.89840
Cumulative Model Updates: 177,821
Cumulative Timesteps: 1,354,239,016
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1354239016...
Checkpoint 1354239016 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99632
Policy Entropy: 4.35927
Value Function Loss: 0.00246
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02321
Policy Update Magnitude: 0.91347
Value Function Update Magnitude: 0.71134
Collected Steps per Second: 13,137.85431
Overall Steps per Second: 7,273.27363
Timestep Collection Time: 3.80625
Timestep Consumption Time: 3.06906
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.87531
Cumulative Model Updates: 177,830
Cumulative Timesteps: 1,354,289,022
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56693
Policy Entropy: 4.35427
Value Function Loss: 0.00244
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.90210
Value Function Update Magnitude: 0.72579
Collected Steps per Second: 13,268.32164
Overall Steps per Second: 7,383.55169
Timestep Collection Time: 3.76868
Timestep Consumption Time: 3.00367
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.77235
Cumulative Model Updates: 177,839
Cumulative Timesteps: 1,354,339,026
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1354339026...
Checkpoint 1354339026 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.67417
Policy Entropy: 4.35098
Value Function Loss: 0.00247
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.91207
Value Function Update Magnitude: 0.74518
Collected Steps per Second: 13,255.60381
Overall Steps per Second: 7,066.48652
Timestep Collection Time: 3.77214
Timestep Consumption Time: 3.30379
PPO Batch Consumption Time: 0.24201
Total Iteration Time: 7.07594
Cumulative Model Updates: 177,848
Cumulative Timesteps: 1,354,389,028
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54307
Policy Entropy: 4.34914
Value Function Loss: 0.00258
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.93228
Value Function Update Magnitude: 0.76724
Collected Steps per Second: 13,318.65972
Overall Steps per Second: 7,323.05632
Timestep Collection Time: 3.75413
Timestep Consumption Time: 3.07362
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.82775
Cumulative Model Updates: 177,857
Cumulative Timesteps: 1,354,439,028
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1354439028...
Checkpoint 1354439028 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.71711
Policy Entropy: 4.35026
Value Function Loss: 0.00254
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02730
Policy Update Magnitude: 0.91889
Value Function Update Magnitude: 0.74725
Collected Steps per Second: 13,529.76459
Overall Steps per Second: 7,372.92114
Timestep Collection Time: 3.69955
Timestep Consumption Time: 3.08935
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.78890
Cumulative Model Updates: 177,866
Cumulative Timesteps: 1,354,489,082
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.98985
Policy Entropy: 4.34792
Value Function Loss: 0.00251
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.92013
Value Function Update Magnitude: 0.81655
Collected Steps per Second: 13,225.05073
Overall Steps per Second: 7,265.52826
Timestep Collection Time: 3.78267
Timestep Consumption Time: 3.10272
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.88539
Cumulative Model Updates: 177,875
Cumulative Timesteps: 1,354,539,108
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1354539108...
Checkpoint 1354539108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91689
Policy Entropy: 4.34912
Value Function Loss: 0.00247
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.93467
Value Function Update Magnitude: 0.75763
Collected Steps per Second: 13,157.77187
Overall Steps per Second: 7,278.00248
Timestep Collection Time: 3.80171
Timestep Consumption Time: 3.07133
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.87304
Cumulative Model Updates: 177,884
Cumulative Timesteps: 1,354,589,130
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69412
Policy Entropy: 4.35109
Value Function Loss: 0.00234
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.91971
Value Function Update Magnitude: 0.70924
Collected Steps per Second: 13,504.25438
Overall Steps per Second: 7,347.34062
Timestep Collection Time: 3.70372
Timestep Consumption Time: 3.10364
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.80736
Cumulative Model Updates: 177,893
Cumulative Timesteps: 1,354,639,146
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1354639146...
Checkpoint 1354639146 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54454
Policy Entropy: 4.35343
Value Function Loss: 0.00238
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.90693
Value Function Update Magnitude: 0.66030
Collected Steps per Second: 13,202.10473
Overall Steps per Second: 7,224.45607
Timestep Collection Time: 3.78743
Timestep Consumption Time: 3.13379
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.92121
Cumulative Model Updates: 177,902
Cumulative Timesteps: 1,354,689,148
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88065
Policy Entropy: 4.35712
Value Function Loss: 0.00225
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.88392
Value Function Update Magnitude: 0.63553
Collected Steps per Second: 13,127.12682
Overall Steps per Second: 7,140.56859
Timestep Collection Time: 3.80891
Timestep Consumption Time: 3.19334
PPO Batch Consumption Time: 0.24430
Total Iteration Time: 7.00224
Cumulative Model Updates: 177,911
Cumulative Timesteps: 1,354,739,148
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1354739148...
Checkpoint 1354739148 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24833
Policy Entropy: 4.35396
Value Function Loss: 0.00230
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.87378
Value Function Update Magnitude: 0.66073
Collected Steps per Second: 13,187.77678
Overall Steps per Second: 7,234.99405
Timestep Collection Time: 3.79351
Timestep Consumption Time: 3.12121
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.91473
Cumulative Model Updates: 177,920
Cumulative Timesteps: 1,354,789,176
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.13477
Policy Entropy: 4.35400
Value Function Loss: 0.00226
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02387
Policy Update Magnitude: 0.90517
Value Function Update Magnitude: 0.70334
Collected Steps per Second: 13,297.40127
Overall Steps per Second: 7,299.53925
Timestep Collection Time: 3.76013
Timestep Consumption Time: 3.08961
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.84975
Cumulative Model Updates: 177,929
Cumulative Timesteps: 1,354,839,176
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1354839176...
Checkpoint 1354839176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.55783
Policy Entropy: 4.35302
Value Function Loss: 0.00228
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.92194
Value Function Update Magnitude: 0.71981
Collected Steps per Second: 13,100.25292
Overall Steps per Second: 7,334.60503
Timestep Collection Time: 3.81870
Timestep Consumption Time: 3.00184
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.82054
Cumulative Model Updates: 177,938
Cumulative Timesteps: 1,354,889,202
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.95256
Policy Entropy: 4.35251
Value Function Loss: 0.00246
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.92906
Value Function Update Magnitude: 0.71615
Collected Steps per Second: 13,251.51232
Overall Steps per Second: 7,271.88697
Timestep Collection Time: 3.77346
Timestep Consumption Time: 3.10289
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.87634
Cumulative Model Updates: 177,947
Cumulative Timesteps: 1,354,939,206
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1354939206...
Checkpoint 1354939206 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.08781
Policy Entropy: 4.35313
Value Function Loss: 0.00232
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.90853
Value Function Update Magnitude: 0.69223
Collected Steps per Second: 13,218.37567
Overall Steps per Second: 7,281.69957
Timestep Collection Time: 3.78503
Timestep Consumption Time: 3.08589
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.87092
Cumulative Model Updates: 177,956
Cumulative Timesteps: 1,354,989,238
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99912
Policy Entropy: 4.35448
Value Function Loss: 0.00231
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.89153
Value Function Update Magnitude: 0.70351
Collected Steps per Second: 13,454.73443
Overall Steps per Second: 7,317.84268
Timestep Collection Time: 3.71706
Timestep Consumption Time: 3.11720
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.83425
Cumulative Model Updates: 177,965
Cumulative Timesteps: 1,355,039,250
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1355039250...
Checkpoint 1355039250 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46930
Policy Entropy: 4.35246
Value Function Loss: 0.00231
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.91133
Value Function Update Magnitude: 0.69812
Collected Steps per Second: 13,141.13752
Overall Steps per Second: 7,063.24040
Timestep Collection Time: 3.80622
Timestep Consumption Time: 3.27524
PPO Batch Consumption Time: 0.24116
Total Iteration Time: 7.08145
Cumulative Model Updates: 177,974
Cumulative Timesteps: 1,355,089,268
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11596
Policy Entropy: 4.35288
Value Function Loss: 0.00232
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.89539
Value Function Update Magnitude: 0.70485
Collected Steps per Second: 13,128.00066
Overall Steps per Second: 7,272.64641
Timestep Collection Time: 3.81140
Timestep Consumption Time: 3.06863
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.88003
Cumulative Model Updates: 177,983
Cumulative Timesteps: 1,355,139,304
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1355139304...
Checkpoint 1355139304 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.37824
Policy Entropy: 4.34994
Value Function Loss: 0.00242
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02237
Policy Update Magnitude: 0.87693
Value Function Update Magnitude: 0.67439
Collected Steps per Second: 13,459.22080
Overall Steps per Second: 7,332.92469
Timestep Collection Time: 3.71537
Timestep Consumption Time: 3.10401
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.81938
Cumulative Model Updates: 177,992
Cumulative Timesteps: 1,355,189,310
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91931
Policy Entropy: 4.35115
Value Function Loss: 0.00240
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02336
Policy Update Magnitude: 0.90294
Value Function Update Magnitude: 0.66877
Collected Steps per Second: 13,258.13587
Overall Steps per Second: 7,245.84107
Timestep Collection Time: 3.77293
Timestep Consumption Time: 3.13062
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.90355
Cumulative Model Updates: 178,001
Cumulative Timesteps: 1,355,239,332
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1355239332...
Checkpoint 1355239332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12386
Policy Entropy: 4.35023
Value Function Loss: 0.00252
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.91420
Value Function Update Magnitude: 0.69837
Collected Steps per Second: 13,201.10893
Overall Steps per Second: 7,365.00864
Timestep Collection Time: 3.78786
Timestep Consumption Time: 3.00154
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.78940
Cumulative Model Updates: 178,010
Cumulative Timesteps: 1,355,289,336
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56312
Policy Entropy: 4.35291
Value Function Loss: 0.00231
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02534
Policy Update Magnitude: 0.89293
Value Function Update Magnitude: 0.69026
Collected Steps per Second: 13,149.35103
Overall Steps per Second: 7,244.96145
Timestep Collection Time: 3.80566
Timestep Consumption Time: 3.10148
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.90715
Cumulative Model Updates: 178,019
Cumulative Timesteps: 1,355,339,378
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1355339378...
Checkpoint 1355339378 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.95404
Policy Entropy: 4.35480
Value Function Loss: 0.00231
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.88261
Value Function Update Magnitude: 0.67715
Collected Steps per Second: 13,241.36476
Overall Steps per Second: 7,302.83592
Timestep Collection Time: 3.77635
Timestep Consumption Time: 3.07086
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.84720
Cumulative Model Updates: 178,028
Cumulative Timesteps: 1,355,389,382
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.55867
Policy Entropy: 4.35772
Value Function Loss: 0.00216
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.86709
Value Function Update Magnitude: 0.67518
Collected Steps per Second: 13,006.00041
Overall Steps per Second: 7,148.46328
Timestep Collection Time: 3.84745
Timestep Consumption Time: 3.15265
PPO Batch Consumption Time: 0.23954
Total Iteration Time: 7.00011
Cumulative Model Updates: 178,037
Cumulative Timesteps: 1,355,439,422
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1355439422...
Checkpoint 1355439422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.64219
Policy Entropy: 4.35377
Value Function Loss: 0.00242
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.87988
Value Function Update Magnitude: 0.68140
Collected Steps per Second: 13,270.88645
Overall Steps per Second: 7,257.85544
Timestep Collection Time: 3.76945
Timestep Consumption Time: 3.12294
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.89239
Cumulative Model Updates: 178,046
Cumulative Timesteps: 1,355,489,446
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95431
Policy Entropy: 4.35898
Value Function Loss: 0.00223
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.89234
Value Function Update Magnitude: 0.66506
Collected Steps per Second: 13,217.18310
Overall Steps per Second: 7,307.40511
Timestep Collection Time: 3.78522
Timestep Consumption Time: 3.06126
PPO Batch Consumption Time: 0.22762
Total Iteration Time: 6.84648
Cumulative Model Updates: 178,055
Cumulative Timesteps: 1,355,539,476
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1355539476...
Checkpoint 1355539476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03541
Policy Entropy: 4.35572
Value Function Loss: 0.00223
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.89780
Value Function Update Magnitude: 0.67705
Collected Steps per Second: 13,457.49110
Overall Steps per Second: 7,338.75755
Timestep Collection Time: 3.71733
Timestep Consumption Time: 3.09935
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.81669
Cumulative Model Updates: 178,064
Cumulative Timesteps: 1,355,589,502
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87599
Policy Entropy: 4.35262
Value Function Loss: 0.00246
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02223
Policy Update Magnitude: 0.92663
Value Function Update Magnitude: 0.67205
Collected Steps per Second: 13,358.06527
Overall Steps per Second: 7,273.54812
Timestep Collection Time: 3.74560
Timestep Consumption Time: 3.13330
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.87890
Cumulative Model Updates: 178,073
Cumulative Timesteps: 1,355,639,536
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1355639536...
Checkpoint 1355639536 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92053
Policy Entropy: 4.34272
Value Function Loss: 0.00280
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.95458
Value Function Update Magnitude: 0.74672
Collected Steps per Second: 13,147.52791
Overall Steps per Second: 7,351.39153
Timestep Collection Time: 3.80376
Timestep Consumption Time: 2.99904
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.80279
Cumulative Model Updates: 178,082
Cumulative Timesteps: 1,355,689,546
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.55195
Policy Entropy: 4.34186
Value Function Loss: 0.00289
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.94712
Value Function Update Magnitude: 0.82384
Collected Steps per Second: 13,273.39149
Overall Steps per Second: 7,272.49929
Timestep Collection Time: 3.77010
Timestep Consumption Time: 3.11089
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.88099
Cumulative Model Updates: 178,091
Cumulative Timesteps: 1,355,739,588
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1355739588...
Checkpoint 1355739588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.38556
Policy Entropy: 4.34226
Value Function Loss: 0.00284
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02653
Policy Update Magnitude: 0.96099
Value Function Update Magnitude: 0.79207
Collected Steps per Second: 13,237.99814
Overall Steps per Second: 7,090.79667
Timestep Collection Time: 3.77716
Timestep Consumption Time: 3.27452
PPO Batch Consumption Time: 0.24505
Total Iteration Time: 7.05168
Cumulative Model Updates: 178,100
Cumulative Timesteps: 1,355,789,590
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.67982
Policy Entropy: 4.34397
Value Function Loss: 0.00270
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.96255
Value Function Update Magnitude: 0.74750
Collected Steps per Second: 13,139.43672
Overall Steps per Second: 7,350.18617
Timestep Collection Time: 3.80686
Timestep Consumption Time: 2.99841
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.80527
Cumulative Model Updates: 178,109
Cumulative Timesteps: 1,355,839,610
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1355839610...
Checkpoint 1355839610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54605
Policy Entropy: 4.34711
Value Function Loss: 0.00260
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.93679
Value Function Update Magnitude: 0.75784
Collected Steps per Second: 13,175.58455
Overall Steps per Second: 7,249.66968
Timestep Collection Time: 3.79642
Timestep Consumption Time: 3.10321
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.89962
Cumulative Model Updates: 178,118
Cumulative Timesteps: 1,355,889,630
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83955
Policy Entropy: 4.35080
Value Function Loss: 0.00246
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02445
Policy Update Magnitude: 0.92074
Value Function Update Magnitude: 0.76118
Collected Steps per Second: 13,324.58280
Overall Steps per Second: 7,306.17305
Timestep Collection Time: 3.75276
Timestep Consumption Time: 3.09131
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.84408
Cumulative Model Updates: 178,127
Cumulative Timesteps: 1,355,939,634
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1355939634...
Checkpoint 1355939634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22912
Policy Entropy: 4.35501
Value Function Loss: 0.00230
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.89913
Value Function Update Magnitude: 0.77388
Collected Steps per Second: 13,424.08765
Overall Steps per Second: 7,329.27562
Timestep Collection Time: 3.72793
Timestep Consumption Time: 3.10003
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.82796
Cumulative Model Updates: 178,136
Cumulative Timesteps: 1,355,989,678
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.30584
Policy Entropy: 4.35659
Value Function Loss: 0.00220
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.87016
Value Function Update Magnitude: 0.76131
Collected Steps per Second: 13,058.09980
Overall Steps per Second: 7,217.20281
Timestep Collection Time: 3.83119
Timestep Consumption Time: 3.10059
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.93177
Cumulative Model Updates: 178,145
Cumulative Timesteps: 1,356,039,706
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1356039706...
Checkpoint 1356039706 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.13445
Policy Entropy: 4.35842
Value Function Loss: 0.00209
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.86740
Value Function Update Magnitude: 0.78022
Collected Steps per Second: 13,289.95099
Overall Steps per Second: 7,303.80934
Timestep Collection Time: 3.76390
Timestep Consumption Time: 3.08486
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.84875
Cumulative Model Updates: 178,154
Cumulative Timesteps: 1,356,089,728
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10452
Policy Entropy: 4.35885
Value Function Loss: 0.00207
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02193
Policy Update Magnitude: 0.87513
Value Function Update Magnitude: 0.72736
Collected Steps per Second: 13,503.81606
Overall Steps per Second: 7,171.66477
Timestep Collection Time: 3.70340
Timestep Consumption Time: 3.26988
PPO Batch Consumption Time: 0.24042
Total Iteration Time: 6.97328
Cumulative Model Updates: 178,163
Cumulative Timesteps: 1,356,139,738
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1356139738...
Checkpoint 1356139738 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.26722
Policy Entropy: 4.35429
Value Function Loss: 0.00220
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02289
Policy Update Magnitude: 0.88869
Value Function Update Magnitude: 0.70914
Collected Steps per Second: 13,088.70511
Overall Steps per Second: 7,252.26171
Timestep Collection Time: 3.82039
Timestep Consumption Time: 3.07456
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.89495
Cumulative Model Updates: 178,172
Cumulative Timesteps: 1,356,189,742
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87814
Policy Entropy: 4.35325
Value Function Loss: 0.00234
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02399
Policy Update Magnitude: 0.89937
Value Function Update Magnitude: 0.70008
Collected Steps per Second: 13,316.61152
Overall Steps per Second: 7,404.43772
Timestep Collection Time: 3.75621
Timestep Consumption Time: 2.99920
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.75541
Cumulative Model Updates: 178,181
Cumulative Timesteps: 1,356,239,762
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1356239762...
Checkpoint 1356239762 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63762
Policy Entropy: 4.35232
Value Function Loss: 0.00228
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.89169
Value Function Update Magnitude: 0.69304
Collected Steps per Second: 13,261.45286
Overall Steps per Second: 7,270.99672
Timestep Collection Time: 3.77078
Timestep Consumption Time: 3.10668
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.87746
Cumulative Model Updates: 178,190
Cumulative Timesteps: 1,356,289,768
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.51155
Policy Entropy: 4.35624
Value Function Loss: 0.00230
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.88436
Value Function Update Magnitude: 0.73247
Collected Steps per Second: 13,186.52233
Overall Steps per Second: 7,281.37939
Timestep Collection Time: 3.79327
Timestep Consumption Time: 3.07631
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.86958
Cumulative Model Updates: 178,199
Cumulative Timesteps: 1,356,339,788
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1356339788...
Checkpoint 1356339788 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25036
Policy Entropy: 4.36012
Value Function Loss: 0.00219
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02194
Policy Update Magnitude: 0.88062
Value Function Update Magnitude: 0.73445
Collected Steps per Second: 13,541.23857
Overall Steps per Second: 7,341.03778
Timestep Collection Time: 3.69346
Timestep Consumption Time: 3.11947
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.81293
Cumulative Model Updates: 178,208
Cumulative Timesteps: 1,356,389,802
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.45933
Policy Entropy: 4.35905
Value Function Loss: 0.00222
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02149
Policy Update Magnitude: 0.88663
Value Function Update Magnitude: 0.71786
Collected Steps per Second: 13,308.73033
Overall Steps per Second: 7,291.65042
Timestep Collection Time: 3.75949
Timestep Consumption Time: 3.10233
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.86182
Cumulative Model Updates: 178,217
Cumulative Timesteps: 1,356,439,836
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1356439836...
Checkpoint 1356439836 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01021
Policy Entropy: 4.35793
Value Function Loss: 0.00235
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.90702
Value Function Update Magnitude: 0.75839
Collected Steps per Second: 13,157.94528
Overall Steps per Second: 7,258.43482
Timestep Collection Time: 3.80059
Timestep Consumption Time: 3.08905
PPO Batch Consumption Time: 0.23070
Total Iteration Time: 6.88964
Cumulative Model Updates: 178,226
Cumulative Timesteps: 1,356,489,844
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61788
Policy Entropy: 4.35700
Value Function Loss: 0.00231
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.90959
Value Function Update Magnitude: 0.70979
Collected Steps per Second: 13,636.97019
Overall Steps per Second: 7,371.24501
Timestep Collection Time: 3.66680
Timestep Consumption Time: 3.11686
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.78366
Cumulative Model Updates: 178,235
Cumulative Timesteps: 1,356,539,848
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1356539848...
Checkpoint 1356539848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.59966
Policy Entropy: 4.35657
Value Function Loss: 0.00239
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02488
Policy Update Magnitude: 0.90346
Value Function Update Magnitude: 0.70704
Collected Steps per Second: 13,284.09349
Overall Steps per Second: 7,282.67890
Timestep Collection Time: 3.76541
Timestep Consumption Time: 3.10295
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.86835
Cumulative Model Updates: 178,244
Cumulative Timesteps: 1,356,589,868
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.24198
Policy Entropy: 4.35522
Value Function Loss: 0.00243
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.90320
Value Function Update Magnitude: 0.69990
Collected Steps per Second: 13,246.16156
Overall Steps per Second: 7,384.90387
Timestep Collection Time: 3.77709
Timestep Consumption Time: 2.99781
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.77490
Cumulative Model Updates: 178,253
Cumulative Timesteps: 1,356,639,900
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1356639900...
Checkpoint 1356639900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.85009
Policy Entropy: 4.35343
Value Function Loss: 0.00263
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.94946
Value Function Update Magnitude: 0.68872
Collected Steps per Second: 13,204.98793
Overall Steps per Second: 7,233.78073
Timestep Collection Time: 3.78857
Timestep Consumption Time: 3.12732
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.91589
Cumulative Model Updates: 178,262
Cumulative Timesteps: 1,356,689,928
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61010
Policy Entropy: 4.35482
Value Function Loss: 0.00263
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.94163
Value Function Update Magnitude: 0.71915
Collected Steps per Second: 13,344.92736
Overall Steps per Second: 7,333.95522
Timestep Collection Time: 3.74779
Timestep Consumption Time: 3.07172
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.81951
Cumulative Model Updates: 178,271
Cumulative Timesteps: 1,356,739,942
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1356739942...
Checkpoint 1356739942 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.68041
Policy Entropy: 4.35675
Value Function Loss: 0.00245
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.91637
Value Function Update Magnitude: 0.71082
Collected Steps per Second: 13,180.29048
Overall Steps per Second: 7,358.33127
Timestep Collection Time: 3.79536
Timestep Consumption Time: 3.00292
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.79828
Cumulative Model Updates: 178,280
Cumulative Timesteps: 1,356,789,966
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01198
Policy Entropy: 4.35801
Value Function Loss: 0.00237
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02214
Policy Update Magnitude: 0.88696
Value Function Update Magnitude: 0.63312
Collected Steps per Second: 13,222.47532
Overall Steps per Second: 7,141.96653
Timestep Collection Time: 3.78401
Timestep Consumption Time: 3.22162
PPO Batch Consumption Time: 0.23864
Total Iteration Time: 7.00563
Cumulative Model Updates: 178,289
Cumulative Timesteps: 1,356,840,000
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1356840000...
Checkpoint 1356840000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19308
Policy Entropy: 4.35782
Value Function Loss: 0.00231
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.88296
Value Function Update Magnitude: 0.63091
Collected Steps per Second: 13,201.92472
Overall Steps per Second: 7,318.30912
Timestep Collection Time: 3.78839
Timestep Consumption Time: 3.04571
PPO Batch Consumption Time: 0.22786
Total Iteration Time: 6.83409
Cumulative Model Updates: 178,298
Cumulative Timesteps: 1,356,890,014
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.83830
Policy Entropy: 4.35846
Value Function Loss: 0.00237
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02234
Policy Update Magnitude: 0.87982
Value Function Update Magnitude: 0.71896
Collected Steps per Second: 13,621.83106
Overall Steps per Second: 7,377.04948
Timestep Collection Time: 3.67322
Timestep Consumption Time: 3.10944
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.78266
Cumulative Model Updates: 178,307
Cumulative Timesteps: 1,356,940,050
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1356940050...
Checkpoint 1356940050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50331
Policy Entropy: 4.35827
Value Function Loss: 0.00231
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.90171
Value Function Update Magnitude: 0.71772
Collected Steps per Second: 13,064.33793
Overall Steps per Second: 7,211.72265
Timestep Collection Time: 3.82982
Timestep Consumption Time: 3.10806
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.93787
Cumulative Model Updates: 178,316
Cumulative Timesteps: 1,356,990,084
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.49430
Policy Entropy: 4.35605
Value Function Loss: 0.00225
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.90755
Value Function Update Magnitude: 0.68176
Collected Steps per Second: 13,136.01407
Overall Steps per Second: 7,316.26502
Timestep Collection Time: 3.80816
Timestep Consumption Time: 3.02921
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.83737
Cumulative Model Updates: 178,325
Cumulative Timesteps: 1,357,040,108
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1357040108...
Checkpoint 1357040108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.07208
Policy Entropy: 4.35555
Value Function Loss: 0.00233
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.91505
Value Function Update Magnitude: 0.67544
Collected Steps per Second: 13,224.46269
Overall Steps per Second: 7,249.87941
Timestep Collection Time: 3.78284
Timestep Consumption Time: 3.11741
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.90025
Cumulative Model Updates: 178,334
Cumulative Timesteps: 1,357,090,134
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04666
Policy Entropy: 4.35614
Value Function Loss: 0.00218
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02342
Policy Update Magnitude: 0.89144
Value Function Update Magnitude: 0.67956
Collected Steps per Second: 13,095.56217
Overall Steps per Second: 7,266.97210
Timestep Collection Time: 3.82114
Timestep Consumption Time: 3.06481
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.88595
Cumulative Model Updates: 178,343
Cumulative Timesteps: 1,357,140,174
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1357140174...
Checkpoint 1357140174 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44450
Policy Entropy: 4.35427
Value Function Loss: 0.00217
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.89952
Value Function Update Magnitude: 0.66387
Collected Steps per Second: 13,441.82998
Overall Steps per Second: 7,192.49868
Timestep Collection Time: 3.72137
Timestep Consumption Time: 3.23338
PPO Batch Consumption Time: 0.24038
Total Iteration Time: 6.95475
Cumulative Model Updates: 178,352
Cumulative Timesteps: 1,357,190,196
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89042
Policy Entropy: 4.35694
Value Function Loss: 0.00223
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.89680
Value Function Update Magnitude: 0.64698
Collected Steps per Second: 13,288.84903
Overall Steps per Second: 7,279.68384
Timestep Collection Time: 3.76316
Timestep Consumption Time: 3.10637
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.86953
Cumulative Model Updates: 178,361
Cumulative Timesteps: 1,357,240,204
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1357240204...
Checkpoint 1357240204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.53945
Policy Entropy: 4.35744
Value Function Loss: 0.00233
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.91437
Value Function Update Magnitude: 0.72374
Collected Steps per Second: 13,036.92095
Overall Steps per Second: 7,263.28645
Timestep Collection Time: 3.83787
Timestep Consumption Time: 3.05075
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.88862
Cumulative Model Updates: 178,370
Cumulative Timesteps: 1,357,290,238
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.74277
Policy Entropy: 4.35457
Value Function Loss: 0.00240
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.91408
Value Function Update Magnitude: 0.72076
Collected Steps per Second: 13,618.15932
Overall Steps per Second: 7,393.03403
Timestep Collection Time: 3.67333
Timestep Consumption Time: 3.09304
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.76637
Cumulative Model Updates: 178,379
Cumulative Timesteps: 1,357,340,262
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1357340262...
Checkpoint 1357340262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.96054
Policy Entropy: 4.35573
Value Function Loss: 0.00234
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02399
Policy Update Magnitude: 0.92170
Value Function Update Magnitude: 0.71789
Collected Steps per Second: 13,337.56537
Overall Steps per Second: 7,287.50947
Timestep Collection Time: 3.75076
Timestep Consumption Time: 3.11386
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.86462
Cumulative Model Updates: 178,388
Cumulative Timesteps: 1,357,390,288
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35849
Policy Entropy: 4.35130
Value Function Loss: 0.00247
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.92952
Value Function Update Magnitude: 0.68375
Collected Steps per Second: 13,222.48575
Overall Steps per Second: 7,378.53269
Timestep Collection Time: 3.78371
Timestep Consumption Time: 2.99677
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.78048
Cumulative Model Updates: 178,397
Cumulative Timesteps: 1,357,440,318
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1357440318...
Checkpoint 1357440318 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24876
Policy Entropy: 4.35189
Value Function Loss: 0.00253
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.92839
Value Function Update Magnitude: 0.66158
Collected Steps per Second: 13,305.99952
Overall Steps per Second: 7,252.66744
Timestep Collection Time: 3.75906
Timestep Consumption Time: 3.13744
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.89650
Cumulative Model Updates: 178,406
Cumulative Timesteps: 1,357,490,336
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71863
Policy Entropy: 4.34914
Value Function Loss: 0.00256
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.93775
Value Function Update Magnitude: 0.68537
Collected Steps per Second: 13,276.08305
Overall Steps per Second: 7,126.42188
Timestep Collection Time: 3.76979
Timestep Consumption Time: 3.25309
PPO Batch Consumption Time: 0.24365
Total Iteration Time: 7.02288
Cumulative Model Updates: 178,415
Cumulative Timesteps: 1,357,540,384
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1357540384...
Checkpoint 1357540384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02351
Policy Entropy: 4.35168
Value Function Loss: 0.00241
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.91133
Value Function Update Magnitude: 0.70856
Collected Steps per Second: 13,555.12539
Overall Steps per Second: 7,370.53411
Timestep Collection Time: 3.69012
Timestep Consumption Time: 3.09637
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.78648
Cumulative Model Updates: 178,424
Cumulative Timesteps: 1,357,590,404
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06290
Policy Entropy: 4.35519
Value Function Loss: 0.00228
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02283
Policy Update Magnitude: 0.89749
Value Function Update Magnitude: 0.72224
Collected Steps per Second: 13,197.07279
Overall Steps per Second: 7,264.38378
Timestep Collection Time: 3.79099
Timestep Consumption Time: 3.09603
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.88703
Cumulative Model Updates: 178,433
Cumulative Timesteps: 1,357,640,434
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1357640434...
Checkpoint 1357640434 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04608
Policy Entropy: 4.35735
Value Function Loss: 0.00223
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02218
Policy Update Magnitude: 0.90191
Value Function Update Magnitude: 0.67559
Collected Steps per Second: 13,197.80797
Overall Steps per Second: 7,285.03952
Timestep Collection Time: 3.78957
Timestep Consumption Time: 3.07573
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.86530
Cumulative Model Updates: 178,442
Cumulative Timesteps: 1,357,690,448
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09411
Policy Entropy: 4.35166
Value Function Loss: 0.00236
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.91509
Value Function Update Magnitude: 0.70993
Collected Steps per Second: 13,501.48389
Overall Steps per Second: 7,351.37724
Timestep Collection Time: 3.70448
Timestep Consumption Time: 3.09914
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.80362
Cumulative Model Updates: 178,451
Cumulative Timesteps: 1,357,740,464
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1357740464...
Checkpoint 1357740464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.60263
Policy Entropy: 4.35049
Value Function Loss: 0.00238
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.94351
Value Function Update Magnitude: 0.72211
Collected Steps per Second: 13,092.11444
Overall Steps per Second: 7,210.04404
Timestep Collection Time: 3.81909
Timestep Consumption Time: 3.11568
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.93477
Cumulative Model Updates: 178,460
Cumulative Timesteps: 1,357,790,464
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99470
Policy Entropy: 4.35021
Value Function Loss: 0.00246
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.94955
Value Function Update Magnitude: 0.71681
Collected Steps per Second: 13,242.14252
Overall Steps per Second: 7,383.65822
Timestep Collection Time: 3.77658
Timestep Consumption Time: 2.99649
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.77307
Cumulative Model Updates: 178,469
Cumulative Timesteps: 1,357,840,474
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1357840474...
Checkpoint 1357840474 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22166
Policy Entropy: 4.35473
Value Function Loss: 0.00231
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.91222
Value Function Update Magnitude: 0.70061
Collected Steps per Second: 13,332.99748
Overall Steps per Second: 7,210.08479
Timestep Collection Time: 3.75159
Timestep Consumption Time: 3.18591
PPO Batch Consumption Time: 0.23302
Total Iteration Time: 6.93751
Cumulative Model Updates: 178,478
Cumulative Timesteps: 1,357,890,494
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.46749
Policy Entropy: 4.35643
Value Function Loss: 0.00247
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02382
Policy Update Magnitude: 0.91588
Value Function Update Magnitude: 0.67282
Collected Steps per Second: 13,197.51574
Overall Steps per Second: 7,269.98216
Timestep Collection Time: 3.78996
Timestep Consumption Time: 3.09012
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.88007
Cumulative Model Updates: 178,487
Cumulative Timesteps: 1,357,940,512
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1357940512...
Checkpoint 1357940512 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.22682
Policy Entropy: 4.35384
Value Function Loss: 0.00255
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.95665
Value Function Update Magnitude: 0.69203
Collected Steps per Second: 13,223.29447
Overall Steps per Second: 7,357.80926
Timestep Collection Time: 3.78287
Timestep Consumption Time: 3.01562
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.79849
Cumulative Model Updates: 178,496
Cumulative Timesteps: 1,357,990,534
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.86616
Policy Entropy: 4.35267
Value Function Loss: 0.00238
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02376
Policy Update Magnitude: 0.94590
Value Function Update Magnitude: 0.71896
Collected Steps per Second: 13,373.28972
Overall Steps per Second: 7,295.43983
Timestep Collection Time: 3.73954
Timestep Consumption Time: 3.11542
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.85497
Cumulative Model Updates: 178,505
Cumulative Timesteps: 1,358,040,544
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1358040544...
Checkpoint 1358040544 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31232
Policy Entropy: 4.35250
Value Function Loss: 0.00219
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.90039
Value Function Update Magnitude: 0.71035
Collected Steps per Second: 13,255.16519
Overall Steps per Second: 7,308.28729
Timestep Collection Time: 3.77543
Timestep Consumption Time: 3.07213
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.84757
Cumulative Model Updates: 178,514
Cumulative Timesteps: 1,358,090,588
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56797
Policy Entropy: 4.35588
Value Function Loss: 0.00215
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.90078
Value Function Update Magnitude: 0.67430
Collected Steps per Second: 13,481.63219
Overall Steps per Second: 7,339.13091
Timestep Collection Time: 3.71038
Timestep Consumption Time: 3.10541
PPO Batch Consumption Time: 0.22779
Total Iteration Time: 6.81579
Cumulative Model Updates: 178,523
Cumulative Timesteps: 1,358,140,610
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1358140610...
Checkpoint 1358140610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54937
Policy Entropy: 4.35899
Value Function Loss: 0.00237
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.92641
Value Function Update Magnitude: 0.68763
Collected Steps per Second: 13,036.88359
Overall Steps per Second: 7,180.91314
Timestep Collection Time: 3.83650
Timestep Consumption Time: 3.12863
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.96513
Cumulative Model Updates: 178,532
Cumulative Timesteps: 1,358,190,626
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.22610
Policy Entropy: 4.35768
Value Function Loss: 0.00236
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.92728
Value Function Update Magnitude: 0.70606
Collected Steps per Second: 13,082.35960
Overall Steps per Second: 7,116.39817
Timestep Collection Time: 3.82194
Timestep Consumption Time: 3.20409
PPO Batch Consumption Time: 0.24535
Total Iteration Time: 7.02603
Cumulative Model Updates: 178,541
Cumulative Timesteps: 1,358,240,626
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1358240626...
Checkpoint 1358240626 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.88102
Policy Entropy: 4.35439
Value Function Loss: 0.00250
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.94851
Value Function Update Magnitude: 0.70220
Collected Steps per Second: 13,322.09412
Overall Steps per Second: 7,287.82380
Timestep Collection Time: 3.75602
Timestep Consumption Time: 3.10996
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.86597
Cumulative Model Updates: 178,550
Cumulative Timesteps: 1,358,290,664
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.00045
Policy Entropy: 4.35101
Value Function Loss: 0.00250
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.96390
Value Function Update Magnitude: 0.69686
Collected Steps per Second: 13,360.45769
Overall Steps per Second: 7,298.46716
Timestep Collection Time: 3.74448
Timestep Consumption Time: 3.11011
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.85459
Cumulative Model Updates: 178,559
Cumulative Timesteps: 1,358,340,692
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1358340692...
Checkpoint 1358340692 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33460
Policy Entropy: 4.34832
Value Function Loss: 0.00263
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.96675
Value Function Update Magnitude: 0.68084
Collected Steps per Second: 13,152.47766
Overall Steps per Second: 7,330.27705
Timestep Collection Time: 3.80643
Timestep Consumption Time: 3.02332
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.82976
Cumulative Model Updates: 178,568
Cumulative Timesteps: 1,358,390,756
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43555
Policy Entropy: 4.34871
Value Function Loss: 0.00245
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.93135
Value Function Update Magnitude: 0.67469
Collected Steps per Second: 13,298.55142
Overall Steps per Second: 7,286.64097
Timestep Collection Time: 3.76176
Timestep Consumption Time: 3.10368
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.86544
Cumulative Model Updates: 178,577
Cumulative Timesteps: 1,358,440,782
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1358440782...
Checkpoint 1358440782 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63443
Policy Entropy: 4.35189
Value Function Loss: 0.00249
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.92323
Value Function Update Magnitude: 0.70133
Collected Steps per Second: 13,253.70095
Overall Steps per Second: 7,317.42042
Timestep Collection Time: 3.77585
Timestep Consumption Time: 3.06317
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.83902
Cumulative Model Updates: 178,586
Cumulative Timesteps: 1,358,490,826
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50007
Policy Entropy: 4.35287
Value Function Loss: 0.00237
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02318
Policy Update Magnitude: 0.92799
Value Function Update Magnitude: 0.69168
Collected Steps per Second: 13,227.70072
Overall Steps per Second: 7,391.48671
Timestep Collection Time: 3.78146
Timestep Consumption Time: 2.98579
PPO Batch Consumption Time: 0.22776
Total Iteration Time: 6.76724
Cumulative Model Updates: 178,595
Cumulative Timesteps: 1,358,540,846
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1358540846...
Checkpoint 1358540846 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.15244
Policy Entropy: 4.35147
Value Function Loss: 0.00253
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02363
Policy Update Magnitude: 0.95311
Value Function Update Magnitude: 0.71584
Collected Steps per Second: 13,249.52051
Overall Steps per Second: 7,098.03081
Timestep Collection Time: 3.77629
Timestep Consumption Time: 3.27271
PPO Batch Consumption Time: 0.24219
Total Iteration Time: 7.04900
Cumulative Model Updates: 178,604
Cumulative Timesteps: 1,358,590,880
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.73530
Policy Entropy: 4.34842
Value Function Loss: 0.00248
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.94654
Value Function Update Magnitude: 0.71976
Collected Steps per Second: 13,250.53340
Overall Steps per Second: 7,309.92624
Timestep Collection Time: 3.77464
Timestep Consumption Time: 3.06756
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.84220
Cumulative Model Updates: 178,613
Cumulative Timesteps: 1,358,640,896
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1358640896...
Checkpoint 1358640896 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95028
Policy Entropy: 4.34358
Value Function Loss: 0.00255
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02862
Policy Update Magnitude: 0.92134
Value Function Update Magnitude: 0.72601
Collected Steps per Second: 13,525.45059
Overall Steps per Second: 7,349.07816
Timestep Collection Time: 3.69777
Timestep Consumption Time: 3.10771
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.80548
Cumulative Model Updates: 178,622
Cumulative Timesteps: 1,358,690,910
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.73528
Policy Entropy: 4.34685
Value Function Loss: 0.00254
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02690
Policy Update Magnitude: 0.92594
Value Function Update Magnitude: 0.74625
Collected Steps per Second: 13,336.63070
Overall Steps per Second: 7,297.33513
Timestep Collection Time: 3.75087
Timestep Consumption Time: 3.10423
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.85511
Cumulative Model Updates: 178,631
Cumulative Timesteps: 1,358,740,934
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1358740934...
Checkpoint 1358740934 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.39133
Policy Entropy: 4.34884
Value Function Loss: 0.00241
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.91261
Value Function Update Magnitude: 0.74294
Collected Steps per Second: 13,162.41328
Overall Steps per Second: 7,338.94199
Timestep Collection Time: 3.80158
Timestep Consumption Time: 3.01657
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.81815
Cumulative Model Updates: 178,640
Cumulative Timesteps: 1,358,790,972
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41532
Policy Entropy: 4.35533
Value Function Loss: 0.00221
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.89746
Value Function Update Magnitude: 0.69272
Collected Steps per Second: 13,196.33159
Overall Steps per Second: 7,264.43256
Timestep Collection Time: 3.79060
Timestep Consumption Time: 3.09528
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.88588
Cumulative Model Updates: 178,649
Cumulative Timesteps: 1,358,840,994
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1358840994...
Checkpoint 1358840994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75390
Policy Entropy: 4.35154
Value Function Loss: 0.00223
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.90506
Value Function Update Magnitude: 0.69009
Collected Steps per Second: 13,110.30783
Overall Steps per Second: 7,269.68337
Timestep Collection Time: 3.81532
Timestep Consumption Time: 3.06531
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.88063
Cumulative Model Updates: 178,658
Cumulative Timesteps: 1,358,891,014
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.92802
Policy Entropy: 4.35105
Value Function Loss: 0.00228
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.90778
Value Function Update Magnitude: 0.67314
Collected Steps per Second: 13,441.62660
Overall Steps per Second: 7,319.44089
Timestep Collection Time: 3.72157
Timestep Consumption Time: 3.11283
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.83440
Cumulative Model Updates: 178,667
Cumulative Timesteps: 1,358,941,038
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1358941038...
Checkpoint 1358941038 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.78329
Policy Entropy: 4.35051
Value Function Loss: 0.00247
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.91065
Value Function Update Magnitude: 0.66327
Collected Steps per Second: 13,280.04719
Overall Steps per Second: 7,306.32142
Timestep Collection Time: 3.76821
Timestep Consumption Time: 3.08093
PPO Batch Consumption Time: 0.22780
Total Iteration Time: 6.84914
Cumulative Model Updates: 178,676
Cumulative Timesteps: 1,358,991,080
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22217
Policy Entropy: 4.35328
Value Function Loss: 0.00240
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02764
Policy Update Magnitude: 0.91157
Value Function Update Magnitude: 0.66351
Collected Steps per Second: 13,329.43748
Overall Steps per Second: 7,343.89647
Timestep Collection Time: 3.75305
Timestep Consumption Time: 3.05887
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.81192
Cumulative Model Updates: 178,685
Cumulative Timesteps: 1,359,041,106
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1359041106...
Checkpoint 1359041106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91682
Policy Entropy: 4.35247
Value Function Loss: 0.00233
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02594
Policy Update Magnitude: 0.87540
Value Function Update Magnitude: 0.67216
Collected Steps per Second: 13,504.73827
Overall Steps per Second: 7,351.51414
Timestep Collection Time: 3.70329
Timestep Consumption Time: 3.09966
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.80295
Cumulative Model Updates: 178,694
Cumulative Timesteps: 1,359,091,118
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50790
Policy Entropy: 4.35194
Value Function Loss: 0.00230
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.87332
Value Function Update Magnitude: 0.65159
Collected Steps per Second: 13,007.49622
Overall Steps per Second: 7,202.40292
Timestep Collection Time: 3.84686
Timestep Consumption Time: 3.10054
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.94740
Cumulative Model Updates: 178,703
Cumulative Timesteps: 1,359,141,156
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1359141156...
Checkpoint 1359141156 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.10034
Policy Entropy: 4.35241
Value Function Loss: 0.00218
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02414
Policy Update Magnitude: 0.87144
Value Function Update Magnitude: 0.61829
Collected Steps per Second: 13,199.81786
Overall Steps per Second: 7,293.00565
Timestep Collection Time: 3.79096
Timestep Consumption Time: 3.07041
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.86137
Cumulative Model Updates: 178,712
Cumulative Timesteps: 1,359,191,196
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.22357
Policy Entropy: 4.35338
Value Function Loss: 0.00234
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.88045
Value Function Update Magnitude: 0.67644
Collected Steps per Second: 13,645.94953
Overall Steps per Second: 7,371.34357
Timestep Collection Time: 3.66585
Timestep Consumption Time: 3.12043
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.78628
Cumulative Model Updates: 178,721
Cumulative Timesteps: 1,359,241,220
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1359241220...
Checkpoint 1359241220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.58870
Policy Entropy: 4.35138
Value Function Loss: 0.00231
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.89226
Value Function Update Magnitude: 0.67693
Collected Steps per Second: 13,194.36591
Overall Steps per Second: 7,150.31340
Timestep Collection Time: 3.78980
Timestep Consumption Time: 3.20346
PPO Batch Consumption Time: 0.24043
Total Iteration Time: 6.99326
Cumulative Model Updates: 178,730
Cumulative Timesteps: 1,359,291,224
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.69835
Policy Entropy: 4.34856
Value Function Loss: 0.00239
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.88801
Value Function Update Magnitude: 0.70663
Collected Steps per Second: 13,249.69359
Overall Steps per Second: 7,375.29627
Timestep Collection Time: 3.77473
Timestep Consumption Time: 3.00656
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.78129
Cumulative Model Updates: 178,739
Cumulative Timesteps: 1,359,341,238
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1359341238...
Checkpoint 1359341238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96373
Policy Entropy: 4.35202
Value Function Loss: 0.00234
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02434
Policy Update Magnitude: 0.90299
Value Function Update Magnitude: 0.67496
Collected Steps per Second: 13,118.09843
Overall Steps per Second: 7,245.31946
Timestep Collection Time: 3.81168
Timestep Consumption Time: 3.08960
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.90128
Cumulative Model Updates: 178,748
Cumulative Timesteps: 1,359,391,240
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.00265
Policy Entropy: 4.35426
Value Function Loss: 0.00231
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.89789
Value Function Update Magnitude: 0.69573
Collected Steps per Second: 13,340.61550
Overall Steps per Second: 7,345.63157
Timestep Collection Time: 3.74870
Timestep Consumption Time: 3.05943
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.80813
Cumulative Model Updates: 178,757
Cumulative Timesteps: 1,359,441,250
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1359441250...
Checkpoint 1359441250 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.01001
Policy Entropy: 4.35399
Value Function Loss: 0.00233
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02411
Policy Update Magnitude: 0.88236
Value Function Update Magnitude: 0.69788
Collected Steps per Second: 13,644.23779
Overall Steps per Second: 7,417.27358
Timestep Collection Time: 3.66631
Timestep Consumption Time: 3.07795
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.74426
Cumulative Model Updates: 178,766
Cumulative Timesteps: 1,359,491,274
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08742
Policy Entropy: 4.35409
Value Function Loss: 0.00240
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02405
Policy Update Magnitude: 0.89877
Value Function Update Magnitude: 0.72857
Collected Steps per Second: 13,307.32164
Overall Steps per Second: 7,288.14468
Timestep Collection Time: 3.75928
Timestep Consumption Time: 3.10474
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.86402
Cumulative Model Updates: 178,775
Cumulative Timesteps: 1,359,541,300
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1359541300...
Checkpoint 1359541300 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33931
Policy Entropy: 4.35375
Value Function Loss: 0.00241
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02478
Policy Update Magnitude: 0.91203
Value Function Update Magnitude: 0.70472
Collected Steps per Second: 13,223.40008
Overall Steps per Second: 7,295.61938
Timestep Collection Time: 3.78481
Timestep Consumption Time: 3.07520
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.86001
Cumulative Model Updates: 178,784
Cumulative Timesteps: 1,359,591,348
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17661
Policy Entropy: 4.35442
Value Function Loss: 0.00238
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02446
Policy Update Magnitude: 0.89977
Value Function Update Magnitude: 0.71988
Collected Steps per Second: 13,538.13866
Overall Steps per Second: 7,151.66292
Timestep Collection Time: 3.69711
Timestep Consumption Time: 3.30154
PPO Batch Consumption Time: 0.24514
Total Iteration Time: 6.99865
Cumulative Model Updates: 178,793
Cumulative Timesteps: 1,359,641,400
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1359641400...
Checkpoint 1359641400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.29305
Policy Entropy: 4.35068
Value Function Loss: 0.00249
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02574
Policy Update Magnitude: 0.90304
Value Function Update Magnitude: 0.72627
Collected Steps per Second: 13,174.42620
Overall Steps per Second: 7,244.62498
Timestep Collection Time: 3.79842
Timestep Consumption Time: 3.10905
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.90747
Cumulative Model Updates: 178,802
Cumulative Timesteps: 1,359,691,442
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.74431
Policy Entropy: 4.34947
Value Function Loss: 0.00250
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.91916
Value Function Update Magnitude: 0.72778
Collected Steps per Second: 13,147.90762
Overall Steps per Second: 7,263.64237
Timestep Collection Time: 3.80319
Timestep Consumption Time: 3.08096
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.88415
Cumulative Model Updates: 178,811
Cumulative Timesteps: 1,359,741,446
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1359741446...
Checkpoint 1359741446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82740
Policy Entropy: 4.34895
Value Function Loss: 0.00263
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.92481
Value Function Update Magnitude: 0.74309
Collected Steps per Second: 13,299.57544
Overall Steps per Second: 7,283.08148
Timestep Collection Time: 3.76192
Timestep Consumption Time: 3.10770
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.86962
Cumulative Model Updates: 178,820
Cumulative Timesteps: 1,359,791,478
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69246
Policy Entropy: 4.34877
Value Function Loss: 0.00252
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.92377
Value Function Update Magnitude: 0.80845
Collected Steps per Second: 13,334.26686
Overall Steps per Second: 7,272.12597
Timestep Collection Time: 3.75064
Timestep Consumption Time: 3.12658
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.87722
Cumulative Model Updates: 178,829
Cumulative Timesteps: 1,359,841,490
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1359841490...
Checkpoint 1359841490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.11677
Policy Entropy: 4.34717
Value Function Loss: 0.00244
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.89848
Value Function Update Magnitude: 0.76918
Collected Steps per Second: 13,246.35773
Overall Steps per Second: 7,378.48975
Timestep Collection Time: 3.77568
Timestep Consumption Time: 3.00267
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.77835
Cumulative Model Updates: 178,838
Cumulative Timesteps: 1,359,891,504
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33202
Policy Entropy: 4.34658
Value Function Loss: 0.00243
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.87957
Value Function Update Magnitude: 0.76139
Collected Steps per Second: 13,247.80724
Overall Steps per Second: 7,266.90416
Timestep Collection Time: 3.77663
Timestep Consumption Time: 3.10829
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.88491
Cumulative Model Updates: 178,847
Cumulative Timesteps: 1,359,941,536
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1359941536...
Checkpoint 1359941536 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46154
Policy Entropy: 4.35160
Value Function Loss: 0.00255
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02390
Policy Update Magnitude: 0.87298
Value Function Update Magnitude: 0.76204
Collected Steps per Second: 13,063.74580
Overall Steps per Second: 7,083.22344
Timestep Collection Time: 3.82968
Timestep Consumption Time: 3.23349
PPO Batch Consumption Time: 0.24109
Total Iteration Time: 7.06317
Cumulative Model Updates: 178,856
Cumulative Timesteps: 1,359,991,566
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93936
Policy Entropy: 4.35280
Value Function Loss: 0.00255
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.88344
Value Function Update Magnitude: 0.74209
Collected Steps per Second: 13,201.72221
Overall Steps per Second: 7,365.59801
Timestep Collection Time: 3.78890
Timestep Consumption Time: 3.00213
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.79103
Cumulative Model Updates: 178,865
Cumulative Timesteps: 1,360,041,586
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1360041586...
Checkpoint 1360041586 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.38023
Policy Entropy: 4.35241
Value Function Loss: 0.00244
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.88516
Value Function Update Magnitude: 0.78027
Collected Steps per Second: 13,284.86999
Overall Steps per Second: 7,282.30977
Timestep Collection Time: 3.76579
Timestep Consumption Time: 3.10401
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.86980
Cumulative Model Updates: 178,874
Cumulative Timesteps: 1,360,091,614
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.08207
Policy Entropy: 4.35504
Value Function Loss: 0.00229
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02439
Policy Update Magnitude: 0.87955
Value Function Update Magnitude: 0.75827
Collected Steps per Second: 13,271.87612
Overall Steps per Second: 7,320.56870
Timestep Collection Time: 3.76963
Timestep Consumption Time: 3.06454
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.83417
Cumulative Model Updates: 178,883
Cumulative Timesteps: 1,360,141,644
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1360141644...
Checkpoint 1360141644 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.27452
Policy Entropy: 4.35556
Value Function Loss: 0.00218
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.86460
Value Function Update Magnitude: 0.75653
Collected Steps per Second: 13,064.27259
Overall Steps per Second: 7,316.79521
Timestep Collection Time: 3.82922
Timestep Consumption Time: 3.00792
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.83715
Cumulative Model Updates: 178,892
Cumulative Timesteps: 1,360,191,670
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.67531
Policy Entropy: 4.35706
Value Function Loss: 0.00218
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.85432
Value Function Update Magnitude: 0.76554
Collected Steps per Second: 13,159.59769
Overall Steps per Second: 7,262.91553
Timestep Collection Time: 3.80376
Timestep Consumption Time: 3.08823
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.89200
Cumulative Model Updates: 178,901
Cumulative Timesteps: 1,360,241,726
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1360241726...
Checkpoint 1360241726 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49964
Policy Entropy: 4.35437
Value Function Loss: 0.00213
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.84661
Value Function Update Magnitude: 0.77774
Collected Steps per Second: 13,104.91742
Overall Steps per Second: 7,244.17836
Timestep Collection Time: 3.81536
Timestep Consumption Time: 3.08673
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.90209
Cumulative Model Updates: 178,910
Cumulative Timesteps: 1,360,291,726
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.44214
Policy Entropy: 4.35240
Value Function Loss: 0.00225
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02293
Policy Update Magnitude: 0.85888
Value Function Update Magnitude: 0.77834
Collected Steps per Second: 13,595.14707
Overall Steps per Second: 7,193.89918
Timestep Collection Time: 3.67984
Timestep Consumption Time: 3.27438
PPO Batch Consumption Time: 0.24495
Total Iteration Time: 6.95423
Cumulative Model Updates: 178,919
Cumulative Timesteps: 1,360,341,754
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1360341754...
Checkpoint 1360341754 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20493
Policy Entropy: 4.35392
Value Function Loss: 0.00232
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02360
Policy Update Magnitude: 0.87304
Value Function Update Magnitude: 0.72070
Collected Steps per Second: 13,142.63132
Overall Steps per Second: 7,253.02446
Timestep Collection Time: 3.80502
Timestep Consumption Time: 3.08976
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.89478
Cumulative Model Updates: 178,928
Cumulative Timesteps: 1,360,391,762
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.07378
Policy Entropy: 4.35137
Value Function Loss: 0.00246
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02479
Policy Update Magnitude: 0.88149
Value Function Update Magnitude: 0.74067
Collected Steps per Second: 13,080.30658
Overall Steps per Second: 7,325.31956
Timestep Collection Time: 3.82499
Timestep Consumption Time: 3.00502
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.83001
Cumulative Model Updates: 178,937
Cumulative Timesteps: 1,360,441,794
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1360441794...
Checkpoint 1360441794 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.26398
Policy Entropy: 4.35197
Value Function Loss: 0.00242
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.89422
Value Function Update Magnitude: 0.71690
Collected Steps per Second: 12,867.25119
Overall Steps per Second: 7,160.13859
Timestep Collection Time: 3.88801
Timestep Consumption Time: 3.09901
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.98702
Cumulative Model Updates: 178,946
Cumulative Timesteps: 1,360,491,822
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46436
Policy Entropy: 4.35220
Value Function Loss: 0.00240
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.91166
Value Function Update Magnitude: 0.76586
Collected Steps per Second: 13,116.98501
Overall Steps per Second: 7,289.18784
Timestep Collection Time: 3.81231
Timestep Consumption Time: 3.04799
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.86030
Cumulative Model Updates: 178,955
Cumulative Timesteps: 1,360,541,828
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1360541828...
Checkpoint 1360541828 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.26736
Policy Entropy: 4.35403
Value Function Loss: 0.00238
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02309
Policy Update Magnitude: 0.90131
Value Function Update Magnitude: 0.71048
Collected Steps per Second: 13,607.74392
Overall Steps per Second: 7,394.61363
Timestep Collection Time: 3.67482
Timestep Consumption Time: 3.08767
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.76249
Cumulative Model Updates: 178,964
Cumulative Timesteps: 1,360,591,834
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44853
Policy Entropy: 4.35677
Value Function Loss: 0.00219
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.87109
Value Function Update Magnitude: 0.75815
Collected Steps per Second: 13,329.02928
Overall Steps per Second: 7,286.05688
Timestep Collection Time: 3.75181
Timestep Consumption Time: 3.11171
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.86352
Cumulative Model Updates: 178,973
Cumulative Timesteps: 1,360,641,842
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1360641842...
Checkpoint 1360641842 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.90458
Policy Entropy: 4.36066
Value Function Loss: 0.00223
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02326
Policy Update Magnitude: 0.84937
Value Function Update Magnitude: 0.71408
Collected Steps per Second: 13,197.48727
Overall Steps per Second: 7,213.74178
Timestep Collection Time: 3.78936
Timestep Consumption Time: 3.14324
PPO Batch Consumption Time: 0.23998
Total Iteration Time: 6.93260
Cumulative Model Updates: 178,982
Cumulative Timesteps: 1,360,691,852
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43309
Policy Entropy: 4.36263
Value Function Loss: 0.00219
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02126
Policy Update Magnitude: 0.86242
Value Function Update Magnitude: 0.70630
Collected Steps per Second: 13,435.77041
Overall Steps per Second: 7,327.04488
Timestep Collection Time: 3.72424
Timestep Consumption Time: 3.10498
PPO Batch Consumption Time: 0.22778
Total Iteration Time: 6.82922
Cumulative Model Updates: 178,991
Cumulative Timesteps: 1,360,741,890
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1360741890...
Checkpoint 1360741890 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97238
Policy Entropy: 4.36398
Value Function Loss: 0.00229
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.88937
Value Function Update Magnitude: 0.73195
Collected Steps per Second: 13,133.68231
Overall Steps per Second: 7,222.94805
Timestep Collection Time: 3.80807
Timestep Consumption Time: 3.11625
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.92432
Cumulative Model Updates: 179,000
Cumulative Timesteps: 1,360,791,904
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61844
Policy Entropy: 4.36024
Value Function Loss: 0.00228
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.92118
Value Function Update Magnitude: 0.73240
Collected Steps per Second: 13,157.63546
Overall Steps per Second: 7,336.23605
Timestep Collection Time: 3.80099
Timestep Consumption Time: 3.01613
PPO Batch Consumption Time: 0.22782
Total Iteration Time: 6.81712
Cumulative Model Updates: 179,009
Cumulative Timesteps: 1,360,841,916
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1360841916...
Checkpoint 1360841916 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33802
Policy Entropy: 4.35873
Value Function Loss: 0.00252
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.95709
Value Function Update Magnitude: 0.77628
Collected Steps per Second: 13,203.07768
Overall Steps per Second: 7,264.90326
Timestep Collection Time: 3.78715
Timestep Consumption Time: 3.09553
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.88268
Cumulative Model Updates: 179,018
Cumulative Timesteps: 1,360,891,918
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64921
Policy Entropy: 4.36075
Value Function Loss: 0.00237
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.94457
Value Function Update Magnitude: 0.79009
Collected Steps per Second: 13,260.21304
Overall Steps per Second: 7,315.76585
Timestep Collection Time: 3.77189
Timestep Consumption Time: 3.06486
PPO Batch Consumption Time: 0.22768
Total Iteration Time: 6.83674
Cumulative Model Updates: 179,027
Cumulative Timesteps: 1,360,941,934
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1360941934...
Checkpoint 1360941934 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.14352
Policy Entropy: 4.36042
Value Function Loss: 0.00242
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.90814
Value Function Update Magnitude: 0.77128
Collected Steps per Second: 13,520.34477
Overall Steps per Second: 7,350.04529
Timestep Collection Time: 3.70079
Timestep Consumption Time: 3.10678
PPO Batch Consumption Time: 0.22771
Total Iteration Time: 6.80758
Cumulative Model Updates: 179,036
Cumulative Timesteps: 1,360,991,970
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71511
Policy Entropy: 4.36068
Value Function Loss: 0.00237
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.89559
Value Function Update Magnitude: 0.75189
Collected Steps per Second: 13,349.37308
Overall Steps per Second: 7,138.51882
Timestep Collection Time: 3.74669
Timestep Consumption Time: 3.25980
PPO Batch Consumption Time: 0.23937
Total Iteration Time: 7.00650
Cumulative Model Updates: 179,045
Cumulative Timesteps: 1,361,041,986
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1361041986...
Checkpoint 1361041986 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.21504
Policy Entropy: 4.35857
Value Function Loss: 0.00245
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02336
Policy Update Magnitude: 0.90467
Value Function Update Magnitude: 0.75251
Collected Steps per Second: 13,155.94747
Overall Steps per Second: 7,283.67148
Timestep Collection Time: 3.80223
Timestep Consumption Time: 3.06546
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.86769
Cumulative Model Updates: 179,054
Cumulative Timesteps: 1,361,092,008
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70391
Policy Entropy: 4.35817
Value Function Loss: 0.00242
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02278
Policy Update Magnitude: 0.89927
Value Function Update Magnitude: 0.73058
Collected Steps per Second: 13,645.92918
Overall Steps per Second: 7,406.36591
Timestep Collection Time: 3.66410
Timestep Consumption Time: 3.08685
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.75095
Cumulative Model Updates: 179,063
Cumulative Timesteps: 1,361,142,008
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1361142008...
Checkpoint 1361142008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44257
Policy Entropy: 4.35753
Value Function Loss: 0.00241
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.89123
Value Function Update Magnitude: 0.71071
Collected Steps per Second: 13,177.61442
Overall Steps per Second: 7,260.50009
Timestep Collection Time: 3.79750
Timestep Consumption Time: 3.09486
PPO Batch Consumption Time: 0.22778
Total Iteration Time: 6.89236
Cumulative Model Updates: 179,072
Cumulative Timesteps: 1,361,192,050
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.69512
Policy Entropy: 4.36013
Value Function Loss: 0.00235
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02333
Policy Update Magnitude: 0.87908
Value Function Update Magnitude: 0.76409
Collected Steps per Second: 13,251.72451
Overall Steps per Second: 7,379.35855
Timestep Collection Time: 3.77672
Timestep Consumption Time: 3.00545
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.78216
Cumulative Model Updates: 179,081
Cumulative Timesteps: 1,361,242,098
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1361242098...
Checkpoint 1361242098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.15496
Policy Entropy: 4.36272
Value Function Loss: 0.00223
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.88041
Value Function Update Magnitude: 0.75130
Collected Steps per Second: 13,201.98166
Overall Steps per Second: 7,259.51917
Timestep Collection Time: 3.78761
Timestep Consumption Time: 3.10045
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.88806
Cumulative Model Updates: 179,090
Cumulative Timesteps: 1,361,292,102
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01134
Policy Entropy: 4.36310
Value Function Loss: 0.00231
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.90105
Value Function Update Magnitude: 0.71440
Collected Steps per Second: 13,230.03013
Overall Steps per Second: 7,242.91459
Timestep Collection Time: 3.77973
Timestep Consumption Time: 3.12439
PPO Batch Consumption Time: 0.22939
Total Iteration Time: 6.90413
Cumulative Model Updates: 179,099
Cumulative Timesteps: 1,361,342,108
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1361342108...
Checkpoint 1361342108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.58801
Policy Entropy: 4.35845
Value Function Loss: 0.00249
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02297
Policy Update Magnitude: 0.90381
Value Function Update Magnitude: 0.72397
Collected Steps per Second: 13,156.68249
Overall Steps per Second: 7,194.21645
Timestep Collection Time: 3.80111
Timestep Consumption Time: 3.15031
PPO Batch Consumption Time: 0.23964
Total Iteration Time: 6.95142
Cumulative Model Updates: 179,108
Cumulative Timesteps: 1,361,392,118
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70689
Policy Entropy: 4.35827
Value Function Loss: 0.00242
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.89899
Value Function Update Magnitude: 0.73289
Collected Steps per Second: 13,343.26709
Overall Steps per Second: 7,299.82041
Timestep Collection Time: 3.74991
Timestep Consumption Time: 3.10451
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.85442
Cumulative Model Updates: 179,117
Cumulative Timesteps: 1,361,442,154
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1361442154...
Checkpoint 1361442154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.66664
Policy Entropy: 4.35887
Value Function Loss: 0.00231
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02313
Policy Update Magnitude: 0.87780
Value Function Update Magnitude: 0.74521
Collected Steps per Second: 13,296.36024
Overall Steps per Second: 7,324.35848
Timestep Collection Time: 3.76133
Timestep Consumption Time: 3.06684
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.82817
Cumulative Model Updates: 179,126
Cumulative Timesteps: 1,361,492,166
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66776
Policy Entropy: 4.35838
Value Function Loss: 0.00220
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.87738
Value Function Update Magnitude: 0.73576
Collected Steps per Second: 13,272.49796
Overall Steps per Second: 7,390.14651
Timestep Collection Time: 3.77050
Timestep Consumption Time: 3.00122
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.77172
Cumulative Model Updates: 179,135
Cumulative Timesteps: 1,361,542,210
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1361542210...
Checkpoint 1361542210 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.08216
Policy Entropy: 4.35735
Value Function Loss: 0.00223
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.87517
Value Function Update Magnitude: 0.68504
Collected Steps per Second: 13,320.37526
Overall Steps per Second: 7,293.63412
Timestep Collection Time: 3.75560
Timestep Consumption Time: 3.10326
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.85886
Cumulative Model Updates: 179,144
Cumulative Timesteps: 1,361,592,236
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.83421
Policy Entropy: 4.35805
Value Function Loss: 0.00227
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.86754
Value Function Update Magnitude: 0.70702
Collected Steps per Second: 13,296.93534
Overall Steps per Second: 7,314.80530
Timestep Collection Time: 3.76087
Timestep Consumption Time: 3.07568
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.83655
Cumulative Model Updates: 179,153
Cumulative Timesteps: 1,361,642,244
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1361642244...
Checkpoint 1361642244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74619
Policy Entropy: 4.35810
Value Function Loss: 0.00230
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.87365
Value Function Update Magnitude: 0.69843
Collected Steps per Second: 13,586.54951
Overall Steps per Second: 7,389.43350
Timestep Collection Time: 3.68202
Timestep Consumption Time: 3.08791
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.76994
Cumulative Model Updates: 179,162
Cumulative Timesteps: 1,361,692,270
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99535
Policy Entropy: 4.35801
Value Function Loss: 0.00227
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.87989
Value Function Update Magnitude: 0.65535
Collected Steps per Second: 13,113.31126
Overall Steps per Second: 7,099.27673
Timestep Collection Time: 3.81307
Timestep Consumption Time: 3.23018
PPO Batch Consumption Time: 0.23955
Total Iteration Time: 7.04325
Cumulative Model Updates: 179,171
Cumulative Timesteps: 1,361,742,272
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1361742272...
Checkpoint 1361742272 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11377
Policy Entropy: 4.35282
Value Function Loss: 0.00249
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.90348
Value Function Update Magnitude: 0.66292
Collected Steps per Second: 13,250.22892
Overall Steps per Second: 7,382.04078
Timestep Collection Time: 3.77533
Timestep Consumption Time: 3.00111
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.77645
Cumulative Model Updates: 179,180
Cumulative Timesteps: 1,361,792,296
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90571
Policy Entropy: 4.34982
Value Function Loss: 0.00268
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.94619
Value Function Update Magnitude: 0.68282
Collected Steps per Second: 13,108.49200
Overall Steps per Second: 7,202.75838
Timestep Collection Time: 3.81478
Timestep Consumption Time: 3.12784
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.94262
Cumulative Model Updates: 179,189
Cumulative Timesteps: 1,361,842,302
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1361842302...
Checkpoint 1361842302 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86290
Policy Entropy: 4.35015
Value Function Loss: 0.00264
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.93832
Value Function Update Magnitude: 0.74898
Collected Steps per Second: 13,255.07757
Overall Steps per Second: 7,318.70853
Timestep Collection Time: 3.77501
Timestep Consumption Time: 3.06199
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.83700
Cumulative Model Updates: 179,198
Cumulative Timesteps: 1,361,892,340
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.58279
Policy Entropy: 4.35223
Value Function Loss: 0.00235
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.90051
Value Function Update Magnitude: 0.76355
Collected Steps per Second: 13,568.03544
Overall Steps per Second: 7,342.94614
Timestep Collection Time: 3.68557
Timestep Consumption Time: 3.12450
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.81007
Cumulative Model Updates: 179,207
Cumulative Timesteps: 1,361,942,346
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1361942346...
Checkpoint 1361942346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41092
Policy Entropy: 4.35750
Value Function Loss: 0.00223
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02302
Policy Update Magnitude: 0.89281
Value Function Update Magnitude: 0.74038
Collected Steps per Second: 13,124.18877
Overall Steps per Second: 7,226.96684
Timestep Collection Time: 3.81265
Timestep Consumption Time: 3.11114
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.92379
Cumulative Model Updates: 179,216
Cumulative Timesteps: 1,361,992,384
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.61791
Policy Entropy: 4.35619
Value Function Loss: 0.00225
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02304
Policy Update Magnitude: 0.89301
Value Function Update Magnitude: 0.68110
Collected Steps per Second: 13,294.95098
Overall Steps per Second: 7,310.70766
Timestep Collection Time: 3.76128
Timestep Consumption Time: 3.07883
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.84010
Cumulative Model Updates: 179,225
Cumulative Timesteps: 1,362,042,390
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1362042390...
Checkpoint 1362042390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88126
Policy Entropy: 4.35833
Value Function Loss: 0.00227
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.87964
Value Function Update Magnitude: 0.71308
Collected Steps per Second: 13,384.68973
Overall Steps per Second: 7,100.90694
Timestep Collection Time: 3.73845
Timestep Consumption Time: 3.30825
PPO Batch Consumption Time: 0.24563
Total Iteration Time: 7.04671
Cumulative Model Updates: 179,234
Cumulative Timesteps: 1,362,092,428
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.60924
Policy Entropy: 4.35856
Value Function Loss: 0.00221
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.86941
Value Function Update Magnitude: 0.71334
Collected Steps per Second: 13,159.10005
Overall Steps per Second: 7,225.89423
Timestep Collection Time: 3.80224
Timestep Consumption Time: 3.12203
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.92426
Cumulative Model Updates: 179,243
Cumulative Timesteps: 1,362,142,462
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1362142462...
Checkpoint 1362142462 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.24472
Policy Entropy: 4.35994
Value Function Loss: 0.00223
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.84533
Value Function Update Magnitude: 0.69510
Collected Steps per Second: 13,047.81244
Overall Steps per Second: 7,292.78856
Timestep Collection Time: 3.83283
Timestep Consumption Time: 3.02463
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.85746
Cumulative Model Updates: 179,252
Cumulative Timesteps: 1,362,192,472
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.07779
Policy Entropy: 4.35867
Value Function Loss: 0.00209
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02408
Policy Update Magnitude: 0.82375
Value Function Update Magnitude: 0.67424
Collected Steps per Second: 13,173.11488
Overall Steps per Second: 7,261.09480
Timestep Collection Time: 3.79622
Timestep Consumption Time: 3.09090
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.88712
Cumulative Model Updates: 179,261
Cumulative Timesteps: 1,362,242,480
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1362242480...
Checkpoint 1362242480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.40356
Policy Entropy: 4.35757
Value Function Loss: 0.00212
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02263
Policy Update Magnitude: 0.82679
Value Function Update Magnitude: 0.62310
Collected Steps per Second: 13,251.73803
Overall Steps per Second: 7,315.41726
Timestep Collection Time: 3.77384
Timestep Consumption Time: 3.06240
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.83625
Cumulative Model Updates: 179,270
Cumulative Timesteps: 1,362,292,490
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.46929
Policy Entropy: 4.35931
Value Function Loss: 0.00210
Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02143
Policy Update Magnitude: 0.85260
Value Function Update Magnitude: 0.61241
Collected Steps per Second: 13,439.18915
Overall Steps per Second: 7,343.10697
Timestep Collection Time: 3.72403
Timestep Consumption Time: 3.09161
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.81564
Cumulative Model Updates: 179,279
Cumulative Timesteps: 1,362,342,538
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1362342538...
Checkpoint 1362342538 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28021
Policy Entropy: 4.35708
Value Function Loss: 0.00216
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02223
Policy Update Magnitude: 0.86682
Value Function Update Magnitude: 0.63000
Collected Steps per Second: 13,136.94783
Overall Steps per Second: 7,252.87021
Timestep Collection Time: 3.81032
Timestep Consumption Time: 3.09122
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.90154
Cumulative Model Updates: 179,288
Cumulative Timesteps: 1,362,392,594
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81016
Policy Entropy: 4.35691
Value Function Loss: 0.00211
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02235
Policy Update Magnitude: 0.85618
Value Function Update Magnitude: 0.61674
Collected Steps per Second: 13,081.90715
Overall Steps per Second: 7,145.17284
Timestep Collection Time: 3.82284
Timestep Consumption Time: 3.17629
PPO Batch Consumption Time: 0.23753
Total Iteration Time: 6.99913
Cumulative Model Updates: 179,297
Cumulative Timesteps: 1,362,442,604
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1362442604...
Checkpoint 1362442604 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74702
Policy Entropy: 4.35861
Value Function Loss: 0.00221
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02274
Policy Update Magnitude: 0.87646
Value Function Update Magnitude: 0.63340
Collected Steps per Second: 13,520.69170
Overall Steps per Second: 7,355.23584
Timestep Collection Time: 3.70040
Timestep Consumption Time: 3.10183
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.80223
Cumulative Model Updates: 179,306
Cumulative Timesteps: 1,362,492,636
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51341
Policy Entropy: 4.35944
Value Function Loss: 0.00210
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.85452
Value Function Update Magnitude: 0.63877
Collected Steps per Second: 13,396.36758
Overall Steps per Second: 7,310.18343
Timestep Collection Time: 3.73325
Timestep Consumption Time: 3.10816
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.84142
Cumulative Model Updates: 179,315
Cumulative Timesteps: 1,362,542,648
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1362542648...
Checkpoint 1362542648 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70186
Policy Entropy: 4.35940
Value Function Loss: 0.00207
Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.83250
Value Function Update Magnitude: 0.64882
Collected Steps per Second: 13,187.91042
Overall Steps per Second: 7,357.04998
Timestep Collection Time: 3.79135
Timestep Consumption Time: 3.00485
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.79620
Cumulative Model Updates: 179,324
Cumulative Timesteps: 1,362,592,648
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.32371
Policy Entropy: 4.35690
Value Function Loss: 0.00211
Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02080
Policy Update Magnitude: 0.85552
Value Function Update Magnitude: 0.66971
Collected Steps per Second: 13,187.59269
Overall Steps per Second: 7,247.02390
Timestep Collection Time: 3.79448
Timestep Consumption Time: 3.11043
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.90490
Cumulative Model Updates: 179,333
Cumulative Timesteps: 1,362,642,688
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1362642688...
Checkpoint 1362642688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84417
Policy Entropy: 4.35503
Value Function Loss: 0.00207
Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.85564
Value Function Update Magnitude: 0.66306
Collected Steps per Second: 13,232.44945
Overall Steps per Second: 7,284.38920
Timestep Collection Time: 3.77889
Timestep Consumption Time: 3.08565
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.86454
Cumulative Model Updates: 179,342
Cumulative Timesteps: 1,362,692,692
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92505
Policy Entropy: 4.35403
Value Function Loss: 0.00205
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.85955
Value Function Update Magnitude: 0.63302
Collected Steps per Second: 13,280.78401
Overall Steps per Second: 7,379.45303
Timestep Collection Time: 3.76665
Timestep Consumption Time: 3.01218
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.77882
Cumulative Model Updates: 179,351
Cumulative Timesteps: 1,362,742,716
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1362742716...
Checkpoint 1362742716 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.60384
Policy Entropy: 4.35426
Value Function Loss: 0.00208
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.86248
Value Function Update Magnitude: 0.61879
Collected Steps per Second: 13,223.69088
Overall Steps per Second: 7,037.31956
Timestep Collection Time: 3.78276
Timestep Consumption Time: 3.32535
PPO Batch Consumption Time: 0.24536
Total Iteration Time: 7.10810
Cumulative Model Updates: 179,360
Cumulative Timesteps: 1,362,792,738
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.36480
Policy Entropy: 4.35527
Value Function Loss: 0.00219
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02242
Policy Update Magnitude: 0.85201
Value Function Update Magnitude: 0.69300
Collected Steps per Second: 13,143.00559
Overall Steps per Second: 7,249.77343
Timestep Collection Time: 3.80461
Timestep Consumption Time: 3.09271
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.89732
Cumulative Model Updates: 179,369
Cumulative Timesteps: 1,362,842,742
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1362842742...
Checkpoint 1362842742 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08249
Policy Entropy: 4.35673
Value Function Loss: 0.00215
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.85562
Value Function Update Magnitude: 0.73346
Collected Steps per Second: 13,484.65453
Overall Steps per Second: 7,341.40531
Timestep Collection Time: 3.70881
Timestep Consumption Time: 3.10351
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.81232
Cumulative Model Updates: 179,378
Cumulative Timesteps: 1,362,892,754
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51154
Policy Entropy: 4.35537
Value Function Loss: 0.00215
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.85070
Value Function Update Magnitude: 0.71924
Collected Steps per Second: 13,376.35332
Overall Steps per Second: 7,289.79845
Timestep Collection Time: 3.73929
Timestep Consumption Time: 3.12208
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.86137
Cumulative Model Updates: 179,387
Cumulative Timesteps: 1,362,942,772
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1362942772...
Checkpoint 1362942772 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.40714
Policy Entropy: 4.35305
Value Function Loss: 0.00219
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02208
Policy Update Magnitude: 0.87007
Value Function Update Magnitude: 0.72019
Collected Steps per Second: 13,303.01869
Overall Steps per Second: 7,365.74484
Timestep Collection Time: 3.75990
Timestep Consumption Time: 3.03073
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.79062
Cumulative Model Updates: 179,396
Cumulative Timesteps: 1,362,992,790
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.45988
Policy Entropy: 4.35235
Value Function Loss: 0.00234
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.88912
Value Function Update Magnitude: 0.68660
Collected Steps per Second: 13,174.71071
Overall Steps per Second: 7,233.74056
Timestep Collection Time: 3.79652
Timestep Consumption Time: 3.11803
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.91454
Cumulative Model Updates: 179,405
Cumulative Timesteps: 1,363,042,808
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1363042808...
Checkpoint 1363042808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.70028
Policy Entropy: 4.35517
Value Function Loss: 0.00233
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.87230
Value Function Update Magnitude: 0.66198
Collected Steps per Second: 13,140.34828
Overall Steps per Second: 7,284.61365
Timestep Collection Time: 3.80599
Timestep Consumption Time: 3.05944
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.86543
Cumulative Model Updates: 179,414
Cumulative Timesteps: 1,363,092,820
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.13891
Policy Entropy: 4.35872
Value Function Loss: 0.00227
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02160
Policy Update Magnitude: 0.85451
Value Function Update Magnitude: 0.70089
Collected Steps per Second: 13,161.43935
Overall Steps per Second: 7,160.08453
Timestep Collection Time: 3.80080
Timestep Consumption Time: 3.18571
PPO Batch Consumption Time: 0.24427
Total Iteration Time: 6.98651
Cumulative Model Updates: 179,423
Cumulative Timesteps: 1,363,142,844
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1363142844...
Checkpoint 1363142844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45511
Policy Entropy: 4.35849
Value Function Loss: 0.00212
Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02104
Policy Update Magnitude: 0.85714
Value Function Update Magnitude: 0.68910
Collected Steps per Second: 13,302.91613
Overall Steps per Second: 7,262.20916
Timestep Collection Time: 3.75857
Timestep Consumption Time: 3.12638
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.88496
Cumulative Model Updates: 179,432
Cumulative Timesteps: 1,363,192,844
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96778
Policy Entropy: 4.35834
Value Function Loss: 0.00219
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.87017
Value Function Update Magnitude: 0.68729
Collected Steps per Second: 13,172.51461
Overall Steps per Second: 7,290.80795
Timestep Collection Time: 3.79836
Timestep Consumption Time: 3.06425
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.86261
Cumulative Model Updates: 179,441
Cumulative Timesteps: 1,363,242,878
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1363242878...
Checkpoint 1363242878 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10079
Policy Entropy: 4.35892
Value Function Loss: 0.00212
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02174
Policy Update Magnitude: 0.85989
Value Function Update Magnitude: 0.68165
Collected Steps per Second: 13,297.20432
Overall Steps per Second: 7,293.94602
Timestep Collection Time: 3.76034
Timestep Consumption Time: 3.09493
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.85527
Cumulative Model Updates: 179,450
Cumulative Timesteps: 1,363,292,880
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16482
Policy Entropy: 4.35950
Value Function Loss: 0.00202
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02168
Policy Update Magnitude: 0.83904
Value Function Update Magnitude: 0.68085
Collected Steps per Second: 13,165.99415
Overall Steps per Second: 7,235.88332
Timestep Collection Time: 3.79933
Timestep Consumption Time: 3.11371
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.91305
Cumulative Model Updates: 179,459
Cumulative Timesteps: 1,363,342,902
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1363342902...
Checkpoint 1363342902 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.98992
Policy Entropy: 4.35973
Value Function Loss: 0.00207
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02099
Policy Update Magnitude: 0.85173
Value Function Update Magnitude: 0.66042
Collected Steps per Second: 13,015.75041
Overall Steps per Second: 7,222.45671
Timestep Collection Time: 3.84304
Timestep Consumption Time: 3.08259
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.92562
Cumulative Model Updates: 179,468
Cumulative Timesteps: 1,363,392,922
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16320
Policy Entropy: 4.35925
Value Function Loss: 0.00206
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02381
Policy Update Magnitude: 0.83653
Value Function Update Magnitude: 0.68027
Collected Steps per Second: 13,379.84542
Overall Steps per Second: 7,305.28827
Timestep Collection Time: 3.73801
Timestep Consumption Time: 3.10826
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.84627
Cumulative Model Updates: 179,477
Cumulative Timesteps: 1,363,442,936
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1363442936...
Checkpoint 1363442936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.13955
Policy Entropy: 4.35931
Value Function Loss: 0.00223
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.86139
Value Function Update Magnitude: 0.68373
Collected Steps per Second: 13,295.34633
Overall Steps per Second: 7,057.18143
Timestep Collection Time: 3.76402
Timestep Consumption Time: 3.32719
PPO Batch Consumption Time: 0.24451
Total Iteration Time: 7.09122
Cumulative Model Updates: 179,486
Cumulative Timesteps: 1,363,492,980
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.84407
Policy Entropy: 4.35757
Value Function Loss: 0.00217
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02270
Policy Update Magnitude: 0.88344
Value Function Update Magnitude: 0.68616
Collected Steps per Second: 13,082.32102
Overall Steps per Second: 7,308.12566
Timestep Collection Time: 3.82455
Timestep Consumption Time: 3.02180
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.84635
Cumulative Model Updates: 179,495
Cumulative Timesteps: 1,363,543,014
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1363543014...
Checkpoint 1363543014 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.27766
Policy Entropy: 4.35575
Value Function Loss: 0.00222
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.89534
Value Function Update Magnitude: 0.64917
Collected Steps per Second: 13,419.86279
Overall Steps per Second: 7,303.46700
Timestep Collection Time: 3.72806
Timestep Consumption Time: 3.12212
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.85017
Cumulative Model Updates: 179,504
Cumulative Timesteps: 1,363,593,044
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.13419
Policy Entropy: 4.35595
Value Function Loss: 0.00240
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.89956
Value Function Update Magnitude: 0.65214
Collected Steps per Second: 13,173.60591
Overall Steps per Second: 7,281.21520
Timestep Collection Time: 3.79850
Timestep Consumption Time: 3.07397
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.87248
Cumulative Model Updates: 179,513
Cumulative Timesteps: 1,363,643,084
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1363643084...
Checkpoint 1363643084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50494
Policy Entropy: 4.35411
Value Function Loss: 0.00244
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.91919
Value Function Update Magnitude: 0.67764
Collected Steps per Second: 13,419.39329
Overall Steps per Second: 7,352.88608
Timestep Collection Time: 3.72923
Timestep Consumption Time: 3.07681
PPO Batch Consumption Time: 0.22762
Total Iteration Time: 6.80603
Cumulative Model Updates: 179,522
Cumulative Timesteps: 1,363,693,128
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72514
Policy Entropy: 4.35147
Value Function Loss: 0.00253
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.92849
Value Function Update Magnitude: 0.69635
Collected Steps per Second: 13,183.97782
Overall Steps per Second: 7,236.24600
Timestep Collection Time: 3.79430
Timestep Consumption Time: 3.11867
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.91298
Cumulative Model Updates: 179,531
Cumulative Timesteps: 1,363,743,152
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1363743152...
Checkpoint 1363743152 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.80481
Policy Entropy: 4.35267
Value Function Loss: 0.00228
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.90947
Value Function Update Magnitude: 0.65672
Collected Steps per Second: 13,138.98448
Overall Steps per Second: 7,267.38085
Timestep Collection Time: 3.80836
Timestep Consumption Time: 3.07693
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.88529
Cumulative Model Updates: 179,540
Cumulative Timesteps: 1,363,793,190
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51571
Policy Entropy: 4.35337
Value Function Loss: 0.00222
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.86591
Value Function Update Magnitude: 0.62630
Collected Steps per Second: 13,422.38576
Overall Steps per Second: 7,161.59365
Timestep Collection Time: 3.72587
Timestep Consumption Time: 3.25722
PPO Batch Consumption Time: 0.24017
Total Iteration Time: 6.98308
Cumulative Model Updates: 179,549
Cumulative Timesteps: 1,363,843,200
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1363843200...
Checkpoint 1363843200 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72735
Policy Entropy: 4.35731
Value Function Loss: 0.00207
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02388
Policy Update Magnitude: 0.84480
Value Function Update Magnitude: 0.61187
Collected Steps per Second: 13,159.49964
Overall Steps per Second: 7,256.98658
Timestep Collection Time: 3.80166
Timestep Consumption Time: 3.09211
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.89377
Cumulative Model Updates: 179,558
Cumulative Timesteps: 1,363,893,228
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.00778
Policy Entropy: 4.35414
Value Function Loss: 0.00244
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.88562
Value Function Update Magnitude: 0.63789
Collected Steps per Second: 13,024.69418
Overall Steps per Second: 7,292.60411
Timestep Collection Time: 3.84132
Timestep Consumption Time: 3.01933
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.86065
Cumulative Model Updates: 179,567
Cumulative Timesteps: 1,363,943,260
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1363943260...
Checkpoint 1363943260 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.08239
Policy Entropy: 4.35183
Value Function Loss: 0.00243
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02412
Policy Update Magnitude: 0.90265
Value Function Update Magnitude: 0.68018
Collected Steps per Second: 13,159.24617
Overall Steps per Second: 7,231.91765
Timestep Collection Time: 3.80007
Timestep Consumption Time: 3.11456
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.91463
Cumulative Model Updates: 179,576
Cumulative Timesteps: 1,363,993,266
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25473
Policy Entropy: 4.34927
Value Function Loss: 0.00243
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.89154
Value Function Update Magnitude: 0.68962
Collected Steps per Second: 13,142.33456
Overall Steps per Second: 7,278.50702
Timestep Collection Time: 3.80678
Timestep Consumption Time: 3.06688
PPO Batch Consumption Time: 0.22794
Total Iteration Time: 6.87366
Cumulative Model Updates: 179,585
Cumulative Timesteps: 1,364,043,296
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1364043296...
Checkpoint 1364043296 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88628
Policy Entropy: 4.35455
Value Function Loss: 0.00220
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.87676
Value Function Update Magnitude: 0.65558
Collected Steps per Second: 13,432.86716
Overall Steps per Second: 7,332.82503
Timestep Collection Time: 3.72400
Timestep Consumption Time: 3.09793
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.82193
Cumulative Model Updates: 179,594
Cumulative Timesteps: 1,364,093,320
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46014
Policy Entropy: 4.35356
Value Function Loss: 0.00214
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02272
Policy Update Magnitude: 0.85307
Value Function Update Magnitude: 0.64151
Collected Steps per Second: 13,157.40878
Overall Steps per Second: 7,238.74143
Timestep Collection Time: 3.80151
Timestep Consumption Time: 3.10826
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.90976
Cumulative Model Updates: 179,603
Cumulative Timesteps: 1,364,143,338
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1364143338...
Checkpoint 1364143338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76338
Policy Entropy: 4.35640
Value Function Loss: 0.00212
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02262
Policy Update Magnitude: 0.85788
Value Function Update Magnitude: 0.65279
Collected Steps per Second: 13,183.65635
Overall Steps per Second: 7,057.66089
Timestep Collection Time: 3.79333
Timestep Consumption Time: 3.29258
PPO Batch Consumption Time: 0.24545
Total Iteration Time: 7.08592
Cumulative Model Updates: 179,612
Cumulative Timesteps: 1,364,193,348
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43153
Policy Entropy: 4.35797
Value Function Loss: 0.00213
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02272
Policy Update Magnitude: 0.88025
Value Function Update Magnitude: 0.63934
Collected Steps per Second: 13,671.59782
Overall Steps per Second: 7,386.45503
Timestep Collection Time: 3.65985
Timestep Consumption Time: 3.11417
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.77402
Cumulative Model Updates: 179,621
Cumulative Timesteps: 1,364,243,384
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1364243384...
Checkpoint 1364243384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74714
Policy Entropy: 4.35539
Value Function Loss: 0.00234
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02265
Policy Update Magnitude: 0.91206
Value Function Update Magnitude: 0.67911
Collected Steps per Second: 13,212.46769
Overall Steps per Second: 7,252.55059
Timestep Collection Time: 3.78446
Timestep Consumption Time: 3.10995
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.89440
Cumulative Model Updates: 179,630
Cumulative Timesteps: 1,364,293,386
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17542
Policy Entropy: 4.35408
Value Function Loss: 0.00230
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02275
Policy Update Magnitude: 0.90481
Value Function Update Magnitude: 0.68610
Collected Steps per Second: 13,140.32772
Overall Steps per Second: 7,351.16416
Timestep Collection Time: 3.80812
Timestep Consumption Time: 2.99896
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.80709
Cumulative Model Updates: 179,639
Cumulative Timesteps: 1,364,343,426
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1364343426...
Checkpoint 1364343426 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.95936
Policy Entropy: 4.35054
Value Function Loss: 0.00239
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.90846
Value Function Update Magnitude: 0.67916
Collected Steps per Second: 13,117.48900
Overall Steps per Second: 7,227.65624
Timestep Collection Time: 3.81277
Timestep Consumption Time: 3.10704
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.91981
Cumulative Model Updates: 179,648
Cumulative Timesteps: 1,364,393,440
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.52043
Policy Entropy: 4.35028
Value Function Loss: 0.00250
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.91813
Value Function Update Magnitude: 0.69626
Collected Steps per Second: 13,363.11786
Overall Steps per Second: 7,331.10715
Timestep Collection Time: 3.74239
Timestep Consumption Time: 3.07923
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.82162
Cumulative Model Updates: 179,657
Cumulative Timesteps: 1,364,443,450
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1364443450...
Checkpoint 1364443450 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.13650
Policy Entropy: 4.35047
Value Function Loss: 0.00240
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.93502
Value Function Update Magnitude: 0.70931
Collected Steps per Second: 13,275.65790
Overall Steps per Second: 7,365.65293
Timestep Collection Time: 3.76750
Timestep Consumption Time: 3.02294
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.79044
Cumulative Model Updates: 179,666
Cumulative Timesteps: 1,364,493,466
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86746
Policy Entropy: 4.35097
Value Function Loss: 0.00239
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02445
Policy Update Magnitude: 0.93810
Value Function Update Magnitude: 0.71693
Collected Steps per Second: 13,039.82768
Overall Steps per Second: 7,028.06726
Timestep Collection Time: 3.83763
Timestep Consumption Time: 3.28268
PPO Batch Consumption Time: 0.24206
Total Iteration Time: 7.12031
Cumulative Model Updates: 179,675
Cumulative Timesteps: 1,364,543,508
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1364543508...
Checkpoint 1364543508 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.36598
Policy Entropy: 4.35783
Value Function Loss: 0.00221
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.93804
Value Function Update Magnitude: 0.73269
Collected Steps per Second: 13,044.34797
Overall Steps per Second: 7,232.68287
Timestep Collection Time: 3.83338
Timestep Consumption Time: 3.08023
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.91362
Cumulative Model Updates: 179,684
Cumulative Timesteps: 1,364,593,512
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50597
Policy Entropy: 4.35327
Value Function Loss: 0.00231
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.91366
Value Function Update Magnitude: 0.71195
Collected Steps per Second: 13,424.81780
Overall Steps per Second: 7,335.01835
Timestep Collection Time: 3.72668
Timestep Consumption Time: 3.09403
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.82071
Cumulative Model Updates: 179,693
Cumulative Timesteps: 1,364,643,542
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1364643542...
Checkpoint 1364643542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33161
Policy Entropy: 4.35330
Value Function Loss: 0.00235
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.93328
Value Function Update Magnitude: 0.71994
Collected Steps per Second: 13,214.26988
Overall Steps per Second: 7,250.83905
Timestep Collection Time: 3.78697
Timestep Consumption Time: 3.11458
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.90155
Cumulative Model Updates: 179,702
Cumulative Timesteps: 1,364,693,584
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.81821
Policy Entropy: 4.35125
Value Function Loss: 0.00237
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.92802
Value Function Update Magnitude: 0.73502
Collected Steps per Second: 13,114.72419
Overall Steps per Second: 7,263.29326
Timestep Collection Time: 3.81525
Timestep Consumption Time: 3.07363
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.88889
Cumulative Model Updates: 179,711
Cumulative Timesteps: 1,364,743,620
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1364743620...
Checkpoint 1364743620 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.15811
Policy Entropy: 4.35358
Value Function Loss: 0.00235
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.94273
Value Function Update Magnitude: 0.76917
Collected Steps per Second: 13,443.24854
Overall Steps per Second: 7,340.82158
Timestep Collection Time: 3.71993
Timestep Consumption Time: 3.09238
PPO Batch Consumption Time: 0.22784
Total Iteration Time: 6.81232
Cumulative Model Updates: 179,720
Cumulative Timesteps: 1,364,793,628
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84099
Policy Entropy: 4.35282
Value Function Loss: 0.00240
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.96708
Value Function Update Magnitude: 0.74215
Collected Steps per Second: 13,236.16020
Overall Steps per Second: 7,255.40199
Timestep Collection Time: 3.77934
Timestep Consumption Time: 3.11538
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.89472
Cumulative Model Updates: 179,729
Cumulative Timesteps: 1,364,843,652
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1364843652...
Checkpoint 1364843652 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.38212
Policy Entropy: 4.35165
Value Function Loss: 0.00240
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02770
Policy Update Magnitude: 0.95561
Value Function Update Magnitude: 0.73403
Collected Steps per Second: 13,069.30915
Overall Steps per Second: 7,247.39885
Timestep Collection Time: 3.82713
Timestep Consumption Time: 3.07438
PPO Batch Consumption Time: 0.23413
Total Iteration Time: 6.90151
Cumulative Model Updates: 179,738
Cumulative Timesteps: 1,364,893,670
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31410
Policy Entropy: 4.35019
Value Function Loss: 0.00246
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.93999
Value Function Update Magnitude: 0.75173
Collected Steps per Second: 13,244.77120
Overall Steps per Second: 7,251.92980
Timestep Collection Time: 3.77764
Timestep Consumption Time: 3.12176
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.89940
Cumulative Model Updates: 179,747
Cumulative Timesteps: 1,364,943,704
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1364943704...
Checkpoint 1364943704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69896
Policy Entropy: 4.35051
Value Function Loss: 0.00238
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.93899
Value Function Update Magnitude: 0.73802
Collected Steps per Second: 13,251.36136
Overall Steps per Second: 7,304.80621
Timestep Collection Time: 3.77410
Timestep Consumption Time: 3.07235
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.84645
Cumulative Model Updates: 179,756
Cumulative Timesteps: 1,364,993,716
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.83053
Policy Entropy: 4.35129
Value Function Loss: 0.00234
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.93912
Value Function Update Magnitude: 0.69830
Collected Steps per Second: 13,237.67635
Overall Steps per Second: 7,359.84635
Timestep Collection Time: 3.78118
Timestep Consumption Time: 3.01978
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.80096
Cumulative Model Updates: 179,765
Cumulative Timesteps: 1,365,043,770
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1365043770...
Checkpoint 1365043770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20047
Policy Entropy: 4.35603
Value Function Loss: 0.00233
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.93511
Value Function Update Magnitude: 0.71205
Collected Steps per Second: 13,273.01746
Overall Steps per Second: 7,300.50186
Timestep Collection Time: 3.76810
Timestep Consumption Time: 3.08267
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.85076
Cumulative Model Updates: 179,774
Cumulative Timesteps: 1,365,093,784
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.52335
Policy Entropy: 4.35268
Value Function Loss: 0.00228
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.90975
Value Function Update Magnitude: 0.70656
Collected Steps per Second: 13,202.81348
Overall Steps per Second: 7,290.47912
Timestep Collection Time: 3.78798
Timestep Consumption Time: 3.07193
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.85991
Cumulative Model Updates: 179,783
Cumulative Timesteps: 1,365,143,796
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1365143796...
Checkpoint 1365143796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.07061
Policy Entropy: 4.35176
Value Function Loss: 0.00229
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.90966
Value Function Update Magnitude: 0.68034
Collected Steps per Second: 13,327.06211
Overall Steps per Second: 7,290.81969
Timestep Collection Time: 3.75387
Timestep Consumption Time: 3.10791
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.86178
Cumulative Model Updates: 179,792
Cumulative Timesteps: 1,365,193,824
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56930
Policy Entropy: 4.35221
Value Function Loss: 0.00231
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.90272
Value Function Update Magnitude: 0.69680
Collected Steps per Second: 13,255.02655
Overall Steps per Second: 7,096.94715
Timestep Collection Time: 3.77427
Timestep Consumption Time: 3.27496
PPO Batch Consumption Time: 0.24329
Total Iteration Time: 7.04923
Cumulative Model Updates: 179,801
Cumulative Timesteps: 1,365,243,852
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1365243852...
Checkpoint 1365243852 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53160
Policy Entropy: 4.35128
Value Function Loss: 0.00236
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.91883
Value Function Update Magnitude: 0.78144
Collected Steps per Second: 13,086.80155
Overall Steps per Second: 7,318.12615
Timestep Collection Time: 3.82095
Timestep Consumption Time: 3.01195
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.83290
Cumulative Model Updates: 179,810
Cumulative Timesteps: 1,365,293,856
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46577
Policy Entropy: 4.35547
Value Function Loss: 0.00240
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.92463
Value Function Update Magnitude: 0.76321
Collected Steps per Second: 13,113.07278
Overall Steps per Second: 7,249.05283
Timestep Collection Time: 3.81589
Timestep Consumption Time: 3.08681
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.90269
Cumulative Model Updates: 179,819
Cumulative Timesteps: 1,365,343,894
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1365343894...
Checkpoint 1365343894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.40675
Policy Entropy: 4.34747
Value Function Loss: 0.00251
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02618
Policy Update Magnitude: 0.91621
Value Function Update Magnitude: 0.72014
Collected Steps per Second: 13,118.29003
Overall Steps per Second: 7,273.24304
Timestep Collection Time: 3.81284
Timestep Consumption Time: 3.06414
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.87699
Cumulative Model Updates: 179,828
Cumulative Timesteps: 1,365,393,912
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05638
Policy Entropy: 4.34446
Value Function Loss: 0.00251
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.92250
Value Function Update Magnitude: 0.72693
Collected Steps per Second: 13,182.51277
Overall Steps per Second: 7,348.01948
Timestep Collection Time: 3.79488
Timestep Consumption Time: 3.01322
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.80809
Cumulative Model Updates: 179,837
Cumulative Timesteps: 1,365,443,938
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1365443938...
Checkpoint 1365443938 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.03285
Policy Entropy: 4.34474
Value Function Loss: 0.00237
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.89459
Value Function Update Magnitude: 0.72030
Collected Steps per Second: 13,149.46859
Overall Steps per Second: 7,227.28541
Timestep Collection Time: 3.80426
Timestep Consumption Time: 3.11729
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.92155
Cumulative Model Updates: 179,846
Cumulative Timesteps: 1,365,493,962
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.14423
Policy Entropy: 4.34764
Value Function Loss: 0.00239
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02648
Policy Update Magnitude: 0.92623
Value Function Update Magnitude: 0.70014
Collected Steps per Second: 13,193.95818
Overall Steps per Second: 7,274.91594
Timestep Collection Time: 3.79007
Timestep Consumption Time: 3.08369
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.87376
Cumulative Model Updates: 179,855
Cumulative Timesteps: 1,365,543,968
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1365543968...
Checkpoint 1365543968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.03782
Policy Entropy: 4.34878
Value Function Loss: 0.00257
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.93009
Value Function Update Magnitude: 0.71169
Collected Steps per Second: 13,464.88836
Overall Steps per Second: 7,136.75812
Timestep Collection Time: 3.71618
Timestep Consumption Time: 3.29512
PPO Batch Consumption Time: 0.24363
Total Iteration Time: 7.01131
Cumulative Model Updates: 179,864
Cumulative Timesteps: 1,365,594,006
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.42411
Policy Entropy: 4.34374
Value Function Loss: 0.00261
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.93469
Value Function Update Magnitude: 0.73511
Collected Steps per Second: 13,342.00363
Overall Steps per Second: 7,307.32293
Timestep Collection Time: 3.74966
Timestep Consumption Time: 3.09662
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.84628
Cumulative Model Updates: 179,873
Cumulative Timesteps: 1,365,644,034
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1365644034...
Checkpoint 1365644034 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24665
Policy Entropy: 4.34212
Value Function Loss: 0.00263
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02783
Policy Update Magnitude: 0.94848
Value Function Update Magnitude: 0.71458
Collected Steps per Second: 13,178.54723
Overall Steps per Second: 7,265.30593
Timestep Collection Time: 3.79526
Timestep Consumption Time: 3.08897
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.88422
Cumulative Model Updates: 179,882
Cumulative Timesteps: 1,365,694,050
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85742
Policy Entropy: 4.34389
Value Function Loss: 0.00267
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.94300
Value Function Update Magnitude: 0.70337
Collected Steps per Second: 13,465.00758
Overall Steps per Second: 7,346.67115
Timestep Collection Time: 3.71392
Timestep Consumption Time: 3.09297
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.80689
Cumulative Model Updates: 179,891
Cumulative Timesteps: 1,365,744,058
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1365744058...
Checkpoint 1365744058 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.50505
Policy Entropy: 4.34641
Value Function Loss: 0.00259
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02628
Policy Update Magnitude: 0.92476
Value Function Update Magnitude: 0.71224
Collected Steps per Second: 13,175.09943
Overall Steps per Second: 7,233.96150
Timestep Collection Time: 3.79762
Timestep Consumption Time: 3.11892
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.91654
Cumulative Model Updates: 179,900
Cumulative Timesteps: 1,365,794,092
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.14562
Policy Entropy: 4.34536
Value Function Loss: 0.00245
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.89269
Value Function Update Magnitude: 0.70627
Collected Steps per Second: 13,230.15569
Overall Steps per Second: 7,368.91942
Timestep Collection Time: 3.77985
Timestep Consumption Time: 3.00649
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.78634
Cumulative Model Updates: 179,909
Cumulative Timesteps: 1,365,844,100
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1365844100...
Checkpoint 1365844100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54869
Policy Entropy: 4.34905
Value Function Loss: 0.00235
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.89475
Value Function Update Magnitude: 0.71805
Collected Steps per Second: 13,273.33461
Overall Steps per Second: 7,267.15087
Timestep Collection Time: 3.76981
Timestep Consumption Time: 3.11569
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.88550
Cumulative Model Updates: 179,918
Cumulative Timesteps: 1,365,894,138
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.07567
Policy Entropy: 4.34926
Value Function Loss: 0.00232
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.88055
Value Function Update Magnitude: 0.67772
Collected Steps per Second: 13,088.51256
Overall Steps per Second: 7,091.37741
Timestep Collection Time: 3.82305
Timestep Consumption Time: 3.23313
PPO Batch Consumption Time: 0.23828
Total Iteration Time: 7.05618
Cumulative Model Updates: 179,927
Cumulative Timesteps: 1,365,944,176
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1365944176...
Checkpoint 1365944176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54868
Policy Entropy: 4.34853
Value Function Loss: 0.00235
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.88528
Value Function Update Magnitude: 0.65665
Collected Steps per Second: 13,213.63141
Overall Steps per Second: 7,358.68791
Timestep Collection Time: 3.78488
Timestep Consumption Time: 3.01144
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.79632
Cumulative Model Updates: 179,936
Cumulative Timesteps: 1,365,994,188
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.86344
Policy Entropy: 4.34272
Value Function Loss: 0.00255
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.91132
Value Function Update Magnitude: 0.69698
Collected Steps per Second: 13,195.79150
Overall Steps per Second: 7,269.11698
Timestep Collection Time: 3.78969
Timestep Consumption Time: 3.08982
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.87952
Cumulative Model Updates: 179,945
Cumulative Timesteps: 1,366,044,196
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1366044196...
Checkpoint 1366044196 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16146
Policy Entropy: 4.34200
Value Function Loss: 0.00259
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.92559
Value Function Update Magnitude: 0.74360
Collected Steps per Second: 13,071.59756
Overall Steps per Second: 7,340.29854
Timestep Collection Time: 3.82677
Timestep Consumption Time: 2.98794
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.81471
Cumulative Model Updates: 179,954
Cumulative Timesteps: 1,366,094,218
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.37456
Policy Entropy: 4.34295
Value Function Loss: 0.00245
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02513
Policy Update Magnitude: 0.92882
Value Function Update Magnitude: 0.76349
Collected Steps per Second: 13,384.49892
Overall Steps per Second: 7,300.35954
Timestep Collection Time: 3.73910
Timestep Consumption Time: 3.11618
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.85528
Cumulative Model Updates: 179,963
Cumulative Timesteps: 1,366,144,264
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1366144264...
Checkpoint 1366144264 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.25777
Policy Entropy: 4.34651
Value Function Loss: 0.00235
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.93208
Value Function Update Magnitude: 0.73183
Collected Steps per Second: 13,128.15830
Overall Steps per Second: 7,269.96102
Timestep Collection Time: 3.80952
Timestep Consumption Time: 3.06975
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.87927
Cumulative Model Updates: 179,972
Cumulative Timesteps: 1,366,194,276
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05357
Policy Entropy: 4.34595
Value Function Loss: 0.00233
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.92368
Value Function Update Magnitude: 0.71726
Collected Steps per Second: 12,853.15480
Overall Steps per Second: 7,219.67062
Timestep Collection Time: 3.89305
Timestep Consumption Time: 3.03774
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.93079
Cumulative Model Updates: 179,981
Cumulative Timesteps: 1,366,244,314
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1366244314...
Checkpoint 1366244314 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.50609
Policy Entropy: 4.34621
Value Function Loss: 0.00237
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.92125
Value Function Update Magnitude: 0.77463
Collected Steps per Second: 13,245.87577
Overall Steps per Second: 7,098.33092
Timestep Collection Time: 3.77551
Timestep Consumption Time: 3.26980
PPO Batch Consumption Time: 0.23971
Total Iteration Time: 7.04532
Cumulative Model Updates: 179,990
Cumulative Timesteps: 1,366,294,324
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.03567
Policy Entropy: 4.34072
Value Function Loss: 0.00257
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02756
Policy Update Magnitude: 0.94219
Value Function Update Magnitude: 0.73929
Collected Steps per Second: 13,142.87702
Overall Steps per Second: 7,266.98652
Timestep Collection Time: 3.80708
Timestep Consumption Time: 3.07830
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.88539
Cumulative Model Updates: 179,999
Cumulative Timesteps: 1,366,344,360
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1366344360...
Checkpoint 1366344360 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.98498
Policy Entropy: 4.33807
Value Function Loss: 0.00260
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.93336
Value Function Update Magnitude: 0.71703
Collected Steps per Second: 13,491.55761
Overall Steps per Second: 7,334.28298
Timestep Collection Time: 3.70780
Timestep Consumption Time: 3.11277
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.82057
Cumulative Model Updates: 180,008
Cumulative Timesteps: 1,366,394,384
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.04085
Policy Entropy: 4.34248
Value Function Loss: 0.00250
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.91730
Value Function Update Magnitude: 0.70601
Collected Steps per Second: 13,221.26256
Overall Steps per Second: 7,258.95950
Timestep Collection Time: 3.78436
Timestep Consumption Time: 3.10836
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.89272
Cumulative Model Updates: 180,017
Cumulative Timesteps: 1,366,444,418
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1366444418...
Checkpoint 1366444418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10517
Policy Entropy: 4.34404
Value Function Loss: 0.00254
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02432
Policy Update Magnitude: 0.91912
Value Function Update Magnitude: 0.70504
Collected Steps per Second: 13,189.94020
Overall Steps per Second: 7,358.08911
Timestep Collection Time: 3.79198
Timestep Consumption Time: 3.00544
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.79742
Cumulative Model Updates: 180,026
Cumulative Timesteps: 1,366,494,434
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.78714
Policy Entropy: 4.35143
Value Function Loss: 0.00250
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.92245
Value Function Update Magnitude: 0.71578
Collected Steps per Second: 13,198.42513
Overall Steps per Second: 7,244.80601
Timestep Collection Time: 3.79076
Timestep Consumption Time: 3.11516
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.90591
Cumulative Model Updates: 180,035
Cumulative Timesteps: 1,366,544,466
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1366544466...
Checkpoint 1366544466 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69888
Policy Entropy: 4.34727
Value Function Loss: 0.00259
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.91114
Value Function Update Magnitude: 0.68905
Collected Steps per Second: 13,143.17853
Overall Steps per Second: 7,263.85079
Timestep Collection Time: 3.80425
Timestep Consumption Time: 3.07915
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.88340
Cumulative Model Updates: 180,044
Cumulative Timesteps: 1,366,594,466
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26450
Policy Entropy: 4.34903
Value Function Loss: 0.00245
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.89797
Value Function Update Magnitude: 0.73166
Collected Steps per Second: 13,147.94461
Overall Steps per Second: 7,218.30706
Timestep Collection Time: 3.80318
Timestep Consumption Time: 3.12421
PPO Batch Consumption Time: 0.23843
Total Iteration Time: 6.92739
Cumulative Model Updates: 180,053
Cumulative Timesteps: 1,366,644,470
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1366644470...
Checkpoint 1366644470 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12010
Policy Entropy: 4.34722
Value Function Loss: 0.00244
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02503
Policy Update Magnitude: 0.89213
Value Function Update Magnitude: 0.74458
Collected Steps per Second: 13,206.90921
Overall Steps per Second: 7,252.85357
Timestep Collection Time: 3.78862
Timestep Consumption Time: 3.11018
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.89880
Cumulative Model Updates: 180,062
Cumulative Timesteps: 1,366,694,506
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.67766
Policy Entropy: 4.34819
Value Function Loss: 0.00240
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.89259
Value Function Update Magnitude: 0.72931
Collected Steps per Second: 13,215.62385
Overall Steps per Second: 7,283.00948
Timestep Collection Time: 3.78567
Timestep Consumption Time: 3.08374
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.86941
Cumulative Model Updates: 180,071
Cumulative Timesteps: 1,366,744,536
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1366744536...
Checkpoint 1366744536 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.78558
Policy Entropy: 4.34883
Value Function Loss: 0.00249
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.91325
Value Function Update Magnitude: 0.72366
Collected Steps per Second: 13,550.90886
Overall Steps per Second: 7,360.73014
Timestep Collection Time: 3.68994
Timestep Consumption Time: 3.10314
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.79308
Cumulative Model Updates: 180,080
Cumulative Timesteps: 1,366,794,538
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20650
Policy Entropy: 4.34829
Value Function Loss: 0.00246
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.90517
Value Function Update Magnitude: 0.75886
Collected Steps per Second: 13,116.72723
Overall Steps per Second: 7,225.05958
Timestep Collection Time: 3.81452
Timestep Consumption Time: 3.11055
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.92506
Cumulative Model Updates: 180,089
Cumulative Timesteps: 1,366,844,572
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1366844572...
Checkpoint 1366844572 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89179
Policy Entropy: 4.34913
Value Function Loss: 0.00248
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.89290
Value Function Update Magnitude: 0.75941
Collected Steps per Second: 13,302.77067
Overall Steps per Second: 7,325.92073
Timestep Collection Time: 3.75997
Timestep Consumption Time: 3.06757
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.82754
Cumulative Model Updates: 180,098
Cumulative Timesteps: 1,366,894,590
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.54155
Policy Entropy: 4.35092
Value Function Loss: 0.00238
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.88451
Value Function Update Magnitude: 0.76808
Collected Steps per Second: 13,437.67612
Overall Steps per Second: 7,327.87728
Timestep Collection Time: 3.72103
Timestep Consumption Time: 3.10250
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.82353
Cumulative Model Updates: 180,107
Cumulative Timesteps: 1,366,944,592
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1366944592...
Checkpoint 1366944592 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02247
Policy Entropy: 4.34751
Value Function Loss: 0.00230
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.87911
Value Function Update Magnitude: 0.75055
Collected Steps per Second: 13,199.69134
Overall Steps per Second: 7,054.04058
Timestep Collection Time: 3.78827
Timestep Consumption Time: 3.30043
PPO Batch Consumption Time: 0.24155
Total Iteration Time: 7.08870
Cumulative Model Updates: 180,116
Cumulative Timesteps: 1,366,994,596
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.19820
Policy Entropy: 4.34817
Value Function Loss: 0.00238
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02304
Policy Update Magnitude: 0.89157
Value Function Update Magnitude: 0.72259
Collected Steps per Second: 13,310.67395
Overall Steps per Second: 7,362.05688
Timestep Collection Time: 3.75774
Timestep Consumption Time: 3.03629
PPO Batch Consumption Time: 0.22959
Total Iteration Time: 6.79403
Cumulative Model Updates: 180,125
Cumulative Timesteps: 1,367,044,614
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1367044614...
Checkpoint 1367044614 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.29014
Policy Entropy: 4.34816
Value Function Loss: 0.00240
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02446
Policy Update Magnitude: 0.90537
Value Function Update Magnitude: 0.76623
Collected Steps per Second: 13,277.10652
Overall Steps per Second: 7,288.53292
Timestep Collection Time: 3.76904
Timestep Consumption Time: 3.09681
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.86585
Cumulative Model Updates: 180,134
Cumulative Timesteps: 1,367,094,656
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.06572
Policy Entropy: 4.34909
Value Function Loss: 0.00246
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.89583
Value Function Update Magnitude: 0.76321
Collected Steps per Second: 13,217.41023
Overall Steps per Second: 7,290.52710
Timestep Collection Time: 3.78561
Timestep Consumption Time: 3.07754
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.86315
Cumulative Model Updates: 180,143
Cumulative Timesteps: 1,367,144,692
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1367144692...
Checkpoint 1367144692 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85068
Policy Entropy: 4.35364
Value Function Loss: 0.00248
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.89227
Value Function Update Magnitude: 0.73131
Collected Steps per Second: 13,111.88101
Overall Steps per Second: 7,323.94045
Timestep Collection Time: 3.81379
Timestep Consumption Time: 3.01395
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.82775
Cumulative Model Updates: 180,152
Cumulative Timesteps: 1,367,194,698
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.42053
Policy Entropy: 4.35157
Value Function Loss: 0.00243
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.88903
Value Function Update Magnitude: 0.76746
Collected Steps per Second: 13,239.96189
Overall Steps per Second: 7,258.30146
Timestep Collection Time: 3.77901
Timestep Consumption Time: 3.11433
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.89335
Cumulative Model Updates: 180,161
Cumulative Timesteps: 1,367,244,732
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1367244732...
Checkpoint 1367244732 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.04779
Policy Entropy: 4.34935
Value Function Loss: 0.00250
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.90295
Value Function Update Magnitude: 0.75771
Collected Steps per Second: 13,058.72301
Overall Steps per Second: 7,240.83780
Timestep Collection Time: 3.83054
Timestep Consumption Time: 3.07777
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.90832
Cumulative Model Updates: 180,170
Cumulative Timesteps: 1,367,294,754
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35534
Policy Entropy: 4.34222
Value Function Loss: 0.00258
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.94461
Value Function Update Magnitude: 0.82393
Collected Steps per Second: 13,470.55286
Overall Steps per Second: 7,169.78033
Timestep Collection Time: 3.71254
Timestep Consumption Time: 3.26257
PPO Batch Consumption Time: 0.24061
Total Iteration Time: 6.97511
Cumulative Model Updates: 180,179
Cumulative Timesteps: 1,367,344,764
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1367344764...
Checkpoint 1367344764 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61000
Policy Entropy: 4.33964
Value Function Loss: 0.00262
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02916
Policy Update Magnitude: 0.93433
Value Function Update Magnitude: 0.80860
Collected Steps per Second: 13,157.23511
Overall Steps per Second: 7,238.23026
Timestep Collection Time: 3.80201
Timestep Consumption Time: 3.10907
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.91108
Cumulative Model Updates: 180,188
Cumulative Timesteps: 1,367,394,788
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33488
Policy Entropy: 4.34353
Value Function Loss: 0.00248
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.91127
Value Function Update Magnitude: 0.78406
Collected Steps per Second: 13,277.99984
Overall Steps per Second: 7,353.78881
Timestep Collection Time: 3.76804
Timestep Consumption Time: 3.03553
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.80357
Cumulative Model Updates: 180,197
Cumulative Timesteps: 1,367,444,820
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1367444820...
Checkpoint 1367444820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.15920
Policy Entropy: 4.34866
Value Function Loss: 0.00247
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.90894
Value Function Update Magnitude: 0.75091
Collected Steps per Second: 13,251.81686
Overall Steps per Second: 7,274.31751
Timestep Collection Time: 3.77548
Timestep Consumption Time: 3.10241
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.87790
Cumulative Model Updates: 180,206
Cumulative Timesteps: 1,367,494,852
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26801
Policy Entropy: 4.35198
Value Function Loss: 0.00236
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02434
Policy Update Magnitude: 0.91175
Value Function Update Magnitude: 0.73487
Collected Steps per Second: 13,268.75104
Overall Steps per Second: 7,278.31378
Timestep Collection Time: 3.77036
Timestep Consumption Time: 3.10321
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.87357
Cumulative Model Updates: 180,215
Cumulative Timesteps: 1,367,544,880
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1367544880...
Checkpoint 1367544880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.51172
Policy Entropy: 4.34643
Value Function Loss: 0.00243
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.91269
Value Function Update Magnitude: 0.75250
Collected Steps per Second: 13,147.20104
Overall Steps per Second: 7,344.44110
Timestep Collection Time: 3.80340
Timestep Consumption Time: 3.00502
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.80841
Cumulative Model Updates: 180,224
Cumulative Timesteps: 1,367,594,884
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85545
Policy Entropy: 4.34452
Value Function Loss: 0.00232
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.89751
Value Function Update Magnitude: 0.73401
Collected Steps per Second: 13,295.78857
Overall Steps per Second: 7,276.32745
Timestep Collection Time: 3.76390
Timestep Consumption Time: 3.11375
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.87765
Cumulative Model Updates: 180,233
Cumulative Timesteps: 1,367,644,928
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1367644928...
Checkpoint 1367644928 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31543
Policy Entropy: 4.34299
Value Function Loss: 0.00239
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02313
Policy Update Magnitude: 0.90306
Value Function Update Magnitude: 0.73159
Collected Steps per Second: 13,177.71942
Overall Steps per Second: 7,137.39171
Timestep Collection Time: 3.79717
Timestep Consumption Time: 3.21352
PPO Batch Consumption Time: 0.24040
Total Iteration Time: 7.01068
Cumulative Model Updates: 180,242
Cumulative Timesteps: 1,367,694,966
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.34543
Policy Entropy: 4.34203
Value Function Loss: 0.00244
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.91323
Value Function Update Magnitude: 0.70649
Collected Steps per Second: 13,129.66127
Overall Steps per Second: 7,358.19379
Timestep Collection Time: 3.80954
Timestep Consumption Time: 2.98805
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.79759
Cumulative Model Updates: 180,251
Cumulative Timesteps: 1,367,744,984
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1367744984...
Checkpoint 1367744984 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28768
Policy Entropy: 4.34377
Value Function Loss: 0.00235
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.89583
Value Function Update Magnitude: 0.74285
Collected Steps per Second: 13,096.56442
Overall Steps per Second: 7,222.70281
Timestep Collection Time: 3.81856
Timestep Consumption Time: 3.10544
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.92400
Cumulative Model Updates: 180,260
Cumulative Timesteps: 1,367,794,994
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.59833
Policy Entropy: 4.34239
Value Function Loss: 0.00255
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02871
Policy Update Magnitude: 0.93214
Value Function Update Magnitude: 0.74550
Collected Steps per Second: 13,158.31580
Overall Steps per Second: 7,295.85422
Timestep Collection Time: 3.80307
Timestep Consumption Time: 3.05589
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.85896
Cumulative Model Updates: 180,269
Cumulative Timesteps: 1,367,845,036
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1367845036...
Checkpoint 1367845036 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.00842
Policy Entropy: 4.34035
Value Function Loss: 0.00268
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02970
Policy Update Magnitude: 0.96057
Value Function Update Magnitude: 0.75157
Collected Steps per Second: 13,483.12245
Overall Steps per Second: 7,353.60179
Timestep Collection Time: 3.71086
Timestep Consumption Time: 3.09315
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.80401
Cumulative Model Updates: 180,278
Cumulative Timesteps: 1,367,895,070
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81133
Policy Entropy: 4.33646
Value Function Loss: 0.00277
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03083
Policy Update Magnitude: 0.95736
Value Function Update Magnitude: 0.73991
Collected Steps per Second: 13,164.84404
Overall Steps per Second: 7,259.00232
Timestep Collection Time: 3.79799
Timestep Consumption Time: 3.09000
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.88800
Cumulative Model Updates: 180,287
Cumulative Timesteps: 1,367,945,070
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1367945070...
Checkpoint 1367945070 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97914
Policy Entropy: 4.33871
Value Function Loss: 0.00261
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.94586
Value Function Update Magnitude: 0.71301
Collected Steps per Second: 13,186.39068
Overall Steps per Second: 7,377.74458
Timestep Collection Time: 3.79315
Timestep Consumption Time: 2.98643
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.77958
Cumulative Model Updates: 180,296
Cumulative Timesteps: 1,367,995,088
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.54665
Policy Entropy: 4.34430
Value Function Loss: 0.00238
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02984
Policy Update Magnitude: 0.90303
Value Function Update Magnitude: 0.74202
Collected Steps per Second: 13,128.19455
Overall Steps per Second: 7,112.31081
Timestep Collection Time: 3.81027
Timestep Consumption Time: 3.22288
PPO Batch Consumption Time: 0.23883
Total Iteration Time: 7.03316
Cumulative Model Updates: 180,305
Cumulative Timesteps: 1,368,045,110
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1368045110...
Checkpoint 1368045110 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.17645
Policy Entropy: 4.34621
Value Function Loss: 0.00228
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.86251
Value Function Update Magnitude: 0.80861
Collected Steps per Second: 12,676.02918
Overall Steps per Second: 7,093.50466
Timestep Collection Time: 3.94729
Timestep Consumption Time: 3.10648
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 7.05378
Cumulative Model Updates: 180,314
Cumulative Timesteps: 1,368,095,146
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32635
Policy Entropy: 4.34492
Value Function Loss: 0.00222
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.85826
Value Function Update Magnitude: 0.79393
Collected Steps per Second: 12,884.46300
Overall Steps per Second: 7,229.78397
Timestep Collection Time: 3.88359
Timestep Consumption Time: 3.03750
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.92109
Cumulative Model Updates: 180,323
Cumulative Timesteps: 1,368,145,184
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1368145184...
Checkpoint 1368145184 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.23054
Policy Entropy: 4.34649
Value Function Loss: 0.00224
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02456
Policy Update Magnitude: 0.86776
Value Function Update Magnitude: 0.75974
Collected Steps per Second: 13,218.78847
Overall Steps per Second: 7,244.34114
Timestep Collection Time: 3.78325
Timestep Consumption Time: 3.12007
PPO Batch Consumption Time: 0.23077
Total Iteration Time: 6.90332
Cumulative Model Updates: 180,332
Cumulative Timesteps: 1,368,195,194
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79508
Policy Entropy: 4.35023
Value Function Loss: 0.00223
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02234
Policy Update Magnitude: 0.85550
Value Function Update Magnitude: 0.77374
Collected Steps per Second: 13,065.54553
Overall Steps per Second: 7,238.58793
Timestep Collection Time: 3.82961
Timestep Consumption Time: 3.08278
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.91240
Cumulative Model Updates: 180,341
Cumulative Timesteps: 1,368,245,230
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1368245230...
Checkpoint 1368245230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00750
Policy Entropy: 4.35061
Value Function Loss: 0.00214
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.83957
Value Function Update Magnitude: 0.70770
Collected Steps per Second: 13,425.61976
Overall Steps per Second: 7,296.30671
Timestep Collection Time: 3.72690
Timestep Consumption Time: 3.13081
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 6.85772
Cumulative Model Updates: 180,350
Cumulative Timesteps: 1,368,295,266
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25470
Policy Entropy: 4.34934
Value Function Loss: 0.00220
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.83489
Value Function Update Magnitude: 0.66759
Collected Steps per Second: 13,139.60936
Overall Steps per Second: 7,267.52762
Timestep Collection Time: 3.80574
Timestep Consumption Time: 3.07500
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.88074
Cumulative Model Updates: 180,359
Cumulative Timesteps: 1,368,345,272
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1368345272...
Checkpoint 1368345272 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10130
Policy Entropy: 4.34549
Value Function Loss: 0.00220
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.84395
Value Function Update Magnitude: 0.68694
Collected Steps per Second: 13,146.24010
Overall Steps per Second: 7,198.77559
Timestep Collection Time: 3.80580
Timestep Consumption Time: 3.14427
PPO Batch Consumption Time: 0.24038
Total Iteration Time: 6.95007
Cumulative Model Updates: 180,368
Cumulative Timesteps: 1,368,395,304
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.23984
Policy Entropy: 4.34777
Value Function Loss: 0.00235
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.87708
Value Function Update Magnitude: 0.73241
Collected Steps per Second: 13,211.86590
Overall Steps per Second: 7,267.84254
Timestep Collection Time: 3.78448
Timestep Consumption Time: 3.09514
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.87962
Cumulative Model Updates: 180,377
Cumulative Timesteps: 1,368,445,304
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1368445304...
Checkpoint 1368445304 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12631
Policy Entropy: 4.35083
Value Function Loss: 0.00232
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.87963
Value Function Update Magnitude: 0.75746
Collected Steps per Second: 13,293.36501
Overall Steps per Second: 7,326.53984
Timestep Collection Time: 3.76308
Timestep Consumption Time: 3.06470
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.82778
Cumulative Model Updates: 180,386
Cumulative Timesteps: 1,368,495,328
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42317
Policy Entropy: 4.34888
Value Function Loss: 0.00243
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.87575
Value Function Update Magnitude: 0.80653
Collected Steps per Second: 13,244.38132
Overall Steps per Second: 7,385.33393
Timestep Collection Time: 3.77564
Timestep Consumption Time: 2.99535
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.77099
Cumulative Model Updates: 180,395
Cumulative Timesteps: 1,368,545,334
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1368545334...
Checkpoint 1368545334 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17883
Policy Entropy: 4.34638
Value Function Loss: 0.00253
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.89618
Value Function Update Magnitude: 0.78749
Collected Steps per Second: 13,117.41662
Overall Steps per Second: 7,202.42316
Timestep Collection Time: 3.81249
Timestep Consumption Time: 3.13101
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.94350
Cumulative Model Updates: 180,404
Cumulative Timesteps: 1,368,595,344
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83931
Policy Entropy: 4.34592
Value Function Loss: 0.00251
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.90378
Value Function Update Magnitude: 0.82598
Collected Steps per Second: 13,285.49246
Overall Steps per Second: 7,309.30129
Timestep Collection Time: 3.76651
Timestep Consumption Time: 3.07956
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.84607
Cumulative Model Updates: 180,413
Cumulative Timesteps: 1,368,645,384
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1368645384...
Checkpoint 1368645384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64522
Policy Entropy: 4.34758
Value Function Loss: 0.00262
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.92135
Value Function Update Magnitude: 0.80410
Collected Steps per Second: 13,516.97448
Overall Steps per Second: 7,352.48061
Timestep Collection Time: 3.70112
Timestep Consumption Time: 3.10311
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.80423
Cumulative Model Updates: 180,422
Cumulative Timesteps: 1,368,695,412
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.89393
Policy Entropy: 4.34404
Value Function Loss: 0.00276
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.96295
Value Function Update Magnitude: 0.82312
Collected Steps per Second: 13,119.13768
Overall Steps per Second: 7,092.40487
Timestep Collection Time: 3.81214
Timestep Consumption Time: 3.23935
PPO Batch Consumption Time: 0.23898
Total Iteration Time: 7.05149
Cumulative Model Updates: 180,431
Cumulative Timesteps: 1,368,745,424
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1368745424...
Checkpoint 1368745424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51901
Policy Entropy: 4.34109
Value Function Loss: 0.00272
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.95989
Value Function Update Magnitude: 0.81605
Collected Steps per Second: 13,273.46019
Overall Steps per Second: 7,368.02777
Timestep Collection Time: 3.76872
Timestep Consumption Time: 3.02061
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.78933
Cumulative Model Updates: 180,440
Cumulative Timesteps: 1,368,795,448
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.44026
Policy Entropy: 4.34091
Value Function Loss: 0.00255
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.92467
Value Function Update Magnitude: 0.81981
Collected Steps per Second: 13,191.56442
Overall Steps per Second: 7,249.49494
Timestep Collection Time: 3.79515
Timestep Consumption Time: 3.11071
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.90586
Cumulative Model Updates: 180,449
Cumulative Timesteps: 1,368,845,512
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
Saving checkpoint 1368845512...
Checkpoint 1368845512 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.23977
Policy Entropy: 4.34407
Value Function Loss: 0.00241
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.92264
Value Function Update Magnitude: 0.78223
Collected Steps per Second: 13,190.98960
Overall Steps per Second: 7,282.35949
Timestep Collection Time: 3.79304
Timestep Consumption Time: 3.07753
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.87058
Cumulative Model Updates: 180,458
Cumulative Timesteps: 1,368,895,546
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30732
Policy Entropy: 4.34667
Value Function Loss: 0.00235
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.90851
Value Function Update Magnitude: 0.77678
Collected Steps per Second: 13,080.12289
Overall Steps per Second: 7,319.48566
Timestep Collection Time: 3.82443
Timestep Consumption Time: 3.00993
PPO Batch Consumption Time: 0.22940
Total Iteration Time: 6.83436
Cumulative Model Updates: 180,467
Cumulative Timesteps: 1,368,945,570
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1368945570...
Checkpoint 1368945570 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.90948
Policy Entropy: 4.34314
Value Function Loss: 0.00241
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.89510
Value Function Update Magnitude: 0.76273
Collected Steps per Second: 13,362.87410
Overall Steps per Second: 7,278.85578
Timestep Collection Time: 3.74515
Timestep Consumption Time: 3.13038
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.87553
Cumulative Model Updates: 180,476
Cumulative Timesteps: 1,368,995,616
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87078
Policy Entropy: 4.34318
Value Function Loss: 0.00238
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.90454
Value Function Update Magnitude: 0.73797
Collected Steps per Second: 13,050.00694
Overall Steps per Second: 7,252.63712
Timestep Collection Time: 3.83172
Timestep Consumption Time: 3.06287
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.89460
Cumulative Model Updates: 180,485
Cumulative Timesteps: 1,369,045,620
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1369045620...
Checkpoint 1369045620 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74556
Policy Entropy: 4.34007
Value Function Loss: 0.00249
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.90481
Value Function Update Magnitude: 0.72820
Collected Steps per Second: 13,440.20852
Overall Steps per Second: 7,141.15534
Timestep Collection Time: 3.72271
Timestep Consumption Time: 3.28372
PPO Batch Consumption Time: 0.24389
Total Iteration Time: 7.00643
Cumulative Model Updates: 180,494
Cumulative Timesteps: 1,369,095,654
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.25294
Policy Entropy: 4.34316
Value Function Loss: 0.00234
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.88321
Value Function Update Magnitude: 0.70398
Collected Steps per Second: 13,197.98793
Overall Steps per Second: 7,227.64215
Timestep Collection Time: 3.78861
Timestep Consumption Time: 3.12955
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.91816
Cumulative Model Updates: 180,503
Cumulative Timesteps: 1,369,145,656
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1369145656...
Checkpoint 1369145656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.69905
Policy Entropy: 4.34616
Value Function Loss: 0.00248
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02405
Policy Update Magnitude: 0.90170
Value Function Update Magnitude: 0.68379
Collected Steps per Second: 13,173.85017
Overall Steps per Second: 7,293.70804
Timestep Collection Time: 3.79585
Timestep Consumption Time: 3.06019
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.85605
Cumulative Model Updates: 180,512
Cumulative Timesteps: 1,369,195,662
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.83119
Policy Entropy: 4.34941
Value Function Loss: 0.00246
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.90459
Value Function Update Magnitude: 0.71243
Collected Steps per Second: 13,463.36691
Overall Steps per Second: 7,334.79905
Timestep Collection Time: 3.71616
Timestep Consumption Time: 3.10502
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.82118
Cumulative Model Updates: 180,521
Cumulative Timesteps: 1,369,245,694
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1369245694...
Checkpoint 1369245694 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.50552
Policy Entropy: 4.34685
Value Function Loss: 0.00248
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.90771
Value Function Update Magnitude: 0.69281
Collected Steps per Second: 13,291.28172
Overall Steps per Second: 7,269.64373
Timestep Collection Time: 3.76502
Timestep Consumption Time: 3.11867
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.88369
Cumulative Model Updates: 180,530
Cumulative Timesteps: 1,369,295,736
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46574
Policy Entropy: 4.34511
Value Function Loss: 0.00245
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.91783
Value Function Update Magnitude: 0.66866
Collected Steps per Second: 13,138.46329
Overall Steps per Second: 7,349.10797
Timestep Collection Time: 3.80745
Timestep Consumption Time: 2.99937
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.80681
Cumulative Model Updates: 180,539
Cumulative Timesteps: 1,369,345,760
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1369345760...
Checkpoint 1369345760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.59298
Policy Entropy: 4.34367
Value Function Loss: 0.00236
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.89544
Value Function Update Magnitude: 0.70116
Collected Steps per Second: 13,274.39441
Overall Steps per Second: 7,258.85729
Timestep Collection Time: 3.76831
Timestep Consumption Time: 3.12286
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.89117
Cumulative Model Updates: 180,548
Cumulative Timesteps: 1,369,395,782
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.17296
Policy Entropy: 4.34488
Value Function Loss: 0.00236
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.89435
Value Function Update Magnitude: 0.70733
Collected Steps per Second: 13,283.74105
Overall Steps per Second: 7,140.17325
Timestep Collection Time: 3.76400
Timestep Consumption Time: 3.23863
PPO Batch Consumption Time: 0.24027
Total Iteration Time: 7.00263
Cumulative Model Updates: 180,557
Cumulative Timesteps: 1,369,445,782
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1369445782...
Checkpoint 1369445782 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.88762
Policy Entropy: 4.34459
Value Function Loss: 0.00253
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.92017
Value Function Update Magnitude: 0.73374
Collected Steps per Second: 12,878.35344
Overall Steps per Second: 7,254.92813
Timestep Collection Time: 3.88450
Timestep Consumption Time: 3.01095
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.89545
Cumulative Model Updates: 180,566
Cumulative Timesteps: 1,369,495,808
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35038
Policy Entropy: 4.34245
Value Function Loss: 0.00262
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.92343
Value Function Update Magnitude: 0.75282
Collected Steps per Second: 13,305.19613
Overall Steps per Second: 7,287.34189
Timestep Collection Time: 3.76034
Timestep Consumption Time: 3.10527
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.86560
Cumulative Model Updates: 180,575
Cumulative Timesteps: 1,369,545,840
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1369545840...
Checkpoint 1369545840 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70529
Policy Entropy: 4.34030
Value Function Loss: 0.00251
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02366
Policy Update Magnitude: 0.89727
Value Function Update Magnitude: 0.70490
Collected Steps per Second: 13,259.85807
Overall Steps per Second: 7,391.27960
Timestep Collection Time: 3.77259
Timestep Consumption Time: 2.99539
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.76798
Cumulative Model Updates: 180,584
Cumulative Timesteps: 1,369,595,864
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61312
Policy Entropy: 4.33804
Value Function Loss: 0.00253
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.89774
Value Function Update Magnitude: 0.70812
Collected Steps per Second: 13,295.24352
Overall Steps per Second: 7,263.41928
Timestep Collection Time: 3.76150
Timestep Consumption Time: 3.12369
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.88519
Cumulative Model Updates: 180,593
Cumulative Timesteps: 1,369,645,874
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1369645874...
Checkpoint 1369645874 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.40108
Policy Entropy: 4.33985
Value Function Loss: 0.00250
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.90246
Value Function Update Magnitude: 0.76323
Collected Steps per Second: 13,157.00649
Overall Steps per Second: 7,283.61161
Timestep Collection Time: 3.80406
Timestep Consumption Time: 3.06753
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.87159
Cumulative Model Updates: 180,602
Cumulative Timesteps: 1,369,695,924
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.93637
Policy Entropy: 4.34513
Value Function Loss: 0.00249
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.89293
Value Function Update Magnitude: 0.70556
Collected Steps per Second: 13,157.81723
Overall Steps per Second: 7,355.77112
Timestep Collection Time: 3.80261
Timestep Consumption Time: 2.99940
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.80201
Cumulative Model Updates: 180,611
Cumulative Timesteps: 1,369,745,958
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1369745958...
Checkpoint 1369745958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.05218
Policy Entropy: 4.34862
Value Function Loss: 0.00240
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02279
Policy Update Magnitude: 0.87174
Value Function Update Magnitude: 0.65169
Collected Steps per Second: 13,299.16284
Overall Steps per Second: 7,132.97223
Timestep Collection Time: 3.76009
Timestep Consumption Time: 3.25046
PPO Batch Consumption Time: 0.23947
Total Iteration Time: 7.01054
Cumulative Model Updates: 180,620
Cumulative Timesteps: 1,369,795,964
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00655
Policy Entropy: 4.34757
Value Function Loss: 0.00240
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.85043
Value Function Update Magnitude: 0.62016
Collected Steps per Second: 13,206.69866
Overall Steps per Second: 7,280.09673
Timestep Collection Time: 3.78868
Timestep Consumption Time: 3.08430
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.87299
Cumulative Model Updates: 180,629
Cumulative Timesteps: 1,369,846,000
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1369846000...
Checkpoint 1369846000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13728
Policy Entropy: 4.34726
Value Function Loss: 0.00229
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02155
Policy Update Magnitude: 0.84061
Value Function Update Magnitude: 0.62814
Collected Steps per Second: 13,385.72627
Overall Steps per Second: 7,313.23133
Timestep Collection Time: 3.73577
Timestep Consumption Time: 3.10197
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.83774
Cumulative Model Updates: 180,638
Cumulative Timesteps: 1,369,896,006
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38064
Policy Entropy: 4.34611
Value Function Loss: 0.00217
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.83770
Value Function Update Magnitude: 0.66677
Collected Steps per Second: 13,102.70581
Overall Steps per Second: 7,225.88301
Timestep Collection Time: 3.81906
Timestep Consumption Time: 3.10605
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.92511
Cumulative Model Updates: 180,647
Cumulative Timesteps: 1,369,946,046
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1369946046...
Checkpoint 1369946046 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34841
Policy Entropy: 4.34963
Value Function Loss: 0.00206
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02440
Policy Update Magnitude: 0.81648
Value Function Update Magnitude: 0.67593
Collected Steps per Second: 13,332.21814
Overall Steps per Second: 7,327.47234
Timestep Collection Time: 3.75181
Timestep Consumption Time: 3.07455
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.82636
Cumulative Model Updates: 180,656
Cumulative Timesteps: 1,369,996,066
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.03055
Policy Entropy: 4.34709
Value Function Loss: 0.00220
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02390
Policy Update Magnitude: 0.84011
Value Function Update Magnitude: 0.71335
Collected Steps per Second: 13,319.44209
Overall Steps per Second: 7,292.78406
Timestep Collection Time: 3.75421
Timestep Consumption Time: 3.10243
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.85664
Cumulative Model Updates: 180,665
Cumulative Timesteps: 1,370,046,070
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1370046070...
Checkpoint 1370046070 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.65721
Policy Entropy: 4.34989
Value Function Loss: 0.00236
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.87648
Value Function Update Magnitude: 0.67203
Collected Steps per Second: 13,120.75913
Overall Steps per Second: 7,223.11580
Timestep Collection Time: 3.81167
Timestep Consumption Time: 3.11221
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.92388
Cumulative Model Updates: 180,674
Cumulative Timesteps: 1,370,096,082
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.17719
Policy Entropy: 4.34540
Value Function Loss: 0.00259
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.90461
Value Function Update Magnitude: 0.68368
Collected Steps per Second: 13,144.53304
Overall Steps per Second: 7,151.55858
Timestep Collection Time: 3.80447
Timestep Consumption Time: 3.18813
PPO Batch Consumption Time: 0.24348
Total Iteration Time: 6.99260
Cumulative Model Updates: 180,683
Cumulative Timesteps: 1,370,146,090
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1370146090...
Checkpoint 1370146090 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.00282
Policy Entropy: 4.34757
Value Function Loss: 0.00252
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.89287
Value Function Update Magnitude: 0.68737
Collected Steps per Second: 13,270.59738
Overall Steps per Second: 7,288.31678
Timestep Collection Time: 3.76939
Timestep Consumption Time: 3.09393
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.86331
Cumulative Model Updates: 180,692
Cumulative Timesteps: 1,370,196,112
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03512
Policy Entropy: 4.34934
Value Function Loss: 0.00235
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.87127
Value Function Update Magnitude: 0.67172
Collected Steps per Second: 13,276.26115
Overall Steps per Second: 7,306.38375
Timestep Collection Time: 3.76627
Timestep Consumption Time: 3.07733
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.84360
Cumulative Model Updates: 180,701
Cumulative Timesteps: 1,370,246,114
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1370246114...
Checkpoint 1370246114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33190
Policy Entropy: 4.35072
Value Function Loss: 0.00217
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.85074
Value Function Update Magnitude: 0.61907
Collected Steps per Second: 13,238.85636
Overall Steps per Second: 7,364.03829
Timestep Collection Time: 3.77918
Timestep Consumption Time: 3.01492
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.79410
Cumulative Model Updates: 180,710
Cumulative Timesteps: 1,370,296,146
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.52961
Policy Entropy: 4.35145
Value Function Loss: 0.00202
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02220
Policy Update Magnitude: 0.83861
Value Function Update Magnitude: 0.58751
Collected Steps per Second: 13,289.63152
Overall Steps per Second: 7,240.63609
Timestep Collection Time: 3.76354
Timestep Consumption Time: 3.14414
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.90768
Cumulative Model Updates: 180,719
Cumulative Timesteps: 1,370,346,162
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1370346162...
Checkpoint 1370346162 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70584
Policy Entropy: 4.35203
Value Function Loss: 0.00207
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02057
Policy Update Magnitude: 0.82574
Value Function Update Magnitude: 0.58697
Collected Steps per Second: 13,132.36030
Overall Steps per Second: 7,253.02478
Timestep Collection Time: 3.81028
Timestep Consumption Time: 3.08863
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.89891
Cumulative Model Updates: 180,728
Cumulative Timesteps: 1,370,396,200
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.53678
Policy Entropy: 4.35587
Value Function Loss: 0.00206
Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02221
Policy Update Magnitude: 0.82906
Value Function Update Magnitude: 0.63534
Collected Steps per Second: 13,423.18454
Overall Steps per Second: 7,329.03214
Timestep Collection Time: 3.72505
Timestep Consumption Time: 3.09741
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.82246
Cumulative Model Updates: 180,737
Cumulative Timesteps: 1,370,446,202
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1370446202...
Checkpoint 1370446202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.94016
Policy Entropy: 4.35153
Value Function Loss: 0.00226
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.87188
Value Function Update Magnitude: 0.69935
Collected Steps per Second: 13,103.34092
Overall Steps per Second: 7,047.36579
Timestep Collection Time: 3.81704
Timestep Consumption Time: 3.28008
PPO Batch Consumption Time: 0.24181
Total Iteration Time: 7.09712
Cumulative Model Updates: 180,746
Cumulative Timesteps: 1,370,496,218
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.58468
Policy Entropy: 4.35007
Value Function Loss: 0.00230
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02376
Policy Update Magnitude: 0.88203
Value Function Update Magnitude: 0.69698
Collected Steps per Second: 13,235.33898
Overall Steps per Second: 7,308.54619
Timestep Collection Time: 3.77958
Timestep Consumption Time: 3.06501
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.84459
Cumulative Model Updates: 180,755
Cumulative Timesteps: 1,370,546,242
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1370546242...
Checkpoint 1370546242 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.47713
Policy Entropy: 4.34699
Value Function Loss: 0.00248
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.89699
Value Function Update Magnitude: 0.69555
Collected Steps per Second: 13,402.25595
Overall Steps per Second: 7,305.68169
Timestep Collection Time: 3.73072
Timestep Consumption Time: 3.11327
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.84399
Cumulative Model Updates: 180,764
Cumulative Timesteps: 1,370,596,242
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83608
Policy Entropy: 4.34897
Value Function Loss: 0.00237
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02237
Policy Update Magnitude: 0.88896
Value Function Update Magnitude: 0.66514
Collected Steps per Second: 13,046.59918
Overall Steps per Second: 7,193.73834
Timestep Collection Time: 3.83472
Timestep Consumption Time: 3.11994
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.95466
Cumulative Model Updates: 180,773
Cumulative Timesteps: 1,370,646,272
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1370646272...
Checkpoint 1370646272 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.18446
Policy Entropy: 4.34700
Value Function Loss: 0.00238
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02196
Policy Update Magnitude: 0.86348
Value Function Update Magnitude: 0.68257
Collected Steps per Second: 13,077.92885
Overall Steps per Second: 7,331.47725
Timestep Collection Time: 3.82553
Timestep Consumption Time: 2.99847
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.82400
Cumulative Model Updates: 180,782
Cumulative Timesteps: 1,370,696,302
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06858
Policy Entropy: 4.34803
Value Function Loss: 0.00216
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.85798
Value Function Update Magnitude: 0.67216
Collected Steps per Second: 13,146.92704
Overall Steps per Second: 7,236.18168
Timestep Collection Time: 3.80423
Timestep Consumption Time: 3.10742
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.91166
Cumulative Model Updates: 180,791
Cumulative Timesteps: 1,370,746,316
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1370746316...
Checkpoint 1370746316 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.26818
Policy Entropy: 4.35187
Value Function Loss: 0.00227
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.85718
Value Function Update Magnitude: 0.67278
Collected Steps per Second: 13,208.67242
Overall Steps per Second: 7,291.78480
Timestep Collection Time: 3.78751
Timestep Consumption Time: 3.07336
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.86087
Cumulative Model Updates: 180,800
Cumulative Timesteps: 1,370,796,344
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.50194
Policy Entropy: 4.35196
Value Function Loss: 0.00224
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02189
Policy Update Magnitude: 0.86548
Value Function Update Magnitude: 0.68651
Collected Steps per Second: 13,167.99442
Overall Steps per Second: 7,282.38274
Timestep Collection Time: 3.79936
Timestep Consumption Time: 3.07064
PPO Batch Consumption Time: 0.23456
Total Iteration Time: 6.87000
Cumulative Model Updates: 180,809
Cumulative Timesteps: 1,370,846,374
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1370846374...
Checkpoint 1370846374 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32074
Policy Entropy: 4.35351
Value Function Loss: 0.00227
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.86445
Value Function Update Magnitude: 0.69202
Collected Steps per Second: 13,156.11328
Overall Steps per Second: 7,211.81484
Timestep Collection Time: 3.80234
Timestep Consumption Time: 3.13406
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.93640
Cumulative Model Updates: 180,818
Cumulative Timesteps: 1,370,896,398
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81440
Policy Entropy: 4.35210
Value Function Loss: 0.00231
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02202
Policy Update Magnitude: 0.84743
Value Function Update Magnitude: 0.66555
Collected Steps per Second: 13,215.97241
Overall Steps per Second: 7,282.26485
Timestep Collection Time: 3.78436
Timestep Consumption Time: 3.08356
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.86792
Cumulative Model Updates: 180,827
Cumulative Timesteps: 1,370,946,412
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1370946412...
Checkpoint 1370946412 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34146
Policy Entropy: 4.35458
Value Function Loss: 0.00212
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02303
Policy Update Magnitude: 0.81860
Value Function Update Magnitude: 0.72080
Collected Steps per Second: 13,502.12556
Overall Steps per Second: 7,333.53631
Timestep Collection Time: 3.70460
Timestep Consumption Time: 3.11612
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.82072
Cumulative Model Updates: 180,836
Cumulative Timesteps: 1,370,996,432
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.51441
Policy Entropy: 4.35470
Value Function Loss: 0.00200
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.81409
Value Function Update Magnitude: 0.73018
Collected Steps per Second: 13,108.62086
Overall Steps per Second: 7,213.38345
Timestep Collection Time: 3.81581
Timestep Consumption Time: 3.11852
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.93433
Cumulative Model Updates: 180,845
Cumulative Timesteps: 1,371,046,452
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1371046452...
Checkpoint 1371046452 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.65654
Policy Entropy: 4.35512
Value Function Loss: 0.00194
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.82008
Value Function Update Magnitude: 0.70713
Collected Steps per Second: 13,219.96499
Overall Steps per Second: 7,374.52560
Timestep Collection Time: 3.78412
Timestep Consumption Time: 2.99950
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.78362
Cumulative Model Updates: 180,854
Cumulative Timesteps: 1,371,096,478
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06482
Policy Entropy: 4.35345
Value Function Loss: 0.00203
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02214
Policy Update Magnitude: 0.86528
Value Function Update Magnitude: 0.66224
Collected Steps per Second: 13,124.42366
Overall Steps per Second: 7,225.58196
Timestep Collection Time: 3.81091
Timestep Consumption Time: 3.11116
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.92207
Cumulative Model Updates: 180,863
Cumulative Timesteps: 1,371,146,494
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1371146494...
Checkpoint 1371146494 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.42849
Policy Entropy: 4.35478
Value Function Loss: 0.00208
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02327
Policy Update Magnitude: 0.87554
Value Function Update Magnitude: 0.67068
Collected Steps per Second: 13,057.74535
Overall Steps per Second: 7,130.14388
Timestep Collection Time: 3.83083
Timestep Consumption Time: 3.18474
PPO Batch Consumption Time: 0.23851
Total Iteration Time: 7.01557
Cumulative Model Updates: 180,872
Cumulative Timesteps: 1,371,196,516
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33318
Policy Entropy: 4.35834
Value Function Loss: 0.00226
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02323
Policy Update Magnitude: 0.89087
Value Function Update Magnitude: 0.66150
Collected Steps per Second: 13,127.70740
Overall Steps per Second: 7,346.10774
Timestep Collection Time: 3.80920
Timestep Consumption Time: 2.99795
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.80714
Cumulative Model Updates: 180,881
Cumulative Timesteps: 1,371,246,522
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1371246522...
Checkpoint 1371246522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.56032
Policy Entropy: 4.35768
Value Function Loss: 0.00238
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02348
Policy Update Magnitude: 0.90790
Value Function Update Magnitude: 0.67197
Collected Steps per Second: 13,133.17156
Overall Steps per Second: 7,225.06684
Timestep Collection Time: 3.80929
Timestep Consumption Time: 3.11494
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.92423
Cumulative Model Updates: 180,890
Cumulative Timesteps: 1,371,296,550
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.93962
Policy Entropy: 4.35767
Value Function Loss: 0.00244
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.91093
Value Function Update Magnitude: 0.66281
Collected Steps per Second: 13,147.52895
Overall Steps per Second: 7,286.73599
Timestep Collection Time: 3.80376
Timestep Consumption Time: 3.05940
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.86316
Cumulative Model Updates: 180,899
Cumulative Timesteps: 1,371,346,560
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1371346560...
Checkpoint 1371346560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01804
Policy Entropy: 4.35865
Value Function Loss: 0.00228
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02288
Policy Update Magnitude: 0.89801
Value Function Update Magnitude: 0.66716
Collected Steps per Second: 13,335.13346
Overall Steps per Second: 7,319.72899
Timestep Collection Time: 3.75084
Timestep Consumption Time: 3.08247
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.83331
Cumulative Model Updates: 180,908
Cumulative Timesteps: 1,371,396,578
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12068
Policy Entropy: 4.36069
Value Function Loss: 0.00232
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02250
Policy Update Magnitude: 0.89804
Value Function Update Magnitude: 0.68920
Collected Steps per Second: 13,353.92165
Overall Steps per Second: 7,279.97077
Timestep Collection Time: 3.74452
Timestep Consumption Time: 3.12419
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.86871
Cumulative Model Updates: 180,917
Cumulative Timesteps: 1,371,446,582
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1371446582...
Checkpoint 1371446582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38146
Policy Entropy: 4.35886
Value Function Loss: 0.00233
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02408
Policy Update Magnitude: 0.90216
Value Function Update Magnitude: 0.71585
Collected Steps per Second: 13,053.92930
Overall Steps per Second: 7,258.35133
Timestep Collection Time: 3.83103
Timestep Consumption Time: 3.05896
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.88999
Cumulative Model Updates: 180,926
Cumulative Timesteps: 1,371,496,592
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.22284
Policy Entropy: 4.35599
Value Function Loss: 0.00251
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.93102
Value Function Update Magnitude: 0.73575
Collected Steps per Second: 13,527.55583
Overall Steps per Second: 7,272.86989
Timestep Collection Time: 3.69838
Timestep Consumption Time: 3.18061
PPO Batch Consumption Time: 0.23351
Total Iteration Time: 6.87899
Cumulative Model Updates: 180,935
Cumulative Timesteps: 1,371,546,622
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1371546622...
Checkpoint 1371546622 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.32310
Policy Entropy: 4.34833
Value Function Loss: 0.00249
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02585
Policy Update Magnitude: 0.95130
Value Function Update Magnitude: 0.74686
Collected Steps per Second: 13,189.55106
Overall Steps per Second: 7,246.68093
Timestep Collection Time: 3.79391
Timestep Consumption Time: 3.11132
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.90523
Cumulative Model Updates: 180,944
Cumulative Timesteps: 1,371,596,662
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.13347
Policy Entropy: 4.34640
Value Function Loss: 0.00262
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.95237
Value Function Update Magnitude: 0.76651
Collected Steps per Second: 13,257.69148
Overall Steps per Second: 7,359.79628
Timestep Collection Time: 3.77396
Timestep Consumption Time: 3.02433
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.79829
Cumulative Model Updates: 180,953
Cumulative Timesteps: 1,371,646,696
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1371646696...
Checkpoint 1371646696 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.13340
Policy Entropy: 4.34749
Value Function Loss: 0.00255
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.93472
Value Function Update Magnitude: 0.72157
Collected Steps per Second: 13,291.46203
Overall Steps per Second: 7,236.06607
Timestep Collection Time: 3.76347
Timestep Consumption Time: 3.14940
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.91287
Cumulative Model Updates: 180,962
Cumulative Timesteps: 1,371,696,718
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.50161
Policy Entropy: 4.34956
Value Function Loss: 0.00257
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.91922
Value Function Update Magnitude: 0.69152
Collected Steps per Second: 13,281.02833
Overall Steps per Second: 7,293.87921
Timestep Collection Time: 3.76507
Timestep Consumption Time: 3.09054
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.85561
Cumulative Model Updates: 180,971
Cumulative Timesteps: 1,371,746,722
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1371746722...
Checkpoint 1371746722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.10929
Policy Entropy: 4.35028
Value Function Loss: 0.00246
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02357
Policy Update Magnitude: 0.91661
Value Function Update Magnitude: 0.71488
Collected Steps per Second: 12,983.40654
Overall Steps per Second: 7,294.06018
Timestep Collection Time: 3.85169
Timestep Consumption Time: 3.00430
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.85599
Cumulative Model Updates: 180,980
Cumulative Timesteps: 1,371,796,730
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00063
Policy Entropy: 4.34852
Value Function Loss: 0.00236
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02332
Policy Update Magnitude: 0.91648
Value Function Update Magnitude: 0.71770
Collected Steps per Second: 13,318.72901
Overall Steps per Second: 7,285.29629
Timestep Collection Time: 3.75441
Timestep Consumption Time: 3.10928
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.86369
Cumulative Model Updates: 180,989
Cumulative Timesteps: 1,371,846,734
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1371846734...
Checkpoint 1371846734 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95486
Policy Entropy: 4.34983
Value Function Loss: 0.00249
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02387
Policy Update Magnitude: 0.90311
Value Function Update Magnitude: 0.77198
Collected Steps per Second: 13,170.96880
Overall Steps per Second: 7,156.92023
Timestep Collection Time: 3.79759
Timestep Consumption Time: 3.19117
PPO Batch Consumption Time: 0.23910
Total Iteration Time: 6.98876
Cumulative Model Updates: 180,998
Cumulative Timesteps: 1,371,896,752
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75114
Policy Entropy: 4.34361
Value Function Loss: 0.00271
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.92279
Value Function Update Magnitude: 0.83032
Collected Steps per Second: 13,422.70325
Overall Steps per Second: 7,329.72044
Timestep Collection Time: 3.72920
Timestep Consumption Time: 3.09998
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.82918
Cumulative Model Updates: 181,007
Cumulative Timesteps: 1,371,946,808
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1371946808...
Checkpoint 1371946808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.72862
Policy Entropy: 4.34390
Value Function Loss: 0.00261
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02355
Policy Update Magnitude: 0.92244
Value Function Update Magnitude: 0.78833
Collected Steps per Second: 13,136.23244
Overall Steps per Second: 7,220.52606
Timestep Collection Time: 3.80901
Timestep Consumption Time: 3.12068
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.92969
Cumulative Model Updates: 181,016
Cumulative Timesteps: 1,371,996,844
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41139
Policy Entropy: 4.34434
Value Function Loss: 0.00259
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02311
Policy Update Magnitude: 0.91126
Value Function Update Magnitude: 0.77310
Collected Steps per Second: 13,178.16727
Overall Steps per Second: 7,363.49491
Timestep Collection Time: 3.79415
Timestep Consumption Time: 2.99610
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.79025
Cumulative Model Updates: 181,025
Cumulative Timesteps: 1,372,046,844
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1372046844...
Checkpoint 1372046844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.14722
Policy Entropy: 4.34983
Value Function Loss: 0.00214
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02152
Policy Update Magnitude: 0.87861
Value Function Update Magnitude: 0.77806
Collected Steps per Second: 13,127.14422
Overall Steps per Second: 7,254.63825
Timestep Collection Time: 3.81012
Timestep Consumption Time: 3.08423
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.89435
Cumulative Model Updates: 181,034
Cumulative Timesteps: 1,372,096,860
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.91490
Policy Entropy: 4.34908
Value Function Loss: 0.00241
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.90000
Value Function Update Magnitude: 0.74339
Collected Steps per Second: 13,122.00797
Overall Steps per Second: 7,245.81533
Timestep Collection Time: 3.81192
Timestep Consumption Time: 3.09138
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.90329
Cumulative Model Updates: 181,043
Cumulative Timesteps: 1,372,146,880
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1372146880...
Checkpoint 1372146880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63062
Policy Entropy: 4.34734
Value Function Loss: 0.00239
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.92546
Value Function Update Magnitude: 0.73599
Collected Steps per Second: 13,161.61259
Overall Steps per Second: 7,331.18842
Timestep Collection Time: 3.80029
Timestep Consumption Time: 3.02234
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.82263
Cumulative Model Updates: 181,052
Cumulative Timesteps: 1,372,196,898
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.21214
Policy Entropy: 4.34565
Value Function Loss: 0.00246
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.90815
Value Function Update Magnitude: 0.74677
Collected Steps per Second: 13,027.66868
Overall Steps per Second: 7,014.24509
Timestep Collection Time: 3.84090
Timestep Consumption Time: 3.29287
PPO Batch Consumption Time: 0.24427
Total Iteration Time: 7.13377
Cumulative Model Updates: 181,061
Cumulative Timesteps: 1,372,246,936
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1372246936...
Checkpoint 1372246936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57640
Policy Entropy: 4.34764
Value Function Loss: 0.00226
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02347
Policy Update Magnitude: 0.89153
Value Function Update Magnitude: 0.73946
Collected Steps per Second: 13,216.32638
Overall Steps per Second: 7,291.19189
Timestep Collection Time: 3.78456
Timestep Consumption Time: 3.07550
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.86006
Cumulative Model Updates: 181,070
Cumulative Timesteps: 1,372,296,954
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88013
Policy Entropy: 4.34748
Value Function Loss: 0.00228
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.89468
Value Function Update Magnitude: 0.79385
Collected Steps per Second: 13,691.77748
Overall Steps per Second: 7,375.72185
Timestep Collection Time: 3.65402
Timestep Consumption Time: 3.12905
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.78306
Cumulative Model Updates: 181,079
Cumulative Timesteps: 1,372,346,984
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1372346984...
Checkpoint 1372346984 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99633
Policy Entropy: 4.35097
Value Function Loss: 0.00236
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.91241
Value Function Update Magnitude: 0.79118
Collected Steps per Second: 13,328.51244
Overall Steps per Second: 7,288.16997
Timestep Collection Time: 3.75256
Timestep Consumption Time: 3.11007
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.86263
Cumulative Model Updates: 181,088
Cumulative Timesteps: 1,372,397,000
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97733
Policy Entropy: 4.35165
Value Function Loss: 0.00246
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.91384
Value Function Update Magnitude: 0.73015
Collected Steps per Second: 13,284.07234
Overall Steps per Second: 7,306.11460
Timestep Collection Time: 3.76436
Timestep Consumption Time: 3.08005
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.84440
Cumulative Model Updates: 181,097
Cumulative Timesteps: 1,372,447,006
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1372447006...
Checkpoint 1372447006 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.07367
Policy Entropy: 4.35416
Value Function Loss: 0.00245
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02339
Policy Update Magnitude: 0.92347
Value Function Update Magnitude: 0.73090
Collected Steps per Second: 13,488.01743
Overall Steps per Second: 7,345.75407
Timestep Collection Time: 3.70937
Timestep Consumption Time: 3.10164
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.81101
Cumulative Model Updates: 181,106
Cumulative Timesteps: 1,372,497,038
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.02041
Policy Entropy: 4.34949
Value Function Loss: 0.00238
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.91502
Value Function Update Magnitude: 0.76497
Collected Steps per Second: 13,264.02446
Overall Steps per Second: 7,266.43493
Timestep Collection Time: 3.77125
Timestep Consumption Time: 3.11273
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.88398
Cumulative Model Updates: 181,115
Cumulative Timesteps: 1,372,547,060
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1372547060...
Checkpoint 1372547060 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41512
Policy Entropy: 4.35000
Value Function Loss: 0.00239
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02432
Policy Update Magnitude: 0.91393
Value Function Update Magnitude: 0.74325
Collected Steps per Second: 13,109.84332
Overall Steps per Second: 7,188.37158
Timestep Collection Time: 3.81576
Timestep Consumption Time: 3.14326
PPO Batch Consumption Time: 0.24114
Total Iteration Time: 6.95902
Cumulative Model Updates: 181,124
Cumulative Timesteps: 1,372,597,084
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.96530
Policy Entropy: 4.34943
Value Function Loss: 0.00244
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02412
Policy Update Magnitude: 0.92558
Value Function Update Magnitude: 0.75846
Collected Steps per Second: 13,353.66550
Overall Steps per Second: 7,308.40075
Timestep Collection Time: 3.74579
Timestep Consumption Time: 3.09839
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.84418
Cumulative Model Updates: 181,133
Cumulative Timesteps: 1,372,647,104
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1372647104...
Checkpoint 1372647104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80359
Policy Entropy: 4.35173
Value Function Loss: 0.00233
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.92868
Value Function Update Magnitude: 0.78771
Collected Steps per Second: 13,157.51259
Overall Steps per Second: 7,291.08461
Timestep Collection Time: 3.80467
Timestep Consumption Time: 3.06125
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.86592
Cumulative Model Updates: 181,142
Cumulative Timesteps: 1,372,697,164
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05505
Policy Entropy: 4.35076
Value Function Loss: 0.00237
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.91212
Value Function Update Magnitude: 0.69942
Collected Steps per Second: 13,208.52787
Overall Steps per Second: 7,352.44663
Timestep Collection Time: 3.78801
Timestep Consumption Time: 3.01707
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.80508
Cumulative Model Updates: 181,151
Cumulative Timesteps: 1,372,747,198
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1372747198...
Checkpoint 1372747198 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81857
Policy Entropy: 4.34958
Value Function Loss: 0.00247
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.93864
Value Function Update Magnitude: 0.70596
Collected Steps per Second: 12,989.17457
Overall Steps per Second: 7,202.40963
Timestep Collection Time: 3.85059
Timestep Consumption Time: 3.09375
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.94434
Cumulative Model Updates: 181,160
Cumulative Timesteps: 1,372,797,214
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35904
Policy Entropy: 4.34868
Value Function Loss: 0.00261
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.94864
Value Function Update Magnitude: 0.71564
Collected Steps per Second: 13,319.66577
Overall Steps per Second: 7,324.88819
Timestep Collection Time: 3.75400
Timestep Consumption Time: 3.07232
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.82632
Cumulative Model Updates: 181,169
Cumulative Timesteps: 1,372,847,216
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1372847216...
Checkpoint 1372847216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42848
Policy Entropy: 4.34731
Value Function Loss: 0.00253
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.92980
Value Function Update Magnitude: 0.69677
Collected Steps per Second: 13,611.88272
Overall Steps per Second: 7,355.09229
Timestep Collection Time: 3.67591
Timestep Consumption Time: 3.12700
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.80291
Cumulative Model Updates: 181,178
Cumulative Timesteps: 1,372,897,252
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96297
Policy Entropy: 4.34866
Value Function Loss: 0.00255
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.92167
Value Function Update Magnitude: 0.70273
Collected Steps per Second: 13,203.04555
Overall Steps per Second: 7,163.11792
Timestep Collection Time: 3.78882
Timestep Consumption Time: 3.19473
PPO Batch Consumption Time: 0.23767
Total Iteration Time: 6.98355
Cumulative Model Updates: 181,187
Cumulative Timesteps: 1,372,947,276
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1372947276...
Checkpoint 1372947276 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51582
Policy Entropy: 4.34591
Value Function Loss: 0.00262
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02410
Policy Update Magnitude: 0.92314
Value Function Update Magnitude: 0.74265
Collected Steps per Second: 13,221.25277
Overall Steps per Second: 7,334.14763
Timestep Collection Time: 3.78224
Timestep Consumption Time: 3.03600
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.81824
Cumulative Model Updates: 181,196
Cumulative Timesteps: 1,372,997,282
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.05600
Policy Entropy: 4.34537
Value Function Loss: 0.00272
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02512
Policy Update Magnitude: 0.94683
Value Function Update Magnitude: 0.77930
Collected Steps per Second: 13,250.49901
Overall Steps per Second: 7,230.71482
Timestep Collection Time: 3.77707
Timestep Consumption Time: 3.14452
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.92158
Cumulative Model Updates: 181,205
Cumulative Timesteps: 1,373,047,330
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1373047330...
Checkpoint 1373047330 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00544
Policy Entropy: 4.34569
Value Function Loss: 0.00269
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.93760
Value Function Update Magnitude: 0.80179
Collected Steps per Second: 13,148.99543
Overall Steps per Second: 7,289.43537
Timestep Collection Time: 3.80470
Timestep Consumption Time: 3.05838
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.86308
Cumulative Model Updates: 181,214
Cumulative Timesteps: 1,373,097,358
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97049
Policy Entropy: 4.34596
Value Function Loss: 0.00253
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.93125
Value Function Update Magnitude: 0.86192
Collected Steps per Second: 13,526.03127
Overall Steps per Second: 7,352.56732
Timestep Collection Time: 3.69702
Timestep Consumption Time: 3.10414
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.80116
Cumulative Model Updates: 181,223
Cumulative Timesteps: 1,373,147,364
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1373147364...
Checkpoint 1373147364 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.35360
Policy Entropy: 4.34816
Value Function Loss: 0.00244
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.91144
Value Function Update Magnitude: 0.80464
Collected Steps per Second: 13,314.48915
Overall Steps per Second: 7,278.55320
Timestep Collection Time: 3.75741
Timestep Consumption Time: 3.11593
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.87334
Cumulative Model Updates: 181,232
Cumulative Timesteps: 1,373,197,392
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.31048
Policy Entropy: 4.35323
Value Function Loss: 0.00226
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.90204
Value Function Update Magnitude: 0.74738
Collected Steps per Second: 13,069.62012
Overall Steps per Second: 7,229.47326
Timestep Collection Time: 3.82567
Timestep Consumption Time: 3.09047
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.91613
Cumulative Model Updates: 181,241
Cumulative Timesteps: 1,373,247,392
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1373247392...
Checkpoint 1373247392 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08185
Policy Entropy: 4.35374
Value Function Loss: 0.00223
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.89727
Value Function Update Magnitude: 0.69867
Collected Steps per Second: 13,490.51820
Overall Steps per Second: 7,183.23315
Timestep Collection Time: 3.70957
Timestep Consumption Time: 3.25721
PPO Batch Consumption Time: 0.24048
Total Iteration Time: 6.96678
Cumulative Model Updates: 181,250
Cumulative Timesteps: 1,373,297,436
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61035
Policy Entropy: 4.35214
Value Function Loss: 0.00228
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.90823
Value Function Update Magnitude: 0.68802
Collected Steps per Second: 13,244.82761
Overall Steps per Second: 7,238.66357
Timestep Collection Time: 3.77687
Timestep Consumption Time: 3.13380
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.91067
Cumulative Model Updates: 181,259
Cumulative Timesteps: 1,373,347,460
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1373347460...
Checkpoint 1373347460 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.49658
Policy Entropy: 4.35320
Value Function Loss: 0.00222
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02434
Policy Update Magnitude: 0.89993
Value Function Update Magnitude: 0.72063
Collected Steps per Second: 13,093.83789
Overall Steps per Second: 7,339.86793
Timestep Collection Time: 3.82027
Timestep Consumption Time: 2.99484
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.81511
Cumulative Model Updates: 181,268
Cumulative Timesteps: 1,373,397,482
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.30359
Policy Entropy: 4.35340
Value Function Loss: 0.00249
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02279
Policy Update Magnitude: 0.92950
Value Function Update Magnitude: 0.75065
Collected Steps per Second: 13,093.21772
Overall Steps per Second: 7,225.79569
Timestep Collection Time: 3.82060
Timestep Consumption Time: 3.10237
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.92297
Cumulative Model Updates: 181,277
Cumulative Timesteps: 1,373,447,506
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1373447506...
Checkpoint 1373447506 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97895
Policy Entropy: 4.35750
Value Function Loss: 0.00241
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.94132
Value Function Update Magnitude: 0.74577
Collected Steps per Second: 13,014.42661
Overall Steps per Second: 7,236.53298
Timestep Collection Time: 3.84220
Timestep Consumption Time: 3.06774
PPO Batch Consumption Time: 0.22772
Total Iteration Time: 6.90994
Cumulative Model Updates: 181,286
Cumulative Timesteps: 1,373,497,510
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88246
Policy Entropy: 4.35181
Value Function Loss: 0.00265
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02388
Policy Update Magnitude: 0.95838
Value Function Update Magnitude: 0.73105
Collected Steps per Second: 13,181.21124
Overall Steps per Second: 7,340.36077
Timestep Collection Time: 3.79373
Timestep Consumption Time: 3.01874
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.81247
Cumulative Model Updates: 181,295
Cumulative Timesteps: 1,373,547,516
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1373547516...
Checkpoint 1373547516 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.06561
Policy Entropy: 4.35186
Value Function Loss: 0.00239
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02203
Policy Update Magnitude: 0.96131
Value Function Update Magnitude: 0.71942
Collected Steps per Second: 13,300.62290
Overall Steps per Second: 7,287.27152
Timestep Collection Time: 3.76133
Timestep Consumption Time: 3.10379
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.86512
Cumulative Model Updates: 181,304
Cumulative Timesteps: 1,373,597,544
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95259
Policy Entropy: 4.34431
Value Function Loss: 0.00263
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02529
Policy Update Magnitude: 0.96663
Value Function Update Magnitude: 0.75557
Collected Steps per Second: 13,235.21668
Overall Steps per Second: 7,106.43267
Timestep Collection Time: 3.77931
Timestep Consumption Time: 3.25938
PPO Batch Consumption Time: 0.24306
Total Iteration Time: 7.03869
Cumulative Model Updates: 181,313
Cumulative Timesteps: 1,373,647,564
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1373647564...
Checkpoint 1373647564 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.52535
Policy Entropy: 4.34729
Value Function Loss: 0.00248
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02430
Policy Update Magnitude: 0.95327
Value Function Update Magnitude: 0.74427
Collected Steps per Second: 13,434.48143
Overall Steps per Second: 7,326.53714
Timestep Collection Time: 3.72370
Timestep Consumption Time: 3.10435
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.82806
Cumulative Model Updates: 181,322
Cumulative Timesteps: 1,373,697,590
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99050
Policy Entropy: 4.34640
Value Function Loss: 0.00247
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.93357
Value Function Update Magnitude: 0.74329
Collected Steps per Second: 13,142.95714
Overall Steps per Second: 7,227.85141
Timestep Collection Time: 3.80645
Timestep Consumption Time: 3.11511
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.92156
Cumulative Model Updates: 181,331
Cumulative Timesteps: 1,373,747,618
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1373747618...
Checkpoint 1373747618 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.73776
Policy Entropy: 4.35196
Value Function Loss: 0.00227
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.91457
Value Function Update Magnitude: 0.69855
Collected Steps per Second: 13,069.04029
Overall Steps per Second: 7,343.29792
Timestep Collection Time: 3.82798
Timestep Consumption Time: 2.98476
PPO Batch Consumption Time: 0.22786
Total Iteration Time: 6.81274
Cumulative Model Updates: 181,340
Cumulative Timesteps: 1,373,797,646
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37907
Policy Entropy: 4.35078
Value Function Loss: 0.00234
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02280
Policy Update Magnitude: 0.92812
Value Function Update Magnitude: 0.64841
Collected Steps per Second: 13,232.10578
Overall Steps per Second: 7,258.90576
Timestep Collection Time: 3.78171
Timestep Consumption Time: 3.11189
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.89360
Cumulative Model Updates: 181,349
Cumulative Timesteps: 1,373,847,686
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1373847686...
Checkpoint 1373847686 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.54924
Policy Entropy: 4.34809
Value Function Loss: 0.00261
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.95724
Value Function Update Magnitude: 0.69428
Collected Steps per Second: 13,183.55531
Overall Steps per Second: 7,297.29010
Timestep Collection Time: 3.79442
Timestep Consumption Time: 3.06072
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.85515
Cumulative Model Updates: 181,358
Cumulative Timesteps: 1,373,897,710
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.25314
Policy Entropy: 4.34499
Value Function Loss: 0.00257
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02616
Policy Update Magnitude: 0.95430
Value Function Update Magnitude: 0.72103
Collected Steps per Second: 13,531.79900
Overall Steps per Second: 7,367.29574
Timestep Collection Time: 3.69781
Timestep Consumption Time: 3.09410
PPO Batch Consumption Time: 0.22791
Total Iteration Time: 6.79191
Cumulative Model Updates: 181,367
Cumulative Timesteps: 1,373,947,748
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1373947748...
Checkpoint 1373947748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.50295
Policy Entropy: 4.34380
Value Function Loss: 0.00252
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.93413
Value Function Update Magnitude: 0.72446
Collected Steps per Second: 13,190.95421
Overall Steps per Second: 7,042.04098
Timestep Collection Time: 3.79245
Timestep Consumption Time: 3.31146
PPO Batch Consumption Time: 0.24379
Total Iteration Time: 7.10391
Cumulative Model Updates: 181,376
Cumulative Timesteps: 1,373,997,774
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.50794
Policy Entropy: 4.34679
Value Function Loss: 0.00237
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.92613
Value Function Update Magnitude: 0.73292
Collected Steps per Second: 13,189.07215
Overall Steps per Second: 7,281.01555
Timestep Collection Time: 3.79344
Timestep Consumption Time: 3.07813
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.87157
Cumulative Model Updates: 181,385
Cumulative Timesteps: 1,374,047,806
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1374047806...
Checkpoint 1374047806 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90965
Policy Entropy: 4.34345
Value Function Loss: 0.00235
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.92343
Value Function Update Magnitude: 0.71518
Collected Steps per Second: 13,487.27950
Overall Steps per Second: 7,318.23346
Timestep Collection Time: 3.70898
Timestep Consumption Time: 3.12655
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.83553
Cumulative Model Updates: 181,394
Cumulative Timesteps: 1,374,097,830
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45610
Policy Entropy: 4.34335
Value Function Loss: 0.00253
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02411
Policy Update Magnitude: 0.94110
Value Function Update Magnitude: 0.72672
Collected Steps per Second: 13,204.57805
Overall Steps per Second: 7,238.56040
Timestep Collection Time: 3.78869
Timestep Consumption Time: 3.12263
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.91132
Cumulative Model Updates: 181,403
Cumulative Timesteps: 1,374,147,858
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1374147858...
Checkpoint 1374147858 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.04469
Policy Entropy: 4.34389
Value Function Loss: 0.00251
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.95929
Value Function Update Magnitude: 0.72296
Collected Steps per Second: 13,212.72791
Overall Steps per Second: 7,357.50034
Timestep Collection Time: 3.78423
Timestep Consumption Time: 3.01156
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.79579
Cumulative Model Updates: 181,412
Cumulative Timesteps: 1,374,197,858
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96764
Policy Entropy: 4.34064
Value Function Loss: 0.00279
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02682
Policy Update Magnitude: 0.96881
Value Function Update Magnitude: 0.72126
Collected Steps per Second: 13,313.93282
Overall Steps per Second: 7,300.03558
Timestep Collection Time: 3.75592
Timestep Consumption Time: 3.09419
PPO Batch Consumption Time: 0.22773
Total Iteration Time: 6.85010
Cumulative Model Updates: 181,421
Cumulative Timesteps: 1,374,247,864
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1374247864...
Checkpoint 1374247864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27149
Policy Entropy: 4.34362
Value Function Loss: 0.00260
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.95545
Value Function Update Magnitude: 0.77840
Collected Steps per Second: 13,107.22218
Overall Steps per Second: 7,263.06860
Timestep Collection Time: 3.81606
Timestep Consumption Time: 3.07056
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.88662
Cumulative Model Updates: 181,430
Cumulative Timesteps: 1,374,297,882
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32530
Policy Entropy: 4.34523
Value Function Loss: 0.00239
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.91278
Value Function Update Magnitude: 0.75612
Collected Steps per Second: 13,411.41224
Overall Steps per Second: 7,171.94279
Timestep Collection Time: 3.73011
Timestep Consumption Time: 3.24513
PPO Batch Consumption Time: 0.24234
Total Iteration Time: 6.97524
Cumulative Model Updates: 181,439
Cumulative Timesteps: 1,374,347,908
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1374347908...
Checkpoint 1374347908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41037
Policy Entropy: 4.34894
Value Function Loss: 0.00218
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.90085
Value Function Update Magnitude: 0.74788
Collected Steps per Second: 13,145.67346
Overall Steps per Second: 7,259.34007
Timestep Collection Time: 3.80505
Timestep Consumption Time: 3.08538
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.89043
Cumulative Model Updates: 181,448
Cumulative Timesteps: 1,374,397,928
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28302
Policy Entropy: 4.35048
Value Function Loss: 0.00217
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02388
Policy Update Magnitude: 0.89589
Value Function Update Magnitude: 0.69028
Collected Steps per Second: 13,211.03123
Overall Steps per Second: 7,317.42012
Timestep Collection Time: 3.78744
Timestep Consumption Time: 3.05049
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.83793
Cumulative Model Updates: 181,457
Cumulative Timesteps: 1,374,447,964
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1374447964...
Checkpoint 1374447964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96629
Policy Entropy: 4.34283
Value Function Loss: 0.00254
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.92130
Value Function Update Magnitude: 0.69962
Collected Steps per Second: 13,408.03401
Overall Steps per Second: 7,334.19604
Timestep Collection Time: 3.73239
Timestep Consumption Time: 3.09099
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.82338
Cumulative Model Updates: 181,466
Cumulative Timesteps: 1,374,498,008
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.52541
Policy Entropy: 4.34359
Value Function Loss: 0.00247
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.91931
Value Function Update Magnitude: 0.71989
Collected Steps per Second: 13,293.06109
Overall Steps per Second: 7,267.03819
Timestep Collection Time: 3.76362
Timestep Consumption Time: 3.12089
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.88451
Cumulative Model Updates: 181,475
Cumulative Timesteps: 1,374,548,038
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1374548038...
Checkpoint 1374548038 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97598
Policy Entropy: 4.34145
Value Function Loss: 0.00249
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.90600
Value Function Update Magnitude: 0.70259
Collected Steps per Second: 13,035.83405
Overall Steps per Second: 7,321.43328
Timestep Collection Time: 3.83558
Timestep Consumption Time: 2.99368
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.82926
Cumulative Model Updates: 181,484
Cumulative Timesteps: 1,374,598,038
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31547
Policy Entropy: 4.34088
Value Function Loss: 0.00260
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.92466
Value Function Update Magnitude: 0.72316
Collected Steps per Second: 13,327.45478
Overall Steps per Second: 7,278.79963
Timestep Collection Time: 3.75376
Timestep Consumption Time: 3.11936
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.87311
Cumulative Model Updates: 181,493
Cumulative Timesteps: 1,374,648,066
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1374648066...
Checkpoint 1374648066 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57922
Policy Entropy: 4.34260
Value Function Loss: 0.00272
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.92429
Value Function Update Magnitude: 0.74716
Collected Steps per Second: 13,121.95009
Overall Steps per Second: 7,073.51891
Timestep Collection Time: 3.81087
Timestep Consumption Time: 3.25860
PPO Batch Consumption Time: 0.24420
Total Iteration Time: 7.06947
Cumulative Model Updates: 181,502
Cumulative Timesteps: 1,374,698,072
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33436
Policy Entropy: 4.34205
Value Function Loss: 0.00266
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.92512
Value Function Update Magnitude: 0.74946
Collected Steps per Second: 13,125.85334
Overall Steps per Second: 7,311.15927
Timestep Collection Time: 3.81004
Timestep Consumption Time: 3.03019
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.84023
Cumulative Model Updates: 181,511
Cumulative Timesteps: 1,374,748,082
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1374748082...
Checkpoint 1374748082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63294
Policy Entropy: 4.34931
Value Function Loss: 0.00253
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.90649
Value Function Update Magnitude: 0.75251
Collected Steps per Second: 13,324.28432
Overall Steps per Second: 7,254.43845
Timestep Collection Time: 3.75555
Timestep Consumption Time: 3.14230
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.89785
Cumulative Model Updates: 181,520
Cumulative Timesteps: 1,374,798,122
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11623
Policy Entropy: 4.34826
Value Function Loss: 0.00243
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.89549
Value Function Update Magnitude: 0.71977
Collected Steps per Second: 13,072.89675
Overall Steps per Second: 7,271.89949
Timestep Collection Time: 3.82761
Timestep Consumption Time: 3.05339
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.88101
Cumulative Model Updates: 181,529
Cumulative Timesteps: 1,374,848,160
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1374848160...
Checkpoint 1374848160 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.98899
Policy Entropy: 4.34841
Value Function Loss: 0.00245
Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.88538
Value Function Update Magnitude: 0.70763
Collected Steps per Second: 13,405.35028
Overall Steps per Second: 7,321.91952
Timestep Collection Time: 3.73105
Timestep Consumption Time: 3.09995
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.83100
Cumulative Model Updates: 181,538
Cumulative Timesteps: 1,374,898,176
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76573
Policy Entropy: 4.34769
Value Function Loss: 0.00245
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02320
Policy Update Magnitude: 0.89982
Value Function Update Magnitude: 0.70678
Collected Steps per Second: 13,282.78402
Overall Steps per Second: 7,254.02381
Timestep Collection Time: 3.76427
Timestep Consumption Time: 3.12846
PPO Batch Consumption Time: 0.22918
Total Iteration Time: 6.89273
Cumulative Model Updates: 181,547
Cumulative Timesteps: 1,374,948,176
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1374948176...
Checkpoint 1374948176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28086
Policy Entropy: 4.34564
Value Function Loss: 0.00245
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02441
Policy Update Magnitude: 0.89717
Value Function Update Magnitude: 0.70423
Collected Steps per Second: 13,107.78176
Overall Steps per Second: 7,324.02657
Timestep Collection Time: 3.81743
Timestep Consumption Time: 3.01461
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.83203
Cumulative Model Updates: 181,556
Cumulative Timesteps: 1,374,998,214
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.19645
Policy Entropy: 4.34733
Value Function Loss: 0.00250
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.91163
Value Function Update Magnitude: 0.70679
Collected Steps per Second: 13,162.76082
Overall Steps per Second: 7,050.46720
Timestep Collection Time: 3.79966
Timestep Consumption Time: 3.29406
PPO Batch Consumption Time: 0.24487
Total Iteration Time: 7.09371
Cumulative Model Updates: 181,565
Cumulative Timesteps: 1,375,048,228
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1375048228...
Checkpoint 1375048228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97697
Policy Entropy: 4.34527
Value Function Loss: 0.00244
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.90360
Value Function Update Magnitude: 0.72855
Collected Steps per Second: 13,212.30714
Overall Steps per Second: 7,308.97541
Timestep Collection Time: 3.78677
Timestep Consumption Time: 3.05851
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.84528
Cumulative Model Updates: 181,574
Cumulative Timesteps: 1,375,098,260
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.59213
Policy Entropy: 4.34752
Value Function Loss: 0.00242
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02372
Policy Update Magnitude: 0.89752
Value Function Update Magnitude: 0.68624
Collected Steps per Second: 13,523.93577
Overall Steps per Second: 7,360.76303
Timestep Collection Time: 3.69804
Timestep Consumption Time: 3.09637
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.79440
Cumulative Model Updates: 181,583
Cumulative Timesteps: 1,375,148,272
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1375148272...
Checkpoint 1375148272 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17678
Policy Entropy: 4.34630
Value Function Loss: 0.00245
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.90055
Value Function Update Magnitude: 0.71426
Collected Steps per Second: 13,367.99184
Overall Steps per Second: 7,289.61574
Timestep Collection Time: 3.74073
Timestep Consumption Time: 3.11917
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.85990
Cumulative Model Updates: 181,592
Cumulative Timesteps: 1,375,198,278
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.67888
Policy Entropy: 4.35027
Value Function Loss: 0.00245
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.90760
Value Function Update Magnitude: 0.73310
Collected Steps per Second: 13,182.90260
Overall Steps per Second: 7,286.92133
Timestep Collection Time: 3.79370
Timestep Consumption Time: 3.06955
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.86326
Cumulative Model Updates: 181,601
Cumulative Timesteps: 1,375,248,290
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1375248290...
Checkpoint 1375248290 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.53587
Policy Entropy: 4.35235
Value Function Loss: 0.00232
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.89296
Value Function Update Magnitude: 0.74826
Collected Steps per Second: 13,425.90902
Overall Steps per Second: 7,323.02065
Timestep Collection Time: 3.72727
Timestep Consumption Time: 3.10625
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.83352
Cumulative Model Updates: 181,610
Cumulative Timesteps: 1,375,298,332
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11375
Policy Entropy: 4.35356
Value Function Loss: 0.00244
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.90352
Value Function Update Magnitude: 0.73821
Collected Steps per Second: 13,425.01449
Overall Steps per Second: 7,304.30980
Timestep Collection Time: 3.72663
Timestep Consumption Time: 3.12276
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.84938
Cumulative Model Updates: 181,619
Cumulative Timesteps: 1,375,348,362
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1375348362...
Checkpoint 1375348362 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18009
Policy Entropy: 4.34987
Value Function Loss: 0.00253
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02278
Policy Update Magnitude: 0.92877
Value Function Update Magnitude: 0.73728
Collected Steps per Second: 13,096.75431
Overall Steps per Second: 7,214.32390
Timestep Collection Time: 3.81957
Timestep Consumption Time: 3.11441
PPO Batch Consumption Time: 0.23940
Total Iteration Time: 6.93398
Cumulative Model Updates: 181,628
Cumulative Timesteps: 1,375,398,386
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.16200
Policy Entropy: 4.34591
Value Function Loss: 0.00270
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.95108
Value Function Update Magnitude: 0.70343
Collected Steps per Second: 13,266.90018
Overall Steps per Second: 7,259.51243
Timestep Collection Time: 3.77089
Timestep Consumption Time: 3.12048
PPO Batch Consumption Time: 0.22938
Total Iteration Time: 6.89137
Cumulative Model Updates: 181,637
Cumulative Timesteps: 1,375,448,414
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1375448414...
Checkpoint 1375448414 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.00740
Policy Entropy: 4.34251
Value Function Loss: 0.00253
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.93794
Value Function Update Magnitude: 0.68340
Collected Steps per Second: 13,095.67450
Overall Steps per Second: 7,251.65694
Timestep Collection Time: 3.82096
Timestep Consumption Time: 3.07926
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.90022
Cumulative Model Updates: 181,646
Cumulative Timesteps: 1,375,498,452
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95756
Policy Entropy: 4.34541
Value Function Loss: 0.00247
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.91983
Value Function Update Magnitude: 0.70264
Collected Steps per Second: 13,628.41935
Overall Steps per Second: 7,365.49057
Timestep Collection Time: 3.66924
Timestep Consumption Time: 3.11998
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.78923
Cumulative Model Updates: 181,655
Cumulative Timesteps: 1,375,548,458
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1375548458...
Checkpoint 1375548458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.52670
Policy Entropy: 4.34756
Value Function Loss: 0.00254
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.92922
Value Function Update Magnitude: 0.72424
Collected Steps per Second: 13,303.09698
Overall Steps per Second: 7,255.60819
Timestep Collection Time: 3.76108
Timestep Consumption Time: 3.13483
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.89591
Cumulative Model Updates: 181,664
Cumulative Timesteps: 1,375,598,492
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.94977
Policy Entropy: 4.34838
Value Function Loss: 0.00254
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02390
Policy Update Magnitude: 0.92587
Value Function Update Magnitude: 0.75647
Collected Steps per Second: 13,252.66865
Overall Steps per Second: 7,293.20804
Timestep Collection Time: 3.77479
Timestep Consumption Time: 3.08447
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.85926
Cumulative Model Updates: 181,673
Cumulative Timesteps: 1,375,648,518
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1375648518...
Checkpoint 1375648518 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.25611
Policy Entropy: 4.34707
Value Function Loss: 0.00256
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.91855
Value Function Update Magnitude: 0.72277
Collected Steps per Second: 13,513.40253
Overall Steps per Second: 7,356.91335
Timestep Collection Time: 3.70166
Timestep Consumption Time: 3.09766
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.79932
Cumulative Model Updates: 181,682
Cumulative Timesteps: 1,375,698,540
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93608
Policy Entropy: 4.34671
Value Function Loss: 0.00254
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02814
Policy Update Magnitude: 0.93150
Value Function Update Magnitude: 0.76400
Collected Steps per Second: 13,350.24350
Overall Steps per Second: 7,130.91226
Timestep Collection Time: 3.74765
Timestep Consumption Time: 3.26857
PPO Batch Consumption Time: 0.24170
Total Iteration Time: 7.01621
Cumulative Model Updates: 181,691
Cumulative Timesteps: 1,375,748,572
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1375748572...
Checkpoint 1375748572 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.59209
Policy Entropy: 4.34784
Value Function Loss: 0.00249
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02871
Policy Update Magnitude: 0.94567
Value Function Update Magnitude: 0.76315
Collected Steps per Second: 13,285.75306
Overall Steps per Second: 7,371.23686
Timestep Collection Time: 3.76433
Timestep Consumption Time: 3.02042
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.78475
Cumulative Model Updates: 181,700
Cumulative Timesteps: 1,375,798,584
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57269
Policy Entropy: 4.34982
Value Function Loss: 0.00251
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.93182
Value Function Update Magnitude: 0.72196
Collected Steps per Second: 13,473.37670
Overall Steps per Second: 7,349.03335
Timestep Collection Time: 3.71176
Timestep Consumption Time: 3.09321
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.80498
Cumulative Model Updates: 181,709
Cumulative Timesteps: 1,375,848,594
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1375848594...
Checkpoint 1375848594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12158
Policy Entropy: 4.35091
Value Function Loss: 0.00256
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.93977
Value Function Update Magnitude: 0.71694
Collected Steps per Second: 13,189.13167
Overall Steps per Second: 7,293.31591
Timestep Collection Time: 3.79388
Timestep Consumption Time: 3.06692
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.86080
Cumulative Model Updates: 181,718
Cumulative Timesteps: 1,375,898,632
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.24722
Policy Entropy: 4.35237
Value Function Loss: 0.00235
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.91615
Value Function Update Magnitude: 0.72600
Collected Steps per Second: 13,254.29037
Overall Steps per Second: 7,375.67499
Timestep Collection Time: 3.77538
Timestep Consumption Time: 3.00908
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.78446
Cumulative Model Updates: 181,727
Cumulative Timesteps: 1,375,948,672
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1375948672...
Checkpoint 1375948672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75465
Policy Entropy: 4.35350
Value Function Loss: 0.00230
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.90676
Value Function Update Magnitude: 0.70797
Collected Steps per Second: 13,125.45754
Overall Steps per Second: 7,215.93934
Timestep Collection Time: 3.81198
Timestep Consumption Time: 3.12184
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.93382
Cumulative Model Updates: 181,736
Cumulative Timesteps: 1,375,998,706
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.84455
Policy Entropy: 4.35131
Value Function Loss: 0.00239
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02432
Policy Update Magnitude: 0.91410
Value Function Update Magnitude: 0.70880
Collected Steps per Second: 13,128.80021
Overall Steps per Second: 7,250.87222
Timestep Collection Time: 3.81040
Timestep Consumption Time: 3.08891
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.89931
Cumulative Model Updates: 181,745
Cumulative Timesteps: 1,376,048,732
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1376048732...
Checkpoint 1376048732 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81580
Policy Entropy: 4.35190
Value Function Loss: 0.00240
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.92715
Value Function Update Magnitude: 0.72094
Collected Steps per Second: 13,486.01777
Overall Steps per Second: 7,209.64446
Timestep Collection Time: 3.70888
Timestep Consumption Time: 3.22877
PPO Batch Consumption Time: 0.23878
Total Iteration Time: 6.93765
Cumulative Model Updates: 181,754
Cumulative Timesteps: 1,376,098,750
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81635
Policy Entropy: 4.35107
Value Function Loss: 0.00236
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02603
Policy Update Magnitude: 0.91642
Value Function Update Magnitude: 0.72564
Collected Steps per Second: 13,203.50668
Overall Steps per Second: 7,254.49273
Timestep Collection Time: 3.78975
Timestep Consumption Time: 3.10777
PPO Batch Consumption Time: 0.22784
Total Iteration Time: 6.89752
Cumulative Model Updates: 181,763
Cumulative Timesteps: 1,376,148,788
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1376148788...
Checkpoint 1376148788 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76182
Policy Entropy: 4.35254
Value Function Loss: 0.00234
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.91539
Value Function Update Magnitude: 0.72066
Collected Steps per Second: 13,222.81659
Overall Steps per Second: 7,306.63331
Timestep Collection Time: 3.78240
Timestep Consumption Time: 3.06261
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.84501
Cumulative Model Updates: 181,772
Cumulative Timesteps: 1,376,198,802
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01884
Policy Entropy: 4.35121
Value Function Loss: 0.00235
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.93245
Value Function Update Magnitude: 0.71646
Collected Steps per Second: 13,655.69549
Overall Steps per Second: 7,380.26200
Timestep Collection Time: 3.66221
Timestep Consumption Time: 3.11397
PPO Batch Consumption Time: 0.22771
Total Iteration Time: 6.77618
Cumulative Model Updates: 181,781
Cumulative Timesteps: 1,376,248,812
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1376248812...
Checkpoint 1376248812 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.94386
Policy Entropy: 4.34811
Value Function Loss: 0.00242
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.95281
Value Function Update Magnitude: 0.73370
Collected Steps per Second: 13,002.66859
Overall Steps per Second: 7,191.40613
Timestep Collection Time: 3.84552
Timestep Consumption Time: 3.10750
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.95302
Cumulative Model Updates: 181,790
Cumulative Timesteps: 1,376,298,814
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.75816
Policy Entropy: 4.34756
Value Function Loss: 0.00245
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.95176
Value Function Update Magnitude: 0.72104
Collected Steps per Second: 13,267.70411
Overall Steps per Second: 7,377.56862
Timestep Collection Time: 3.76991
Timestep Consumption Time: 3.00983
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.77974
Cumulative Model Updates: 181,799
Cumulative Timesteps: 1,376,348,832
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1376348832...
Checkpoint 1376348832 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.48223
Policy Entropy: 4.34420
Value Function Loss: 0.00278
Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02646
Policy Update Magnitude: 0.96494
Value Function Update Magnitude: 0.80869
Collected Steps per Second: 13,135.43680
Overall Steps per Second: 7,222.03304
Timestep Collection Time: 3.80665
Timestep Consumption Time: 3.11689
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.92354
Cumulative Model Updates: 181,808
Cumulative Timesteps: 1,376,398,834
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08675
Policy Entropy: 4.34546
Value Function Loss: 0.00276
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.98628
Value Function Update Magnitude: 0.81287
Collected Steps per Second: 13,221.96350
Overall Steps per Second: 7,209.77539
Timestep Collection Time: 3.78159
Timestep Consumption Time: 3.15344
PPO Batch Consumption Time: 0.23508
Total Iteration Time: 6.93503
Cumulative Model Updates: 181,817
Cumulative Timesteps: 1,376,448,834
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1376448834...
Checkpoint 1376448834 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75577
Policy Entropy: 4.34820
Value Function Loss: 0.00265
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.96343
Value Function Update Magnitude: 0.80664
Collected Steps per Second: 13,099.66801
Overall Steps per Second: 7,322.01197
Timestep Collection Time: 3.81704
Timestep Consumption Time: 3.01195
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.82900
Cumulative Model Updates: 181,826
Cumulative Timesteps: 1,376,498,836
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.00219
Policy Entropy: 4.35115
Value Function Loss: 0.00238
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.91603
Value Function Update Magnitude: 0.73517
Collected Steps per Second: 13,176.93633
Overall Steps per Second: 7,239.83089
Timestep Collection Time: 3.79709
Timestep Consumption Time: 3.11385
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.91093
Cumulative Model Updates: 181,835
Cumulative Timesteps: 1,376,548,870
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1376548870...
Checkpoint 1376548870 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.45008
Policy Entropy: 4.35174
Value Function Loss: 0.00236
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.92594
Value Function Update Magnitude: 0.75152
Collected Steps per Second: 13,037.70399
Overall Steps per Second: 7,249.09201
Timestep Collection Time: 3.83779
Timestep Consumption Time: 3.06459
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.90238
Cumulative Model Updates: 181,844
Cumulative Timesteps: 1,376,598,906
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28782
Policy Entropy: 4.34999
Value Function Loss: 0.00249
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.95436
Value Function Update Magnitude: 0.70115
Collected Steps per Second: 13,665.71114
Overall Steps per Second: 7,382.68178
Timestep Collection Time: 3.65909
Timestep Consumption Time: 3.11406
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.77315
Cumulative Model Updates: 181,853
Cumulative Timesteps: 1,376,648,910
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1376648910...
Checkpoint 1376648910 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90496
Policy Entropy: 4.35303
Value Function Loss: 0.00240
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02235
Policy Update Magnitude: 0.93075
Value Function Update Magnitude: 0.69161
Collected Steps per Second: 13,154.59234
Overall Steps per Second: 7,243.96924
Timestep Collection Time: 3.80187
Timestep Consumption Time: 3.10208
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.90395
Cumulative Model Updates: 181,862
Cumulative Timesteps: 1,376,698,922
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.48952
Policy Entropy: 4.35156
Value Function Loss: 0.00240
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.91729
Value Function Update Magnitude: 0.66764
Collected Steps per Second: 13,229.00295
Overall Steps per Second: 7,296.02227
Timestep Collection Time: 3.77988
Timestep Consumption Time: 3.07372
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.85360
Cumulative Model Updates: 181,871
Cumulative Timesteps: 1,376,748,926
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1376748926...
Checkpoint 1376748926 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30803
Policy Entropy: 4.35262
Value Function Loss: 0.00233
Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01988
Policy Update Magnitude: 0.92128
Value Function Update Magnitude: 0.65681
Collected Steps per Second: 13,459.98098
Overall Steps per Second: 7,237.28471
Timestep Collection Time: 3.71605
Timestep Consumption Time: 3.19510
PPO Batch Consumption Time: 0.23580
Total Iteration Time: 6.91116
Cumulative Model Updates: 181,880
Cumulative Timesteps: 1,376,798,944
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.44900
Policy Entropy: 4.35115
Value Function Loss: 0.00244
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.92909
Value Function Update Magnitude: 0.62066
Collected Steps per Second: 13,282.81913
Overall Steps per Second: 7,276.52099
Timestep Collection Time: 3.76501
Timestep Consumption Time: 3.10778
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.87279
Cumulative Model Updates: 181,889
Cumulative Timesteps: 1,376,848,954
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1376848954...
Checkpoint 1376848954 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38591
Policy Entropy: 4.34657
Value Function Loss: 0.00251
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.94000
Value Function Update Magnitude: 0.67782
Collected Steps per Second: 13,317.05516
Overall Steps per Second: 7,385.82575
Timestep Collection Time: 3.75669
Timestep Consumption Time: 3.01683
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.77351
Cumulative Model Updates: 181,898
Cumulative Timesteps: 1,376,898,982
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.93442
Policy Entropy: 4.34992
Value Function Loss: 0.00241
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.94441
Value Function Update Magnitude: 0.71235
Collected Steps per Second: 13,209.20837
Overall Steps per Second: 7,247.50024
Timestep Collection Time: 3.78857
Timestep Consumption Time: 3.11643
PPO Batch Consumption Time: 0.22770
Total Iteration Time: 6.90500
Cumulative Model Updates: 181,907
Cumulative Timesteps: 1,376,949,026
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1376949026...
Checkpoint 1376949026 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61239
Policy Entropy: 4.34905
Value Function Loss: 0.00247
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.94584
Value Function Update Magnitude: 0.71723
Collected Steps per Second: 13,245.63350
Overall Steps per Second: 7,270.53150
Timestep Collection Time: 3.77679
Timestep Consumption Time: 3.10386
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.88065
Cumulative Model Updates: 181,916
Cumulative Timesteps: 1,376,999,052
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.20043
Policy Entropy: 4.34979
Value Function Loss: 0.00253
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02207
Policy Update Magnitude: 0.94580
Value Function Update Magnitude: 0.73125
Collected Steps per Second: 13,560.31579
Overall Steps per Second: 7,354.73346
Timestep Collection Time: 3.68811
Timestep Consumption Time: 3.11186
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.79997
Cumulative Model Updates: 181,925
Cumulative Timesteps: 1,377,049,064
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1377049064...
Checkpoint 1377049064 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.58947
Policy Entropy: 4.34957
Value Function Loss: 0.00254
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.93529
Value Function Update Magnitude: 0.70573
Collected Steps per Second: 13,251.66508
Overall Steps per Second: 7,252.29032
Timestep Collection Time: 3.77402
Timestep Consumption Time: 3.12201
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.89603
Cumulative Model Updates: 181,934
Cumulative Timesteps: 1,377,099,076
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88067
Policy Entropy: 4.34484
Value Function Loss: 0.00253
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.92322
Value Function Update Magnitude: 0.69278
Collected Steps per Second: 13,119.07539
Overall Steps per Second: 7,109.52967
Timestep Collection Time: 3.81216
Timestep Consumption Time: 3.22234
PPO Batch Consumption Time: 0.23938
Total Iteration Time: 7.03450
Cumulative Model Updates: 181,943
Cumulative Timesteps: 1,377,149,088
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1377149088...
Checkpoint 1377149088 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.86630
Policy Entropy: 4.34875
Value Function Loss: 0.00241
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.92010
Value Function Update Magnitude: 0.69154
Collected Steps per Second: 13,499.98371
Overall Steps per Second: 7,349.68922
Timestep Collection Time: 3.70563
Timestep Consumption Time: 3.10091
PPO Batch Consumption Time: 0.22773
Total Iteration Time: 6.80655
Cumulative Model Updates: 181,952
Cumulative Timesteps: 1,377,199,114
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75400
Policy Entropy: 4.34556
Value Function Loss: 0.00245
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.92755
Value Function Update Magnitude: 0.69892
Collected Steps per Second: 13,166.36868
Overall Steps per Second: 7,254.77290
Timestep Collection Time: 3.79755
Timestep Consumption Time: 3.09446
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.89201
Cumulative Model Updates: 181,961
Cumulative Timesteps: 1,377,249,114
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1377249114...
Checkpoint 1377249114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.40477
Policy Entropy: 4.34716
Value Function Loss: 0.00246
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.94867
Value Function Update Magnitude: 0.70538
Collected Steps per Second: 13,225.84589
Overall Steps per Second: 7,372.88841
Timestep Collection Time: 3.78259
Timestep Consumption Time: 3.00281
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.78540
Cumulative Model Updates: 181,970
Cumulative Timesteps: 1,377,299,142
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16189
Policy Entropy: 4.34695
Value Function Loss: 0.00243
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.91905
Value Function Update Magnitude: 0.70445
Collected Steps per Second: 13,185.30126
Overall Steps per Second: 7,257.60909
Timestep Collection Time: 3.79256
Timestep Consumption Time: 3.09759
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.89015
Cumulative Model Updates: 181,979
Cumulative Timesteps: 1,377,349,148
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1377349148...
Checkpoint 1377349148 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39606
Policy Entropy: 4.34873
Value Function Loss: 0.00233
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.90362
Value Function Update Magnitude: 0.75688
Collected Steps per Second: 13,158.96145
Overall Steps per Second: 7,275.06465
Timestep Collection Time: 3.80288
Timestep Consumption Time: 3.07568
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.87856
Cumulative Model Updates: 181,988
Cumulative Timesteps: 1,377,399,190
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16210
Policy Entropy: 4.35017
Value Function Loss: 0.00220
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.89538
Value Function Update Magnitude: 0.73292
Collected Steps per Second: 13,217.67266
Overall Steps per Second: 7,367.94635
Timestep Collection Time: 3.78387
Timestep Consumption Time: 3.00418
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.78805
Cumulative Model Updates: 181,997
Cumulative Timesteps: 1,377,449,204
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1377449204...
Checkpoint 1377449204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.98261
Policy Entropy: 4.35021
Value Function Loss: 0.00231
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02268
Policy Update Magnitude: 0.91435
Value Function Update Magnitude: 0.77879
Collected Steps per Second: 13,302.01002
Overall Steps per Second: 7,066.88687
Timestep Collection Time: 3.75988
Timestep Consumption Time: 3.31735
PPO Batch Consumption Time: 0.24226
Total Iteration Time: 7.07723
Cumulative Model Updates: 182,006
Cumulative Timesteps: 1,377,499,218
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.83192
Policy Entropy: 4.34921
Value Function Loss: 0.00241
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.92917
Value Function Update Magnitude: 0.77495
Collected Steps per Second: 13,166.64778
Overall Steps per Second: 7,282.85772
Timestep Collection Time: 3.79763
Timestep Consumption Time: 3.06809
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.86571
Cumulative Model Updates: 182,015
Cumulative Timesteps: 1,377,549,220
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1377549220...
Checkpoint 1377549220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34509
Policy Entropy: 4.35091
Value Function Loss: 0.00227
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.91311
Value Function Update Magnitude: 0.69890
Collected Steps per Second: 13,603.87518
Overall Steps per Second: 7,382.30015
Timestep Collection Time: 3.67704
Timestep Consumption Time: 3.09890
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.77594
Cumulative Model Updates: 182,024
Cumulative Timesteps: 1,377,599,242
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95272
Policy Entropy: 4.35141
Value Function Loss: 0.00239
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.91363
Value Function Update Magnitude: 0.68722
Collected Steps per Second: 13,090.73609
Overall Steps per Second: 7,219.64427
Timestep Collection Time: 3.81965
Timestep Consumption Time: 3.10618
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.92583
Cumulative Model Updates: 182,033
Cumulative Timesteps: 1,377,649,244
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1377649244...
Checkpoint 1377649244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41935
Policy Entropy: 4.35120
Value Function Loss: 0.00233
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.91062
Value Function Update Magnitude: 0.72606
Collected Steps per Second: 13,066.35785
Overall Steps per Second: 7,245.63165
Timestep Collection Time: 3.82815
Timestep Consumption Time: 3.07532
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.90347
Cumulative Model Updates: 182,042
Cumulative Timesteps: 1,377,699,264
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.25241
Policy Entropy: 4.34967
Value Function Loss: 0.00242
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.92925
Value Function Update Magnitude: 0.72483
Collected Steps per Second: 13,705.21160
Overall Steps per Second: 7,402.79397
Timestep Collection Time: 3.65014
Timestep Consumption Time: 3.10757
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.75772
Cumulative Model Updates: 182,051
Cumulative Timesteps: 1,377,749,290
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1377749290...
Checkpoint 1377749290 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.24656
Policy Entropy: 4.35068
Value Function Loss: 0.00224
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02409
Policy Update Magnitude: 0.90185
Value Function Update Magnitude: 0.70195
Collected Steps per Second: 13,360.58706
Overall Steps per Second: 7,292.25326
Timestep Collection Time: 3.74549
Timestep Consumption Time: 3.11686
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.86235
Cumulative Model Updates: 182,060
Cumulative Timesteps: 1,377,799,332
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.60186
Policy Entropy: 4.35080
Value Function Loss: 0.00226
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02408
Policy Update Magnitude: 0.91107
Value Function Update Magnitude: 0.70696
Collected Steps per Second: 13,279.03499
Overall Steps per Second: 7,157.89243
Timestep Collection Time: 3.76699
Timestep Consumption Time: 3.22138
PPO Batch Consumption Time: 0.24595
Total Iteration Time: 6.98837
Cumulative Model Updates: 182,069
Cumulative Timesteps: 1,377,849,354
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1377849354...
Checkpoint 1377849354 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.14197
Policy Entropy: 4.35183
Value Function Loss: 0.00209
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.88880
Value Function Update Magnitude: 0.70234
Collected Steps per Second: 13,263.71869
Overall Steps per Second: 7,255.02174
Timestep Collection Time: 3.77179
Timestep Consumption Time: 3.12384
PPO Batch Consumption Time: 0.22926
Total Iteration Time: 6.89564
Cumulative Model Updates: 182,078
Cumulative Timesteps: 1,377,899,382
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.63849
Policy Entropy: 4.35516
Value Function Loss: 0.00213
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.86703
Value Function Update Magnitude: 0.69651
Collected Steps per Second: 13,272.08474
Overall Steps per Second: 7,349.38047
Timestep Collection Time: 3.77047
Timestep Consumption Time: 3.03854
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.80901
Cumulative Model Updates: 182,087
Cumulative Timesteps: 1,377,949,424
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1377949424...
Checkpoint 1377949424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.40909
Policy Entropy: 4.35926
Value Function Loss: 0.00229
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.87563
Value Function Update Magnitude: 0.71180
Collected Steps per Second: 13,348.82184
Overall Steps per Second: 7,413.24906
Timestep Collection Time: 3.74790
Timestep Consumption Time: 3.00083
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.74873
Cumulative Model Updates: 182,096
Cumulative Timesteps: 1,377,999,454
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.70537
Policy Entropy: 4.35550
Value Function Loss: 0.00250
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.92462
Value Function Update Magnitude: 0.73771
Collected Steps per Second: 13,231.26494
Overall Steps per Second: 7,254.27598
Timestep Collection Time: 3.78029
Timestep Consumption Time: 3.11468
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.89497
Cumulative Model Updates: 182,105
Cumulative Timesteps: 1,378,049,472
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1378049472...
Checkpoint 1378049472 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30092
Policy Entropy: 4.35152
Value Function Loss: 0.00267
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.95499
Value Function Update Magnitude: 0.75958
Collected Steps per Second: 13,159.19085
Overall Steps per Second: 7,268.17172
Timestep Collection Time: 3.80084
Timestep Consumption Time: 3.08067
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.88151
Cumulative Model Updates: 182,114
Cumulative Timesteps: 1,378,099,488
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05669
Policy Entropy: 4.34832
Value Function Loss: 0.00256
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02631
Policy Update Magnitude: 0.95194
Value Function Update Magnitude: 0.80015
Collected Steps per Second: 13,429.24706
Overall Steps per Second: 7,324.88230
Timestep Collection Time: 3.72411
Timestep Consumption Time: 3.10358
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.82769
Cumulative Model Updates: 182,123
Cumulative Timesteps: 1,378,149,500
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1378149500...
Checkpoint 1378149500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.43518
Policy Entropy: 4.34882
Value Function Loss: 0.00245
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02594
Policy Update Magnitude: 0.92285
Value Function Update Magnitude: 0.74614
Collected Steps per Second: 13,165.51140
Overall Steps per Second: 7,107.47647
Timestep Collection Time: 3.79932
Timestep Consumption Time: 3.23834
PPO Batch Consumption Time: 0.23675
Total Iteration Time: 7.03766
Cumulative Model Updates: 182,132
Cumulative Timesteps: 1,378,199,520
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.83885
Policy Entropy: 4.34805
Value Function Loss: 0.00253
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.91358
Value Function Update Magnitude: 0.76175
Collected Steps per Second: 13,302.95309
Overall Steps per Second: 7,383.22073
Timestep Collection Time: 3.75871
Timestep Consumption Time: 3.01367
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.77238
Cumulative Model Updates: 182,141
Cumulative Timesteps: 1,378,249,522
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1378249522...
Checkpoint 1378249522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89850
Policy Entropy: 4.34801
Value Function Loss: 0.00250
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.92970
Value Function Update Magnitude: 0.73546
Collected Steps per Second: 13,170.52113
Overall Steps per Second: 7,243.27442
Timestep Collection Time: 3.79833
Timestep Consumption Time: 3.10821
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.90654
Cumulative Model Updates: 182,150
Cumulative Timesteps: 1,378,299,548
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.37280
Policy Entropy: 4.34608
Value Function Loss: 0.00262
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.95218
Value Function Update Magnitude: 0.76174
Collected Steps per Second: 13,244.01791
Overall Steps per Second: 7,289.03923
Timestep Collection Time: 3.77831
Timestep Consumption Time: 3.08679
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.86510
Cumulative Model Updates: 182,159
Cumulative Timesteps: 1,378,349,588
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1378349588...
Checkpoint 1378349588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.18411
Policy Entropy: 4.34810
Value Function Loss: 0.00251
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02628
Policy Update Magnitude: 0.93894
Value Function Update Magnitude: 0.73738
Collected Steps per Second: 13,506.13564
Overall Steps per Second: 7,373.40819
Timestep Collection Time: 3.70483
Timestep Consumption Time: 3.08144
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.78628
Cumulative Model Updates: 182,168
Cumulative Timesteps: 1,378,399,626
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.39083
Policy Entropy: 4.34744
Value Function Loss: 0.00255
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.93880
Value Function Update Magnitude: 0.71943
Collected Steps per Second: 13,280.32216
Overall Steps per Second: 7,306.58362
Timestep Collection Time: 3.76572
Timestep Consumption Time: 3.07879
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.84451
Cumulative Model Updates: 182,177
Cumulative Timesteps: 1,378,449,636
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1378449636...
Checkpoint 1378449636 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74778
Policy Entropy: 4.35122
Value Function Loss: 0.00232
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.90130
Value Function Update Magnitude: 0.71367
Collected Steps per Second: 13,326.42495
Overall Steps per Second: 7,313.25694
Timestep Collection Time: 3.75525
Timestep Consumption Time: 3.08767
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.84292
Cumulative Model Updates: 182,186
Cumulative Timesteps: 1,378,499,680
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.21631
Policy Entropy: 4.35091
Value Function Loss: 0.00232
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.87356
Value Function Update Magnitude: 0.70163
Collected Steps per Second: 13,484.76800
Overall Steps per Second: 7,256.47815
Timestep Collection Time: 3.70982
Timestep Consumption Time: 3.18416
PPO Batch Consumption Time: 0.23481
Total Iteration Time: 6.89398
Cumulative Model Updates: 182,195
Cumulative Timesteps: 1,378,549,706
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1378549706...
Checkpoint 1378549706 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.04565
Policy Entropy: 4.34767
Value Function Loss: 0.00248
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.90753
Value Function Update Magnitude: 0.72141
Collected Steps per Second: 13,309.65989
Overall Steps per Second: 7,225.08466
Timestep Collection Time: 3.75847
Timestep Consumption Time: 3.16518
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.92366
Cumulative Model Updates: 182,204
Cumulative Timesteps: 1,378,599,730
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18662
Policy Entropy: 4.34371
Value Function Loss: 0.00251
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.92823
Value Function Update Magnitude: 0.72917
Collected Steps per Second: 13,166.59159
Overall Steps per Second: 7,368.52454
Timestep Collection Time: 3.80068
Timestep Consumption Time: 2.99064
PPO Batch Consumption Time: 0.22770
Total Iteration Time: 6.79132
Cumulative Model Updates: 182,213
Cumulative Timesteps: 1,378,649,772
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1378649772...
Checkpoint 1378649772 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73099
Policy Entropy: 4.34408
Value Function Loss: 0.00264
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.92152
Value Function Update Magnitude: 0.70079
Collected Steps per Second: 13,439.91400
Overall Steps per Second: 7,330.69723
Timestep Collection Time: 3.72309
Timestep Consumption Time: 3.10273
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.82582
Cumulative Model Updates: 182,222
Cumulative Timesteps: 1,378,699,810
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.38500
Policy Entropy: 4.34630
Value Function Loss: 0.00275
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.95923
Value Function Update Magnitude: 0.74706
Collected Steps per Second: 13,209.99987
Overall Steps per Second: 7,300.22702
Timestep Collection Time: 3.78743
Timestep Consumption Time: 3.06605
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.85349
Cumulative Model Updates: 182,231
Cumulative Timesteps: 1,378,749,842
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1378749842...
Checkpoint 1378749842 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.67341
Policy Entropy: 4.34531
Value Function Loss: 0.00276
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.95762
Value Function Update Magnitude: 0.76021
Collected Steps per Second: 13,124.19706
Overall Steps per Second: 7,321.37130
Timestep Collection Time: 3.81098
Timestep Consumption Time: 3.02053
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.83151
Cumulative Model Updates: 182,240
Cumulative Timesteps: 1,378,799,858
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03735
Policy Entropy: 4.34508
Value Function Loss: 0.00262
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02786
Policy Update Magnitude: 0.93570
Value Function Update Magnitude: 0.77182
Collected Steps per Second: 13,287.84064
Overall Steps per Second: 7,260.95185
Timestep Collection Time: 3.76480
Timestep Consumption Time: 3.12493
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.88973
Cumulative Model Updates: 182,249
Cumulative Timesteps: 1,378,849,884
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1378849884...
Checkpoint 1378849884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97194
Policy Entropy: 4.34581
Value Function Loss: 0.00254
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.92095
Value Function Update Magnitude: 0.80332
Collected Steps per Second: 13,195.67222
Overall Steps per Second: 7,081.95921
Timestep Collection Time: 3.79170
Timestep Consumption Time: 3.27330
PPO Batch Consumption Time: 0.24546
Total Iteration Time: 7.06499
Cumulative Model Updates: 182,258
Cumulative Timesteps: 1,378,899,918
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85301
Policy Entropy: 4.35103
Value Function Loss: 0.00247
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.92647
Value Function Update Magnitude: 0.80262
Collected Steps per Second: 13,250.89532
Overall Steps per Second: 7,266.88191
Timestep Collection Time: 3.77590
Timestep Consumption Time: 3.10931
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.88521
Cumulative Model Updates: 182,267
Cumulative Timesteps: 1,378,949,952
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1378949952...
Checkpoint 1378949952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65209
Policy Entropy: 4.35310
Value Function Loss: 0.00252
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.92903
Value Function Update Magnitude: 0.83391
Collected Steps per Second: 13,285.59463
Overall Steps per Second: 7,257.91538
Timestep Collection Time: 3.76558
Timestep Consumption Time: 3.12731
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.89289
Cumulative Model Updates: 182,276
Cumulative Timesteps: 1,378,999,980
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.23561
Policy Entropy: 4.35319
Value Function Loss: 0.00255
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02470
Policy Update Magnitude: 0.91592
Value Function Update Magnitude: 0.79642
Collected Steps per Second: 13,385.68072
Overall Steps per Second: 7,338.79717
Timestep Collection Time: 3.73787
Timestep Consumption Time: 3.07986
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.81774
Cumulative Model Updates: 182,285
Cumulative Timesteps: 1,379,050,014
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1379050014...
Checkpoint 1379050014 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88275
Policy Entropy: 4.35063
Value Function Loss: 0.00257
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.92846
Value Function Update Magnitude: 0.75758
Collected Steps per Second: 13,605.86679
Overall Steps per Second: 7,385.26553
Timestep Collection Time: 3.67518
Timestep Consumption Time: 3.09560
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.77078
Cumulative Model Updates: 182,294
Cumulative Timesteps: 1,379,100,018
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87358
Policy Entropy: 4.34792
Value Function Loss: 0.00247
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.92465
Value Function Update Magnitude: 0.76030
Collected Steps per Second: 13,168.44741
Overall Steps per Second: 7,262.02356
Timestep Collection Time: 3.79787
Timestep Consumption Time: 3.08892
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.88679
Cumulative Model Updates: 182,303
Cumulative Timesteps: 1,379,150,030
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1379150030...
Checkpoint 1379150030 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33118
Policy Entropy: 4.34683
Value Function Loss: 0.00233
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.90684
Value Function Update Magnitude: 0.73148
Collected Steps per Second: 13,079.86324
Overall Steps per Second: 7,304.89015
Timestep Collection Time: 3.82405
Timestep Consumption Time: 3.02315
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.84719
Cumulative Model Updates: 182,312
Cumulative Timesteps: 1,379,200,048
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77292
Policy Entropy: 4.34868
Value Function Loss: 0.00227
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.88818
Value Function Update Magnitude: 0.73436
Collected Steps per Second: 13,303.10101
Overall Steps per Second: 7,219.39914
Timestep Collection Time: 3.76123
Timestep Consumption Time: 3.16954
PPO Batch Consumption Time: 0.23426
Total Iteration Time: 6.93077
Cumulative Model Updates: 182,321
Cumulative Timesteps: 1,379,250,084
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1379250084...
Checkpoint 1379250084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87718
Policy Entropy: 4.34954
Value Function Loss: 0.00241
Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02132
Policy Update Magnitude: 0.89826
Value Function Update Magnitude: 0.74506
Collected Steps per Second: 13,158.04362
Overall Steps per Second: 7,268.50537
Timestep Collection Time: 3.80011
Timestep Consumption Time: 3.07916
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.87927
Cumulative Model Updates: 182,330
Cumulative Timesteps: 1,379,300,086
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44041
Policy Entropy: 4.35020
Value Function Loss: 0.00248
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.91721
Value Function Update Magnitude: 0.78868
Collected Steps per Second: 13,372.88975
Overall Steps per Second: 7,304.82649
Timestep Collection Time: 3.74324
Timestep Consumption Time: 3.10948
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.85273
Cumulative Model Updates: 182,339
Cumulative Timesteps: 1,379,350,144
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 1379350144...
Checkpoint 1379350144 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80671
Policy Entropy: 4.34920
Value Function Loss: 0.00246
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.91900
Value Function Update Magnitude: 0.76194
Collected Steps per Second: 13,335.45625
Overall Steps per Second: 7,286.66337
Timestep Collection Time: 3.74955
Timestep Consumption Time: 3.11257
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.86213
Cumulative Model Updates: 182,348
Cumulative Timesteps: 1,379,400,146
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96532
Policy Entropy: 4.34622
Value Function Loss: 0.00251
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.92046
Value Function Update Magnitude: 0.73803
Collected Steps per Second: 13,334.14007
Overall Steps per Second: 7,330.55356
Timestep Collection Time: 3.75172
Timestep Consumption Time: 3.07259
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.82431
Cumulative Model Updates: 182,357
Cumulative Timesteps: 1,379,450,172
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1379450172...
Checkpoint 1379450172 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72076
Policy Entropy: 4.34515
Value Function Loss: 0.00257
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.93572
Value Function Update Magnitude: 0.74873
Collected Steps per Second: 13,509.42917
Overall Steps per Second: 7,349.85487
Timestep Collection Time: 3.70201
Timestep Consumption Time: 3.10248
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.80449
Cumulative Model Updates: 182,366
Cumulative Timesteps: 1,379,500,184
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.76271
Policy Entropy: 4.34454
Value Function Loss: 0.00254
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.93015
Value Function Update Magnitude: 0.73917
Collected Steps per Second: 13,220.33384
Overall Steps per Second: 7,258.41055
Timestep Collection Time: 3.78251
Timestep Consumption Time: 3.10688
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.88939
Cumulative Model Updates: 182,375
Cumulative Timesteps: 1,379,550,190
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1379550190...
Checkpoint 1379550190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.63845
Policy Entropy: 4.34261
Value Function Loss: 0.00252
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02479
Policy Update Magnitude: 0.94081
Value Function Update Magnitude: 0.71943
Collected Steps per Second: 12,998.76755
Overall Steps per Second: 7,101.50860
Timestep Collection Time: 3.84852
Timestep Consumption Time: 3.19590
PPO Batch Consumption Time: 0.24530
Total Iteration Time: 7.04442
Cumulative Model Updates: 182,384
Cumulative Timesteps: 1,379,600,216
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.48160
Policy Entropy: 4.34385
Value Function Loss: 0.00255
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.94672
Value Function Update Magnitude: 0.71581
Collected Steps per Second: 13,435.88002
Overall Steps per Second: 7,335.46399
Timestep Collection Time: 3.72227
Timestep Consumption Time: 3.09557
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.81784
Cumulative Model Updates: 182,393
Cumulative Timesteps: 1,379,650,228
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1379650228...
Checkpoint 1379650228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.15728
Policy Entropy: 4.34144
Value Function Loss: 0.00284
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.98036
Value Function Update Magnitude: 0.72433
Collected Steps per Second: 13,102.77554
Overall Steps per Second: 7,237.04326
Timestep Collection Time: 3.81797
Timestep Consumption Time: 3.09452
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.91249
Cumulative Model Updates: 182,402
Cumulative Timesteps: 1,379,700,254
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.26114
Policy Entropy: 4.34281
Value Function Loss: 0.00269
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.95990
Value Function Update Magnitude: 0.72523
Collected Steps per Second: 13,132.91138
Overall Steps per Second: 7,335.65186
Timestep Collection Time: 3.80890
Timestep Consumption Time: 3.01012
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.81903
Cumulative Model Updates: 182,411
Cumulative Timesteps: 1,379,750,276
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1379750276...
Checkpoint 1379750276 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.98751
Policy Entropy: 4.34310
Value Function Loss: 0.00254
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.93326
Value Function Update Magnitude: 0.68094
Collected Steps per Second: 13,273.85228
Overall Steps per Second: 7,263.24537
Timestep Collection Time: 3.76741
Timestep Consumption Time: 3.11767
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.88508
Cumulative Model Updates: 182,420
Cumulative Timesteps: 1,379,800,284
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.67193
Policy Entropy: 4.34638
Value Function Loss: 0.00243
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.90271
Value Function Update Magnitude: 0.66671
Collected Steps per Second: 13,358.03858
Overall Steps per Second: 7,341.21973
Timestep Collection Time: 3.74306
Timestep Consumption Time: 3.06779
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.81086
Cumulative Model Updates: 182,429
Cumulative Timesteps: 1,379,850,284
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1379850284...
Checkpoint 1379850284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.58460
Policy Entropy: 4.34579
Value Function Loss: 0.00255
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02506
Policy Update Magnitude: 0.92290
Value Function Update Magnitude: 0.70160
Collected Steps per Second: 13,462.63352
Overall Steps per Second: 7,332.90223
Timestep Collection Time: 3.71651
Timestep Consumption Time: 3.10671
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.82322
Cumulative Model Updates: 182,438
Cumulative Timesteps: 1,379,900,318
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.23916
Policy Entropy: 4.34632
Value Function Loss: 0.00256
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.92647
Value Function Update Magnitude: 0.72019
Collected Steps per Second: 13,197.00786
Overall Steps per Second: 7,127.29376
Timestep Collection Time: 3.79116
Timestep Consumption Time: 3.22861
PPO Batch Consumption Time: 0.23780
Total Iteration Time: 7.01978
Cumulative Model Updates: 182,447
Cumulative Timesteps: 1,379,950,350
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1379950350...
Checkpoint 1379950350 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49584
Policy Entropy: 4.34314
Value Function Loss: 0.00266
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.92083
Value Function Update Magnitude: 0.70909
Collected Steps per Second: 13,235.50424
Overall Steps per Second: 7,359.23737
Timestep Collection Time: 3.77938
Timestep Consumption Time: 3.01779
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.79717
Cumulative Model Updates: 182,456
Cumulative Timesteps: 1,380,000,372
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56814
Policy Entropy: 4.34379
Value Function Loss: 0.00264
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.93104
Value Function Update Magnitude: 0.72716
Collected Steps per Second: 13,243.18356
Overall Steps per Second: 7,266.21636
Timestep Collection Time: 3.77825
Timestep Consumption Time: 3.10787
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.88611
Cumulative Model Updates: 182,465
Cumulative Timesteps: 1,380,050,408
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1380050408...
Checkpoint 1380050408 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87899
Policy Entropy: 4.34278
Value Function Loss: 0.00254
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02613
Policy Update Magnitude: 0.92663
Value Function Update Magnitude: 0.71868
Collected Steps per Second: 13,355.53383
Overall Steps per Second: 7,307.81065
Timestep Collection Time: 3.74646
Timestep Consumption Time: 3.10046
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.84692
Cumulative Model Updates: 182,474
Cumulative Timesteps: 1,380,100,444
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.60282
Policy Entropy: 4.34660
Value Function Loss: 0.00254
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.93190
Value Function Update Magnitude: 0.73623
Collected Steps per Second: 13,207.83156
Overall Steps per Second: 7,373.12252
Timestep Collection Time: 3.78760
Timestep Consumption Time: 2.99731
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.78491
Cumulative Model Updates: 182,483
Cumulative Timesteps: 1,380,150,470
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1380150470...
Checkpoint 1380150470 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.15909
Policy Entropy: 4.34783
Value Function Loss: 0.00252
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.93972
Value Function Update Magnitude: 0.79330
Collected Steps per Second: 13,304.55058
Overall Steps per Second: 7,298.27221
Timestep Collection Time: 3.76142
Timestep Consumption Time: 3.09555
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.85697
Cumulative Model Updates: 182,492
Cumulative Timesteps: 1,380,200,514
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90854
Policy Entropy: 4.34760
Value Function Loss: 0.00257
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.92911
Value Function Update Magnitude: 0.77878
Collected Steps per Second: 13,252.75347
Overall Steps per Second: 7,302.26174
Timestep Collection Time: 3.77552
Timestep Consumption Time: 3.07661
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.85212
Cumulative Model Updates: 182,501
Cumulative Timesteps: 1,380,250,550
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1380250550...
Checkpoint 1380250550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.08075
Policy Entropy: 4.34891
Value Function Loss: 0.00257
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02909
Policy Update Magnitude: 0.92452
Value Function Update Magnitude: 0.77167
Collected Steps per Second: 13,141.97282
Overall Steps per Second: 7,185.29467
Timestep Collection Time: 3.80673
Timestep Consumption Time: 3.15582
PPO Batch Consumption Time: 0.24012
Total Iteration Time: 6.96255
Cumulative Model Updates: 182,510
Cumulative Timesteps: 1,380,300,578
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01472
Policy Entropy: 4.34913
Value Function Loss: 0.00258
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.93956
Value Function Update Magnitude: 0.76682
Collected Steps per Second: 13,316.48747
Overall Steps per Second: 7,272.37367
Timestep Collection Time: 3.75610
Timestep Consumption Time: 3.12171
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.87781
Cumulative Model Updates: 182,519
Cumulative Timesteps: 1,380,350,596
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1380350596...
Checkpoint 1380350596 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.10665
Policy Entropy: 4.34791
Value Function Loss: 0.00255
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.93185
Value Function Update Magnitude: 0.80937
Collected Steps per Second: 13,188.33635
Overall Steps per Second: 7,295.46697
Timestep Collection Time: 3.79199
Timestep Consumption Time: 3.06295
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.85494
Cumulative Model Updates: 182,528
Cumulative Timesteps: 1,380,400,606
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62942
Policy Entropy: 4.34589
Value Function Loss: 0.00261
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.93973
Value Function Update Magnitude: 0.82938
Collected Steps per Second: 13,782.89401
Overall Steps per Second: 7,372.65374
Timestep Collection Time: 3.62856
Timestep Consumption Time: 3.15489
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.78345
Cumulative Model Updates: 182,537
Cumulative Timesteps: 1,380,450,618
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1380450618...
Checkpoint 1380450618 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.68471
Policy Entropy: 4.34556
Value Function Loss: 0.00259
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.93523
Value Function Update Magnitude: 0.82982
Collected Steps per Second: 13,233.18002
Overall Steps per Second: 6,937.69688
Timestep Collection Time: 3.78050
Timestep Consumption Time: 3.43054
PPO Batch Consumption Time: 0.24450
Total Iteration Time: 7.21104
Cumulative Model Updates: 182,546
Cumulative Timesteps: 1,380,500,646
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11539
Policy Entropy: 4.34571
Value Function Loss: 0.00251
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.92517
Value Function Update Magnitude: 0.81273
Collected Steps per Second: 11,828.41423
Overall Steps per Second: 6,865.86896
Timestep Collection Time: 4.22728
Timestep Consumption Time: 3.05541
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 7.28269
Cumulative Model Updates: 182,555
Cumulative Timesteps: 1,380,550,648
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1380550648...
Checkpoint 1380550648 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.79926
Policy Entropy: 4.34331
Value Function Loss: 0.00257
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.91874
Value Function Update Magnitude: 0.76611
Collected Steps per Second: 12,992.22230
Overall Steps per Second: 7,151.04140
Timestep Collection Time: 3.85000
Timestep Consumption Time: 3.14479
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.99479
Cumulative Model Updates: 182,564
Cumulative Timesteps: 1,380,600,668
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95990
Policy Entropy: 4.34232
Value Function Loss: 0.00256
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.91525
Value Function Update Magnitude: 0.78399
Collected Steps per Second: 13,067.41595
Overall Steps per Second: 7,087.50125
Timestep Collection Time: 3.82953
Timestep Consumption Time: 3.23107
PPO Batch Consumption Time: 0.24268
Total Iteration Time: 7.06060
Cumulative Model Updates: 182,573
Cumulative Timesteps: 1,380,650,710
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1380650710...
Checkpoint 1380650710 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.68612
Policy Entropy: 4.34577
Value Function Loss: 0.00251
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.89471
Value Function Update Magnitude: 0.72152
Collected Steps per Second: 13,313.51482
Overall Steps per Second: 7,402.15471
Timestep Collection Time: 3.75588
Timestep Consumption Time: 2.99945
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.75533
Cumulative Model Updates: 182,582
Cumulative Timesteps: 1,380,700,714
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.44420
Policy Entropy: 4.34775
Value Function Loss: 0.00233
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.87630
Value Function Update Magnitude: 0.70851
Collected Steps per Second: 13,287.31196
Overall Steps per Second: 7,258.88553
Timestep Collection Time: 3.76344
Timestep Consumption Time: 3.12550
PPO Batch Consumption Time: 0.22788
Total Iteration Time: 6.88894
Cumulative Model Updates: 182,591
Cumulative Timesteps: 1,380,750,720
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1380750720...
Checkpoint 1380750720 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.22150
Policy Entropy: 4.35363
Value Function Loss: 0.00227
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.87267
Value Function Update Magnitude: 0.70994
Collected Steps per Second: 13,153.71630
Overall Steps per Second: 7,275.63647
Timestep Collection Time: 3.80273
Timestep Consumption Time: 3.07227
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.87500
Cumulative Model Updates: 182,600
Cumulative Timesteps: 1,380,800,740
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09872
Policy Entropy: 4.34716
Value Function Loss: 0.00246
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02501
Policy Update Magnitude: 0.89775
Value Function Update Magnitude: 0.70809
Collected Steps per Second: 13,398.04907
Overall Steps per Second: 7,309.88183
Timestep Collection Time: 3.73502
Timestep Consumption Time: 3.11078
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.84580
Cumulative Model Updates: 182,609
Cumulative Timesteps: 1,380,850,782
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1380850782...
Checkpoint 1380850782 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.60339
Policy Entropy: 4.34586
Value Function Loss: 0.00242
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02646
Policy Update Magnitude: 0.91419
Value Function Update Magnitude: 0.72473
Collected Steps per Second: 13,286.92493
Overall Steps per Second: 7,274.35914
Timestep Collection Time: 3.76340
Timestep Consumption Time: 3.11061
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.87401
Cumulative Model Updates: 182,618
Cumulative Timesteps: 1,380,900,786
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.57182
Policy Entropy: 4.34311
Value Function Loss: 0.00253
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02791
Policy Update Magnitude: 0.93291
Value Function Update Magnitude: 0.74137
Collected Steps per Second: 13,299.81490
Overall Steps per Second: 7,287.58615
Timestep Collection Time: 3.76231
Timestep Consumption Time: 3.10389
PPO Batch Consumption Time: 0.22763
Total Iteration Time: 6.86620
Cumulative Model Updates: 182,627
Cumulative Timesteps: 1,380,950,824
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1380950824...
Checkpoint 1380950824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65821
Policy Entropy: 4.34452
Value Function Loss: 0.00252
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.93299
Value Function Update Magnitude: 0.69207
Collected Steps per Second: 13,520.12046
Overall Steps per Second: 7,317.52243
Timestep Collection Time: 3.70085
Timestep Consumption Time: 3.13698
PPO Batch Consumption Time: 0.23148
Total Iteration Time: 6.83783
Cumulative Model Updates: 182,636
Cumulative Timesteps: 1,381,000,860
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69536
Policy Entropy: 4.34565
Value Function Loss: 0.00251
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.91844
Value Function Update Magnitude: 0.69456
Collected Steps per Second: 13,223.26481
Overall Steps per Second: 7,253.97952
Timestep Collection Time: 3.78137
Timestep Consumption Time: 3.11168
PPO Batch Consumption Time: 0.22955
Total Iteration Time: 6.89304
Cumulative Model Updates: 182,645
Cumulative Timesteps: 1,381,050,862
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1381050862...
Checkpoint 1381050862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.91935
Policy Entropy: 4.34812
Value Function Loss: 0.00251
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.91056
Value Function Update Magnitude: 0.72416
Collected Steps per Second: 13,278.47585
Overall Steps per Second: 7,366.84454
Timestep Collection Time: 3.76926
Timestep Consumption Time: 3.02470
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.79395
Cumulative Model Updates: 182,654
Cumulative Timesteps: 1,381,100,912
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31014
Policy Entropy: 4.35109
Value Function Loss: 0.00235
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02220
Policy Update Magnitude: 0.89040
Value Function Update Magnitude: 0.70301
Collected Steps per Second: 13,344.64659
Overall Steps per Second: 7,289.15764
Timestep Collection Time: 3.74817
Timestep Consumption Time: 3.11380
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.86197
Cumulative Model Updates: 182,663
Cumulative Timesteps: 1,381,150,930
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1381150930...
Checkpoint 1381150930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35508
Policy Entropy: 4.35271
Value Function Loss: 0.00228
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.86896
Value Function Update Magnitude: 0.67111
Collected Steps per Second: 13,092.59703
Overall Steps per Second: 7,231.43829
Timestep Collection Time: 3.82124
Timestep Consumption Time: 3.09716
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.91840
Cumulative Model Updates: 182,672
Cumulative Timesteps: 1,381,200,960
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04430
Policy Entropy: 4.35275
Value Function Loss: 0.00235
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.89093
Value Function Update Magnitude: 0.68160
Collected Steps per Second: 13,210.27273
Overall Steps per Second: 7,345.46510
Timestep Collection Time: 3.78569
Timestep Consumption Time: 3.02259
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.80828
Cumulative Model Updates: 182,681
Cumulative Timesteps: 1,381,250,970
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1381250970...
Checkpoint 1381250970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.32967
Policy Entropy: 4.35010
Value Function Loss: 0.00251
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.90463
Value Function Update Magnitude: 0.72973
Collected Steps per Second: 12,730.83581
Overall Steps per Second: 7,114.64288
Timestep Collection Time: 3.92857
Timestep Consumption Time: 3.10116
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 7.02973
Cumulative Model Updates: 182,690
Cumulative Timesteps: 1,381,300,984
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09783
Policy Entropy: 4.34702
Value Function Loss: 0.00250
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02360
Policy Update Magnitude: 0.90517
Value Function Update Magnitude: 0.71571
Collected Steps per Second: 13,051.73133
Overall Steps per Second: 7,057.92647
Timestep Collection Time: 3.83351
Timestep Consumption Time: 3.25554
PPO Batch Consumption Time: 0.24579
Total Iteration Time: 7.08905
Cumulative Model Updates: 182,699
Cumulative Timesteps: 1,381,351,018
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1381351018...
Checkpoint 1381351018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.43340
Policy Entropy: 4.34946
Value Function Loss: 0.00236
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.91174
Value Function Update Magnitude: 0.72900
Collected Steps per Second: 13,413.03505
Overall Steps per Second: 7,330.67278
Timestep Collection Time: 3.72787
Timestep Consumption Time: 3.09306
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.82093
Cumulative Model Updates: 182,708
Cumulative Timesteps: 1,381,401,020
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28156
Policy Entropy: 4.35268
Value Function Loss: 0.00215
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.87752
Value Function Update Magnitude: 0.74979
Collected Steps per Second: 13,193.37313
Overall Steps per Second: 7,256.13140
Timestep Collection Time: 3.79312
Timestep Consumption Time: 3.10367
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.89679
Cumulative Model Updates: 182,717
Cumulative Timesteps: 1,381,451,064
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1381451064...
Checkpoint 1381451064 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.48896
Policy Entropy: 4.35600
Value Function Loss: 0.00214
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.85386
Value Function Update Magnitude: 0.71308
Collected Steps per Second: 12,872.53804
Overall Steps per Second: 7,268.45119
Timestep Collection Time: 3.88470
Timestep Consumption Time: 2.99517
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.87987
Cumulative Model Updates: 182,726
Cumulative Timesteps: 1,381,501,070
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.21508
Policy Entropy: 4.35289
Value Function Loss: 0.00234
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.87525
Value Function Update Magnitude: 0.72247
Collected Steps per Second: 13,230.01098
Overall Steps per Second: 7,246.84210
Timestep Collection Time: 3.78171
Timestep Consumption Time: 3.12227
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.90397
Cumulative Model Updates: 182,735
Cumulative Timesteps: 1,381,551,102
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1381551102...
Checkpoint 1381551102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.80171
Policy Entropy: 4.35016
Value Function Loss: 0.00256
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.90066
Value Function Update Magnitude: 0.73601
Collected Steps per Second: 13,020.99191
Overall Steps per Second: 7,219.40927
Timestep Collection Time: 3.84287
Timestep Consumption Time: 3.08817
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.93104
Cumulative Model Updates: 182,744
Cumulative Timesteps: 1,381,601,140
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.94352
Policy Entropy: 4.35155
Value Function Loss: 0.00269
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.90368
Value Function Update Magnitude: 0.74494
Collected Steps per Second: 13,475.85319
Overall Steps per Second: 7,334.05728
Timestep Collection Time: 3.71346
Timestep Consumption Time: 3.10978
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.82324
Cumulative Model Updates: 182,753
Cumulative Timesteps: 1,381,651,182
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1381651182...
Checkpoint 1381651182 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.89753
Policy Entropy: 4.35108
Value Function Loss: 0.00261
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.91205
Value Function Update Magnitude: 0.77924
Collected Steps per Second: 13,048.49997
Overall Steps per Second: 7,089.52650
Timestep Collection Time: 3.83232
Timestep Consumption Time: 3.22119
PPO Batch Consumption Time: 0.23575
Total Iteration Time: 7.05350
Cumulative Model Updates: 182,762
Cumulative Timesteps: 1,381,701,188
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54703
Policy Entropy: 4.35298
Value Function Loss: 0.00264
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.93959
Value Function Update Magnitude: 0.75521
Collected Steps per Second: 13,186.96613
Overall Steps per Second: 7,264.33535
Timestep Collection Time: 3.79375
Timestep Consumption Time: 3.09305
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.88680
Cumulative Model Updates: 182,771
Cumulative Timesteps: 1,381,751,216
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1381751216...
Checkpoint 1381751216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51379
Policy Entropy: 4.35171
Value Function Loss: 0.00258
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.93528
Value Function Update Magnitude: 0.74390
Collected Steps per Second: 13,606.37984
Overall Steps per Second: 7,344.13164
Timestep Collection Time: 3.67680
Timestep Consumption Time: 3.13516
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.81197
Cumulative Model Updates: 182,780
Cumulative Timesteps: 1,381,801,244
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.03174
Policy Entropy: 4.35378
Value Function Loss: 0.00266
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02605
Policy Update Magnitude: 0.92697
Value Function Update Magnitude: 0.71625
Collected Steps per Second: 13,066.71525
Overall Steps per Second: 7,194.70192
Timestep Collection Time: 3.83034
Timestep Consumption Time: 3.12616
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.95651
Cumulative Model Updates: 182,789
Cumulative Timesteps: 1,381,851,294
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1381851294...
Checkpoint 1381851294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.60174
Policy Entropy: 4.35217
Value Function Loss: 0.00258
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.93075
Value Function Update Magnitude: 0.70484
Collected Steps per Second: 13,065.32548
Overall Steps per Second: 7,304.94998
Timestep Collection Time: 3.82968
Timestep Consumption Time: 3.01992
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.84960
Cumulative Model Updates: 182,798
Cumulative Timesteps: 1,381,901,330
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01742
Policy Entropy: 4.35665
Value Function Loss: 0.00233
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02534
Policy Update Magnitude: 0.88432
Value Function Update Magnitude: 0.71205
Collected Steps per Second: 13,274.68330
Overall Steps per Second: 7,275.34439
Timestep Collection Time: 3.76657
Timestep Consumption Time: 3.10596
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.87253
Cumulative Model Updates: 182,807
Cumulative Timesteps: 1,381,951,330
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1381951330...
Checkpoint 1381951330 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.85965
Policy Entropy: 4.35861
Value Function Loss: 0.00228
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.87339
Value Function Update Magnitude: 0.71162
Collected Steps per Second: 13,129.31424
Overall Steps per Second: 7,279.28425
Timestep Collection Time: 3.80919
Timestep Consumption Time: 3.06127
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.87046
Cumulative Model Updates: 182,816
Cumulative Timesteps: 1,382,001,342
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87908
Policy Entropy: 4.36128
Value Function Loss: 0.00229
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02220
Policy Update Magnitude: 0.90135
Value Function Update Magnitude: 0.69413
Collected Steps per Second: 13,020.04850
Overall Steps per Second: 7,155.28013
Timestep Collection Time: 3.84238
Timestep Consumption Time: 3.14938
PPO Batch Consumption Time: 0.24009
Total Iteration Time: 6.99176
Cumulative Model Updates: 182,825
Cumulative Timesteps: 1,382,051,370
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1382051370...
Checkpoint 1382051370 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.04388
Policy Entropy: 4.35804
Value Function Loss: 0.00258
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.89337
Value Function Update Magnitude: 0.71663
Collected Steps per Second: 12,996.88554
Overall Steps per Second: 7,199.80900
Timestep Collection Time: 3.84985
Timestep Consumption Time: 3.09978
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.94963
Cumulative Model Updates: 182,834
Cumulative Timesteps: 1,382,101,406
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02444
Policy Entropy: 4.35714
Value Function Loss: 0.00251
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.89702
Value Function Update Magnitude: 0.73722
Collected Steps per Second: 13,134.62367
Overall Steps per Second: 7,268.48952
Timestep Collection Time: 3.80917
Timestep Consumption Time: 3.07424
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.88341
Cumulative Model Updates: 182,843
Cumulative Timesteps: 1,382,151,438
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1382151438...
Checkpoint 1382151438 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.59748
Policy Entropy: 4.35479
Value Function Loss: 0.00249
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.88181
Value Function Update Magnitude: 0.73999
Collected Steps per Second: 13,458.75856
Overall Steps per Second: 7,339.99060
Timestep Collection Time: 3.71520
Timestep Consumption Time: 3.09707
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.81227
Cumulative Model Updates: 182,852
Cumulative Timesteps: 1,382,201,440
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.01866
Policy Entropy: 4.35513
Value Function Loss: 0.00238
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.88055
Value Function Update Magnitude: 0.74444
Collected Steps per Second: 13,198.12849
Overall Steps per Second: 7,255.57941
Timestep Collection Time: 3.79084
Timestep Consumption Time: 3.10482
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.89566
Cumulative Model Updates: 182,861
Cumulative Timesteps: 1,382,251,472
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1382251472...
Checkpoint 1382251472 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.81332
Policy Entropy: 4.35472
Value Function Loss: 0.00242
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.88421
Value Function Update Magnitude: 0.74852
Collected Steps per Second: 12,752.80346
Overall Steps per Second: 7,217.16086
Timestep Collection Time: 3.92212
Timestep Consumption Time: 3.00831
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.93043
Cumulative Model Updates: 182,870
Cumulative Timesteps: 1,382,301,490
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.00978
Policy Entropy: 4.35786
Value Function Loss: 0.00232
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.89188
Value Function Update Magnitude: 0.72860
Collected Steps per Second: 13,045.53288
Overall Steps per Second: 7,190.79130
Timestep Collection Time: 3.83610
Timestep Consumption Time: 3.12335
PPO Batch Consumption Time: 0.22778
Total Iteration Time: 6.95946
Cumulative Model Updates: 182,879
Cumulative Timesteps: 1,382,351,534
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1382351534...
Checkpoint 1382351534 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76131
Policy Entropy: 4.35612
Value Function Loss: 0.00232
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.88366
Value Function Update Magnitude: 0.73263
Collected Steps per Second: 13,067.97515
Overall Steps per Second: 7,054.22950
Timestep Collection Time: 3.82860
Timestep Consumption Time: 3.26389
PPO Batch Consumption Time: 0.24419
Total Iteration Time: 7.09248
Cumulative Model Updates: 182,888
Cumulative Timesteps: 1,382,401,566
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05270
Policy Entropy: 4.35829
Value Function Loss: 0.00223
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.86037
Value Function Update Magnitude: 0.69125
Collected Steps per Second: 13,111.78134
Overall Steps per Second: 7,318.65510
Timestep Collection Time: 3.81519
Timestep Consumption Time: 3.01994
PPO Batch Consumption Time: 0.22788
Total Iteration Time: 6.83514
Cumulative Model Updates: 182,897
Cumulative Timesteps: 1,382,451,590
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1382451590...
Checkpoint 1382451590 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.23708
Policy Entropy: 4.35645
Value Function Loss: 0.00242
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.88175
Value Function Update Magnitude: 0.70899
Collected Steps per Second: 13,022.66042
Overall Steps per Second: 7,164.63352
Timestep Collection Time: 3.84192
Timestep Consumption Time: 3.14127
PPO Batch Consumption Time: 0.22918
Total Iteration Time: 6.98319
Cumulative Model Updates: 182,906
Cumulative Timesteps: 1,382,501,622
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.94894
Policy Entropy: 4.35587
Value Function Loss: 0.00236
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.89047
Value Function Update Magnitude: 0.68942
Collected Steps per Second: 13,129.10330
Overall Steps per Second: 7,248.50410
Timestep Collection Time: 3.80925
Timestep Consumption Time: 3.09038
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.89963
Cumulative Model Updates: 182,915
Cumulative Timesteps: 1,382,551,634
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1382551634...
Checkpoint 1382551634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.49867
Policy Entropy: 4.35226
Value Function Loss: 0.00250
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.89657
Value Function Update Magnitude: 0.67901
Collected Steps per Second: 13,320.10198
Overall Steps per Second: 7,293.25666
Timestep Collection Time: 3.75583
Timestep Consumption Time: 3.10366
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.85949
Cumulative Model Updates: 182,924
Cumulative Timesteps: 1,382,601,662
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71633
Policy Entropy: 4.35476
Value Function Loss: 0.00248
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.91102
Value Function Update Magnitude: 0.67540
Collected Steps per Second: 13,222.66099
Overall Steps per Second: 7,265.39602
Timestep Collection Time: 3.78350
Timestep Consumption Time: 3.10229
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.88579
Cumulative Model Updates: 182,933
Cumulative Timesteps: 1,382,651,690
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1382651690...
Checkpoint 1382651690 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.63174
Policy Entropy: 4.35256
Value Function Loss: 0.00264
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02816
Policy Update Magnitude: 0.93141
Value Function Update Magnitude: 0.70241
Collected Steps per Second: 13,139.89118
Overall Steps per Second: 7,264.94756
Timestep Collection Time: 3.80612
Timestep Consumption Time: 3.07789
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.88401
Cumulative Model Updates: 182,942
Cumulative Timesteps: 1,382,701,702
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.39805
Policy Entropy: 4.35641
Value Function Loss: 0.00256
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.92199
Value Function Update Magnitude: 0.71932
Collected Steps per Second: 13,487.16555
Overall Steps per Second: 7,188.07944
Timestep Collection Time: 3.70812
Timestep Consumption Time: 3.24951
PPO Batch Consumption Time: 0.24020
Total Iteration Time: 6.95763
Cumulative Model Updates: 182,951
Cumulative Timesteps: 1,382,751,714
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1382751714...
Checkpoint 1382751714 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.66333
Policy Entropy: 4.35735
Value Function Loss: 0.00228
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.88459
Value Function Update Magnitude: 0.74881
Collected Steps per Second: 12,948.31033
Overall Steps per Second: 7,140.05819
Timestep Collection Time: 3.86382
Timestep Consumption Time: 3.14312
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 7.00695
Cumulative Model Updates: 182,960
Cumulative Timesteps: 1,382,801,744
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27758
Policy Entropy: 4.36067
Value Function Loss: 0.00204
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.85844
Value Function Update Magnitude: 0.72208
Collected Steps per Second: 13,234.51618
Overall Steps per Second: 7,360.43244
Timestep Collection Time: 3.77845
Timestep Consumption Time: 3.01544
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.79389
Cumulative Model Updates: 182,969
Cumulative Timesteps: 1,382,851,750
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1382851750...
Checkpoint 1382851750 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61519
Policy Entropy: 4.35776
Value Function Loss: 0.00228
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02311
Policy Update Magnitude: 0.87802
Value Function Update Magnitude: 0.72828
Collected Steps per Second: 13,230.39895
Overall Steps per Second: 7,265.02346
Timestep Collection Time: 3.77978
Timestep Consumption Time: 3.10361
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.88339
Cumulative Model Updates: 182,978
Cumulative Timesteps: 1,382,901,758
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.25189
Policy Entropy: 4.35443
Value Function Loss: 0.00264
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.91910
Value Function Update Magnitude: 0.76547
Collected Steps per Second: 13,200.93541
Overall Steps per Second: 7,284.85114
Timestep Collection Time: 3.78822
Timestep Consumption Time: 3.07644
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.86466
Cumulative Model Updates: 182,987
Cumulative Timesteps: 1,382,951,766
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1382951766...
Checkpoint 1382951766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.02724
Policy Entropy: 4.35181
Value Function Loss: 0.00291
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02614
Policy Update Magnitude: 0.95705
Value Function Update Magnitude: 0.78933
Collected Steps per Second: 12,980.45888
Overall Steps per Second: 7,288.05842
Timestep Collection Time: 3.85364
Timestep Consumption Time: 3.00992
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.86356
Cumulative Model Updates: 182,996
Cumulative Timesteps: 1,383,001,788
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.71217
Policy Entropy: 4.34984
Value Function Loss: 0.00278
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.95016
Value Function Update Magnitude: 0.78911
Collected Steps per Second: 13,202.15476
Overall Steps per Second: 7,257.15889
Timestep Collection Time: 3.78817
Timestep Consumption Time: 3.10323
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.89140
Cumulative Model Updates: 183,005
Cumulative Timesteps: 1,383,051,800
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1383051800...
Checkpoint 1383051800 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87612
Policy Entropy: 4.35113
Value Function Loss: 0.00242
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.91598
Value Function Update Magnitude: 0.71137
Collected Steps per Second: 13,192.63650
Overall Steps per Second: 7,087.50164
Timestep Collection Time: 3.79105
Timestep Consumption Time: 3.26559
PPO Batch Consumption Time: 0.24297
Total Iteration Time: 7.05665
Cumulative Model Updates: 183,014
Cumulative Timesteps: 1,383,101,814
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.24145
Policy Entropy: 4.35104
Value Function Loss: 0.00239
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.90671
Value Function Update Magnitude: 0.69124
Collected Steps per Second: 13,406.34404
Overall Steps per Second: 7,299.83820
Timestep Collection Time: 3.73017
Timestep Consumption Time: 3.12039
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.85056
Cumulative Model Updates: 183,023
Cumulative Timesteps: 1,383,151,822
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1383151822...
Checkpoint 1383151822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82681
Policy Entropy: 4.35396
Value Function Loss: 0.00246
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02451
Policy Update Magnitude: 0.90083
Value Function Update Magnitude: 0.68622
Collected Steps per Second: 13,173.98111
Overall Steps per Second: 7,233.49161
Timestep Collection Time: 3.79612
Timestep Consumption Time: 3.11755
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.91367
Cumulative Model Updates: 183,032
Cumulative Timesteps: 1,383,201,832
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.26003
Policy Entropy: 4.35208
Value Function Loss: 0.00269
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.92524
Value Function Update Magnitude: 0.72941
Collected Steps per Second: 13,211.79657
Overall Steps per Second: 7,327.36945
Timestep Collection Time: 3.78646
Timestep Consumption Time: 3.04082
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.82728
Cumulative Model Updates: 183,041
Cumulative Timesteps: 1,383,251,858
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1383251858...
Checkpoint 1383251858 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.24654
Policy Entropy: 4.35162
Value Function Loss: 0.00261
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.93659
Value Function Update Magnitude: 0.74576
Collected Steps per Second: 13,197.47534
Overall Steps per Second: 7,250.06801
Timestep Collection Time: 3.79133
Timestep Consumption Time: 3.11012
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.90145
Cumulative Model Updates: 183,050
Cumulative Timesteps: 1,383,301,894
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11626
Policy Entropy: 4.35174
Value Function Loss: 0.00245
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.91955
Value Function Update Magnitude: 0.76956
Collected Steps per Second: 13,248.97539
Overall Steps per Second: 7,283.87339
Timestep Collection Time: 3.77433
Timestep Consumption Time: 3.09097
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.86530
Cumulative Model Updates: 183,059
Cumulative Timesteps: 1,383,351,900
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1383351900...
Checkpoint 1383351900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32380
Policy Entropy: 4.35345
Value Function Loss: 0.00242
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02574
Policy Update Magnitude: 0.90342
Value Function Update Magnitude: 0.72993
Collected Steps per Second: 12,369.46383
Overall Steps per Second: 7,052.06273
Timestep Collection Time: 4.04496
Timestep Consumption Time: 3.04998
PPO Batch Consumption Time: 0.22965
Total Iteration Time: 7.09495
Cumulative Model Updates: 183,068
Cumulative Timesteps: 1,383,401,934
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65184
Policy Entropy: 4.35368
Value Function Loss: 0.00250
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.91163
Value Function Update Magnitude: 0.72843
Collected Steps per Second: 12,611.79195
Overall Steps per Second: 6,852.67678
Timestep Collection Time: 3.96692
Timestep Consumption Time: 3.33387
PPO Batch Consumption Time: 0.24602
Total Iteration Time: 7.30080
Cumulative Model Updates: 183,077
Cumulative Timesteps: 1,383,451,964
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1383451964...
Checkpoint 1383451964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33730
Policy Entropy: 4.35268
Value Function Loss: 0.00266
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.91977
Value Function Update Magnitude: 0.75196
Collected Steps per Second: 12,554.99647
Overall Steps per Second: 7,041.00365
Timestep Collection Time: 3.98614
Timestep Consumption Time: 3.12165
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 7.10779
Cumulative Model Updates: 183,086
Cumulative Timesteps: 1,383,502,010
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.47968
Policy Entropy: 4.34997
Value Function Loss: 0.00278
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02548
Policy Update Magnitude: 0.94118
Value Function Update Magnitude: 0.80355
Collected Steps per Second: 12,980.35548
Overall Steps per Second: 7,132.37919
Timestep Collection Time: 3.85367
Timestep Consumption Time: 3.15970
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 7.01337
Cumulative Model Updates: 183,095
Cumulative Timesteps: 1,383,552,032
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1383552032...
Checkpoint 1383552032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.84618
Policy Entropy: 4.34760
Value Function Loss: 0.00282
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.95845
Value Function Update Magnitude: 0.78841
Collected Steps per Second: 12,651.63818
Overall Steps per Second: 7,044.02344
Timestep Collection Time: 3.95364
Timestep Consumption Time: 3.14742
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 7.10106
Cumulative Model Updates: 183,104
Cumulative Timesteps: 1,383,602,052
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.90330
Policy Entropy: 4.34848
Value Function Loss: 0.00264
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.95400
Value Function Update Magnitude: 0.78036
Collected Steps per Second: 13,108.87625
Overall Steps per Second: 7,321.95259
Timestep Collection Time: 3.81650
Timestep Consumption Time: 3.01638
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.83288
Cumulative Model Updates: 183,113
Cumulative Timesteps: 1,383,652,082
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1383652082...
Checkpoint 1383652082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82850
Policy Entropy: 4.34951
Value Function Loss: 0.00247
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02548
Policy Update Magnitude: 0.92166
Value Function Update Magnitude: 0.74559
Collected Steps per Second: 13,251.12006
Overall Steps per Second: 7,287.68747
Timestep Collection Time: 3.77553
Timestep Consumption Time: 3.08947
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.86500
Cumulative Model Updates: 183,122
Cumulative Timesteps: 1,383,702,112
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35277
Policy Entropy: 4.34685
Value Function Loss: 0.00235
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.90196
Value Function Update Magnitude: 0.74113
Collected Steps per Second: 13,308.61047
Overall Steps per Second: 7,322.50929
Timestep Collection Time: 3.75712
Timestep Consumption Time: 3.07142
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.82853
Cumulative Model Updates: 183,131
Cumulative Timesteps: 1,383,752,114
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1383752114...
Checkpoint 1383752114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.91096
Policy Entropy: 4.34890
Value Function Loss: 0.00235
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.89120
Value Function Update Magnitude: 0.72814
Collected Steps per Second: 13,176.23874
Overall Steps per Second: 7,296.37517
Timestep Collection Time: 3.79638
Timestep Consumption Time: 3.05935
PPO Batch Consumption Time: 0.23269
Total Iteration Time: 6.85573
Cumulative Model Updates: 183,140
Cumulative Timesteps: 1,383,802,136
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95251
Policy Entropy: 4.34606
Value Function Loss: 0.00246
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.88301
Value Function Update Magnitude: 0.72593
Collected Steps per Second: 13,294.86158
Overall Steps per Second: 7,268.35894
Timestep Collection Time: 3.76266
Timestep Consumption Time: 3.11978
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.88243
Cumulative Model Updates: 183,149
Cumulative Timesteps: 1,383,852,160
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1383852160...
Checkpoint 1383852160 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20091
Policy Entropy: 4.34839
Value Function Loss: 0.00234
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.86717
Value Function Update Magnitude: 0.72913
Collected Steps per Second: 13,096.57326
Overall Steps per Second: 7,253.87042
Timestep Collection Time: 3.81825
Timestep Consumption Time: 3.07545
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.89370
Cumulative Model Updates: 183,158
Cumulative Timesteps: 1,383,902,166
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56828
Policy Entropy: 4.34406
Value Function Loss: 0.00245
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.88885
Value Function Update Magnitude: 0.75550
Collected Steps per Second: 13,451.40523
Overall Steps per Second: 7,328.58995
Timestep Collection Time: 3.71946
Timestep Consumption Time: 3.10750
PPO Batch Consumption Time: 0.22784
Total Iteration Time: 6.82696
Cumulative Model Updates: 183,167
Cumulative Timesteps: 1,383,952,198
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1383952198...
Checkpoint 1383952198 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50814
Policy Entropy: 4.34673
Value Function Loss: 0.00235
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.88900
Value Function Update Magnitude: 0.82374
Collected Steps per Second: 13,243.47197
Overall Steps per Second: 7,254.60625
Timestep Collection Time: 3.77801
Timestep Consumption Time: 3.11885
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.89686
Cumulative Model Updates: 183,176
Cumulative Timesteps: 1,384,002,232
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.95613
Policy Entropy: 4.34788
Value Function Loss: 0.00232
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.87841
Value Function Update Magnitude: 0.73698
Collected Steps per Second: 13,248.78669
Overall Steps per Second: 7,279.05356
Timestep Collection Time: 3.77423
Timestep Consumption Time: 3.09534
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.86957
Cumulative Model Updates: 183,185
Cumulative Timesteps: 1,384,052,236
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1384052236...
Checkpoint 1384052236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.72854
Policy Entropy: 4.35240
Value Function Loss: 0.00228
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.87189
Value Function Update Magnitude: 0.72897
Collected Steps per Second: 13,491.65950
Overall Steps per Second: 7,312.76063
Timestep Collection Time: 3.70703
Timestep Consumption Time: 3.13225
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.83928
Cumulative Model Updates: 183,194
Cumulative Timesteps: 1,384,102,250
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.30007
Policy Entropy: 4.35293
Value Function Loss: 0.00225
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.85658
Value Function Update Magnitude: 0.73758
Collected Steps per Second: 13,344.05574
Overall Steps per Second: 7,211.07080
Timestep Collection Time: 3.74879
Timestep Consumption Time: 3.18833
PPO Batch Consumption Time: 0.23517
Total Iteration Time: 6.93711
Cumulative Model Updates: 183,203
Cumulative Timesteps: 1,384,152,274
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1384152274...
Checkpoint 1384152274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.12568
Policy Entropy: 4.35063
Value Function Loss: 0.00234
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02306
Policy Update Magnitude: 0.86261
Value Function Update Magnitude: 0.72509
Collected Steps per Second: 13,323.40611
Overall Steps per Second: 7,375.57872
Timestep Collection Time: 3.75520
Timestep Consumption Time: 3.02827
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.78347
Cumulative Model Updates: 183,212
Cumulative Timesteps: 1,384,202,306
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64351
Policy Entropy: 4.34699
Value Function Loss: 0.00237
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.88379
Value Function Update Magnitude: 0.72614
Collected Steps per Second: 13,132.65390
Overall Steps per Second: 7,195.87346
Timestep Collection Time: 3.80852
Timestep Consumption Time: 3.14213
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.95065
Cumulative Model Updates: 183,221
Cumulative Timesteps: 1,384,252,322
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1384252322...
Checkpoint 1384252322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33147
Policy Entropy: 4.34899
Value Function Loss: 0.00242
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02320
Policy Update Magnitude: 0.87191
Value Function Update Magnitude: 0.71717
Collected Steps per Second: 13,093.02373
Overall Steps per Second: 7,254.41191
Timestep Collection Time: 3.82036
Timestep Consumption Time: 3.07476
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.89511
Cumulative Model Updates: 183,230
Cumulative Timesteps: 1,384,302,342
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.99344
Policy Entropy: 4.34915
Value Function Loss: 0.00258
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.88107
Value Function Update Magnitude: 0.76441
Collected Steps per Second: 13,192.45036
Overall Steps per Second: 7,363.87507
Timestep Collection Time: 3.79202
Timestep Consumption Time: 3.00142
PPO Batch Consumption Time: 0.22782
Total Iteration Time: 6.79343
Cumulative Model Updates: 183,239
Cumulative Timesteps: 1,384,352,368
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1384352368...
Checkpoint 1384352368 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71542
Policy Entropy: 4.35054
Value Function Loss: 0.00264
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.90725
Value Function Update Magnitude: 0.73455
Collected Steps per Second: 13,056.59773
Overall Steps per Second: 7,205.85298
Timestep Collection Time: 3.82979
Timestep Consumption Time: 3.10957
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.93936
Cumulative Model Updates: 183,248
Cumulative Timesteps: 1,384,402,372
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06757
Policy Entropy: 4.34689
Value Function Loss: 0.00268
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.91135
Value Function Update Magnitude: 0.73893
Collected Steps per Second: 13,085.68484
Overall Steps per Second: 7,253.07811
Timestep Collection Time: 3.82296
Timestep Consumption Time: 3.07425
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.89721
Cumulative Model Updates: 183,257
Cumulative Timesteps: 1,384,452,398
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1384452398...
Checkpoint 1384452398 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.48920
Policy Entropy: 4.34679
Value Function Loss: 0.00251
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.89989
Value Function Update Magnitude: 0.72397
Collected Steps per Second: 13,416.72576
Overall Steps per Second: 7,189.93626
Timestep Collection Time: 3.72744
Timestep Consumption Time: 3.22812
PPO Batch Consumption Time: 0.23807
Total Iteration Time: 6.95556
Cumulative Model Updates: 183,266
Cumulative Timesteps: 1,384,502,408
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.99440
Policy Entropy: 4.34652
Value Function Loss: 0.00247
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.88182
Value Function Update Magnitude: 0.71865
Collected Steps per Second: 13,146.39360
Overall Steps per Second: 7,236.10959
Timestep Collection Time: 3.80363
Timestep Consumption Time: 3.10671
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.91034
Cumulative Model Updates: 183,275
Cumulative Timesteps: 1,384,552,412
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1384552412...
Checkpoint 1384552412 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26127
Policy Entropy: 4.34652
Value Function Loss: 0.00259
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.90636
Value Function Update Magnitude: 0.78189
Collected Steps per Second: 13,025.44843
Overall Steps per Second: 7,334.16202
Timestep Collection Time: 3.83987
Timestep Consumption Time: 2.97973
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.81959
Cumulative Model Updates: 183,284
Cumulative Timesteps: 1,384,602,428
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.48556
Policy Entropy: 4.34278
Value Function Loss: 0.00263
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.91207
Value Function Update Magnitude: 0.75645
Collected Steps per Second: 13,332.05224
Overall Steps per Second: 7,273.35933
Timestep Collection Time: 3.75201
Timestep Consumption Time: 3.12542
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.87743
Cumulative Model Updates: 183,293
Cumulative Timesteps: 1,384,652,450
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1384652450...
Checkpoint 1384652450 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.44047
Policy Entropy: 4.34219
Value Function Loss: 0.00269
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.91482
Value Function Update Magnitude: 0.77439
Collected Steps per Second: 13,184.21620
Overall Steps per Second: 7,289.11490
Timestep Collection Time: 3.79408
Timestep Consumption Time: 3.06848
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.86256
Cumulative Model Updates: 183,302
Cumulative Timesteps: 1,384,702,472
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31051
Policy Entropy: 4.34089
Value Function Loss: 0.00259
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.88853
Value Function Update Magnitude: 0.72962
Collected Steps per Second: 13,264.12617
Overall Steps per Second: 7,371.82208
Timestep Collection Time: 3.77107
Timestep Consumption Time: 3.01422
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.78530
Cumulative Model Updates: 183,311
Cumulative Timesteps: 1,384,752,492
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1384752492...
Checkpoint 1384752492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.30419
Policy Entropy: 4.34135
Value Function Loss: 0.00286
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.90411
Value Function Update Magnitude: 0.73395
Collected Steps per Second: 13,281.18362
Overall Steps per Second: 7,268.90758
Timestep Collection Time: 3.76608
Timestep Consumption Time: 3.11501
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.88109
Cumulative Model Updates: 183,320
Cumulative Timesteps: 1,384,802,510
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.28242
Policy Entropy: 4.33960
Value Function Loss: 0.00271
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.90471
Value Function Update Magnitude: 0.79834
Collected Steps per Second: 13,239.52311
Overall Steps per Second: 7,197.44094
Timestep Collection Time: 3.77687
Timestep Consumption Time: 3.17060
PPO Batch Consumption Time: 0.23608
Total Iteration Time: 6.94747
Cumulative Model Updates: 183,329
Cumulative Timesteps: 1,384,852,514
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1384852514...
Checkpoint 1384852514 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.47939
Policy Entropy: 4.33811
Value Function Loss: 0.00287
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02745
Policy Update Magnitude: 0.91797
Value Function Update Magnitude: 0.75746
Collected Steps per Second: 13,514.78612
Overall Steps per Second: 7,324.97057
Timestep Collection Time: 3.70276
Timestep Consumption Time: 3.12894
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.83170
Cumulative Model Updates: 183,338
Cumulative Timesteps: 1,384,902,556
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.74212
Policy Entropy: 4.33924
Value Function Loss: 0.00260
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.92355
Value Function Update Magnitude: 0.74414
Collected Steps per Second: 13,207.69727
Overall Steps per Second: 7,248.61526
Timestep Collection Time: 3.78870
Timestep Consumption Time: 3.11469
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.90339
Cumulative Model Updates: 183,347
Cumulative Timesteps: 1,384,952,596
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1384952596...
Checkpoint 1384952596 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.91895
Policy Entropy: 4.34254
Value Function Loss: 0.00257
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.91335
Value Function Update Magnitude: 0.73759
Collected Steps per Second: 13,107.24596
Overall Steps per Second: 7,261.01523
Timestep Collection Time: 3.81575
Timestep Consumption Time: 3.07227
PPO Batch Consumption Time: 0.22778
Total Iteration Time: 6.88802
Cumulative Model Updates: 183,356
Cumulative Timesteps: 1,385,002,610
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87035
Policy Entropy: 4.34542
Value Function Loss: 0.00247
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02440
Policy Update Magnitude: 0.90262
Value Function Update Magnitude: 0.71092
Collected Steps per Second: 13,481.42582
Overall Steps per Second: 7,317.41402
Timestep Collection Time: 3.71074
Timestep Consumption Time: 3.12583
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.83657
Cumulative Model Updates: 183,365
Cumulative Timesteps: 1,385,052,636
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1385052636...
Checkpoint 1385052636 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82895
Policy Entropy: 4.34678
Value Function Loss: 0.00240
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.89189
Value Function Update Magnitude: 0.75229
Collected Steps per Second: 13,152.02510
Overall Steps per Second: 7,219.85567
Timestep Collection Time: 3.80504
Timestep Consumption Time: 3.12640
PPO Batch Consumption Time: 0.22938
Total Iteration Time: 6.93144
Cumulative Model Updates: 183,374
Cumulative Timesteps: 1,385,102,680
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83341
Policy Entropy: 4.34895
Value Function Loss: 0.00240
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02286
Policy Update Magnitude: 0.87837
Value Function Update Magnitude: 0.74776
Collected Steps per Second: 13,259.11416
Overall Steps per Second: 7,381.14812
Timestep Collection Time: 3.77446
Timestep Consumption Time: 3.00579
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.78025
Cumulative Model Updates: 183,383
Cumulative Timesteps: 1,385,152,726
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1385152726...
Checkpoint 1385152726 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.16941
Policy Entropy: 4.35099
Value Function Loss: 0.00243
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02326
Policy Update Magnitude: 0.87286
Value Function Update Magnitude: 0.74229
Collected Steps per Second: 13,146.99137
Overall Steps per Second: 7,197.07510
Timestep Collection Time: 3.80604
Timestep Consumption Time: 3.14650
PPO Batch Consumption Time: 0.23349
Total Iteration Time: 6.95255
Cumulative Model Updates: 183,392
Cumulative Timesteps: 1,385,202,764
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.19694
Policy Entropy: 4.35359
Value Function Loss: 0.00253
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.87192
Value Function Update Magnitude: 0.74108
Collected Steps per Second: 13,179.18520
Overall Steps per Second: 7,293.54574
Timestep Collection Time: 3.79568
Timestep Consumption Time: 3.06298
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.85867
Cumulative Model Updates: 183,401
Cumulative Timesteps: 1,385,252,788
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1385252788...
Checkpoint 1385252788 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.61560
Policy Entropy: 4.34968
Value Function Loss: 0.00261
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.87824
Value Function Update Magnitude: 0.77463
Collected Steps per Second: 13,209.18593
Overall Steps per Second: 7,384.26967
Timestep Collection Time: 3.78646
Timestep Consumption Time: 2.98686
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.77332
Cumulative Model Updates: 183,410
Cumulative Timesteps: 1,385,302,804
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.24817
Policy Entropy: 4.34790
Value Function Loss: 0.00258
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.88763
Value Function Update Magnitude: 0.79394
Collected Steps per Second: 13,259.71783
Overall Steps per Second: 7,256.01880
Timestep Collection Time: 3.77263
Timestep Consumption Time: 3.12151
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.89414
Cumulative Model Updates: 183,419
Cumulative Timesteps: 1,385,352,828
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1385352828...
Checkpoint 1385352828 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09099
Policy Entropy: 4.34583
Value Function Loss: 0.00269
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.89816
Value Function Update Magnitude: 0.76687
Collected Steps per Second: 13,242.74880
Overall Steps per Second: 7,314.95586
Timestep Collection Time: 3.77641
Timestep Consumption Time: 3.06027
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.83668
Cumulative Model Updates: 183,428
Cumulative Timesteps: 1,385,402,838
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35111
Policy Entropy: 4.34765
Value Function Loss: 0.00271
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.90770
Value Function Update Magnitude: 0.79689
Collected Steps per Second: 13,420.04796
Overall Steps per Second: 7,200.94210
Timestep Collection Time: 3.72577
Timestep Consumption Time: 3.21777
PPO Batch Consumption Time: 0.23645
Total Iteration Time: 6.94354
Cumulative Model Updates: 183,437
Cumulative Timesteps: 1,385,452,838
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1385452838...
Checkpoint 1385452838 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01635
Policy Entropy: 4.34674
Value Function Loss: 0.00275
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.92514
Value Function Update Magnitude: 0.80269
Collected Steps per Second: 12,120.31920
Overall Steps per Second: 6,845.75535
Timestep Collection Time: 4.12811
Timestep Consumption Time: 3.18065
PPO Batch Consumption Time: 0.23128
Total Iteration Time: 7.30876
Cumulative Model Updates: 183,446
Cumulative Timesteps: 1,385,502,872
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77841
Policy Entropy: 4.34757
Value Function Loss: 0.00279
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.94302
Value Function Update Magnitude: 0.79735
Collected Steps per Second: 12,025.47400
Overall Steps per Second: 6,735.00411
Timestep Collection Time: 4.15950
Timestep Consumption Time: 3.26737
PPO Batch Consumption Time: 0.25434
Total Iteration Time: 7.42687
Cumulative Model Updates: 183,455
Cumulative Timesteps: 1,385,552,892
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1385552892...
Checkpoint 1385552892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.15463
Policy Entropy: 4.34793
Value Function Loss: 0.00263
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.93637
Value Function Update Magnitude: 0.81565
Collected Steps per Second: 12,107.60282
Overall Steps per Second: 6,891.24937
Timestep Collection Time: 4.13327
Timestep Consumption Time: 3.12869
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 7.26196
Cumulative Model Updates: 183,464
Cumulative Timesteps: 1,385,602,936
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.03507
Policy Entropy: 4.34978
Value Function Loss: 0.00254
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02441
Policy Update Magnitude: 0.91624
Value Function Update Magnitude: 0.76673
Collected Steps per Second: 11,387.42337
Overall Steps per Second: 6,407.04507
Timestep Collection Time: 4.39292
Timestep Consumption Time: 3.41474
PPO Batch Consumption Time: 0.23816
Total Iteration Time: 7.80766
Cumulative Model Updates: 183,473
Cumulative Timesteps: 1,385,652,960
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1385652960...
Checkpoint 1385652960 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68698
Policy Entropy: 4.35346
Value Function Loss: 0.00261
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02425
Policy Update Magnitude: 0.90102
Value Function Update Magnitude: 0.71425
Collected Steps per Second: 11,005.94970
Overall Steps per Second: 6,436.04664
Timestep Collection Time: 4.54554
Timestep Consumption Time: 3.22755
PPO Batch Consumption Time: 0.24625
Total Iteration Time: 7.77309
Cumulative Model Updates: 183,482
Cumulative Timesteps: 1,385,702,988
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81557
Policy Entropy: 4.34974
Value Function Loss: 0.00264
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.91882
Value Function Update Magnitude: 0.70310
Collected Steps per Second: 11,309.32394
Overall Steps per Second: 6,125.82183
Timestep Collection Time: 4.42166
Timestep Consumption Time: 3.74149
PPO Batch Consumption Time: 0.24120
Total Iteration Time: 8.16315
Cumulative Model Updates: 183,491
Cumulative Timesteps: 1,385,752,994
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1385752994...
Checkpoint 1385752994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93739
Policy Entropy: 4.34936
Value Function Loss: 0.00271
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.93185
Value Function Update Magnitude: 0.72378
Collected Steps per Second: 11,006.60812
Overall Steps per Second: 6,440.00842
Timestep Collection Time: 4.54363
Timestep Consumption Time: 3.22188
PPO Batch Consumption Time: 0.23476
Total Iteration Time: 7.76552
Cumulative Model Updates: 183,500
Cumulative Timesteps: 1,385,803,004
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.40018
Policy Entropy: 4.34718
Value Function Loss: 0.00268
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.93798
Value Function Update Magnitude: 0.72957
Collected Steps per Second: 11,808.91789
Overall Steps per Second: 6,608.86262
Timestep Collection Time: 4.23460
Timestep Consumption Time: 3.33191
PPO Batch Consumption Time: 0.24582
Total Iteration Time: 7.56651
Cumulative Model Updates: 183,509
Cumulative Timesteps: 1,385,853,010
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1385853010...
Checkpoint 1385853010 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.64765
Policy Entropy: 4.34761
Value Function Loss: 0.00275
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.94556
Value Function Update Magnitude: 0.75985
Collected Steps per Second: 12,161.92367
Overall Steps per Second: 6,876.08381
Timestep Collection Time: 4.11317
Timestep Consumption Time: 3.16191
PPO Batch Consumption Time: 0.22990
Total Iteration Time: 7.27507
Cumulative Model Updates: 183,518
Cumulative Timesteps: 1,385,903,034
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18461
Policy Entropy: 4.34723
Value Function Loss: 0.00285
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.95485
Value Function Update Magnitude: 0.76981
Collected Steps per Second: 12,344.96650
Overall Steps per Second: 6,919.48930
Timestep Collection Time: 4.05104
Timestep Consumption Time: 3.17637
PPO Batch Consumption Time: 0.23182
Total Iteration Time: 7.22741
Cumulative Model Updates: 183,527
Cumulative Timesteps: 1,385,953,044
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1385953044...
Checkpoint 1385953044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.00944
Policy Entropy: 4.34686
Value Function Loss: 0.00275
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.93790
Value Function Update Magnitude: 0.77764
Collected Steps per Second: 12,054.87618
Overall Steps per Second: 6,672.67927
Timestep Collection Time: 4.14820
Timestep Consumption Time: 3.34594
PPO Batch Consumption Time: 0.24100
Total Iteration Time: 7.49414
Cumulative Model Updates: 183,536
Cumulative Timesteps: 1,386,003,050
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.29313
Policy Entropy: 4.34716
Value Function Loss: 0.00268
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.92005
Value Function Update Magnitude: 0.74147
Collected Steps per Second: 10,767.23290
Overall Steps per Second: 6,266.90436
Timestep Collection Time: 4.64781
Timestep Consumption Time: 3.33764
PPO Batch Consumption Time: 0.24061
Total Iteration Time: 7.98544
Cumulative Model Updates: 183,545
Cumulative Timesteps: 1,386,053,094
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1386053094...
Checkpoint 1386053094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90690
Policy Entropy: 4.34842
Value Function Loss: 0.00261
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.90964
Value Function Update Magnitude: 0.71219
Collected Steps per Second: 10,306.53231
Overall Steps per Second: 5,864.77389
Timestep Collection Time: 4.85459
Timestep Consumption Time: 3.67668
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 8.53128
Cumulative Model Updates: 183,554
Cumulative Timesteps: 1,386,103,128
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.79397
Policy Entropy: 4.34237
Value Function Loss: 0.00279
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02411
Policy Update Magnitude: 0.93753
Value Function Update Magnitude: 0.70973
Collected Steps per Second: 10,878.63634
Overall Steps per Second: 6,240.02395
Timestep Collection Time: 4.60168
Timestep Consumption Time: 3.42073
PPO Batch Consumption Time: 0.24649
Total Iteration Time: 8.02241
Cumulative Model Updates: 183,563
Cumulative Timesteps: 1,386,153,188
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 1386153188...
Checkpoint 1386153188 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.68503
Policy Entropy: 4.34170
Value Function Loss: 0.00293
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.97092
Value Function Update Magnitude: 0.73257
Collected Steps per Second: 10,418.19439
Overall Steps per Second: 6,079.88501
Timestep Collection Time: 4.79949
Timestep Consumption Time: 3.42468
PPO Batch Consumption Time: 0.25252
Total Iteration Time: 8.22417
Cumulative Model Updates: 183,572
Cumulative Timesteps: 1,386,203,190
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.19320
Policy Entropy: 4.33648
Value Function Loss: 0.00294
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02810
Policy Update Magnitude: 0.96652
Value Function Update Magnitude: 0.75240
Collected Steps per Second: 9,768.36934
Overall Steps per Second: 5,897.79696
Timestep Collection Time: 5.12204
Timestep Consumption Time: 3.36146
PPO Batch Consumption Time: 0.24213
Total Iteration Time: 8.48351
Cumulative Model Updates: 183,581
Cumulative Timesteps: 1,386,253,224
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1386253224...
Checkpoint 1386253224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.03681
Policy Entropy: 4.34089
Value Function Loss: 0.00280
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03033
Policy Update Magnitude: 0.93364
Value Function Update Magnitude: 0.75087
Collected Steps per Second: 11,125.24274
Overall Steps per Second: 6,405.69950
Timestep Collection Time: 4.49842
Timestep Consumption Time: 3.31431
PPO Batch Consumption Time: 0.23615
Total Iteration Time: 7.81273
Cumulative Model Updates: 183,590
Cumulative Timesteps: 1,386,303,270
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.29656
Policy Entropy: 4.34032
Value Function Loss: 0.00273
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.91065
Value Function Update Magnitude: 0.73693
Collected Steps per Second: 10,751.97954
Overall Steps per Second: 6,246.21615
Timestep Collection Time: 4.65533
Timestep Consumption Time: 3.35816
PPO Batch Consumption Time: 0.23391
Total Iteration Time: 8.01349
Cumulative Model Updates: 183,599
Cumulative Timesteps: 1,386,353,324
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1386353324...
Checkpoint 1386353324 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.43705
Policy Entropy: 4.34387
Value Function Loss: 0.00267
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.91012
Value Function Update Magnitude: 0.74812
Collected Steps per Second: 11,721.09623
Overall Steps per Second: 6,718.40032
Timestep Collection Time: 4.26581
Timestep Consumption Time: 3.17644
PPO Batch Consumption Time: 0.23058
Total Iteration Time: 7.44225
Cumulative Model Updates: 183,608
Cumulative Timesteps: 1,386,403,324
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.58621
Policy Entropy: 4.34461
Value Function Loss: 0.00253
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.89951
Value Function Update Magnitude: 0.71671
Collected Steps per Second: 11,709.82577
Overall Steps per Second: 6,604.14373
Timestep Collection Time: 4.27282
Timestep Consumption Time: 3.30333
PPO Batch Consumption Time: 0.24261
Total Iteration Time: 7.57615
Cumulative Model Updates: 183,617
Cumulative Timesteps: 1,386,453,358
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1386453358...
Checkpoint 1386453358 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.17512
Policy Entropy: 4.34819
Value Function Loss: 0.00249
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.88814
Value Function Update Magnitude: 0.73689
Collected Steps per Second: 11,856.73177
Overall Steps per Second: 6,638.64327
Timestep Collection Time: 4.21853
Timestep Consumption Time: 3.31584
PPO Batch Consumption Time: 0.23477
Total Iteration Time: 7.53437
Cumulative Model Updates: 183,626
Cumulative Timesteps: 1,386,503,376
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.00857
Policy Entropy: 4.34984
Value Function Loss: 0.00244
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02456
Policy Update Magnitude: 0.88888
Value Function Update Magnitude: 0.76893
Collected Steps per Second: 10,624.79947
Overall Steps per Second: 6,139.94403
Timestep Collection Time: 4.70804
Timestep Consumption Time: 3.43894
PPO Batch Consumption Time: 0.23192
Total Iteration Time: 8.14698
Cumulative Model Updates: 183,635
Cumulative Timesteps: 1,386,553,398
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1386553398...
Checkpoint 1386553398 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.56877
Policy Entropy: 4.35043
Value Function Loss: 0.00237
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02451
Policy Update Magnitude: 0.88375
Value Function Update Magnitude: 0.75845
Collected Steps per Second: 9,724.15927
Overall Steps per Second: 5,455.94354
Timestep Collection Time: 5.14636
Timestep Consumption Time: 4.02602
PPO Batch Consumption Time: 0.31843
Total Iteration Time: 9.17238
Cumulative Model Updates: 183,644
Cumulative Timesteps: 1,386,603,442
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.48518
Policy Entropy: 4.34714
Value Function Loss: 0.00247
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.88042
Value Function Update Magnitude: 0.77647
Collected Steps per Second: 10,053.75030
Overall Steps per Second: 5,609.73467
Timestep Collection Time: 4.97566
Timestep Consumption Time: 3.94170
PPO Batch Consumption Time: 0.32414
Total Iteration Time: 8.91736
Cumulative Model Updates: 183,653
Cumulative Timesteps: 1,386,653,466
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1386653466...
Checkpoint 1386653466 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.47090
Policy Entropy: 4.34842
Value Function Loss: 0.00247
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.89942
Value Function Update Magnitude: 0.76249
Collected Steps per Second: 10,027.97091
Overall Steps per Second: 5,526.91279
Timestep Collection Time: 4.98865
Timestep Consumption Time: 4.06270
PPO Batch Consumption Time: 0.31968
Total Iteration Time: 9.05135
Cumulative Model Updates: 183,662
Cumulative Timesteps: 1,386,703,492
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50863
Policy Entropy: 4.34515
Value Function Loss: 0.00263
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02649
Policy Update Magnitude: 0.92531
Value Function Update Magnitude: 0.77360
Collected Steps per Second: 9,943.09231
Overall Steps per Second: 5,467.70444
Timestep Collection Time: 5.03224
Timestep Consumption Time: 4.11895
PPO Batch Consumption Time: 0.32673
Total Iteration Time: 9.15119
Cumulative Model Updates: 183,671
Cumulative Timesteps: 1,386,753,528
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1386753528...
Checkpoint 1386753528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.89596
Policy Entropy: 4.34791
Value Function Loss: 0.00264
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.91456
Value Function Update Magnitude: 0.76620
Collected Steps per Second: 10,300.98948
Overall Steps per Second: 5,555.31165
Timestep Collection Time: 4.85584
Timestep Consumption Time: 4.14815
PPO Batch Consumption Time: 0.32657
Total Iteration Time: 9.00400
Cumulative Model Updates: 183,680
Cumulative Timesteps: 1,386,803,548
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79174
Policy Entropy: 4.34742
Value Function Loss: 0.00273
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02605
Policy Update Magnitude: 0.92048
Value Function Update Magnitude: 0.76447
Collected Steps per Second: 10,338.39908
Overall Steps per Second: 5,646.31022
Timestep Collection Time: 4.83943
Timestep Consumption Time: 4.02157
PPO Batch Consumption Time: 0.31752
Total Iteration Time: 8.86101
Cumulative Model Updates: 183,689
Cumulative Timesteps: 1,386,853,580
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1386853580...
Checkpoint 1386853580 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04784
Policy Entropy: 4.34563
Value Function Loss: 0.00269
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.93022
Value Function Update Magnitude: 0.75799
Collected Steps per Second: 10,046.59604
Overall Steps per Second: 5,664.97507
Timestep Collection Time: 4.97781
Timestep Consumption Time: 3.85012
PPO Batch Consumption Time: 0.31465
Total Iteration Time: 8.82793
Cumulative Model Updates: 183,698
Cumulative Timesteps: 1,386,903,590
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.34365
Policy Entropy: 4.34541
Value Function Loss: 0.00285
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.93195
Value Function Update Magnitude: 0.77719
Collected Steps per Second: 10,081.15213
Overall Steps per Second: 5,496.02848
Timestep Collection Time: 4.96511
Timestep Consumption Time: 4.14220
PPO Batch Consumption Time: 0.32927
Total Iteration Time: 9.10730
Cumulative Model Updates: 183,707
Cumulative Timesteps: 1,386,953,644
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1386953644...
Checkpoint 1386953644 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.59297
Policy Entropy: 4.34449
Value Function Loss: 0.00267
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.92259
Value Function Update Magnitude: 0.78685
Collected Steps per Second: 10,182.72904
Overall Steps per Second: 5,520.15896
Timestep Collection Time: 4.91538
Timestep Consumption Time: 4.15175
PPO Batch Consumption Time: 0.33363
Total Iteration Time: 9.06713
Cumulative Model Updates: 183,716
Cumulative Timesteps: 1,387,003,696
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.80371
Policy Entropy: 4.34702
Value Function Loss: 0.00253
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.89682
Value Function Update Magnitude: 0.78997
Collected Steps per Second: 10,098.41533
Overall Steps per Second: 5,652.73816
Timestep Collection Time: 4.95246
Timestep Consumption Time: 3.89493
PPO Batch Consumption Time: 0.31742
Total Iteration Time: 8.84739
Cumulative Model Updates: 183,725
Cumulative Timesteps: 1,387,053,708
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1387053708...
Checkpoint 1387053708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.45493
Policy Entropy: 4.34760
Value Function Loss: 0.00253
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.88104
Value Function Update Magnitude: 0.79272
Collected Steps per Second: 10,107.28655
Overall Steps per Second: 5,580.37090
Timestep Collection Time: 4.95069
Timestep Consumption Time: 4.01610
PPO Batch Consumption Time: 0.31606
Total Iteration Time: 8.96679
Cumulative Model Updates: 183,734
Cumulative Timesteps: 1,387,103,746
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50837
Policy Entropy: 4.34660
Value Function Loss: 0.00266
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02299
Policy Update Magnitude: 0.88339
Value Function Update Magnitude: 0.80913
Collected Steps per Second: 10,116.22171
Overall Steps per Second: 5,627.80521
Timestep Collection Time: 4.94592
Timestep Consumption Time: 3.94458
PPO Batch Consumption Time: 0.31545
Total Iteration Time: 8.89050
Cumulative Model Updates: 183,743
Cumulative Timesteps: 1,387,153,780
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1387153780...
Checkpoint 1387153780 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.92021
Policy Entropy: 4.34606
Value Function Loss: 0.00278
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.89374
Value Function Update Magnitude: 0.80048
Collected Steps per Second: 10,276.45919
Overall Steps per Second: 5,590.37767
Timestep Collection Time: 4.86666
Timestep Consumption Time: 4.07943
PPO Batch Consumption Time: 0.32215
Total Iteration Time: 8.94609
Cumulative Model Updates: 183,752
Cumulative Timesteps: 1,387,203,792
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.92952
Policy Entropy: 4.34368
Value Function Loss: 0.00257
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.89724
Value Function Update Magnitude: 0.80039
Collected Steps per Second: 9,948.82956
Overall Steps per Second: 5,465.53068
Timestep Collection Time: 5.02913
Timestep Consumption Time: 4.12533
PPO Batch Consumption Time: 0.32637
Total Iteration Time: 9.15446
Cumulative Model Updates: 183,761
Cumulative Timesteps: 1,387,253,826
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1387253826...
Checkpoint 1387253826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.60958
Policy Entropy: 4.34637
Value Function Loss: 0.00266
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.88026
Value Function Update Magnitude: 0.77973
Collected Steps per Second: 8,328.03298
Overall Steps per Second: 4,872.70929
Timestep Collection Time: 6.00526
Timestep Consumption Time: 4.25843
PPO Batch Consumption Time: 0.33452
Total Iteration Time: 10.26369
Cumulative Model Updates: 183,770
Cumulative Timesteps: 1,387,303,838
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09402
Policy Entropy: 4.34767
Value Function Loss: 0.00251
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.88695
Value Function Update Magnitude: 0.77045
Collected Steps per Second: 9,616.99864
Overall Steps per Second: 5,309.50406
Timestep Collection Time: 5.20141
Timestep Consumption Time: 4.21980
PPO Batch Consumption Time: 0.32549
Total Iteration Time: 9.42122
Cumulative Model Updates: 183,779
Cumulative Timesteps: 1,387,353,860
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1387353860...
Checkpoint 1387353860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85884
Policy Entropy: 4.35065
Value Function Loss: 0.00243
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.86878
Value Function Update Magnitude: 0.70279
Collected Steps per Second: 10,090.02445
Overall Steps per Second: 5,603.87933
Timestep Collection Time: 4.95816
Timestep Consumption Time: 3.96922
PPO Batch Consumption Time: 0.31707
Total Iteration Time: 8.92739
Cumulative Model Updates: 183,788
Cumulative Timesteps: 1,387,403,888
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77309
Policy Entropy: 4.35073
Value Function Loss: 0.00228
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02184
Policy Update Magnitude: 0.85215
Value Function Update Magnitude: 0.67624
Collected Steps per Second: 10,297.55159
Overall Steps per Second: 5,654.75111
Timestep Collection Time: 4.85611
Timestep Consumption Time: 3.98708
PPO Batch Consumption Time: 0.31770
Total Iteration Time: 8.84318
Cumulative Model Updates: 183,797
Cumulative Timesteps: 1,387,453,894
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1387453894...
Checkpoint 1387453894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12650
Policy Entropy: 4.35039
Value Function Loss: 0.00245
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02430
Policy Update Magnitude: 0.86445
Value Function Update Magnitude: 0.72465
Collected Steps per Second: 10,875.00061
Overall Steps per Second: 5,749.29324
Timestep Collection Time: 4.59788
Timestep Consumption Time: 4.09918
PPO Batch Consumption Time: 0.32659
Total Iteration Time: 8.69707
Cumulative Model Updates: 183,806
Cumulative Timesteps: 1,387,503,896
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49329
Policy Entropy: 4.34088
Value Function Loss: 0.00265
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.91122
Value Function Update Magnitude: 0.71676
Collected Steps per Second: 10,457.04947
Overall Steps per Second: 5,580.65288
Timestep Collection Time: 4.78223
Timestep Consumption Time: 4.17873
PPO Batch Consumption Time: 0.34266
Total Iteration Time: 8.96096
Cumulative Model Updates: 183,815
Cumulative Timesteps: 1,387,553,904
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1387553904...
Checkpoint 1387553904 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.42257
Policy Entropy: 4.34124
Value Function Loss: 0.00271
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.91583
Value Function Update Magnitude: 0.73257
Collected Steps per Second: 10,287.62442
Overall Steps per Second: 5,466.97278
Timestep Collection Time: 4.86176
Timestep Consumption Time: 4.28699
PPO Batch Consumption Time: 0.34714
Total Iteration Time: 9.14876
Cumulative Model Updates: 183,824
Cumulative Timesteps: 1,387,603,920
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.76653
Policy Entropy: 4.34395
Value Function Loss: 0.00273
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.90707
Value Function Update Magnitude: 0.74811
Collected Steps per Second: 10,080.29718
Overall Steps per Second: 5,552.87396
Timestep Collection Time: 4.96235
Timestep Consumption Time: 4.04595
PPO Batch Consumption Time: 0.32150
Total Iteration Time: 9.00831
Cumulative Model Updates: 183,833
Cumulative Timesteps: 1,387,653,942
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1387653942...
Checkpoint 1387653942 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.26725
Policy Entropy: 4.35047
Value Function Loss: 0.00259
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.89846
Value Function Update Magnitude: 0.81990
Collected Steps per Second: 10,284.85134
Overall Steps per Second: 5,755.48863
Timestep Collection Time: 4.86191
Timestep Consumption Time: 3.82615
PPO Batch Consumption Time: 0.31419
Total Iteration Time: 8.68805
Cumulative Model Updates: 183,842
Cumulative Timesteps: 1,387,703,946
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.20531
Policy Entropy: 4.34990
Value Function Loss: 0.00261
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.89420
Value Function Update Magnitude: 0.82074
Collected Steps per Second: 10,487.43753
Overall Steps per Second: 5,660.60808
Timestep Collection Time: 4.76971
Timestep Consumption Time: 4.06715
PPO Batch Consumption Time: 0.32288
Total Iteration Time: 8.83686
Cumulative Model Updates: 183,851
Cumulative Timesteps: 1,387,753,968
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1387753968...
Checkpoint 1387753968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.92429
Policy Entropy: 4.35149
Value Function Loss: 0.00239
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.86653
Value Function Update Magnitude: 0.75822
Collected Steps per Second: 10,389.57089
Overall Steps per Second: 5,735.05388
Timestep Collection Time: 4.81310
Timestep Consumption Time: 3.90626
PPO Batch Consumption Time: 0.31153
Total Iteration Time: 8.71936
Cumulative Model Updates: 183,860
Cumulative Timesteps: 1,387,803,974
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.35908
Policy Entropy: 4.35031
Value Function Loss: 0.00245
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.86495
Value Function Update Magnitude: 0.71214
Collected Steps per Second: 10,862.10299
Overall Steps per Second: 5,838.72829
Timestep Collection Time: 4.60537
Timestep Consumption Time: 3.96225
PPO Batch Consumption Time: 0.31128
Total Iteration Time: 8.56762
Cumulative Model Updates: 183,869
Cumulative Timesteps: 1,387,853,998
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1387853998...
Checkpoint 1387853998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.83829
Policy Entropy: 4.34509
Value Function Loss: 0.00260
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.90530
Value Function Update Magnitude: 0.75409
Collected Steps per Second: 10,574.41788
Overall Steps per Second: 5,730.30211
Timestep Collection Time: 4.73066
Timestep Consumption Time: 3.99907
PPO Batch Consumption Time: 0.31798
Total Iteration Time: 8.72973
Cumulative Model Updates: 183,878
Cumulative Timesteps: 1,387,904,022
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.08710
Policy Entropy: 4.34037
Value Function Loss: 0.00267
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02705
Policy Update Magnitude: 0.92125
Value Function Update Magnitude: 0.77611
Collected Steps per Second: 10,439.98436
Overall Steps per Second: 5,697.55281
Timestep Collection Time: 4.79330
Timestep Consumption Time: 3.98977
PPO Batch Consumption Time: 0.31792
Total Iteration Time: 8.78307
Cumulative Model Updates: 183,887
Cumulative Timesteps: 1,387,954,064
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1387954064...
Checkpoint 1387954064 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54023
Policy Entropy: 4.33902
Value Function Loss: 0.00266
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.90712
Value Function Update Magnitude: 0.75834
Collected Steps per Second: 10,715.89018
Overall Steps per Second: 5,824.88663
Timestep Collection Time: 4.66821
Timestep Consumption Time: 3.91977
PPO Batch Consumption Time: 0.31009
Total Iteration Time: 8.58798
Cumulative Model Updates: 183,896
Cumulative Timesteps: 1,388,004,088
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.04757
Policy Entropy: 4.34171
Value Function Loss: 0.00266
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.90001
Value Function Update Magnitude: 0.78463
Collected Steps per Second: 10,408.61526
Overall Steps per Second: 5,639.84787
Timestep Collection Time: 4.80506
Timestep Consumption Time: 4.06291
PPO Batch Consumption Time: 0.32150
Total Iteration Time: 8.86797
Cumulative Model Updates: 183,905
Cumulative Timesteps: 1,388,054,102
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1388054102...
Checkpoint 1388054102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.70046
Policy Entropy: 4.34798
Value Function Loss: 0.00262
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.88441
Value Function Update Magnitude: 0.77498
Collected Steps per Second: 10,492.34576
Overall Steps per Second: 5,809.56381
Timestep Collection Time: 4.76786
Timestep Consumption Time: 3.84312
PPO Batch Consumption Time: 0.31337
Total Iteration Time: 8.61097
Cumulative Model Updates: 183,914
Cumulative Timesteps: 1,388,104,128
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.82937
Policy Entropy: 4.34452
Value Function Loss: 0.00260
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02405
Policy Update Magnitude: 0.87236
Value Function Update Magnitude: 0.76842
Collected Steps per Second: 10,517.12404
Overall Steps per Second: 5,750.51805
Timestep Collection Time: 4.75415
Timestep Consumption Time: 3.94072
PPO Batch Consumption Time: 0.31204
Total Iteration Time: 8.69487
Cumulative Model Updates: 183,923
Cumulative Timesteps: 1,388,154,128
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1388154128...
Checkpoint 1388154128 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76185
Policy Entropy: 4.35015
Value Function Loss: 0.00229
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02202
Policy Update Magnitude: 0.85103
Value Function Update Magnitude: 0.74023
Collected Steps per Second: 10,500.41413
Overall Steps per Second: 5,750.53139
Timestep Collection Time: 4.76267
Timestep Consumption Time: 3.93392
PPO Batch Consumption Time: 0.31670
Total Iteration Time: 8.69659
Cumulative Model Updates: 183,932
Cumulative Timesteps: 1,388,204,138
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.48033
Policy Entropy: 4.34835
Value Function Loss: 0.00236
Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02089
Policy Update Magnitude: 0.83172
Value Function Update Magnitude: 0.74264
Collected Steps per Second: 10,351.78760
Overall Steps per Second: 5,759.50337
Timestep Collection Time: 4.83317
Timestep Consumption Time: 3.85369
PPO Batch Consumption Time: 0.31448
Total Iteration Time: 8.68686
Cumulative Model Updates: 183,941
Cumulative Timesteps: 1,388,254,170
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1388254170...
Checkpoint 1388254170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.27190
Policy Entropy: 4.34417
Value Function Loss: 0.00257
Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02192
Policy Update Magnitude: 0.86486
Value Function Update Magnitude: 0.76326
Collected Steps per Second: 10,476.03989
Overall Steps per Second: 5,758.88885
Timestep Collection Time: 4.77318
Timestep Consumption Time: 3.90975
PPO Batch Consumption Time: 0.30839
Total Iteration Time: 8.68292
Cumulative Model Updates: 183,950
Cumulative Timesteps: 1,388,304,174
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.67012
Policy Entropy: 4.34178
Value Function Loss: 0.00273
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02382
Policy Update Magnitude: 0.90290
Value Function Update Magnitude: 0.76657
Collected Steps per Second: 10,465.45093
Overall Steps per Second: 5,673.20941
Timestep Collection Time: 4.77763
Timestep Consumption Time: 4.03573
PPO Batch Consumption Time: 0.31999
Total Iteration Time: 8.81335
Cumulative Model Updates: 183,959
Cumulative Timesteps: 1,388,354,174
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1388354174...
Checkpoint 1388354174 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45597
Policy Entropy: 4.33951
Value Function Loss: 0.00267
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.90989
Value Function Update Magnitude: 0.75639
Collected Steps per Second: 10,623.11704
Overall Steps per Second: 5,712.89753
Timestep Collection Time: 4.70898
Timestep Consumption Time: 4.04735
PPO Batch Consumption Time: 0.32687
Total Iteration Time: 8.75633
Cumulative Model Updates: 183,968
Cumulative Timesteps: 1,388,404,198
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88751
Policy Entropy: 4.34233
Value Function Loss: 0.00270
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.89723
Value Function Update Magnitude: 0.78639
Collected Steps per Second: 10,455.62933
Overall Steps per Second: 5,456.74585
Timestep Collection Time: 4.78345
Timestep Consumption Time: 4.38208
PPO Batch Consumption Time: 0.35819
Total Iteration Time: 9.16554
Cumulative Model Updates: 183,977
Cumulative Timesteps: 1,388,454,212
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1388454212...
Checkpoint 1388454212 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61275
Policy Entropy: 4.34417
Value Function Loss: 0.00248
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02282
Policy Update Magnitude: 0.87690
Value Function Update Magnitude: 0.76858
Collected Steps per Second: 10,232.20260
Overall Steps per Second: 5,466.18050
Timestep Collection Time: 4.88868
Timestep Consumption Time: 4.26250
PPO Batch Consumption Time: 0.35799
Total Iteration Time: 9.15118
Cumulative Model Updates: 183,986
Cumulative Timesteps: 1,388,504,234
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.26497
Policy Entropy: 4.34149
Value Function Loss: 0.00267
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.87936
Value Function Update Magnitude: 0.73463
Collected Steps per Second: 10,283.42527
Overall Steps per Second: 5,410.28179
Timestep Collection Time: 4.86628
Timestep Consumption Time: 4.38315
PPO Batch Consumption Time: 0.35809
Total Iteration Time: 9.24943
Cumulative Model Updates: 183,995
Cumulative Timesteps: 1,388,554,276
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1388554276...
Checkpoint 1388554276 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.28118
Policy Entropy: 4.34180
Value Function Loss: 0.00258
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.87649
Value Function Update Magnitude: 0.74097
Collected Steps per Second: 10,815.14524
Overall Steps per Second: 5,585.13958
Timestep Collection Time: 4.62444
Timestep Consumption Time: 4.33039
PPO Batch Consumption Time: 0.35869
Total Iteration Time: 8.95483
Cumulative Model Updates: 184,004
Cumulative Timesteps: 1,388,604,290
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17728
Policy Entropy: 4.34179
Value Function Loss: 0.00253
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02456
Policy Update Magnitude: 0.86343
Value Function Update Magnitude: 0.73724
Collected Steps per Second: 10,846.43078
Overall Steps per Second: 5,551.98983
Timestep Collection Time: 4.61166
Timestep Consumption Time: 4.39773
PPO Batch Consumption Time: 0.36010
Total Iteration Time: 9.00938
Cumulative Model Updates: 184,013
Cumulative Timesteps: 1,388,654,310
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1388654310...
Checkpoint 1388654310 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39815
Policy Entropy: 4.34506
Value Function Loss: 0.00241
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02320
Policy Update Magnitude: 0.86045
Value Function Update Magnitude: 0.69803
Collected Steps per Second: 10,107.66170
Overall Steps per Second: 5,372.42007
Timestep Collection Time: 4.94694
Timestep Consumption Time: 4.36022
PPO Batch Consumption Time: 0.35798
Total Iteration Time: 9.30716
Cumulative Model Updates: 184,022
Cumulative Timesteps: 1,388,704,312
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.07572
Policy Entropy: 4.34774
Value Function Loss: 0.00242
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.87100
Value Function Update Magnitude: 0.71394
Collected Steps per Second: 10,228.20306
Overall Steps per Second: 5,421.70577
Timestep Collection Time: 4.89099
Timestep Consumption Time: 4.33600
PPO Batch Consumption Time: 0.35795
Total Iteration Time: 9.22699
Cumulative Model Updates: 184,031
Cumulative Timesteps: 1,388,754,338
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1388754338...
Checkpoint 1388754338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.62013
Policy Entropy: 4.34228
Value Function Loss: 0.00251
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02268
Policy Update Magnitude: 0.88803
Value Function Update Magnitude: 0.78903
Collected Steps per Second: 10,360.70133
Overall Steps per Second: 5,435.68068
Timestep Collection Time: 4.82940
Timestep Consumption Time: 4.37570
PPO Batch Consumption Time: 0.35932
Total Iteration Time: 9.20510
Cumulative Model Updates: 184,040
Cumulative Timesteps: 1,388,804,374
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.58820
Policy Entropy: 4.34048
Value Function Loss: 0.00245
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02501
Policy Update Magnitude: 0.89019
Value Function Update Magnitude: 0.77923
Collected Steps per Second: 10,707.51583
Overall Steps per Second: 5,510.51138
Timestep Collection Time: 4.67074
Timestep Consumption Time: 4.40501
PPO Batch Consumption Time: 0.36063
Total Iteration Time: 9.07575
Cumulative Model Updates: 184,049
Cumulative Timesteps: 1,388,854,386
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1388854386...
Checkpoint 1388854386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.15461
Policy Entropy: 4.33943
Value Function Loss: 0.00245
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.88224
Value Function Update Magnitude: 0.72529
Collected Steps per Second: 10,344.38627
Overall Steps per Second: 5,496.32781
Timestep Collection Time: 4.83431
Timestep Consumption Time: 4.26413
PPO Batch Consumption Time: 0.35962
Total Iteration Time: 9.09844
Cumulative Model Updates: 184,058
Cumulative Timesteps: 1,388,904,394
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66999
Policy Entropy: 4.34037
Value Function Loss: 0.00271
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02248
Policy Update Magnitude: 0.89907
Value Function Update Magnitude: 0.73141
Collected Steps per Second: 10,211.14493
Overall Steps per Second: 5,360.65249
Timestep Collection Time: 4.89798
Timestep Consumption Time: 4.43185
PPO Batch Consumption Time: 0.35916
Total Iteration Time: 9.32983
Cumulative Model Updates: 184,067
Cumulative Timesteps: 1,388,954,408
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1388954408...
Checkpoint 1388954408 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.62123
Policy Entropy: 4.33638
Value Function Loss: 0.00267
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.89834
Value Function Update Magnitude: 0.68577
Collected Steps per Second: 9,463.97367
Overall Steps per Second: 5,084.89618
Timestep Collection Time: 5.28657
Timestep Consumption Time: 4.55276
PPO Batch Consumption Time: 0.36125
Total Iteration Time: 9.83934
Cumulative Model Updates: 184,076
Cumulative Timesteps: 1,389,004,440
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43144
Policy Entropy: 4.33754
Value Function Loss: 0.00268
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02567
Policy Update Magnitude: 0.89066
Value Function Update Magnitude: 0.67259
Collected Steps per Second: 9,901.09567
Overall Steps per Second: 4,830.73575
Timestep Collection Time: 5.05500
Timestep Consumption Time: 5.30574
PPO Batch Consumption Time: 0.47027
Total Iteration Time: 10.36074
Cumulative Model Updates: 184,085
Cumulative Timesteps: 1,389,054,490
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1389054490...
Checkpoint 1389054490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.83133
Policy Entropy: 4.33699
Value Function Loss: 0.00254
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.88703
Value Function Update Magnitude: 0.68429
Collected Steps per Second: 10,574.42733
Overall Steps per Second: 6,183.06075
Timestep Collection Time: 4.73028
Timestep Consumption Time: 3.35956
PPO Batch Consumption Time: 0.24485
Total Iteration Time: 8.08984
Cumulative Model Updates: 184,094
Cumulative Timesteps: 1,389,104,510
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.92177
Policy Entropy: 4.34257
Value Function Loss: 0.00258
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.89303
Value Function Update Magnitude: 0.68456
Collected Steps per Second: 11,310.77456
Overall Steps per Second: 6,701.91520
Timestep Collection Time: 4.42410
Timestep Consumption Time: 3.04242
PPO Batch Consumption Time: 0.22930
Total Iteration Time: 7.46652
Cumulative Model Updates: 184,103
Cumulative Timesteps: 1,389,154,550
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1389154550...
Checkpoint 1389154550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.94040
Policy Entropy: 4.34255
Value Function Loss: 0.00251
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.87864
Value Function Update Magnitude: 0.68001
Collected Steps per Second: 12,410.05924
Overall Steps per Second: 6,945.10064
Timestep Collection Time: 4.03270
Timestep Consumption Time: 3.17325
PPO Batch Consumption Time: 0.22963
Total Iteration Time: 7.20594
Cumulative Model Updates: 184,112
Cumulative Timesteps: 1,389,204,596
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.15832
Policy Entropy: 4.34286
Value Function Loss: 0.00240
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.86372
Value Function Update Magnitude: 0.66271
Collected Steps per Second: 12,754.26000
Overall Steps per Second: 7,134.46289
Timestep Collection Time: 3.92481
Timestep Consumption Time: 3.09156
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 7.01637
Cumulative Model Updates: 184,121
Cumulative Timesteps: 1,389,254,654
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 1389254654...
Checkpoint 1389254654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.39613
Policy Entropy: 4.34049
Value Function Loss: 0.00261
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.90216
Value Function Update Magnitude: 0.65941
Collected Steps per Second: 11,964.98876
Overall Steps per Second: 6,933.79625
Timestep Collection Time: 4.18003
Timestep Consumption Time: 3.03305
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 7.21308
Cumulative Model Updates: 184,130
Cumulative Timesteps: 1,389,304,668
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27520
Policy Entropy: 4.33850
Value Function Loss: 0.00264
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.90527
Value Function Update Magnitude: 0.66696
Collected Steps per Second: 12,996.47978
Overall Steps per Second: 7,066.19133
Timestep Collection Time: 3.84735
Timestep Consumption Time: 3.22888
PPO Batch Consumption Time: 0.23756
Total Iteration Time: 7.07623
Cumulative Model Updates: 184,139
Cumulative Timesteps: 1,389,354,670
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1389354670...
Checkpoint 1389354670 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43006
Policy Entropy: 4.33689
Value Function Loss: 0.00269
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02440
Policy Update Magnitude: 0.89596
Value Function Update Magnitude: 0.63621
Collected Steps per Second: 11,666.97252
Overall Steps per Second: 6,750.66295
Timestep Collection Time: 4.28749
Timestep Consumption Time: 3.12245
PPO Batch Consumption Time: 0.23253
Total Iteration Time: 7.40994
Cumulative Model Updates: 184,148
Cumulative Timesteps: 1,389,404,692
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75383
Policy Entropy: 4.33984
Value Function Loss: 0.00240
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.87698
Value Function Update Magnitude: 0.62701
Collected Steps per Second: 12,773.35219
Overall Steps per Second: 7,014.98201
Timestep Collection Time: 3.91722
Timestep Consumption Time: 3.21552
PPO Batch Consumption Time: 0.23786
Total Iteration Time: 7.13273
Cumulative Model Updates: 184,157
Cumulative Timesteps: 1,389,454,728
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1389454728...
Checkpoint 1389454728 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.69163
Policy Entropy: 4.34284
Value Function Loss: 0.00238
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02332
Policy Update Magnitude: 0.85217
Value Function Update Magnitude: 0.66546
Collected Steps per Second: 13,180.96501
Overall Steps per Second: 7,201.35833
Timestep Collection Time: 3.79350
Timestep Consumption Time: 3.14991
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.94341
Cumulative Model Updates: 184,166
Cumulative Timesteps: 1,389,504,730
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30764
Policy Entropy: 4.34331
Value Function Loss: 0.00235
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.84739
Value Function Update Magnitude: 0.73549
Collected Steps per Second: 13,113.44755
Overall Steps per Second: 7,251.16663
Timestep Collection Time: 3.81334
Timestep Consumption Time: 3.08293
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.89627
Cumulative Model Updates: 184,175
Cumulative Timesteps: 1,389,554,736
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1389554736...
Checkpoint 1389554736 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.72052
Policy Entropy: 4.34097
Value Function Loss: 0.00235
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.86657
Value Function Update Magnitude: 0.73392
Collected Steps per Second: 13,393.15585
Overall Steps per Second: 7,303.65775
Timestep Collection Time: 3.73639
Timestep Consumption Time: 3.11525
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.85164
Cumulative Model Updates: 184,184
Cumulative Timesteps: 1,389,604,778
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.01100
Policy Entropy: 4.34366
Value Function Loss: 0.00229
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.83889
Value Function Update Magnitude: 0.70241
Collected Steps per Second: 12,393.28520
Overall Steps per Second: 6,988.68145
Timestep Collection Time: 4.03719
Timestep Consumption Time: 3.12210
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 7.15929
Cumulative Model Updates: 184,193
Cumulative Timesteps: 1,389,654,812
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1389654812...
Checkpoint 1389654812 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.13440
Policy Entropy: 4.34646
Value Function Loss: 0.00227
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.82086
Value Function Update Magnitude: 0.67940
Collected Steps per Second: 11,851.31118
Overall Steps per Second: 6,854.58101
Timestep Collection Time: 4.22080
Timestep Consumption Time: 3.07680
PPO Batch Consumption Time: 0.23375
Total Iteration Time: 7.29760
Cumulative Model Updates: 184,202
Cumulative Timesteps: 1,389,704,834
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.78806
Policy Entropy: 4.34313
Value Function Loss: 0.00260
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.86361
Value Function Update Magnitude: 0.72927
Collected Steps per Second: 12,335.63270
Overall Steps per Second: 6,915.45730
Timestep Collection Time: 4.05443
Timestep Consumption Time: 3.17777
PPO Batch Consumption Time: 0.23171
Total Iteration Time: 7.23220
Cumulative Model Updates: 184,211
Cumulative Timesteps: 1,389,754,848
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1389754848...
Checkpoint 1389754848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.46275
Policy Entropy: 4.34084
Value Function Loss: 0.00270
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02732
Policy Update Magnitude: 0.90543
Value Function Update Magnitude: 0.70551
Collected Steps per Second: 13,124.69430
Overall Steps per Second: 6,940.22619
Timestep Collection Time: 3.81297
Timestep Consumption Time: 3.39775
PPO Batch Consumption Time: 0.25805
Total Iteration Time: 7.21072
Cumulative Model Updates: 184,220
Cumulative Timesteps: 1,389,804,892
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.05266
Policy Entropy: 4.34118
Value Function Loss: 0.00262
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.88008
Value Function Update Magnitude: 0.72737
Collected Steps per Second: 11,730.98544
Overall Steps per Second: 6,700.35238
Timestep Collection Time: 4.26409
Timestep Consumption Time: 3.20149
PPO Batch Consumption Time: 0.24396
Total Iteration Time: 7.46558
Cumulative Model Updates: 184,229
Cumulative Timesteps: 1,389,854,914
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1389854914...
Checkpoint 1389854914 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33945
Policy Entropy: 4.34107
Value Function Loss: 0.00272
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.88134
Value Function Update Magnitude: 0.74542
Collected Steps per Second: 11,857.63686
Overall Steps per Second: 6,667.60682
Timestep Collection Time: 4.21821
Timestep Consumption Time: 3.28343
PPO Batch Consumption Time: 0.24302
Total Iteration Time: 7.50164
Cumulative Model Updates: 184,238
Cumulative Timesteps: 1,389,904,932
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.24698
Policy Entropy: 4.33929
Value Function Loss: 0.00255
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.87643
Value Function Update Magnitude: 0.72671
Collected Steps per Second: 11,771.77270
Overall Steps per Second: 6,669.20906
Timestep Collection Time: 4.25102
Timestep Consumption Time: 3.25242
PPO Batch Consumption Time: 0.24335
Total Iteration Time: 7.50344
Cumulative Model Updates: 184,247
Cumulative Timesteps: 1,389,954,974
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1389954974...
Checkpoint 1389954974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.33637
Policy Entropy: 4.33564
Value Function Loss: 0.00269
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.87727
Value Function Update Magnitude: 0.71289
Collected Steps per Second: 12,102.13476
Overall Steps per Second: 6,752.80299
Timestep Collection Time: 4.13398
Timestep Consumption Time: 3.27479
PPO Batch Consumption Time: 0.24336
Total Iteration Time: 7.40878
Cumulative Model Updates: 184,256
Cumulative Timesteps: 1,390,005,004
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.00894
Policy Entropy: 4.34144
Value Function Loss: 0.00245
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.87251
Value Function Update Magnitude: 0.72763
Collected Steps per Second: 11,725.65339
Overall Steps per Second: 6,619.83057
Timestep Collection Time: 4.26415
Timestep Consumption Time: 3.28891
PPO Batch Consumption Time: 0.24254
Total Iteration Time: 7.55306
Cumulative Model Updates: 184,265
Cumulative Timesteps: 1,390,055,004
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1390055004...
Checkpoint 1390055004 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.59445
Policy Entropy: 4.34066
Value Function Loss: 0.00257
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.83856
Value Function Update Magnitude: 0.73439
Collected Steps per Second: 11,717.17967
Overall Steps per Second: 6,615.29680
Timestep Collection Time: 4.26860
Timestep Consumption Time: 3.29205
PPO Batch Consumption Time: 0.24377
Total Iteration Time: 7.56066
Cumulative Model Updates: 184,274
Cumulative Timesteps: 1,390,105,020
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.90612
Policy Entropy: 4.34352
Value Function Loss: 0.00271
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02342
Policy Update Magnitude: 0.87272
Value Function Update Magnitude: 0.76954
Collected Steps per Second: 13,068.23032
Overall Steps per Second: 7,138.18749
Timestep Collection Time: 3.82837
Timestep Consumption Time: 3.18041
PPO Batch Consumption Time: 0.23135
Total Iteration Time: 7.00878
Cumulative Model Updates: 184,283
Cumulative Timesteps: 1,390,155,050
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1390155050...
Checkpoint 1390155050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20792
Policy Entropy: 4.33395
Value Function Loss: 0.00291
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.91971
Value Function Update Magnitude: 0.73672
Collected Steps per Second: 10,879.01572
Overall Steps per Second: 6,401.22541
Timestep Collection Time: 4.59637
Timestep Consumption Time: 3.21526
PPO Batch Consumption Time: 0.24014
Total Iteration Time: 7.81163
Cumulative Model Updates: 184,292
Cumulative Timesteps: 1,390,205,054
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.48937
Policy Entropy: 4.33411
Value Function Loss: 0.00288
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02849
Policy Update Magnitude: 0.91983
Value Function Update Magnitude: 0.72991
Collected Steps per Second: 12,218.81117
Overall Steps per Second: 7,001.53237
Timestep Collection Time: 4.09320
Timestep Consumption Time: 3.05010
PPO Batch Consumption Time: 0.23229
Total Iteration Time: 7.14329
Cumulative Model Updates: 184,301
Cumulative Timesteps: 1,390,255,068
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1390255068...
Checkpoint 1390255068 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73259
Policy Entropy: 4.33388
Value Function Loss: 0.00284
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.91026
Value Function Update Magnitude: 0.71028
Collected Steps per Second: 12,210.23017
Overall Steps per Second: 6,863.05520
Timestep Collection Time: 4.09509
Timestep Consumption Time: 3.19059
PPO Batch Consumption Time: 0.23607
Total Iteration Time: 7.28568
Cumulative Model Updates: 184,310
Cumulative Timesteps: 1,390,305,070
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.28856
Policy Entropy: 4.33643
Value Function Loss: 0.00272
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02705
Policy Update Magnitude: 0.89501
Value Function Update Magnitude: 0.73515
Collected Steps per Second: 11,378.47381
Overall Steps per Second: 6,602.86641
Timestep Collection Time: 4.39743
Timestep Consumption Time: 3.18049
PPO Batch Consumption Time: 0.23352
Total Iteration Time: 7.57792
Cumulative Model Updates: 184,319
Cumulative Timesteps: 1,390,355,106
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1390355106...
Checkpoint 1390355106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.11570
Policy Entropy: 4.33831
Value Function Loss: 0.00278
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.89364
Value Function Update Magnitude: 0.73082
Collected Steps per Second: 12,039.38645
Overall Steps per Second: 6,772.29224
Timestep Collection Time: 4.15569
Timestep Consumption Time: 3.23206
PPO Batch Consumption Time: 0.24134
Total Iteration Time: 7.38775
Cumulative Model Updates: 184,328
Cumulative Timesteps: 1,390,405,138
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.38487
Policy Entropy: 4.34154
Value Function Loss: 0.00247
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02574
Policy Update Magnitude: 0.86462
Value Function Update Magnitude: 0.72270
Collected Steps per Second: 11,393.70097
Overall Steps per Second: 6,584.92553
Timestep Collection Time: 4.38839
Timestep Consumption Time: 3.20471
PPO Batch Consumption Time: 0.23185
Total Iteration Time: 7.59310
Cumulative Model Updates: 184,337
Cumulative Timesteps: 1,390,455,138
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1390455138...
Checkpoint 1390455138 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.66250
Policy Entropy: 4.34427
Value Function Loss: 0.00247
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02503
Policy Update Magnitude: 0.84372
Value Function Update Magnitude: 0.71033
Collected Steps per Second: 12,235.27236
Overall Steps per Second: 6,740.71234
Timestep Collection Time: 4.08753
Timestep Consumption Time: 3.33187
PPO Batch Consumption Time: 0.25277
Total Iteration Time: 7.41939
Cumulative Model Updates: 184,346
Cumulative Timesteps: 1,390,505,150
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.51798
Policy Entropy: 4.34657
Value Function Loss: 0.00234
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02276
Policy Update Magnitude: 0.82693
Value Function Update Magnitude: 0.74203
Collected Steps per Second: 11,002.01981
Overall Steps per Second: 6,371.30996
Timestep Collection Time: 4.54662
Timestep Consumption Time: 3.30451
PPO Batch Consumption Time: 0.24026
Total Iteration Time: 7.85113
Cumulative Model Updates: 184,355
Cumulative Timesteps: 1,390,555,172
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1390555172...
Checkpoint 1390555172 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.71064
Policy Entropy: 4.34687
Value Function Loss: 0.00245
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02181
Policy Update Magnitude: 0.83737
Value Function Update Magnitude: 0.77039
Collected Steps per Second: 12,211.23558
Overall Steps per Second: 6,709.10726
Timestep Collection Time: 4.09705
Timestep Consumption Time: 3.35998
PPO Batch Consumption Time: 0.24979
Total Iteration Time: 7.45703
Cumulative Model Updates: 184,364
Cumulative Timesteps: 1,390,605,202
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.92793
Policy Entropy: 4.35036
Value Function Loss: 0.00233
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02314
Policy Update Magnitude: 0.83244
Value Function Update Magnitude: 0.74402
Collected Steps per Second: 11,137.41509
Overall Steps per Second: 6,564.63541
Timestep Collection Time: 4.49045
Timestep Consumption Time: 3.12795
PPO Batch Consumption Time: 0.23348
Total Iteration Time: 7.61840
Cumulative Model Updates: 184,373
Cumulative Timesteps: 1,390,655,214
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1390655214...
Checkpoint 1390655214 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82505
Policy Entropy: 4.35181
Value Function Loss: 0.00227
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02255
Policy Update Magnitude: 0.81626
Value Function Update Magnitude: 0.74227
Collected Steps per Second: 11,873.89562
Overall Steps per Second: 6,552.15924
Timestep Collection Time: 4.21260
Timestep Consumption Time: 3.42152
PPO Batch Consumption Time: 0.25804
Total Iteration Time: 7.63412
Cumulative Model Updates: 184,382
Cumulative Timesteps: 1,390,705,234
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.40487
Policy Entropy: 4.35540
Value Function Loss: 0.00223
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02161
Policy Update Magnitude: 0.81947
Value Function Update Magnitude: 0.73691
Collected Steps per Second: 11,705.25822
Overall Steps per Second: 6,610.75994
Timestep Collection Time: 4.27176
Timestep Consumption Time: 3.29197
PPO Batch Consumption Time: 0.24553
Total Iteration Time: 7.56373
Cumulative Model Updates: 184,391
Cumulative Timesteps: 1,390,755,236
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1390755236...
Checkpoint 1390755236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.29401
Policy Entropy: 4.35490
Value Function Loss: 0.00214
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02110
Policy Update Magnitude: 0.78943
Value Function Update Magnitude: 0.77564
Collected Steps per Second: 12,584.31250
Overall Steps per Second: 7,148.31246
Timestep Collection Time: 3.97400
Timestep Consumption Time: 3.02206
PPO Batch Consumption Time: 0.23048
Total Iteration Time: 6.99606
Cumulative Model Updates: 184,400
Cumulative Timesteps: 1,390,805,246
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.36171
Policy Entropy: 4.35282
Value Function Loss: 0.00220
Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01992
Policy Update Magnitude: 0.79740
Value Function Update Magnitude: 0.72101
Collected Steps per Second: 12,350.01441
Overall Steps per Second: 6,800.06753
Timestep Collection Time: 4.04906
Timestep Consumption Time: 3.30469
PPO Batch Consumption Time: 0.24368
Total Iteration Time: 7.35375
Cumulative Model Updates: 184,409
Cumulative Timesteps: 1,390,855,252
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1390855252...
Checkpoint 1390855252 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.45332
Policy Entropy: 4.35001
Value Function Loss: 0.00241
Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01939
Policy Update Magnitude: 0.86319
Value Function Update Magnitude: 0.75842
Collected Steps per Second: 12,720.82735
Overall Steps per Second: 6,952.74865
Timestep Collection Time: 3.93088
Timestep Consumption Time: 3.26110
PPO Batch Consumption Time: 0.24590
Total Iteration Time: 7.19198
Cumulative Model Updates: 184,418
Cumulative Timesteps: 1,390,905,256
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.59032
Policy Entropy: 4.34884
Value Function Loss: 0.00262
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.87199
Value Function Update Magnitude: 0.75976
Collected Steps per Second: 12,323.56298
Overall Steps per Second: 6,926.10888
Timestep Collection Time: 4.05873
Timestep Consumption Time: 3.16293
PPO Batch Consumption Time: 0.23454
Total Iteration Time: 7.22166
Cumulative Model Updates: 184,427
Cumulative Timesteps: 1,390,955,274
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1390955274...
Checkpoint 1390955274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10440
Policy Entropy: 4.34879
Value Function Loss: 0.00263
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.87082
Value Function Update Magnitude: 0.76647
Collected Steps per Second: 11,824.12879
Overall Steps per Second: 6,630.34013
Timestep Collection Time: 4.22881
Timestep Consumption Time: 3.31258
PPO Batch Consumption Time: 0.24553
Total Iteration Time: 7.54139
Cumulative Model Updates: 184,436
Cumulative Timesteps: 1,391,005,276
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.06405
Policy Entropy: 4.34947
Value Function Loss: 0.00253
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.88129
Value Function Update Magnitude: 0.70938
Collected Steps per Second: 11,662.28081
Overall Steps per Second: 6,693.83663
Timestep Collection Time: 4.28784
Timestep Consumption Time: 3.18261
PPO Batch Consumption Time: 0.24403
Total Iteration Time: 7.47045
Cumulative Model Updates: 184,445
Cumulative Timesteps: 1,391,055,282
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1391055282...
Checkpoint 1391055282 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.40747
Policy Entropy: 4.34795
Value Function Loss: 0.00251
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.88604
Value Function Update Magnitude: 0.66214
Collected Steps per Second: 11,978.32131
Overall Steps per Second: 6,841.56124
Timestep Collection Time: 4.17638
Timestep Consumption Time: 3.13570
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 7.31207
Cumulative Model Updates: 184,454
Cumulative Timesteps: 1,391,105,308
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.40457
Policy Entropy: 4.34477
Value Function Loss: 0.00249
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02372
Policy Update Magnitude: 0.87566
Value Function Update Magnitude: 0.70899
Collected Steps per Second: 11,876.13275
Overall Steps per Second: 6,686.85687
Timestep Collection Time: 4.21299
Timestep Consumption Time: 3.26945
PPO Batch Consumption Time: 0.24706
Total Iteration Time: 7.48244
Cumulative Model Updates: 184,463
Cumulative Timesteps: 1,391,155,342
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1391155342...
Checkpoint 1391155342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33906
Policy Entropy: 4.34797
Value Function Loss: 0.00237
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.85025
Value Function Update Magnitude: 0.71336
Collected Steps per Second: 11,301.80717
Overall Steps per Second: 6,575.36422
Timestep Collection Time: 4.42566
Timestep Consumption Time: 3.18122
PPO Batch Consumption Time: 0.24651
Total Iteration Time: 7.60688
Cumulative Model Updates: 184,472
Cumulative Timesteps: 1,391,205,360
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.30996
Policy Entropy: 4.34939
Value Function Loss: 0.00236
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.81990
Value Function Update Magnitude: 0.71503
Collected Steps per Second: 11,897.35364
Overall Steps per Second: 6,852.07107
Timestep Collection Time: 4.20396
Timestep Consumption Time: 3.09544
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 7.29940
Cumulative Model Updates: 184,481
Cumulative Timesteps: 1,391,255,376
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1391255376...
Checkpoint 1391255376 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.04208
Policy Entropy: 4.35205
Value Function Loss: 0.00226
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.82768
Value Function Update Magnitude: 0.72469
Collected Steps per Second: 13,105.44073
Overall Steps per Second: 7,255.12587
Timestep Collection Time: 3.81613
Timestep Consumption Time: 3.07721
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.89333
Cumulative Model Updates: 184,490
Cumulative Timesteps: 1,391,305,388
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.63963
Policy Entropy: 4.35188
Value Function Loss: 0.00230
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02084
Policy Update Magnitude: 0.82189
Value Function Update Magnitude: 0.68411
Collected Steps per Second: 13,318.20317
Overall Steps per Second: 7,263.02614
Timestep Collection Time: 3.75726
Timestep Consumption Time: 3.13243
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.88969
Cumulative Model Updates: 184,499
Cumulative Timesteps: 1,391,355,428
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1391355428...
Checkpoint 1391355428 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96799
Policy Entropy: 4.35253
Value Function Loss: 0.00225
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02261
Policy Update Magnitude: 0.81726
Value Function Update Magnitude: 0.68037
Collected Steps per Second: 12,033.52668
Overall Steps per Second: 6,694.30055
Timestep Collection Time: 4.15556
Timestep Consumption Time: 3.31438
PPO Batch Consumption Time: 0.24312
Total Iteration Time: 7.46994
Cumulative Model Updates: 184,508
Cumulative Timesteps: 1,391,405,434
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.51306
Policy Entropy: 4.34874
Value Function Loss: 0.00242
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02191
Policy Update Magnitude: 0.82728
Value Function Update Magnitude: 0.69896
Collected Steps per Second: 13,108.36260
Overall Steps per Second: 7,205.30308
Timestep Collection Time: 3.81695
Timestep Consumption Time: 3.12710
PPO Batch Consumption Time: 0.23153
Total Iteration Time: 6.94405
Cumulative Model Updates: 184,517
Cumulative Timesteps: 1,391,455,468
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1391455468...
Checkpoint 1391455468 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42328
Policy Entropy: 4.34971
Value Function Loss: 0.00247
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02141
Policy Update Magnitude: 0.83109
Value Function Update Magnitude: 0.70043
Collected Steps per Second: 12,219.08011
Overall Steps per Second: 6,786.81176
Timestep Collection Time: 4.09393
Timestep Consumption Time: 3.27684
PPO Batch Consumption Time: 0.24505
Total Iteration Time: 7.37077
Cumulative Model Updates: 184,526
Cumulative Timesteps: 1,391,505,492
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.35369
Policy Entropy: 4.35172
Value Function Loss: 0.00242
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.82477
Value Function Update Magnitude: 0.67620
Collected Steps per Second: 11,602.21329
Overall Steps per Second: 6,583.51048
Timestep Collection Time: 4.31194
Timestep Consumption Time: 3.28705
PPO Batch Consumption Time: 0.24438
Total Iteration Time: 7.59899
Cumulative Model Updates: 184,535
Cumulative Timesteps: 1,391,555,520
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1391555520...
Checkpoint 1391555520 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.88111
Policy Entropy: 4.34732
Value Function Loss: 0.00246
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02230
Policy Update Magnitude: 0.81201
Value Function Update Magnitude: 0.68843
Collected Steps per Second: 11,195.04850
Overall Steps per Second: 6,383.71557
Timestep Collection Time: 4.47001
Timestep Consumption Time: 3.36900
PPO Batch Consumption Time: 0.24256
Total Iteration Time: 7.83901
Cumulative Model Updates: 184,544
Cumulative Timesteps: 1,391,605,562
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.64096
Policy Entropy: 4.34780
Value Function Loss: 0.00254
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.86410
Value Function Update Magnitude: 0.72651
Collected Steps per Second: 12,434.33253
Overall Steps per Second: 6,872.49859
Timestep Collection Time: 4.02482
Timestep Consumption Time: 3.25724
PPO Batch Consumption Time: 0.23703
Total Iteration Time: 7.28207
Cumulative Model Updates: 184,553
Cumulative Timesteps: 1,391,655,608
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1391655608...
Checkpoint 1391655608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.34847
Policy Entropy: 4.34226
Value Function Loss: 0.00254
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.86783
Value Function Update Magnitude: 0.74487
Collected Steps per Second: 11,811.25984
Overall Steps per Second: 6,632.33125
Timestep Collection Time: 4.23511
Timestep Consumption Time: 3.30703
PPO Batch Consumption Time: 0.25208
Total Iteration Time: 7.54214
Cumulative Model Updates: 184,562
Cumulative Timesteps: 1,391,705,630
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64210
Policy Entropy: 4.34120
Value Function Loss: 0.00259
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.85584
Value Function Update Magnitude: 0.80047
Collected Steps per Second: 11,708.61066
Overall Steps per Second: 6,706.12459
Timestep Collection Time: 4.27173
Timestep Consumption Time: 3.18653
PPO Batch Consumption Time: 0.24390
Total Iteration Time: 7.45826
Cumulative Model Updates: 184,571
Cumulative Timesteps: 1,391,755,646
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1391755646...
Checkpoint 1391755646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.15445
Policy Entropy: 4.34305
Value Function Loss: 0.00237
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02361
Policy Update Magnitude: 0.83753
Value Function Update Magnitude: 0.77371
Collected Steps per Second: 12,782.08037
Overall Steps per Second: 7,108.10238
Timestep Collection Time: 3.91376
Timestep Consumption Time: 3.12412
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 7.03788
Cumulative Model Updates: 184,580
Cumulative Timesteps: 1,391,805,672
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.75319
Policy Entropy: 4.34597
Value Function Loss: 0.00239
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02170
Policy Update Magnitude: 0.82300
Value Function Update Magnitude: 0.74637
Collected Steps per Second: 13,057.93679
Overall Steps per Second: 7,137.00366
Timestep Collection Time: 3.83261
Timestep Consumption Time: 3.17957
PPO Batch Consumption Time: 0.23981
Total Iteration Time: 7.01219
Cumulative Model Updates: 184,589
Cumulative Timesteps: 1,391,855,718
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1391855718...
Checkpoint 1391855718 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.31305
Policy Entropy: 4.34618
Value Function Loss: 0.00244
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02142
Policy Update Magnitude: 0.84822
Value Function Update Magnitude: 0.75962
Collected Steps per Second: 12,082.70786
Overall Steps per Second: 6,676.48201
Timestep Collection Time: 4.14046
Timestep Consumption Time: 3.35271
PPO Batch Consumption Time: 0.24686
Total Iteration Time: 7.49317
Cumulative Model Updates: 184,598
Cumulative Timesteps: 1,391,905,746
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.34048
Policy Entropy: 4.34057
Value Function Loss: 0.00268
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.86843
Value Function Update Magnitude: 0.78587
Collected Steps per Second: 11,550.49352
Overall Steps per Second: 6,594.44579
Timestep Collection Time: 4.33124
Timestep Consumption Time: 3.25514
PPO Batch Consumption Time: 0.23550
Total Iteration Time: 7.58638
Cumulative Model Updates: 184,607
Cumulative Timesteps: 1,391,955,774
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1391955774...
Checkpoint 1391955774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.99465
Policy Entropy: 4.34384
Value Function Loss: 0.00263
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.88073
Value Function Update Magnitude: 0.80003
Collected Steps per Second: 12,307.38148
Overall Steps per Second: 6,775.47960
Timestep Collection Time: 4.06260
Timestep Consumption Time: 3.31695
PPO Batch Consumption Time: 0.24547
Total Iteration Time: 7.37955
Cumulative Model Updates: 184,616
Cumulative Timesteps: 1,392,005,774
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.77440
Policy Entropy: 4.34417
Value Function Loss: 0.00238
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02300
Policy Update Magnitude: 0.85643
Value Function Update Magnitude: 0.70837
Collected Steps per Second: 11,953.63517
Overall Steps per Second: 6,522.04175
Timestep Collection Time: 4.18400
Timestep Consumption Time: 3.48446
PPO Batch Consumption Time: 0.25729
Total Iteration Time: 7.66846
Cumulative Model Updates: 184,625
Cumulative Timesteps: 1,392,055,788
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1392055788...
Checkpoint 1392055788 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.48206
Policy Entropy: 4.35023
Value Function Loss: 0.00228
Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02154
Policy Update Magnitude: 0.83228
Value Function Update Magnitude: 0.68661
Collected Steps per Second: 11,567.03422
Overall Steps per Second: 6,644.65328
Timestep Collection Time: 4.32557
Timestep Consumption Time: 3.20440
PPO Batch Consumption Time: 0.23546
Total Iteration Time: 7.52996
Cumulative Model Updates: 184,634
Cumulative Timesteps: 1,392,105,822
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.76517
Policy Entropy: 4.34469
Value Function Loss: 0.00244
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.83802
Value Function Update Magnitude: 0.67169
Collected Steps per Second: 12,167.92899
Overall Steps per Second: 7,015.67429
Timestep Collection Time: 4.11261
Timestep Consumption Time: 3.02027
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 7.13289
Cumulative Model Updates: 184,643
Cumulative Timesteps: 1,392,155,864
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1392155864...
Checkpoint 1392155864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.86595
Policy Entropy: 4.34544
Value Function Loss: 0.00254
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.86112
Value Function Update Magnitude: 0.69188
Collected Steps per Second: 13,131.69052
Overall Steps per Second: 7,224.53819
Timestep Collection Time: 3.80850
Timestep Consumption Time: 3.11402
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.92252
Cumulative Model Updates: 184,652
Cumulative Timesteps: 1,392,205,876
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.28886
Policy Entropy: 4.34314
Value Function Loss: 0.00262
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.88203
Value Function Update Magnitude: 0.73829
Collected Steps per Second: 12,846.27454
Overall Steps per Second: 7,132.69000
Timestep Collection Time: 3.89218
Timestep Consumption Time: 3.11780
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 7.00998
Cumulative Model Updates: 184,661
Cumulative Timesteps: 1,392,255,876
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1392255876...
Checkpoint 1392255876 saved!