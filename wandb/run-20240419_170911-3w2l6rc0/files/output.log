Created new wandb run! 3w2l6rc0
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.74052
Policy Entropy: 7.56845
Value Function Loss: nan
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10941
Value Function Update Magnitude: 0.10930
Collected Steps per Second: 9,689.00420
Overall Steps per Second: 7,533.16261
Timestep Collection Time: 5.16214
Timestep Consumption Time: 1.47730
PPO Batch Consumption Time: 0.19673
Total Iteration Time: 6.63944
Cumulative Model Updates: 1
Cumulative Timesteps: 50,016
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.51726
Policy Entropy: 7.56773
Value Function Loss: 0.17755
Mean KL Divergence: 0.00013
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08545
Value Function Update Magnitude: 0.09876
Collected Steps per Second: 10,819.06400
Overall Steps per Second: 8,459.80770
Timestep Collection Time: 4.62406
Timestep Consumption Time: 1.28955
PPO Batch Consumption Time: 0.10000
Total Iteration Time: 5.91361
Cumulative Model Updates: 2
Cumulative Timesteps: 100,044
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 100044...
Checkpoint 100044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.51136
Policy Entropy: 7.56632
Value Function Loss: 0.25892
Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.13426
Value Function Update Magnitude: 0.18671
Collected Steps per Second: 10,353.52507
Overall Steps per Second: 7,978.06703
Timestep Collection Time: 4.82985
Timestep Consumption Time: 1.43808
PPO Batch Consumption Time: 0.08450
Total Iteration Time: 6.26793
Cumulative Model Updates: 4
Cumulative Timesteps: 150,050
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.51807
Policy Entropy: 7.56458
Value Function Loss: 0.44739
Mean KL Divergence: 0.00116
SB3 Clip Fraction: 0.00061
Policy Update Magnitude: 0.17000
Value Function Update Magnitude: 0.26618
Collected Steps per Second: 11,091.99291
Overall Steps per Second: 8,443.26372
Timestep Collection Time: 4.51100
Timestep Consumption Time: 1.41514
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.92614
Cumulative Model Updates: 7
Cumulative Timesteps: 200,086
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 200086...
Checkpoint 200086 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.38887
Policy Entropy: 7.56277
Value Function Loss: 0.60469
Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.00201
Policy Update Magnitude: 0.15339
Value Function Update Magnitude: 0.26589
Collected Steps per Second: 11,307.61883
Overall Steps per Second: 8,557.46002
Timestep Collection Time: 4.42268
Timestep Consumption Time: 1.42134
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.84402
Cumulative Model Updates: 10
Cumulative Timesteps: 250,096
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08190
Policy Entropy: 7.56141
Value Function Loss: 0.75743
Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.00626
Policy Update Magnitude: 0.14200
Value Function Update Magnitude: 0.27193
Collected Steps per Second: 11,195.67404
Overall Steps per Second: 8,462.66641
Timestep Collection Time: 4.46869
Timestep Consumption Time: 1.44316
PPO Batch Consumption Time: 0.05234
Total Iteration Time: 5.91185
Cumulative Model Updates: 13
Cumulative Timesteps: 300,126
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 300126...
Checkpoint 300126 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.63219
Policy Entropy: 7.56077
Value Function Loss: 0.87317
Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.00425
Policy Update Magnitude: 0.13671
Value Function Update Magnitude: 0.28135
Collected Steps per Second: 11,166.37391
Overall Steps per Second: 8,619.69242
Timestep Collection Time: 4.48095
Timestep Consumption Time: 1.32389
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.80485
Cumulative Model Updates: 16
Cumulative Timesteps: 350,162
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13284
Policy Entropy: 7.55894
Value Function Loss: 0.99668
Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.00392
Policy Update Magnitude: 0.12702
Value Function Update Magnitude: 0.28945
Collected Steps per Second: 11,228.75160
Overall Steps per Second: 8,476.06604
Timestep Collection Time: 4.45588
Timestep Consumption Time: 1.44709
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.90297
Cumulative Model Updates: 19
Cumulative Timesteps: 400,196
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 400196...
Checkpoint 400196 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.26179
Policy Entropy: 7.55767
Value Function Loss: 1.12625
Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.00041
Policy Update Magnitude: 0.12714
Value Function Update Magnitude: 0.29329
Collected Steps per Second: 10,689.31994
Overall Steps per Second: 8,245.08732
Timestep Collection Time: 4.68150
Timestep Consumption Time: 1.38782
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 6.06931
Cumulative Model Updates: 22
Cumulative Timesteps: 450,238
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.47869
Policy Entropy: 7.55640
Value Function Loss: 1.19487
Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.00028
Policy Update Magnitude: 0.13185
Value Function Update Magnitude: 0.29933
Collected Steps per Second: 11,140.56155
Overall Steps per Second: 8,610.61507
Timestep Collection Time: 4.48882
Timestep Consumption Time: 1.31889
PPO Batch Consumption Time: 0.04937
Total Iteration Time: 5.80772
Cumulative Model Updates: 25
Cumulative Timesteps: 500,246
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 500246...
Checkpoint 500246 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.25375
Policy Entropy: 7.55252
Value Function Loss: 1.25784
Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.00727
Policy Update Magnitude: 0.12940
Value Function Update Magnitude: 0.29473
Collected Steps per Second: 10,672.33741
Overall Steps per Second: 8,065.44405
Timestep Collection Time: 4.68632
Timestep Consumption Time: 1.51470
PPO Batch Consumption Time: 0.07667
Total Iteration Time: 6.20102
Cumulative Model Updates: 28
Cumulative Timesteps: 550,260
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.53025
Policy Entropy: 7.54690
Value Function Loss: 1.35564
Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.00813
Policy Update Magnitude: 0.12925
Value Function Update Magnitude: 0.26704
Collected Steps per Second: 10,986.80334
Overall Steps per Second: 8,413.40779
Timestep Collection Time: 4.55310
Timestep Consumption Time: 1.39265
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.94575
Cumulative Model Updates: 31
Cumulative Timesteps: 600,284
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 600284...
Checkpoint 600284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11340
Policy Entropy: 7.54165
Value Function Loss: 1.51589
Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.00369
Policy Update Magnitude: 0.13078
Value Function Update Magnitude: 0.24284
Collected Steps per Second: 10,350.04372
Overall Steps per Second: 7,939.13176
Timestep Collection Time: 4.83322
Timestep Consumption Time: 1.46772
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 6.30094
Cumulative Model Updates: 34
Cumulative Timesteps: 650,308
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.51569
Policy Entropy: 7.53853
Value Function Loss: 1.17371
Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.00243
Policy Update Magnitude: 0.12781
Value Function Update Magnitude: 0.20453
Collected Steps per Second: 10,679.86009
Overall Steps per Second: 8,205.28335
Timestep Collection Time: 4.68508
Timestep Consumption Time: 1.41294
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 6.09802
Cumulative Model Updates: 37
Cumulative Timesteps: 700,344
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 700344...
Checkpoint 700344 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.49921
Policy Entropy: 7.53527
Value Function Loss: 0.75843
Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.00188
Policy Update Magnitude: 0.12225
Value Function Update Magnitude: 0.19355
Collected Steps per Second: 11,126.27085
Overall Steps per Second: 8,625.68645
Timestep Collection Time: 4.49495
Timestep Consumption Time: 1.30308
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.79803
Cumulative Model Updates: 40
Cumulative Timesteps: 750,356
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.46325
Policy Entropy: 7.52952
Value Function Loss: 0.31068
Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00209
Policy Update Magnitude: 0.11219
Value Function Update Magnitude: 0.20137
Collected Steps per Second: 11,010.00705
Overall Steps per Second: 8,341.52318
Timestep Collection Time: 4.54387
Timestep Consumption Time: 1.45360
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.99747
Cumulative Model Updates: 43
Cumulative Timesteps: 800,384
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 800384...
Checkpoint 800384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23558
Policy Entropy: 7.51949
Value Function Loss: 0.26729
Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.00499
Policy Update Magnitude: 0.10596
Value Function Update Magnitude: 0.21551
Collected Steps per Second: 10,137.54382
Overall Steps per Second: 7,806.97294
Timestep Collection Time: 4.93611
Timestep Consumption Time: 1.47355
PPO Batch Consumption Time: 0.05358
Total Iteration Time: 6.40965
Cumulative Model Updates: 46
Cumulative Timesteps: 850,424
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.30098
Policy Entropy: 7.50620
Value Function Loss: 0.23818
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01131
Policy Update Magnitude: 0.09851
Value Function Update Magnitude: 0.19224
Collected Steps per Second: 10,780.79320
Overall Steps per Second: 8,186.61247
Timestep Collection Time: 4.63955
Timestep Consumption Time: 1.47018
PPO Batch Consumption Time: 0.05433
Total Iteration Time: 6.10973
Cumulative Model Updates: 49
Cumulative Timesteps: 900,442
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 900442...
Checkpoint 900442 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.61599
Policy Entropy: 7.49716
Value Function Loss: 0.17932
Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.00545
Policy Update Magnitude: 0.09248
Value Function Update Magnitude: 0.15110
Collected Steps per Second: 10,060.52199
Overall Steps per Second: 7,677.53046
Timestep Collection Time: 4.97310
Timestep Consumption Time: 1.54358
PPO Batch Consumption Time: 0.08267
Total Iteration Time: 6.51668
Cumulative Model Updates: 52
Cumulative Timesteps: 950,474
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.28497
Policy Entropy: 7.48839
Value Function Loss: 0.16494
Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00323
Policy Update Magnitude: 0.08826
Value Function Update Magnitude: 0.12374
Collected Steps per Second: 10,626.17138
Overall Steps per Second: 8,238.55908
Timestep Collection Time: 4.70800
Timestep Consumption Time: 1.36442
PPO Batch Consumption Time: 0.07148
Total Iteration Time: 6.07242
Cumulative Model Updates: 55
Cumulative Timesteps: 1,000,502
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1000502...
Checkpoint 1000502 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.70538
Policy Entropy: 7.47616
Value Function Loss: 0.15193
Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.00529
Policy Update Magnitude: 0.08464
Value Function Update Magnitude: 0.10468
Collected Steps per Second: 10,843.70331
Overall Steps per Second: 8,263.30080
Timestep Collection Time: 4.61116
Timestep Consumption Time: 1.43994
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.05109
Cumulative Model Updates: 58
Cumulative Timesteps: 1,050,504
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16726
Policy Entropy: 7.46324
Value Function Loss: 0.12616
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01217
Policy Update Magnitude: 0.07959
Value Function Update Magnitude: 0.09540
Collected Steps per Second: 10,655.10233
Overall Steps per Second: 8,173.10025
Timestep Collection Time: 4.69259
Timestep Consumption Time: 1.42504
PPO Batch Consumption Time: 0.06167
Total Iteration Time: 6.11763
Cumulative Model Updates: 61
Cumulative Timesteps: 1,100,504
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1100504...
Checkpoint 1100504 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.52133
Policy Entropy: 7.45416
Value Function Loss: 0.13751
Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.00720
Policy Update Magnitude: 0.07662
Value Function Update Magnitude: 0.09284
Collected Steps per Second: 9,301.78800
Overall Steps per Second: 7,073.97885
Timestep Collection Time: 5.37639
Timestep Consumption Time: 1.69319
PPO Batch Consumption Time: 0.07414
Total Iteration Time: 7.06957
Cumulative Model Updates: 64
Cumulative Timesteps: 1,150,514
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.61070
Policy Entropy: 7.43844
Value Function Loss: 0.13939
Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.00852
Policy Update Magnitude: 0.08011
Value Function Update Magnitude: 0.08966
Collected Steps per Second: 9,986.86279
Overall Steps per Second: 7,705.34554
Timestep Collection Time: 5.00738
Timestep Consumption Time: 1.48266
PPO Batch Consumption Time: 0.05400
Total Iteration Time: 6.49004
Cumulative Model Updates: 67
Cumulative Timesteps: 1,200,522
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1200522...
Checkpoint 1200522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.30380
Policy Entropy: 7.41846
Value Function Loss: 0.15050
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01435
Policy Update Magnitude: 0.07615
Value Function Update Magnitude: 0.08898
Collected Steps per Second: 9,846.23653
Overall Steps per Second: 7,781.19391
Timestep Collection Time: 5.08194
Timestep Consumption Time: 1.34869
PPO Batch Consumption Time: 0.05112
Total Iteration Time: 6.43063
Cumulative Model Updates: 70
Cumulative Timesteps: 1,250,560
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.78503
Policy Entropy: 7.41045
Value Function Loss: 0.15741
Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.00358
Policy Update Magnitude: 0.07438
Value Function Update Magnitude: 0.09033
Collected Steps per Second: 10,853.39447
Overall Steps per Second: 8,208.53351
Timestep Collection Time: 4.60870
Timestep Consumption Time: 1.48496
PPO Batch Consumption Time: 0.06907
Total Iteration Time: 6.09366
Cumulative Model Updates: 73
Cumulative Timesteps: 1,300,580
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1300580...
Checkpoint 1300580 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.48417
Policy Entropy: 7.40618
Value Function Loss: 0.15776
Mean KL Divergence: 0.00100
SB3 Clip Fraction: 0.00025
Policy Update Magnitude: 0.08260
Value Function Update Magnitude: 0.09646
Collected Steps per Second: 10,800.43401
Overall Steps per Second: 8,210.13415
Timestep Collection Time: 4.63352
Timestep Consumption Time: 1.46188
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 6.09539
Cumulative Model Updates: 76
Cumulative Timesteps: 1,350,624
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.75310
Policy Entropy: 7.40073
Value Function Loss: 0.19429
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.00937
Policy Update Magnitude: 0.08924
Value Function Update Magnitude: 0.09892
Collected Steps per Second: 10,943.88756
Overall Steps per Second: 8,389.15260
Timestep Collection Time: 4.57242
Timestep Consumption Time: 1.39243
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.96485
Cumulative Model Updates: 79
Cumulative Timesteps: 1,400,664
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1400664...
Checkpoint 1400664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.59103
Policy Entropy: 7.39626
Value Function Loss: 0.16932
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02304
Policy Update Magnitude: 0.08546
Value Function Update Magnitude: 0.09711
Collected Steps per Second: 10,450.33758
Overall Steps per Second: 8,032.22522
Timestep Collection Time: 4.78798
Timestep Consumption Time: 1.44143
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.22941
Cumulative Model Updates: 82
Cumulative Timesteps: 1,450,700
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.26644
Policy Entropy: 7.38806
Value Function Loss: 0.18049
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01395
Policy Update Magnitude: 0.08807
Value Function Update Magnitude: 0.09501
Collected Steps per Second: 10,679.54204
Overall Steps per Second: 8,301.61534
Timestep Collection Time: 4.68616
Timestep Consumption Time: 1.34231
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 6.02847
Cumulative Model Updates: 85
Cumulative Timesteps: 1,500,746
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1500746...
Checkpoint 1500746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.51770
Policy Entropy: 7.37770
Value Function Loss: 0.15507
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01018
Policy Update Magnitude: 0.08708
Value Function Update Magnitude: 0.09451
Collected Steps per Second: 10,768.34256
Overall Steps per Second: 8,234.99948
Timestep Collection Time: 4.64324
Timestep Consumption Time: 1.42841
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 6.07165
Cumulative Model Updates: 88
Cumulative Timesteps: 1,550,746
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.44211
Policy Entropy: 7.35952
Value Function Loss: 0.16328
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.08008
Value Function Update Magnitude: 0.09707
Collected Steps per Second: 11,197.97563
Overall Steps per Second: 8,484.91336
Timestep Collection Time: 4.46670
Timestep Consumption Time: 1.42823
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.89493
Cumulative Model Updates: 91
Cumulative Timesteps: 1,600,764
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1600764...
Checkpoint 1600764 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.61353
Policy Entropy: 7.35023
Value Function Loss: 0.16468
Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.00398
Policy Update Magnitude: 0.08013
Value Function Update Magnitude: 0.09917
Collected Steps per Second: 10,935.73711
Overall Steps per Second: 8,471.29716
Timestep Collection Time: 4.57637
Timestep Consumption Time: 1.33134
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.90771
Cumulative Model Updates: 94
Cumulative Timesteps: 1,650,810
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.35129
Policy Entropy: 7.33939
Value Function Loss: 0.18472
Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.00465
Policy Update Magnitude: 0.08782
Value Function Update Magnitude: 0.10343
Collected Steps per Second: 11,037.97849
Overall Steps per Second: 8,294.40546
Timestep Collection Time: 4.53108
Timestep Consumption Time: 1.49876
PPO Batch Consumption Time: 0.07628
Total Iteration Time: 6.02985
Cumulative Model Updates: 97
Cumulative Timesteps: 1,700,824
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1700824...
Checkpoint 1700824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.39384
Policy Entropy: 7.33195
Value Function Loss: 0.19170
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02999
Policy Update Magnitude: 0.08463
Value Function Update Magnitude: 0.10696
Collected Steps per Second: 10,799.97760
Overall Steps per Second: 8,307.14865
Timestep Collection Time: 4.63260
Timestep Consumption Time: 1.39016
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 6.02276
Cumulative Model Updates: 100
Cumulative Timesteps: 1,750,856
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.40599
Policy Entropy: 7.34270
Value Function Loss: 0.17767
Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.00477
Policy Update Magnitude: 0.08525
Value Function Update Magnitude: 0.10700
Collected Steps per Second: 11,307.88405
Overall Steps per Second: 8,570.75350
Timestep Collection Time: 4.42240
Timestep Consumption Time: 1.41233
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.83473
Cumulative Model Updates: 103
Cumulative Timesteps: 1,800,864
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1800864...
Checkpoint 1800864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.76647
Policy Entropy: 7.34355
Value Function Loss: 0.15922
Mean KL Divergence: 0.00120
SB3 Clip Fraction: 0.00119
Policy Update Magnitude: 0.08411
Value Function Update Magnitude: 0.09655
Collected Steps per Second: 10,929.28524
Overall Steps per Second: 8,345.71281
Timestep Collection Time: 4.57779
Timestep Consumption Time: 1.41714
PPO Batch Consumption Time: 0.04991
Total Iteration Time: 5.99493
Cumulative Model Updates: 106
Cumulative Timesteps: 1,850,896
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.45108
Policy Entropy: 7.32144
Value Function Loss: 0.16227
Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.00702
Policy Update Magnitude: 0.08746
Value Function Update Magnitude: 0.08716
Collected Steps per Second: 10,761.72234
Overall Steps per Second: 8,373.26409
Timestep Collection Time: 4.64926
Timestep Consumption Time: 1.32619
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.97545
Cumulative Model Updates: 109
Cumulative Timesteps: 1,900,930
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1900930...
Checkpoint 1900930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.64626
Policy Entropy: 7.30026
Value Function Loss: 0.20170
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02200
Policy Update Magnitude: 0.07834
Value Function Update Magnitude: 0.08357
Collected Steps per Second: 10,672.06934
Overall Steps per Second: 8,118.96103
Timestep Collection Time: 4.68588
Timestep Consumption Time: 1.47353
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 6.15941
Cumulative Model Updates: 112
Cumulative Timesteps: 1,950,938
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18446
Policy Entropy: 7.31959
Value Function Loss: 0.22065
Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.00155
Policy Update Magnitude: 0.08679
Value Function Update Magnitude: 0.09210
Collected Steps per Second: 11,190.39888
Overall Steps per Second: 8,507.71625
Timestep Collection Time: 4.46829
Timestep Consumption Time: 1.40896
PPO Batch Consumption Time: 0.05061
Total Iteration Time: 5.87725
Cumulative Model Updates: 115
Cumulative Timesteps: 2,000,940
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 2000940...
Checkpoint 2000940 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12843
Policy Entropy: 7.32641
Value Function Loss: 0.24928
Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01135
Policy Update Magnitude: 0.08903
Value Function Update Magnitude: 0.09196
Collected Steps per Second: 11,086.86151
Overall Steps per Second: 8,454.73415
Timestep Collection Time: 4.51183
Timestep Consumption Time: 1.40462
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.91645
Cumulative Model Updates: 118
Cumulative Timesteps: 2,050,962
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.45972
Policy Entropy: 7.29925
Value Function Loss: 0.25799
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01241
Policy Update Magnitude: 0.09195
Value Function Update Magnitude: 0.08969
Collected Steps per Second: 11,036.79572
Overall Steps per Second: 8,322.04494
Timestep Collection Time: 4.53338
Timestep Consumption Time: 1.47884
PPO Batch Consumption Time: 0.06700
Total Iteration Time: 6.01222
Cumulative Model Updates: 121
Cumulative Timesteps: 2,100,996
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 2100996...
Checkpoint 2100996 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.48812
Policy Entropy: 7.28764
Value Function Loss: 0.25067
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01621
Policy Update Magnitude: 0.09099
Value Function Update Magnitude: 0.08437
Collected Steps per Second: 10,770.77013
Overall Steps per Second: 8,293.46248
Timestep Collection Time: 4.64349
Timestep Consumption Time: 1.38704
PPO Batch Consumption Time: 0.05350
Total Iteration Time: 6.03053
Cumulative Model Updates: 124
Cumulative Timesteps: 2,151,010
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.71691
Policy Entropy: 7.29933
Value Function Loss: 0.24485
Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.00666
Policy Update Magnitude: 0.09588
Value Function Update Magnitude: 0.08017
Collected Steps per Second: 11,198.05160
Overall Steps per Second: 8,488.18343
Timestep Collection Time: 4.46685
Timestep Consumption Time: 1.42605
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.89290
Cumulative Model Updates: 127
Cumulative Timesteps: 2,201,030
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 2201030...
Checkpoint 2201030 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.44670
Policy Entropy: 7.27429
Value Function Loss: 0.23815
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.09286
Value Function Update Magnitude: 0.07852
Collected Steps per Second: 10,762.80597
Overall Steps per Second: 8,210.75485
Timestep Collection Time: 4.64879
Timestep Consumption Time: 1.44493
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.09372
Cumulative Model Updates: 130
Cumulative Timesteps: 2,251,064
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.72706
Policy Entropy: 7.24248
Value Function Loss: 0.22935
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.09379
Value Function Update Magnitude: 0.07818
Collected Steps per Second: 10,723.67598
Overall Steps per Second: 8,346.87575
Timestep Collection Time: 4.66463
Timestep Consumption Time: 1.32827
PPO Batch Consumption Time: 0.04980
Total Iteration Time: 5.99290
Cumulative Model Updates: 133
Cumulative Timesteps: 2,301,086
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 2301086...
Checkpoint 2301086 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.28848
Policy Entropy: 7.25205
Value Function Loss: 0.20334
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01661
Policy Update Magnitude: 0.08578
Value Function Update Magnitude: 0.07242
Collected Steps per Second: 10,827.44233
Overall Steps per Second: 8,270.72512
Timestep Collection Time: 4.61956
Timestep Consumption Time: 1.42804
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 6.04760
Cumulative Model Updates: 136
Cumulative Timesteps: 2,351,104
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.33197
Policy Entropy: 7.24831
Value Function Loss: 0.20304
Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.00121
Policy Update Magnitude: 0.09278
Value Function Update Magnitude: 0.07275
Collected Steps per Second: 10,958.06857
Overall Steps per Second: 8,388.39338
Timestep Collection Time: 4.56303
Timestep Consumption Time: 1.39783
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.96086
Cumulative Model Updates: 139
Cumulative Timesteps: 2,401,106
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 2401106...
Checkpoint 2401106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.28950
Policy Entropy: 7.20408
Value Function Loss: 0.20332
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02870
Policy Update Magnitude: 0.09183
Value Function Update Magnitude: 0.07515
Collected Steps per Second: 10,744.62267
Overall Steps per Second: 8,218.89572
Timestep Collection Time: 4.65517
Timestep Consumption Time: 1.43057
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 6.08573
Cumulative Model Updates: 142
Cumulative Timesteps: 2,451,124
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.68350
Policy Entropy: 7.21456
Value Function Loss: 0.23779
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01297
Policy Update Magnitude: 0.09784
Value Function Update Magnitude: 0.08182
Collected Steps per Second: 11,027.63872
Overall Steps per Second: 8,271.07874
Timestep Collection Time: 4.53461
Timestep Consumption Time: 1.51128
PPO Batch Consumption Time: 0.08167
Total Iteration Time: 6.04589
Cumulative Model Updates: 145
Cumulative Timesteps: 2,501,130
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 2501130...
Checkpoint 2501130 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.61732
Policy Entropy: 7.22499
Value Function Loss: 0.23903
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.09256
Value Function Update Magnitude: 0.08150
Collected Steps per Second: 11,310.27459
Overall Steps per Second: 8,726.66193
Timestep Collection Time: 4.42447
Timestep Consumption Time: 1.30991
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.73438
Cumulative Model Updates: 148
Cumulative Timesteps: 2,551,172
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.57801
Policy Entropy: 7.18781
Value Function Loss: 0.26018
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.00962
Policy Update Magnitude: 0.09782
Value Function Update Magnitude: 0.08215
Collected Steps per Second: 10,986.35941
Overall Steps per Second: 8,314.74464
Timestep Collection Time: 4.55419
Timestep Consumption Time: 1.46331
PPO Batch Consumption Time: 0.05310
Total Iteration Time: 6.01750
Cumulative Model Updates: 151
Cumulative Timesteps: 2,601,206
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 2601206...
Checkpoint 2601206 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.78063
Policy Entropy: 7.16943
Value Function Loss: 0.27267
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01604
Policy Update Magnitude: 0.10267
Value Function Update Magnitude: 0.07494
Collected Steps per Second: 10,075.76829
Overall Steps per Second: 7,824.72271
Timestep Collection Time: 4.96419
Timestep Consumption Time: 1.42812
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 6.39230
Cumulative Model Updates: 154
Cumulative Timesteps: 2,651,224
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.85135
Policy Entropy: 7.18433
Value Function Loss: 0.28876
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01805
Policy Update Magnitude: 0.09888
Value Function Update Magnitude: 0.07900
Collected Steps per Second: 11,277.68828
Overall Steps per Second: 8,675.90766
Timestep Collection Time: 4.43602
Timestep Consumption Time: 1.33030
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.76631
Cumulative Model Updates: 157
Cumulative Timesteps: 2,701,252
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 2701252...
Checkpoint 2701252 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.27298
Policy Entropy: 7.13269
Value Function Loss: 0.25863
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.10202
Value Function Update Magnitude: 0.07553
Collected Steps per Second: 11,163.87291
Overall Steps per Second: 8,462.78058
Timestep Collection Time: 4.48178
Timestep Consumption Time: 1.43046
PPO Batch Consumption Time: 0.05025
Total Iteration Time: 5.91224
Cumulative Model Updates: 160
Cumulative Timesteps: 2,751,286
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.82899
Policy Entropy: 7.12387
Value Function Loss: 0.19780
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.01758
Policy Update Magnitude: 0.09714
Value Function Update Magnitude: 0.07910
Collected Steps per Second: 11,011.14438
Overall Steps per Second: 8,349.28377
Timestep Collection Time: 4.54249
Timestep Consumption Time: 1.44820
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.99069
Cumulative Model Updates: 163
Cumulative Timesteps: 2,801,304
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 2801304...
Checkpoint 2801304 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.72987
Policy Entropy: 7.16056
Value Function Loss: 0.14032
Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.03555
Policy Update Magnitude: 0.08476
Value Function Update Magnitude: 0.08199
Collected Steps per Second: 11,032.85691
Overall Steps per Second: 8,410.50414
Timestep Collection Time: 4.53536
Timestep Consumption Time: 1.41410
PPO Batch Consumption Time: 0.04867
Total Iteration Time: 5.94946
Cumulative Model Updates: 166
Cumulative Timesteps: 2,851,342
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.73598
Policy Entropy: 7.10231
Value Function Loss: 0.14371
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.08662
Value Function Update Magnitude: 0.06817
Collected Steps per Second: 11,124.90064
Overall Steps per Second: 8,360.41585
Timestep Collection Time: 4.50035
Timestep Consumption Time: 1.48810
PPO Batch Consumption Time: 0.07733
Total Iteration Time: 5.98846
Cumulative Model Updates: 169
Cumulative Timesteps: 2,901,408
Timesteps Collected: 50,066
--------END ITERATION REPORT--------
Saving checkpoint 2901408...
Checkpoint 2901408 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.36745
Policy Entropy: 7.07156
Value Function Loss: 0.16411
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.08462
Value Function Update Magnitude: 0.06279
Collected Steps per Second: 10,186.59395
Overall Steps per Second: 8,002.53648
Timestep Collection Time: 4.90841
Timestep Consumption Time: 1.33961
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 6.24802
Cumulative Model Updates: 172
Cumulative Timesteps: 2,951,408
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.69873
Policy Entropy: 7.12830
Value Function Loss: 0.18337
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.01483
Policy Update Magnitude: 0.08269
Value Function Update Magnitude: 0.06313
Collected Steps per Second: 10,769.86269
Overall Steps per Second: 8,229.62989
Timestep Collection Time: 4.64667
Timestep Consumption Time: 1.43428
PPO Batch Consumption Time: 0.05221
Total Iteration Time: 6.08095
Cumulative Model Updates: 175
Cumulative Timesteps: 3,001,452
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 3001452...
Checkpoint 3001452 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.51845
Policy Entropy: 7.09839
Value Function Loss: 0.17631
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01855
Policy Update Magnitude: 0.09645
Value Function Update Magnitude: 0.06667
Collected Steps per Second: 10,418.24024
Overall Steps per Second: 8,059.71696
Timestep Collection Time: 4.80331
Timestep Consumption Time: 1.40560
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.20890
Cumulative Model Updates: 178
Cumulative Timesteps: 3,051,494
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.59823
Policy Entropy: 7.03746
Value Function Loss: 0.15672
Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.03607
Policy Update Magnitude: 0.08477
Value Function Update Magnitude: 0.06429
Collected Steps per Second: 10,846.62281
Overall Steps per Second: 8,185.64660
Timestep Collection Time: 4.61250
Timestep Consumption Time: 1.49942
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 6.11192
Cumulative Model Updates: 181
Cumulative Timesteps: 3,101,524
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 3101524...
Checkpoint 3101524 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.51342
Policy Entropy: 7.09057
Value Function Loss: 0.13098
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.00799
Policy Update Magnitude: 0.08399
Value Function Update Magnitude: 0.06567
Collected Steps per Second: 10,678.91586
Overall Steps per Second: 8,195.50548
Timestep Collection Time: 4.68493
Timestep Consumption Time: 1.41963
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.10457
Cumulative Model Updates: 184
Cumulative Timesteps: 3,151,554
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.59807
Policy Entropy: 7.08491
Value Function Loss: 0.12035
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01351
Policy Update Magnitude: 0.08549
Value Function Update Magnitude: 0.06107
Collected Steps per Second: 10,799.21323
Overall Steps per Second: 8,434.43714
Timestep Collection Time: 4.63274
Timestep Consumption Time: 1.29889
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.93163
Cumulative Model Updates: 187
Cumulative Timesteps: 3,201,584
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 3201584...
Checkpoint 3201584 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.67514
Policy Entropy: 7.02663
Value Function Loss: 0.13903
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.07745
Value Function Update Magnitude: 0.05637
Collected Steps per Second: 10,464.54961
Overall Steps per Second: 8,029.28221
Timestep Collection Time: 4.77804
Timestep Consumption Time: 1.44917
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 6.22721
Cumulative Model Updates: 190
Cumulative Timesteps: 3,251,584
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.65935
Policy Entropy: 7.04576
Value Function Loss: 0.14683
Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.00860
Policy Update Magnitude: 0.08472
Value Function Update Magnitude: 0.05196
Collected Steps per Second: 11,030.94337
Overall Steps per Second: 8,235.11891
Timestep Collection Time: 4.53724
Timestep Consumption Time: 1.54039
PPO Batch Consumption Time: 0.08000
Total Iteration Time: 6.07763
Cumulative Model Updates: 193
Cumulative Timesteps: 3,301,634
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 3301634...
Checkpoint 3301634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.84876
Policy Entropy: 7.08628
Value Function Loss: 0.17148
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02184
Policy Update Magnitude: 0.08222
Value Function Update Magnitude: 0.06376
Collected Steps per Second: 10,866.71875
Overall Steps per Second: 8,133.30494
Timestep Collection Time: 4.60525
Timestep Consumption Time: 1.54772
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.15297
Cumulative Model Updates: 196
Cumulative Timesteps: 3,351,678
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.73205
Policy Entropy: 7.04507
Value Function Loss: 0.16366
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.00967
Policy Update Magnitude: 0.09391
Value Function Update Magnitude: 0.06229
Collected Steps per Second: 9,003.28205
Overall Steps per Second: 6,977.99262
Timestep Collection Time: 5.55820
Timestep Consumption Time: 1.61321
PPO Batch Consumption Time: 0.05877
Total Iteration Time: 7.17140
Cumulative Model Updates: 199
Cumulative Timesteps: 3,401,720
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 3401720...
Checkpoint 3401720 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.93028
Policy Entropy: 7.00412
Value Function Loss: 0.17269
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.09376
Value Function Update Magnitude: 0.05873
Collected Steps per Second: 9,706.26240
Overall Steps per Second: 7,629.01231
Timestep Collection Time: 5.15152
Timestep Consumption Time: 1.40267
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.55419
Cumulative Model Updates: 202
Cumulative Timesteps: 3,451,722
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.87762
Policy Entropy: 7.03348
Value Function Loss: 0.13400
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.08672
Value Function Update Magnitude: 0.05081
Collected Steps per Second: 10,974.80906
Overall Steps per Second: 8,357.09811
Timestep Collection Time: 4.55990
Timestep Consumption Time: 1.42831
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.98820
Cumulative Model Updates: 205
Cumulative Timesteps: 3,501,766
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 3501766...
Checkpoint 3501766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.86239
Policy Entropy: 6.99050
Value Function Loss: 0.11425
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01399
Policy Update Magnitude: 0.09171
Value Function Update Magnitude: 0.04656
Collected Steps per Second: 11,261.37125
Overall Steps per Second: 8,554.47479
Timestep Collection Time: 4.44369
Timestep Consumption Time: 1.40612
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.84980
Cumulative Model Updates: 208
Cumulative Timesteps: 3,551,808
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.85906
Policy Entropy: 6.94581
Value Function Loss: 0.10760
Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.03549
Policy Update Magnitude: 0.08189
Value Function Update Magnitude: 0.05387
Collected Steps per Second: 11,329.45440
Overall Steps per Second: 8,704.15580
Timestep Collection Time: 4.41734
Timestep Consumption Time: 1.33233
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.74967
Cumulative Model Updates: 211
Cumulative Timesteps: 3,601,854
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 3601854...
Checkpoint 3601854 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.52024
Policy Entropy: 6.99887
Value Function Loss: 0.11144
Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.00967
Policy Update Magnitude: 0.07544
Value Function Update Magnitude: 0.05446
Collected Steps per Second: 11,232.92325
Overall Steps per Second: 8,528.58369
Timestep Collection Time: 4.45316
Timestep Consumption Time: 1.41206
PPO Batch Consumption Time: 0.05028
Total Iteration Time: 5.86522
Cumulative Model Updates: 214
Cumulative Timesteps: 3,651,876
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.65484
Policy Entropy: 6.97198
Value Function Loss: 0.14450
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.01352
Policy Update Magnitude: 0.08202
Value Function Update Magnitude: 0.04378
Collected Steps per Second: 10,665.66230
Overall Steps per Second: 8,185.66161
Timestep Collection Time: 4.68888
Timestep Consumption Time: 1.42058
PPO Batch Consumption Time: 0.07834
Total Iteration Time: 6.10946
Cumulative Model Updates: 217
Cumulative Timesteps: 3,701,886
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 3701886...
Checkpoint 3701886 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.06874
Policy Entropy: 6.90837
Value Function Loss: 0.13695
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.08188
Value Function Update Magnitude: 0.03701
Collected Steps per Second: 10,087.73823
Overall Steps per Second: 7,832.59752
Timestep Collection Time: 4.95671
Timestep Consumption Time: 1.42712
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 6.38383
Cumulative Model Updates: 220
Cumulative Timesteps: 3,751,888
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.91275
Policy Entropy: 6.95278
Value Function Loss: 0.14168
Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.00571
Policy Update Magnitude: 0.09102
Value Function Update Magnitude: 0.03652
Collected Steps per Second: 10,957.28449
Overall Steps per Second: 8,413.49664
Timestep Collection Time: 4.56390
Timestep Consumption Time: 1.37988
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.94378
Cumulative Model Updates: 223
Cumulative Timesteps: 3,801,896
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 3801896...
Checkpoint 3801896 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.59172
Policy Entropy: 6.96117
Value Function Loss: 0.13095
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01345
Policy Update Magnitude: 0.08968
Value Function Update Magnitude: 0.03023
Collected Steps per Second: 10,936.42255
Overall Steps per Second: 8,495.23334
Timestep Collection Time: 4.57663
Timestep Consumption Time: 1.31514
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.89177
Cumulative Model Updates: 226
Cumulative Timesteps: 3,851,948
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.79880
Policy Entropy: 6.90694
Value Function Loss: 0.12967
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01622
Policy Update Magnitude: 0.08862
Value Function Update Magnitude: 0.03643
Collected Steps per Second: 11,138.35810
Overall Steps per Second: 8,469.92171
Timestep Collection Time: 4.49151
Timestep Consumption Time: 1.41504
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.90655
Cumulative Model Updates: 229
Cumulative Timesteps: 3,901,976
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 3901976...
Checkpoint 3901976 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.70778
Policy Entropy: 6.91952
Value Function Loss: 0.11144
Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.00742
Policy Update Magnitude: 0.09084
Value Function Update Magnitude: 0.03760
Collected Steps per Second: 10,709.01243
Overall Steps per Second: 8,278.68427
Timestep Collection Time: 4.67214
Timestep Consumption Time: 1.37157
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.04371
Cumulative Model Updates: 232
Cumulative Timesteps: 3,952,010
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.71320
Policy Entropy: 6.96803
Value Function Loss: 0.10474
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01405
Policy Update Magnitude: 0.08456
Value Function Update Magnitude: 0.03970
Collected Steps per Second: 11,240.12732
Overall Steps per Second: 8,547.85104
Timestep Collection Time: 4.45155
Timestep Consumption Time: 1.40208
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.85363
Cumulative Model Updates: 235
Cumulative Timesteps: 4,002,046
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 4002046...
Checkpoint 4002046 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.01242
Policy Entropy: 6.92685
Value Function Loss: 0.11151
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.00877
Policy Update Magnitude: 0.09005
Value Function Update Magnitude: 0.04215
Collected Steps per Second: 11,108.89273
Overall Steps per Second: 8,458.48048
Timestep Collection Time: 4.50378
Timestep Consumption Time: 1.41123
PPO Batch Consumption Time: 0.05015
Total Iteration Time: 5.91501
Cumulative Model Updates: 238
Cumulative Timesteps: 4,052,078
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.49238
Policy Entropy: 6.89136
Value Function Loss: 0.13247
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.08771
Value Function Update Magnitude: 0.04634
Collected Steps per Second: 11,119.64337
Overall Steps per Second: 8,472.50286
Timestep Collection Time: 4.49978
Timestep Consumption Time: 1.40591
PPO Batch Consumption Time: 0.08100
Total Iteration Time: 5.90569
Cumulative Model Updates: 241
Cumulative Timesteps: 4,102,114
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 4102114...
Checkpoint 4102114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.94272
Policy Entropy: 6.92607
Value Function Loss: 0.14411
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01121
Policy Update Magnitude: 0.08611
Value Function Update Magnitude: 0.04550
Collected Steps per Second: 11,146.84131
Overall Steps per Second: 8,479.63562
Timestep Collection Time: 4.48593
Timestep Consumption Time: 1.41102
PPO Batch Consumption Time: 0.05304
Total Iteration Time: 5.89695
Cumulative Model Updates: 244
Cumulative Timesteps: 4,152,118
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.76865
Policy Entropy: 6.89659
Value Function Loss: 0.16856
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02128
Policy Update Magnitude: 0.09754
Value Function Update Magnitude: 0.04838
Collected Steps per Second: 11,122.73852
Overall Steps per Second: 8,490.97286
Timestep Collection Time: 4.49799
Timestep Consumption Time: 1.39415
PPO Batch Consumption Time: 0.05322
Total Iteration Time: 5.89214
Cumulative Model Updates: 247
Cumulative Timesteps: 4,202,148
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 4202148...
Checkpoint 4202148 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.94549
Policy Entropy: 6.85126
Value Function Loss: 0.15445
Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.09424
Value Function Update Magnitude: 0.05175
Collected Steps per Second: 11,058.98381
Overall Steps per Second: 8,402.71483
Timestep Collection Time: 4.52320
Timestep Consumption Time: 1.42988
PPO Batch Consumption Time: 0.04971
Total Iteration Time: 5.95308
Cumulative Model Updates: 250
Cumulative Timesteps: 4,252,170
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.80775
Policy Entropy: 6.87596
Value Function Loss: 0.16131
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.00911
Policy Update Magnitude: 0.09857
Value Function Update Magnitude: 0.05258
Collected Steps per Second: 10,981.83484
Overall Steps per Second: 8,354.95104
Timestep Collection Time: 4.55753
Timestep Consumption Time: 1.43293
PPO Batch Consumption Time: 0.04989
Total Iteration Time: 5.99046
Cumulative Model Updates: 253
Cumulative Timesteps: 4,302,220
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 4302220...
Checkpoint 4302220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.82860
Policy Entropy: 6.87586
Value Function Loss: 0.14649
Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.00804
Policy Update Magnitude: 0.10197
Value Function Update Magnitude: 0.05451
Collected Steps per Second: 10,951.80765
Overall Steps per Second: 8,411.83027
Timestep Collection Time: 4.56874
Timestep Consumption Time: 1.37955
PPO Batch Consumption Time: 0.04969
Total Iteration Time: 5.94829
Cumulative Model Updates: 256
Cumulative Timesteps: 4,352,256
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.13628
Policy Entropy: 6.82586
Value Function Loss: 0.17596
Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04333
Policy Update Magnitude: 0.09912
Value Function Update Magnitude: 0.05771
Collected Steps per Second: 11,295.46575
Overall Steps per Second: 8,536.72795
Timestep Collection Time: 4.42779
Timestep Consumption Time: 1.43089
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.85869
Cumulative Model Updates: 259
Cumulative Timesteps: 4,402,270
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 4402270...
Checkpoint 4402270 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.90423
Policy Entropy: 6.87340
Value Function Loss: 0.16570
Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.04482
Policy Update Magnitude: 0.09708
Value Function Update Magnitude: 0.05649
Collected Steps per Second: 10,942.34241
Overall Steps per Second: 8,404.16923
Timestep Collection Time: 4.57123
Timestep Consumption Time: 1.38057
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.95181
Cumulative Model Updates: 262
Cumulative Timesteps: 4,452,290
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.52153
Policy Entropy: 6.80263
Value Function Loss: 0.14250
Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.03971
Policy Update Magnitude: 0.10494
Value Function Update Magnitude: 0.05225
Collected Steps per Second: 11,089.92420
Overall Steps per Second: 8,494.64606
Timestep Collection Time: 4.51275
Timestep Consumption Time: 1.37873
PPO Batch Consumption Time: 0.08000
Total Iteration Time: 5.89148
Cumulative Model Updates: 265
Cumulative Timesteps: 4,502,336
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 4502336...
Checkpoint 4502336 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.12454
Policy Entropy: 6.79220
Value Function Loss: 0.12640
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02713
Policy Update Magnitude: 0.09629
Value Function Update Magnitude: 0.05439
Collected Steps per Second: 11,121.06277
Overall Steps per Second: 8,465.46780
Timestep Collection Time: 4.49651
Timestep Consumption Time: 1.41054
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.90706
Cumulative Model Updates: 268
Cumulative Timesteps: 4,552,342
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.03181
Policy Entropy: 6.82649
Value Function Loss: 0.10483
Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 0.08828
Value Function Update Magnitude: 0.06401
Collected Steps per Second: 11,009.90422
Overall Steps per Second: 8,440.78804
Timestep Collection Time: 4.54246
Timestep Consumption Time: 1.38258
PPO Batch Consumption Time: 0.05030
Total Iteration Time: 5.92504
Cumulative Model Updates: 271
Cumulative Timesteps: 4,602,354
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 4602354...
Checkpoint 4602354 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.60471
Policy Entropy: 6.72341
Value Function Loss: 0.12049
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03211
Policy Update Magnitude: 0.08381
Value Function Update Magnitude: 0.06806
Collected Steps per Second: 11,100.05659
Overall Steps per Second: 8,456.28114
Timestep Collection Time: 4.50917
Timestep Consumption Time: 1.40975
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.91891
Cumulative Model Updates: 274
Cumulative Timesteps: 4,652,406
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.18750
Policy Entropy: 6.76280
Value Function Loss: 0.11475
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01371
Policy Update Magnitude: 0.09062
Value Function Update Magnitude: 0.06391
Collected Steps per Second: 11,096.49923
Overall Steps per Second: 8,444.04750
Timestep Collection Time: 4.50737
Timestep Consumption Time: 1.41586
PPO Batch Consumption Time: 0.04993
Total Iteration Time: 5.92323
Cumulative Model Updates: 277
Cumulative Timesteps: 4,702,422
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 4702422...
Checkpoint 4702422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.58853
Policy Entropy: 6.77073
Value Function Loss: 0.14152
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01657
Policy Update Magnitude: 0.09508
Value Function Update Magnitude: 0.06371
Collected Steps per Second: 11,095.43661
Overall Steps per Second: 8,588.82578
Timestep Collection Time: 4.50888
Timestep Consumption Time: 1.31590
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.82478
Cumulative Model Updates: 280
Cumulative Timesteps: 4,752,450
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.34772
Policy Entropy: 6.68905
Value Function Loss: 0.12985
Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04251
Policy Update Magnitude: 0.09017
Value Function Update Magnitude: 0.06229
Collected Steps per Second: 11,150.79809
Overall Steps per Second: 8,478.63304
Timestep Collection Time: 4.48434
Timestep Consumption Time: 1.41331
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.89765
Cumulative Model Updates: 283
Cumulative Timesteps: 4,802,454
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 4802454...
Checkpoint 4802454 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.96013
Policy Entropy: 6.76217
Value Function Loss: 0.15473
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01726
Policy Update Magnitude: 0.09456
Value Function Update Magnitude: 0.06339
Collected Steps per Second: 11,078.18609
Overall Steps per Second: 8,486.46044
Timestep Collection Time: 4.51355
Timestep Consumption Time: 1.37842
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.89197
Cumulative Model Updates: 286
Cumulative Timesteps: 4,852,456
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.28429
Policy Entropy: 6.72446
Value Function Loss: 0.15529
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.10633
Value Function Update Magnitude: 0.06790
Collected Steps per Second: 11,031.95596
Overall Steps per Second: 8,459.06048
Timestep Collection Time: 4.53555
Timestep Consumption Time: 1.37953
PPO Batch Consumption Time: 0.06633
Total Iteration Time: 5.91508
Cumulative Model Updates: 289
Cumulative Timesteps: 4,902,492
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 4902492...
Checkpoint 4902492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.95628
Policy Entropy: 6.63053
Value Function Loss: 0.17397
Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06174
Policy Update Magnitude: 0.10590
Value Function Update Magnitude: 0.08172
Collected Steps per Second: 10,131.70980
Overall Steps per Second: 7,570.15015
Timestep Collection Time: 4.93520
Timestep Consumption Time: 1.66995
PPO Batch Consumption Time: 0.09767
Total Iteration Time: 6.60515
Cumulative Model Updates: 292
Cumulative Timesteps: 4,952,494
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.95700
Policy Entropy: 6.72557
Value Function Loss: 0.14744
Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04131
Policy Update Magnitude: 0.09912
Value Function Update Magnitude: 0.07908
Collected Steps per Second: 8,339.36163
Overall Steps per Second: 6,854.20822
Timestep Collection Time: 6.00142
Timestep Consumption Time: 1.30037
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 7.30179
Cumulative Model Updates: 295
Cumulative Timesteps: 5,002,542
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 5002542...
Checkpoint 5002542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.86405
Policy Entropy: 6.63887
Value Function Loss: 0.14941
Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04893
Policy Update Magnitude: 0.09327
Value Function Update Magnitude: 0.06436
Collected Steps per Second: 11,153.67295
Overall Steps per Second: 8,458.66426
Timestep Collection Time: 4.48372
Timestep Consumption Time: 1.42856
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.91228
Cumulative Model Updates: 298
Cumulative Timesteps: 5,052,552
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.18276
Policy Entropy: 6.67750
Value Function Loss: 0.13467
Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03354
Policy Update Magnitude: 0.09161
Value Function Update Magnitude: 0.05624
Collected Steps per Second: 11,138.72744
Overall Steps per Second: 8,502.81997
Timestep Collection Time: 4.49046
Timestep Consumption Time: 1.39206
PPO Batch Consumption Time: 0.05158
Total Iteration Time: 5.88252
Cumulative Model Updates: 301
Cumulative Timesteps: 5,102,570
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 5102570...
Checkpoint 5102570 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.89417
Policy Entropy: 6.67688
Value Function Loss: 0.17825
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.10099
Value Function Update Magnitude: 0.05863
Collected Steps per Second: 11,096.95496
Overall Steps per Second: 8,612.01158
Timestep Collection Time: 4.50844
Timestep Consumption Time: 1.30088
PPO Batch Consumption Time: 0.05066
Total Iteration Time: 5.80933
Cumulative Model Updates: 304
Cumulative Timesteps: 5,152,600
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.37914
Policy Entropy: 6.63283
Value Function Loss: 0.16859
Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04188
Policy Update Magnitude: 0.09889
Value Function Update Magnitude: 0.05513
Collected Steps per Second: 11,186.41911
Overall Steps per Second: 8,479.79907
Timestep Collection Time: 4.47257
Timestep Consumption Time: 1.42757
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.90014
Cumulative Model Updates: 307
Cumulative Timesteps: 5,202,632
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 5202632...
Checkpoint 5202632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.04531
Policy Entropy: 6.71350
Value Function Loss: 0.19230
Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03493
Policy Update Magnitude: 0.09726
Value Function Update Magnitude: 0.05239
Collected Steps per Second: 10,881.40986
Overall Steps per Second: 8,381.91682
Timestep Collection Time: 4.59830
Timestep Consumption Time: 1.37122
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.96952
Cumulative Model Updates: 310
Cumulative Timesteps: 5,252,668
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.99541
Policy Entropy: 6.64436
Value Function Loss: 0.17149
Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04747
Policy Update Magnitude: 0.09396
Value Function Update Magnitude: 0.04308
Collected Steps per Second: 11,267.75069
Overall Steps per Second: 8,391.45325
Timestep Collection Time: 4.44312
Timestep Consumption Time: 1.52295
PPO Batch Consumption Time: 0.08267
Total Iteration Time: 5.96607
Cumulative Model Updates: 313
Cumulative Timesteps: 5,302,732
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
Saving checkpoint 5302732...
Checkpoint 5302732 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.72255
Policy Entropy: 6.66577
Value Function Loss: 0.18554
Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.03579
Policy Update Magnitude: 0.09463
Value Function Update Magnitude: 0.04401
Collected Steps per Second: 11,010.95812
Overall Steps per Second: 8,379.19544
Timestep Collection Time: 4.54384
Timestep Consumption Time: 1.42714
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.97098
Cumulative Model Updates: 316
Cumulative Timesteps: 5,352,764
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.75202
Policy Entropy: 6.69171
Value Function Loss: 0.16086
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.09746
Value Function Update Magnitude: 0.04534
Collected Steps per Second: 11,077.44028
Overall Steps per Second: 8,590.54421
Timestep Collection Time: 4.51584
Timestep Consumption Time: 1.30730
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.82315
Cumulative Model Updates: 319
Cumulative Timesteps: 5,402,788
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 5402788...
Checkpoint 5402788 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.93065
Policy Entropy: 6.58811
Value Function Loss: 0.13426
Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04396
Policy Update Magnitude: 0.08986
Value Function Update Magnitude: 0.04850
Collected Steps per Second: 10,894.99951
Overall Steps per Second: 8,336.69611
Timestep Collection Time: 4.59073
Timestep Consumption Time: 1.40877
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.99950
Cumulative Model Updates: 322
Cumulative Timesteps: 5,452,804
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.31274
Policy Entropy: 6.67219
Value Function Loss: 0.12227
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.08666
Value Function Update Magnitude: 0.05563
Collected Steps per Second: 11,137.13726
Overall Steps per Second: 8,522.17281
Timestep Collection Time: 4.49505
Timestep Consumption Time: 1.37927
PPO Batch Consumption Time: 0.05047
Total Iteration Time: 5.87432
Cumulative Model Updates: 325
Cumulative Timesteps: 5,502,866
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
Saving checkpoint 5502866...
Checkpoint 5502866 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.60987
Policy Entropy: 6.66863
Value Function Loss: 0.13205
Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02488
Policy Update Magnitude: 0.09189
Value Function Update Magnitude: 0.04898
Collected Steps per Second: 11,305.59551
Overall Steps per Second: 8,574.36297
Timestep Collection Time: 4.42294
Timestep Consumption Time: 1.40886
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.83180
Cumulative Model Updates: 328
Cumulative Timesteps: 5,552,870
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.96510
Policy Entropy: 6.60078
Value Function Loss: 0.15039
Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.03697
Policy Update Magnitude: 0.08657
Value Function Update Magnitude: 0.04396
Collected Steps per Second: 11,123.01543
Overall Steps per Second: 8,423.44693
Timestep Collection Time: 4.49734
Timestep Consumption Time: 1.44132
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.93866
Cumulative Model Updates: 331
Cumulative Timesteps: 5,602,894
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 5602894...
Checkpoint 5602894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.95961
Policy Entropy: 6.62880
Value Function Loss: 0.15271
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.08250
Value Function Update Magnitude: 0.03724
Collected Steps per Second: 11,110.45856
Overall Steps per Second: 8,478.37430
Timestep Collection Time: 4.50026
Timestep Consumption Time: 1.39709
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 5.89736
Cumulative Model Updates: 334
Cumulative Timesteps: 5,652,894
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.67809
Policy Entropy: 6.58387
Value Function Loss: 0.14598
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02321
Policy Update Magnitude: 0.08285
Value Function Update Magnitude: 0.03448
Collected Steps per Second: 11,313.25174
Overall Steps per Second: 8,459.90324
Timestep Collection Time: 4.42189
Timestep Consumption Time: 1.49141
PPO Batch Consumption Time: 0.07434
Total Iteration Time: 5.91331
Cumulative Model Updates: 337
Cumulative Timesteps: 5,702,920
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 5702920...
Checkpoint 5702920 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.34843
Policy Entropy: 6.52576
Value Function Loss: 0.13876
Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02885
Policy Update Magnitude: 0.08464
Value Function Update Magnitude: 0.03265
Collected Steps per Second: 11,115.56985
Overall Steps per Second: 8,416.55095
Timestep Collection Time: 4.49927
Timestep Consumption Time: 1.44283
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.94210
Cumulative Model Updates: 340
Cumulative Timesteps: 5,752,932
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.10538
Policy Entropy: 6.54194
Value Function Loss: 0.12987
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02305
Policy Update Magnitude: 0.08516
Value Function Update Magnitude: 0.03146
Collected Steps per Second: 10,954.87440
Overall Steps per Second: 8,488.25712
Timestep Collection Time: 4.56473
Timestep Consumption Time: 1.32647
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.89120
Cumulative Model Updates: 343
Cumulative Timesteps: 5,802,938
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 5802938...
Checkpoint 5802938 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.05684
Policy Entropy: 6.52770
Value Function Loss: 0.13483
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.08713
Value Function Update Magnitude: 0.02961
Collected Steps per Second: 11,104.34552
Overall Steps per Second: 8,422.30027
Timestep Collection Time: 4.50400
Timestep Consumption Time: 1.43428
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.93828
Cumulative Model Updates: 346
Cumulative Timesteps: 5,852,952
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.11423
Policy Entropy: 6.50502
Value Function Loss: 0.13613
Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03297
Policy Update Magnitude: 0.08665
Value Function Update Magnitude: 0.03042
Collected Steps per Second: 11,054.50089
Overall Steps per Second: 8,474.36426
Timestep Collection Time: 4.52594
Timestep Consumption Time: 1.37798
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.90392
Cumulative Model Updates: 349
Cumulative Timesteps: 5,902,984
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 5902984...
Checkpoint 5902984 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.21040
Policy Entropy: 6.50560
Value Function Loss: 0.13760
Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04133
Policy Update Magnitude: 0.07885
Value Function Update Magnitude: 0.03152
Collected Steps per Second: 11,273.60078
Overall Steps per Second: 8,566.30882
Timestep Collection Time: 4.43833
Timestep Consumption Time: 1.40269
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.84102
Cumulative Model Updates: 352
Cumulative Timesteps: 5,953,020
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.68700
Policy Entropy: 6.47317
Value Function Loss: 0.16419
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01249
Policy Update Magnitude: 0.08124
Value Function Update Magnitude: 0.03250
Collected Steps per Second: 11,044.35936
Overall Steps per Second: 8,409.22493
Timestep Collection Time: 4.53100
Timestep Consumption Time: 1.41984
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.95085
Cumulative Model Updates: 355
Cumulative Timesteps: 6,003,062
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 6003062...
Checkpoint 6003062 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.15012
Policy Entropy: 6.43923
Value Function Loss: 0.16348
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.08629
Value Function Update Magnitude: 0.03116
Collected Steps per Second: 11,083.53365
Overall Steps per Second: 8,573.37659
Timestep Collection Time: 4.51210
Timestep Consumption Time: 1.32108
PPO Batch Consumption Time: 0.05084
Total Iteration Time: 5.83317
Cumulative Model Updates: 358
Cumulative Timesteps: 6,053,072
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.31078
Policy Entropy: 6.44246
Value Function Loss: 0.17655
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01874
Policy Update Magnitude: 0.09174
Value Function Update Magnitude: 0.03177
Collected Steps per Second: 11,041.25624
Overall Steps per Second: 8,271.55232
Timestep Collection Time: 4.53028
Timestep Consumption Time: 1.51695
PPO Batch Consumption Time: 0.08233
Total Iteration Time: 6.04723
Cumulative Model Updates: 361
Cumulative Timesteps: 6,103,092
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 6103092...
Checkpoint 6103092 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.27522
Policy Entropy: 6.39831
Value Function Loss: 0.14454
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01297
Policy Update Magnitude: 0.09439
Value Function Update Magnitude: 0.02990
Collected Steps per Second: 11,179.67716
Overall Steps per Second: 8,559.49054
Timestep Collection Time: 4.47526
Timestep Consumption Time: 1.36994
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.84521
Cumulative Model Updates: 364
Cumulative Timesteps: 6,153,124
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.36382
Policy Entropy: 6.37300
Value Function Loss: 0.16132
Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03513
Policy Update Magnitude: 0.09113
Value Function Update Magnitude: 0.04363
Collected Steps per Second: 11,094.43341
Overall Steps per Second: 8,586.31599
Timestep Collection Time: 4.50875
Timestep Consumption Time: 1.31703
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.82578
Cumulative Model Updates: 367
Cumulative Timesteps: 6,203,146
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 6203146...
Checkpoint 6203146 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.94499
Policy Entropy: 6.39710
Value Function Loss: 0.17631
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01554
Policy Update Magnitude: 0.09253
Value Function Update Magnitude: 0.04699
Collected Steps per Second: 11,116.40506
Overall Steps per Second: 8,454.04047
Timestep Collection Time: 4.49822
Timestep Consumption Time: 1.41659
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.91480
Cumulative Model Updates: 370
Cumulative Timesteps: 6,253,150
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.35797
Policy Entropy: 6.37122
Value Function Loss: 0.17795
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02272
Policy Update Magnitude: 0.10070
Value Function Update Magnitude: 0.04923
Collected Steps per Second: 11,095.15759
Overall Steps per Second: 8,491.54914
Timestep Collection Time: 4.51026
Timestep Consumption Time: 1.38290
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.89315
Cumulative Model Updates: 373
Cumulative Timesteps: 6,303,192
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 6303192...
Checkpoint 6303192 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.10280
Policy Entropy: 6.35507
Value Function Loss: 0.16088
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.10374
Value Function Update Magnitude: 0.04690
Collected Steps per Second: 11,236.86705
Overall Steps per Second: 8,550.07982
Timestep Collection Time: 4.45498
Timestep Consumption Time: 1.39994
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.85492
Cumulative Model Updates: 376
Cumulative Timesteps: 6,353,252
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.15882
Policy Entropy: 6.39252
Value Function Loss: 0.17051
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02279
Policy Update Magnitude: 0.09527
Value Function Update Magnitude: 0.03959
Collected Steps per Second: 11,101.01361
Overall Steps per Second: 8,440.36247
Timestep Collection Time: 4.50662
Timestep Consumption Time: 1.42062
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.92723
Cumulative Model Updates: 379
Cumulative Timesteps: 6,403,280
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 6403280...
Checkpoint 6403280 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.21203
Policy Entropy: 6.33530
Value Function Loss: 0.17994
Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03488
Policy Update Magnitude: 0.09444
Value Function Update Magnitude: 0.03873
Collected Steps per Second: 11,049.21250
Overall Steps per Second: 8,569.06428
Timestep Collection Time: 4.52575
Timestep Consumption Time: 1.30989
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.83564
Cumulative Model Updates: 382
Cumulative Timesteps: 6,453,286
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.10496
Policy Entropy: 6.32399
Value Function Loss: 0.19255
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02161
Policy Update Magnitude: 0.10453
Value Function Update Magnitude: 0.03521
Collected Steps per Second: 11,168.06688
Overall Steps per Second: 8,363.05222
Timestep Collection Time: 4.47956
Timestep Consumption Time: 1.50247
PPO Batch Consumption Time: 0.07419
Total Iteration Time: 5.98203
Cumulative Model Updates: 385
Cumulative Timesteps: 6,503,314
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 6503314...
Checkpoint 6503314 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.23488
Policy Entropy: 6.33796
Value Function Loss: 0.20354
Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 0.10343
Value Function Update Magnitude: 0.03614
Collected Steps per Second: 11,036.66564
Overall Steps per Second: 8,434.63451
Timestep Collection Time: 4.53307
Timestep Consumption Time: 1.39842
PPO Batch Consumption Time: 0.05400
Total Iteration Time: 5.93150
Cumulative Model Updates: 388
Cumulative Timesteps: 6,553,344
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.10681
Policy Entropy: 6.31227
Value Function Loss: 0.19970
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03023
Policy Update Magnitude: 0.10112
Value Function Update Magnitude: 0.03902
Collected Steps per Second: 11,194.51499
Overall Steps per Second: 8,525.80434
Timestep Collection Time: 4.46862
Timestep Consumption Time: 1.39875
PPO Batch Consumption Time: 0.05101
Total Iteration Time: 5.86736
Cumulative Model Updates: 391
Cumulative Timesteps: 6,603,368
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 6603368...
Checkpoint 6603368 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.15864
Policy Entropy: 6.35742
Value Function Loss: 0.20340
Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.03659
Policy Update Magnitude: 0.10082
Value Function Update Magnitude: 0.03704
Collected Steps per Second: 11,165.47130
Overall Steps per Second: 8,497.95381
Timestep Collection Time: 4.48257
Timestep Consumption Time: 1.40708
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.88965
Cumulative Model Updates: 394
Cumulative Timesteps: 6,653,418
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.26667
Policy Entropy: 6.32080
Value Function Loss: 0.18399
Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04271
Policy Update Magnitude: 0.09775
Value Function Update Magnitude: 0.03615
Collected Steps per Second: 11,093.98704
Overall Steps per Second: 8,600.40875
Timestep Collection Time: 4.50821
Timestep Consumption Time: 1.30710
PPO Batch Consumption Time: 0.05022
Total Iteration Time: 5.81531
Cumulative Model Updates: 397
Cumulative Timesteps: 6,703,432
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 6703432...
Checkpoint 6703432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.09813
Policy Entropy: 6.33019
Value Function Loss: 0.17961
Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05451
Policy Update Magnitude: 0.09638
Value Function Update Magnitude: 0.03621
Collected Steps per Second: 11,049.67911
Overall Steps per Second: 8,427.25765
Timestep Collection Time: 4.52936
Timestep Consumption Time: 1.40946
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.93882
Cumulative Model Updates: 400
Cumulative Timesteps: 6,753,480
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.00660
Policy Entropy: 6.29686
Value Function Loss: 0.19425
Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06016
Policy Update Magnitude: 0.09453
Value Function Update Magnitude: 0.03805
Collected Steps per Second: 11,026.38890
Overall Steps per Second: 8,443.52193
Timestep Collection Time: 4.53712
Timestep Consumption Time: 1.38790
PPO Batch Consumption Time: 0.05108
Total Iteration Time: 5.92502
Cumulative Model Updates: 403
Cumulative Timesteps: 6,803,508
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 6803508...
Checkpoint 6803508 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.25178
Policy Entropy: 6.27997
Value Function Loss: 0.17714
Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05872
Policy Update Magnitude: 0.09325
Value Function Update Magnitude: 0.04257
Collected Steps per Second: 11,020.43770
Overall Steps per Second: 8,568.68546
Timestep Collection Time: 4.53775
Timestep Consumption Time: 1.29838
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.83613
Cumulative Model Updates: 406
Cumulative Timesteps: 6,853,516
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.23669
Policy Entropy: 6.28530
Value Function Loss: 0.18997
Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05935
Policy Update Magnitude: 0.09376
Value Function Update Magnitude: 0.04425
Collected Steps per Second: 11,077.42240
Overall Steps per Second: 8,300.74811
Timestep Collection Time: 4.51513
Timestep Consumption Time: 1.51035
PPO Batch Consumption Time: 0.07338
Total Iteration Time: 6.02548
Cumulative Model Updates: 409
Cumulative Timesteps: 6,903,532
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 6903532...
Checkpoint 6903532 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.92591
Policy Entropy: 6.22344
Value Function Loss: 0.17549
Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04847
Policy Update Magnitude: 0.08731
Value Function Update Magnitude: 0.04315
Collected Steps per Second: 11,077.76790
Overall Steps per Second: 8,452.89745
Timestep Collection Time: 4.51679
Timestep Consumption Time: 1.40260
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.91939
Cumulative Model Updates: 412
Cumulative Timesteps: 6,953,568
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.35052
Policy Entropy: 6.25900
Value Function Loss: 0.17647
Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 0.08870
Value Function Update Magnitude: 0.04089
Collected Steps per Second: 11,256.49354
Overall Steps per Second: 8,553.88394
Timestep Collection Time: 4.44312
Timestep Consumption Time: 1.40381
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.84693
Cumulative Model Updates: 415
Cumulative Timesteps: 7,003,582
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 7003582...
Checkpoint 7003582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.28222
Policy Entropy: 6.20946
Value Function Loss: 0.16395
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.08856
Value Function Update Magnitude: 0.03879
Collected Steps per Second: 10,864.09355
Overall Steps per Second: 8,258.24547
Timestep Collection Time: 4.60674
Timestep Consumption Time: 1.45363
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.06037
Cumulative Model Updates: 418
Cumulative Timesteps: 7,053,630
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.25647
Policy Entropy: 6.22670
Value Function Loss: 0.17311
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.08419
Value Function Update Magnitude: 0.03643
Collected Steps per Second: 11,032.28037
Overall Steps per Second: 8,544.00496
Timestep Collection Time: 4.53451
Timestep Consumption Time: 1.32059
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.85510
Cumulative Model Updates: 421
Cumulative Timesteps: 7,103,656
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 7103656...
Checkpoint 7103656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.63425
Policy Entropy: 6.24950
Value Function Loss: 0.19756
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02313
Policy Update Magnitude: 0.08252
Value Function Update Magnitude: 0.03605
Collected Steps per Second: 11,081.70109
Overall Steps per Second: 8,445.24723
Timestep Collection Time: 4.51573
Timestep Consumption Time: 1.40973
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.92546
Cumulative Model Updates: 424
Cumulative Timesteps: 7,153,698
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.37237
Policy Entropy: 6.20678
Value Function Loss: 0.21181
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.01893
Policy Update Magnitude: 0.08813
Value Function Update Magnitude: 0.03604
Collected Steps per Second: 11,124.01348
Overall Steps per Second: 8,500.12041
Timestep Collection Time: 4.49892
Timestep Consumption Time: 1.38877
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.88768
Cumulative Model Updates: 427
Cumulative Timesteps: 7,203,744
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 7203744...
Checkpoint 7203744 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.82400
Policy Entropy: 6.22386
Value Function Loss: 0.20067
Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 0.09089
Value Function Update Magnitude: 0.03537
Collected Steps per Second: 11,329.63640
Overall Steps per Second: 8,657.81435
Timestep Collection Time: 4.41638
Timestep Consumption Time: 1.36291
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.77929
Cumulative Model Updates: 430
Cumulative Timesteps: 7,253,780
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.19859
Policy Entropy: 6.19034
Value Function Loss: 0.18840
Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.03039
Policy Update Magnitude: 0.09198
Value Function Update Magnitude: 0.03769
Collected Steps per Second: 11,117.76109
Overall Steps per Second: 8,373.01748
Timestep Collection Time: 4.49893
Timestep Consumption Time: 1.47479
PPO Batch Consumption Time: 0.06539
Total Iteration Time: 5.97371
Cumulative Model Updates: 433
Cumulative Timesteps: 7,303,798
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 7303798...
Checkpoint 7303798 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.14492
Policy Entropy: 6.16315
Value Function Loss: 0.19928
Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03659
Policy Update Magnitude: 0.09419
Value Function Update Magnitude: 0.03993
Collected Steps per Second: 11,006.38321
Overall Steps per Second: 8,418.08940
Timestep Collection Time: 4.54445
Timestep Consumption Time: 1.39727
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.94173
Cumulative Model Updates: 436
Cumulative Timesteps: 7,353,816
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.91047
Policy Entropy: 6.20470
Value Function Loss: 0.21231
Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04045
Policy Update Magnitude: 0.08909
Value Function Update Magnitude: 0.04530
Collected Steps per Second: 11,393.14281
Overall Steps per Second: 8,614.50053
Timestep Collection Time: 4.39141
Timestep Consumption Time: 1.41647
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.80788
Cumulative Model Updates: 439
Cumulative Timesteps: 7,403,848
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 7403848...
Checkpoint 7403848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.29093
Policy Entropy: 6.12902
Value Function Loss: 0.20496
Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04112
Policy Update Magnitude: 0.08717
Value Function Update Magnitude: 0.04635
Collected Steps per Second: 10,964.37514
Overall Steps per Second: 8,344.19680
Timestep Collection Time: 4.56442
Timestep Consumption Time: 1.43328
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.99770
Cumulative Model Updates: 442
Cumulative Timesteps: 7,453,894
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.23304
Policy Entropy: 6.12619
Value Function Loss: 0.17549
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.09300
Value Function Update Magnitude: 0.04486
Collected Steps per Second: 11,058.51922
Overall Steps per Second: 8,542.36008
Timestep Collection Time: 4.52556
Timestep Consumption Time: 1.33301
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.85857
Cumulative Model Updates: 445
Cumulative Timesteps: 7,503,940
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 7503940...
Checkpoint 7503940 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.49693
Policy Entropy: 6.14211
Value Function Loss: 0.15118
Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04695
Policy Update Magnitude: 0.09033
Value Function Update Magnitude: 0.04002
Collected Steps per Second: 11,119.76698
Overall Steps per Second: 8,440.18837
Timestep Collection Time: 4.49650
Timestep Consumption Time: 1.42754
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.92404
Cumulative Model Updates: 448
Cumulative Timesteps: 7,553,940
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.34063
Policy Entropy: 6.09180
Value Function Loss: 0.18720
Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04375
Policy Update Magnitude: 0.08305
Value Function Update Magnitude: 0.04012
Collected Steps per Second: 11,187.84984
Overall Steps per Second: 8,520.63596
Timestep Collection Time: 4.47217
Timestep Consumption Time: 1.39992
PPO Batch Consumption Time: 0.05003
Total Iteration Time: 5.87210
Cumulative Model Updates: 451
Cumulative Timesteps: 7,603,974
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 7603974...
Checkpoint 7603974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.12837
Policy Entropy: 6.13060
Value Function Loss: 0.18559
Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03247
Policy Update Magnitude: 0.09006
Value Function Update Magnitude: 0.04182
Collected Steps per Second: 11,356.18423
Overall Steps per Second: 8,592.56147
Timestep Collection Time: 4.40676
Timestep Consumption Time: 1.41735
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.82411
Cumulative Model Updates: 454
Cumulative Timesteps: 7,654,018
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.32496
Policy Entropy: 6.08373
Value Function Loss: 0.18408
Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03422
Policy Update Magnitude: 0.09321
Value Function Update Magnitude: 0.04558
Collected Steps per Second: 11,093.01393
Overall Steps per Second: 8,361.98008
Timestep Collection Time: 4.51059
Timestep Consumption Time: 1.47316
PPO Batch Consumption Time: 0.06533
Total Iteration Time: 5.98375
Cumulative Model Updates: 457
Cumulative Timesteps: 7,704,054
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 7704054...
Checkpoint 7704054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.13145
Policy Entropy: 6.10174
Value Function Loss: 0.16709
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01996
Policy Update Magnitude: 0.09562
Value Function Update Magnitude: 0.04390
Collected Steps per Second: 10,988.37726
Overall Steps per Second: 8,455.40162
Timestep Collection Time: 4.55354
Timestep Consumption Time: 1.36410
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.91764
Cumulative Model Updates: 460
Cumulative Timesteps: 7,754,090
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.09634
Policy Entropy: 6.06024
Value Function Loss: 0.17922
Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05165
Policy Update Magnitude: 0.09266
Value Function Update Magnitude: 0.04279
Collected Steps per Second: 11,307.39098
Overall Steps per Second: 8,573.33185
Timestep Collection Time: 4.42507
Timestep Consumption Time: 1.41117
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.83624
Cumulative Model Updates: 463
Cumulative Timesteps: 7,804,126
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 7804126...
Checkpoint 7804126 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.06932
Policy Entropy: 6.02451
Value Function Loss: 0.18052
Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.04801
Policy Update Magnitude: 0.08795
Value Function Update Magnitude: 0.05399
Collected Steps per Second: 10,932.08327
Overall Steps per Second: 8,341.44089
Timestep Collection Time: 4.57497
Timestep Consumption Time: 1.42087
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.99585
Cumulative Model Updates: 466
Cumulative Timesteps: 7,854,140
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.08891
Policy Entropy: 6.10843
Value Function Loss: 0.15985
Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04671
Policy Update Magnitude: 0.09022
Value Function Update Magnitude: 0.05541
Collected Steps per Second: 11,170.50148
Overall Steps per Second: 8,642.98516
Timestep Collection Time: 4.47822
Timestep Consumption Time: 1.30959
PPO Batch Consumption Time: 0.05074
Total Iteration Time: 5.78782
Cumulative Model Updates: 469
Cumulative Timesteps: 7,904,164
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 7904164...
Checkpoint 7904164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.81527
Policy Entropy: 6.03181
Value Function Loss: 0.11537
Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05617
Policy Update Magnitude: 0.08325
Value Function Update Magnitude: 0.04552
Collected Steps per Second: 11,119.82535
Overall Steps per Second: 8,448.80618
Timestep Collection Time: 4.49953
Timestep Consumption Time: 1.42249
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.92202
Cumulative Model Updates: 472
Cumulative Timesteps: 7,954,198
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.86964
Policy Entropy: 6.02061
Value Function Loss: 0.11556
Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04772
Policy Update Magnitude: 0.07278
Value Function Update Magnitude: 0.04375
Collected Steps per Second: 10,740.46190
Overall Steps per Second: 8,286.90442
Timestep Collection Time: 4.65734
Timestep Consumption Time: 1.37893
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.03627
Cumulative Model Updates: 475
Cumulative Timesteps: 8,004,220
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 8004220...
Checkpoint 8004220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.03690
Policy Entropy: 6.05590
Value Function Loss: 0.12937
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.06633
Value Function Update Magnitude: 0.04859
Collected Steps per Second: 11,284.92872
Overall Steps per Second: 8,549.65696
Timestep Collection Time: 4.43228
Timestep Consumption Time: 1.41801
PPO Batch Consumption Time: 0.05078
Total Iteration Time: 5.85029
Cumulative Model Updates: 478
Cumulative Timesteps: 8,054,238
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.21835
Policy Entropy: 5.96381
Value Function Loss: 0.13546
Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04253
Policy Update Magnitude: 0.06711
Value Function Update Magnitude: 0.05318
Collected Steps per Second: 10,867.80407
Overall Steps per Second: 8,152.38577
Timestep Collection Time: 4.60111
Timestep Consumption Time: 1.53255
PPO Batch Consumption Time: 0.07956
Total Iteration Time: 6.13366
Cumulative Model Updates: 481
Cumulative Timesteps: 8,104,242
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 8104242...
Checkpoint 8104242 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.24955
Policy Entropy: 5.99147
Value Function Loss: 0.12914
Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.03635
Policy Update Magnitude: 0.07410
Value Function Update Magnitude: 0.04383
Collected Steps per Second: 10,887.33072
Overall Steps per Second: 8,453.99093
Timestep Collection Time: 4.59690
Timestep Consumption Time: 1.32314
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.92004
Cumulative Model Updates: 484
Cumulative Timesteps: 8,154,290
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.93619
Policy Entropy: 6.01184
Value Function Loss: 0.10439
Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04167
Policy Update Magnitude: 0.07133
Value Function Update Magnitude: 0.04235
Collected Steps per Second: 11,162.51934
Overall Steps per Second: 8,471.73387
Timestep Collection Time: 4.48393
Timestep Consumption Time: 1.42418
PPO Batch Consumption Time: 0.05056
Total Iteration Time: 5.90812
Cumulative Model Updates: 487
Cumulative Timesteps: 8,204,342
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 8204342...
Checkpoint 8204342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.03653
Policy Entropy: 5.97577
Value Function Loss: 0.13475
Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.03995
Policy Update Magnitude: 0.07219
Value Function Update Magnitude: 0.04866
Collected Steps per Second: 11,013.08814
Overall Steps per Second: 8,446.45968
Timestep Collection Time: 4.54423
Timestep Consumption Time: 1.38086
PPO Batch Consumption Time: 0.05059
Total Iteration Time: 5.92509
Cumulative Model Updates: 490
Cumulative Timesteps: 8,254,388
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.35911
Policy Entropy: 6.01473
Value Function Loss: 0.13807
Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03527
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.04587
Collected Steps per Second: 11,075.00257
Overall Steps per Second: 8,568.02713
Timestep Collection Time: 4.51521
Timestep Consumption Time: 1.32114
PPO Batch Consumption Time: 0.04968
Total Iteration Time: 5.83635
Cumulative Model Updates: 493
Cumulative Timesteps: 8,304,394
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 8304394...
Checkpoint 8304394 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.30286
Policy Entropy: 6.01842
Value Function Loss: 0.16845
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 0.07434
Value Function Update Magnitude: 0.04335
Collected Steps per Second: 11,032.06937
Overall Steps per Second: 8,397.61537
Timestep Collection Time: 4.53333
Timestep Consumption Time: 1.42217
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.95550
Cumulative Model Updates: 496
Cumulative Timesteps: 8,354,406
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.30392
Policy Entropy: 6.03601
Value Function Loss: 0.17397
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02095
Policy Update Magnitude: 0.08440
Value Function Update Magnitude: 0.04593
Collected Steps per Second: 11,131.65520
Overall Steps per Second: 8,483.80593
Timestep Collection Time: 4.49169
Timestep Consumption Time: 1.40189
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.89358
Cumulative Model Updates: 499
Cumulative Timesteps: 8,404,406
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 8404406...
Checkpoint 8404406 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.34377
Policy Entropy: 6.07215
Value Function Loss: 0.16609
Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.08478
Value Function Update Magnitude: 0.05261
Collected Steps per Second: 11,432.35408
Overall Steps per Second: 8,638.75009
Timestep Collection Time: 4.37425
Timestep Consumption Time: 1.41455
PPO Batch Consumption Time: 0.05178
Total Iteration Time: 5.78880
Cumulative Model Updates: 502
Cumulative Timesteps: 8,454,414
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.37379
Policy Entropy: 6.03887
Value Function Loss: 0.14328
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.01645
Policy Update Magnitude: 0.08945
Value Function Update Magnitude: 0.05504
Collected Steps per Second: 11,165.01231
Overall Steps per Second: 8,379.67695
Timestep Collection Time: 4.48114
Timestep Consumption Time: 1.48949
PPO Batch Consumption Time: 0.08200
Total Iteration Time: 5.97064
Cumulative Model Updates: 505
Cumulative Timesteps: 8,504,446
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 8504446...
Checkpoint 8504446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.27117
Policy Entropy: 6.01199
Value Function Loss: 0.14388
Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.08239
Value Function Update Magnitude: 0.06156
Collected Steps per Second: 10,990.91757
Overall Steps per Second: 8,504.81017
Timestep Collection Time: 4.55103
Timestep Consumption Time: 1.33035
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.88138
Cumulative Model Updates: 508
Cumulative Timesteps: 8,554,466
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.13987
Policy Entropy: 5.97996
Value Function Loss: 0.13728
Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04620
Policy Update Magnitude: 0.08358
Value Function Update Magnitude: 0.06676
Collected Steps per Second: 11,177.85372
Overall Steps per Second: 8,472.99326
Timestep Collection Time: 4.47921
Timestep Consumption Time: 1.42991
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.90913
Cumulative Model Updates: 511
Cumulative Timesteps: 8,604,534
Timesteps Collected: 50,068
--------END ITERATION REPORT--------
Saving checkpoint 8604534...
Checkpoint 8604534 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.08242
Policy Entropy: 5.99169
Value Function Loss: 0.12430
Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04508
Policy Update Magnitude: 0.07991
Value Function Update Magnitude: 0.06551
Collected Steps per Second: 10,986.25275
Overall Steps per Second: 8,401.69157
Timestep Collection Time: 4.55260
Timestep Consumption Time: 1.40049
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.95309
Cumulative Model Updates: 514
Cumulative Timesteps: 8,654,550
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.06774
Policy Entropy: 5.94881
Value Function Loss: 0.13971
Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.03958
Policy Update Magnitude: 0.08629
Value Function Update Magnitude: 0.06819
Collected Steps per Second: 11,323.54841
Overall Steps per Second: 8,593.72739
Timestep Collection Time: 4.41858
Timestep Consumption Time: 1.40357
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.82215
Cumulative Model Updates: 517
Cumulative Timesteps: 8,704,584
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 8704584...
Checkpoint 8704584 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.13860
Policy Entropy: 5.96144
Value Function Loss: 0.19538
Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.03933
Policy Update Magnitude: 0.08416
Value Function Update Magnitude: 0.09427
Collected Steps per Second: 11,015.25261
Overall Steps per Second: 8,374.96497
Timestep Collection Time: 4.54370
Timestep Consumption Time: 1.43244
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.97614
Cumulative Model Updates: 520
Cumulative Timesteps: 8,754,634
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.98763
Policy Entropy: 5.95291
Value Function Loss: 0.18781
Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06159
Policy Update Magnitude: 0.09012
Value Function Update Magnitude: 0.11712
Collected Steps per Second: 11,239.89638
Overall Steps per Second: 8,708.64634
Timestep Collection Time: 4.44897
Timestep Consumption Time: 1.29314
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.74211
Cumulative Model Updates: 523
Cumulative Timesteps: 8,804,640
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 8804640...
Checkpoint 8804640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.20131
Policy Entropy: 5.89554
Value Function Loss: 0.18124
Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03744
Policy Update Magnitude: 0.09229
Value Function Update Magnitude: 0.12002
Collected Steps per Second: 11,166.62309
Overall Steps per Second: 8,483.31159
Timestep Collection Time: 4.48067
Timestep Consumption Time: 1.41726
PPO Batch Consumption Time: 0.05119
Total Iteration Time: 5.89793
Cumulative Model Updates: 526
Cumulative Timesteps: 8,854,674
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.16527
Policy Entropy: 5.87036
Value Function Loss: 0.13586
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02117
Policy Update Magnitude: 0.09366
Value Function Update Magnitude: 0.10985
Collected Steps per Second: 11,054.00862
Overall Steps per Second: 8,373.64047
Timestep Collection Time: 4.52705
Timestep Consumption Time: 1.44909
PPO Batch Consumption Time: 0.06933
Total Iteration Time: 5.97613
Cumulative Model Updates: 529
Cumulative Timesteps: 8,904,716
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 8904716...
Checkpoint 8904716 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.23207
Policy Entropy: 5.85551
Value Function Loss: 0.13905
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.09332
Value Function Update Magnitude: 0.10880
Collected Steps per Second: 11,350.22693
Overall Steps per Second: 8,565.60992
Timestep Collection Time: 4.40819
Timestep Consumption Time: 1.43307
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.84127
Cumulative Model Updates: 532
Cumulative Timesteps: 8,954,750
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.53638
Policy Entropy: 5.85288
Value Function Loss: 0.12801
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02123
Policy Update Magnitude: 0.08793
Value Function Update Magnitude: 0.09099
Collected Steps per Second: 11,064.20331
Overall Steps per Second: 8,389.49527
Timestep Collection Time: 4.51908
Timestep Consumption Time: 1.44076
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.95983
Cumulative Model Updates: 535
Cumulative Timesteps: 9,004,750
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 9004750...
Checkpoint 9004750 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.07194
Policy Entropy: 5.82650
Value Function Loss: 0.14046
Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04323
Policy Update Magnitude: 0.08594
Value Function Update Magnitude: 0.07564
Collected Steps per Second: 11,145.14840
Overall Steps per Second: 8,632.90077
Timestep Collection Time: 4.48805
Timestep Consumption Time: 1.30606
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.79411
Cumulative Model Updates: 538
Cumulative Timesteps: 9,054,770
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.20360
Policy Entropy: 5.85964
Value Function Loss: 0.15262
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02545
Policy Update Magnitude: 0.08684
Value Function Update Magnitude: 0.07531
Collected Steps per Second: 11,151.00382
Overall Steps per Second: 8,487.20131
Timestep Collection Time: 4.48821
Timestep Consumption Time: 1.40867
PPO Batch Consumption Time: 0.04993
Total Iteration Time: 5.89688
Cumulative Model Updates: 541
Cumulative Timesteps: 9,104,818
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 9104818...
Checkpoint 9104818 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.41814
Policy Entropy: 5.86759
Value Function Loss: 0.13228
Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.03437
Policy Update Magnitude: 0.08857
Value Function Update Magnitude: 0.08319
Collected Steps per Second: 10,998.60053
Overall Steps per Second: 8,450.01894
Timestep Collection Time: 4.54731
Timestep Consumption Time: 1.37150
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.91880
Cumulative Model Updates: 544
Cumulative Timesteps: 9,154,832
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.00369
Policy Entropy: 5.81193
Value Function Loss: 0.14652
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02430
Policy Update Magnitude: 0.08219
Value Function Update Magnitude: 0.07969
Collected Steps per Second: 11,081.93879
Overall Steps per Second: 8,567.69275
Timestep Collection Time: 4.51455
Timestep Consumption Time: 1.32483
PPO Batch Consumption Time: 0.04938
Total Iteration Time: 5.83938
Cumulative Model Updates: 547
Cumulative Timesteps: 9,204,862
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 9204862...
Checkpoint 9204862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.27288
Policy Entropy: 5.74478
Value Function Loss: 0.14823
Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.04874
Policy Update Magnitude: 0.08195
Value Function Update Magnitude: 0.08061
Collected Steps per Second: 11,055.41399
Overall Steps per Second: 8,402.38255
Timestep Collection Time: 4.52321
Timestep Consumption Time: 1.42819
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.95141
Cumulative Model Updates: 550
Cumulative Timesteps: 9,254,868
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.12879
Policy Entropy: 5.75396
Value Function Loss: 0.15944
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02967
Policy Update Magnitude: 0.08252
Value Function Update Magnitude: 0.09236
Collected Steps per Second: 11,127.39308
Overall Steps per Second: 8,526.99480
Timestep Collection Time: 4.49611
Timestep Consumption Time: 1.37114
PPO Batch Consumption Time: 0.07304
Total Iteration Time: 5.86725
Cumulative Model Updates: 553
Cumulative Timesteps: 9,304,898
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 9304898...
Checkpoint 9304898 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.56233
Policy Entropy: 5.70159
Value Function Loss: 0.15355
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.08756
Value Function Update Magnitude: 0.09748
Collected Steps per Second: 11,071.32421
Overall Steps per Second: 8,427.28466
Timestep Collection Time: 4.51924
Timestep Consumption Time: 1.41790
PPO Batch Consumption Time: 0.05270
Total Iteration Time: 5.93714
Cumulative Model Updates: 556
Cumulative Timesteps: 9,354,932
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.59225
Policy Entropy: 5.63746
Value Function Loss: 0.14953
Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04244
Policy Update Magnitude: 0.08945
Value Function Update Magnitude: 0.09726
Collected Steps per Second: 11,039.87013
Overall Steps per Second: 8,465.24585
Timestep Collection Time: 4.53085
Timestep Consumption Time: 1.37802
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.90887
Cumulative Model Updates: 559
Cumulative Timesteps: 9,404,952
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 9404952...
Checkpoint 9404952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.54129
Policy Entropy: 5.66553
Value Function Loss: 0.13551
Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.03900
Policy Update Magnitude: 0.08421
Value Function Update Magnitude: 0.09698
Collected Steps per Second: 11,063.95646
Overall Steps per Second: 8,553.85907
Timestep Collection Time: 4.52044
Timestep Consumption Time: 1.32651
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.84695
Cumulative Model Updates: 562
Cumulative Timesteps: 9,454,966
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.41648
Policy Entropy: 5.61730
Value Function Loss: 0.09568
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01465
Policy Update Magnitude: 0.08445
Value Function Update Magnitude: 0.10080
Collected Steps per Second: 11,078.44787
Overall Steps per Second: 8,409.39315
Timestep Collection Time: 4.51670
Timestep Consumption Time: 1.43355
PPO Batch Consumption Time: 0.05107
Total Iteration Time: 5.95025
Cumulative Model Updates: 565
Cumulative Timesteps: 9,505,004
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 9505004...
Checkpoint 9505004 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.30193
Policy Entropy: 5.56584
Value Function Loss: 0.07805
Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.04501
Policy Update Magnitude: 0.07603
Value Function Update Magnitude: 0.09679
Collected Steps per Second: 11,077.72441
Overall Steps per Second: 8,498.99400
Timestep Collection Time: 4.51753
Timestep Consumption Time: 1.37069
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.88823
Cumulative Model Updates: 568
Cumulative Timesteps: 9,555,048
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.30785
Policy Entropy: 5.60688
Value Function Loss: 0.08892
Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03783
Policy Update Magnitude: 0.06695
Value Function Update Magnitude: 0.08475
Collected Steps per Second: 11,279.17604
Overall Steps per Second: 8,543.51755
Timestep Collection Time: 4.43667
Timestep Consumption Time: 1.42063
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.85731
Cumulative Model Updates: 571
Cumulative Timesteps: 9,605,090
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 9605090...
Checkpoint 9605090 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.54039
Policy Entropy: 5.58959
Value Function Loss: 0.09972
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02998
Policy Update Magnitude: 0.06799
Value Function Update Magnitude: 0.07849
Collected Steps per Second: 10,978.77275
Overall Steps per Second: 8,362.59738
Timestep Collection Time: 4.55843
Timestep Consumption Time: 1.42607
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.98450
Cumulative Model Updates: 574
Cumulative Timesteps: 9,655,136
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.35007
Policy Entropy: 5.53592
Value Function Loss: 0.10178
Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 0.07634
Value Function Update Magnitude: 0.07580
Collected Steps per Second: 11,057.19019
Overall Steps per Second: 8,442.78470
Timestep Collection Time: 4.52412
Timestep Consumption Time: 1.40094
PPO Batch Consumption Time: 0.07800
Total Iteration Time: 5.92506
Cumulative Model Updates: 577
Cumulative Timesteps: 9,705,160
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 9705160...
Checkpoint 9705160 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.59629
Policy Entropy: 5.55467
Value Function Loss: 0.10543
Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03591
Policy Update Magnitude: 0.07318
Value Function Update Magnitude: 0.07470
Collected Steps per Second: 11,125.00743
Overall Steps per Second: 8,435.59434
Timestep Collection Time: 4.49887
Timestep Consumption Time: 1.43432
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.93319
Cumulative Model Updates: 580
Cumulative Timesteps: 9,755,210
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.95989
Policy Entropy: 5.54205
Value Function Loss: 0.10669
Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.03309
Policy Update Magnitude: 0.07428
Value Function Update Magnitude: 0.07433
Collected Steps per Second: 11,079.19308
Overall Steps per Second: 8,512.92123
Timestep Collection Time: 4.51351
Timestep Consumption Time: 1.36062
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.87413
Cumulative Model Updates: 583
Cumulative Timesteps: 9,805,216
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 9805216...
Checkpoint 9805216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.73769
Policy Entropy: 5.43904
Value Function Loss: 0.12332
Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.03424
Policy Update Magnitude: 0.07489
Value Function Update Magnitude: 0.07647
Collected Steps per Second: 11,270.20620
Overall Steps per Second: 8,556.71585
Timestep Collection Time: 4.44020
Timestep Consumption Time: 1.40807
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.84827
Cumulative Model Updates: 586
Cumulative Timesteps: 9,855,258
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.46760
Policy Entropy: 5.48102
Value Function Loss: 0.13754
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.07716
Value Function Update Magnitude: 0.07152
Collected Steps per Second: 11,097.02356
Overall Steps per Second: 8,438.45185
Timestep Collection Time: 4.50950
Timestep Consumption Time: 1.42074
PPO Batch Consumption Time: 0.05064
Total Iteration Time: 5.93023
Cumulative Model Updates: 589
Cumulative Timesteps: 9,905,300
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 9905300...
Checkpoint 9905300 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.64156
Policy Entropy: 5.49392
Value Function Loss: 0.16206
Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.03340
Policy Update Magnitude: 0.07795
Value Function Update Magnitude: 0.07202
Collected Steps per Second: 11,077.00521
Overall Steps per Second: 8,489.56263
Timestep Collection Time: 4.51512
Timestep Consumption Time: 1.37611
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.89123
Cumulative Model Updates: 592
Cumulative Timesteps: 9,955,314
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.76630
Policy Entropy: 5.38444
Value Function Loss: 0.15150
Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05147
Policy Update Magnitude: 0.07614
Value Function Update Magnitude: 0.07772
Collected Steps per Second: 11,327.17786
Overall Steps per Second: 8,557.44599
Timestep Collection Time: 4.41769
Timestep Consumption Time: 1.42985
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.84754
Cumulative Model Updates: 595
Cumulative Timesteps: 10,005,354
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 10005354...
Checkpoint 10005354 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.70393
Policy Entropy: 5.39442
Value Function Loss: 0.12170
Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.03789
Policy Update Magnitude: 0.07399
Value Function Update Magnitude: 0.07595
Collected Steps per Second: 11,151.00956
Overall Steps per Second: 8,476.06656
Timestep Collection Time: 4.48408
Timestep Consumption Time: 1.41512
PPO Batch Consumption Time: 0.04952
Total Iteration Time: 5.89920
Cumulative Model Updates: 598
Cumulative Timesteps: 10,055,356
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.57952
Policy Entropy: 5.43232
Value Function Loss: 0.09906
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.06639
Value Function Update Magnitude: 0.06478
Collected Steps per Second: 11,098.93380
Overall Steps per Second: 8,439.89905
Timestep Collection Time: 4.50656
Timestep Consumption Time: 1.41982
PPO Batch Consumption Time: 0.07900
Total Iteration Time: 5.92637
Cumulative Model Updates: 601
Cumulative Timesteps: 10,105,374
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 10105374...
Checkpoint 10105374 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.72813
Policy Entropy: 5.35354
Value Function Loss: 0.10489
Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03159
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.05701
Collected Steps per Second: 11,097.48876
Overall Steps per Second: 8,402.76257
Timestep Collection Time: 4.50877
Timestep Consumption Time: 1.44594
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.95471
Cumulative Model Updates: 604
Cumulative Timesteps: 10,155,410
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.53149
Policy Entropy: 5.44017
Value Function Loss: 0.11922
Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.03547
Policy Update Magnitude: 0.06686
Value Function Update Magnitude: 0.06011
Collected Steps per Second: 11,028.11596
Overall Steps per Second: 8,444.06657
Timestep Collection Time: 4.53387
Timestep Consumption Time: 1.38745
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.92132
Cumulative Model Updates: 607
Cumulative Timesteps: 10,205,410
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 10205410...
Checkpoint 10205410 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.69081
Policy Entropy: 5.39241
Value Function Loss: 0.13084
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.07641
Value Function Update Magnitude: 0.06255
Collected Steps per Second: 11,271.12378
Overall Steps per Second: 8,534.01656
Timestep Collection Time: 4.43736
Timestep Consumption Time: 1.42319
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.86055
Cumulative Model Updates: 610
Cumulative Timesteps: 10,255,424
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.61482
Policy Entropy: 5.28092
Value Function Loss: 0.13668
Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.05928
Policy Update Magnitude: 0.07150
Value Function Update Magnitude: 0.05808
Collected Steps per Second: 11,057.30375
Overall Steps per Second: 8,404.55531
Timestep Collection Time: 4.52208
Timestep Consumption Time: 1.42731
PPO Batch Consumption Time: 0.04947
Total Iteration Time: 5.94939
Cumulative Model Updates: 613
Cumulative Timesteps: 10,305,426
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 10305426...
Checkpoint 10305426 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.45046
Policy Entropy: 5.36153
Value Function Loss: 0.14200
Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.03637
Policy Update Magnitude: 0.07128
Value Function Update Magnitude: 0.05434
Collected Steps per Second: 10,971.04476
Overall Steps per Second: 8,490.19982
Timestep Collection Time: 4.55745
Timestep Consumption Time: 1.33169
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.88914
Cumulative Model Updates: 616
Cumulative Timesteps: 10,355,426
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.41035
Policy Entropy: 5.28584
Value Function Loss: 0.16531
Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05365
Policy Update Magnitude: 0.07359
Value Function Update Magnitude: 0.05403
Collected Steps per Second: 10,883.44394
Overall Steps per Second: 8,312.14131
Timestep Collection Time: 4.59634
Timestep Consumption Time: 1.42185
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 6.01818
Cumulative Model Updates: 619
Cumulative Timesteps: 10,405,450
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 10405450...
Checkpoint 10405450 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.92904
Policy Entropy: 5.23958
Value Function Loss: 0.17564
Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03250
Policy Update Magnitude: 0.07348
Value Function Update Magnitude: 0.05061
Collected Steps per Second: 11,034.29373
Overall Steps per Second: 8,473.83803
Timestep Collection Time: 4.53568
Timestep Consumption Time: 1.37050
PPO Batch Consumption Time: 0.05032
Total Iteration Time: 5.90618
Cumulative Model Updates: 622
Cumulative Timesteps: 10,455,498
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.76122
Policy Entropy: 5.34550
Value Function Loss: 0.15569
Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05226
Policy Update Magnitude: 0.07026
Value Function Update Magnitude: 0.04701
Collected Steps per Second: 11,084.10264
Overall Steps per Second: 8,459.54561
Timestep Collection Time: 4.51151
Timestep Consumption Time: 1.39969
PPO Batch Consumption Time: 0.07667
Total Iteration Time: 5.91119
Cumulative Model Updates: 625
Cumulative Timesteps: 10,505,504
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 10505504...
Checkpoint 10505504 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.52296
Policy Entropy: 5.24665
Value Function Loss: 0.15229
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.01584
Policy Update Magnitude: 0.07656
Value Function Update Magnitude: 0.04478
Collected Steps per Second: 11,220.78836
Overall Steps per Second: 8,520.84586
Timestep Collection Time: 4.45958
Timestep Consumption Time: 1.41308
PPO Batch Consumption Time: 0.05304
Total Iteration Time: 5.87266
Cumulative Model Updates: 628
Cumulative Timesteps: 10,555,544
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.38125
Policy Entropy: 5.20996
Value Function Loss: 0.12610
Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 0.07566
Value Function Update Magnitude: 0.04133
Collected Steps per Second: 11,016.04630
Overall Steps per Second: 8,407.63878
Timestep Collection Time: 4.53883
Timestep Consumption Time: 1.40814
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.94697
Cumulative Model Updates: 631
Cumulative Timesteps: 10,605,544
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 10605544...
Checkpoint 10605544 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.57789
Policy Entropy: 5.26807
Value Function Loss: 0.13730
Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04683
Policy Update Magnitude: 0.07226
Value Function Update Magnitude: 0.04142
Collected Steps per Second: 11,158.14182
Overall Steps per Second: 8,501.59759
Timestep Collection Time: 4.48300
Timestep Consumption Time: 1.40083
PPO Batch Consumption Time: 0.05090
Total Iteration Time: 5.88384
Cumulative Model Updates: 634
Cumulative Timesteps: 10,655,566
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.57086
Policy Entropy: 5.14403
Value Function Loss: 0.13920
Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05455
Policy Update Magnitude: 0.07077
Value Function Update Magnitude: 0.03820
Collected Steps per Second: 11,126.62806
Overall Steps per Second: 8,483.34992
Timestep Collection Time: 4.49372
Timestep Consumption Time: 1.40017
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.89390
Cumulative Model Updates: 637
Cumulative Timesteps: 10,705,566
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 10705566...
Checkpoint 10705566 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.40362
Policy Entropy: 5.17402
Value Function Loss: 0.14585
Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04375
Policy Update Magnitude: 0.07423
Value Function Update Magnitude: 0.04038
Collected Steps per Second: 11,120.45793
Overall Steps per Second: 8,625.65005
Timestep Collection Time: 4.49874
Timestep Consumption Time: 1.30118
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.79991
Cumulative Model Updates: 640
Cumulative Timesteps: 10,755,594
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.59100
Policy Entropy: 5.17579
Value Function Loss: 0.14205
Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04438
Policy Update Magnitude: 0.06879
Value Function Update Magnitude: 0.03713
Collected Steps per Second: 11,027.63045
Overall Steps per Second: 8,384.86416
Timestep Collection Time: 4.53751
Timestep Consumption Time: 1.43015
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.96766
Cumulative Model Updates: 643
Cumulative Timesteps: 10,805,632
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 10805632...
Checkpoint 10805632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.63782
Policy Entropy: 5.09993
Value Function Loss: 0.13338
Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.06449
Value Function Update Magnitude: 0.03799
Collected Steps per Second: 11,043.67767
Overall Steps per Second: 8,458.86451
Timestep Collection Time: 4.52820
Timestep Consumption Time: 1.38370
PPO Batch Consumption Time: 0.05156
Total Iteration Time: 5.91190
Cumulative Model Updates: 646
Cumulative Timesteps: 10,855,640
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.65128
Policy Entropy: 5.17093
Value Function Loss: 0.18240
Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.06902
Value Function Update Magnitude: 0.03813
Collected Steps per Second: 11,293.79369
Overall Steps per Second: 8,416.89561
Timestep Collection Time: 4.43058
Timestep Consumption Time: 1.51437
PPO Batch Consumption Time: 0.07733
Total Iteration Time: 5.94495
Cumulative Model Updates: 649
Cumulative Timesteps: 10,905,678
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 10905678...
Checkpoint 10905678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.55639
Policy Entropy: 5.15497
Value Function Loss: 0.20213
Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05005
Policy Update Magnitude: 0.07541
Value Function Update Magnitude: 0.04721
Collected Steps per Second: 11,026.68841
Overall Steps per Second: 8,369.51730
Timestep Collection Time: 4.53917
Timestep Consumption Time: 1.44110
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.98027
Cumulative Model Updates: 652
Cumulative Timesteps: 10,955,730
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.58707
Policy Entropy: 5.08447
Value Function Loss: 0.19510
Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.03263
Policy Update Magnitude: 0.07858
Value Function Update Magnitude: 0.04642
Collected Steps per Second: 11,046.77786
Overall Steps per Second: 8,567.16804
Timestep Collection Time: 4.52657
Timestep Consumption Time: 1.31013
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.83670
Cumulative Model Updates: 655
Cumulative Timesteps: 11,005,734
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 11005734...
Checkpoint 11005734 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.90757
Policy Entropy: 5.14676
Value Function Loss: 0.14957
Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04235
Policy Update Magnitude: 0.07477
Value Function Update Magnitude: 0.04782
Collected Steps per Second: 11,169.99336
Overall Steps per Second: 8,489.22940
Timestep Collection Time: 4.47628
Timestep Consumption Time: 1.41354
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.88982
Cumulative Model Updates: 658
Cumulative Timesteps: 11,055,734
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.98727
Policy Entropy: 5.04733
Value Function Loss: 0.13492
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02063
Policy Update Magnitude: 0.06792
Value Function Update Magnitude: 0.04447
Collected Steps per Second: 11,057.20075
Overall Steps per Second: 8,469.22521
Timestep Collection Time: 4.52393
Timestep Consumption Time: 1.38240
PPO Batch Consumption Time: 0.04955
Total Iteration Time: 5.90633
Cumulative Model Updates: 661
Cumulative Timesteps: 11,105,756
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 11105756...
Checkpoint 11105756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.42416
Policy Entropy: 4.99722
Value Function Loss: 0.14441
Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.04362
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.04073
Collected Steps per Second: 11,228.37573
Overall Steps per Second: 8,545.94026
Timestep Collection Time: 4.45372
Timestep Consumption Time: 1.39795
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.85167
Cumulative Model Updates: 664
Cumulative Timesteps: 11,155,764
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.50830
Policy Entropy: 5.04484
Value Function Loss: 0.13908
Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05204
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.04017
Collected Steps per Second: 11,087.56976
Overall Steps per Second: 8,389.79346
Timestep Collection Time: 4.51046
Timestep Consumption Time: 1.45036
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.96081
Cumulative Model Updates: 667
Cumulative Timesteps: 11,205,774
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 11205774...
Checkpoint 11205774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.07766
Policy Entropy: 4.98834
Value Function Loss: 0.12939
Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03521
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.04043
Collected Steps per Second: 11,087.83796
Overall Steps per Second: 8,577.58304
Timestep Collection Time: 4.51359
Timestep Consumption Time: 1.32092
PPO Batch Consumption Time: 0.05073
Total Iteration Time: 5.83451
Cumulative Model Updates: 670
Cumulative Timesteps: 11,255,820
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.79659
Policy Entropy: 4.97317
Value Function Loss: 0.11237
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.03820
Collected Steps per Second: 11,134.52497
Overall Steps per Second: 8,344.71313
Timestep Collection Time: 4.49197
Timestep Consumption Time: 1.50176
PPO Batch Consumption Time: 0.07800
Total Iteration Time: 5.99374
Cumulative Model Updates: 673
Cumulative Timesteps: 11,305,836
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 11305836...
Checkpoint 11305836 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.67440
Policy Entropy: 5.04899
Value Function Loss: 0.12668
Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04056
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.04619
Collected Steps per Second: 11,020.22120
Overall Steps per Second: 8,406.82035
Timestep Collection Time: 4.54074
Timestep Consumption Time: 1.41157
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.95231
Cumulative Model Updates: 676
Cumulative Timesteps: 11,355,876
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.70016
Policy Entropy: 4.97992
Value Function Loss: 0.13396
Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05124
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.04491
Collected Steps per Second: 10,945.04949
Overall Steps per Second: 8,474.53390
Timestep Collection Time: 4.56846
Timestep Consumption Time: 1.33181
PPO Batch Consumption Time: 0.05262
Total Iteration Time: 5.90027
Cumulative Model Updates: 679
Cumulative Timesteps: 11,405,878
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 11405878...
Checkpoint 11405878 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.01429
Policy Entropy: 4.98694
Value Function Loss: 0.15384
Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.03810
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.04732
Collected Steps per Second: 10,960.95991
Overall Steps per Second: 8,331.42868
Timestep Collection Time: 4.56310
Timestep Consumption Time: 1.44019
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 6.00329
Cumulative Model Updates: 682
Cumulative Timesteps: 11,455,894
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.36492
Policy Entropy: 5.02022
Value Function Loss: 0.16013
Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05826
Policy Update Magnitude: 0.06501
Value Function Update Magnitude: 0.04103
Collected Steps per Second: 11,031.38269
Overall Steps per Second: 8,581.83923
Timestep Collection Time: 4.53542
Timestep Consumption Time: 1.29456
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.82999
Cumulative Model Updates: 685
Cumulative Timesteps: 11,505,926
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 11505926...
Checkpoint 11505926 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.32873
Policy Entropy: 4.97792
Value Function Loss: 0.13195
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01765
Policy Update Magnitude: 0.06971
Value Function Update Magnitude: 0.03864
Collected Steps per Second: 11,097.52618
Overall Steps per Second: 8,458.64309
Timestep Collection Time: 4.50965
Timestep Consumption Time: 1.40690
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.91655
Cumulative Model Updates: 688
Cumulative Timesteps: 11,555,972
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.01871
Policy Entropy: 4.97272
Value Function Loss: 0.12297
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02913
Policy Update Magnitude: 0.07071
Value Function Update Magnitude: 0.03458
Collected Steps per Second: 11,009.95650
Overall Steps per Second: 8,430.15518
Timestep Collection Time: 4.54334
Timestep Consumption Time: 1.39036
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.93370
Cumulative Model Updates: 691
Cumulative Timesteps: 11,605,994
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 11605994...
Checkpoint 11605994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.11635
Policy Entropy: 4.96112
Value Function Loss: 0.15641
Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09933
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.03464
Collected Steps per Second: 10,807.04112
Overall Steps per Second: 8,435.45614
Timestep Collection Time: 4.62809
Timestep Consumption Time: 1.30116
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.92926
Cumulative Model Updates: 694
Cumulative Timesteps: 11,656,010
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.54212
Policy Entropy: 4.88669
Value Function Loss: 0.19467
Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.03689
Collected Steps per Second: 11,045.15496
Overall Steps per Second: 8,321.08786
Timestep Collection Time: 4.53158
Timestep Consumption Time: 1.48350
PPO Batch Consumption Time: 0.06701
Total Iteration Time: 6.01508
Cumulative Model Updates: 697
Cumulative Timesteps: 11,706,062
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 11706062...
Checkpoint 11706062 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.98831
Policy Entropy: 4.91257
Value Function Loss: 0.19631
Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05852
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.03918
Collected Steps per Second: 10,917.03176
Overall Steps per Second: 8,510.87888
Timestep Collection Time: 4.58348
Timestep Consumption Time: 1.29582
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.87930
Cumulative Model Updates: 700
Cumulative Timesteps: 11,756,100
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.46337
Policy Entropy: 4.93278
Value Function Loss: 0.17233
Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.04728
Policy Update Magnitude: 0.06453
Value Function Update Magnitude: 0.03520
Collected Steps per Second: 11,104.92271
Overall Steps per Second: 8,463.68796
Timestep Collection Time: 4.50287
Timestep Consumption Time: 1.40519
PPO Batch Consumption Time: 0.05023
Total Iteration Time: 5.90806
Cumulative Model Updates: 703
Cumulative Timesteps: 11,806,104
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 11806104...
Checkpoint 11806104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.53409
Policy Entropy: 4.84184
Value Function Loss: 0.18181
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.03599
Collected Steps per Second: 10,924.38306
Overall Steps per Second: 8,390.78926
Timestep Collection Time: 4.57692
Timestep Consumption Time: 1.38200
PPO Batch Consumption Time: 0.05001
Total Iteration Time: 5.95892
Cumulative Model Updates: 706
Cumulative Timesteps: 11,856,104
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.66755
Policy Entropy: 4.97165
Value Function Loss: 0.20719
Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.03355
Policy Update Magnitude: 0.06145
Value Function Update Magnitude: 0.03665
Collected Steps per Second: 10,935.39196
Overall Steps per Second: 8,487.19578
Timestep Collection Time: 4.57505
Timestep Consumption Time: 1.31971
PPO Batch Consumption Time: 0.04954
Total Iteration Time: 5.89476
Cumulative Model Updates: 709
Cumulative Timesteps: 11,906,134
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 11906134...
Checkpoint 11906134 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.70243
Policy Entropy: 4.97931
Value Function Loss: 0.20469
Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.03647
Policy Update Magnitude: 0.07157
Value Function Update Magnitude: 0.03781
Collected Steps per Second: 10,949.34284
Overall Steps per Second: 8,366.71116
Timestep Collection Time: 4.57233
Timestep Consumption Time: 1.41138
PPO Batch Consumption Time: 0.05043
Total Iteration Time: 5.98371
Cumulative Model Updates: 712
Cumulative Timesteps: 11,956,198
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.74975
Policy Entropy: 4.88021
Value Function Loss: 0.18209
Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 0.06277
Value Function Update Magnitude: 0.04403
Collected Steps per Second: 10,916.60393
Overall Steps per Second: 8,397.01081
Timestep Collection Time: 4.58293
Timestep Consumption Time: 1.37515
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.95807
Cumulative Model Updates: 715
Cumulative Timesteps: 12,006,228
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 12006228...
Checkpoint 12006228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.87838
Policy Entropy: 4.92331
Value Function Loss: 0.15797
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01358
Policy Update Magnitude: 0.06580
Value Function Update Magnitude: 0.03938
Collected Steps per Second: 11,050.84297
Overall Steps per Second: 8,427.46040
Timestep Collection Time: 4.52961
Timestep Consumption Time: 1.41002
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.93963
Cumulative Model Updates: 718
Cumulative Timesteps: 12,056,284
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.77458
Policy Entropy: 4.96716
Value Function Loss: 0.15285
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.03839
Collected Steps per Second: 11,092.34709
Overall Steps per Second: 8,355.95178
Timestep Collection Time: 4.50833
Timestep Consumption Time: 1.47638
PPO Batch Consumption Time: 0.07400
Total Iteration Time: 5.98472
Cumulative Model Updates: 721
Cumulative Timesteps: 12,106,292
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 12106292...
Checkpoint 12106292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.82949
Policy Entropy: 4.88646
Value Function Loss: 0.19757
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02827
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.04480
Collected Steps per Second: 11,012.24108
Overall Steps per Second: 8,499.96056
Timestep Collection Time: 4.54185
Timestep Consumption Time: 1.34241
PPO Batch Consumption Time: 0.05400
Total Iteration Time: 5.88426
Cumulative Model Updates: 724
Cumulative Timesteps: 12,156,308
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.07889
Policy Entropy: 4.84481
Value Function Loss: 0.19908
Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 0.06811
Value Function Update Magnitude: 0.04317
Collected Steps per Second: 10,837.12350
Overall Steps per Second: 8,242.74521
Timestep Collection Time: 4.61691
Timestep Consumption Time: 1.45316
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 6.07007
Cumulative Model Updates: 727
Cumulative Timesteps: 12,206,342
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 12206342...
Checkpoint 12206342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.92472
Policy Entropy: 4.92701
Value Function Loss: 0.23807
Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.03901
Policy Update Magnitude: 0.07344
Value Function Update Magnitude: 0.04716
Collected Steps per Second: 10,816.05239
Overall Steps per Second: 8,271.88689
Timestep Collection Time: 4.62683
Timestep Consumption Time: 1.42306
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 6.04989
Cumulative Model Updates: 730
Cumulative Timesteps: 12,256,386
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.55907
Policy Entropy: 4.83770
Value Function Loss: 0.20634
Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.07321
Value Function Update Magnitude: 0.04509
Collected Steps per Second: 11,218.98247
Overall Steps per Second: 8,522.02182
Timestep Collection Time: 4.45941
Timestep Consumption Time: 1.41127
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.87067
Cumulative Model Updates: 733
Cumulative Timesteps: 12,306,416
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 12306416...
Checkpoint 12306416 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.76071
Policy Entropy: 4.86034
Value Function Loss: 0.23432
Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05669
Policy Update Magnitude: 0.07534
Value Function Update Magnitude: 0.05123
Collected Steps per Second: 11,038.35652
Overall Steps per Second: 8,381.93309
Timestep Collection Time: 4.53256
Timestep Consumption Time: 1.43647
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.96903
Cumulative Model Updates: 736
Cumulative Timesteps: 12,356,448
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.95710
Policy Entropy: 4.87927
Value Function Loss: 0.19999
Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.07193
Value Function Update Magnitude: 0.04930
Collected Steps per Second: 10,740.80682
Overall Steps per Second: 8,218.30514
Timestep Collection Time: 4.65924
Timestep Consumption Time: 1.43009
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 6.08933
Cumulative Model Updates: 739
Cumulative Timesteps: 12,406,492
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 12406492...
Checkpoint 12406492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.73667
Policy Entropy: 4.85409
Value Function Loss: 0.19257
Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05161
Policy Update Magnitude: 0.06633
Value Function Update Magnitude: 0.05315
Collected Steps per Second: 11,229.67828
Overall Steps per Second: 8,522.89764
Timestep Collection Time: 4.45480
Timestep Consumption Time: 1.41480
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.86960
Cumulative Model Updates: 742
Cumulative Timesteps: 12,456,518
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.14414
Policy Entropy: 4.86843
Value Function Loss: 0.14342
Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.06711
Value Function Update Magnitude: 0.05252
Collected Steps per Second: 10,904.58389
Overall Steps per Second: 8,220.36118
Timestep Collection Time: 4.58541
Timestep Consumption Time: 1.49729
PPO Batch Consumption Time: 0.07367
Total Iteration Time: 6.08270
Cumulative Model Updates: 745
Cumulative Timesteps: 12,506,520
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 12506520...
Checkpoint 12506520 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.77448
Policy Entropy: 4.92013
Value Function Loss: 0.14500
Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.06626
Value Function Update Magnitude: 0.05521
Collected Steps per Second: 10,993.52486
Overall Steps per Second: 8,519.39126
Timestep Collection Time: 4.54959
Timestep Consumption Time: 1.32125
PPO Batch Consumption Time: 0.05318
Total Iteration Time: 5.87084
Cumulative Model Updates: 748
Cumulative Timesteps: 12,556,536
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.41509
Policy Entropy: 4.84510
Value Function Loss: 0.19505
Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.05036
Collected Steps per Second: 10,896.45160
Overall Steps per Second: 8,311.56451
Timestep Collection Time: 4.59122
Timestep Consumption Time: 1.42786
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 6.01908
Cumulative Model Updates: 751
Cumulative Timesteps: 12,606,564
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 12606564...
Checkpoint 12606564 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.44959
Policy Entropy: 4.84251
Value Function Loss: 0.24239
Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05231
Policy Update Magnitude: 0.06808
Value Function Update Magnitude: 0.05349
Collected Steps per Second: 10,836.77677
Overall Steps per Second: 8,291.99113
Timestep Collection Time: 4.61927
Timestep Consumption Time: 1.41764
PPO Batch Consumption Time: 0.05270
Total Iteration Time: 6.03691
Cumulative Model Updates: 754
Cumulative Timesteps: 12,656,622
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.87374
Policy Entropy: 4.86888
Value Function Loss: 0.25868
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01678
Policy Update Magnitude: 0.07567
Value Function Update Magnitude: 0.05544
Collected Steps per Second: 11,222.58089
Overall Steps per Second: 8,515.62512
Timestep Collection Time: 4.45602
Timestep Consumption Time: 1.41648
PPO Batch Consumption Time: 0.05223
Total Iteration Time: 5.87250
Cumulative Model Updates: 757
Cumulative Timesteps: 12,706,630
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 12706630...
Checkpoint 12706630 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81037
Policy Entropy: 4.83413
Value Function Loss: 0.20617
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01953
Policy Update Magnitude: 0.07717
Value Function Update Magnitude: 0.05822
Collected Steps per Second: 10,898.50562
Overall Steps per Second: 8,283.89637
Timestep Collection Time: 4.58870
Timestep Consumption Time: 1.44831
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 6.03701
Cumulative Model Updates: 760
Cumulative Timesteps: 12,756,640
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99592
Policy Entropy: 4.79397
Value Function Loss: 0.18858
Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03321
Policy Update Magnitude: 0.06758
Value Function Update Magnitude: 0.05524
Collected Steps per Second: 10,894.36933
Overall Steps per Second: 8,309.89405
Timestep Collection Time: 4.59338
Timestep Consumption Time: 1.42860
PPO Batch Consumption Time: 0.05140
Total Iteration Time: 6.02198
Cumulative Model Updates: 763
Cumulative Timesteps: 12,806,682
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 12806682...
Checkpoint 12806682 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.83537
Policy Entropy: 4.89387
Value Function Loss: 0.16327
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02836
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.06478
Collected Steps per Second: 11,055.36055
Overall Steps per Second: 8,382.39980
Timestep Collection Time: 4.52414
Timestep Consumption Time: 1.44265
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.96679
Cumulative Model Updates: 766
Cumulative Timesteps: 12,856,698
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.49861
Policy Entropy: 4.89875
Value Function Loss: 0.17121
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.06174
Collected Steps per Second: 11,012.99360
Overall Steps per Second: 8,227.26155
Timestep Collection Time: 4.54391
Timestep Consumption Time: 1.53856
PPO Batch Consumption Time: 0.07070
Total Iteration Time: 6.08246
Cumulative Model Updates: 769
Cumulative Timesteps: 12,906,740
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 12906740...
Checkpoint 12906740 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.77471
Policy Entropy: 4.85676
Value Function Loss: 0.17644
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.01891
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.06520
Collected Steps per Second: 10,926.04071
Overall Steps per Second: 8,471.88982
Timestep Collection Time: 4.57769
Timestep Consumption Time: 1.32607
PPO Batch Consumption Time: 0.05871
Total Iteration Time: 5.90376
Cumulative Model Updates: 772
Cumulative Timesteps: 12,956,756
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.80415
Policy Entropy: 4.91911
Value Function Loss: 0.22802
Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.00799
Policy Update Magnitude: 0.05952
Value Function Update Magnitude: 0.05817
Collected Steps per Second: 10,925.23890
Overall Steps per Second: 8,346.94325
Timestep Collection Time: 4.57784
Timestep Consumption Time: 1.41405
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.99189
Cumulative Model Updates: 775
Cumulative Timesteps: 13,006,770
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 13006770...
Checkpoint 13006770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.86863
Policy Entropy: 4.94790
Value Function Loss: 0.25966
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 0.06307
Value Function Update Magnitude: 0.06560
Collected Steps per Second: 10,974.81320
Overall Steps per Second: 8,423.86801
Timestep Collection Time: 4.55589
Timestep Consumption Time: 1.37963
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.93552
Cumulative Model Updates: 778
Cumulative Timesteps: 13,056,770
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.90122
Policy Entropy: 4.87897
Value Function Loss: 0.25130
Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04451
Policy Update Magnitude: 0.06514
Value Function Update Magnitude: 0.06210
Collected Steps per Second: 11,213.68195
Overall Steps per Second: 8,535.38667
Timestep Collection Time: 4.45955
Timestep Consumption Time: 1.39935
PPO Batch Consumption Time: 0.04969
Total Iteration Time: 5.85890
Cumulative Model Updates: 781
Cumulative Timesteps: 13,106,778
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 13106778...
Checkpoint 13106778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.61363
Policy Entropy: 4.90584
Value Function Loss: 0.23045
Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.03611
Policy Update Magnitude: 0.07338
Value Function Update Magnitude: 0.06206
Collected Steps per Second: 10,943.65893
Overall Steps per Second: 8,352.56451
Timestep Collection Time: 4.57141
Timestep Consumption Time: 1.41812
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 5.98954
Cumulative Model Updates: 784
Cumulative Timesteps: 13,156,806
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.88464
Policy Entropy: 4.98363
Value Function Loss: 0.24404
Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.07132
Value Function Update Magnitude: 0.05990
Collected Steps per Second: 10,964.54900
Overall Steps per Second: 8,522.76543
Timestep Collection Time: 4.56070
Timestep Consumption Time: 1.30665
PPO Batch Consumption Time: 0.04934
Total Iteration Time: 5.86734
Cumulative Model Updates: 787
Cumulative Timesteps: 13,206,812
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 13206812...
Checkpoint 13206812 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.58853
Policy Entropy: 4.87846
Value Function Loss: 0.27460
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03565
Policy Update Magnitude: 0.07060
Value Function Update Magnitude: 0.05921
Collected Steps per Second: 10,970.49807
Overall Steps per Second: 8,375.24748
Timestep Collection Time: 4.56515
Timestep Consumption Time: 1.41461
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.97976
Cumulative Model Updates: 790
Cumulative Timesteps: 13,256,894
Timesteps Collected: 50,082
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.40122
Policy Entropy: 4.91059
Value Function Loss: 0.27486
Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.03646
Policy Update Magnitude: 0.06978
Value Function Update Magnitude: 0.05929
Collected Steps per Second: 10,991.95515
Overall Steps per Second: 8,326.16163
Timestep Collection Time: 4.54951
Timestep Consumption Time: 1.45662
PPO Batch Consumption Time: 0.07400
Total Iteration Time: 6.00613
Cumulative Model Updates: 793
Cumulative Timesteps: 13,306,902
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 13306902...
Checkpoint 13306902 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.71232
Policy Entropy: 4.89926
Value Function Loss: 0.26095
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02927
Policy Update Magnitude: 0.06555
Value Function Update Magnitude: 0.06461
Collected Steps per Second: 10,934.04200
Overall Steps per Second: 8,480.58425
Timestep Collection Time: 4.57617
Timestep Consumption Time: 1.32390
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.90007
Cumulative Model Updates: 796
Cumulative Timesteps: 13,356,938
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.90919
Policy Entropy: 4.84089
Value Function Loss: 0.25761
Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.07061
Value Function Update Magnitude: 0.06217
Collected Steps per Second: 10,910.13991
Overall Steps per Second: 8,346.32971
Timestep Collection Time: 4.58931
Timestep Consumption Time: 1.40974
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.99904
Cumulative Model Updates: 799
Cumulative Timesteps: 13,407,008
Timesteps Collected: 50,070
--------END ITERATION REPORT--------
Saving checkpoint 13407008...
Checkpoint 13407008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.88831
Policy Entropy: 4.82164
Value Function Loss: 0.26389
Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05369
Policy Update Magnitude: 0.07093
Value Function Update Magnitude: 0.06388
Collected Steps per Second: 10,944.03678
Overall Steps per Second: 8,410.83714
Timestep Collection Time: 4.57290
Timestep Consumption Time: 1.37728
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.95018
Cumulative Model Updates: 802
Cumulative Timesteps: 13,457,054
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.48192
Policy Entropy: 4.88341
Value Function Loss: 0.24017
Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.03408
Policy Update Magnitude: 0.06938
Value Function Update Magnitude: 0.06404
Collected Steps per Second: 11,053.63935
Overall Steps per Second: 8,387.33603
Timestep Collection Time: 4.52702
Timestep Consumption Time: 1.43912
PPO Batch Consumption Time: 0.05086
Total Iteration Time: 5.96614
Cumulative Model Updates: 805
Cumulative Timesteps: 13,507,094
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 13507094...
Checkpoint 13507094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.68435
Policy Entropy: 4.86900
Value Function Loss: 0.21559
Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02328
Policy Update Magnitude: 0.07366
Value Function Update Magnitude: 0.06488
Collected Steps per Second: 10,917.00009
Overall Steps per Second: 8,383.23143
Timestep Collection Time: 4.58459
Timestep Consumption Time: 1.38566
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.97025
Cumulative Model Updates: 808
Cumulative Timesteps: 13,557,144
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81874
Policy Entropy: 4.87354
Value Function Loss: 0.19877
Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05135
Policy Update Magnitude: 0.07061
Value Function Update Magnitude: 0.06110
Collected Steps per Second: 11,002.42923
Overall Steps per Second: 8,538.56838
Timestep Collection Time: 4.54572
Timestep Consumption Time: 1.31170
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.85742
Cumulative Model Updates: 811
Cumulative Timesteps: 13,607,158
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 13607158...
Checkpoint 13607158 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.79882
Policy Entropy: 4.91231
Value Function Loss: 0.19767
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.06986
Value Function Update Magnitude: 0.07081
Collected Steps per Second: 11,045.12261
Overall Steps per Second: 8,413.23789
Timestep Collection Time: 4.53286
Timestep Consumption Time: 1.41800
PPO Batch Consumption Time: 0.05030
Total Iteration Time: 5.95086
Cumulative Model Updates: 814
Cumulative Timesteps: 13,657,224
Timesteps Collected: 50,066
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.63489
Policy Entropy: 4.91575
Value Function Loss: 0.20238
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01567
Policy Update Magnitude: 0.07579
Value Function Update Magnitude: 0.07675
Collected Steps per Second: 10,984.84401
Overall Steps per Second: 8,346.94557
Timestep Collection Time: 4.55227
Timestep Consumption Time: 1.43866
PPO Batch Consumption Time: 0.06967
Total Iteration Time: 5.99093
Cumulative Model Updates: 817
Cumulative Timesteps: 13,707,230
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 13707230...
Checkpoint 13707230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.79298
Policy Entropy: 4.90749
Value Function Loss: 0.23716
Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.03813
Policy Update Magnitude: 0.08193
Value Function Update Magnitude: 0.08031
Collected Steps per Second: 11,184.37547
Overall Steps per Second: 8,483.79187
Timestep Collection Time: 4.47392
Timestep Consumption Time: 1.42415
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.89807
Cumulative Model Updates: 820
Cumulative Timesteps: 13,757,268
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.91226
Policy Entropy: 4.93314
Value Function Loss: 0.24921
Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.03591
Policy Update Magnitude: 0.08045
Value Function Update Magnitude: 0.07625
Collected Steps per Second: 10,869.25262
Overall Steps per Second: 8,313.72661
Timestep Collection Time: 4.60032
Timestep Consumption Time: 1.41407
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 6.01439
Cumulative Model Updates: 823
Cumulative Timesteps: 13,807,270
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 13807270...
Checkpoint 13807270 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.88816
Policy Entropy: 4.95980
Value Function Loss: 0.26254
Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06375
Policy Update Magnitude: 0.07607
Value Function Update Magnitude: 0.07046
Collected Steps per Second: 10,909.18444
Overall Steps per Second: 8,466.96092
Timestep Collection Time: 4.58366
Timestep Consumption Time: 1.32212
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.90578
Cumulative Model Updates: 826
Cumulative Timesteps: 13,857,274
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.39021
Policy Entropy: 4.91783
Value Function Loss: 0.25852
Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.07568
Value Function Update Magnitude: 0.07341
Collected Steps per Second: 11,069.01911
Overall Steps per Second: 8,431.35048
Timestep Collection Time: 4.51928
Timestep Consumption Time: 1.41381
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.93309
Cumulative Model Updates: 829
Cumulative Timesteps: 13,907,298
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 13907298...
Checkpoint 13907298 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.46012
Policy Entropy: 4.92700
Value Function Loss: 0.27970
Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06140
Policy Update Magnitude: 0.07546
Value Function Update Magnitude: 0.07353
Collected Steps per Second: 10,920.89486
Overall Steps per Second: 8,400.29155
Timestep Collection Time: 4.58204
Timestep Consumption Time: 1.37489
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.95694
Cumulative Model Updates: 832
Cumulative Timesteps: 13,957,338
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.61387
Policy Entropy: 4.96756
Value Function Loss: 0.27627
Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.07080
Value Function Update Magnitude: 0.07066
Collected Steps per Second: 11,043.26451
Overall Steps per Second: 8,520.99712
Timestep Collection Time: 4.52801
Timestep Consumption Time: 1.34032
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.86833
Cumulative Model Updates: 835
Cumulative Timesteps: 14,007,342
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 14007342...
Checkpoint 14007342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.76964
Policy Entropy: 4.95587
Value Function Loss: 0.24519
Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05354
Policy Update Magnitude: 0.07054
Value Function Update Magnitude: 0.08033
Collected Steps per Second: 10,993.55639
Overall Steps per Second: 8,368.73726
Timestep Collection Time: 4.55067
Timestep Consumption Time: 1.42730
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.97796
Cumulative Model Updates: 838
Cumulative Timesteps: 14,057,370
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.88418
Policy Entropy: 4.95787
Value Function Loss: 0.23573
Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05159
Policy Update Magnitude: 0.07288
Value Function Update Magnitude: 0.07640
Collected Steps per Second: 11,020.58727
Overall Steps per Second: 8,434.03615
Timestep Collection Time: 4.53696
Timestep Consumption Time: 1.39140
PPO Batch Consumption Time: 0.08100
Total Iteration Time: 5.92836
Cumulative Model Updates: 841
Cumulative Timesteps: 14,107,370
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 14107370...
Checkpoint 14107370 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.65541
Policy Entropy: 4.97395
Value Function Loss: 0.21201
Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.07232
Value Function Update Magnitude: 0.08583
Collected Steps per Second: 11,082.64567
Overall Steps per Second: 8,408.76234
Timestep Collection Time: 4.51354
Timestep Consumption Time: 1.43525
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.94879
Cumulative Model Updates: 844
Cumulative Timesteps: 14,157,392
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.53228
Policy Entropy: 4.92198
Value Function Loss: 0.22101
Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06792
Policy Update Magnitude: 0.06456
Value Function Update Magnitude: 0.07844
Collected Steps per Second: 10,947.70203
Overall Steps per Second: 8,431.24071
Timestep Collection Time: 4.57009
Timestep Consumption Time: 1.36403
PPO Batch Consumption Time: 0.05079
Total Iteration Time: 5.93412
Cumulative Model Updates: 847
Cumulative Timesteps: 14,207,424
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 14207424...
Checkpoint 14207424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.25994
Policy Entropy: 4.94093
Value Function Loss: 0.25009
Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.07069
Policy Update Magnitude: 0.06143
Value Function Update Magnitude: 0.06889
Collected Steps per Second: 10,949.93763
Overall Steps per Second: 8,514.25820
Timestep Collection Time: 4.56715
Timestep Consumption Time: 1.30653
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.87368
Cumulative Model Updates: 850
Cumulative Timesteps: 14,257,434
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.86587
Policy Entropy: 4.96080
Value Function Loss: 0.26505
Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.07170
Collected Steps per Second: 11,038.91103
Overall Steps per Second: 8,395.58259
Timestep Collection Time: 4.53251
Timestep Consumption Time: 1.42705
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.95956
Cumulative Model Updates: 853
Cumulative Timesteps: 14,307,468
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 14307468...
Checkpoint 14307468 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.94752
Policy Entropy: 4.97101
Value Function Loss: 0.29412
Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05251
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.07135
Collected Steps per Second: 11,007.50220
Overall Steps per Second: 8,471.44318
Timestep Collection Time: 4.54472
Timestep Consumption Time: 1.36053
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.90525
Cumulative Model Updates: 856
Cumulative Timesteps: 14,357,494
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.61164
Policy Entropy: 4.97252
Value Function Loss: 0.25390
Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.08333
Policy Update Magnitude: 0.06334
Value Function Update Magnitude: 0.07988
Collected Steps per Second: 11,139.25112
Overall Steps per Second: 8,462.65266
Timestep Collection Time: 4.49186
Timestep Consumption Time: 1.42070
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.91257
Cumulative Model Updates: 859
Cumulative Timesteps: 14,407,530
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 14407530...
Checkpoint 14407530 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.62948
Policy Entropy: 4.96628
Value Function Loss: 0.26817
Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.08170
Collected Steps per Second: 10,949.97649
Overall Steps per Second: 8,351.33796
Timestep Collection Time: 4.56640
Timestep Consumption Time: 1.42090
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.98730
Cumulative Model Updates: 862
Cumulative Timesteps: 14,457,532
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.87644
Policy Entropy: 4.96135
Value Function Loss: 0.25852
Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.06616
Value Function Update Magnitude: 0.08467
Collected Steps per Second: 10,856.78748
Overall Steps per Second: 8,367.38060
Timestep Collection Time: 4.60762
Timestep Consumption Time: 1.37083
PPO Batch Consumption Time: 0.07233
Total Iteration Time: 5.97845
Cumulative Model Updates: 865
Cumulative Timesteps: 14,507,556
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 14507556...
Checkpoint 14507556 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.37351
Policy Entropy: 5.02504
Value Function Loss: 0.28648
Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.08249
Collected Steps per Second: 10,863.31678
Overall Steps per Second: 8,276.00892
Timestep Collection Time: 4.60393
Timestep Consumption Time: 1.43932
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 6.04325
Cumulative Model Updates: 868
Cumulative Timesteps: 14,557,570
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.41472
Policy Entropy: 4.95842
Value Function Loss: 0.29117
Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.06091
Value Function Update Magnitude: 0.08345
Collected Steps per Second: 10,983.46543
Overall Steps per Second: 8,436.82149
Timestep Collection Time: 4.55230
Timestep Consumption Time: 1.37411
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.92640
Cumulative Model Updates: 871
Cumulative Timesteps: 14,607,570
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 14607570...
Checkpoint 14607570 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.89361
Policy Entropy: 4.97864
Value Function Loss: 0.29738
Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06753
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.08347
Collected Steps per Second: 11,112.58243
Overall Steps per Second: 8,515.60540
Timestep Collection Time: 4.50012
Timestep Consumption Time: 1.37239
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.87251
Cumulative Model Updates: 874
Cumulative Timesteps: 14,657,578
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.62935
Policy Entropy: 4.97959
Value Function Loss: 0.27732
Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.06864
Value Function Update Magnitude: 0.08573
Collected Steps per Second: 10,986.63376
Overall Steps per Second: 8,370.86525
Timestep Collection Time: 4.55189
Timestep Consumption Time: 1.42240
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.97429
Cumulative Model Updates: 877
Cumulative Timesteps: 14,707,588
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 14707588...
Checkpoint 14707588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.50331
Policy Entropy: 4.92868
Value Function Loss: 0.26363
Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.07114
Value Function Update Magnitude: 0.09967
Collected Steps per Second: 11,016.51510
Overall Steps per Second: 8,435.14355
Timestep Collection Time: 4.53882
Timestep Consumption Time: 1.38900
PPO Batch Consumption Time: 0.05017
Total Iteration Time: 5.92782
Cumulative Model Updates: 880
Cumulative Timesteps: 14,757,590
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.69901
Policy Entropy: 4.93910
Value Function Loss: 0.25848
Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06000
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.09449
Collected Steps per Second: 11,150.24495
Overall Steps per Second: 8,482.98142
Timestep Collection Time: 4.48546
Timestep Consumption Time: 1.41034
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.89580
Cumulative Model Updates: 883
Cumulative Timesteps: 14,807,604
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 14807604...
Checkpoint 14807604 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.69972
Policy Entropy: 4.95755
Value Function Loss: 0.26526
Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.06113
Policy Update Magnitude: 0.07088
Value Function Update Magnitude: 0.08912
Collected Steps per Second: 10,938.98760
Overall Steps per Second: 8,395.07813
Timestep Collection Time: 4.57647
Timestep Consumption Time: 1.38678
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.96326
Cumulative Model Updates: 886
Cumulative Timesteps: 14,857,666
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.78604
Policy Entropy: 4.95202
Value Function Loss: 0.25514
Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04457
Policy Update Magnitude: 0.07457
Value Function Update Magnitude: 0.08362
Collected Steps per Second: 10,964.60336
Overall Steps per Second: 8,401.23111
Timestep Collection Time: 4.56104
Timestep Consumption Time: 1.39166
PPO Batch Consumption Time: 0.07411
Total Iteration Time: 5.95270
Cumulative Model Updates: 889
Cumulative Timesteps: 14,907,676
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 14907676...
Checkpoint 14907676 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.65909
Policy Entropy: 4.93233
Value Function Loss: 0.27077
Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.07525
Value Function Update Magnitude: 0.07383
Collected Steps per Second: 11,037.03478
Overall Steps per Second: 8,413.95459
Timestep Collection Time: 4.53310
Timestep Consumption Time: 1.41321
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.94631
Cumulative Model Updates: 892
Cumulative Timesteps: 14,957,708
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.61801
Policy Entropy: 4.96987
Value Function Loss: 0.27331
Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07759
Policy Update Magnitude: 0.07169
Value Function Update Magnitude: 0.08070
Collected Steps per Second: 10,998.39987
Overall Steps per Second: 8,440.22548
Timestep Collection Time: 4.54957
Timestep Consumption Time: 1.37894
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.92851
Cumulative Model Updates: 895
Cumulative Timesteps: 15,007,746
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 15007746...
Checkpoint 15007746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.69739
Policy Entropy: 4.92208
Value Function Loss: 0.26750
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.06860
Value Function Update Magnitude: 0.07241
Collected Steps per Second: 11,067.15145
Overall Steps per Second: 8,421.67673
Timestep Collection Time: 4.52293
Timestep Consumption Time: 1.42078
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.94371
Cumulative Model Updates: 898
Cumulative Timesteps: 15,057,802
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.28558
Policy Entropy: 4.90330
Value Function Loss: 0.21060
Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.03961
Policy Update Magnitude: 0.06723
Value Function Update Magnitude: 0.08311
Collected Steps per Second: 11,021.10777
Overall Steps per Second: 8,378.05597
Timestep Collection Time: 4.53875
Timestep Consumption Time: 1.43185
PPO Batch Consumption Time: 0.05068
Total Iteration Time: 5.97060
Cumulative Model Updates: 901
Cumulative Timesteps: 15,107,824
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 15107824...
Checkpoint 15107824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.64198
Policy Entropy: 4.91870
Value Function Loss: 0.21716
Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.03534
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.09445
Collected Steps per Second: 11,052.63292
Overall Steps per Second: 8,437.67862
Timestep Collection Time: 4.52562
Timestep Consumption Time: 1.40255
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.92817
Cumulative Model Updates: 904
Cumulative Timesteps: 15,157,844
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.69391
Policy Entropy: 4.94002
Value Function Loss: 0.24869
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02361
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.09812
Collected Steps per Second: 11,250.29780
Overall Steps per Second: 8,534.65285
Timestep Collection Time: 4.44433
Timestep Consumption Time: 1.41414
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.85847
Cumulative Model Updates: 907
Cumulative Timesteps: 15,207,844
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 15207844...
Checkpoint 15207844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.56480
Policy Entropy: 4.95953
Value Function Loss: 0.26970
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03372
Policy Update Magnitude: 0.06301
Value Function Update Magnitude: 0.09807
Collected Steps per Second: 10,983.90853
Overall Steps per Second: 8,401.74856
Timestep Collection Time: 4.55630
Timestep Consumption Time: 1.40032
PPO Batch Consumption Time: 0.05073
Total Iteration Time: 5.95662
Cumulative Model Updates: 910
Cumulative Timesteps: 15,257,890
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.06315
Policy Entropy: 4.96927
Value Function Loss: 0.26528
Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.06336
Value Function Update Magnitude: 0.09957
Collected Steps per Second: 10,904.05495
Overall Steps per Second: 8,350.03357
Timestep Collection Time: 4.58838
Timestep Consumption Time: 1.40345
PPO Batch Consumption Time: 0.07569
Total Iteration Time: 5.99183
Cumulative Model Updates: 913
Cumulative Timesteps: 15,307,922
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 15307922...
Checkpoint 15307922 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.45528
Policy Entropy: 4.95938
Value Function Loss: 0.25591
Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04075
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.10212
Collected Steps per Second: 10,953.38415
Overall Steps per Second: 8,359.68709
Timestep Collection Time: 4.56644
Timestep Consumption Time: 1.41680
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.98324
Cumulative Model Updates: 916
Cumulative Timesteps: 15,357,940
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.57739
Policy Entropy: 4.98302
Value Function Loss: 0.26921
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01816
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.10467
Collected Steps per Second: 10,914.26668
Overall Steps per Second: 8,358.64602
Timestep Collection Time: 4.58226
Timestep Consumption Time: 1.40101
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.98327
Cumulative Model Updates: 919
Cumulative Timesteps: 15,407,952
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 15407952...
Checkpoint 15407952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.98957
Policy Entropy: 4.93900
Value Function Loss: 0.28827
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02256
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.11786
Collected Steps per Second: 11,147.06853
Overall Steps per Second: 8,474.18293
Timestep Collection Time: 4.48620
Timestep Consumption Time: 1.41502
PPO Batch Consumption Time: 0.05004
Total Iteration Time: 5.90122
Cumulative Model Updates: 922
Cumulative Timesteps: 15,457,960
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.65743
Policy Entropy: 4.92795
Value Function Loss: 0.28770
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.10918
Collected Steps per Second: 11,104.44907
Overall Steps per Second: 8,457.69271
Timestep Collection Time: 4.50396
Timestep Consumption Time: 1.40947
PPO Batch Consumption Time: 0.05008
Total Iteration Time: 5.91343
Cumulative Model Updates: 925
Cumulative Timesteps: 15,507,974
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 15507974...
Checkpoint 15507974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.89012
Policy Entropy: 4.90861
Value Function Loss: 0.26810
Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04197
Policy Update Magnitude: 0.06340
Value Function Update Magnitude: 0.10113
Collected Steps per Second: 11,027.20172
Overall Steps per Second: 8,552.73897
Timestep Collection Time: 4.53660
Timestep Consumption Time: 1.31252
PPO Batch Consumption Time: 0.04986
Total Iteration Time: 5.84912
Cumulative Model Updates: 928
Cumulative Timesteps: 15,558,000
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.27337
Policy Entropy: 4.92289
Value Function Loss: 0.26414
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01631
Policy Update Magnitude: 0.06133
Value Function Update Magnitude: 0.09533
Collected Steps per Second: 11,045.65115
Overall Steps per Second: 8,423.70439
Timestep Collection Time: 4.53101
Timestep Consumption Time: 1.41032
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.94133
Cumulative Model Updates: 931
Cumulative Timesteps: 15,608,048
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 15608048...
Checkpoint 15608048 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.79013
Policy Entropy: 4.92631
Value Function Loss: 0.26385
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.10738
Collected Steps per Second: 10,978.76360
Overall Steps per Second: 8,413.47663
Timestep Collection Time: 4.55844
Timestep Consumption Time: 1.38988
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.94831
Cumulative Model Updates: 934
Cumulative Timesteps: 15,658,094
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.60817
Policy Entropy: 4.92640
Value Function Loss: 0.25222
Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01045
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.10953
Collected Steps per Second: 10,774.01678
Overall Steps per Second: 8,264.62808
Timestep Collection Time: 4.64135
Timestep Consumption Time: 1.40925
PPO Batch Consumption Time: 0.08200
Total Iteration Time: 6.05061
Cumulative Model Updates: 937
Cumulative Timesteps: 15,708,100
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 15708100...
Checkpoint 15708100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.51029
Policy Entropy: 4.92278
Value Function Loss: 0.22895
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02804
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.11103
Collected Steps per Second: 10,990.94767
Overall Steps per Second: 8,382.71843
Timestep Collection Time: 4.55065
Timestep Consumption Time: 1.41591
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.96656
Cumulative Model Updates: 940
Cumulative Timesteps: 15,758,116
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.43058
Policy Entropy: 4.91598
Value Function Loss: 0.21430
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.11034
Collected Steps per Second: 10,959.56626
Overall Steps per Second: 8,395.82254
Timestep Collection Time: 4.56295
Timestep Consumption Time: 1.39334
PPO Batch Consumption Time: 0.05119
Total Iteration Time: 5.95630
Cumulative Model Updates: 943
Cumulative Timesteps: 15,808,124
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 15808124...
Checkpoint 15808124 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.56325
Policy Entropy: 4.91277
Value Function Loss: 0.22702
Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03624
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.09450
Collected Steps per Second: 11,090.47796
Overall Steps per Second: 8,426.30715
Timestep Collection Time: 4.51162
Timestep Consumption Time: 1.42645
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.93807
Cumulative Model Updates: 946
Cumulative Timesteps: 15,858,160
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.71806
Policy Entropy: 4.88733
Value Function Loss: 0.22794
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.09777
Collected Steps per Second: 11,001.40203
Overall Steps per Second: 8,382.85301
Timestep Collection Time: 4.54742
Timestep Consumption Time: 1.42048
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.96790
Cumulative Model Updates: 949
Cumulative Timesteps: 15,908,188
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 15908188...
Checkpoint 15908188 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.77647
Policy Entropy: 4.93885
Value Function Loss: 0.22870
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.09557
Collected Steps per Second: 10,950.86989
Overall Steps per Second: 8,530.81931
Timestep Collection Time: 4.56895
Timestep Consumption Time: 1.29614
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.86509
Cumulative Model Updates: 952
Cumulative Timesteps: 15,958,222
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.57807
Policy Entropy: 4.96051
Value Function Loss: 0.18254
Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.09824
Collected Steps per Second: 10,999.68132
Overall Steps per Second: 8,401.26924
Timestep Collection Time: 4.54686
Timestep Consumption Time: 1.40629
PPO Batch Consumption Time: 0.04985
Total Iteration Time: 5.95315
Cumulative Model Updates: 955
Cumulative Timesteps: 16,008,236
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 16008236...
Checkpoint 16008236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.50013
Policy Entropy: 4.90798
Value Function Loss: 0.16348
Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03197
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.08521
Collected Steps per Second: 11,010.76863
Overall Steps per Second: 8,447.99985
Timestep Collection Time: 4.54482
Timestep Consumption Time: 1.37871
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.92353
Cumulative Model Updates: 958
Cumulative Timesteps: 16,058,278
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.72417
Policy Entropy: 4.89693
Value Function Loss: 0.15714
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03109
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.08366
Collected Steps per Second: 11,159.24327
Overall Steps per Second: 8,310.23399
Timestep Collection Time: 4.48471
Timestep Consumption Time: 1.53750
PPO Batch Consumption Time: 0.08200
Total Iteration Time: 6.02221
Cumulative Model Updates: 961
Cumulative Timesteps: 16,108,324
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 16108324...
Checkpoint 16108324 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.75614
Policy Entropy: 4.93052
Value Function Loss: 0.17548
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.10118
Collected Steps per Second: 10,954.58833
Overall Steps per Second: 8,327.40074
Timestep Collection Time: 4.56813
Timestep Consumption Time: 1.44119
PPO Batch Consumption Time: 0.05309
Total Iteration Time: 6.00932
Cumulative Model Updates: 964
Cumulative Timesteps: 16,158,366
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.85730
Policy Entropy: 4.94598
Value Function Loss: 0.18281
Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.03722
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.10418
Collected Steps per Second: 10,923.74518
Overall Steps per Second: 8,489.14562
Timestep Collection Time: 4.57810
Timestep Consumption Time: 1.31295
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.89105
Cumulative Model Updates: 967
Cumulative Timesteps: 16,208,376
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 16208376...
Checkpoint 16208376 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.69554
Policy Entropy: 4.88482
Value Function Loss: 0.18019
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01047
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.10326
Collected Steps per Second: 11,011.92980
Overall Steps per Second: 8,408.80986
Timestep Collection Time: 4.54380
Timestep Consumption Time: 1.40663
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.95043
Cumulative Model Updates: 970
Cumulative Timesteps: 16,258,412
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.35008
Policy Entropy: 4.92481
Value Function Loss: 0.17425
Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.09654
Collected Steps per Second: 10,967.25832
Overall Steps per Second: 8,450.87736
Timestep Collection Time: 4.55975
Timestep Consumption Time: 1.35774
PPO Batch Consumption Time: 0.05022
Total Iteration Time: 5.91749
Cumulative Model Updates: 973
Cumulative Timesteps: 16,308,420
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 16308420...
Checkpoint 16308420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.78967
Policy Entropy: 4.99533
Value Function Loss: 0.20023
Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05891
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.08959
Collected Steps per Second: 10,969.09115
Overall Steps per Second: 8,534.03811
Timestep Collection Time: 4.55954
Timestep Consumption Time: 1.30099
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.86053
Cumulative Model Updates: 976
Cumulative Timesteps: 16,358,434
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.48392
Policy Entropy: 4.92946
Value Function Loss: 0.21133
Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04225
Policy Update Magnitude: 0.07040
Value Function Update Magnitude: 0.09015
Collected Steps per Second: 10,797.00275
Overall Steps per Second: 8,254.13043
Timestep Collection Time: 4.63184
Timestep Consumption Time: 1.42694
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.05878
Cumulative Model Updates: 979
Cumulative Timesteps: 16,408,444
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 16408444...
Checkpoint 16408444 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.77716
Policy Entropy: 4.93741
Value Function Loss: 0.21712
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.06980
Value Function Update Magnitude: 0.11376
Collected Steps per Second: 10,945.45317
Overall Steps per Second: 8,414.82826
Timestep Collection Time: 4.57121
Timestep Consumption Time: 1.37472
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.94593
Cumulative Model Updates: 982
Cumulative Timesteps: 16,458,478
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.97321
Policy Entropy: 4.97496
Value Function Loss: 0.21384
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.11178
Collected Steps per Second: 11,186.39231
Overall Steps per Second: 8,397.96431
Timestep Collection Time: 4.47436
Timestep Consumption Time: 1.48565
PPO Batch Consumption Time: 0.07800
Total Iteration Time: 5.96002
Cumulative Model Updates: 985
Cumulative Timesteps: 16,508,530
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 16508530...
Checkpoint 16508530 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.67749
Policy Entropy: 4.97117
Value Function Loss: 0.20493
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.12305
Collected Steps per Second: 10,926.89946
Overall Steps per Second: 8,355.79806
Timestep Collection Time: 4.57660
Timestep Consumption Time: 1.40823
PPO Batch Consumption Time: 0.05270
Total Iteration Time: 5.98483
Cumulative Model Updates: 988
Cumulative Timesteps: 16,558,538
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.68080
Policy Entropy: 4.90069
Value Function Loss: 0.20749
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.12641
Collected Steps per Second: 10,843.36093
Overall Steps per Second: 8,462.97701
Timestep Collection Time: 4.61130
Timestep Consumption Time: 1.29702
PPO Batch Consumption Time: 0.05119
Total Iteration Time: 5.90832
Cumulative Model Updates: 991
Cumulative Timesteps: 16,608,540
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 16608540...
Checkpoint 16608540 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.53599
Policy Entropy: 4.90182
Value Function Loss: 0.20964
Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.03362
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.11273
Collected Steps per Second: 10,965.65794
Overall Steps per Second: 8,324.97386
Timestep Collection Time: 4.56297
Timestep Consumption Time: 1.44738
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 6.01035
Cumulative Model Updates: 994
Cumulative Timesteps: 16,658,576
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.39279
Policy Entropy: 4.95772
Value Function Loss: 0.22649
Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03150
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.11670
Collected Steps per Second: 10,917.59944
Overall Steps per Second: 8,372.68208
Timestep Collection Time: 4.58269
Timestep Consumption Time: 1.39293
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.97562
Cumulative Model Updates: 997
Cumulative Timesteps: 16,708,608
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 16708608...
Checkpoint 16708608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.47712
Policy Entropy: 4.84066
Value Function Loss: 0.21058
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01614
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.13067
Collected Steps per Second: 11,215.26065
Overall Steps per Second: 8,484.43912
Timestep Collection Time: 4.45982
Timestep Consumption Time: 1.43545
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.89526
Cumulative Model Updates: 1,000
Cumulative Timesteps: 16,758,626
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.88866
Policy Entropy: 4.80249
Value Function Loss: 0.18284
Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.04284
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.13463
Collected Steps per Second: 10,962.78277
Overall Steps per Second: 8,340.46782
Timestep Collection Time: 4.56308
Timestep Consumption Time: 1.43467
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.99775
Cumulative Model Updates: 1,003
Cumulative Timesteps: 16,808,650
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 16808650...
Checkpoint 16808650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.05384
Policy Entropy: 4.90405
Value Function Loss: 0.17673
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03083
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.12987
Collected Steps per Second: 10,834.98268
Overall Steps per Second: 8,468.85610
Timestep Collection Time: 4.61819
Timestep Consumption Time: 1.29028
PPO Batch Consumption Time: 0.05015
Total Iteration Time: 5.90847
Cumulative Model Updates: 1,006
Cumulative Timesteps: 16,858,688
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.73613
Policy Entropy: 4.83892
Value Function Loss: 0.19417
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.11146
Collected Steps per Second: 10,921.44535
Overall Steps per Second: 8,194.22962
Timestep Collection Time: 4.57870
Timestep Consumption Time: 1.52389
PPO Batch Consumption Time: 0.08333
Total Iteration Time: 6.10259
Cumulative Model Updates: 1,009
Cumulative Timesteps: 16,908,694
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 16908694...
Checkpoint 16908694 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.82085
Policy Entropy: 4.80619
Value Function Loss: 0.20992
Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03603
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.11052
Collected Steps per Second: 10,808.17193
Overall Steps per Second: 8,292.16834
Timestep Collection Time: 4.62890
Timestep Consumption Time: 1.40450
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 6.03340
Cumulative Model Updates: 1,012
Cumulative Timesteps: 16,958,724
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.78315
Policy Entropy: 4.88665
Value Function Loss: 0.18553
Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04036
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.10119
Collected Steps per Second: 11,257.95183
Overall Steps per Second: 8,550.19901
Timestep Collection Time: 4.44131
Timestep Consumption Time: 1.40651
PPO Batch Consumption Time: 0.04982
Total Iteration Time: 5.84782
Cumulative Model Updates: 1,015
Cumulative Timesteps: 17,008,724
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 17008724...
Checkpoint 17008724 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.73053
Policy Entropy: 4.90024
Value Function Loss: 0.18809
Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.04997
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.09068
Collected Steps per Second: 10,956.40846
Overall Steps per Second: 8,365.67777
Timestep Collection Time: 4.56774
Timestep Consumption Time: 1.41456
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.98230
Cumulative Model Updates: 1,018
Cumulative Timesteps: 17,058,770
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.93178
Policy Entropy: 4.82837
Value Function Loss: 0.18712
Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02932
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.08541
Collected Steps per Second: 10,933.39542
Overall Steps per Second: 8,490.21670
Timestep Collection Time: 4.57625
Timestep Consumption Time: 1.31688
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.89314
Cumulative Model Updates: 1,021
Cumulative Timesteps: 17,108,804
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 17108804...
Checkpoint 17108804 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.71174
Policy Entropy: 4.90700
Value Function Loss: 0.19886
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02162
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.07615
Collected Steps per Second: 11,018.94726
Overall Steps per Second: 8,414.66155
Timestep Collection Time: 4.53891
Timestep Consumption Time: 1.40476
PPO Batch Consumption Time: 0.05106
Total Iteration Time: 5.94367
Cumulative Model Updates: 1,024
Cumulative Timesteps: 17,158,818
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.43998
Policy Entropy: 4.94723
Value Function Loss: 0.17948
Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.08149
Collected Steps per Second: 10,958.17731
Overall Steps per Second: 8,433.54347
Timestep Collection Time: 4.56572
Timestep Consumption Time: 1.36678
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.93250
Cumulative Model Updates: 1,027
Cumulative Timesteps: 17,208,850
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 17208850...
Checkpoint 17208850 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.27801
Policy Entropy: 4.85923
Value Function Loss: 0.15591
Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03019
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.08176
Collected Steps per Second: 10,828.60222
Overall Steps per Second: 8,416.44864
Timestep Collection Time: 4.61832
Timestep Consumption Time: 1.32361
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.94194
Cumulative Model Updates: 1,030
Cumulative Timesteps: 17,258,860
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.73870
Policy Entropy: 4.88330
Value Function Loss: 0.14521
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.08369
Collected Steps per Second: 10,939.09975
Overall Steps per Second: 8,261.16639
Timestep Collection Time: 4.57113
Timestep Consumption Time: 1.48177
PPO Batch Consumption Time: 0.07427
Total Iteration Time: 6.05290
Cumulative Model Updates: 1,033
Cumulative Timesteps: 17,308,864
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 17308864...
Checkpoint 17308864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.82445
Policy Entropy: 4.93724
Value Function Loss: 0.15683
Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.08596
Collected Steps per Second: 10,871.80434
Overall Steps per Second: 8,303.46384
Timestep Collection Time: 4.59905
Timestep Consumption Time: 1.42253
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 6.02158
Cumulative Model Updates: 1,036
Cumulative Timesteps: 17,358,864
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.39129
Policy Entropy: 4.86120
Value Function Loss: 0.16585
Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03618
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.09108
Collected Steps per Second: 11,221.00557
Overall Steps per Second: 8,506.15491
Timestep Collection Time: 4.45914
Timestep Consumption Time: 1.42319
PPO Batch Consumption Time: 0.05301
Total Iteration Time: 5.88233
Cumulative Model Updates: 1,039
Cumulative Timesteps: 17,408,900
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 17408900...
Checkpoint 17408900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.83808
Policy Entropy: 4.83942
Value Function Loss: 0.17920
Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04040
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.10454
Collected Steps per Second: 10,946.93600
Overall Steps per Second: 8,351.33666
Timestep Collection Time: 4.57114
Timestep Consumption Time: 1.42071
PPO Batch Consumption Time: 0.05215
Total Iteration Time: 5.99186
Cumulative Model Updates: 1,042
Cumulative Timesteps: 17,458,940
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.66126
Policy Entropy: 4.94303
Value Function Loss: 0.16265
Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03842
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.10418
Collected Steps per Second: 10,894.14103
Overall Steps per Second: 8,485.10654
Timestep Collection Time: 4.59421
Timestep Consumption Time: 1.30436
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.89857
Cumulative Model Updates: 1,045
Cumulative Timesteps: 17,508,990
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 17508990...
Checkpoint 17508990 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.53941
Policy Entropy: 4.90136
Value Function Loss: 0.17770
Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05015
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.09788
Collected Steps per Second: 10,979.99843
Overall Steps per Second: 8,365.81738
Timestep Collection Time: 4.55774
Timestep Consumption Time: 1.42422
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.98196
Cumulative Model Updates: 1,048
Cumulative Timesteps: 17,559,034
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.65553
Policy Entropy: 4.82736
Value Function Loss: 0.17814
Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.03959
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.08557
Collected Steps per Second: 10,890.96888
Overall Steps per Second: 8,377.51348
Timestep Collection Time: 4.59445
Timestep Consumption Time: 1.37845
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.97289
Cumulative Model Updates: 1,051
Cumulative Timesteps: 17,609,072
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 17609072...
Checkpoint 17609072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.90957
Policy Entropy: 4.84810
Value Function Loss: 0.19180
Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03748
Policy Update Magnitude: 0.06563
Value Function Update Magnitude: 0.10011
Collected Steps per Second: 11,123.66774
Overall Steps per Second: 8,462.67956
Timestep Collection Time: 4.49528
Timestep Consumption Time: 1.41349
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.90877
Cumulative Model Updates: 1,054
Cumulative Timesteps: 17,659,076
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.40715
Policy Entropy: 4.87651
Value Function Loss: 0.18307
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01785
Policy Update Magnitude: 0.06393
Value Function Update Magnitude: 0.10071
Collected Steps per Second: 10,954.08706
Overall Steps per Second: 8,229.38288
Timestep Collection Time: 4.56779
Timestep Consumption Time: 1.51237
PPO Batch Consumption Time: 0.07766
Total Iteration Time: 6.08016
Cumulative Model Updates: 1,057
Cumulative Timesteps: 17,709,112
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 17709112...
Checkpoint 17709112 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.52395
Policy Entropy: 4.80449
Value Function Loss: 0.17970
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02075
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.09567
Collected Steps per Second: 10,965.24681
Overall Steps per Second: 8,489.60954
Timestep Collection Time: 4.56260
Timestep Consumption Time: 1.33049
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.89309
Cumulative Model Updates: 1,060
Cumulative Timesteps: 17,759,142
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.67402
Policy Entropy: 4.77928
Value Function Loss: 0.17824
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.08943
Collected Steps per Second: 10,950.02894
Overall Steps per Second: 8,351.89705
Timestep Collection Time: 4.56857
Timestep Consumption Time: 1.42120
PPO Batch Consumption Time: 0.05130
Total Iteration Time: 5.98978
Cumulative Model Updates: 1,063
Cumulative Timesteps: 17,809,168
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 17809168...
Checkpoint 17809168 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.68131
Policy Entropy: 4.84657
Value Function Loss: 0.17789
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03021
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.09311
Collected Steps per Second: 10,864.36380
Overall Steps per Second: 8,342.83417
Timestep Collection Time: 4.60368
Timestep Consumption Time: 1.39141
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.99509
Cumulative Model Updates: 1,066
Cumulative Timesteps: 17,859,184
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.67806
Policy Entropy: 4.81760
Value Function Loss: 0.17516
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02199
Policy Update Magnitude: 0.06268
Value Function Update Magnitude: 0.09907
Collected Steps per Second: 10,929.34681
Overall Steps per Second: 8,490.11466
Timestep Collection Time: 4.57813
Timestep Consumption Time: 1.31531
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.89344
Cumulative Model Updates: 1,069
Cumulative Timesteps: 17,909,220
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 17909220...
Checkpoint 17909220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.95246
Policy Entropy: 4.76773
Value Function Loss: 0.16593
Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03350
Policy Update Magnitude: 0.06172
Value Function Update Magnitude: 0.10464
Collected Steps per Second: 10,932.25586
Overall Steps per Second: 8,328.12555
Timestep Collection Time: 4.57746
Timestep Consumption Time: 1.43133
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.00880
Cumulative Model Updates: 1,072
Cumulative Timesteps: 17,959,262
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.33266
Policy Entropy: 4.79440
Value Function Loss: 0.16732
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02386
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.10101
Collected Steps per Second: 10,964.42322
Overall Steps per Second: 8,418.78031
Timestep Collection Time: 4.56476
Timestep Consumption Time: 1.38028
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.94504
Cumulative Model Updates: 1,075
Cumulative Timesteps: 18,009,312
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 18009312...
Checkpoint 18009312 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.46310
Policy Entropy: 4.81395
Value Function Loss: 0.17355
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.10345
Collected Steps per Second: 11,075.83327
Overall Steps per Second: 8,470.40628
Timestep Collection Time: 4.51794
Timestep Consumption Time: 1.38968
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.90763
Cumulative Model Updates: 1,078
Cumulative Timesteps: 18,059,352
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.50806
Policy Entropy: 4.77088
Value Function Loss: 0.16585
Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02951
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.10267
Collected Steps per Second: 10,984.33716
Overall Steps per Second: 8,326.55509
Timestep Collection Time: 4.55212
Timestep Consumption Time: 1.45301
PPO Batch Consumption Time: 0.06733
Total Iteration Time: 6.00512
Cumulative Model Updates: 1,081
Cumulative Timesteps: 18,109,354
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 18109354...
Checkpoint 18109354 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.71739
Policy Entropy: 4.82677
Value Function Loss: 0.15393
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02308
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.09959
Collected Steps per Second: 10,934.47800
Overall Steps per Second: 8,499.59968
Timestep Collection Time: 4.57287
Timestep Consumption Time: 1.30999
PPO Batch Consumption Time: 0.05209
Total Iteration Time: 5.88287
Cumulative Model Updates: 1,084
Cumulative Timesteps: 18,159,356
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.53210
Policy Entropy: 4.86155
Value Function Loss: 0.15321
Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.03677
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.09344
Collected Steps per Second: 10,932.17666
Overall Steps per Second: 8,333.43287
Timestep Collection Time: 4.57567
Timestep Consumption Time: 1.42690
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.00257
Cumulative Model Updates: 1,087
Cumulative Timesteps: 18,209,378
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 18209378...
Checkpoint 18209378 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.63619
Policy Entropy: 4.83521
Value Function Loss: 0.16499
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01693
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.08905
Collected Steps per Second: 10,966.71289
Overall Steps per Second: 8,394.86422
Timestep Collection Time: 4.56290
Timestep Consumption Time: 1.39789
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.96079
Cumulative Model Updates: 1,090
Cumulative Timesteps: 18,259,418
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.73442
Policy Entropy: 4.83182
Value Function Loss: 0.15437
Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.00225
Policy Update Magnitude: 0.06477
Value Function Update Magnitude: 0.09331
Collected Steps per Second: 11,246.45352
Overall Steps per Second: 8,577.70921
Timestep Collection Time: 4.44602
Timestep Consumption Time: 1.38327
PPO Batch Consumption Time: 0.05109
Total Iteration Time: 5.82930
Cumulative Model Updates: 1,093
Cumulative Timesteps: 18,309,420
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 18309420...
Checkpoint 18309420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.57461
Policy Entropy: 4.86925
Value Function Loss: 0.15969
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01357
Policy Update Magnitude: 0.06454
Value Function Update Magnitude: 0.09191
Collected Steps per Second: 10,714.33338
Overall Steps per Second: 8,123.30730
Timestep Collection Time: 4.66777
Timestep Consumption Time: 1.48884
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.15661
Cumulative Model Updates: 1,096
Cumulative Timesteps: 18,359,432
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.02749
Policy Entropy: 4.84071
Value Function Loss: 0.16445
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03011
Policy Update Magnitude: 0.06662
Value Function Update Magnitude: 0.09309
Collected Steps per Second: 11,043.07708
Overall Steps per Second: 8,446.35745
Timestep Collection Time: 4.52899
Timestep Consumption Time: 1.39238
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.92137
Cumulative Model Updates: 1,099
Cumulative Timesteps: 18,409,446
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 18409446...
Checkpoint 18409446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.71414
Policy Entropy: 4.80916
Value Function Loss: 0.19015
Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03515
Policy Update Magnitude: 0.06558
Value Function Update Magnitude: 0.09552
Collected Steps per Second: 11,083.58769
Overall Steps per Second: 8,440.86878
Timestep Collection Time: 4.51514
Timestep Consumption Time: 1.41363
PPO Batch Consumption Time: 0.05072
Total Iteration Time: 5.92877
Cumulative Model Updates: 1,102
Cumulative Timesteps: 18,459,490
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.83666
Policy Entropy: 4.79586
Value Function Loss: 0.20325
Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03335
Policy Update Magnitude: 0.06702
Value Function Update Magnitude: 0.09946
Collected Steps per Second: 10,986.52892
Overall Steps per Second: 8,284.45425
Timestep Collection Time: 4.55576
Timestep Consumption Time: 1.48592
PPO Batch Consumption Time: 0.07300
Total Iteration Time: 6.04168
Cumulative Model Updates: 1,105
Cumulative Timesteps: 18,509,542
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 18509542...
Checkpoint 18509542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.58747
Policy Entropy: 4.81992
Value Function Loss: 0.19712
Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05282
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.09880
Collected Steps per Second: 11,012.82424
Overall Steps per Second: 8,527.27482
Timestep Collection Time: 4.54452
Timestep Consumption Time: 1.32465
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.86917
Cumulative Model Updates: 1,108
Cumulative Timesteps: 18,559,590
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.62689
Policy Entropy: 4.80494
Value Function Loss: 0.19120
Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03147
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.08453
Collected Steps per Second: 11,019.23058
Overall Steps per Second: 8,412.02622
Timestep Collection Time: 4.53934
Timestep Consumption Time: 1.40691
PPO Batch Consumption Time: 0.05237
Total Iteration Time: 5.94625
Cumulative Model Updates: 1,111
Cumulative Timesteps: 18,609,610
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 18609610...
Checkpoint 18609610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.34972
Policy Entropy: 4.85760
Value Function Loss: 0.16839
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02199
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.07435
Collected Steps per Second: 10,794.50823
Overall Steps per Second: 8,332.46176
Timestep Collection Time: 4.63273
Timestep Consumption Time: 1.36886
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 6.00159
Cumulative Model Updates: 1,114
Cumulative Timesteps: 18,659,618
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.79332
Policy Entropy: 4.86718
Value Function Loss: 0.17542
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02387
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.06270
Collected Steps per Second: 11,240.81390
Overall Steps per Second: 8,526.30526
Timestep Collection Time: 4.45128
Timestep Consumption Time: 1.41715
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.86843
Cumulative Model Updates: 1,117
Cumulative Timesteps: 18,709,654
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 18709654...
Checkpoint 18709654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.55213
Policy Entropy: 4.83534
Value Function Loss: 0.18203
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03008
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.05229
Collected Steps per Second: 10,932.64782
Overall Steps per Second: 8,362.79359
Timestep Collection Time: 4.57401
Timestep Consumption Time: 1.40557
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.97958
Cumulative Model Updates: 1,120
Cumulative Timesteps: 18,759,660
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.71379
Policy Entropy: 4.81022
Value Function Loss: 0.18182
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.05390
Collected Steps per Second: 10,829.16098
Overall Steps per Second: 8,323.41573
Timestep Collection Time: 4.62086
Timestep Consumption Time: 1.39110
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.01195
Cumulative Model Updates: 1,123
Cumulative Timesteps: 18,809,700
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 18809700...
Checkpoint 18809700 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.68845
Policy Entropy: 4.83221
Value Function Loss: 0.19799
Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04167
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.04897
Collected Steps per Second: 11,157.50278
Overall Steps per Second: 8,495.08652
Timestep Collection Time: 4.48165
Timestep Consumption Time: 1.40458
PPO Batch Consumption Time: 0.05014
Total Iteration Time: 5.88623
Cumulative Model Updates: 1,126
Cumulative Timesteps: 18,859,704
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.48155
Policy Entropy: 4.82879
Value Function Loss: 0.17634
Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04432
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.04878
Collected Steps per Second: 10,905.55694
Overall Steps per Second: 8,302.50528
Timestep Collection Time: 4.58922
Timestep Consumption Time: 1.43884
PPO Batch Consumption Time: 0.06668
Total Iteration Time: 6.02806
Cumulative Model Updates: 1,129
Cumulative Timesteps: 18,909,752
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 18909752...
Checkpoint 18909752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.56260
Policy Entropy: 4.82064
Value Function Loss: 0.18175
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01771
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.05609
Collected Steps per Second: 10,914.57845
Overall Steps per Second: 8,468.40400
Timestep Collection Time: 4.58341
Timestep Consumption Time: 1.32396
PPO Batch Consumption Time: 0.05236
Total Iteration Time: 5.90737
Cumulative Model Updates: 1,132
Cumulative Timesteps: 18,959,778
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.61797
Policy Entropy: 4.80817
Value Function Loss: 0.15726
Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04913
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.05498
Collected Steps per Second: 10,875.89864
Overall Steps per Second: 8,321.75205
Timestep Collection Time: 4.59879
Timestep Consumption Time: 1.41148
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 6.01027
Cumulative Model Updates: 1,135
Cumulative Timesteps: 19,009,794
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 19009794...
Checkpoint 19009794 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.49824
Policy Entropy: 4.82415
Value Function Loss: 0.16581
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03085
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.06170
Collected Steps per Second: 10,898.16525
Overall Steps per Second: 8,391.83633
Timestep Collection Time: 4.58866
Timestep Consumption Time: 1.37046
PPO Batch Consumption Time: 0.05020
Total Iteration Time: 5.95912
Cumulative Model Updates: 1,138
Cumulative Timesteps: 19,059,802
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.52680
Policy Entropy: 4.79101
Value Function Loss: 0.15025
Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04107
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.07722
Collected Steps per Second: 11,119.44400
Overall Steps per Second: 8,462.85917
Timestep Collection Time: 4.49771
Timestep Consumption Time: 1.41188
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.90959
Cumulative Model Updates: 1,141
Cumulative Timesteps: 19,109,814
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 19109814...
Checkpoint 19109814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.08256
Policy Entropy: 4.76386
Value Function Loss: 0.15707
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.07759
Collected Steps per Second: 10,856.22584
Overall Steps per Second: 8,333.45133
Timestep Collection Time: 4.60805
Timestep Consumption Time: 1.39499
PPO Batch Consumption Time: 0.04995
Total Iteration Time: 6.00303
Cumulative Model Updates: 1,144
Cumulative Timesteps: 19,159,840
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.56606
Policy Entropy: 4.79239
Value Function Loss: 0.16092
Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.03747
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.07337
Collected Steps per Second: 10,912.65945
Overall Steps per Second: 8,475.21097
Timestep Collection Time: 4.58348
Timestep Consumption Time: 1.31820
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.90168
Cumulative Model Updates: 1,147
Cumulative Timesteps: 19,209,858
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 19209858...
Checkpoint 19209858 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81148
Policy Entropy: 4.79650
Value Function Loss: 0.16468
Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03381
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.07308
Collected Steps per Second: 10,984.47368
Overall Steps per Second: 8,392.66601
Timestep Collection Time: 4.55297
Timestep Consumption Time: 1.40604
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.95901
Cumulative Model Updates: 1,150
Cumulative Timesteps: 19,259,870
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.66980
Policy Entropy: 4.83321
Value Function Loss: 0.17499
Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04383
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.07714
Collected Steps per Second: 11,004.37387
Overall Steps per Second: 8,338.90731
Timestep Collection Time: 4.54492
Timestep Consumption Time: 1.45275
PPO Batch Consumption Time: 0.08119
Total Iteration Time: 5.99767
Cumulative Model Updates: 1,153
Cumulative Timesteps: 19,309,884
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 19309884...
Checkpoint 19309884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81434
Policy Entropy: 4.77062
Value Function Loss: 0.17547
Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04452
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.06907
Collected Steps per Second: 11,003.99033
Overall Steps per Second: 8,541.00497
Timestep Collection Time: 4.54399
Timestep Consumption Time: 1.31036
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.85435
Cumulative Model Updates: 1,156
Cumulative Timesteps: 19,359,886
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.77005
Policy Entropy: 4.73649
Value Function Loss: 0.18695
Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.03932
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.07724
Collected Steps per Second: 10,989.66877
Overall Steps per Second: 8,366.11152
Timestep Collection Time: 4.55410
Timestep Consumption Time: 1.42813
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.98223
Cumulative Model Updates: 1,159
Cumulative Timesteps: 19,409,934
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 19409934...
Checkpoint 19409934 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.73239
Policy Entropy: 4.70604
Value Function Loss: 0.17843
Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04447
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.07411
Collected Steps per Second: 10,982.13632
Overall Steps per Second: 8,413.39650
Timestep Collection Time: 4.55758
Timestep Consumption Time: 1.39150
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.94908
Cumulative Model Updates: 1,162
Cumulative Timesteps: 19,459,986
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.62671
Policy Entropy: 4.73212
Value Function Loss: 0.17146
Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.04935
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.07111
Collected Steps per Second: 11,161.47303
Overall Steps per Second: 8,483.08815
Timestep Collection Time: 4.48346
Timestep Consumption Time: 1.41557
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.89903
Cumulative Model Updates: 1,165
Cumulative Timesteps: 19,510,028
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 19510028...
Checkpoint 19510028 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.83655
Policy Entropy: 4.73508
Value Function Loss: 0.15491
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02582
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.07976
Collected Steps per Second: 11,024.60559
Overall Steps per Second: 8,410.72064
Timestep Collection Time: 4.53767
Timestep Consumption Time: 1.41022
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.94789
Cumulative Model Updates: 1,168
Cumulative Timesteps: 19,560,054
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.90079
Policy Entropy: 4.71969
Value Function Loss: 0.15538
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02293
Policy Update Magnitude: 0.04159
Value Function Update Magnitude: 0.06531
Collected Steps per Second: 11,002.60399
Overall Steps per Second: 8,564.14665
Timestep Collection Time: 4.54783
Timestep Consumption Time: 1.29490
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.84273
Cumulative Model Updates: 1,171
Cumulative Timesteps: 19,610,092
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 19610092...
Checkpoint 19610092 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.49481
Policy Entropy: 4.76203
Value Function Loss: 0.14912
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01632
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.06199
Collected Steps per Second: 11,008.83686
Overall Steps per Second: 8,374.07037
Timestep Collection Time: 4.54562
Timestep Consumption Time: 1.43021
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.97583
Cumulative Model Updates: 1,174
Cumulative Timesteps: 19,660,134
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.11799
Policy Entropy: 4.76172
Value Function Loss: 0.16326
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03208
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.04892
Collected Steps per Second: 10,976.16309
Overall Steps per Second: 8,322.75636
Timestep Collection Time: 4.55533
Timestep Consumption Time: 1.45230
PPO Batch Consumption Time: 0.06900
Total Iteration Time: 6.00763
Cumulative Model Updates: 1,177
Cumulative Timesteps: 19,710,134
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 19710134...
Checkpoint 19710134 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.68143
Policy Entropy: 4.69997
Value Function Loss: 0.16875
Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03799
Policy Update Magnitude: 0.04640
Value Function Update Magnitude: 0.05207
Collected Steps per Second: 11,309.34418
Overall Steps per Second: 8,559.23942
Timestep Collection Time: 4.42289
Timestep Consumption Time: 1.42109
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.84398
Cumulative Model Updates: 1,180
Cumulative Timesteps: 19,760,154
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.64626
Policy Entropy: 4.67711
Value Function Loss: 0.17321
Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04104
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.04969
Collected Steps per Second: 10,998.34880
Overall Steps per Second: 8,377.43454
Timestep Collection Time: 4.54868
Timestep Consumption Time: 1.42307
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.97176
Cumulative Model Updates: 1,183
Cumulative Timesteps: 19,810,182
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 19810182...
Checkpoint 19810182 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.02061
Policy Entropy: 4.66882
Value Function Loss: 0.16488
Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05928
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.04646
Collected Steps per Second: 11,003.03340
Overall Steps per Second: 8,566.59537
Timestep Collection Time: 4.54602
Timestep Consumption Time: 1.29294
PPO Batch Consumption Time: 0.05198
Total Iteration Time: 5.83896
Cumulative Model Updates: 1,186
Cumulative Timesteps: 19,860,202
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.94363
Policy Entropy: 4.67745
Value Function Loss: 0.14828
Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05535
Policy Update Magnitude: 0.04271
Value Function Update Magnitude: 0.05073
Collected Steps per Second: 10,999.76846
Overall Steps per Second: 8,387.67114
Timestep Collection Time: 4.54864
Timestep Consumption Time: 1.41654
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.96518
Cumulative Model Updates: 1,189
Cumulative Timesteps: 19,910,236
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 19910236...
Checkpoint 19910236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.89052
Policy Entropy: 4.64931
Value Function Loss: 0.14742
Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04271
Policy Update Magnitude: 0.04065
Value Function Update Magnitude: 0.04270
Collected Steps per Second: 10,924.32272
Overall Steps per Second: 8,381.24686
Timestep Collection Time: 4.58170
Timestep Consumption Time: 1.39020
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.97190
Cumulative Model Updates: 1,192
Cumulative Timesteps: 19,960,288
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.61268
Policy Entropy: 4.71336
Value Function Loss: 0.13652
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.04338
Value Function Update Magnitude: 0.04285
Collected Steps per Second: 11,148.95090
Overall Steps per Second: 8,509.80021
Timestep Collection Time: 4.48473
Timestep Consumption Time: 1.39085
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.87558
Cumulative Model Updates: 1,195
Cumulative Timesteps: 20,010,288
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 20010288...
Checkpoint 20010288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.92040
Policy Entropy: 4.72376
Value Function Loss: 0.13826
Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04026
Policy Update Magnitude: 0.04379
Value Function Update Magnitude: 0.04469
Collected Steps per Second: 11,020.35031
Overall Steps per Second: 8,408.09364
Timestep Collection Time: 4.54178
Timestep Consumption Time: 1.41106
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.95284
Cumulative Model Updates: 1,198
Cumulative Timesteps: 20,060,340
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.53856
Policy Entropy: 4.71119
Value Function Loss: 0.14072
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03310
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.04017
Collected Steps per Second: 11,039.45232
Overall Steps per Second: 8,442.19475
Timestep Collection Time: 4.52975
Timestep Consumption Time: 1.39359
PPO Batch Consumption Time: 0.07634
Total Iteration Time: 5.92334
Cumulative Model Updates: 1,201
Cumulative Timesteps: 20,110,346
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 20110346...
Checkpoint 20110346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.12258
Policy Entropy: 4.70938
Value Function Loss: 0.14905
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.03859
Collected Steps per Second: 11,047.49831
Overall Steps per Second: 8,425.22280
Timestep Collection Time: 4.53170
Timestep Consumption Time: 1.41045
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.94216
Cumulative Model Updates: 1,204
Cumulative Timesteps: 20,160,410
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.71590
Policy Entropy: 4.71225
Value Function Loss: 0.14681
Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04583
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.04471
Collected Steps per Second: 10,868.81469
Overall Steps per Second: 8,395.73565
Timestep Collection Time: 4.60400
Timestep Consumption Time: 1.35617
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.96017
Cumulative Model Updates: 1,207
Cumulative Timesteps: 20,210,450
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 20210450...
Checkpoint 20210450 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.74363
Policy Entropy: 4.71972
Value Function Loss: 0.14941
Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03785
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.05078
Collected Steps per Second: 10,951.31082
Overall Steps per Second: 8,531.93408
Timestep Collection Time: 4.56639
Timestep Consumption Time: 1.29488
PPO Batch Consumption Time: 0.05042
Total Iteration Time: 5.86127
Cumulative Model Updates: 1,210
Cumulative Timesteps: 20,260,458
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.74611
Policy Entropy: 4.74156
Value Function Loss: 0.14378
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.05082
Collected Steps per Second: 10,899.45259
Overall Steps per Second: 8,365.96357
Timestep Collection Time: 4.58922
Timestep Consumption Time: 1.38977
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.97899
Cumulative Model Updates: 1,213
Cumulative Timesteps: 20,310,478
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 20310478...
Checkpoint 20310478 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.54581
Policy Entropy: 4.78601
Value Function Loss: 0.14316
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.04982
Collected Steps per Second: 10,804.77178
Overall Steps per Second: 8,287.64020
Timestep Collection Time: 4.63203
Timestep Consumption Time: 1.40684
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 6.03887
Cumulative Model Updates: 1,216
Cumulative Timesteps: 20,360,526
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.50535
Policy Entropy: 4.75591
Value Function Loss: 0.13807
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01881
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.04616
Collected Steps per Second: 11,103.77136
Overall Steps per Second: 8,469.76657
Timestep Collection Time: 4.50712
Timestep Consumption Time: 1.40166
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.90878
Cumulative Model Updates: 1,219
Cumulative Timesteps: 20,410,572
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 20410572...
Checkpoint 20410572 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.77842
Policy Entropy: 4.75639
Value Function Loss: 0.13168
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02172
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.05050
Collected Steps per Second: 10,985.28111
Overall Steps per Second: 8,367.74806
Timestep Collection Time: 4.55573
Timestep Consumption Time: 1.42509
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.98082
Cumulative Model Updates: 1,222
Cumulative Timesteps: 20,460,618
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.86961
Policy Entropy: 4.78402
Value Function Loss: 0.12435
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02865
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.05032
Collected Steps per Second: 10,935.03367
Overall Steps per Second: 8,318.51269
Timestep Collection Time: 4.57593
Timestep Consumption Time: 1.43932
PPO Batch Consumption Time: 0.08267
Total Iteration Time: 6.01526
Cumulative Model Updates: 1,225
Cumulative Timesteps: 20,510,656
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 20510656...
Checkpoint 20510656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.79658
Policy Entropy: 4.81263
Value Function Loss: 0.12356
Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03993
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.05925
Collected Steps per Second: 11,008.11872
Overall Steps per Second: 8,406.56460
Timestep Collection Time: 4.54410
Timestep Consumption Time: 1.40625
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.95035
Cumulative Model Updates: 1,228
Cumulative Timesteps: 20,560,678
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.04310
Policy Entropy: 4.83122
Value Function Loss: 0.13773
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.07346
Collected Steps per Second: 10,985.15884
Overall Steps per Second: 8,433.14280
Timestep Collection Time: 4.55433
Timestep Consumption Time: 1.37822
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.93255
Cumulative Model Updates: 1,231
Cumulative Timesteps: 20,610,708
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 20610708...
Checkpoint 20610708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.15192
Policy Entropy: 4.79288
Value Function Loss: 0.15550
Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.03579
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.07980
Collected Steps per Second: 11,013.90723
Overall Steps per Second: 8,547.88814
Timestep Collection Time: 4.53990
Timestep Consumption Time: 1.30974
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.84963
Cumulative Model Updates: 1,234
Cumulative Timesteps: 20,660,710
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.80849
Policy Entropy: 4.83087
Value Function Loss: 0.16961
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.08987
Collected Steps per Second: 10,980.15730
Overall Steps per Second: 8,400.82821
Timestep Collection Time: 4.55513
Timestep Consumption Time: 1.39857
PPO Batch Consumption Time: 0.05063
Total Iteration Time: 5.95370
Cumulative Model Updates: 1,237
Cumulative Timesteps: 20,710,726
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 20710726...
Checkpoint 20710726 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.04180
Policy Entropy: 4.83355
Value Function Loss: 0.17639
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.09105
Collected Steps per Second: 10,843.37083
Overall Steps per Second: 8,316.08671
Timestep Collection Time: 4.61259
Timestep Consumption Time: 1.40178
PPO Batch Consumption Time: 0.05053
Total Iteration Time: 6.01437
Cumulative Model Updates: 1,240
Cumulative Timesteps: 20,760,742
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.87658
Policy Entropy: 4.79787
Value Function Loss: 0.17665
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.08937
Collected Steps per Second: 11,197.85423
Overall Steps per Second: 8,502.92486
Timestep Collection Time: 4.46907
Timestep Consumption Time: 1.41643
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.88550
Cumulative Model Updates: 1,243
Cumulative Timesteps: 20,810,786
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 20810786...
Checkpoint 20810786 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.65040
Policy Entropy: 4.81595
Value Function Loss: 0.16328
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.06379
Value Function Update Magnitude: 0.08594
Collected Steps per Second: 11,049.13609
Overall Steps per Second: 8,428.92341
Timestep Collection Time: 4.52578
Timestep Consumption Time: 1.40688
PPO Batch Consumption Time: 0.05029
Total Iteration Time: 5.93267
Cumulative Model Updates: 1,246
Cumulative Timesteps: 20,860,792
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.33696
Policy Entropy: 4.81908
Value Function Loss: 0.15883
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.06351
Value Function Update Magnitude: 0.07468
Collected Steps per Second: 10,873.62607
Overall Steps per Second: 8,378.56143
Timestep Collection Time: 4.60012
Timestep Consumption Time: 1.36988
PPO Batch Consumption Time: 0.07267
Total Iteration Time: 5.97000
Cumulative Model Updates: 1,249
Cumulative Timesteps: 20,910,812
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 20910812...
Checkpoint 20910812 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.98213
Policy Entropy: 4.84550
Value Function Loss: 0.16060
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.07505
Collected Steps per Second: 10,928.76712
Overall Steps per Second: 8,319.71043
Timestep Collection Time: 4.57636
Timestep Consumption Time: 1.43514
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 6.01151
Cumulative Model Updates: 1,252
Cumulative Timesteps: 20,960,826
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.57266
Policy Entropy: 4.85990
Value Function Loss: 0.15963
Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04874
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.08380
Collected Steps per Second: 11,096.49133
Overall Steps per Second: 8,484.69289
Timestep Collection Time: 4.51170
Timestep Consumption Time: 1.38881
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.90051
Cumulative Model Updates: 1,255
Cumulative Timesteps: 21,010,890
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
Saving checkpoint 21010890...
Checkpoint 21010890 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.75918
Policy Entropy: 4.83529
Value Function Loss: 0.15034
Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04917
Policy Update Magnitude: 0.06997
Value Function Update Magnitude: 0.08037
Collected Steps per Second: 11,214.63810
Overall Steps per Second: 8,499.74854
Timestep Collection Time: 4.46345
Timestep Consumption Time: 1.42566
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.88912
Cumulative Model Updates: 1,258
Cumulative Timesteps: 21,060,946
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.94742
Policy Entropy: 4.88283
Value Function Loss: 0.15398
Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05182
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.07929
Collected Steps per Second: 11,080.29607
Overall Steps per Second: 8,413.14487
Timestep Collection Time: 4.51306
Timestep Consumption Time: 1.43074
PPO Batch Consumption Time: 0.05021
Total Iteration Time: 5.94379
Cumulative Model Updates: 1,261
Cumulative Timesteps: 21,110,952
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 21110952...
Checkpoint 21110952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.93600
Policy Entropy: 4.88047
Value Function Loss: 0.15044
Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03629
Policy Update Magnitude: 0.06432
Value Function Update Magnitude: 0.07903
Collected Steps per Second: 10,871.24104
Overall Steps per Second: 8,498.53638
Timestep Collection Time: 4.59929
Timestep Consumption Time: 1.28408
PPO Batch Consumption Time: 0.04986
Total Iteration Time: 5.88337
Cumulative Model Updates: 1,264
Cumulative Timesteps: 21,160,952
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.79487
Policy Entropy: 4.89849
Value Function Loss: 0.14425
Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.03780
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.07662
Collected Steps per Second: 10,984.15862
Overall Steps per Second: 8,371.14865
Timestep Collection Time: 4.55583
Timestep Consumption Time: 1.42208
PPO Batch Consumption Time: 0.05002
Total Iteration Time: 5.97791
Cumulative Model Updates: 1,267
Cumulative Timesteps: 21,210,994
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 21210994...
Checkpoint 21210994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.96642
Policy Entropy: 4.90577
Value Function Loss: 0.14191
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03042
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.06906
Collected Steps per Second: 10,904.46187
Overall Steps per Second: 8,398.62508
Timestep Collection Time: 4.58528
Timestep Consumption Time: 1.36808
PPO Batch Consumption Time: 0.05052
Total Iteration Time: 5.95336
Cumulative Model Updates: 1,270
Cumulative Timesteps: 21,260,994
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.79577
Policy Entropy: 4.92653
Value Function Loss: 0.14493
Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04389
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.06717
Collected Steps per Second: 11,046.84539
Overall Steps per Second: 8,501.45939
Timestep Collection Time: 4.52835
Timestep Consumption Time: 1.35581
PPO Batch Consumption Time: 0.06667
Total Iteration Time: 5.88417
Cumulative Model Updates: 1,273
Cumulative Timesteps: 21,311,018
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 21311018...
Checkpoint 21311018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.19235
Policy Entropy: 4.92179
Value Function Loss: 0.16081
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02274
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.06282
Collected Steps per Second: 10,986.49649
Overall Steps per Second: 8,364.85533
Timestep Collection Time: 4.55468
Timestep Consumption Time: 1.42749
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.98217
Cumulative Model Updates: 1,276
Cumulative Timesteps: 21,361,058
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.04862
Policy Entropy: 4.91534
Value Function Loss: 0.16057
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 0.06611
Value Function Update Magnitude: 0.06581
Collected Steps per Second: 10,957.62600
Overall Steps per Second: 8,413.01781
Timestep Collection Time: 4.56924
Timestep Consumption Time: 1.38202
PPO Batch Consumption Time: 0.05275
Total Iteration Time: 5.95125
Cumulative Model Updates: 1,279
Cumulative Timesteps: 21,411,126
Timesteps Collected: 50,068
--------END ITERATION REPORT--------
Saving checkpoint 21411126...
Checkpoint 21411126 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.27003
Policy Entropy: 4.92391
Value Function Loss: 0.16698
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.06867
Collected Steps per Second: 11,122.46889
Overall Steps per Second: 8,464.93445
Timestep Collection Time: 4.49990
Timestep Consumption Time: 1.41273
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.91263
Cumulative Model Updates: 1,282
Cumulative Timesteps: 21,461,176
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.89010
Policy Entropy: 4.94029
Value Function Loss: 0.15587
Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03806
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.06528
Collected Steps per Second: 10,936.77349
Overall Steps per Second: 8,362.92061
Timestep Collection Time: 4.57557
Timestep Consumption Time: 1.40822
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.98379
Cumulative Model Updates: 1,285
Cumulative Timesteps: 21,511,218
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 21511218...
Checkpoint 21511218 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.49284
Policy Entropy: 4.91502
Value Function Loss: 0.14740
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03621
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.08091
Collected Steps per Second: 10,937.26939
Overall Steps per Second: 8,522.25083
Timestep Collection Time: 4.57555
Timestep Consumption Time: 1.29661
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.87216
Cumulative Model Updates: 1,288
Cumulative Timesteps: 21,561,262
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.63038
Policy Entropy: 4.91714
Value Function Loss: 0.14179
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.06657
Value Function Update Magnitude: 0.09403
Collected Steps per Second: 11,079.34391
Overall Steps per Second: 8,457.34389
Timestep Collection Time: 4.51507
Timestep Consumption Time: 1.39979
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.91486
Cumulative Model Updates: 1,291
Cumulative Timesteps: 21,611,286
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 21611286...
Checkpoint 21611286 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.08878
Policy Entropy: 4.91073
Value Function Loss: 0.15458
Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04398
Policy Update Magnitude: 0.06543
Value Function Update Magnitude: 0.09013
Collected Steps per Second: 11,092.61160
Overall Steps per Second: 8,482.95154
Timestep Collection Time: 4.51129
Timestep Consumption Time: 1.38783
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.89913
Cumulative Model Updates: 1,294
Cumulative Timesteps: 21,661,328
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.54236
Policy Entropy: 4.88216
Value Function Loss: 0.16428
Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.08130
Collected Steps per Second: 10,989.01051
Overall Steps per Second: 8,379.40816
Timestep Collection Time: 4.55491
Timestep Consumption Time: 1.41854
PPO Batch Consumption Time: 0.07967
Total Iteration Time: 5.97345
Cumulative Model Updates: 1,297
Cumulative Timesteps: 21,711,382
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 21711382...
Checkpoint 21711382 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.83253
Policy Entropy: 4.91082
Value Function Loss: 0.16384
Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05178
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.09490
Collected Steps per Second: 10,954.41645
Overall Steps per Second: 8,330.90193
Timestep Collection Time: 4.56875
Timestep Consumption Time: 1.43876
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 6.00751
Cumulative Model Updates: 1,300
Cumulative Timesteps: 21,761,430
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.93207
Policy Entropy: 4.93602
Value Function Loss: 0.14923
Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04555
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.09618
Collected Steps per Second: 10,962.52538
Overall Steps per Second: 8,440.49595
Timestep Collection Time: 4.56300
Timestep Consumption Time: 1.36343
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.92643
Cumulative Model Updates: 1,303
Cumulative Timesteps: 21,811,452
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 21811452...
Checkpoint 21811452 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.91138
Policy Entropy: 4.94847
Value Function Loss: 0.14593
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02133
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.08178
Collected Steps per Second: 11,070.15870
Overall Steps per Second: 8,412.90397
Timestep Collection Time: 4.52080
Timestep Consumption Time: 1.42792
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.94872
Cumulative Model Updates: 1,306
Cumulative Timesteps: 21,861,498
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.02075
Policy Entropy: 4.95825
Value Function Loss: 0.14874
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03043
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.07214
Collected Steps per Second: 10,978.12852
Overall Steps per Second: 8,636.39763
Timestep Collection Time: 4.55779
Timestep Consumption Time: 1.23583
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.79362
Cumulative Model Updates: 1,309
Cumulative Timesteps: 21,911,534
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 21911534...
Checkpoint 21911534 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.56561
Policy Entropy: 4.96247
Value Function Loss: 0.15443
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.07206
Collected Steps per Second: 10,969.42081
Overall Steps per Second: 8,825.79598
Timestep Collection Time: 4.56250
Timestep Consumption Time: 1.10815
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.67065
Cumulative Model Updates: 1,312
Cumulative Timesteps: 21,961,582
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.12000
Policy Entropy: 4.96096
Value Function Loss: 0.14309
Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03811
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.07508
Collected Steps per Second: 10,907.83890
Overall Steps per Second: 8,618.22157
Timestep Collection Time: 4.58551
Timestep Consumption Time: 1.21824
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.80375
Cumulative Model Updates: 1,315
Cumulative Timesteps: 22,011,600
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 22011600...
Checkpoint 22011600 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81165
Policy Entropy: 4.92388
Value Function Loss: 0.15113
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01413
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.07916
Collected Steps per Second: 10,904.90557
Overall Steps per Second: 8,655.79721
Timestep Collection Time: 4.58839
Timestep Consumption Time: 1.19224
PPO Batch Consumption Time: 0.05064
Total Iteration Time: 5.78063
Cumulative Model Updates: 1,318
Cumulative Timesteps: 22,061,636
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.19281
Policy Entropy: 4.93752
Value Function Loss: 0.16781
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02017
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.07157
Collected Steps per Second: 11,160.19169
Overall Steps per Second: 8,690.54409
Timestep Collection Time: 4.48272
Timestep Consumption Time: 1.27388
PPO Batch Consumption Time: 0.06867
Total Iteration Time: 5.75660
Cumulative Model Updates: 1,321
Cumulative Timesteps: 22,111,664
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 22111664...
Checkpoint 22111664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.17661
Policy Entropy: 4.96323
Value Function Loss: 0.17538
Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03734
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.07934
Collected Steps per Second: 11,038.46181
Overall Steps per Second: 8,662.18457
Timestep Collection Time: 4.53215
Timestep Consumption Time: 1.24330
PPO Batch Consumption Time: 0.05338
Total Iteration Time: 5.77545
Cumulative Model Updates: 1,324
Cumulative Timesteps: 22,161,692
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.91304
Policy Entropy: 4.93133
Value Function Loss: 0.15516
Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03251
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.07636
Collected Steps per Second: 10,993.97015
Overall Steps per Second: 8,850.54157
Timestep Collection Time: 4.55013
Timestep Consumption Time: 1.10195
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.65208
Cumulative Model Updates: 1,327
Cumulative Timesteps: 22,211,716
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 22211716...
Checkpoint 22211716 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81453
Policy Entropy: 4.98450
Value Function Loss: 0.13760
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02974
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.07643
Collected Steps per Second: 10,923.38948
Overall Steps per Second: 8,622.06848
Timestep Collection Time: 4.57770
Timestep Consumption Time: 1.22184
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.79954
Cumulative Model Updates: 1,330
Cumulative Timesteps: 22,261,720
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.67768
Policy Entropy: 4.97921
Value Function Loss: 0.13385
Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.03467
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.08053
Collected Steps per Second: 11,029.04796
Overall Steps per Second: 8,771.97258
Timestep Collection Time: 4.53638
Timestep Consumption Time: 1.16724
PPO Batch Consumption Time: 0.05119
Total Iteration Time: 5.70362
Cumulative Model Updates: 1,333
Cumulative Timesteps: 22,311,752
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 22311752...
Checkpoint 22311752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.78925
Policy Entropy: 4.96644
Value Function Loss: 0.15021
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.07256
Collected Steps per Second: 10,981.07638
Overall Steps per Second: 8,792.85265
Timestep Collection Time: 4.55329
Timestep Consumption Time: 1.13315
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.68644
Cumulative Model Updates: 1,336
Cumulative Timesteps: 22,361,752
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.94609
Policy Entropy: 4.96264
Value Function Loss: 0.14304
Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03379
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.07151
Collected Steps per Second: 10,930.33856
Overall Steps per Second: 8,649.98180
Timestep Collection Time: 4.57461
Timestep Consumption Time: 1.20598
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78059
Cumulative Model Updates: 1,339
Cumulative Timesteps: 22,411,754
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 22411754...
Checkpoint 22411754 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.93204
Policy Entropy: 4.98983
Value Function Loss: 0.15002
Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03507
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.07497
Collected Steps per Second: 10,943.65766
Overall Steps per Second: 8,821.60196
Timestep Collection Time: 4.57233
Timestep Consumption Time: 1.09988
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.67221
Cumulative Model Updates: 1,342
Cumulative Timesteps: 22,461,792
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.06834
Policy Entropy: 5.00540
Value Function Loss: 0.14172
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.07385
Collected Steps per Second: 11,067.09474
Overall Steps per Second: 8,615.94431
Timestep Collection Time: 4.52097
Timestep Consumption Time: 1.28617
PPO Batch Consumption Time: 0.07375
Total Iteration Time: 5.80714
Cumulative Model Updates: 1,345
Cumulative Timesteps: 22,511,826
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 22511826...
Checkpoint 22511826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.15754
Policy Entropy: 4.98960
Value Function Loss: 0.14908
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02263
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.06437
Collected Steps per Second: 10,957.78568
Overall Steps per Second: 8,697.86119
Timestep Collection Time: 4.56315
Timestep Consumption Time: 1.18562
PPO Batch Consumption Time: 0.05226
Total Iteration Time: 5.74877
Cumulative Model Updates: 1,348
Cumulative Timesteps: 22,561,828
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42309
Policy Entropy: 5.01169
Value Function Loss: 0.14763
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.01929
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.06750
Collected Steps per Second: 10,934.45485
Overall Steps per Second: 8,801.14798
Timestep Collection Time: 4.57325
Timestep Consumption Time: 1.10851
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.68176
Cumulative Model Updates: 1,351
Cumulative Timesteps: 22,611,834
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 22611834...
Checkpoint 22611834 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.24268
Policy Entropy: 5.01379
Value Function Loss: 0.15292
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.07155
Collected Steps per Second: 10,943.25390
Overall Steps per Second: 8,643.80121
Timestep Collection Time: 4.56921
Timestep Consumption Time: 1.21552
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.78472
Cumulative Model Updates: 1,354
Cumulative Timesteps: 22,661,836
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.88867
Policy Entropy: 4.97611
Value Function Loss: 0.15809
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03169
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.06782
Collected Steps per Second: 10,980.37488
Overall Steps per Second: 8,706.89673
Timestep Collection Time: 4.55740
Timestep Consumption Time: 1.18999
PPO Batch Consumption Time: 0.04952
Total Iteration Time: 5.74740
Cumulative Model Updates: 1,357
Cumulative Timesteps: 22,711,878
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 22711878...
Checkpoint 22711878 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.17667
Policy Entropy: 4.98154
Value Function Loss: 0.17549
Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03905
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.06522
Collected Steps per Second: 11,149.55577
Overall Steps per Second: 8,792.93197
Timestep Collection Time: 4.48448
Timestep Consumption Time: 1.20190
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.68639
Cumulative Model Updates: 1,360
Cumulative Timesteps: 22,761,878
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.55209
Policy Entropy: 4.96871
Value Function Loss: 0.16999
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03225
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.07010
Collected Steps per Second: 11,023.81980
Overall Steps per Second: 8,673.73300
Timestep Collection Time: 4.53835
Timestep Consumption Time: 1.22964
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76799
Cumulative Model Updates: 1,363
Cumulative Timesteps: 22,811,908
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 22811908...
Checkpoint 22811908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.92701
Policy Entropy: 4.90984
Value Function Loss: 0.16847
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.00872
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.06410
Collected Steps per Second: 10,919.33620
Overall Steps per Second: 8,792.85756
Timestep Collection Time: 4.58343
Timestep Consumption Time: 1.10846
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69189
Cumulative Model Updates: 1,366
Cumulative Timesteps: 22,861,956
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.68635
Policy Entropy: 4.92206
Value Function Loss: 0.14413
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01300
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.07193
Collected Steps per Second: 10,979.72291
Overall Steps per Second: 8,501.86462
Timestep Collection Time: 4.55458
Timestep Consumption Time: 1.32743
PPO Batch Consumption Time: 0.08300
Total Iteration Time: 5.88200
Cumulative Model Updates: 1,369
Cumulative Timesteps: 22,911,964
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 22911964...
Checkpoint 22911964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.78576
Policy Entropy: 4.93262
Value Function Loss: 0.14145
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01265
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.07840
Collected Steps per Second: 11,072.72987
Overall Steps per Second: 8,779.95767
Timestep Collection Time: 4.51722
Timestep Consumption Time: 1.17961
PPO Batch Consumption Time: 0.05222
Total Iteration Time: 5.69684
Cumulative Model Updates: 1,372
Cumulative Timesteps: 22,961,982
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.76349
Policy Entropy: 4.92488
Value Function Loss: 0.13251
Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.00861
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.08382
Collected Steps per Second: 11,160.65827
Overall Steps per Second: 8,859.04790
Timestep Collection Time: 4.48325
Timestep Consumption Time: 1.16476
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.64801
Cumulative Model Updates: 1,375
Cumulative Timesteps: 23,012,018
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 23012018...
Checkpoint 23012018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.15439
Policy Entropy: 4.93570
Value Function Loss: 0.12333
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01451
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.08582
Collected Steps per Second: 10,801.97703
Overall Steps per Second: 8,594.65765
Timestep Collection Time: 4.62989
Timestep Consumption Time: 1.18907
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.81896
Cumulative Model Updates: 1,378
Cumulative Timesteps: 23,062,030
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.06011
Policy Entropy: 5.01673
Value Function Loss: 0.12886
Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03735
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.08825
Collected Steps per Second: 10,982.08598
Overall Steps per Second: 8,704.70551
Timestep Collection Time: 4.55524
Timestep Consumption Time: 1.19177
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.74701
Cumulative Model Updates: 1,381
Cumulative Timesteps: 23,112,056
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 23112056...
Checkpoint 23112056 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.19405
Policy Entropy: 4.96243
Value Function Loss: 0.14466
Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04137
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.08477
Collected Steps per Second: 11,130.90706
Overall Steps per Second: 8,774.02470
Timestep Collection Time: 4.49290
Timestep Consumption Time: 1.20688
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69978
Cumulative Model Updates: 1,384
Cumulative Timesteps: 23,162,066
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26849
Policy Entropy: 4.96189
Value Function Loss: 0.17972
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01903
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.07820
Collected Steps per Second: 10,906.98798
Overall Steps per Second: 8,629.87379
Timestep Collection Time: 4.58495
Timestep Consumption Time: 1.20980
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.79475
Cumulative Model Updates: 1,387
Cumulative Timesteps: 23,212,074
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 23212074...
Checkpoint 23212074 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.97444
Policy Entropy: 4.96066
Value Function Loss: 0.18701
Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01040
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.08957
Collected Steps per Second: 10,911.83714
Overall Steps per Second: 8,773.67903
Timestep Collection Time: 4.58255
Timestep Consumption Time: 1.11677
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.69932
Cumulative Model Updates: 1,390
Cumulative Timesteps: 23,262,078
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.05099
Policy Entropy: 4.96701
Value Function Loss: 0.17659
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02019
Policy Update Magnitude: 0.06530
Value Function Update Magnitude: 0.08836
Collected Steps per Second: 10,894.88181
Overall Steps per Second: 8,503.89698
Timestep Collection Time: 4.59206
Timestep Consumption Time: 1.29112
PPO Batch Consumption Time: 0.06747
Total Iteration Time: 5.88319
Cumulative Model Updates: 1,393
Cumulative Timesteps: 23,312,108
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 23312108...
Checkpoint 23312108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.86175
Policy Entropy: 4.96567
Value Function Loss: 0.16552
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03000
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.08557
Collected Steps per Second: 10,936.51653
Overall Steps per Second: 8,713.12975
Timestep Collection Time: 4.57641
Timestep Consumption Time: 1.16779
PPO Batch Consumption Time: 0.05074
Total Iteration Time: 5.74420
Cumulative Model Updates: 1,396
Cumulative Timesteps: 23,362,158
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99399
Policy Entropy: 4.96862
Value Function Loss: 0.15420
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.06513
Value Function Update Magnitude: 0.08267
Collected Steps per Second: 11,210.05923
Overall Steps per Second: 8,821.60676
Timestep Collection Time: 4.46135
Timestep Consumption Time: 1.20791
PPO Batch Consumption Time: 0.05130
Total Iteration Time: 5.66926
Cumulative Model Updates: 1,399
Cumulative Timesteps: 23,412,170
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 23412170...
Checkpoint 23412170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.78713
Policy Entropy: 5.01229
Value Function Loss: 0.14091
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.06756
Value Function Update Magnitude: 0.07607
Collected Steps per Second: 10,959.78414
Overall Steps per Second: 8,650.93857
Timestep Collection Time: 4.56524
Timestep Consumption Time: 1.21841
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78365
Cumulative Model Updates: 1,402
Cumulative Timesteps: 23,462,204
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.94905
Policy Entropy: 5.00990
Value Function Loss: 0.12550
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.06638
Value Function Update Magnitude: 0.07924
Collected Steps per Second: 10,843.57370
Overall Steps per Second: 8,613.61826
Timestep Collection Time: 4.61564
Timestep Consumption Time: 1.19493
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.81057
Cumulative Model Updates: 1,405
Cumulative Timesteps: 23,512,254
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 23512254...
Checkpoint 23512254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.05231
Policy Entropy: 4.96530
Value Function Loss: 0.12759
Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03686
Policy Update Magnitude: 0.06289
Value Function Update Magnitude: 0.07138
Collected Steps per Second: 11,186.61879
Overall Steps per Second: 8,790.84783
Timestep Collection Time: 4.47088
Timestep Consumption Time: 1.21845
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.68933
Cumulative Model Updates: 1,408
Cumulative Timesteps: 23,562,268
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81795
Policy Entropy: 5.02345
Value Function Loss: 0.12934
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.07221
Collected Steps per Second: 10,973.84819
Overall Steps per Second: 8,667.31499
Timestep Collection Time: 4.55866
Timestep Consumption Time: 1.21314
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.77180
Cumulative Model Updates: 1,411
Cumulative Timesteps: 23,612,294
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 23612294...
Checkpoint 23612294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.05480
Policy Entropy: 4.98658
Value Function Loss: 0.14059
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.07732
Collected Steps per Second: 10,876.56988
Overall Steps per Second: 8,772.72131
Timestep Collection Time: 4.59741
Timestep Consumption Time: 1.10254
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.69994
Cumulative Model Updates: 1,414
Cumulative Timesteps: 23,662,298
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.95750
Policy Entropy: 4.96426
Value Function Loss: 0.13854
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01697
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.07898
Collected Steps per Second: 11,005.64887
Overall Steps per Second: 8,570.76423
Timestep Collection Time: 4.54458
Timestep Consumption Time: 1.29108
PPO Batch Consumption Time: 0.07267
Total Iteration Time: 5.83565
Cumulative Model Updates: 1,417
Cumulative Timesteps: 23,712,314
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 23712314...
Checkpoint 23712314 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.31750
Policy Entropy: 4.96865
Value Function Loss: 0.14748
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01864
Policy Update Magnitude: 0.06545
Value Function Update Magnitude: 0.08965
Collected Steps per Second: 10,953.25714
Overall Steps per Second: 8,682.83335
Timestep Collection Time: 4.56503
Timestep Consumption Time: 1.19368
PPO Batch Consumption Time: 0.05319
Total Iteration Time: 5.75872
Cumulative Model Updates: 1,420
Cumulative Timesteps: 23,762,316
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.56998
Policy Entropy: 4.97238
Value Function Loss: 0.13313
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03210
Policy Update Magnitude: 0.06686
Value Function Update Magnitude: 0.09193
Collected Steps per Second: 11,148.39448
Overall Steps per Second: 8,774.40930
Timestep Collection Time: 4.48800
Timestep Consumption Time: 1.21426
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.70226
Cumulative Model Updates: 1,423
Cumulative Timesteps: 23,812,350
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 23812350...
Checkpoint 23812350 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.70860
Policy Entropy: 4.98182
Value Function Loss: 0.13205
Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03435
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.08655
Collected Steps per Second: 10,850.28181
Overall Steps per Second: 8,575.68813
Timestep Collection Time: 4.61131
Timestep Consumption Time: 1.22309
PPO Batch Consumption Time: 0.05054
Total Iteration Time: 5.83440
Cumulative Model Updates: 1,426
Cumulative Timesteps: 23,862,384
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.35426
Policy Entropy: 4.91861
Value Function Loss: 0.13671
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.06932
Value Function Update Magnitude: 0.07795
Collected Steps per Second: 10,956.51406
Overall Steps per Second: 8,707.73562
Timestep Collection Time: 4.56642
Timestep Consumption Time: 1.17928
PPO Batch Consumption Time: 0.05047
Total Iteration Time: 5.74570
Cumulative Model Updates: 1,429
Cumulative Timesteps: 23,912,416
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 23912416...
Checkpoint 23912416 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.07134
Policy Entropy: 4.95107
Value Function Loss: 0.15802
Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04361
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.07160
Collected Steps per Second: 11,182.24405
Overall Steps per Second: 8,779.56932
Timestep Collection Time: 4.47424
Timestep Consumption Time: 1.22445
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69868
Cumulative Model Updates: 1,432
Cumulative Timesteps: 23,962,448
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41657
Policy Entropy: 4.94269
Value Function Loss: 0.16131
Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 0.06926
Value Function Update Magnitude: 0.07215
Collected Steps per Second: 10,910.54256
Overall Steps per Second: 8,666.44805
Timestep Collection Time: 4.58639
Timestep Consumption Time: 1.18760
PPO Batch Consumption Time: 0.05103
Total Iteration Time: 5.77399
Cumulative Model Updates: 1,435
Cumulative Timesteps: 24,012,488
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 24012488...
Checkpoint 24012488 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.92819
Policy Entropy: 4.92566
Value Function Loss: 0.13549
Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06089
Policy Update Magnitude: 0.06621
Value Function Update Magnitude: 0.07793
Collected Steps per Second: 10,933.50578
Overall Steps per Second: 8,760.11923
Timestep Collection Time: 4.57383
Timestep Consumption Time: 1.13477
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.70860
Cumulative Model Updates: 1,438
Cumulative Timesteps: 24,062,496
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.08880
Policy Entropy: 4.98324
Value Function Loss: 0.12806
Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06403
Policy Update Magnitude: 0.07345
Value Function Update Magnitude: 0.07904
Collected Steps per Second: 11,011.59814
Overall Steps per Second: 8,566.13246
Timestep Collection Time: 4.54357
Timestep Consumption Time: 1.29710
PPO Batch Consumption Time: 0.07652
Total Iteration Time: 5.84068
Cumulative Model Updates: 1,441
Cumulative Timesteps: 24,112,528
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 24112528...
Checkpoint 24112528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.24522
Policy Entropy: 4.95165
Value Function Loss: 0.12929
Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05286
Policy Update Magnitude: 0.07293
Value Function Update Magnitude: 0.08161
Collected Steps per Second: 10,981.10182
Overall Steps per Second: 8,674.09738
Timestep Collection Time: 4.55473
Timestep Consumption Time: 1.21140
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.76613
Cumulative Model Updates: 1,444
Cumulative Timesteps: 24,162,544
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.04461
Policy Entropy: 4.91402
Value Function Loss: 0.13180
Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05990
Policy Update Magnitude: 0.07563
Value Function Update Magnitude: 0.08371
Collected Steps per Second: 11,152.58224
Overall Steps per Second: 8,774.46852
Timestep Collection Time: 4.48416
Timestep Consumption Time: 1.21533
PPO Batch Consumption Time: 0.05242
Total Iteration Time: 5.69949
Cumulative Model Updates: 1,447
Cumulative Timesteps: 24,212,554
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 24212554...
Checkpoint 24212554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.01394
Policy Entropy: 4.95268
Value Function Loss: 0.12205
Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05604
Policy Update Magnitude: 0.08035
Value Function Update Magnitude: 0.08277
Collected Steps per Second: 11,087.16122
Overall Steps per Second: 8,736.16407
Timestep Collection Time: 4.51387
Timestep Consumption Time: 1.21473
PPO Batch Consumption Time: 0.05007
Total Iteration Time: 5.72860
Cumulative Model Updates: 1,450
Cumulative Timesteps: 24,262,600
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99520
Policy Entropy: 4.97844
Value Function Loss: 0.11543
Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05383
Policy Update Magnitude: 0.06714
Value Function Update Magnitude: 0.07822
Collected Steps per Second: 10,928.69329
Overall Steps per Second: 8,785.82014
Timestep Collection Time: 4.57584
Timestep Consumption Time: 1.11605
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69190
Cumulative Model Updates: 1,453
Cumulative Timesteps: 24,312,608
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 24312608...
Checkpoint 24312608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.16446
Policy Entropy: 4.93440
Value Function Loss: 0.11751
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03311
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.07906
Collected Steps per Second: 11,041.34145
Overall Steps per Second: 8,694.95546
Timestep Collection Time: 4.53296
Timestep Consumption Time: 1.22325
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.75621
Cumulative Model Updates: 1,456
Cumulative Timesteps: 24,362,658
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.83848
Policy Entropy: 4.92815
Value Function Loss: 0.12099
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02227
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.09130
Collected Steps per Second: 10,991.32878
Overall Steps per Second: 8,730.71737
Timestep Collection Time: 4.55104
Timestep Consumption Time: 1.17838
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.72943
Cumulative Model Updates: 1,459
Cumulative Timesteps: 24,412,680
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 24412680...
Checkpoint 24412680 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.98768
Policy Entropy: 4.93605
Value Function Loss: 0.10537
Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.00877
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.08919
Collected Steps per Second: 10,985.33619
Overall Steps per Second: 8,820.52514
Timestep Collection Time: 4.55553
Timestep Consumption Time: 1.11806
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.67359
Cumulative Model Updates: 1,462
Cumulative Timesteps: 24,462,724
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.05018
Policy Entropy: 4.92213
Value Function Loss: 0.10900
Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03982
Policy Update Magnitude: 0.06608
Value Function Update Magnitude: 0.09667
Collected Steps per Second: 10,794.12066
Overall Steps per Second: 8,336.11812
Timestep Collection Time: 4.63475
Timestep Consumption Time: 1.36661
PPO Batch Consumption Time: 0.08019
Total Iteration Time: 6.00135
Cumulative Model Updates: 1,465
Cumulative Timesteps: 24,512,752
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 24512752...
Checkpoint 24512752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.90198
Policy Entropy: 4.93207
Value Function Loss: 0.11593
Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.03955
Policy Update Magnitude: 0.06164
Value Function Update Magnitude: 0.09492
Collected Steps per Second: 10,722.61934
Overall Steps per Second: 8,540.28320
Timestep Collection Time: 4.66882
Timestep Consumption Time: 1.19304
PPO Batch Consumption Time: 0.05288
Total Iteration Time: 5.86187
Cumulative Model Updates: 1,468
Cumulative Timesteps: 24,562,814
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.79001
Policy Entropy: 4.95528
Value Function Loss: 0.12235
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.09300
Collected Steps per Second: 11,038.56419
Overall Steps per Second: 8,704.76562
Timestep Collection Time: 4.53066
Timestep Consumption Time: 1.21470
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.74536
Cumulative Model Updates: 1,471
Cumulative Timesteps: 24,612,826
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 24612826...
Checkpoint 24612826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.49511
Policy Entropy: 4.95694
Value Function Loss: 0.12447
Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01060
Policy Update Magnitude: 0.06229
Value Function Update Magnitude: 0.08728
Collected Steps per Second: 10,910.28526
Overall Steps per Second: 8,631.20767
Timestep Collection Time: 4.58705
Timestep Consumption Time: 1.21121
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.79826
Cumulative Model Updates: 1,474
Cumulative Timesteps: 24,662,872
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.09225
Policy Entropy: 4.92795
Value Function Loss: 0.11801
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.08435
Collected Steps per Second: 10,924.20051
Overall Steps per Second: 8,795.65133
Timestep Collection Time: 4.57864
Timestep Consumption Time: 1.10803
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.68667
Cumulative Model Updates: 1,477
Cumulative Timesteps: 24,712,890
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 24712890...
Checkpoint 24712890 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50220
Policy Entropy: 4.95196
Value Function Loss: 0.12199
Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01337
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.08239
Collected Steps per Second: 10,941.75918
Overall Steps per Second: 8,615.65277
Timestep Collection Time: 4.56965
Timestep Consumption Time: 1.23374
PPO Batch Consumption Time: 0.05066
Total Iteration Time: 5.80339
Cumulative Model Updates: 1,480
Cumulative Timesteps: 24,762,890
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.25034
Policy Entropy: 4.98030
Value Function Loss: 0.12598
Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05612
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.08386
Collected Steps per Second: 10,865.16168
Overall Steps per Second: 8,644.66905
Timestep Collection Time: 4.60573
Timestep Consumption Time: 1.18304
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.78877
Cumulative Model Updates: 1,483
Cumulative Timesteps: 24,812,932
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 24812932...
Checkpoint 24812932 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.11859
Policy Entropy: 4.98120
Value Function Loss: 0.13106
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.06761
Value Function Update Magnitude: 0.08221
Collected Steps per Second: 11,040.32799
Overall Steps per Second: 8,688.38072
Timestep Collection Time: 4.53302
Timestep Consumption Time: 1.22709
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.76011
Cumulative Model Updates: 1,486
Cumulative Timesteps: 24,862,978
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.02583
Policy Entropy: 4.98021
Value Function Loss: 0.13494
Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03859
Policy Update Magnitude: 0.07395
Value Function Update Magnitude: 0.08318
Collected Steps per Second: 10,974.73864
Overall Steps per Second: 8,566.66832
Timestep Collection Time: 4.55665
Timestep Consumption Time: 1.28086
PPO Batch Consumption Time: 0.06945
Total Iteration Time: 5.83751
Cumulative Model Updates: 1,489
Cumulative Timesteps: 24,912,986
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 24912986...
Checkpoint 24912986 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.29071
Policy Entropy: 4.97513
Value Function Loss: 0.13198
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02846
Policy Update Magnitude: 0.07378
Value Function Update Magnitude: 0.08625
Collected Steps per Second: 10,992.95624
Overall Steps per Second: 8,820.05290
Timestep Collection Time: 4.55019
Timestep Consumption Time: 1.12098
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.67117
Cumulative Model Updates: 1,492
Cumulative Timesteps: 24,963,006
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99725
Policy Entropy: 4.95466
Value Function Loss: 0.12776
Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06522
Policy Update Magnitude: 0.06222
Value Function Update Magnitude: 0.08861
Collected Steps per Second: 11,030.19222
Overall Steps per Second: 8,703.04821
Timestep Collection Time: 4.53591
Timestep Consumption Time: 1.21288
PPO Batch Consumption Time: 0.05069
Total Iteration Time: 5.74879
Cumulative Model Updates: 1,495
Cumulative Timesteps: 25,013,038
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 25013038...
Checkpoint 25013038 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81259
Policy Entropy: 5.00040
Value Function Loss: 0.13455
Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04452
Policy Update Magnitude: 0.06352
Value Function Update Magnitude: 0.08387
Collected Steps per Second: 10,952.00383
Overall Steps per Second: 8,705.90184
Timestep Collection Time: 4.56793
Timestep Consumption Time: 1.17852
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.74645
Cumulative Model Updates: 1,498
Cumulative Timesteps: 25,063,066
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.33451
Policy Entropy: 4.96114
Value Function Loss: 0.13871
Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04487
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.08246
Collected Steps per Second: 10,870.58688
Overall Steps per Second: 8,767.53274
Timestep Collection Time: 4.60141
Timestep Consumption Time: 1.10373
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.70514
Cumulative Model Updates: 1,501
Cumulative Timesteps: 25,113,086
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 25113086...
Checkpoint 25113086 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.72225
Policy Entropy: 4.94131
Value Function Loss: 0.13688
Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04303
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.09406
Collected Steps per Second: 10,918.30007
Overall Steps per Second: 8,582.52096
Timestep Collection Time: 4.58350
Timestep Consumption Time: 1.24742
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.83092
Cumulative Model Updates: 1,504
Cumulative Timesteps: 25,163,130
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.67673
Policy Entropy: 4.94326
Value Function Loss: 0.14120
Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04534
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.09719
Collected Steps per Second: 11,027.77145
Overall Steps per Second: 8,759.44796
Timestep Collection Time: 4.53419
Timestep Consumption Time: 1.17416
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.70835
Cumulative Model Updates: 1,507
Cumulative Timesteps: 25,213,132
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 25213132...
Checkpoint 25213132 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.74517
Policy Entropy: 4.92592
Value Function Loss: 0.12701
Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.09559
Collected Steps per Second: 11,186.33570
Overall Steps per Second: 8,818.05037
Timestep Collection Time: 4.47171
Timestep Consumption Time: 1.20098
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.67268
Cumulative Model Updates: 1,510
Cumulative Timesteps: 25,263,154
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.87912
Policy Entropy: 4.96619
Value Function Loss: 0.12413
Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05731
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.08115
Collected Steps per Second: 10,907.05857
Overall Steps per Second: 8,504.06179
Timestep Collection Time: 4.58675
Timestep Consumption Time: 1.29608
PPO Batch Consumption Time: 0.08267
Total Iteration Time: 5.88284
Cumulative Model Updates: 1,513
Cumulative Timesteps: 25,313,182
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 25313182...
Checkpoint 25313182 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63588
Policy Entropy: 4.92225
Value Function Loss: 0.11459
Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06148
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.07515
Collected Steps per Second: 10,912.58706
Overall Steps per Second: 8,748.05816
Timestep Collection Time: 4.58571
Timestep Consumption Time: 1.13464
PPO Batch Consumption Time: 0.05273
Total Iteration Time: 5.72036
Cumulative Model Updates: 1,516
Cumulative Timesteps: 25,363,224
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.75626
Policy Entropy: 4.91011
Value Function Loss: 0.11695
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03315
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.07831
Collected Steps per Second: 11,010.31371
Overall Steps per Second: 8,619.36627
Timestep Collection Time: 4.54319
Timestep Consumption Time: 1.26025
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.80344
Cumulative Model Updates: 1,519
Cumulative Timesteps: 25,413,246
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 25413246...
Checkpoint 25413246 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48452
Policy Entropy: 4.94683
Value Function Loss: 0.11203
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03582
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.07988
Collected Steps per Second: 10,861.65536
Overall Steps per Second: 8,616.68055
Timestep Collection Time: 4.60611
Timestep Consumption Time: 1.20007
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.80618
Cumulative Model Updates: 1,522
Cumulative Timesteps: 25,463,276
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.17542
Policy Entropy: 4.89442
Value Function Loss: 0.11625
Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04322
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.07130
Collected Steps per Second: 10,849.05892
Overall Steps per Second: 8,711.32646
Timestep Collection Time: 4.61035
Timestep Consumption Time: 1.13137
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.74172
Cumulative Model Updates: 1,525
Cumulative Timesteps: 25,513,294
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 25513294...
Checkpoint 25513294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.20972
Policy Entropy: 4.92691
Value Function Loss: 0.12519
Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05819
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.07448
Collected Steps per Second: 10,788.50349
Overall Steps per Second: 8,543.71532
Timestep Collection Time: 4.63864
Timestep Consumption Time: 1.21876
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.85740
Cumulative Model Updates: 1,528
Cumulative Timesteps: 25,563,338
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.97060
Policy Entropy: 4.91482
Value Function Loss: 0.12682
Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05114
Policy Update Magnitude: 0.06307
Value Function Update Magnitude: 0.07729
Collected Steps per Second: 10,936.48765
Overall Steps per Second: 8,699.62579
Timestep Collection Time: 4.57350
Timestep Consumption Time: 1.17595
PPO Batch Consumption Time: 0.04928
Total Iteration Time: 5.74944
Cumulative Model Updates: 1,531
Cumulative Timesteps: 25,613,356
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 25613356...
Checkpoint 25613356 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.16582
Policy Entropy: 4.89314
Value Function Loss: 0.13931
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03221
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.07643
Collected Steps per Second: 11,130.54568
Overall Steps per Second: 8,741.63459
Timestep Collection Time: 4.49520
Timestep Consumption Time: 1.22845
PPO Batch Consumption Time: 0.05022
Total Iteration Time: 5.72364
Cumulative Model Updates: 1,534
Cumulative Timesteps: 25,663,390
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.29986
Policy Entropy: 4.89316
Value Function Loss: 0.12929
Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.03633
Policy Update Magnitude: 0.06635
Value Function Update Magnitude: 0.08270
Collected Steps per Second: 10,927.96339
Overall Steps per Second: 8,524.44062
Timestep Collection Time: 4.57908
Timestep Consumption Time: 1.29110
PPO Batch Consumption Time: 0.07482
Total Iteration Time: 5.87018
Cumulative Model Updates: 1,537
Cumulative Timesteps: 25,713,430
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 25713430...
Checkpoint 25713430 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.00461
Policy Entropy: 4.88353
Value Function Loss: 0.13601
Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06846
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.07978
Collected Steps per Second: 11,010.41209
Overall Steps per Second: 8,837.08221
Timestep Collection Time: 4.54588
Timestep Consumption Time: 1.11798
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.66386
Cumulative Model Updates: 1,540
Cumulative Timesteps: 25,763,482
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.94898
Policy Entropy: 4.94926
Value Function Loss: 0.13924
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02847
Policy Update Magnitude: 0.06635
Value Function Update Magnitude: 0.07143
Collected Steps per Second: 11,022.98550
Overall Steps per Second: 8,702.69127
Timestep Collection Time: 4.53779
Timestep Consumption Time: 1.20986
PPO Batch Consumption Time: 0.05108
Total Iteration Time: 5.74765
Cumulative Model Updates: 1,543
Cumulative Timesteps: 25,813,502
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 25813502...
Checkpoint 25813502 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.10979
Policy Entropy: 4.88686
Value Function Loss: 0.15194
Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05365
Policy Update Magnitude: 0.06644
Value Function Update Magnitude: 0.07284
Collected Steps per Second: 10,952.95384
Overall Steps per Second: 8,695.04089
Timestep Collection Time: 4.56680
Timestep Consumption Time: 1.18590
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.75270
Cumulative Model Updates: 1,546
Cumulative Timesteps: 25,863,522
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.85368
Policy Entropy: 4.83580
Value Function Loss: 0.15071
Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05232
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.07352
Collected Steps per Second: 11,176.25779
Overall Steps per Second: 8,800.76134
Timestep Collection Time: 4.47627
Timestep Consumption Time: 1.20823
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.68451
Cumulative Model Updates: 1,549
Cumulative Timesteps: 25,913,550
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 25913550...
Checkpoint 25913550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.21050
Policy Entropy: 4.89534
Value Function Loss: 0.13026
Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05513
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.07818
Collected Steps per Second: 10,919.52279
Overall Steps per Second: 8,630.57578
Timestep Collection Time: 4.57932
Timestep Consumption Time: 1.21450
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.79382
Cumulative Model Updates: 1,552
Cumulative Timesteps: 25,963,554
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.08193
Policy Entropy: 4.87514
Value Function Loss: 0.11099
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.08095
Collected Steps per Second: 10,967.80197
Overall Steps per Second: 8,710.57585
Timestep Collection Time: 4.56099
Timestep Consumption Time: 1.18192
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.74290
Cumulative Model Updates: 1,555
Cumulative Timesteps: 26,013,578
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 26013578...
Checkpoint 26013578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26101
Policy Entropy: 4.89192
Value Function Loss: 0.11864
Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03991
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.07963
Collected Steps per Second: 11,172.45423
Overall Steps per Second: 8,791.57333
Timestep Collection Time: 4.48227
Timestep Consumption Time: 1.21386
PPO Batch Consumption Time: 0.05011
Total Iteration Time: 5.69614
Cumulative Model Updates: 1,558
Cumulative Timesteps: 26,063,656
Timesteps Collected: 50,078
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.87215
Policy Entropy: 4.92776
Value Function Loss: 0.12015
Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04661
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.07870
Collected Steps per Second: 11,001.40551
Overall Steps per Second: 8,601.15075
Timestep Collection Time: 4.54596
Timestep Consumption Time: 1.26861
PPO Batch Consumption Time: 0.07633
Total Iteration Time: 5.81457
Cumulative Model Updates: 1,561
Cumulative Timesteps: 26,113,668
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 26113668...
Checkpoint 26113668 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.10470
Policy Entropy: 4.90165
Value Function Loss: 0.12744
Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07587
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.07852
Collected Steps per Second: 11,002.27880
Overall Steps per Second: 8,819.97806
Timestep Collection Time: 4.54815
Timestep Consumption Time: 1.12533
PPO Batch Consumption Time: 0.05251
Total Iteration Time: 5.67348
Cumulative Model Updates: 1,564
Cumulative Timesteps: 26,163,708
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.49849
Policy Entropy: 4.92714
Value Function Loss: 0.11404
Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06388
Policy Update Magnitude: 0.06439
Value Function Update Magnitude: 0.06809
Collected Steps per Second: 10,979.48520
Overall Steps per Second: 8,659.06326
Timestep Collection Time: 4.55686
Timestep Consumption Time: 1.22113
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.77799
Cumulative Model Updates: 1,567
Cumulative Timesteps: 26,213,740
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 26213740...
Checkpoint 26213740 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.13149
Policy Entropy: 4.91955
Value Function Loss: 0.12747
Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04671
Policy Update Magnitude: 0.06955
Value Function Update Magnitude: 0.06962
Collected Steps per Second: 10,948.13558
Overall Steps per Second: 8,679.26565
Timestep Collection Time: 4.57101
Timestep Consumption Time: 1.19492
PPO Batch Consumption Time: 0.05062
Total Iteration Time: 5.76593
Cumulative Model Updates: 1,570
Cumulative Timesteps: 26,263,784
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39428
Policy Entropy: 4.94041
Value Function Loss: 0.13516
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01774
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.06416
Collected Steps per Second: 11,186.86539
Overall Steps per Second: 8,817.77031
Timestep Collection Time: 4.47310
Timestep Consumption Time: 1.20180
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.67490
Cumulative Model Updates: 1,573
Cumulative Timesteps: 26,313,824
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 26313824...
Checkpoint 26313824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26905
Policy Entropy: 4.94336
Value Function Loss: 0.13847
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.06829
Value Function Update Magnitude: 0.06497
Collected Steps per Second: 10,889.65438
Overall Steps per Second: 8,624.07456
Timestep Collection Time: 4.59500
Timestep Consumption Time: 1.20713
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.80213
Cumulative Model Updates: 1,576
Cumulative Timesteps: 26,363,862
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.24552
Policy Entropy: 4.91173
Value Function Loss: 0.13571
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.07173
Value Function Update Magnitude: 0.06884
Collected Steps per Second: 10,878.35862
Overall Steps per Second: 8,752.47836
Timestep Collection Time: 4.59757
Timestep Consumption Time: 1.11670
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.71427
Cumulative Model Updates: 1,579
Cumulative Timesteps: 26,413,876
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 26413876...
Checkpoint 26413876 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.09945
Policy Entropy: 4.96298
Value Function Loss: 0.13283
Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04159
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.07428
Collected Steps per Second: 10,981.16224
Overall Steps per Second: 8,669.23214
Timestep Collection Time: 4.55507
Timestep Consumption Time: 1.21476
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76983
Cumulative Model Updates: 1,582
Cumulative Timesteps: 26,463,896
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.28808
Policy Entropy: 4.90693
Value Function Loss: 0.13125
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.06412
Value Function Update Magnitude: 0.07175
Collected Steps per Second: 10,885.45475
Overall Steps per Second: 8,538.35668
Timestep Collection Time: 4.59641
Timestep Consumption Time: 1.26350
PPO Batch Consumption Time: 0.07987
Total Iteration Time: 5.85991
Cumulative Model Updates: 1,585
Cumulative Timesteps: 26,513,930
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 26513930...
Checkpoint 26513930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.13983
Policy Entropy: 4.90229
Value Function Loss: 0.13265
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03075
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.07485
Collected Steps per Second: 10,917.48566
Overall Steps per Second: 8,764.55117
Timestep Collection Time: 4.58182
Timestep Consumption Time: 1.12548
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.70731
Cumulative Model Updates: 1,588
Cumulative Timesteps: 26,563,952
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.05241
Policy Entropy: 4.96807
Value Function Loss: 0.12854
Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03659
Policy Update Magnitude: 0.06387
Value Function Update Magnitude: 0.08092
Collected Steps per Second: 10,931.86320
Overall Steps per Second: 8,637.66461
Timestep Collection Time: 4.57507
Timestep Consumption Time: 1.21516
PPO Batch Consumption Time: 0.05162
Total Iteration Time: 5.79022
Cumulative Model Updates: 1,591
Cumulative Timesteps: 26,613,966
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 26613966...
Checkpoint 26613966 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.90603
Policy Entropy: 4.90506
Value Function Loss: 0.13034
Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05413
Policy Update Magnitude: 0.06445
Value Function Update Magnitude: 0.08113
Collected Steps per Second: 10,787.30952
Overall Steps per Second: 8,709.71368
Timestep Collection Time: 4.63804
Timestep Consumption Time: 1.10635
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.74439
Cumulative Model Updates: 1,594
Cumulative Timesteps: 26,663,998
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.24205
Policy Entropy: 4.90967
Value Function Loss: 0.11741
Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03569
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.07766
Collected Steps per Second: 10,911.14564
Overall Steps per Second: 8,580.16762
Timestep Collection Time: 4.58595
Timestep Consumption Time: 1.24587
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.83182
Cumulative Model Updates: 1,597
Cumulative Timesteps: 26,714,036
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 26714036...
Checkpoint 26714036 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.78229
Policy Entropy: 4.91452
Value Function Loss: 0.13120
Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04053
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.07931
Collected Steps per Second: 11,035.08497
Overall Steps per Second: 8,730.10111
Timestep Collection Time: 4.53408
Timestep Consumption Time: 1.19712
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.73121
Cumulative Model Updates: 1,600
Cumulative Timesteps: 26,764,070
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.75490
Policy Entropy: 4.91535
Value Function Loss: 0.12197
Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03525
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.08442
Collected Steps per Second: 10,909.54794
Overall Steps per Second: 8,764.13299
Timestep Collection Time: 4.58369
Timestep Consumption Time: 1.12206
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.70576
Cumulative Model Updates: 1,603
Cumulative Timesteps: 26,814,076
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 26814076...
Checkpoint 26814076 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.14269
Policy Entropy: 4.93787
Value Function Loss: 0.12577
Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04854
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.08166
Collected Steps per Second: 10,991.68432
Overall Steps per Second: 8,700.10289
Timestep Collection Time: 4.54962
Timestep Consumption Time: 1.19836
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.74798
Cumulative Model Updates: 1,606
Cumulative Timesteps: 26,864,084
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.27639
Policy Entropy: 4.92239
Value Function Loss: 0.11163
Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03821
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.08127
Collected Steps per Second: 10,970.00341
Overall Steps per Second: 8,585.56558
Timestep Collection Time: 4.55880
Timestep Consumption Time: 1.26610
PPO Batch Consumption Time: 0.07572
Total Iteration Time: 5.82489
Cumulative Model Updates: 1,609
Cumulative Timesteps: 26,914,094
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 26914094...
Checkpoint 26914094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99355
Policy Entropy: 4.93414
Value Function Loss: 0.11018
Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03346
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.08361
Collected Steps per Second: 11,203.45078
Overall Steps per Second: 8,807.91873
Timestep Collection Time: 4.46327
Timestep Consumption Time: 1.21390
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.67716
Cumulative Model Updates: 1,612
Cumulative Timesteps: 26,964,098
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.94534
Policy Entropy: 4.93235
Value Function Loss: 0.11574
Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04418
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.08849
Collected Steps per Second: 11,001.02607
Overall Steps per Second: 8,646.49135
Timestep Collection Time: 4.54685
Timestep Consumption Time: 1.23816
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.78501
Cumulative Model Updates: 1,615
Cumulative Timesteps: 27,014,118
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 27014118...
Checkpoint 27014118 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.96102
Policy Entropy: 4.88629
Value Function Loss: 0.12062
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02195
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.08858
Collected Steps per Second: 10,920.15427
Overall Steps per Second: 8,763.05836
Timestep Collection Time: 4.58217
Timestep Consumption Time: 1.12794
PPO Batch Consumption Time: 0.05186
Total Iteration Time: 5.71011
Cumulative Model Updates: 1,618
Cumulative Timesteps: 27,064,156
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.88100
Policy Entropy: 4.91723
Value Function Loss: 0.12121
Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.03972
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.08488
Collected Steps per Second: 11,036.79468
Overall Steps per Second: 8,721.28739
Timestep Collection Time: 4.53302
Timestep Consumption Time: 1.20352
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.73654
Cumulative Model Updates: 1,621
Cumulative Timesteps: 27,114,186
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 27114186...
Checkpoint 27114186 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.17979
Policy Entropy: 4.89829
Value Function Loss: 0.11791
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03011
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.07736
Collected Steps per Second: 11,013.21052
Overall Steps per Second: 8,758.66895
Timestep Collection Time: 4.54055
Timestep Consumption Time: 1.16877
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 5.70931
Cumulative Model Updates: 1,624
Cumulative Timesteps: 27,164,192
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48143
Policy Entropy: 4.87789
Value Function Loss: 0.10981
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.07196
Collected Steps per Second: 11,056.36831
Overall Steps per Second: 8,720.34584
Timestep Collection Time: 4.52246
Timestep Consumption Time: 1.21149
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.73395
Cumulative Model Updates: 1,627
Cumulative Timesteps: 27,214,194
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 27214194...
Checkpoint 27214194 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.94716
Policy Entropy: 4.93528
Value Function Loss: 0.11551
Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06051
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.06880
Collected Steps per Second: 10,954.97401
Overall Steps per Second: 8,646.21521
Timestep Collection Time: 4.56888
Timestep Consumption Time: 1.22001
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.78889
Cumulative Model Updates: 1,630
Cumulative Timesteps: 27,264,246
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.88997
Policy Entropy: 4.93451
Value Function Loss: 0.11757
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03675
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.06611
Collected Steps per Second: 10,991.02754
Overall Steps per Second: 8,621.75419
Timestep Collection Time: 4.55026
Timestep Consumption Time: 1.25042
PPO Batch Consumption Time: 0.07600
Total Iteration Time: 5.80068
Cumulative Model Updates: 1,633
Cumulative Timesteps: 27,314,258
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 27314258...
Checkpoint 27314258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.20180
Policy Entropy: 4.91623
Value Function Loss: 0.12651
Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.03916
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.07121
Collected Steps per Second: 11,167.15605
Overall Steps per Second: 8,757.09903
Timestep Collection Time: 4.47831
Timestep Consumption Time: 1.23248
PPO Batch Consumption Time: 0.05272
Total Iteration Time: 5.71080
Cumulative Model Updates: 1,636
Cumulative Timesteps: 27,364,268
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.35580
Policy Entropy: 4.93644
Value Function Loss: 0.12967
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02142
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.07030
Collected Steps per Second: 10,972.53909
Overall Steps per Second: 8,675.50213
Timestep Collection Time: 4.55701
Timestep Consumption Time: 1.20657
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.76359
Cumulative Model Updates: 1,639
Cumulative Timesteps: 27,414,270
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 27414270...
Checkpoint 27414270 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81891
Policy Entropy: 4.89880
Value Function Loss: 0.12674
Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04099
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.06919
Collected Steps per Second: 10,828.94137
Overall Steps per Second: 8,731.04604
Timestep Collection Time: 4.62113
Timestep Consumption Time: 1.11037
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.73150
Cumulative Model Updates: 1,642
Cumulative Timesteps: 27,464,312
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99764
Policy Entropy: 4.93409
Value Function Loss: 0.12319
Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05507
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.07446
Collected Steps per Second: 11,007.25979
Overall Steps per Second: 8,688.46769
Timestep Collection Time: 4.54373
Timestep Consumption Time: 1.21264
PPO Batch Consumption Time: 0.05099
Total Iteration Time: 5.75637
Cumulative Model Updates: 1,645
Cumulative Timesteps: 27,514,326
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 27514326...
Checkpoint 27514326 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.01999
Policy Entropy: 4.90541
Value Function Loss: 0.12413
Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04569
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.07042
Collected Steps per Second: 10,875.27963
Overall Steps per Second: 8,595.87347
Timestep Collection Time: 4.60144
Timestep Consumption Time: 1.22019
PPO Batch Consumption Time: 0.04970
Total Iteration Time: 5.82163
Cumulative Model Updates: 1,648
Cumulative Timesteps: 27,564,368
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.89407
Policy Entropy: 4.90924
Value Function Loss: 0.12484
Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05254
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.07389
Collected Steps per Second: 11,198.29875
Overall Steps per Second: 8,799.16166
Timestep Collection Time: 4.46871
Timestep Consumption Time: 1.21842
PPO Batch Consumption Time: 0.05035
Total Iteration Time: 5.68713
Cumulative Model Updates: 1,651
Cumulative Timesteps: 27,614,410
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 27614410...
Checkpoint 27614410 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99597
Policy Entropy: 4.93438
Value Function Loss: 0.12102
Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.07648
Collected Steps per Second: 11,017.14245
Overall Steps per Second: 8,728.05574
Timestep Collection Time: 4.54038
Timestep Consumption Time: 1.19079
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.73117
Cumulative Model Updates: 1,654
Cumulative Timesteps: 27,664,432
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.09551
Policy Entropy: 4.89526
Value Function Loss: 0.11676
Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04497
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.08285
Collected Steps per Second: 10,829.75901
Overall Steps per Second: 8,536.87580
Timestep Collection Time: 4.61931
Timestep Consumption Time: 1.24068
PPO Batch Consumption Time: 0.07233
Total Iteration Time: 5.85999
Cumulative Model Updates: 1,657
Cumulative Timesteps: 27,714,458
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 27714458...
Checkpoint 27714458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.13243
Policy Entropy: 4.91870
Value Function Loss: 0.10976
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.08806
Collected Steps per Second: 11,329.70103
Overall Steps per Second: 8,863.47213
Timestep Collection Time: 4.41371
Timestep Consumption Time: 1.22810
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.64181
Cumulative Model Updates: 1,660
Cumulative Timesteps: 27,764,464
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.34451
Policy Entropy: 4.92553
Value Function Loss: 0.10804
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02123
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.08085
Collected Steps per Second: 10,922.74324
Overall Steps per Second: 8,702.90713
Timestep Collection Time: 4.58072
Timestep Consumption Time: 1.16840
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.74911
Cumulative Model Updates: 1,663
Cumulative Timesteps: 27,814,498
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 27814498...
Checkpoint 27814498 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.81784
Policy Entropy: 4.89306
Value Function Loss: 0.09932
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02028
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.07998
Collected Steps per Second: 10,868.44411
Overall Steps per Second: 8,776.60591
Timestep Collection Time: 4.60047
Timestep Consumption Time: 1.09649
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.69696
Cumulative Model Updates: 1,666
Cumulative Timesteps: 27,864,498
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.11220
Policy Entropy: 4.88396
Value Function Loss: 0.10356
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03085
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.08129
Collected Steps per Second: 11,037.30185
Overall Steps per Second: 8,680.59924
Timestep Collection Time: 4.53245
Timestep Consumption Time: 1.23052
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.76297
Cumulative Model Updates: 1,669
Cumulative Timesteps: 27,914,524
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 27914524...
Checkpoint 27914524 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.88039
Policy Entropy: 4.88646
Value Function Loss: 0.10390
Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04748
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.09078
Collected Steps per Second: 10,991.44828
Overall Steps per Second: 8,719.15951
Timestep Collection Time: 4.55063
Timestep Consumption Time: 1.18593
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.73656
Cumulative Model Updates: 1,672
Cumulative Timesteps: 27,964,542
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.00429
Policy Entropy: 4.82636
Value Function Loss: 0.10963
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02605
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.07820
Collected Steps per Second: 11,283.41468
Overall Steps per Second: 8,864.14478
Timestep Collection Time: 4.43447
Timestep Consumption Time: 1.21029
PPO Batch Consumption Time: 0.05053
Total Iteration Time: 5.64476
Cumulative Model Updates: 1,675
Cumulative Timesteps: 28,014,578
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 28014578...
Checkpoint 28014578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.95337
Policy Entropy: 4.85462
Value Function Loss: 0.10740
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01731
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.08266
Collected Steps per Second: 10,926.22674
Overall Steps per Second: 8,594.28599
Timestep Collection Time: 4.57816
Timestep Consumption Time: 1.24222
PPO Batch Consumption Time: 0.05056
Total Iteration Time: 5.82038
Cumulative Model Updates: 1,678
Cumulative Timesteps: 28,064,600
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.01152
Policy Entropy: 4.88389
Value Function Loss: 0.11233
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.08579
Collected Steps per Second: 10,985.62686
Overall Steps per Second: 8,678.87302
Timestep Collection Time: 4.55195
Timestep Consumption Time: 1.20986
PPO Batch Consumption Time: 0.07866
Total Iteration Time: 5.76181
Cumulative Model Updates: 1,681
Cumulative Timesteps: 28,114,606
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 28114606...
Checkpoint 28114606 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.86977
Policy Entropy: 4.86824
Value Function Loss: 0.10500
Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05407
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.07542
Collected Steps per Second: 10,929.92783
Overall Steps per Second: 8,621.69224
Timestep Collection Time: 4.57826
Timestep Consumption Time: 1.22571
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.80397
Cumulative Model Updates: 1,684
Cumulative Timesteps: 28,164,646
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.03308
Policy Entropy: 4.91202
Value Function Loss: 0.10085
Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04347
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.07066
Collected Steps per Second: 10,880.07753
Overall Steps per Second: 8,672.30045
Timestep Collection Time: 4.59647
Timestep Consumption Time: 1.17016
PPO Batch Consumption Time: 0.05039
Total Iteration Time: 5.76664
Cumulative Model Updates: 1,687
Cumulative Timesteps: 28,214,656
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 28214656...
Checkpoint 28214656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.12927
Policy Entropy: 4.88823
Value Function Loss: 0.10305
Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04505
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.06809
Collected Steps per Second: 10,977.09585
Overall Steps per Second: 8,847.44108
Timestep Collection Time: 4.55640
Timestep Consumption Time: 1.09676
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.65316
Cumulative Model Updates: 1,690
Cumulative Timesteps: 28,264,672
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.89757
Policy Entropy: 4.84596
Value Function Loss: 0.11734
Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04589
Policy Update Magnitude: 0.05926
Value Function Update Magnitude: 0.06754
Collected Steps per Second: 10,934.75254
Overall Steps per Second: 8,626.33312
Timestep Collection Time: 4.57349
Timestep Consumption Time: 1.22387
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.79736
Cumulative Model Updates: 1,693
Cumulative Timesteps: 28,314,682
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 28314682...
Checkpoint 28314682 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.08929
Policy Entropy: 4.87625
Value Function Loss: 0.12252
Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04449
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.07447
Collected Steps per Second: 10,900.17710
Overall Steps per Second: 8,638.74080
Timestep Collection Time: 4.58745
Timestep Consumption Time: 1.20090
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.78834
Cumulative Model Updates: 1,696
Cumulative Timesteps: 28,364,686
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.10424
Policy Entropy: 4.85331
Value Function Loss: 0.12038
Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05655
Policy Update Magnitude: 0.06749
Value Function Update Magnitude: 0.07900
Collected Steps per Second: 11,188.50089
Overall Steps per Second: 8,797.54849
Timestep Collection Time: 4.47299
Timestep Consumption Time: 1.21564
PPO Batch Consumption Time: 0.04990
Total Iteration Time: 5.68863
Cumulative Model Updates: 1,699
Cumulative Timesteps: 28,414,732
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 28414732...
Checkpoint 28414732 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.90694
Policy Entropy: 4.85802
Value Function Loss: 0.11875
Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03691
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.07029
Collected Steps per Second: 10,913.45777
Overall Steps per Second: 8,610.00374
Timestep Collection Time: 4.58461
Timestep Consumption Time: 1.22653
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.81115
Cumulative Model Updates: 1,702
Cumulative Timesteps: 28,464,766
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.15326
Policy Entropy: 4.86173
Value Function Loss: 0.10864
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01743
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.06414
Collected Steps per Second: 10,837.92178
Overall Steps per Second: 8,618.11863
Timestep Collection Time: 4.61343
Timestep Consumption Time: 1.18830
PPO Batch Consumption Time: 0.08216
Total Iteration Time: 5.80173
Cumulative Model Updates: 1,705
Cumulative Timesteps: 28,514,766
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 28514766...
Checkpoint 28514766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.19572
Policy Entropy: 4.88806
Value Function Loss: 0.10505
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.06139
Collected Steps per Second: 11,073.42615
Overall Steps per Second: 8,698.75070
Timestep Collection Time: 4.51604
Timestep Consumption Time: 1.23283
PPO Batch Consumption Time: 0.05274
Total Iteration Time: 5.74887
Cumulative Model Updates: 1,708
Cumulative Timesteps: 28,564,774
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79833
Policy Entropy: 4.95493
Value Function Loss: 0.09569
Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.03831
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.06199
Collected Steps per Second: 10,968.40161
Overall Steps per Second: 8,728.46012
Timestep Collection Time: 4.55964
Timestep Consumption Time: 1.17012
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.72976
Cumulative Model Updates: 1,711
Cumulative Timesteps: 28,614,786
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 28614786...
Checkpoint 28614786 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.12707
Policy Entropy: 4.92316
Value Function Loss: 0.09301
Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05032
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.05861
Collected Steps per Second: 11,168.68128
Overall Steps per Second: 8,817.74263
Timestep Collection Time: 4.47788
Timestep Consumption Time: 1.19387
PPO Batch Consumption Time: 0.04988
Total Iteration Time: 5.67175
Cumulative Model Updates: 1,714
Cumulative Timesteps: 28,664,798
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.31954
Policy Entropy: 4.92470
Value Function Loss: 0.07279
Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03548
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.06064
Collected Steps per Second: 10,928.45870
Overall Steps per Second: 8,628.21520
Timestep Collection Time: 4.57759
Timestep Consumption Time: 1.22036
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.79795
Cumulative Model Updates: 1,717
Cumulative Timesteps: 28,714,824
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 28714824...
Checkpoint 28714824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.56919
Policy Entropy: 4.94459
Value Function Loss: 0.06653
Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04935
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.06097
Collected Steps per Second: 10,849.94223
Overall Steps per Second: 8,612.73514
Timestep Collection Time: 4.60906
Timestep Consumption Time: 1.19723
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.80629
Cumulative Model Updates: 1,720
Cumulative Timesteps: 28,764,832
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70731
Policy Entropy: 4.91876
Value Function Loss: 0.07782
Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05027
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.05786
Collected Steps per Second: 11,175.01196
Overall Steps per Second: 8,770.11770
Timestep Collection Time: 4.47821
Timestep Consumption Time: 1.22799
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.70619
Cumulative Model Updates: 1,723
Cumulative Timesteps: 28,814,876
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 28814876...
Checkpoint 28814876 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.30244
Policy Entropy: 4.92979
Value Function Loss: 0.08816
Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04883
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.05781
Collected Steps per Second: 10,870.45491
Overall Steps per Second: 8,646.82466
Timestep Collection Time: 4.60220
Timestep Consumption Time: 1.18351
PPO Batch Consumption Time: 0.05184
Total Iteration Time: 5.78571
Cumulative Model Updates: 1,726
Cumulative Timesteps: 28,864,904
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.19255
Policy Entropy: 4.96128
Value Function Loss: 0.08914
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03073
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.06395
Collected Steps per Second: 10,858.83540
Overall Steps per Second: 8,606.76629
Timestep Collection Time: 4.60602
Timestep Consumption Time: 1.20522
PPO Batch Consumption Time: 0.08100
Total Iteration Time: 5.81124
Cumulative Model Updates: 1,729
Cumulative Timesteps: 28,914,920
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 28914920...
Checkpoint 28914920 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.87921
Policy Entropy: 4.94548
Value Function Loss: 0.07998
Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03645
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.06884
Collected Steps per Second: 10,897.68545
Overall Steps per Second: 8,607.20438
Timestep Collection Time: 4.58868
Timestep Consumption Time: 1.22110
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.80978
Cumulative Model Updates: 1,732
Cumulative Timesteps: 28,964,926
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.03361
Policy Entropy: 4.91992
Value Function Loss: 0.08043
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.06805
Collected Steps per Second: 11,038.50047
Overall Steps per Second: 8,775.18271
Timestep Collection Time: 4.53359
Timestep Consumption Time: 1.16931
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.70290
Cumulative Model Updates: 1,735
Cumulative Timesteps: 29,014,970
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 29014970...
Checkpoint 29014970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52018
Policy Entropy: 4.92859
Value Function Loss: 0.08289
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03140
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.06740
Collected Steps per Second: 11,288.57938
Overall Steps per Second: 8,868.78914
Timestep Collection Time: 4.43280
Timestep Consumption Time: 1.20946
PPO Batch Consumption Time: 0.04938
Total Iteration Time: 5.64226
Cumulative Model Updates: 1,738
Cumulative Timesteps: 29,065,010
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.29878
Policy Entropy: 4.88064
Value Function Loss: 0.09258
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01695
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.07438
Collected Steps per Second: 10,942.57951
Overall Steps per Second: 8,626.83517
Timestep Collection Time: 4.57278
Timestep Consumption Time: 1.22749
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.80027
Cumulative Model Updates: 1,741
Cumulative Timesteps: 29,115,048
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 29115048...
Checkpoint 29115048 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.89273
Policy Entropy: 4.88425
Value Function Loss: 0.09232
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.08133
Collected Steps per Second: 10,828.10793
Overall Steps per Second: 8,729.22754
Timestep Collection Time: 4.61780
Timestep Consumption Time: 1.11032
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.72811
Cumulative Model Updates: 1,744
Cumulative Timesteps: 29,165,050
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65179
Policy Entropy: 4.90975
Value Function Loss: 0.09143
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01487
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.09268
Collected Steps per Second: 10,925.06005
Overall Steps per Second: 8,645.94961
Timestep Collection Time: 4.57865
Timestep Consumption Time: 1.20695
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.78560
Cumulative Model Updates: 1,747
Cumulative Timesteps: 29,215,072
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 29215072...
Checkpoint 29215072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.87806
Policy Entropy: 4.89117
Value Function Loss: 0.08239
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.08657
Collected Steps per Second: 10,979.78134
Overall Steps per Second: 8,694.18556
Timestep Collection Time: 4.55401
Timestep Consumption Time: 1.19719
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.75120
Cumulative Model Updates: 1,750
Cumulative Timesteps: 29,265,074
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64262
Policy Entropy: 4.90942
Value Function Loss: 0.08205
Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03414
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.07599
Collected Steps per Second: 11,015.60134
Overall Steps per Second: 8,731.63814
Timestep Collection Time: 4.53920
Timestep Consumption Time: 1.18733
PPO Batch Consumption Time: 0.07416
Total Iteration Time: 5.72653
Cumulative Model Updates: 1,753
Cumulative Timesteps: 29,315,076
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 29315076...
Checkpoint 29315076 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.87720
Policy Entropy: 4.89787
Value Function Loss: 0.08875
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.07238
Collected Steps per Second: 10,985.04402
Overall Steps per Second: 8,646.04740
Timestep Collection Time: 4.55492
Timestep Consumption Time: 1.23223
PPO Batch Consumption Time: 0.05334
Total Iteration Time: 5.78715
Cumulative Model Updates: 1,756
Cumulative Timesteps: 29,365,112
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.35733
Policy Entropy: 4.87428
Value Function Loss: 0.08698
Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04157
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.07869
Collected Steps per Second: 10,941.67235
Overall Steps per Second: 8,624.82846
Timestep Collection Time: 4.57206
Timestep Consumption Time: 1.22817
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.80023
Cumulative Model Updates: 1,759
Cumulative Timesteps: 29,415,138
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 29415138...
Checkpoint 29415138 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.96604
Policy Entropy: 4.87770
Value Function Loss: 0.09428
Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.04990
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.07364
Collected Steps per Second: 11,042.49087
Overall Steps per Second: 8,729.38480
Timestep Collection Time: 4.53285
Timestep Consumption Time: 1.20111
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.73397
Cumulative Model Updates: 1,762
Cumulative Timesteps: 29,465,192
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.27855
Policy Entropy: 4.85518
Value Function Loss: 0.10098
Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.06743
Collected Steps per Second: 11,026.77542
Overall Steps per Second: 8,694.11030
Timestep Collection Time: 4.53823
Timestep Consumption Time: 1.21762
PPO Batch Consumption Time: 0.04925
Total Iteration Time: 5.75585
Cumulative Model Updates: 1,765
Cumulative Timesteps: 29,515,234
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 29515234...
Checkpoint 29515234 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.03626
Policy Entropy: 4.81868
Value Function Loss: 0.10917
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.06451
Collected Steps per Second: 10,957.70389
Overall Steps per Second: 8,813.65562
Timestep Collection Time: 4.56355
Timestep Consumption Time: 1.11015
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.67370
Cumulative Model Updates: 1,768
Cumulative Timesteps: 29,565,240
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.61153
Policy Entropy: 4.87494
Value Function Loss: 0.10337
Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03899
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.05841
Collected Steps per Second: 10,916.56435
Overall Steps per Second: 8,648.81410
Timestep Collection Time: 4.58258
Timestep Consumption Time: 1.20157
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.78415
Cumulative Model Updates: 1,771
Cumulative Timesteps: 29,615,266
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 29615266...
Checkpoint 29615266 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.30619
Policy Entropy: 4.87246
Value Function Loss: 0.09403
Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04761
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.05842
Collected Steps per Second: 10,909.05871
Overall Steps per Second: 8,665.17621
Timestep Collection Time: 4.58518
Timestep Consumption Time: 1.18735
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.77253
Cumulative Model Updates: 1,774
Cumulative Timesteps: 29,665,286
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.05160
Policy Entropy: 4.85877
Value Function Loss: 0.08247
Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.04522
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.06001
Collected Steps per Second: 10,840.63760
Overall Steps per Second: 8,627.64302
Timestep Collection Time: 4.61301
Timestep Consumption Time: 1.18324
PPO Batch Consumption Time: 0.07500
Total Iteration Time: 5.79625
Cumulative Model Updates: 1,777
Cumulative Timesteps: 29,715,294
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 29715294...
Checkpoint 29715294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26418
Policy Entropy: 4.90273
Value Function Loss: 0.07623
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.05873
Collected Steps per Second: 10,993.80908
Overall Steps per Second: 8,648.84460
Timestep Collection Time: 4.54874
Timestep Consumption Time: 1.23330
PPO Batch Consumption Time: 0.05362
Total Iteration Time: 5.78204
Cumulative Model Updates: 1,780
Cumulative Timesteps: 29,765,302
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53876
Policy Entropy: 4.89106
Value Function Loss: 0.08080
Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04633
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.05823
Collected Steps per Second: 10,824.51529
Overall Steps per Second: 8,619.58061
Timestep Collection Time: 4.62062
Timestep Consumption Time: 1.18198
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.80260
Cumulative Model Updates: 1,783
Cumulative Timesteps: 29,815,318
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 29815318...
Checkpoint 29815318 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.03605
Policy Entropy: 4.84175
Value Function Loss: 0.08049
Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05151
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.06202
Collected Steps per Second: 11,205.43153
Overall Steps per Second: 8,783.18407
Timestep Collection Time: 4.46533
Timestep Consumption Time: 1.23146
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.69680
Cumulative Model Updates: 1,786
Cumulative Timesteps: 29,865,354
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.27139
Policy Entropy: 4.83087
Value Function Loss: 0.09133
Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03891
Policy Update Magnitude: 0.04440
Value Function Update Magnitude: 0.06003
Collected Steps per Second: 10,998.32516
Overall Steps per Second: 8,665.71035
Timestep Collection Time: 4.54760
Timestep Consumption Time: 1.22411
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.77171
Cumulative Model Updates: 1,789
Cumulative Timesteps: 29,915,370
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 29915370...
Checkpoint 29915370 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.35568
Policy Entropy: 4.83794
Value Function Loss: 0.08526
Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03762
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.05395
Collected Steps per Second: 10,962.37043
Overall Steps per Second: 8,801.14666
Timestep Collection Time: 4.56179
Timestep Consumption Time: 1.12020
PPO Batch Consumption Time: 0.05053
Total Iteration Time: 5.68199
Cumulative Model Updates: 1,792
Cumulative Timesteps: 29,965,378
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.30994
Policy Entropy: 4.83213
Value Function Loss: 0.09582
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.05744
Collected Steps per Second: 10,964.60715
Overall Steps per Second: 8,679.55982
Timestep Collection Time: 4.56013
Timestep Consumption Time: 1.20053
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76066
Cumulative Model Updates: 1,795
Cumulative Timesteps: 30,015,378
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 30015378...
Checkpoint 30015378 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.85170
Policy Entropy: 4.84410
Value Function Loss: 0.08988
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.06107
Collected Steps per Second: 10,971.13692
Overall Steps per Second: 8,703.77367
Timestep Collection Time: 4.55832
Timestep Consumption Time: 1.18746
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.74578
Cumulative Model Updates: 1,798
Cumulative Timesteps: 30,065,388
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.33977
Policy Entropy: 4.82188
Value Function Loss: 0.09048
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.06002
Collected Steps per Second: 11,166.27176
Overall Steps per Second: 8,660.22489
Timestep Collection Time: 4.48117
Timestep Consumption Time: 1.29674
PPO Batch Consumption Time: 0.08133
Total Iteration Time: 5.77791
Cumulative Model Updates: 1,801
Cumulative Timesteps: 30,115,426
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 30115426...
Checkpoint 30115426 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44815
Policy Entropy: 4.83454
Value Function Loss: 0.09011
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.04994
Value Function Update Magnitude: 0.06288
Collected Steps per Second: 11,078.04315
Overall Steps per Second: 8,683.97759
Timestep Collection Time: 4.51343
Timestep Consumption Time: 1.24430
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.75773
Cumulative Model Updates: 1,804
Cumulative Timesteps: 30,165,426
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.96281
Policy Entropy: 4.86913
Value Function Loss: 0.08933
Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03981
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.06460
Collected Steps per Second: 10,866.47268
Overall Steps per Second: 8,640.02658
Timestep Collection Time: 4.60260
Timestep Consumption Time: 1.18604
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.78864
Cumulative Model Updates: 1,807
Cumulative Timesteps: 30,215,440
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 30215440...
Checkpoint 30215440 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.33182
Policy Entropy: 4.84401
Value Function Loss: 0.08499
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02326
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.06345
Collected Steps per Second: 11,117.49345
Overall Steps per Second: 8,776.18995
Timestep Collection Time: 4.49940
Timestep Consumption Time: 1.20034
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.69974
Cumulative Model Updates: 1,810
Cumulative Timesteps: 30,265,462
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46100
Policy Entropy: 4.83634
Value Function Loss: 0.07998
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01867
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.06239
Collected Steps per Second: 10,932.28569
Overall Steps per Second: 8,635.19624
Timestep Collection Time: 4.57782
Timestep Consumption Time: 1.21777
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.79558
Cumulative Model Updates: 1,813
Cumulative Timesteps: 30,315,508
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 30315508...
Checkpoint 30315508 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80998
Policy Entropy: 4.86055
Value Function Loss: 0.08132
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01479
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.06698
Collected Steps per Second: 10,908.02147
Overall Steps per Second: 8,786.15582
Timestep Collection Time: 4.58488
Timestep Consumption Time: 1.10725
PPO Batch Consumption Time: 0.05005
Total Iteration Time: 5.69214
Cumulative Model Updates: 1,816
Cumulative Timesteps: 30,365,520
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44140
Policy Entropy: 4.81197
Value Function Loss: 0.08834
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.06961
Collected Steps per Second: 10,936.81238
Overall Steps per Second: 8,648.19939
Timestep Collection Time: 4.57281
Timestep Consumption Time: 1.21012
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.78294
Cumulative Model Updates: 1,819
Cumulative Timesteps: 30,415,532
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 30415532...
Checkpoint 30415532 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41601
Policy Entropy: 4.82771
Value Function Loss: 0.08236
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.07382
Collected Steps per Second: 10,879.82814
Overall Steps per Second: 8,643.57964
Timestep Collection Time: 4.59823
Timestep Consumption Time: 1.18965
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78788
Cumulative Model Updates: 1,822
Cumulative Timesteps: 30,465,560
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.37151
Policy Entropy: 4.86065
Value Function Loss: 0.07615
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.06503
Collected Steps per Second: 11,167.75991
Overall Steps per Second: 8,650.55645
Timestep Collection Time: 4.47735
Timestep Consumption Time: 1.30285
PPO Batch Consumption Time: 0.08067
Total Iteration Time: 5.78021
Cumulative Model Updates: 1,825
Cumulative Timesteps: 30,515,562
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 30515562...
Checkpoint 30515562 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.04564
Policy Entropy: 4.86339
Value Function Loss: 0.06745
Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03901
Policy Update Magnitude: 0.04280
Value Function Update Magnitude: 0.06196
Collected Steps per Second: 10,996.99164
Overall Steps per Second: 8,676.17922
Timestep Collection Time: 4.55015
Timestep Consumption Time: 1.21713
PPO Batch Consumption Time: 0.05353
Total Iteration Time: 5.76729
Cumulative Model Updates: 1,828
Cumulative Timesteps: 30,565,600
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26417
Policy Entropy: 4.87006
Value Function Loss: 0.07069
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02121
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.06338
Collected Steps per Second: 10,898.86134
Overall Steps per Second: 8,657.22801
Timestep Collection Time: 4.59075
Timestep Consumption Time: 1.18869
PPO Batch Consumption Time: 0.05086
Total Iteration Time: 5.77945
Cumulative Model Updates: 1,831
Cumulative Timesteps: 30,615,634
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 30615634...
Checkpoint 30615634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42702
Policy Entropy: 4.90630
Value Function Loss: 0.06994
Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04420
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.06423
Collected Steps per Second: 11,188.88017
Overall Steps per Second: 8,758.97781
Timestep Collection Time: 4.46890
Timestep Consumption Time: 1.23976
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.70866
Cumulative Model Updates: 1,834
Cumulative Timesteps: 30,665,636
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44628
Policy Entropy: 4.91682
Value Function Loss: 0.07555
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.06067
Collected Steps per Second: 10,888.78944
Overall Steps per Second: 8,645.02543
Timestep Collection Time: 4.59390
Timestep Consumption Time: 1.19232
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.78622
Cumulative Model Updates: 1,837
Cumulative Timesteps: 30,715,658
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 30715658...
Checkpoint 30715658 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40899
Policy Entropy: 4.90882
Value Function Loss: 0.07462
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.06676
Collected Steps per Second: 10,840.39668
Overall Steps per Second: 8,718.41268
Timestep Collection Time: 4.61385
Timestep Consumption Time: 1.12297
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.73682
Cumulative Model Updates: 1,840
Cumulative Timesteps: 30,765,674
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39417
Policy Entropy: 4.89199
Value Function Loss: 0.08555
Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.05987
Collected Steps per Second: 11,044.67448
Overall Steps per Second: 8,670.52519
Timestep Collection Time: 4.52797
Timestep Consumption Time: 1.23984
PPO Batch Consumption Time: 0.05144
Total Iteration Time: 5.76782
Cumulative Model Updates: 1,843
Cumulative Timesteps: 30,815,684
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 30815684...
Checkpoint 30815684 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.23799
Policy Entropy: 4.87777
Value Function Loss: 0.08147
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01368
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.06317
Collected Steps per Second: 11,055.39379
Overall Steps per Second: 8,776.32597
Timestep Collection Time: 4.52413
Timestep Consumption Time: 1.17484
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.69897
Cumulative Model Updates: 1,846
Cumulative Timesteps: 30,865,700
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44254
Policy Entropy: 4.91872
Value Function Loss: 0.08863
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.06440
Collected Steps per Second: 11,216.09636
Overall Steps per Second: 8,666.53091
Timestep Collection Time: 4.45948
Timestep Consumption Time: 1.31191
PPO Batch Consumption Time: 0.08133
Total Iteration Time: 5.77140
Cumulative Model Updates: 1,849
Cumulative Timesteps: 30,915,718
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 30915718...
Checkpoint 30915718 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99916
Policy Entropy: 4.91000
Value Function Loss: 0.07790
Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04097
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.06178
Collected Steps per Second: 11,041.57984
Overall Steps per Second: 8,703.24578
Timestep Collection Time: 4.53105
Timestep Consumption Time: 1.21738
PPO Batch Consumption Time: 0.05285
Total Iteration Time: 5.74843
Cumulative Model Updates: 1,852
Cumulative Timesteps: 30,965,748
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.97980
Policy Entropy: 4.89975
Value Function Loss: 0.08239
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02566
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.05857
Collected Steps per Second: 10,926.14402
Overall Steps per Second: 8,801.79566
Timestep Collection Time: 4.57874
Timestep Consumption Time: 1.10510
PPO Batch Consumption Time: 0.05176
Total Iteration Time: 5.68384
Cumulative Model Updates: 1,855
Cumulative Timesteps: 31,015,776
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 31015776...
Checkpoint 31015776 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55822
Policy Entropy: 4.92543
Value Function Loss: 0.09032
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03045
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.05873
Collected Steps per Second: 10,955.92061
Overall Steps per Second: 8,672.61541
Timestep Collection Time: 4.56502
Timestep Consumption Time: 1.20187
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.76689
Cumulative Model Updates: 1,858
Cumulative Timesteps: 31,065,790
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39067
Policy Entropy: 4.92936
Value Function Loss: 0.09917
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02613
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.06119
Collected Steps per Second: 10,921.84551
Overall Steps per Second: 8,688.74351
Timestep Collection Time: 4.58000
Timestep Consumption Time: 1.17711
PPO Batch Consumption Time: 0.05022
Total Iteration Time: 5.75710
Cumulative Model Updates: 1,861
Cumulative Timesteps: 31,115,812
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 31115812...
Checkpoint 31115812 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44503
Policy Entropy: 4.87921
Value Function Loss: 0.10612
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02205
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.05957
Collected Steps per Second: 10,908.27786
Overall Steps per Second: 8,743.83868
Timestep Collection Time: 4.58386
Timestep Consumption Time: 1.13468
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.71854
Cumulative Model Updates: 1,864
Cumulative Timesteps: 31,165,814
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54059
Policy Entropy: 4.90895
Value Function Loss: 0.10365
Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03412
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.06013
Collected Steps per Second: 11,012.59306
Overall Steps per Second: 8,667.94572
Timestep Collection Time: 4.54462
Timestep Consumption Time: 1.22930
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.77392
Cumulative Model Updates: 1,867
Cumulative Timesteps: 31,215,862
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 31215862...
Checkpoint 31215862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66895
Policy Entropy: 4.91037
Value Function Loss: 0.10842
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01561
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.06428
Collected Steps per Second: 11,084.11407
Overall Steps per Second: 8,792.09185
Timestep Collection Time: 4.51457
Timestep Consumption Time: 1.17691
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69148
Cumulative Model Updates: 1,870
Cumulative Timesteps: 31,265,902
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.20332
Policy Entropy: 4.86914
Value Function Loss: 0.10217
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.06037
Collected Steps per Second: 11,062.57668
Overall Steps per Second: 8,607.72375
Timestep Collection Time: 4.52119
Timestep Consumption Time: 1.28941
PPO Batch Consumption Time: 0.07667
Total Iteration Time: 5.81060
Cumulative Model Updates: 1,873
Cumulative Timesteps: 31,315,918
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 31315918...
Checkpoint 31315918 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.13529
Policy Entropy: 4.92059
Value Function Loss: 0.09169
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03751
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.05581
Collected Steps per Second: 11,000.31410
Overall Steps per Second: 8,655.24529
Timestep Collection Time: 4.54732
Timestep Consumption Time: 1.23206
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.77939
Cumulative Model Updates: 1,876
Cumulative Timesteps: 31,365,940
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.16742
Policy Entropy: 4.96705
Value Function Loss: 0.07091
Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04358
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.05140
Collected Steps per Second: 10,281.47410
Overall Steps per Second: 8,321.25851
Timestep Collection Time: 4.86720
Timestep Consumption Time: 1.14655
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 6.01375
Cumulative Model Updates: 1,879
Cumulative Timesteps: 31,415,982
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 31415982...
Checkpoint 31415982 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57983
Policy Entropy: 4.98037
Value Function Loss: 0.07030
Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04379
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.04880
Collected Steps per Second: 10,980.57747
Overall Steps per Second: 8,636.41690
Timestep Collection Time: 4.55495
Timestep Consumption Time: 1.23634
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.79129
Cumulative Model Updates: 1,882
Cumulative Timesteps: 31,465,998
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.17988
Policy Entropy: 5.01717
Value Function Loss: 0.06751
Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04501
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.04587
Collected Steps per Second: 10,977.13058
Overall Steps per Second: 8,710.91460
Timestep Collection Time: 4.55529
Timestep Consumption Time: 1.18510
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.74038
Cumulative Model Updates: 1,885
Cumulative Timesteps: 31,516,002
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 31516002...
Checkpoint 31516002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50062
Policy Entropy: 5.00821
Value Function Loss: 0.07360
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.06851
Value Function Update Magnitude: 0.05323
Collected Steps per Second: 10,920.57513
Overall Steps per Second: 8,782.00826
Timestep Collection Time: 4.57925
Timestep Consumption Time: 1.11512
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69437
Cumulative Model Updates: 1,888
Cumulative Timesteps: 31,566,010
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.15260
Policy Entropy: 5.00120
Value Function Loss: 0.06860
Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04761
Policy Update Magnitude: 0.06489
Value Function Update Magnitude: 0.05038
Collected Steps per Second: 10,888.75737
Overall Steps per Second: 8,616.89318
Timestep Collection Time: 4.59263
Timestep Consumption Time: 1.21086
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.80348
Cumulative Model Updates: 1,891
Cumulative Timesteps: 31,616,018
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 31616018...
Checkpoint 31616018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.12539
Policy Entropy: 5.01280
Value Function Loss: 0.06963
Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03737
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.05415
Collected Steps per Second: 10,827.98514
Overall Steps per Second: 8,589.33412
Timestep Collection Time: 4.62154
Timestep Consumption Time: 1.20452
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.82606
Cumulative Model Updates: 1,894
Cumulative Timesteps: 31,666,060
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41637
Policy Entropy: 4.98579
Value Function Loss: 0.07156
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01940
Policy Update Magnitude: 0.06464
Value Function Update Magnitude: 0.05634
Collected Steps per Second: 11,195.86082
Overall Steps per Second: 8,677.54953
Timestep Collection Time: 4.47076
Timestep Consumption Time: 1.29746
PPO Batch Consumption Time: 0.07800
Total Iteration Time: 5.76822
Cumulative Model Updates: 1,897
Cumulative Timesteps: 31,716,114
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 31716114...
Checkpoint 31716114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.22060
Policy Entropy: 4.98291
Value Function Loss: 0.07231
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02775
Policy Update Magnitude: 0.06616
Value Function Update Magnitude: 0.05958
Collected Steps per Second: 10,978.94793
Overall Steps per Second: 8,647.06803
Timestep Collection Time: 4.55818
Timestep Consumption Time: 1.22922
PPO Batch Consumption Time: 0.05237
Total Iteration Time: 5.78740
Cumulative Model Updates: 1,900
Cumulative Timesteps: 31,766,158
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.20208
Policy Entropy: 5.00119
Value Function Loss: 0.06993
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02327
Policy Update Magnitude: 0.06160
Value Function Update Magnitude: 0.06352
Collected Steps per Second: 10,874.25772
Overall Steps per Second: 8,729.64582
Timestep Collection Time: 4.60077
Timestep Consumption Time: 1.13027
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.73105
Cumulative Model Updates: 1,903
Cumulative Timesteps: 31,816,188
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 31816188...
Checkpoint 31816188 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77455
Policy Entropy: 4.99694
Value Function Loss: 0.07306
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01596
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.05721
Collected Steps per Second: 11,042.96832
Overall Steps per Second: 8,691.26944
Timestep Collection Time: 4.53067
Timestep Consumption Time: 1.22592
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.75658
Cumulative Model Updates: 1,906
Cumulative Timesteps: 31,866,220
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.12336
Policy Entropy: 4.97315
Value Function Loss: 0.07927
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.06051
Collected Steps per Second: 11,052.12409
Overall Steps per Second: 8,762.90935
Timestep Collection Time: 4.52746
Timestep Consumption Time: 1.18275
PPO Batch Consumption Time: 0.05038
Total Iteration Time: 5.71020
Cumulative Model Updates: 1,909
Cumulative Timesteps: 31,916,258
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 31916258...
Checkpoint 31916258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.36933
Policy Entropy: 5.02191
Value Function Loss: 0.07867
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.06055
Collected Steps per Second: 11,281.57863
Overall Steps per Second: 8,862.23237
Timestep Collection Time: 4.43519
Timestep Consumption Time: 1.21079
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.64598
Cumulative Model Updates: 1,912
Cumulative Timesteps: 31,966,294
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52002
Policy Entropy: 5.02417
Value Function Loss: 0.07617
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.06075
Collected Steps per Second: 11,068.19595
Overall Steps per Second: 8,726.40926
Timestep Collection Time: 4.52016
Timestep Consumption Time: 1.21301
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.73317
Cumulative Model Updates: 1,915
Cumulative Timesteps: 32,016,324
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 32016324...
Checkpoint 32016324 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.25886
Policy Entropy: 4.98527
Value Function Loss: 0.07810
Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03487
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.05690
Collected Steps per Second: 10,986.28566
Overall Steps per Second: 8,701.64202
Timestep Collection Time: 4.55313
Timestep Consumption Time: 1.19544
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.74857
Cumulative Model Updates: 1,918
Cumulative Timesteps: 32,066,346
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.01599
Policy Entropy: 5.02269
Value Function Loss: 0.07599
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02799
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.05708
Collected Steps per Second: 11,218.45046
Overall Steps per Second: 8,684.92331
Timestep Collection Time: 4.45944
Timestep Consumption Time: 1.30089
PPO Batch Consumption Time: 0.07805
Total Iteration Time: 5.76033
Cumulative Model Updates: 1,921
Cumulative Timesteps: 32,116,374
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 32116374...
Checkpoint 32116374 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63211
Policy Entropy: 5.02698
Value Function Loss: 0.07409
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01524
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.05558
Collected Steps per Second: 10,977.03636
Overall Steps per Second: 8,716.82372
Timestep Collection Time: 4.55533
Timestep Consumption Time: 1.18117
PPO Batch Consumption Time: 0.05271
Total Iteration Time: 5.73649
Cumulative Model Updates: 1,924
Cumulative Timesteps: 32,166,378
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.31725
Policy Entropy: 5.02054
Value Function Loss: 0.07017
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02022
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.05324
Collected Steps per Second: 11,051.49853
Overall Steps per Second: 8,859.64821
Timestep Collection Time: 4.52880
Timestep Consumption Time: 1.12041
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.64921
Cumulative Model Updates: 1,927
Cumulative Timesteps: 32,216,428
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 32216428...
Checkpoint 32216428 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42587
Policy Entropy: 5.01513
Value Function Loss: 0.07220
Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05003
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.05502
Collected Steps per Second: 10,884.40146
Overall Steps per Second: 8,589.31233
Timestep Collection Time: 4.59612
Timestep Consumption Time: 1.22810
PPO Batch Consumption Time: 0.05087
Total Iteration Time: 5.82421
Cumulative Model Updates: 1,930
Cumulative Timesteps: 32,266,454
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99815
Policy Entropy: 5.02700
Value Function Loss: 0.07234
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01513
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.05948
Collected Steps per Second: 11,081.78416
Overall Steps per Second: 8,734.62044
Timestep Collection Time: 4.51534
Timestep Consumption Time: 1.21336
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.72870
Cumulative Model Updates: 1,933
Cumulative Timesteps: 32,316,492
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 32316492...
Checkpoint 32316492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44795
Policy Entropy: 5.03249
Value Function Loss: 0.07874
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02432
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.06381
Collected Steps per Second: 11,212.93744
Overall Steps per Second: 8,805.08741
Timestep Collection Time: 4.45985
Timestep Consumption Time: 1.21960
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.67944
Cumulative Model Updates: 1,936
Cumulative Timesteps: 32,366,500
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.99434
Policy Entropy: 5.05384
Value Function Loss: 0.08600
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01968
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.06483
Collected Steps per Second: 10,872.61637
Overall Steps per Second: 8,614.62690
Timestep Collection Time: 4.60018
Timestep Consumption Time: 1.20576
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.80594
Cumulative Model Updates: 1,939
Cumulative Timesteps: 32,416,516
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 32416516...
Checkpoint 32416516 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42627
Policy Entropy: 5.02425
Value Function Loss: 0.08649
Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01243
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.06644
Collected Steps per Second: 11,047.77739
Overall Steps per Second: 8,867.58527
Timestep Collection Time: 4.53032
Timestep Consumption Time: 1.11383
PPO Batch Consumption Time: 0.05183
Total Iteration Time: 5.64415
Cumulative Model Updates: 1,942
Cumulative Timesteps: 32,466,566
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.51956
Policy Entropy: 5.02973
Value Function Loss: 0.06967
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02872
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.06239
Collected Steps per Second: 11,013.19816
Overall Steps per Second: 8,570.16255
Timestep Collection Time: 4.54146
Timestep Consumption Time: 1.29460
PPO Batch Consumption Time: 0.07867
Total Iteration Time: 5.83606
Cumulative Model Updates: 1,945
Cumulative Timesteps: 32,516,582
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 32516582...
Checkpoint 32516582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.33264
Policy Entropy: 5.08372
Value Function Loss: 0.06068
Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.03615
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.05838
Collected Steps per Second: 11,020.26997
Overall Steps per Second: 8,723.26910
Timestep Collection Time: 4.53855
Timestep Consumption Time: 1.19508
PPO Batch Consumption Time: 0.05204
Total Iteration Time: 5.73363
Cumulative Model Updates: 1,948
Cumulative Timesteps: 32,566,598
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59851
Policy Entropy: 5.06169
Value Function Loss: 0.05120
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01778
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.05968
Collected Steps per Second: 11,187.01626
Overall Steps per Second: 8,795.15304
Timestep Collection Time: 4.46947
Timestep Consumption Time: 1.21548
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.68495
Cumulative Model Updates: 1,951
Cumulative Timesteps: 32,616,598
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 32616598...
Checkpoint 32616598 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46715
Policy Entropy: 5.03091
Value Function Loss: 0.05606
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02884
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.05539
Collected Steps per Second: 10,961.90353
Overall Steps per Second: 8,618.69878
Timestep Collection Time: 4.56271
Timestep Consumption Time: 1.24048
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.80320
Cumulative Model Updates: 1,954
Cumulative Timesteps: 32,666,614
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60254
Policy Entropy: 5.07777
Value Function Loss: 0.06107
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.05155
Collected Steps per Second: 10,980.79474
Overall Steps per Second: 8,847.70656
Timestep Collection Time: 4.55650
Timestep Consumption Time: 1.09852
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.65502
Cumulative Model Updates: 1,957
Cumulative Timesteps: 32,716,648
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 32716648...
Checkpoint 32716648 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41647
Policy Entropy: 5.04479
Value Function Loss: 0.06413
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.05217
Collected Steps per Second: 10,942.00070
Overall Steps per Second: 8,637.00258
Timestep Collection Time: 4.57192
Timestep Consumption Time: 1.22013
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.79206
Cumulative Model Updates: 1,960
Cumulative Timesteps: 32,766,674
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57835
Policy Entropy: 5.00939
Value Function Loss: 0.06178
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02787
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.05732
Collected Steps per Second: 11,083.92623
Overall Steps per Second: 8,802.48825
Timestep Collection Time: 4.51591
Timestep Consumption Time: 1.17044
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.68635
Cumulative Model Updates: 1,963
Cumulative Timesteps: 32,816,728
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 32816728...
Checkpoint 32816728 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.06191
Policy Entropy: 5.05265
Value Function Loss: 0.06005
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01475
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.06283
Collected Steps per Second: 11,082.02770
Overall Steps per Second: 8,733.61835
Timestep Collection Time: 4.51307
Timestep Consumption Time: 1.21353
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.72661
Cumulative Model Updates: 1,966
Cumulative Timesteps: 32,866,742
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.24524
Policy Entropy: 5.09174
Value Function Loss: 0.06375
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.06436
Collected Steps per Second: 10,943.29419
Overall Steps per Second: 8,535.11072
Timestep Collection Time: 4.56956
Timestep Consumption Time: 1.28930
PPO Batch Consumption Time: 0.07334
Total Iteration Time: 5.85886
Cumulative Model Updates: 1,969
Cumulative Timesteps: 32,916,748
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 32916748...
Checkpoint 32916748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54540
Policy Entropy: 5.07056
Value Function Loss: 0.06343
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01724
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.06184
Collected Steps per Second: 10,997.18967
Overall Steps per Second: 8,846.48580
Timestep Collection Time: 4.54680
Timestep Consumption Time: 1.10539
PPO Batch Consumption Time: 0.05222
Total Iteration Time: 5.65219
Cumulative Model Updates: 1,972
Cumulative Timesteps: 32,966,750
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.18678
Policy Entropy: 5.07041
Value Function Loss: 0.06529
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01544
Policy Update Magnitude: 0.04205
Value Function Update Magnitude: 0.05413
Collected Steps per Second: 10,891.56160
Overall Steps per Second: 8,599.62755
Timestep Collection Time: 4.59181
Timestep Consumption Time: 1.22379
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.81560
Cumulative Model Updates: 1,975
Cumulative Timesteps: 33,016,762
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 33016762...
Checkpoint 33016762 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.49929
Policy Entropy: 5.06676
Value Function Loss: 0.05661
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03319
Policy Update Magnitude: 0.04335
Value Function Update Magnitude: 0.05808
Collected Steps per Second: 10,932.60055
Overall Steps per Second: 8,679.17652
Timestep Collection Time: 4.57695
Timestep Consumption Time: 1.18834
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.76529
Cumulative Model Updates: 1,978
Cumulative Timesteps: 33,066,800
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.51423
Policy Entropy: 5.04789
Value Function Loss: 0.06809
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.05824
Collected Steps per Second: 10,887.52069
Overall Steps per Second: 8,781.42467
Timestep Collection Time: 4.59646
Timestep Consumption Time: 1.10239
PPO Batch Consumption Time: 0.04905
Total Iteration Time: 5.69885
Cumulative Model Updates: 1,981
Cumulative Timesteps: 33,116,844
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 33116844...
Checkpoint 33116844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57994
Policy Entropy: 5.01562
Value Function Loss: 0.06944
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.04427
Value Function Update Magnitude: 0.05503
Collected Steps per Second: 10,999.34434
Overall Steps per Second: 8,654.72290
Timestep Collection Time: 4.54827
Timestep Consumption Time: 1.23216
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.78043
Cumulative Model Updates: 1,984
Cumulative Timesteps: 33,166,872
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60734
Policy Entropy: 5.02555
Value Function Loss: 0.08180
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01587
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.05744
Collected Steps per Second: 10,940.90397
Overall Steps per Second: 8,704.15880
Timestep Collection Time: 4.57586
Timestep Consumption Time: 1.17588
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.75173
Cumulative Model Updates: 1,987
Cumulative Timesteps: 33,216,936
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
Saving checkpoint 33216936...
Checkpoint 33216936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26403
Policy Entropy: 5.04730
Value Function Loss: 0.08144
Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.05603
Collected Steps per Second: 11,132.31874
Overall Steps per Second: 8,783.14179
Timestep Collection Time: 4.49215
Timestep Consumption Time: 1.20149
PPO Batch Consumption Time: 0.05045
Total Iteration Time: 5.69363
Cumulative Model Updates: 1,990
Cumulative Timesteps: 33,266,944
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.19671
Policy Entropy: 5.06954
Value Function Loss: 0.08149
Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.04863
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.05554
Collected Steps per Second: 11,116.39217
Overall Steps per Second: 8,638.67928
Timestep Collection Time: 4.49804
Timestep Consumption Time: 1.29011
PPO Batch Consumption Time: 0.07067
Total Iteration Time: 5.78815
Cumulative Model Updates: 1,993
Cumulative Timesteps: 33,316,946
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 33316946...
Checkpoint 33316946 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70627
Policy Entropy: 5.08069
Value Function Loss: 0.07024
Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.05680
Collected Steps per Second: 10,974.93638
Overall Steps per Second: 8,838.14274
Timestep Collection Time: 4.55984
Timestep Consumption Time: 1.10243
PPO Batch Consumption Time: 0.05308
Total Iteration Time: 5.66228
Cumulative Model Updates: 1,996
Cumulative Timesteps: 33,366,990
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50727
Policy Entropy: 5.09383
Value Function Loss: 0.06524
Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04115
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.05720
Collected Steps per Second: 10,793.24204
Overall Steps per Second: 8,542.97326
Timestep Collection Time: 4.63679
Timestep Consumption Time: 1.22136
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.85815
Cumulative Model Updates: 1,999
Cumulative Timesteps: 33,417,036
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 33417036...
Checkpoint 33417036 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.25589
Policy Entropy: 5.12628
Value Function Loss: 0.06482
Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04257
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.05805
Collected Steps per Second: 10,915.70964
Overall Steps per Second: 8,663.72888
Timestep Collection Time: 4.58110
Timestep Consumption Time: 1.19078
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.77188
Cumulative Model Updates: 2,002
Cumulative Timesteps: 33,467,042
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54221
Policy Entropy: 5.13383
Value Function Loss: 0.07476
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03382
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.06525
Collected Steps per Second: 11,162.33153
Overall Steps per Second: 8,810.30665
Timestep Collection Time: 4.48293
Timestep Consumption Time: 1.19678
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.67971
Cumulative Model Updates: 2,005
Cumulative Timesteps: 33,517,082
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 33517082...
Checkpoint 33517082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40497
Policy Entropy: 5.12308
Value Function Loss: 0.07018
Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.05896
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.06775
Collected Steps per Second: 11,025.36658
Overall Steps per Second: 8,702.54702
Timestep Collection Time: 4.53808
Timestep Consumption Time: 1.21127
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.74935
Cumulative Model Updates: 2,008
Cumulative Timesteps: 33,567,116
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39359
Policy Entropy: 5.13259
Value Function Loss: 0.06964
Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03989
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.06458
Collected Steps per Second: 11,036.72970
Overall Steps per Second: 8,759.88883
Timestep Collection Time: 4.53178
Timestep Consumption Time: 1.17788
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.70966
Cumulative Model Updates: 2,011
Cumulative Timesteps: 33,617,132
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 33617132...
Checkpoint 33617132 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42881
Policy Entropy: 5.14801
Value Function Loss: 0.06414
Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05351
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.06595
Collected Steps per Second: 11,175.64355
Overall Steps per Second: 8,784.23046
Timestep Collection Time: 4.47437
Timestep Consumption Time: 1.21810
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.69247
Cumulative Model Updates: 2,014
Cumulative Timesteps: 33,667,136
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41029
Policy Entropy: 5.10875
Value Function Loss: 0.06741
Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04101
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.06582
Collected Steps per Second: 10,994.16550
Overall Steps per Second: 8,610.27430
Timestep Collection Time: 4.55187
Timestep Consumption Time: 1.26026
PPO Batch Consumption Time: 0.07833
Total Iteration Time: 5.81213
Cumulative Model Updates: 2,017
Cumulative Timesteps: 33,717,180
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 33717180...
Checkpoint 33717180 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50506
Policy Entropy: 5.13859
Value Function Loss: 0.06386
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.06829
Collected Steps per Second: 10,894.50727
Overall Steps per Second: 8,752.75743
Timestep Collection Time: 4.59369
Timestep Consumption Time: 1.12405
PPO Batch Consumption Time: 0.05306
Total Iteration Time: 5.71774
Cumulative Model Updates: 2,020
Cumulative Timesteps: 33,767,226
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.35604
Policy Entropy: 5.15894
Value Function Loss: 0.06146
Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05018
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.06558
Collected Steps per Second: 11,030.93124
Overall Steps per Second: 8,706.94292
Timestep Collection Time: 4.53525
Timestep Consumption Time: 1.21051
PPO Batch Consumption Time: 0.05122
Total Iteration Time: 5.74576
Cumulative Model Updates: 2,023
Cumulative Timesteps: 33,817,254
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 33817254...
Checkpoint 33817254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48316
Policy Entropy: 5.13495
Value Function Loss: 0.05795
Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03923
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.05730
Collected Steps per Second: 10,827.25658
Overall Steps per Second: 8,628.62008
Timestep Collection Time: 4.61816
Timestep Consumption Time: 1.17674
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.79490
Cumulative Model Updates: 2,026
Cumulative Timesteps: 33,867,256
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.71521
Policy Entropy: 5.18057
Value Function Loss: 0.06404
Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04335
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.05373
Collected Steps per Second: 11,124.75526
Overall Steps per Second: 8,750.40423
Timestep Collection Time: 4.49880
Timestep Consumption Time: 1.22071
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.71951
Cumulative Model Updates: 2,029
Cumulative Timesteps: 33,917,304
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 33917304...
Checkpoint 33917304 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.95627
Policy Entropy: 5.19103
Value Function Loss: 0.06515
Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05203
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.05411
Collected Steps per Second: 11,024.04174
Overall Steps per Second: 8,690.70038
Timestep Collection Time: 4.53881
Timestep Consumption Time: 1.21861
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.75742
Cumulative Model Updates: 2,032
Cumulative Timesteps: 33,967,340
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.30902
Policy Entropy: 5.15528
Value Function Loss: 0.06824
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02027
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.05820
Collected Steps per Second: 11,017.89843
Overall Steps per Second: 8,849.85821
Timestep Collection Time: 4.54352
Timestep Consumption Time: 1.11307
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.65659
Cumulative Model Updates: 2,035
Cumulative Timesteps: 34,017,400
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 34017400...
Checkpoint 34017400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.22782
Policy Entropy: 5.12226
Value Function Loss: 0.06529
Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03740
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.06936
Collected Steps per Second: 11,035.04331
Overall Steps per Second: 8,685.78401
Timestep Collection Time: 4.53446
Timestep Consumption Time: 1.22644
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76091
Cumulative Model Updates: 2,038
Cumulative Timesteps: 34,067,438
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52216
Policy Entropy: 5.11514
Value Function Loss: 0.07162
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.01425
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.06825
Collected Steps per Second: 10,922.87884
Overall Steps per Second: 8,578.41979
Timestep Collection Time: 4.57755
Timestep Consumption Time: 1.25103
PPO Batch Consumption Time: 0.07367
Total Iteration Time: 5.82858
Cumulative Model Updates: 2,041
Cumulative Timesteps: 34,117,438
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 34117438...
Checkpoint 34117438 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61026
Policy Entropy: 5.11303
Value Function Loss: 0.06760
Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01394
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.06503
Collected Steps per Second: 10,931.55312
Overall Steps per Second: 8,768.44936
Timestep Collection Time: 4.57593
Timestep Consumption Time: 1.12884
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.70477
Cumulative Model Updates: 2,044
Cumulative Timesteps: 34,167,460
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63417
Policy Entropy: 5.13058
Value Function Loss: 0.06121
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02621
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.06312
Collected Steps per Second: 10,910.74808
Overall Steps per Second: 8,624.98000
Timestep Collection Time: 4.58612
Timestep Consumption Time: 1.21540
PPO Batch Consumption Time: 0.05173
Total Iteration Time: 5.80152
Cumulative Model Updates: 2,047
Cumulative Timesteps: 34,217,498
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 34217498...
Checkpoint 34217498 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.29779
Policy Entropy: 5.12593
Value Function Loss: 0.05102
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.06241
Collected Steps per Second: 10,998.44111
Overall Steps per Second: 8,715.33295
Timestep Collection Time: 4.54774
Timestep Consumption Time: 1.19135
PPO Batch Consumption Time: 0.05110
Total Iteration Time: 5.73908
Cumulative Model Updates: 2,050
Cumulative Timesteps: 34,267,516
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68652
Policy Entropy: 5.09357
Value Function Loss: 0.05329
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01643
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.05884
Collected Steps per Second: 11,092.16059
Overall Steps per Second: 8,785.83158
Timestep Collection Time: 4.51075
Timestep Consumption Time: 1.18410
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.69485
Cumulative Model Updates: 2,053
Cumulative Timesteps: 34,317,550
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 34317550...
Checkpoint 34317550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.91210
Policy Entropy: 5.09040
Value Function Loss: 0.05952
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.05658
Collected Steps per Second: 10,934.63482
Overall Steps per Second: 8,638.63235
Timestep Collection Time: 4.57939
Timestep Consumption Time: 1.21713
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.79652
Cumulative Model Updates: 2,056
Cumulative Timesteps: 34,367,624
Timesteps Collected: 50,074
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52988
Policy Entropy: 5.11639
Value Function Loss: 0.06558
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02479
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.06115
Collected Steps per Second: 11,048.38506
Overall Steps per Second: 8,871.53223
Timestep Collection Time: 4.52736
Timestep Consumption Time: 1.11090
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.63826
Cumulative Model Updates: 2,059
Cumulative Timesteps: 34,417,644
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 34417644...
Checkpoint 34417644 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64523
Policy Entropy: 5.11832
Value Function Loss: 0.07229
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02089
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.06669
Collected Steps per Second: 10,970.10742
Overall Steps per Second: 8,652.01538
Timestep Collection Time: 4.56039
Timestep Consumption Time: 1.22184
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.78224
Cumulative Model Updates: 2,062
Cumulative Timesteps: 34,467,672
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41225
Policy Entropy: 5.14591
Value Function Loss: 0.07462
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01763
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.06100
Collected Steps per Second: 11,050.99606
Overall Steps per Second: 8,653.11234
Timestep Collection Time: 4.52828
Timestep Consumption Time: 1.25484
PPO Batch Consumption Time: 0.07100
Total Iteration Time: 5.78312
Cumulative Model Updates: 2,065
Cumulative Timesteps: 34,517,714
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 34517714...
Checkpoint 34517714 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.27896
Policy Entropy: 5.17109
Value Function Loss: 0.06694
Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01499
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.06575
Collected Steps per Second: 11,044.27738
Overall Steps per Second: 8,856.95891
Timestep Collection Time: 4.53158
Timestep Consumption Time: 1.11912
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.65070
Cumulative Model Updates: 2,068
Cumulative Timesteps: 34,567,762
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41302
Policy Entropy: 5.17598
Value Function Loss: 0.05754
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02085
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.06565
Collected Steps per Second: 11,031.90192
Overall Steps per Second: 8,723.94473
Timestep Collection Time: 4.53358
Timestep Consumption Time: 1.19938
PPO Batch Consumption Time: 0.04957
Total Iteration Time: 5.73296
Cumulative Model Updates: 2,071
Cumulative Timesteps: 34,617,776
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 34617776...
Checkpoint 34617776 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41850
Policy Entropy: 5.17654
Value Function Loss: 0.05705
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01626
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.06005
Collected Steps per Second: 10,899.26237
Overall Steps per Second: 8,678.89235
Timestep Collection Time: 4.58857
Timestep Consumption Time: 1.17392
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76249
Cumulative Model Updates: 2,074
Cumulative Timesteps: 34,667,788
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.15650
Policy Entropy: 5.18196
Value Function Loss: 0.06448
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.05482
Collected Steps per Second: 11,107.19734
Overall Steps per Second: 8,774.99464
Timestep Collection Time: 4.50177
Timestep Consumption Time: 1.19647
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.69824
Cumulative Model Updates: 2,077
Cumulative Timesteps: 34,717,790
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 34717790...
Checkpoint 34717790 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.24225
Policy Entropy: 5.18963
Value Function Loss: 0.06873
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01987
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.05113
Collected Steps per Second: 10,896.76673
Overall Steps per Second: 8,582.18427
Timestep Collection Time: 4.58962
Timestep Consumption Time: 1.23780
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.82742
Cumulative Model Updates: 2,080
Cumulative Timesteps: 34,767,802
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42851
Policy Entropy: 5.19240
Value Function Loss: 0.06872
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03099
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.05780
Collected Steps per Second: 10,937.67991
Overall Steps per Second: 8,833.66383
Timestep Collection Time: 4.57446
Timestep Consumption Time: 1.08955
PPO Batch Consumption Time: 0.05107
Total Iteration Time: 5.66401
Cumulative Model Updates: 2,083
Cumulative Timesteps: 34,817,836
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 34817836...
Checkpoint 34817836 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.29627
Policy Entropy: 5.21426
Value Function Loss: 0.07101
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02190
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.05929
Collected Steps per Second: 10,979.14174
Overall Steps per Second: 8,696.87937
Timestep Collection Time: 4.55427
Timestep Consumption Time: 1.19515
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.74942
Cumulative Model Updates: 2,086
Cumulative Timesteps: 34,867,838
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78559
Policy Entropy: 5.21066
Value Function Loss: 0.07502
Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04330
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.06494
Collected Steps per Second: 11,045.02925
Overall Steps per Second: 8,639.38062
Timestep Collection Time: 4.52910
Timestep Consumption Time: 1.26113
PPO Batch Consumption Time: 0.08000
Total Iteration Time: 5.79023
Cumulative Model Updates: 2,089
Cumulative Timesteps: 34,917,862
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 34917862...
Checkpoint 34917862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89336
Policy Entropy: 5.21371
Value Function Loss: 0.07445
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.05906
Value Function Update Magnitude: 0.06863
Collected Steps per Second: 11,117.76465
Overall Steps per Second: 8,725.41306
Timestep Collection Time: 4.50037
Timestep Consumption Time: 1.23392
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.73428
Cumulative Model Updates: 2,092
Cumulative Timesteps: 34,967,896
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26057
Policy Entropy: 5.24270
Value Function Loss: 0.06836
Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04311
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.06675
Collected Steps per Second: 10,980.09896
Overall Steps per Second: 8,659.73831
Timestep Collection Time: 4.55934
Timestep Consumption Time: 1.22167
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.78101
Cumulative Model Updates: 2,095
Cumulative Timesteps: 35,017,958
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
Saving checkpoint 35017958...
Checkpoint 35017958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40001
Policy Entropy: 5.24530
Value Function Loss: 0.06435
Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05724
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.06270
Collected Steps per Second: 11,047.04656
Overall Steps per Second: 8,748.16649
Timestep Collection Time: 4.52646
Timestep Consumption Time: 1.18948
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.71594
Cumulative Model Updates: 2,098
Cumulative Timesteps: 35,067,962
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.34253
Policy Entropy: 5.23236
Value Function Loss: 0.06807
Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04400
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.06434
Collected Steps per Second: 11,252.47993
Overall Steps per Second: 8,845.56406
Timestep Collection Time: 4.44560
Timestep Consumption Time: 1.20967
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.65526
Cumulative Model Updates: 2,101
Cumulative Timesteps: 35,117,986
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 35117986...
Checkpoint 35117986 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47196
Policy Entropy: 5.23858
Value Function Loss: 0.07213
Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.04689
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.06412
Collected Steps per Second: 11,041.91289
Overall Steps per Second: 8,676.95854
Timestep Collection Time: 4.53200
Timestep Consumption Time: 1.23522
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.76723
Cumulative Model Updates: 2,104
Cumulative Timesteps: 35,168,028
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42552
Policy Entropy: 5.23329
Value Function Loss: 0.07457
Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04339
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.06155
Collected Steps per Second: 11,018.40388
Overall Steps per Second: 8,849.17021
Timestep Collection Time: 4.53986
Timestep Consumption Time: 1.11287
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.65273
Cumulative Model Updates: 2,107
Cumulative Timesteps: 35,218,050
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 35218050...
Checkpoint 35218050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54897
Policy Entropy: 5.19661
Value Function Loss: 0.07897
Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04574
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.06255
Collected Steps per Second: 10,971.43802
Overall Steps per Second: 8,668.41077
Timestep Collection Time: 4.55820
Timestep Consumption Time: 1.21102
PPO Batch Consumption Time: 0.05122
Total Iteration Time: 5.76922
Cumulative Model Updates: 2,110
Cumulative Timesteps: 35,268,060
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46934
Policy Entropy: 5.21753
Value Function Loss: 0.07823
Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03467
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.06265
Collected Steps per Second: 10,934.57421
Overall Steps per Second: 8,584.24370
Timestep Collection Time: 4.57686
Timestep Consumption Time: 1.25312
PPO Batch Consumption Time: 0.07333
Total Iteration Time: 5.82998
Cumulative Model Updates: 2,113
Cumulative Timesteps: 35,318,106
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 35318106...
Checkpoint 35318106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.51143
Policy Entropy: 5.20892
Value Function Loss: 0.07318
Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.04608
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.06275
Collected Steps per Second: 11,160.58331
Overall Steps per Second: 8,777.57264
Timestep Collection Time: 4.48220
Timestep Consumption Time: 1.21687
PPO Batch Consumption Time: 0.05285
Total Iteration Time: 5.69907
Cumulative Model Updates: 2,116
Cumulative Timesteps: 35,368,130
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53636
Policy Entropy: 5.19375
Value Function Loss: 0.06524
Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04116
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.05385
Collected Steps per Second: 10,948.84694
Overall Steps per Second: 8,638.00131
Timestep Collection Time: 4.56742
Timestep Consumption Time: 1.22188
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.78930
Cumulative Model Updates: 2,119
Cumulative Timesteps: 35,418,138
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 35418138...
Checkpoint 35418138 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39792
Policy Entropy: 5.18553
Value Function Loss: 0.05902
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02641
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.05245
Collected Steps per Second: 10,835.76487
Overall Steps per Second: 8,621.21374
Timestep Collection Time: 4.61453
Timestep Consumption Time: 1.18535
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.79988
Cumulative Model Updates: 2,122
Cumulative Timesteps: 35,468,140
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.33061
Policy Entropy: 5.19195
Value Function Loss: 0.06097
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.04696
Collected Steps per Second: 11,035.78505
Overall Steps per Second: 8,734.89642
Timestep Collection Time: 4.53144
Timestep Consumption Time: 1.19364
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.72508
Cumulative Model Updates: 2,125
Cumulative Timesteps: 35,518,148
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 35518148...
Checkpoint 35518148 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.07585
Policy Entropy: 5.17539
Value Function Loss: 0.06108
Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03633
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.04984
Collected Steps per Second: 11,026.13145
Overall Steps per Second: 8,742.65541
Timestep Collection Time: 4.53922
Timestep Consumption Time: 1.18559
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.72481
Cumulative Model Updates: 2,128
Cumulative Timesteps: 35,568,198
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26043
Policy Entropy: 5.20514
Value Function Loss: 0.05951
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.04720
Collected Steps per Second: 10,886.39909
Overall Steps per Second: 8,822.92880
Timestep Collection Time: 4.59619
Timestep Consumption Time: 1.07494
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.67113
Cumulative Model Updates: 2,131
Cumulative Timesteps: 35,618,234
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 35618234...
Checkpoint 35618234 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68319
Policy Entropy: 5.21722
Value Function Loss: 0.05596
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.04905
Collected Steps per Second: 11,030.37809
Overall Steps per Second: 8,676.10232
Timestep Collection Time: 4.53620
Timestep Consumption Time: 1.23091
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.76711
Cumulative Model Updates: 2,134
Cumulative Timesteps: 35,668,270
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.36505
Policy Entropy: 5.21236
Value Function Loss: 0.05235
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02009
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.05072
Collected Steps per Second: 10,915.65947
Overall Steps per Second: 8,519.18918
Timestep Collection Time: 4.58387
Timestep Consumption Time: 1.28946
PPO Batch Consumption Time: 0.08191
Total Iteration Time: 5.87333
Cumulative Model Updates: 2,137
Cumulative Timesteps: 35,718,306
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 35718306...
Checkpoint 35718306 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.23692
Policy Entropy: 5.20874
Value Function Loss: 0.05469
Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01299
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.05523
Collected Steps per Second: 11,076.37895
Overall Steps per Second: 8,702.15853
Timestep Collection Time: 4.51935
Timestep Consumption Time: 1.23302
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.75237
Cumulative Model Updates: 2,140
Cumulative Timesteps: 35,768,364
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.37130
Policy Entropy: 5.20546
Value Function Loss: 0.05284
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.05301
Collected Steps per Second: 10,967.50991
Overall Steps per Second: 8,677.56212
Timestep Collection Time: 4.55965
Timestep Consumption Time: 1.20326
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.76291
Cumulative Model Updates: 2,143
Cumulative Timesteps: 35,818,372
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 35818372...
Checkpoint 35818372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.43218
Policy Entropy: 5.19792
Value Function Loss: 0.05507
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01911
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.05253
Collected Steps per Second: 10,889.75633
Overall Steps per Second: 8,665.54728
Timestep Collection Time: 4.59533
Timestep Consumption Time: 1.17949
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.77482
Cumulative Model Updates: 2,146
Cumulative Timesteps: 35,868,414
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.72800
Policy Entropy: 5.21605
Value Function Loss: 0.06021
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02581
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.05364
Collected Steps per Second: 11,186.54534
Overall Steps per Second: 8,804.37093
Timestep Collection Time: 4.47162
Timestep Consumption Time: 1.20987
PPO Batch Consumption Time: 0.04985
Total Iteration Time: 5.68150
Cumulative Model Updates: 2,149
Cumulative Timesteps: 35,918,436
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 35918436...
Checkpoint 35918436 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.30052
Policy Entropy: 5.25729
Value Function Loss: 0.06457
Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01047
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.05803
Collected Steps per Second: 10,934.24461
Overall Steps per Second: 8,717.45297
Timestep Collection Time: 4.57444
Timestep Consumption Time: 1.16325
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.73769
Cumulative Model Updates: 2,152
Cumulative Timesteps: 35,968,454
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.30584
Policy Entropy: 5.26419
Value Function Loss: 0.06829
Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01206
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.05638
Collected Steps per Second: 10,891.75990
Overall Steps per Second: 8,768.46809
Timestep Collection Time: 4.59099
Timestep Consumption Time: 1.11171
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.70271
Cumulative Model Updates: 2,155
Cumulative Timesteps: 36,018,458
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 36018458...
Checkpoint 36018458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.28009
Policy Entropy: 5.27782
Value Function Loss: 0.06019
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01755
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.06055
Collected Steps per Second: 10,927.60258
Overall Steps per Second: 8,614.05010
Timestep Collection Time: 4.57850
Timestep Consumption Time: 1.22969
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.80819
Cumulative Model Updates: 2,158
Cumulative Timesteps: 36,068,490
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41848
Policy Entropy: 5.26050
Value Function Loss: 0.06086
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01606
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.06875
Collected Steps per Second: 10,888.81693
Overall Steps per Second: 8,531.12589
Timestep Collection Time: 4.59536
Timestep Consumption Time: 1.26999
PPO Batch Consumption Time: 0.07400
Total Iteration Time: 5.86535
Cumulative Model Updates: 2,161
Cumulative Timesteps: 36,118,528
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 36118528...
Checkpoint 36118528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.07455
Policy Entropy: 5.22839
Value Function Loss: 0.06506
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.06954
Collected Steps per Second: 11,109.02216
Overall Steps per Second: 8,709.72808
Timestep Collection Time: 4.50625
Timestep Consumption Time: 1.24135
PPO Batch Consumption Time: 0.05301
Total Iteration Time: 5.74760
Cumulative Model Updates: 2,164
Cumulative Timesteps: 36,168,588
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75177
Policy Entropy: 5.20433
Value Function Loss: 0.06965
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01267
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.06847
Collected Steps per Second: 10,979.42056
Overall Steps per Second: 8,678.00801
Timestep Collection Time: 4.55525
Timestep Consumption Time: 1.20805
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.76330
Cumulative Model Updates: 2,167
Cumulative Timesteps: 36,218,602
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 36218602...
Checkpoint 36218602 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.56500
Policy Entropy: 5.22428
Value Function Loss: 0.07327
Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03577
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.06189
Collected Steps per Second: 10,946.79800
Overall Steps per Second: 8,827.79325
Timestep Collection Time: 4.56864
Timestep Consumption Time: 1.09665
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.66529
Cumulative Model Updates: 2,170
Cumulative Timesteps: 36,268,614
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62434
Policy Entropy: 5.23303
Value Function Loss: 0.06625
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01745
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.05711
Collected Steps per Second: 10,863.39207
Overall Steps per Second: 8,622.11803
Timestep Collection Time: 4.60427
Timestep Consumption Time: 1.19686
PPO Batch Consumption Time: 0.05006
Total Iteration Time: 5.80113
Cumulative Model Updates: 2,173
Cumulative Timesteps: 36,318,632
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 36318632...
Checkpoint 36318632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88213
Policy Entropy: 5.22203
Value Function Loss: 0.06733
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03689
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.05262
Collected Steps per Second: 10,819.09038
Overall Steps per Second: 8,637.43221
Timestep Collection Time: 4.62460
Timestep Consumption Time: 1.16809
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.79269
Cumulative Model Updates: 2,176
Cumulative Timesteps: 36,368,666
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60551
Policy Entropy: 5.22447
Value Function Loss: 0.06478
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02150
Policy Update Magnitude: 0.04240
Value Function Update Magnitude: 0.04954
Collected Steps per Second: 10,832.98004
Overall Steps per Second: 8,730.65226
Timestep Collection Time: 4.61867
Timestep Consumption Time: 1.11217
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.73084
Cumulative Model Updates: 2,179
Cumulative Timesteps: 36,418,700
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 36418700...
Checkpoint 36418700 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48014
Policy Entropy: 5.23209
Value Function Loss: 0.06524
Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.00773
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.04419
Collected Steps per Second: 10,984.53622
Overall Steps per Second: 8,634.45681
Timestep Collection Time: 4.55349
Timestep Consumption Time: 1.23934
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.79284
Cumulative Model Updates: 2,182
Cumulative Timesteps: 36,468,718
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.18532
Policy Entropy: 5.21092
Value Function Loss: 0.05954
Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01110
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.04666
Collected Steps per Second: 11,020.64376
Overall Steps per Second: 8,630.42861
Timestep Collection Time: 4.53730
Timestep Consumption Time: 1.25662
PPO Batch Consumption Time: 0.07579
Total Iteration Time: 5.79392
Cumulative Model Updates: 2,185
Cumulative Timesteps: 36,518,722
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 36518722...
Checkpoint 36518722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.32583
Policy Entropy: 5.19655
Value Function Loss: 0.05745
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02303
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.05795
Collected Steps per Second: 11,206.22860
Overall Steps per Second: 8,790.76084
Timestep Collection Time: 4.46305
Timestep Consumption Time: 1.22633
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.68938
Cumulative Model Updates: 2,188
Cumulative Timesteps: 36,568,736
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48281
Policy Entropy: 5.19758
Value Function Loss: 0.05014
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01269
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.06157
Collected Steps per Second: 10,971.74307
Overall Steps per Second: 8,633.49500
Timestep Collection Time: 4.55898
Timestep Consumption Time: 1.23473
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.79371
Cumulative Model Updates: 2,191
Cumulative Timesteps: 36,618,756
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 36618756...
Checkpoint 36618756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79091
Policy Entropy: 5.21787
Value Function Loss: 0.05824
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.05904
Collected Steps per Second: 10,879.31615
Overall Steps per Second: 8,773.08170
Timestep Collection Time: 4.59900
Timestep Consumption Time: 1.10412
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.70313
Cumulative Model Updates: 2,194
Cumulative Timesteps: 36,668,790
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.99710
Policy Entropy: 5.19628
Value Function Loss: 0.05841
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.04710
Collected Steps per Second: 10,994.85727
Overall Steps per Second: 8,701.18231
Timestep Collection Time: 4.55122
Timestep Consumption Time: 1.19972
PPO Batch Consumption Time: 0.05038
Total Iteration Time: 5.75094
Cumulative Model Updates: 2,197
Cumulative Timesteps: 36,718,830
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 36718830...
Checkpoint 36718830 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.73700
Policy Entropy: 5.19469
Value Function Loss: 0.06511
Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04533
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.05128
Collected Steps per Second: 10,962.89497
Overall Steps per Second: 8,710.54433
Timestep Collection Time: 4.56358
Timestep Consumption Time: 1.18004
PPO Batch Consumption Time: 0.04946
Total Iteration Time: 5.74361
Cumulative Model Updates: 2,200
Cumulative Timesteps: 36,768,860
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.76097
Policy Entropy: 5.18150
Value Function Loss: 0.06563
Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04242
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.04682
Collected Steps per Second: 11,108.84219
Overall Steps per Second: 8,714.04077
Timestep Collection Time: 4.50092
Timestep Consumption Time: 1.23695
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.73787
Cumulative Model Updates: 2,203
Cumulative Timesteps: 36,818,860
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 36818860...
Checkpoint 36818860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53670
Policy Entropy: 5.18318
Value Function Loss: 0.06495
Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.05920
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.04414
Collected Steps per Second: 10,978.96575
Overall Steps per Second: 8,666.01729
Timestep Collection Time: 4.55926
Timestep Consumption Time: 1.21686
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.77613
Cumulative Model Updates: 2,206
Cumulative Timesteps: 36,868,916
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26904
Policy Entropy: 5.16051
Value Function Loss: 0.06521
Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04638
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.04791
Collected Steps per Second: 10,970.51079
Overall Steps per Second: 8,567.31499
Timestep Collection Time: 4.55968
Timestep Consumption Time: 1.27902
PPO Batch Consumption Time: 0.07633
Total Iteration Time: 5.83870
Cumulative Model Updates: 2,209
Cumulative Timesteps: 36,918,938
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 36918938...
Checkpoint 36918938 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88189
Policy Entropy: 5.18223
Value Function Loss: 0.05781
Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03751
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.04545
Collected Steps per Second: 11,227.67074
Overall Steps per Second: 8,831.74377
Timestep Collection Time: 4.45542
Timestep Consumption Time: 1.20869
PPO Batch Consumption Time: 0.05302
Total Iteration Time: 5.66411
Cumulative Model Updates: 2,212
Cumulative Timesteps: 36,968,962
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48890
Policy Entropy: 5.14829
Value Function Loss: 0.05130
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.04723
Collected Steps per Second: 11,024.01664
Overall Steps per Second: 8,680.33097
Timestep Collection Time: 4.53773
Timestep Consumption Time: 1.22518
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.76291
Cumulative Model Updates: 2,215
Cumulative Timesteps: 37,018,986
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 37018986...
Checkpoint 37018986 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80800
Policy Entropy: 5.16458
Value Function Loss: 0.04684
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.04755
Collected Steps per Second: 11,019.65453
Overall Steps per Second: 8,812.72529
Timestep Collection Time: 4.53807
Timestep Consumption Time: 1.13645
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.67452
Cumulative Model Updates: 2,218
Cumulative Timesteps: 37,068,994
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61498
Policy Entropy: 5.18300
Value Function Loss: 0.04539
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.04664
Collected Steps per Second: 10,945.96525
Overall Steps per Second: 8,650.75522
Timestep Collection Time: 4.57045
Timestep Consumption Time: 1.21263
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.78308
Cumulative Model Updates: 2,221
Cumulative Timesteps: 37,119,022
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 37119022...
Checkpoint 37119022 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50192
Policy Entropy: 5.19145
Value Function Loss: 0.04256
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01728
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.04694
Collected Steps per Second: 10,947.27146
Overall Steps per Second: 8,713.02927
Timestep Collection Time: 4.57173
Timestep Consumption Time: 1.17231
PPO Batch Consumption Time: 0.04922
Total Iteration Time: 5.74404
Cumulative Model Updates: 2,224
Cumulative Timesteps: 37,169,070
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.94119
Policy Entropy: 5.17848
Value Function Loss: 0.04888
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01680
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.04176
Collected Steps per Second: 11,120.21403
Overall Steps per Second: 8,783.35330
Timestep Collection Time: 4.49722
Timestep Consumption Time: 1.19651
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69373
Cumulative Model Updates: 2,227
Cumulative Timesteps: 37,219,080
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 37219080...
Checkpoint 37219080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46695
Policy Entropy: 5.15283
Value Function Loss: 0.05848
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03232
Policy Update Magnitude: 0.04494
Value Function Update Magnitude: 0.03981
Collected Steps per Second: 10,909.90483
Overall Steps per Second: 8,619.71236
Timestep Collection Time: 4.58299
Timestep Consumption Time: 1.21767
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.80066
Cumulative Model Updates: 2,230
Cumulative Timesteps: 37,269,080
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66761
Policy Entropy: 5.15648
Value Function Loss: 0.07133
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03511
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.05553
Collected Steps per Second: 10,829.19750
Overall Steps per Second: 8,505.79200
Timestep Collection Time: 4.61844
Timestep Consumption Time: 1.26155
PPO Batch Consumption Time: 0.07841
Total Iteration Time: 5.87999
Cumulative Model Updates: 2,233
Cumulative Timesteps: 37,319,094
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 37319094...
Checkpoint 37319094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98757
Policy Entropy: 5.15342
Value Function Loss: 0.07208
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03295
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.05399
Collected Steps per Second: 11,174.07636
Overall Steps per Second: 8,754.02583
Timestep Collection Time: 4.48055
Timestep Consumption Time: 1.23865
PPO Batch Consumption Time: 0.05269
Total Iteration Time: 5.71920
Cumulative Model Updates: 2,236
Cumulative Timesteps: 37,369,160
Timesteps Collected: 50,066
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54835
Policy Entropy: 5.19773
Value Function Loss: 0.06038
Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03859
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.05165
Collected Steps per Second: 10,963.10822
Overall Steps per Second: 8,635.37235
Timestep Collection Time: 4.56148
Timestep Consumption Time: 1.22958
PPO Batch Consumption Time: 0.05082
Total Iteration Time: 5.79106
Cumulative Model Updates: 2,239
Cumulative Timesteps: 37,419,168
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 37419168...
Checkpoint 37419168 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57202
Policy Entropy: 5.20569
Value Function Loss: 0.05853
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02094
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.04771
Collected Steps per Second: 11,010.01609
Overall Steps per Second: 8,851.87747
Timestep Collection Time: 4.54259
Timestep Consumption Time: 1.10751
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.65010
Cumulative Model Updates: 2,242
Cumulative Timesteps: 37,469,182
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26326
Policy Entropy: 5.20243
Value Function Loss: 0.05802
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02140
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.05290
Collected Steps per Second: 11,015.09189
Overall Steps per Second: 8,698.68603
Timestep Collection Time: 4.54141
Timestep Consumption Time: 1.20935
PPO Batch Consumption Time: 0.05053
Total Iteration Time: 5.75075
Cumulative Model Updates: 2,245
Cumulative Timesteps: 37,519,206
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 37519206...
Checkpoint 37519206 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.28150
Policy Entropy: 5.19838
Value Function Loss: 0.06012
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01988
Policy Update Magnitude: 0.04618
Value Function Update Magnitude: 0.06050
Collected Steps per Second: 10,954.78648
Overall Steps per Second: 8,691.81512
Timestep Collection Time: 4.56787
Timestep Consumption Time: 1.18927
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.75714
Cumulative Model Updates: 2,248
Cumulative Timesteps: 37,569,246
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52212
Policy Entropy: 5.22468
Value Function Loss: 0.05677
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01393
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.06155
Collected Steps per Second: 11,105.31231
Overall Steps per Second: 8,749.45769
Timestep Collection Time: 4.50361
Timestep Consumption Time: 1.21263
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.71624
Cumulative Model Updates: 2,251
Cumulative Timesteps: 37,619,260
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 37619260...
Checkpoint 37619260 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.38772
Policy Entropy: 5.25860
Value Function Loss: 0.05474
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01537
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.06091
Collected Steps per Second: 10,953.34564
Overall Steps per Second: 8,643.97014
Timestep Collection Time: 4.56536
Timestep Consumption Time: 1.21971
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78507
Cumulative Model Updates: 2,254
Cumulative Timesteps: 37,669,266
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67301
Policy Entropy: 5.27888
Value Function Loss: 0.05342
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.06123
Collected Steps per Second: 11,004.60591
Overall Steps per Second: 8,597.87260
Timestep Collection Time: 4.54410
Timestep Consumption Time: 1.27199
PPO Batch Consumption Time: 0.07800
Total Iteration Time: 5.81609
Cumulative Model Updates: 2,257
Cumulative Timesteps: 37,719,272
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 37719272...
Checkpoint 37719272 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 1.94491
Policy Entropy: 5.28228
Value Function Loss: 0.05509
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02139
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.06265
Collected Steps per Second: 11,154.08566
Overall Steps per Second: 8,783.32656
Timestep Collection Time: 4.48643
Timestep Consumption Time: 1.21096
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.69739
Cumulative Model Updates: 2,260
Cumulative Timesteps: 37,769,314
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83563
Policy Entropy: 5.28987
Value Function Loss: 0.04896
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.05916
Collected Steps per Second: 10,943.50424
Overall Steps per Second: 8,644.01703
Timestep Collection Time: 4.57239
Timestep Consumption Time: 1.21635
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.78874
Cumulative Model Updates: 2,263
Cumulative Timesteps: 37,819,352
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 37819352...
Checkpoint 37819352 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52064
Policy Entropy: 5.28258
Value Function Loss: 0.05668
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03045
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.06582
Collected Steps per Second: 11,032.84148
Overall Steps per Second: 8,822.86276
Timestep Collection Time: 4.53573
Timestep Consumption Time: 1.13612
PPO Batch Consumption Time: 0.05055
Total Iteration Time: 5.67186
Cumulative Model Updates: 2,266
Cumulative Timesteps: 37,869,394
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.34812
Policy Entropy: 5.29459
Value Function Loss: 0.05606
Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06445
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.07135
Collected Steps per Second: 10,974.68032
Overall Steps per Second: 8,657.54154
Timestep Collection Time: 4.55612
Timestep Consumption Time: 1.21942
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.77554
Cumulative Model Updates: 2,269
Cumulative Timesteps: 37,919,396
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 37919396...
Checkpoint 37919396 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39108
Policy Entropy: 5.28968
Value Function Loss: 0.05991
Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04627
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.07299
Collected Steps per Second: 11,027.80402
Overall Steps per Second: 8,729.75050
Timestep Collection Time: 4.53962
Timestep Consumption Time: 1.19503
PPO Batch Consumption Time: 0.05110
Total Iteration Time: 5.73464
Cumulative Model Updates: 2,272
Cumulative Timesteps: 37,969,458
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53961
Policy Entropy: 5.28415
Value Function Loss: 0.05986
Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04539
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.07827
Collected Steps per Second: 11,160.84577
Overall Steps per Second: 8,767.41505
Timestep Collection Time: 4.48192
Timestep Consumption Time: 1.22353
PPO Batch Consumption Time: 0.05046
Total Iteration Time: 5.70544
Cumulative Model Updates: 2,275
Cumulative Timesteps: 38,019,480
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 38019480...
Checkpoint 38019480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78014
Policy Entropy: 5.25668
Value Function Loss: 0.05657
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01625
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.07357
Collected Steps per Second: 11,015.91096
Overall Steps per Second: 8,655.96513
Timestep Collection Time: 4.54161
Timestep Consumption Time: 1.23822
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.77983
Cumulative Model Updates: 2,278
Cumulative Timesteps: 38,069,510
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85560
Policy Entropy: 5.25839
Value Function Loss: 0.05562
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02892
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.07743
Collected Steps per Second: 10,920.95283
Overall Steps per Second: 8,666.40552
Timestep Collection Time: 4.58000
Timestep Consumption Time: 1.19148
PPO Batch Consumption Time: 0.07867
Total Iteration Time: 5.77148
Cumulative Model Updates: 2,281
Cumulative Timesteps: 38,119,528
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 38119528...
Checkpoint 38119528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.45786
Policy Entropy: 5.26009
Value Function Loss: 0.05073
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02105
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.07598
Collected Steps per Second: 10,962.89697
Overall Steps per Second: 8,642.96411
Timestep Collection Time: 4.56376
Timestep Consumption Time: 1.22500
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 5.78875
Cumulative Model Updates: 2,284
Cumulative Timesteps: 38,169,560
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60497
Policy Entropy: 5.27055
Value Function Loss: 0.04851
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01522
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.06684
Collected Steps per Second: 10,909.39840
Overall Steps per Second: 8,736.20140
Timestep Collection Time: 4.58614
Timestep Consumption Time: 1.14084
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.72697
Cumulative Model Updates: 2,287
Cumulative Timesteps: 38,219,592
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 38219592...
Checkpoint 38219592 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.45708
Policy Entropy: 5.29007
Value Function Loss: 0.05043
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01609
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.06426
Collected Steps per Second: 10,939.80124
Overall Steps per Second: 8,786.86503
Timestep Collection Time: 4.57193
Timestep Consumption Time: 1.12020
PPO Batch Consumption Time: 0.05101
Total Iteration Time: 5.69213
Cumulative Model Updates: 2,290
Cumulative Timesteps: 38,269,608
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67679
Policy Entropy: 5.31365
Value Function Loss: 0.04950
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.05978
Collected Steps per Second: 11,006.97375
Overall Steps per Second: 8,703.03003
Timestep Collection Time: 4.54512
Timestep Consumption Time: 1.20322
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.74834
Cumulative Model Updates: 2,293
Cumulative Timesteps: 38,319,636
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 38319636...
Checkpoint 38319636 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.45282
Policy Entropy: 5.30015
Value Function Loss: 0.04913
Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01175
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.05786
Collected Steps per Second: 10,889.94220
Overall Steps per Second: 8,656.63234
Timestep Collection Time: 4.59305
Timestep Consumption Time: 1.18495
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77800
Cumulative Model Updates: 2,296
Cumulative Timesteps: 38,369,654
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.56487
Policy Entropy: 5.27829
Value Function Loss: 0.05143
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01659
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.05602
Collected Steps per Second: 11,211.12539
Overall Steps per Second: 8,818.24437
Timestep Collection Time: 4.46200
Timestep Consumption Time: 1.21079
PPO Batch Consumption Time: 0.05209
Total Iteration Time: 5.67278
Cumulative Model Updates: 2,299
Cumulative Timesteps: 38,419,678
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 38419678...
Checkpoint 38419678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.97418
Policy Entropy: 5.29589
Value Function Loss: 0.04941
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02192
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.05753
Collected Steps per Second: 11,030.58107
Overall Steps per Second: 8,714.09303
Timestep Collection Time: 4.53575
Timestep Consumption Time: 1.20575
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.74150
Cumulative Model Updates: 2,302
Cumulative Timesteps: 38,469,710
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50009
Policy Entropy: 5.27897
Value Function Loss: 0.04688
Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01035
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.05375
Collected Steps per Second: 11,073.16180
Overall Steps per Second: 8,687.18859
Timestep Collection Time: 4.51922
Timestep Consumption Time: 1.24122
PPO Batch Consumption Time: 0.07267
Total Iteration Time: 5.76044
Cumulative Model Updates: 2,305
Cumulative Timesteps: 38,519,752
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 38519752...
Checkpoint 38519752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75775
Policy Entropy: 5.27578
Value Function Loss: 0.04380
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02491
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.05514
Collected Steps per Second: 11,150.50684
Overall Steps per Second: 8,775.05990
Timestep Collection Time: 4.48410
Timestep Consumption Time: 1.21387
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.69797
Cumulative Model Updates: 2,308
Cumulative Timesteps: 38,569,752
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52582
Policy Entropy: 5.28885
Value Function Loss: 0.05385
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02919
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.05596
Collected Steps per Second: 10,922.38760
Overall Steps per Second: 8,600.22194
Timestep Collection Time: 4.58178
Timestep Consumption Time: 1.23714
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.81892
Cumulative Model Updates: 2,311
Cumulative Timesteps: 38,619,796
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 38619796...
Checkpoint 38619796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.71876
Policy Entropy: 5.28366
Value Function Loss: 0.05495
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01634
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.05532
Collected Steps per Second: 10,940.36687
Overall Steps per Second: 8,790.15449
Timestep Collection Time: 4.57316
Timestep Consumption Time: 1.11867
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.69182
Cumulative Model Updates: 2,314
Cumulative Timesteps: 38,669,828
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.58699
Policy Entropy: 5.27251
Value Function Loss: 0.05500
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01659
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.05877
Collected Steps per Second: 11,039.93418
Overall Steps per Second: 8,696.71310
Timestep Collection Time: 4.53318
Timestep Consumption Time: 1.22141
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.75459
Cumulative Model Updates: 2,317
Cumulative Timesteps: 38,719,874
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 38719874...
Checkpoint 38719874 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63405
Policy Entropy: 5.28493
Value Function Loss: 0.05196
Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03866
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.06148
Collected Steps per Second: 10,903.73202
Overall Steps per Second: 8,648.30176
Timestep Collection Time: 4.58779
Timestep Consumption Time: 1.19647
PPO Batch Consumption Time: 0.05072
Total Iteration Time: 5.78426
Cumulative Model Updates: 2,320
Cumulative Timesteps: 38,769,898
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.72518
Policy Entropy: 5.27486
Value Function Loss: 0.05005
Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05368
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.06101
Collected Steps per Second: 11,238.86801
Overall Steps per Second: 8,832.83339
Timestep Collection Time: 4.45241
Timestep Consumption Time: 1.21282
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.66523
Cumulative Model Updates: 2,323
Cumulative Timesteps: 38,819,938
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 38819938...
Checkpoint 38819938 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87801
Policy Entropy: 5.24826
Value Function Loss: 0.05045
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.05823
Collected Steps per Second: 10,989.21817
Overall Steps per Second: 8,657.96759
Timestep Collection Time: 4.55082
Timestep Consumption Time: 1.22536
PPO Batch Consumption Time: 0.05171
Total Iteration Time: 5.77618
Cumulative Model Updates: 2,326
Cumulative Timesteps: 38,869,948
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39096
Policy Entropy: 5.26015
Value Function Loss: 0.04470
Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.04937
Policy Update Magnitude: 0.06563
Value Function Update Magnitude: 0.05771
Collected Steps per Second: 10,927.75619
Overall Steps per Second: 8,560.35955
Timestep Collection Time: 4.57624
Timestep Consumption Time: 1.26557
PPO Batch Consumption Time: 0.07467
Total Iteration Time: 5.84181
Cumulative Model Updates: 2,329
Cumulative Timesteps: 38,919,956
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 38919956...
Checkpoint 38919956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.56285
Policy Entropy: 5.28830
Value Function Loss: 0.04759
Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05558
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.06034
Collected Steps per Second: 11,203.59629
Overall Steps per Second: 8,767.41455
Timestep Collection Time: 4.46660
Timestep Consumption Time: 1.24112
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 5.70773
Cumulative Model Updates: 2,332
Cumulative Timesteps: 38,969,998
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87924
Policy Entropy: 5.27099
Value Function Loss: 0.05245
Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04027
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.05248
Collected Steps per Second: 10,871.76160
Overall Steps per Second: 8,623.12498
Timestep Collection Time: 4.60293
Timestep Consumption Time: 1.20030
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.80323
Cumulative Model Updates: 2,335
Cumulative Timesteps: 39,020,040
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 39020040...
Checkpoint 39020040 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88309
Policy Entropy: 5.26270
Value Function Loss: 0.05950
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03119
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.05280
Collected Steps per Second: 10,970.85943
Overall Steps per Second: 8,796.12338
Timestep Collection Time: 4.55935
Timestep Consumption Time: 1.12724
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.68660
Cumulative Model Updates: 2,338
Cumulative Timesteps: 39,070,060
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46505
Policy Entropy: 5.26130
Value Function Loss: 0.06172
Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.00969
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.05901
Collected Steps per Second: 10,990.93472
Overall Steps per Second: 8,663.89565
Timestep Collection Time: 4.55102
Timestep Consumption Time: 1.22236
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77338
Cumulative Model Updates: 2,341
Cumulative Timesteps: 39,120,080
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 39120080...
Checkpoint 39120080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.58166
Policy Entropy: 5.27132
Value Function Loss: 0.05516
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.06172
Collected Steps per Second: 10,989.28954
Overall Steps per Second: 8,691.33570
Timestep Collection Time: 4.55261
Timestep Consumption Time: 1.20369
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.75631
Cumulative Model Updates: 2,344
Cumulative Timesteps: 39,170,110
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.31800
Policy Entropy: 5.26413
Value Function Loss: 0.05161
Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07061
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.05739
Collected Steps per Second: 11,211.73892
Overall Steps per Second: 8,802.59809
Timestep Collection Time: 4.45979
Timestep Consumption Time: 1.22058
PPO Batch Consumption Time: 0.05031
Total Iteration Time: 5.68037
Cumulative Model Updates: 2,347
Cumulative Timesteps: 39,220,112
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 39220112...
Checkpoint 39220112 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80970
Policy Entropy: 5.30238
Value Function Loss: 0.04630
Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04169
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.05626
Collected Steps per Second: 10,893.98222
Overall Steps per Second: 8,613.03763
Timestep Collection Time: 4.59391
Timestep Consumption Time: 1.21658
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.81049
Cumulative Model Updates: 2,350
Cumulative Timesteps: 39,270,158
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.13246
Policy Entropy: 5.30515
Value Function Loss: 0.05426
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03567
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.05718
Collected Steps per Second: 10,938.26789
Overall Steps per Second: 8,730.52642
Timestep Collection Time: 4.57422
Timestep Consumption Time: 1.15671
PPO Batch Consumption Time: 0.07078
Total Iteration Time: 5.73093
Cumulative Model Updates: 2,353
Cumulative Timesteps: 39,320,192
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 39320192...
Checkpoint 39320192 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52099
Policy Entropy: 5.27945
Value Function Loss: 0.05421
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02382
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.05660
Collected Steps per Second: 11,045.84183
Overall Steps per Second: 8,711.55681
Timestep Collection Time: 4.52985
Timestep Consumption Time: 1.21379
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.74363
Cumulative Model Updates: 2,356
Cumulative Timesteps: 39,370,228
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39986
Policy Entropy: 5.27426
Value Function Loss: 0.05906
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.05972
Collected Steps per Second: 10,873.41718
Overall Steps per Second: 8,658.60572
Timestep Collection Time: 4.59929
Timestep Consumption Time: 1.17647
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.77576
Cumulative Model Updates: 2,359
Cumulative Timesteps: 39,420,238
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 39420238...
Checkpoint 39420238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.30771
Policy Entropy: 5.29727
Value Function Loss: 0.05657
Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04041
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.05972
Collected Steps per Second: 10,942.69538
Overall Steps per Second: 8,814.13829
Timestep Collection Time: 4.57200
Timestep Consumption Time: 1.10411
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.67611
Cumulative Model Updates: 2,362
Cumulative Timesteps: 39,470,268
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.06421
Policy Entropy: 5.29631
Value Function Loss: 0.05778
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02187
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.05522
Collected Steps per Second: 10,950.71711
Overall Steps per Second: 8,677.80961
Timestep Collection Time: 4.56628
Timestep Consumption Time: 1.19601
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.76228
Cumulative Model Updates: 2,365
Cumulative Timesteps: 39,520,272
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 39520272...
Checkpoint 39520272 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.32703
Policy Entropy: 5.30263
Value Function Loss: 0.05019
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.05442
Collected Steps per Second: 10,928.47603
Overall Steps per Second: 8,664.04976
Timestep Collection Time: 4.57886
Timestep Consumption Time: 1.19673
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77559
Cumulative Model Updates: 2,368
Cumulative Timesteps: 39,570,312
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52402
Policy Entropy: 5.32048
Value Function Loss: 0.04620
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02114
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.05253
Collected Steps per Second: 11,140.52363
Overall Steps per Second: 8,787.49657
Timestep Collection Time: 4.49045
Timestep Consumption Time: 1.20241
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69286
Cumulative Model Updates: 2,371
Cumulative Timesteps: 39,620,338
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 39620338...
Checkpoint 39620338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04601
Policy Entropy: 5.31093
Value Function Loss: 0.04221
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.05358
Collected Steps per Second: 11,106.28724
Overall Steps per Second: 8,733.91912
Timestep Collection Time: 4.50538
Timestep Consumption Time: 1.22378
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.72916
Cumulative Model Updates: 2,374
Cumulative Timesteps: 39,670,376
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53735
Policy Entropy: 5.33405
Value Function Loss: 0.04684
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03053
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.05592
Collected Steps per Second: 10,930.15157
Overall Steps per Second: 8,537.56704
Timestep Collection Time: 4.57798
Timestep Consumption Time: 1.28294
PPO Batch Consumption Time: 0.07335
Total Iteration Time: 5.86092
Cumulative Model Updates: 2,377
Cumulative Timesteps: 39,720,414
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 39720414...
Checkpoint 39720414 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09389
Policy Entropy: 5.36177
Value Function Loss: 0.04880
Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.03865
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.05983
Collected Steps per Second: 11,345.05685
Overall Steps per Second: 8,846.76105
Timestep Collection Time: 4.40826
Timestep Consumption Time: 1.24488
PPO Batch Consumption Time: 0.05440
Total Iteration Time: 5.65314
Cumulative Model Updates: 2,380
Cumulative Timesteps: 39,770,426
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46719
Policy Entropy: 5.34469
Value Function Loss: 0.04562
Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04511
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.06245
Collected Steps per Second: 10,867.16032
Overall Steps per Second: 8,633.43972
Timestep Collection Time: 4.60157
Timestep Consumption Time: 1.19056
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.79213
Cumulative Model Updates: 2,383
Cumulative Timesteps: 39,820,432
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 39820432...
Checkpoint 39820432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57798
Policy Entropy: 5.35650
Value Function Loss: 0.04643
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.06009
Collected Steps per Second: 10,973.91330
Overall Steps per Second: 8,839.81291
Timestep Collection Time: 4.55735
Timestep Consumption Time: 1.10023
PPO Batch Consumption Time: 0.05077
Total Iteration Time: 5.65759
Cumulative Model Updates: 2,386
Cumulative Timesteps: 39,870,444
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.58911
Policy Entropy: 5.36473
Value Function Loss: 0.04783
Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04039
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.05704
Collected Steps per Second: 10,645.76376
Overall Steps per Second: 8,464.48771
Timestep Collection Time: 4.69896
Timestep Consumption Time: 1.21091
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.90987
Cumulative Model Updates: 2,389
Cumulative Timesteps: 39,920,468
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 39920468...
Checkpoint 39920468 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69645
Policy Entropy: 5.34141
Value Function Loss: 0.05982
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02046
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.05788
Collected Steps per Second: 10,963.81398
Overall Steps per Second: 8,694.73794
Timestep Collection Time: 4.56046
Timestep Consumption Time: 1.19015
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.75060
Cumulative Model Updates: 2,392
Cumulative Timesteps: 39,970,468
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.26762
Policy Entropy: 5.29459
Value Function Loss: 0.05797
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.05894
Collected Steps per Second: 10,936.30278
Overall Steps per Second: 8,666.48661
Timestep Collection Time: 4.57284
Timestep Consumption Time: 1.19766
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.77050
Cumulative Model Updates: 2,395
Cumulative Timesteps: 40,020,478
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 40020478...
Checkpoint 40020478 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.27778
Policy Entropy: 5.30004
Value Function Loss: 0.05570
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.06036
Collected Steps per Second: 10,878.68274
Overall Steps per Second: 8,593.62837
Timestep Collection Time: 4.59817
Timestep Consumption Time: 1.22266
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.82082
Cumulative Model Updates: 2,398
Cumulative Timesteps: 40,070,500
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46807
Policy Entropy: 5.31606
Value Function Loss: 0.04572
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01884
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.05559
Collected Steps per Second: 10,922.33585
Overall Steps per Second: 8,534.38258
Timestep Collection Time: 4.58162
Timestep Consumption Time: 1.28196
PPO Batch Consumption Time: 0.08346
Total Iteration Time: 5.86358
Cumulative Model Updates: 2,401
Cumulative Timesteps: 40,120,542
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 40120542...
Checkpoint 40120542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.27111
Policy Entropy: 5.30445
Value Function Loss: 0.04397
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.05763
Collected Steps per Second: 11,092.38090
Overall Steps per Second: 8,732.72926
Timestep Collection Time: 4.51012
Timestep Consumption Time: 1.21867
PPO Batch Consumption Time: 0.05290
Total Iteration Time: 5.72879
Cumulative Model Updates: 2,404
Cumulative Timesteps: 40,170,570
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.45087
Policy Entropy: 5.29448
Value Function Loss: 0.04270
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01729
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.05903
Collected Steps per Second: 10,913.18848
Overall Steps per Second: 8,663.88187
Timestep Collection Time: 4.58436
Timestep Consumption Time: 1.19019
PPO Batch Consumption Time: 0.05309
Total Iteration Time: 5.77455
Cumulative Model Updates: 2,407
Cumulative Timesteps: 40,220,600
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 40220600...
Checkpoint 40220600 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75537
Policy Entropy: 5.28257
Value Function Loss: 0.04581
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02541
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.05470
Collected Steps per Second: 10,785.82903
Overall Steps per Second: 8,727.17446
Timestep Collection Time: 4.63979
Timestep Consumption Time: 1.09448
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.73427
Cumulative Model Updates: 2,410
Cumulative Timesteps: 40,270,644
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63805
Policy Entropy: 5.27478
Value Function Loss: 0.05029
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01758
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.06088
Collected Steps per Second: 10,910.68676
Overall Steps per Second: 8,607.23497
Timestep Collection Time: 4.58395
Timestep Consumption Time: 1.22675
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.81069
Cumulative Model Updates: 2,413
Cumulative Timesteps: 40,320,658
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 40320658...
Checkpoint 40320658 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50997
Policy Entropy: 5.28965
Value Function Loss: 0.05810
Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05395
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.06024
Collected Steps per Second: 10,884.47822
Overall Steps per Second: 8,633.76886
Timestep Collection Time: 4.59921
Timestep Consumption Time: 1.19895
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.79816
Cumulative Model Updates: 2,416
Cumulative Timesteps: 40,370,718
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.19039
Policy Entropy: 5.31160
Value Function Loss: 0.05579
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.06351
Collected Steps per Second: 10,925.24751
Overall Steps per Second: 8,658.71938
Timestep Collection Time: 4.58022
Timestep Consumption Time: 1.19893
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77915
Cumulative Model Updates: 2,419
Cumulative Timesteps: 40,420,758
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 40420758...
Checkpoint 40420758 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63069
Policy Entropy: 5.29658
Value Function Loss: 0.05315
Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05145
Policy Update Magnitude: 0.06182
Value Function Update Magnitude: 0.06252
Collected Steps per Second: 11,092.05584
Overall Steps per Second: 8,735.15857
Timestep Collection Time: 4.50881
Timestep Consumption Time: 1.21656
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.72537
Cumulative Model Updates: 2,422
Cumulative Timesteps: 40,470,770
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89908
Policy Entropy: 5.31558
Value Function Loss: 0.04113
Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04804
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.06338
Collected Steps per Second: 10,896.94358
Overall Steps per Second: 8,508.98768
Timestep Collection Time: 4.58899
Timestep Consumption Time: 1.28785
PPO Batch Consumption Time: 0.08033
Total Iteration Time: 5.87684
Cumulative Model Updates: 2,425
Cumulative Timesteps: 40,520,776
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 40520776...
Checkpoint 40520776 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87438
Policy Entropy: 5.32992
Value Function Loss: 0.04550
Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.03743
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.06483
Collected Steps per Second: 11,159.38743
Overall Steps per Second: 8,757.43251
Timestep Collection Time: 4.48412
Timestep Consumption Time: 1.22989
PPO Batch Consumption Time: 0.05332
Total Iteration Time: 5.71400
Cumulative Model Updates: 2,428
Cumulative Timesteps: 40,570,816
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62697
Policy Entropy: 5.31648
Value Function Loss: 0.04333
Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05219
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.06254
Collected Steps per Second: 11,004.88910
Overall Steps per Second: 8,691.19919
Timestep Collection Time: 4.54707
Timestep Consumption Time: 1.21048
PPO Batch Consumption Time: 0.05039
Total Iteration Time: 5.75755
Cumulative Model Updates: 2,431
Cumulative Timesteps: 40,620,856
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 40620856...
Checkpoint 40620856 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.38310
Policy Entropy: 5.29200
Value Function Loss: 0.05111
Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04297
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.05700
Collected Steps per Second: 10,886.77893
Overall Steps per Second: 8,770.13405
Timestep Collection Time: 4.59732
Timestep Consumption Time: 1.10955
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.70687
Cumulative Model Updates: 2,434
Cumulative Timesteps: 40,670,906
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47645
Policy Entropy: 5.30605
Value Function Loss: 0.05471
Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05052
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.06227
Collected Steps per Second: 11,032.84114
Overall Steps per Second: 8,712.31212
Timestep Collection Time: 4.53682
Timestep Consumption Time: 1.20838
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.74520
Cumulative Model Updates: 2,437
Cumulative Timesteps: 40,720,960
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 40720960...
Checkpoint 40720960 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.28486
Policy Entropy: 5.29602
Value Function Loss: 0.05960
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.06984
Collected Steps per Second: 10,945.46322
Overall Steps per Second: 8,662.58436
Timestep Collection Time: 4.57194
Timestep Consumption Time: 1.20486
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.77680
Cumulative Model Updates: 2,440
Cumulative Timesteps: 40,771,002
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.14661
Policy Entropy: 5.30689
Value Function Loss: 0.05438
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03388
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.07061
Collected Steps per Second: 11,128.58926
Overall Steps per Second: 8,794.31466
Timestep Collection Time: 4.49329
Timestep Consumption Time: 1.19265
PPO Batch Consumption Time: 0.04934
Total Iteration Time: 5.68595
Cumulative Model Updates: 2,443
Cumulative Timesteps: 40,821,006
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 40821006...
Checkpoint 40821006 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44056
Policy Entropy: 5.31888
Value Function Loss: 0.05761
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03260
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.06951
Collected Steps per Second: 10,954.52169
Overall Steps per Second: 8,621.11146
Timestep Collection Time: 4.56469
Timestep Consumption Time: 1.23549
PPO Batch Consumption Time: 0.05119
Total Iteration Time: 5.80018
Cumulative Model Updates: 2,446
Cumulative Timesteps: 40,871,010
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87412
Policy Entropy: 5.31596
Value Function Loss: 0.05718
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.06985
Collected Steps per Second: 10,874.97465
Overall Steps per Second: 8,582.87291
Timestep Collection Time: 4.59845
Timestep Consumption Time: 1.22804
PPO Batch Consumption Time: 0.06967
Total Iteration Time: 5.82649
Cumulative Model Updates: 2,449
Cumulative Timesteps: 40,921,018
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 40921018...
Checkpoint 40921018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.49908
Policy Entropy: 5.30141
Value Function Loss: 0.05695
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02086
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.07022
Collected Steps per Second: 11,179.71926
Overall Steps per Second: 8,780.33018
Timestep Collection Time: 4.47310
Timestep Consumption Time: 1.22236
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.69546
Cumulative Model Updates: 2,452
Cumulative Timesteps: 40,971,026
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53105
Policy Entropy: 5.33392
Value Function Loss: 0.04927
Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01402
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.06222
Collected Steps per Second: 10,807.70881
Overall Steps per Second: 8,562.63766
Timestep Collection Time: 4.62892
Timestep Consumption Time: 1.21367
PPO Batch Consumption Time: 0.05156
Total Iteration Time: 5.84259
Cumulative Model Updates: 2,455
Cumulative Timesteps: 41,021,054
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 41021054...
Checkpoint 41021054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67257
Policy Entropy: 5.36328
Value Function Loss: 0.04562
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02411
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.05922
Collected Steps per Second: 10,915.84555
Overall Steps per Second: 8,784.46818
Timestep Collection Time: 4.58416
Timestep Consumption Time: 1.11226
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.69642
Cumulative Model Updates: 2,458
Cumulative Timesteps: 41,071,094
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03517
Policy Entropy: 5.36214
Value Function Loss: 0.04437
Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01071
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.06201
Collected Steps per Second: 10,963.94309
Overall Steps per Second: 8,661.18186
Timestep Collection Time: 4.56387
Timestep Consumption Time: 1.21340
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.77727
Cumulative Model Updates: 2,461
Cumulative Timesteps: 41,121,132
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 41121132...
Checkpoint 41121132 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.01767
Policy Entropy: 5.34805
Value Function Loss: 0.04704
Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01435
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.06697
Collected Steps per Second: 11,005.72907
Overall Steps per Second: 8,734.09728
Timestep Collection Time: 4.54854
Timestep Consumption Time: 1.18302
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.73156
Cumulative Model Updates: 2,464
Cumulative Timesteps: 41,171,192
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70339
Policy Entropy: 5.35877
Value Function Loss: 0.04549
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01429
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.06548
Collected Steps per Second: 11,198.93779
Overall Steps per Second: 8,814.08331
Timestep Collection Time: 4.46542
Timestep Consumption Time: 1.20822
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.67365
Cumulative Model Updates: 2,467
Cumulative Timesteps: 41,221,200
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 41221200...
Checkpoint 41221200 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.41573
Policy Entropy: 5.34354
Value Function Loss: 0.04769
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.06140
Collected Steps per Second: 10,905.88316
Overall Steps per Second: 8,644.83906
Timestep Collection Time: 4.58798
Timestep Consumption Time: 1.19998
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.78796
Cumulative Model Updates: 2,470
Cumulative Timesteps: 41,271,236
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.20699
Policy Entropy: 5.33888
Value Function Loss: 0.04729
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01705
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.06045
Collected Steps per Second: 10,875.86235
Overall Steps per Second: 8,586.04119
Timestep Collection Time: 4.60009
Timestep Consumption Time: 1.22680
PPO Batch Consumption Time: 0.07169
Total Iteration Time: 5.82690
Cumulative Model Updates: 2,473
Cumulative Timesteps: 41,321,266
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 41321266...
Checkpoint 41321266 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.58821
Policy Entropy: 5.33571
Value Function Loss: 0.04842
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.05903
Collected Steps per Second: 11,254.41690
Overall Steps per Second: 8,818.14724
Timestep Collection Time: 4.44537
Timestep Consumption Time: 1.22816
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.67353
Cumulative Model Updates: 2,476
Cumulative Timesteps: 41,371,296
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09025
Policy Entropy: 5.32078
Value Function Loss: 0.04795
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02121
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.06192
Collected Steps per Second: 10,851.03888
Overall Steps per Second: 8,579.65702
Timestep Collection Time: 4.61007
Timestep Consumption Time: 1.22047
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.83054
Cumulative Model Updates: 2,479
Cumulative Timesteps: 41,421,320
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 41421320...
Checkpoint 41421320 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77624
Policy Entropy: 5.28736
Value Function Loss: 0.05250
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.06176
Collected Steps per Second: 10,883.79666
Overall Steps per Second: 8,779.45191
Timestep Collection Time: 4.59637
Timestep Consumption Time: 1.10170
PPO Batch Consumption Time: 0.05090
Total Iteration Time: 5.69808
Cumulative Model Updates: 2,482
Cumulative Timesteps: 41,471,346
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.35923
Policy Entropy: 5.28548
Value Function Loss: 0.05231
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.05430
Collected Steps per Second: 10,861.20315
Overall Steps per Second: 8,599.41519
Timestep Collection Time: 4.60686
Timestep Consumption Time: 1.21168
PPO Batch Consumption Time: 0.05001
Total Iteration Time: 5.81854
Cumulative Model Updates: 2,485
Cumulative Timesteps: 41,521,382
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 41521382...
Checkpoint 41521382 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55328
Policy Entropy: 5.28318
Value Function Loss: 0.05390
Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.03783
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.06234
Collected Steps per Second: 11,022.23361
Overall Steps per Second: 8,719.80523
Timestep Collection Time: 4.53792
Timestep Consumption Time: 1.19822
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.73614
Cumulative Model Updates: 2,488
Cumulative Timesteps: 41,571,400
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.00600
Policy Entropy: 5.29460
Value Function Loss: 0.04864
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.06272
Collected Steps per Second: 11,325.00960
Overall Steps per Second: 8,911.88683
Timestep Collection Time: 4.41801
Timestep Consumption Time: 1.19629
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.61430
Cumulative Model Updates: 2,491
Cumulative Timesteps: 41,621,434
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 41621434...
Checkpoint 41621434 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52015
Policy Entropy: 5.30208
Value Function Loss: 0.05162
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.05613
Collected Steps per Second: 10,882.80754
Overall Steps per Second: 8,623.21343
Timestep Collection Time: 4.59955
Timestep Consumption Time: 1.20525
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.80480
Cumulative Model Updates: 2,494
Cumulative Timesteps: 41,671,490
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.58460
Policy Entropy: 5.28972
Value Function Loss: 0.04670
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01818
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.05843
Collected Steps per Second: 10,871.54533
Overall Steps per Second: 8,554.02093
Timestep Collection Time: 4.60339
Timestep Consumption Time: 1.24719
PPO Batch Consumption Time: 0.07467
Total Iteration Time: 5.85058
Cumulative Model Updates: 2,497
Cumulative Timesteps: 41,721,536
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 41721536...
Checkpoint 41721536 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40020
Policy Entropy: 5.28276
Value Function Loss: 0.04309
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01988
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.05790
Collected Steps per Second: 11,095.48854
Overall Steps per Second: 8,715.25613
Timestep Collection Time: 4.50886
Timestep Consumption Time: 1.23142
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.74028
Cumulative Model Updates: 2,500
Cumulative Timesteps: 41,771,564
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70338
Policy Entropy: 5.28632
Value Function Loss: 0.05428
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.05408
Collected Steps per Second: 10,936.29140
Overall Steps per Second: 8,653.75695
Timestep Collection Time: 4.57413
Timestep Consumption Time: 1.20648
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.78061
Cumulative Model Updates: 2,503
Cumulative Timesteps: 41,821,588
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 41821588...
Checkpoint 41821588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.97077
Policy Entropy: 5.29345
Value Function Loss: 0.05804
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02376
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.05454
Collected Steps per Second: 10,949.97358
Overall Steps per Second: 8,798.55337
Timestep Collection Time: 4.56860
Timestep Consumption Time: 1.11711
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.68571
Cumulative Model Updates: 2,506
Cumulative Timesteps: 41,871,614
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.36092
Policy Entropy: 5.26504
Value Function Loss: 0.06086
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01929
Policy Update Magnitude: 0.06716
Value Function Update Magnitude: 0.05621
Collected Steps per Second: 10,970.80655
Overall Steps per Second: 8,668.73046
Timestep Collection Time: 4.56174
Timestep Consumption Time: 1.21142
PPO Batch Consumption Time: 0.05042
Total Iteration Time: 5.77316
Cumulative Model Updates: 2,509
Cumulative Timesteps: 41,921,660
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 41921660...
Checkpoint 41921660 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69561
Policy Entropy: 5.28143
Value Function Loss: 0.05049
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03285
Policy Update Magnitude: 0.06484
Value Function Update Magnitude: 0.05628
Collected Steps per Second: 10,916.94792
Overall Steps per Second: 8,673.43039
Timestep Collection Time: 4.58352
Timestep Consumption Time: 1.18560
PPO Batch Consumption Time: 0.05092
Total Iteration Time: 5.76911
Cumulative Model Updates: 2,512
Cumulative Timesteps: 41,971,698
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39528
Policy Entropy: 5.29970
Value Function Loss: 0.04709
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02318
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.05383
Collected Steps per Second: 11,169.86451
Overall Steps per Second: 8,849.02121
Timestep Collection Time: 4.47723
Timestep Consumption Time: 1.17425
PPO Batch Consumption Time: 0.05046
Total Iteration Time: 5.65147
Cumulative Model Updates: 2,515
Cumulative Timesteps: 42,021,708
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 42021708...
Checkpoint 42021708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.15147
Policy Entropy: 5.30085
Value Function Loss: 0.04601
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02187
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.04818
Collected Steps per Second: 10,908.26908
Overall Steps per Second: 8,620.23987
Timestep Collection Time: 4.58625
Timestep Consumption Time: 1.21731
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.80355
Cumulative Model Updates: 2,518
Cumulative Timesteps: 42,071,736
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85791
Policy Entropy: 5.29578
Value Function Loss: 0.04723
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02376
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.04451
Collected Steps per Second: 10,842.77984
Overall Steps per Second: 8,515.07957
Timestep Collection Time: 4.61247
Timestep Consumption Time: 1.26087
PPO Batch Consumption Time: 0.07300
Total Iteration Time: 5.87334
Cumulative Model Updates: 2,521
Cumulative Timesteps: 42,121,748
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 42121748...
Checkpoint 42121748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.13677
Policy Entropy: 5.32200
Value Function Loss: 0.04756
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02970
Policy Update Magnitude: 0.04449
Value Function Update Magnitude: 0.04553
Collected Steps per Second: 11,252.48582
Overall Steps per Second: 8,831.95466
Timestep Collection Time: 4.44435
Timestep Consumption Time: 1.21804
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.66239
Cumulative Model Updates: 2,524
Cumulative Timesteps: 42,171,758
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.33599
Policy Entropy: 5.34142
Value Function Loss: 0.04973
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.04648
Collected Steps per Second: 10,814.57328
Overall Steps per Second: 8,562.80523
Timestep Collection Time: 4.62635
Timestep Consumption Time: 1.21660
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.84294
Cumulative Model Updates: 2,527
Cumulative Timesteps: 42,221,790
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 42221790...
Checkpoint 42221790 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86159
Policy Entropy: 5.35727
Value Function Loss: 0.04429
Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01079
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.04722
Collected Steps per Second: 10,794.69890
Overall Steps per Second: 8,703.07132
Timestep Collection Time: 4.63320
Timestep Consumption Time: 1.11351
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.74671
Cumulative Model Updates: 2,530
Cumulative Timesteps: 42,271,804
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65693
Policy Entropy: 5.33920
Value Function Loss: 0.04647
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.05339
Collected Steps per Second: 10,862.17434
Overall Steps per Second: 8,589.69525
Timestep Collection Time: 4.60571
Timestep Consumption Time: 1.21848
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.82419
Cumulative Model Updates: 2,533
Cumulative Timesteps: 42,321,832
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 42321832...
Checkpoint 42321832 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69670
Policy Entropy: 5.35054
Value Function Loss: 0.04072
Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.00866
Policy Update Magnitude: 0.04729
Value Function Update Magnitude: 0.05812
Collected Steps per Second: 10,942.44904
Overall Steps per Second: 8,728.12856
Timestep Collection Time: 4.57229
Timestep Consumption Time: 1.15999
PPO Batch Consumption Time: 0.05051
Total Iteration Time: 5.73227
Cumulative Model Updates: 2,536
Cumulative Timesteps: 42,371,864
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.72167
Policy Entropy: 5.31118
Value Function Loss: 0.04687
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01633
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.05915
Collected Steps per Second: 11,108.21142
Overall Steps per Second: 8,770.28235
Timestep Collection Time: 4.50316
Timestep Consumption Time: 1.20042
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.70358
Cumulative Model Updates: 2,539
Cumulative Timesteps: 42,421,886
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 42421886...
Checkpoint 42421886 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44898
Policy Entropy: 5.29202
Value Function Loss: 0.04330
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01421
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.05863
Collected Steps per Second: 10,922.72593
Overall Steps per Second: 8,627.46634
Timestep Collection Time: 4.57834
Timestep Consumption Time: 1.21803
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.79637
Cumulative Model Updates: 2,542
Cumulative Timesteps: 42,471,894
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75049
Policy Entropy: 5.29509
Value Function Loss: 0.04810
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02689
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.05509
Collected Steps per Second: 10,928.56881
Overall Steps per Second: 8,518.37209
Timestep Collection Time: 4.57809
Timestep Consumption Time: 1.29533
PPO Batch Consumption Time: 0.08533
Total Iteration Time: 5.87342
Cumulative Model Updates: 2,545
Cumulative Timesteps: 42,521,926
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 42521926...
Checkpoint 42521926 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.73701
Policy Entropy: 5.29414
Value Function Loss: 0.04651
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01866
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.05162
Collected Steps per Second: 11,263.60891
Overall Steps per Second: 8,812.30816
Timestep Collection Time: 4.44138
Timestep Consumption Time: 1.23545
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.67683
Cumulative Model Updates: 2,548
Cumulative Timesteps: 42,571,952
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70627
Policy Entropy: 5.29150
Value Function Loss: 0.05406
Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.04624
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.05448
Collected Steps per Second: 10,920.16573
Overall Steps per Second: 8,620.77343
Timestep Collection Time: 4.58143
Timestep Consumption Time: 1.22199
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.80342
Cumulative Model Updates: 2,551
Cumulative Timesteps: 42,621,982
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 42621982...
Checkpoint 42621982 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42882
Policy Entropy: 5.29013
Value Function Loss: 0.05445
Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04757
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.05655
Collected Steps per Second: 10,835.86200
Overall Steps per Second: 8,696.62118
Timestep Collection Time: 4.61874
Timestep Consumption Time: 1.13614
PPO Batch Consumption Time: 0.04961
Total Iteration Time: 5.75488
Cumulative Model Updates: 2,554
Cumulative Timesteps: 42,672,030
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.36313
Policy Entropy: 5.29025
Value Function Loss: 0.05617
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.05709
Collected Steps per Second: 11,044.26598
Overall Steps per Second: 8,709.21632
Timestep Collection Time: 4.53122
Timestep Consumption Time: 1.21488
PPO Batch Consumption Time: 0.05010
Total Iteration Time: 5.74610
Cumulative Model Updates: 2,557
Cumulative Timesteps: 42,722,074
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 42722074...
Checkpoint 42722074 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65380
Policy Entropy: 5.28168
Value Function Loss: 0.05418
Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.05627
Collected Steps per Second: 10,917.71848
Overall Steps per Second: 8,687.25971
Timestep Collection Time: 4.58319
Timestep Consumption Time: 1.17674
PPO Batch Consumption Time: 0.05052
Total Iteration Time: 5.75993
Cumulative Model Updates: 2,560
Cumulative Timesteps: 42,772,112
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.16679
Policy Entropy: 5.26549
Value Function Loss: 0.05340
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02238
Policy Update Magnitude: 0.04462
Value Function Update Magnitude: 0.05155
Collected Steps per Second: 11,047.20143
Overall Steps per Second: 8,727.67661
Timestep Collection Time: 4.52621
Timestep Consumption Time: 1.20292
PPO Batch Consumption Time: 0.05024
Total Iteration Time: 5.72913
Cumulative Model Updates: 2,563
Cumulative Timesteps: 42,822,114
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 42822114...
Checkpoint 42822114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.02018
Policy Entropy: 5.25779
Value Function Loss: 0.05149
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01965
Policy Update Magnitude: 0.04491
Value Function Update Magnitude: 0.04861
Collected Steps per Second: 10,936.00436
Overall Steps per Second: 8,642.75679
Timestep Collection Time: 4.57589
Timestep Consumption Time: 1.21416
PPO Batch Consumption Time: 0.05003
Total Iteration Time: 5.79005
Cumulative Model Updates: 2,566
Cumulative Timesteps: 42,872,156
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.43320
Policy Entropy: 5.28036
Value Function Loss: 0.04997
Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01227
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.04643
Collected Steps per Second: 10,835.06174
Overall Steps per Second: 8,516.24572
Timestep Collection Time: 4.61557
Timestep Consumption Time: 1.25673
PPO Batch Consumption Time: 0.07300
Total Iteration Time: 5.87231
Cumulative Model Updates: 2,569
Cumulative Timesteps: 42,922,166
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 42922166...
Checkpoint 42922166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68961
Policy Entropy: 5.30495
Value Function Loss: 0.04997
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02033
Policy Update Magnitude: 0.04477
Value Function Update Magnitude: 0.05291
Collected Steps per Second: 11,113.36045
Overall Steps per Second: 8,748.07379
Timestep Collection Time: 4.50305
Timestep Consumption Time: 1.21753
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.72057
Cumulative Model Updates: 2,572
Cumulative Timesteps: 42,972,210
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50254
Policy Entropy: 5.31506
Value Function Loss: 0.05069
Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01487
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.05267
Collected Steps per Second: 10,946.19557
Overall Steps per Second: 8,648.46848
Timestep Collection Time: 4.56835
Timestep Consumption Time: 1.21372
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78206
Cumulative Model Updates: 2,575
Cumulative Timesteps: 43,022,216
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 43022216...
Checkpoint 43022216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69183
Policy Entropy: 5.27189
Value Function Loss: 0.05862
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.04673
Collected Steps per Second: 10,844.57642
Overall Steps per Second: 8,717.20929
Timestep Collection Time: 4.61115
Timestep Consumption Time: 1.12532
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.73647
Cumulative Model Updates: 2,578
Cumulative Timesteps: 43,072,222
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65787
Policy Entropy: 5.27177
Value Function Loss: 0.05591
Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03384
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.04446
Collected Steps per Second: 10,877.68940
Overall Steps per Second: 8,644.04440
Timestep Collection Time: 4.59712
Timestep Consumption Time: 1.18791
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.78502
Cumulative Model Updates: 2,581
Cumulative Timesteps: 43,122,228
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 43122228...
Checkpoint 43122228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48880
Policy Entropy: 5.29094
Value Function Loss: 0.05275
Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04677
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.04352
Collected Steps per Second: 10,894.48283
Overall Steps per Second: 8,675.91122
Timestep Collection Time: 4.59021
Timestep Consumption Time: 1.17379
PPO Batch Consumption Time: 0.05101
Total Iteration Time: 5.76401
Cumulative Model Updates: 2,584
Cumulative Timesteps: 43,172,236
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57957
Policy Entropy: 5.31237
Value Function Loss: 0.04587
Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04833
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.05041
Collected Steps per Second: 10,846.01380
Overall Steps per Second: 8,796.81017
Timestep Collection Time: 4.61073
Timestep Consumption Time: 1.07406
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.68479
Cumulative Model Updates: 2,587
Cumulative Timesteps: 43,222,244
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 43222244...
Checkpoint 43222244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.34810
Policy Entropy: 5.30460
Value Function Loss: 0.04914
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03155
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.04556
Collected Steps per Second: 11,107.28148
Overall Steps per Second: 8,741.31340
Timestep Collection Time: 4.50551
Timestep Consumption Time: 1.21948
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.72500
Cumulative Model Updates: 2,590
Cumulative Timesteps: 43,272,288
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.99037
Policy Entropy: 5.30042
Value Function Loss: 0.04878
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02009
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.04205
Collected Steps per Second: 10,879.80919
Overall Steps per Second: 8,572.38761
Timestep Collection Time: 4.59751
Timestep Consumption Time: 1.23751
PPO Batch Consumption Time: 0.07370
Total Iteration Time: 5.83501
Cumulative Model Updates: 2,593
Cumulative Timesteps: 43,322,308
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 43322308...
Checkpoint 43322308 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64596
Policy Entropy: 5.33075
Value Function Loss: 0.04793
Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01476
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.04617
Collected Steps per Second: 11,220.18038
Overall Steps per Second: 8,798.84063
Timestep Collection Time: 4.46000
Timestep Consumption Time: 1.22734
PPO Batch Consumption Time: 0.05286
Total Iteration Time: 5.68734
Cumulative Model Updates: 2,596
Cumulative Timesteps: 43,372,350
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50008
Policy Entropy: 5.32108
Value Function Loss: 0.04602
Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01238
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.04836
Collected Steps per Second: 11,033.47954
Overall Steps per Second: 8,690.89668
Timestep Collection Time: 4.53384
Timestep Consumption Time: 1.22207
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.75591
Cumulative Model Updates: 2,599
Cumulative Timesteps: 43,422,374
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 43422374...
Checkpoint 43422374 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.13450
Policy Entropy: 5.30905
Value Function Loss: 0.04362
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01498
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.04844
Collected Steps per Second: 10,889.38587
Overall Steps per Second: 8,774.72142
Timestep Collection Time: 4.59567
Timestep Consumption Time: 1.10753
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.70320
Cumulative Model Updates: 2,602
Cumulative Timesteps: 43,472,418
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.49460
Policy Entropy: 5.32138
Value Function Loss: 0.03806
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01275
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.04464
Collected Steps per Second: 10,949.79576
Overall Steps per Second: 8,626.94390
Timestep Collection Time: 4.56977
Timestep Consumption Time: 1.23043
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.80020
Cumulative Model Updates: 2,605
Cumulative Timesteps: 43,522,456
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 43522456...
Checkpoint 43522456 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66503
Policy Entropy: 5.32548
Value Function Loss: 0.04159
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03005
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.04506
Collected Steps per Second: 11,030.21469
Overall Steps per Second: 8,721.29424
Timestep Collection Time: 4.53808
Timestep Consumption Time: 1.20143
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.73952
Cumulative Model Updates: 2,608
Cumulative Timesteps: 43,572,512
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.51672
Policy Entropy: 5.30074
Value Function Loss: 0.04160
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01537
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.04733
Collected Steps per Second: 11,174.25236
Overall Steps per Second: 8,838.41463
Timestep Collection Time: 4.47869
Timestep Consumption Time: 1.18364
PPO Batch Consumption Time: 0.05137
Total Iteration Time: 5.66233
Cumulative Model Updates: 2,611
Cumulative Timesteps: 43,622,558
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 43622558...
Checkpoint 43622558 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65661
Policy Entropy: 5.30988
Value Function Loss: 0.04916
Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01101
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.04828
Collected Steps per Second: 11,014.17525
Overall Steps per Second: 8,662.25921
Timestep Collection Time: 4.54124
Timestep Consumption Time: 1.23301
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77424
Cumulative Model Updates: 2,614
Cumulative Timesteps: 43,672,576
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47012
Policy Entropy: 5.33124
Value Function Loss: 0.04289
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01669
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.05391
Collected Steps per Second: 10,920.57892
Overall Steps per Second: 8,573.45677
Timestep Collection Time: 4.58236
Timestep Consumption Time: 1.25449
PPO Batch Consumption Time: 0.06889
Total Iteration Time: 5.83685
Cumulative Model Updates: 2,617
Cumulative Timesteps: 43,722,618
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 43722618...
Checkpoint 43722618 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.06739
Policy Entropy: 5.35506
Value Function Loss: 0.04300
Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01192
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.06430
Collected Steps per Second: 11,212.82959
Overall Steps per Second: 8,800.88543
Timestep Collection Time: 4.46043
Timestep Consumption Time: 1.22241
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.68284
Cumulative Model Updates: 2,620
Cumulative Timesteps: 43,772,632
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77978
Policy Entropy: 5.34927
Value Function Loss: 0.04426
Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.03836
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.06562
Collected Steps per Second: 10,915.13110
Overall Steps per Second: 8,623.50611
Timestep Collection Time: 4.58300
Timestep Consumption Time: 1.21789
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.80089
Cumulative Model Updates: 2,623
Cumulative Timesteps: 43,822,656
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 43822656...
Checkpoint 43822656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62361
Policy Entropy: 5.38232
Value Function Loss: 0.04348
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02205
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.06602
Collected Steps per Second: 10,903.50963
Overall Steps per Second: 8,761.76487
Timestep Collection Time: 4.59008
Timestep Consumption Time: 1.12201
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.71209
Cumulative Model Updates: 2,626
Cumulative Timesteps: 43,872,704
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61159
Policy Entropy: 5.36089
Value Function Loss: 0.04100
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01231
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.07323
Collected Steps per Second: 10,929.36695
Overall Steps per Second: 8,617.43459
Timestep Collection Time: 4.57977
Timestep Consumption Time: 1.22869
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.80846
Cumulative Model Updates: 2,629
Cumulative Timesteps: 43,922,758
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 43922758...
Checkpoint 43922758 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52998
Policy Entropy: 5.36605
Value Function Loss: 0.03504
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03186
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.06267
Collected Steps per Second: 10,771.69124
Overall Steps per Second: 8,605.06296
Timestep Collection Time: 4.64588
Timestep Consumption Time: 1.16976
PPO Batch Consumption Time: 0.05041
Total Iteration Time: 5.81565
Cumulative Model Updates: 2,632
Cumulative Timesteps: 43,972,802
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54626
Policy Entropy: 5.35413
Value Function Loss: 0.03351
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01771
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.05357
Collected Steps per Second: 11,177.53763
Overall Steps per Second: 8,830.63475
Timestep Collection Time: 4.47361
Timestep Consumption Time: 1.18895
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.66256
Cumulative Model Updates: 2,635
Cumulative Timesteps: 44,022,806
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 44022806...
Checkpoint 44022806 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75136
Policy Entropy: 5.33930
Value Function Loss: 0.04308
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01473
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.04782
Collected Steps per Second: 10,925.09502
Overall Steps per Second: 8,635.04097
Timestep Collection Time: 4.57680
Timestep Consumption Time: 1.21379
PPO Batch Consumption Time: 0.05119
Total Iteration Time: 5.79059
Cumulative Model Updates: 2,638
Cumulative Timesteps: 44,072,808
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50579
Policy Entropy: 5.31856
Value Function Loss: 0.04571
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01141
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.04609
Collected Steps per Second: 10,830.48997
Overall Steps per Second: 8,509.15354
Timestep Collection Time: 4.61918
Timestep Consumption Time: 1.26013
PPO Batch Consumption Time: 0.07800
Total Iteration Time: 5.87932
Cumulative Model Updates: 2,641
Cumulative Timesteps: 44,122,836
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 44122836...
Checkpoint 44122836 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.37839
Policy Entropy: 5.30832
Value Function Loss: 0.05766
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01541
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.05077
Collected Steps per Second: 11,103.03390
Overall Steps per Second: 8,729.53652
Timestep Collection Time: 4.50706
Timestep Consumption Time: 1.22544
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.73249
Cumulative Model Updates: 2,644
Cumulative Timesteps: 44,172,878
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.71479
Policy Entropy: 5.31261
Value Function Loss: 0.05107
Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01048
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.05758
Collected Steps per Second: 10,883.07507
Overall Steps per Second: 8,601.08738
Timestep Collection Time: 4.59576
Timestep Consumption Time: 1.21932
PPO Batch Consumption Time: 0.04980
Total Iteration Time: 5.81508
Cumulative Model Updates: 2,647
Cumulative Timesteps: 44,222,894
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 44222894...
Checkpoint 44222894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50756
Policy Entropy: 5.30441
Value Function Loss: 0.04874
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01747
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.05449
Collected Steps per Second: 10,759.36428
Overall Steps per Second: 8,672.40337
Timestep Collection Time: 4.64842
Timestep Consumption Time: 1.11861
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.76703
Cumulative Model Updates: 2,650
Cumulative Timesteps: 44,272,908
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.56382
Policy Entropy: 5.33198
Value Function Loss: 0.04198
Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01338
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.05345
Collected Steps per Second: 11,055.58356
Overall Steps per Second: 8,721.51776
Timestep Collection Time: 4.52658
Timestep Consumption Time: 1.21141
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.73799
Cumulative Model Updates: 2,653
Cumulative Timesteps: 44,322,952
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 44322952...
Checkpoint 44322952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.38794
Policy Entropy: 5.35042
Value Function Loss: 0.04466
Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01196
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.05306
Collected Steps per Second: 10,876.03255
Overall Steps per Second: 8,638.60478
Timestep Collection Time: 4.60021
Timestep Consumption Time: 1.19147
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.79168
Cumulative Model Updates: 2,656
Cumulative Timesteps: 44,372,984
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.44822
Policy Entropy: 5.32943
Value Function Loss: 0.04357
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01351
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.05419
Collected Steps per Second: 10,972.31417
Overall Steps per Second: 8,826.33275
Timestep Collection Time: 4.56276
Timestep Consumption Time: 1.10936
PPO Batch Consumption Time: 0.05075
Total Iteration Time: 5.67212
Cumulative Model Updates: 2,659
Cumulative Timesteps: 44,423,048
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
Saving checkpoint 44423048...
Checkpoint 44423048 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52970
Policy Entropy: 5.30931
Value Function Loss: 0.04740
Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01519
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.06126
Collected Steps per Second: 10,968.14515
Overall Steps per Second: 8,654.01652
Timestep Collection Time: 4.56048
Timestep Consumption Time: 1.21950
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.77998
Cumulative Model Updates: 2,662
Cumulative Timesteps: 44,473,068
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04865
Policy Entropy: 5.31996
Value Function Loss: 0.04350
Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.00866
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.06076
Collected Steps per Second: 10,974.99210
Overall Steps per Second: 8,607.23703
Timestep Collection Time: 4.55618
Timestep Consumption Time: 1.25335
PPO Batch Consumption Time: 0.07333
Total Iteration Time: 5.80953
Cumulative Model Updates: 2,665
Cumulative Timesteps: 44,523,072
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 44523072...
Checkpoint 44523072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.76700
Policy Entropy: 5.35257
Value Function Loss: 0.04051
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01461
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.05633
Collected Steps per Second: 11,228.10219
Overall Steps per Second: 8,822.81546
Timestep Collection Time: 4.45454
Timestep Consumption Time: 1.21440
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.66894
Cumulative Model Updates: 2,668
Cumulative Timesteps: 44,573,088
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.15065
Policy Entropy: 5.36764
Value Function Loss: 0.03591
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02142
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.05197
Collected Steps per Second: 10,890.72711
Overall Steps per Second: 8,601.77295
Timestep Collection Time: 4.59198
Timestep Consumption Time: 1.22194
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.81392
Cumulative Model Updates: 2,671
Cumulative Timesteps: 44,623,098
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 44623098...
Checkpoint 44623098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.06920
Policy Entropy: 5.37602
Value Function Loss: 0.03485
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01623
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.05179
Collected Steps per Second: 10,918.66295
Overall Steps per Second: 8,794.55070
Timestep Collection Time: 4.58115
Timestep Consumption Time: 1.10647
PPO Batch Consumption Time: 0.05119
Total Iteration Time: 5.68761
Cumulative Model Updates: 2,674
Cumulative Timesteps: 44,673,118
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.32825
Policy Entropy: 5.35120
Value Function Loss: 0.03869
Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.00831
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.05588
Collected Steps per Second: 11,024.75613
Overall Steps per Second: 8,692.50526
Timestep Collection Time: 4.53688
Timestep Consumption Time: 1.21727
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.75415
Cumulative Model Updates: 2,677
Cumulative Timesteps: 44,723,136
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 44723136...
Checkpoint 44723136 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.71110
Policy Entropy: 5.34266
Value Function Loss: 0.04259
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02107
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.05575
Collected Steps per Second: 10,856.73873
Overall Steps per Second: 8,649.96264
Timestep Collection Time: 4.60562
Timestep Consumption Time: 1.17498
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78060
Cumulative Model Updates: 2,680
Cumulative Timesteps: 44,773,138
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.24813
Policy Entropy: 5.35488
Value Function Loss: 0.04438
Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01339
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.05730
Collected Steps per Second: 11,185.30582
Overall Steps per Second: 8,808.30403
Timestep Collection Time: 4.47122
Timestep Consumption Time: 1.20660
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.67782
Cumulative Model Updates: 2,683
Cumulative Timesteps: 44,823,150
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 44823150...
Checkpoint 44823150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.15274
Policy Entropy: 5.36296
Value Function Loss: 0.03999
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02006
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.05578
Collected Steps per Second: 10,880.51124
Overall Steps per Second: 8,603.60085
Timestep Collection Time: 4.59905
Timestep Consumption Time: 1.21712
PPO Batch Consumption Time: 0.04993
Total Iteration Time: 5.81617
Cumulative Model Updates: 2,686
Cumulative Timesteps: 44,873,190
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.73356
Policy Entropy: 5.34687
Value Function Loss: 0.03601
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01822
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.04990
Collected Steps per Second: 10,966.65284
Overall Steps per Second: 8,597.45462
Timestep Collection Time: 4.56347
Timestep Consumption Time: 1.25755
PPO Batch Consumption Time: 0.07500
Total Iteration Time: 5.82103
Cumulative Model Updates: 2,689
Cumulative Timesteps: 44,923,236
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 44923236...
Checkpoint 44923236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.45401
Policy Entropy: 5.33721
Value Function Loss: 0.03602
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01840
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.04553
Collected Steps per Second: 11,068.82182
Overall Steps per Second: 8,674.68462
Timestep Collection Time: 4.52008
Timestep Consumption Time: 1.24750
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.76759
Cumulative Model Updates: 2,692
Cumulative Timesteps: 44,973,268
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70095
Policy Entropy: 5.33882
Value Function Loss: 0.03977
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01411
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.04571
Collected Steps per Second: 10,961.98559
Overall Steps per Second: 8,638.31029
Timestep Collection Time: 4.56176
Timestep Consumption Time: 1.22710
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.78886
Cumulative Model Updates: 2,695
Cumulative Timesteps: 45,023,274
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 45023274...
Checkpoint 45023274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.92721
Policy Entropy: 5.32783
Value Function Loss: 0.04547
Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01090
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.04704
Collected Steps per Second: 10,973.81210
Overall Steps per Second: 8,777.45263
Timestep Collection Time: 4.55940
Timestep Consumption Time: 1.14089
PPO Batch Consumption Time: 0.04944
Total Iteration Time: 5.70029
Cumulative Model Updates: 2,698
Cumulative Timesteps: 45,073,308
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62679
Policy Entropy: 5.29399
Value Function Loss: 0.04876
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02323
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.04733
Collected Steps per Second: 10,987.81976
Overall Steps per Second: 8,691.31244
Timestep Collection Time: 4.55068
Timestep Consumption Time: 1.20243
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.75310
Cumulative Model Updates: 2,701
Cumulative Timesteps: 45,123,310
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 45123310...
Checkpoint 45123310 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52301
Policy Entropy: 5.32335
Value Function Loss: 0.04978
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02050
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.04915
Collected Steps per Second: 10,936.59799
Overall Steps per Second: 8,678.40859
Timestep Collection Time: 4.57382
Timestep Consumption Time: 1.19014
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76396
Cumulative Model Updates: 2,704
Cumulative Timesteps: 45,173,332
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41099
Policy Entropy: 5.33246
Value Function Loss: 0.04484
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.05129
Collected Steps per Second: 11,070.69492
Overall Steps per Second: 8,763.55688
Timestep Collection Time: 4.52113
Timestep Consumption Time: 1.19025
PPO Batch Consumption Time: 0.05051
Total Iteration Time: 5.71138
Cumulative Model Updates: 2,707
Cumulative Timesteps: 45,223,384
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 45223384...
Checkpoint 45223384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.43098
Policy Entropy: 5.37343
Value Function Loss: 0.03996
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.05268
Collected Steps per Second: 10,955.07031
Overall Steps per Second: 8,660.31555
Timestep Collection Time: 4.56702
Timestep Consumption Time: 1.21014
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.77716
Cumulative Model Updates: 2,710
Cumulative Timesteps: 45,273,416
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.96103
Policy Entropy: 5.39130
Value Function Loss: 0.03509
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02283
Policy Update Magnitude: 0.04642
Value Function Update Magnitude: 0.05115
Collected Steps per Second: 10,929.83534
Overall Steps per Second: 8,617.72705
Timestep Collection Time: 4.57756
Timestep Consumption Time: 1.22815
PPO Batch Consumption Time: 0.06919
Total Iteration Time: 5.80571
Cumulative Model Updates: 2,713
Cumulative Timesteps: 45,323,448
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 45323448...
Checkpoint 45323448 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67786
Policy Entropy: 5.37200
Value Function Loss: 0.03179
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01456
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.05010
Collected Steps per Second: 11,152.04993
Overall Steps per Second: 8,748.49666
Timestep Collection Time: 4.48420
Timestep Consumption Time: 1.23198
PPO Batch Consumption Time: 0.05220
Total Iteration Time: 5.71618
Cumulative Model Updates: 2,716
Cumulative Timesteps: 45,373,456
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53443
Policy Entropy: 5.35250
Value Function Loss: 0.04047
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02097
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.05235
Collected Steps per Second: 10,838.38323
Overall Steps per Second: 8,567.37044
Timestep Collection Time: 4.61397
Timestep Consumption Time: 1.22306
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.83703
Cumulative Model Updates: 2,719
Cumulative Timesteps: 45,423,464
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 45423464...
Checkpoint 45423464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74020
Policy Entropy: 5.36025
Value Function Loss: 0.04381
Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04525
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.05414
Collected Steps per Second: 10,905.35529
Overall Steps per Second: 8,773.01496
Timestep Collection Time: 4.58729
Timestep Consumption Time: 1.11497
PPO Batch Consumption Time: 0.05036
Total Iteration Time: 5.70226
Cumulative Model Updates: 2,722
Cumulative Timesteps: 45,473,490
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40813
Policy Entropy: 5.35346
Value Function Loss: 0.04732
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.05635
Collected Steps per Second: 11,094.27321
Overall Steps per Second: 8,729.96214
Timestep Collection Time: 4.50683
Timestep Consumption Time: 1.22057
PPO Batch Consumption Time: 0.04936
Total Iteration Time: 5.72740
Cumulative Model Updates: 2,725
Cumulative Timesteps: 45,523,490
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 45523490...
Checkpoint 45523490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61432
Policy Entropy: 5.35364
Value Function Loss: 0.04196
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.05952
Collected Steps per Second: 10,864.73127
Overall Steps per Second: 8,633.68025
Timestep Collection Time: 4.60646
Timestep Consumption Time: 1.19037
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.79683
Cumulative Model Updates: 2,728
Cumulative Timesteps: 45,573,538
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80233
Policy Entropy: 5.40266
Value Function Loss: 0.04041
Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03617
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.05480
Collected Steps per Second: 10,985.24975
Overall Steps per Second: 8,858.08631
Timestep Collection Time: 4.55192
Timestep Consumption Time: 1.09309
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.64501
Cumulative Model Updates: 2,731
Cumulative Timesteps: 45,623,542
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 45623542...
Checkpoint 45623542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48632
Policy Entropy: 5.39692
Value Function Loss: 0.04210
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03090
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.05798
Collected Steps per Second: 10,937.71099
Overall Steps per Second: 8,662.66158
Timestep Collection Time: 4.57445
Timestep Consumption Time: 1.20137
PPO Batch Consumption Time: 0.05023
Total Iteration Time: 5.77582
Cumulative Model Updates: 2,734
Cumulative Timesteps: 45,673,576
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53812
Policy Entropy: 5.40749
Value Function Loss: 0.04109
Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03835
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.06115
Collected Steps per Second: 10,884.89486
Overall Steps per Second: 8,557.26948
Timestep Collection Time: 4.59518
Timestep Consumption Time: 1.24991
PPO Batch Consumption Time: 0.07733
Total Iteration Time: 5.84509
Cumulative Model Updates: 2,737
Cumulative Timesteps: 45,723,594
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 45723594...
Checkpoint 45723594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.12635
Policy Entropy: 5.40033
Value Function Loss: 0.04145
Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05007
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.05765
Collected Steps per Second: 11,091.31108
Overall Steps per Second: 8,736.19474
Timestep Collection Time: 4.50948
Timestep Consumption Time: 1.21567
PPO Batch Consumption Time: 0.05259
Total Iteration Time: 5.72515
Cumulative Model Updates: 2,740
Cumulative Timesteps: 45,773,610
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.31305
Policy Entropy: 5.38073
Value Function Loss: 0.04387
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02908
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.04968
Collected Steps per Second: 11,051.34637
Overall Steps per Second: 8,726.59239
Timestep Collection Time: 4.52922
Timestep Consumption Time: 1.20658
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.73580
Cumulative Model Updates: 2,743
Cumulative Timesteps: 45,823,664
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 45823664...
Checkpoint 45823664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.49337
Policy Entropy: 5.40547
Value Function Loss: 0.04741
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02786
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.04590
Collected Steps per Second: 10,912.41449
Overall Steps per Second: 8,791.83143
Timestep Collection Time: 4.58432
Timestep Consumption Time: 1.10573
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69005
Cumulative Model Updates: 2,746
Cumulative Timesteps: 45,873,690
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85554
Policy Entropy: 5.39843
Value Function Loss: 0.04574
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02060
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.05180
Collected Steps per Second: 10,891.46891
Overall Steps per Second: 8,595.27582
Timestep Collection Time: 4.59442
Timestep Consumption Time: 1.22738
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.82180
Cumulative Model Updates: 2,749
Cumulative Timesteps: 45,923,730
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 45923730...
Checkpoint 45923730 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.38333
Policy Entropy: 5.38008
Value Function Loss: 0.05257
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01865
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.05736
Collected Steps per Second: 10,964.55564
Overall Steps per Second: 8,684.96480
Timestep Collection Time: 4.56252
Timestep Consumption Time: 1.19755
PPO Batch Consumption Time: 0.05022
Total Iteration Time: 5.76007
Cumulative Model Updates: 2,752
Cumulative Timesteps: 45,973,756
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.07997
Policy Entropy: 5.38614
Value Function Loss: 0.05359
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.05770
Collected Steps per Second: 10,908.69599
Overall Steps per Second: 8,780.69869
Timestep Collection Time: 4.58735
Timestep Consumption Time: 1.11174
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.69909
Cumulative Model Updates: 2,755
Cumulative Timesteps: 46,023,798
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 46023798...
Checkpoint 46023798 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.49894
Policy Entropy: 5.39351
Value Function Loss: 0.05794
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.05795
Collected Steps per Second: 10,882.55009
Overall Steps per Second: 8,578.77892
Timestep Collection Time: 4.59506
Timestep Consumption Time: 1.23397
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.82903
Cumulative Model Updates: 2,758
Cumulative Timesteps: 46,073,804
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53397
Policy Entropy: 5.39884
Value Function Loss: 0.05346
Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01365
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.05378
Collected Steps per Second: 11,001.99500
Overall Steps per Second: 8,621.31378
Timestep Collection Time: 4.54481
Timestep Consumption Time: 1.25500
PPO Batch Consumption Time: 0.07443
Total Iteration Time: 5.79981
Cumulative Model Updates: 2,761
Cumulative Timesteps: 46,123,806
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 46123806...
Checkpoint 46123806 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75899
Policy Entropy: 5.37466
Value Function Loss: 0.05099
Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03645
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.04558
Collected Steps per Second: 11,016.25721
Overall Steps per Second: 8,694.76807
Timestep Collection Time: 4.54129
Timestep Consumption Time: 1.21252
PPO Batch Consumption Time: 0.05268
Total Iteration Time: 5.75381
Cumulative Model Updates: 2,764
Cumulative Timesteps: 46,173,834
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89282
Policy Entropy: 5.38518
Value Function Loss: 0.04738
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02380
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.04348
Collected Steps per Second: 10,926.80404
Overall Steps per Second: 8,620.55449
Timestep Collection Time: 4.57883
Timestep Consumption Time: 1.22497
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.80380
Cumulative Model Updates: 2,767
Cumulative Timesteps: 46,223,866
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 46223866...
Checkpoint 46223866 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63840
Policy Entropy: 5.38068
Value Function Loss: 0.04139
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01798
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.04869
Collected Steps per Second: 10,907.92725
Overall Steps per Second: 8,769.80066
Timestep Collection Time: 4.58492
Timestep Consumption Time: 1.11783
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.70275
Cumulative Model Updates: 2,770
Cumulative Timesteps: 46,273,878
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70008
Policy Entropy: 5.39942
Value Function Loss: 0.03923
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01953
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.04752
Collected Steps per Second: 10,926.60407
Overall Steps per Second: 8,623.10841
Timestep Collection Time: 4.57800
Timestep Consumption Time: 1.22292
PPO Batch Consumption Time: 0.04971
Total Iteration Time: 5.80092
Cumulative Model Updates: 2,773
Cumulative Timesteps: 46,323,900
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 46323900...
Checkpoint 46323900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57332
Policy Entropy: 5.41720
Value Function Loss: 0.03567
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01931
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.04779
Collected Steps per Second: 10,913.60089
Overall Steps per Second: 8,681.35195
Timestep Collection Time: 4.58144
Timestep Consumption Time: 1.17803
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.75947
Cumulative Model Updates: 2,776
Cumulative Timesteps: 46,373,900
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54994
Policy Entropy: 5.41205
Value Function Loss: 0.03933
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02097
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.04862
Collected Steps per Second: 11,155.82563
Overall Steps per Second: 8,765.13344
Timestep Collection Time: 4.48286
Timestep Consumption Time: 1.22270
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.70556
Cumulative Model Updates: 2,779
Cumulative Timesteps: 46,423,910
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 46423910...
Checkpoint 46423910 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47674
Policy Entropy: 5.37531
Value Function Loss: 0.04309
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01899
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.05380
Collected Steps per Second: 10,891.23864
Overall Steps per Second: 8,608.82224
Timestep Collection Time: 4.59268
Timestep Consumption Time: 1.21764
PPO Batch Consumption Time: 0.05253
Total Iteration Time: 5.81032
Cumulative Model Updates: 2,782
Cumulative Timesteps: 46,473,930
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64721
Policy Entropy: 5.37823
Value Function Loss: 0.04405
Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01527
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.04879
Collected Steps per Second: 10,998.08271
Overall Steps per Second: 8,593.65702
Timestep Collection Time: 4.54643
Timestep Consumption Time: 1.27205
PPO Batch Consumption Time: 0.08200
Total Iteration Time: 5.81848
Cumulative Model Updates: 2,785
Cumulative Timesteps: 46,523,932
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 46523932...
Checkpoint 46523932 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89911
Policy Entropy: 5.38675
Value Function Loss: 0.04069
Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01189
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.04432
Collected Steps per Second: 11,132.18957
Overall Steps per Second: 8,725.77183
Timestep Collection Time: 4.49364
Timestep Consumption Time: 1.23927
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.73290
Cumulative Model Updates: 2,788
Cumulative Timesteps: 46,573,956
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63529
Policy Entropy: 5.37436
Value Function Loss: 0.03648
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.04313
Collected Steps per Second: 10,940.66560
Overall Steps per Second: 8,635.59424
Timestep Collection Time: 4.57175
Timestep Consumption Time: 1.22032
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.79207
Cumulative Model Updates: 2,791
Cumulative Timesteps: 46,623,974
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 46623974...
Checkpoint 46623974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52193
Policy Entropy: 5.37239
Value Function Loss: 0.03632
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.04643
Collected Steps per Second: 10,853.21608
Overall Steps per Second: 8,692.41950
Timestep Collection Time: 4.61080
Timestep Consumption Time: 1.14617
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.75697
Cumulative Model Updates: 2,794
Cumulative Timesteps: 46,674,016
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.38700
Policy Entropy: 5.36819
Value Function Loss: 0.03515
Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.00661
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.05149
Collected Steps per Second: 10,853.03582
Overall Steps per Second: 8,592.55407
Timestep Collection Time: 4.60977
Timestep Consumption Time: 1.21271
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.82248
Cumulative Model Updates: 2,797
Cumulative Timesteps: 46,724,046
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 46724046...
Checkpoint 46724046 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86288
Policy Entropy: 5.37891
Value Function Loss: 0.03491
Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01311
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.05281
Collected Steps per Second: 10,888.60598
Overall Steps per Second: 8,692.03788
Timestep Collection Time: 4.59398
Timestep Consumption Time: 1.16095
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.75492
Cumulative Model Updates: 2,800
Cumulative Timesteps: 46,774,068
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50884
Policy Entropy: 5.37574
Value Function Loss: 0.04049
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01760
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.04997
Collected Steps per Second: 11,169.77686
Overall Steps per Second: 8,832.93360
Timestep Collection Time: 4.47977
Timestep Consumption Time: 1.18517
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.66494
Cumulative Model Updates: 2,803
Cumulative Timesteps: 46,824,106
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 46824106...
Checkpoint 46824106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60557
Policy Entropy: 5.37193
Value Function Loss: 0.04307
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01570
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.05071
Collected Steps per Second: 10,931.61268
Overall Steps per Second: 8,619.13704
Timestep Collection Time: 4.57700
Timestep Consumption Time: 1.22799
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 5.80499
Cumulative Model Updates: 2,806
Cumulative Timesteps: 46,874,140
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.56616
Policy Entropy: 5.34782
Value Function Loss: 0.04101
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02875
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.05073
Collected Steps per Second: 10,910.94266
Overall Steps per Second: 8,579.93221
Timestep Collection Time: 4.58494
Timestep Consumption Time: 1.24564
PPO Batch Consumption Time: 0.06684
Total Iteration Time: 5.83058
Cumulative Model Updates: 2,809
Cumulative Timesteps: 46,924,166
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 46924166...
Checkpoint 46924166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.34202
Policy Entropy: 5.32587
Value Function Loss: 0.04116
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.06642
Value Function Update Magnitude: 0.04882
Collected Steps per Second: 11,183.05302
Overall Steps per Second: 8,772.06613
Timestep Collection Time: 4.47248
Timestep Consumption Time: 1.22925
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.70174
Cumulative Model Updates: 2,812
Cumulative Timesteps: 46,974,182
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.00919
Policy Entropy: 5.32210
Value Function Loss: 0.04259
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.07092
Value Function Update Magnitude: 0.05123
Collected Steps per Second: 10,961.96118
Overall Steps per Second: 8,667.84967
Timestep Collection Time: 4.56378
Timestep Consumption Time: 1.20789
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.77167
Cumulative Model Updates: 2,815
Cumulative Timesteps: 47,024,210
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 47024210...
Checkpoint 47024210 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48714
Policy Entropy: 5.35632
Value Function Loss: 0.04247
Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05153
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.06153
Collected Steps per Second: 10,998.67029
Overall Steps per Second: 8,847.82622
Timestep Collection Time: 4.54655
Timestep Consumption Time: 1.10523
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.65178
Cumulative Model Updates: 2,818
Cumulative Timesteps: 47,074,216
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82100
Policy Entropy: 5.37503
Value Function Loss: 0.03754
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03049
Policy Update Magnitude: 0.07254
Value Function Update Magnitude: 0.06748
Collected Steps per Second: 10,913.76437
Overall Steps per Second: 8,617.08086
Timestep Collection Time: 4.58247
Timestep Consumption Time: 1.22135
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.80382
Cumulative Model Updates: 2,821
Cumulative Timesteps: 47,124,228
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 47124228...
Checkpoint 47124228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46735
Policy Entropy: 5.39831
Value Function Loss: 0.03748
Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04465
Policy Update Magnitude: 0.07848
Value Function Update Magnitude: 0.05533
Collected Steps per Second: 10,914.90332
Overall Steps per Second: 8,711.51817
Timestep Collection Time: 4.58492
Timestep Consumption Time: 1.15965
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.74458
Cumulative Model Updates: 2,824
Cumulative Timesteps: 47,174,272
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.72191
Policy Entropy: 5.41076
Value Function Loss: 0.04138
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.07207
Value Function Update Magnitude: 0.04977
Collected Steps per Second: 10,771.42769
Overall Steps per Second: 8,711.45648
Timestep Collection Time: 4.64581
Timestep Consumption Time: 1.09858
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.74439
Cumulative Model Updates: 2,827
Cumulative Timesteps: 47,224,314
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 47224314...
Checkpoint 47224314 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.43972
Policy Entropy: 5.41129
Value Function Loss: 0.04389
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02863
Policy Update Magnitude: 0.07751
Value Function Update Magnitude: 0.05567
Collected Steps per Second: 10,971.39206
Overall Steps per Second: 8,650.74308
Timestep Collection Time: 4.56041
Timestep Consumption Time: 1.22337
PPO Batch Consumption Time: 0.05152
Total Iteration Time: 5.78378
Cumulative Model Updates: 2,830
Cumulative Timesteps: 47,274,348
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.48405
Policy Entropy: 5.43552
Value Function Loss: 0.04077
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.08075
Value Function Update Magnitude: 0.05372
Collected Steps per Second: 10,886.29120
Overall Steps per Second: 8,539.66475
Timestep Collection Time: 4.59569
Timestep Consumption Time: 1.26286
PPO Batch Consumption Time: 0.07139
Total Iteration Time: 5.85854
Cumulative Model Updates: 2,833
Cumulative Timesteps: 47,324,378
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 47324378...
Checkpoint 47324378 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41809
Policy Entropy: 5.43926
Value Function Loss: 0.03678
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 0.08224
Value Function Update Magnitude: 0.05181
Collected Steps per Second: 11,047.96854
Overall Steps per Second: 8,694.17269
Timestep Collection Time: 4.52952
Timestep Consumption Time: 1.22629
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.75581
Cumulative Model Updates: 2,836
Cumulative Timesteps: 47,374,420
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90698
Policy Entropy: 5.42476
Value Function Loss: 0.03581
Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04189
Policy Update Magnitude: 0.07755
Value Function Update Magnitude: 0.04949
Collected Steps per Second: 10,835.34900
Overall Steps per Second: 8,581.48149
Timestep Collection Time: 4.61674
Timestep Consumption Time: 1.21256
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.82930
Cumulative Model Updates: 2,839
Cumulative Timesteps: 47,424,444
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 47424444...
Checkpoint 47424444 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40477
Policy Entropy: 5.40686
Value Function Loss: 0.03893
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02051
Policy Update Magnitude: 0.06764
Value Function Update Magnitude: 0.04990
Collected Steps per Second: 10,925.30452
Overall Steps per Second: 8,767.22927
Timestep Collection Time: 4.58019
Timestep Consumption Time: 1.12743
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.70762
Cumulative Model Updates: 2,842
Cumulative Timesteps: 47,474,484
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77980
Policy Entropy: 5.43061
Value Function Loss: 0.04232
Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03882
Policy Update Magnitude: 0.06251
Value Function Update Magnitude: 0.05656
Collected Steps per Second: 11,000.35897
Overall Steps per Second: 8,665.16171
Timestep Collection Time: 4.54803
Timestep Consumption Time: 1.22566
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.77369
Cumulative Model Updates: 2,845
Cumulative Timesteps: 47,524,514
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 47524514...
Checkpoint 47524514 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55542
Policy Entropy: 5.42246
Value Function Loss: 0.04634
Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03545
Policy Update Magnitude: 0.06030
Value Function Update Magnitude: 0.05607
Collected Steps per Second: 10,916.65861
Overall Steps per Second: 8,626.77226
Timestep Collection Time: 4.58162
Timestep Consumption Time: 1.21614
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.79777
Cumulative Model Updates: 2,848
Cumulative Timesteps: 47,574,530
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82613
Policy Entropy: 5.43490
Value Function Loss: 0.04925
Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04410
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.05494
Collected Steps per Second: 10,818.47333
Overall Steps per Second: 8,755.44470
Timestep Collection Time: 4.62172
Timestep Consumption Time: 1.08901
PPO Batch Consumption Time: 0.05032
Total Iteration Time: 5.71073
Cumulative Model Updates: 2,851
Cumulative Timesteps: 47,624,530
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 47624530...
Checkpoint 47624530 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64122
Policy Entropy: 5.46200
Value Function Loss: 0.04948
Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.05525
Collected Steps per Second: 10,908.62443
Overall Steps per Second: 8,602.92315
Timestep Collection Time: 4.58518
Timestep Consumption Time: 1.22889
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.81407
Cumulative Model Updates: 2,854
Cumulative Timesteps: 47,674,548
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.56398
Policy Entropy: 5.45951
Value Function Loss: 0.04278
Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04439
Policy Update Magnitude: 0.06488
Value Function Update Magnitude: 0.06097
Collected Steps per Second: 10,877.49416
Overall Steps per Second: 8,588.02706
Timestep Collection Time: 4.60051
Timestep Consumption Time: 1.22644
PPO Batch Consumption Time: 0.06800
Total Iteration Time: 5.82695
Cumulative Model Updates: 2,857
Cumulative Timesteps: 47,724,590
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 47724590...
Checkpoint 47724590 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54074
Policy Entropy: 5.45873
Value Function Loss: 0.04725
Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.06153
Collected Steps per Second: 11,094.60492
Overall Steps per Second: 8,732.09148
Timestep Collection Time: 4.50868
Timestep Consumption Time: 1.21985
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.72852
Cumulative Model Updates: 2,860
Cumulative Timesteps: 47,774,612
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.43209
Policy Entropy: 5.47517
Value Function Loss: 0.04595
Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05737
Policy Update Magnitude: 0.05900
Value Function Update Magnitude: 0.05868
Collected Steps per Second: 10,887.03319
Overall Steps per Second: 8,603.76592
Timestep Collection Time: 4.59593
Timestep Consumption Time: 1.21967
PPO Batch Consumption Time: 0.05154
Total Iteration Time: 5.81559
Cumulative Model Updates: 2,863
Cumulative Timesteps: 47,824,648
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 47824648...
Checkpoint 47824648 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41122
Policy Entropy: 5.46939
Value Function Loss: 0.04999
Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07049
Policy Update Magnitude: 0.06713
Value Function Update Magnitude: 0.05539
Collected Steps per Second: 10,864.25380
Overall Steps per Second: 8,711.62003
Timestep Collection Time: 4.60575
Timestep Consumption Time: 1.13808
PPO Batch Consumption Time: 0.04966
Total Iteration Time: 5.74382
Cumulative Model Updates: 2,866
Cumulative Timesteps: 47,874,686
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59909
Policy Entropy: 5.45397
Value Function Loss: 0.03942
Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05305
Policy Update Magnitude: 0.06588
Value Function Update Magnitude: 0.05006
Collected Steps per Second: 11,031.92912
Overall Steps per Second: 8,714.67985
Timestep Collection Time: 4.53411
Timestep Consumption Time: 1.20563
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.73974
Cumulative Model Updates: 2,869
Cumulative Timesteps: 47,924,706
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 47924706...
Checkpoint 47924706 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61050
Policy Entropy: 5.43299
Value Function Loss: 0.04272
Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04614
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.04988
Collected Steps per Second: 11,055.88621
Overall Steps per Second: 8,722.30296
Timestep Collection Time: 4.52338
Timestep Consumption Time: 1.21020
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.73358
Cumulative Model Updates: 2,872
Cumulative Timesteps: 47,974,716
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63254
Policy Entropy: 5.41890
Value Function Loss: 0.04285
Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04109
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.05208
Collected Steps per Second: 10,902.67634
Overall Steps per Second: 8,752.89457
Timestep Collection Time: 4.59080
Timestep Consumption Time: 1.12754
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.71834
Cumulative Model Updates: 2,875
Cumulative Timesteps: 48,024,768
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 48024768...
Checkpoint 48024768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77609
Policy Entropy: 5.41298
Value Function Loss: 0.04745
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.05410
Collected Steps per Second: 10,871.14262
Overall Steps per Second: 8,618.35855
Timestep Collection Time: 4.60375
Timestep Consumption Time: 1.20339
PPO Batch Consumption Time: 0.04975
Total Iteration Time: 5.80714
Cumulative Model Updates: 2,878
Cumulative Timesteps: 48,074,816
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86861
Policy Entropy: 5.43344
Value Function Loss: 0.04216
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03115
Policy Update Magnitude: 0.06485
Value Function Update Magnitude: 0.05376
Collected Steps per Second: 10,953.52854
Overall Steps per Second: 8,535.48069
Timestep Collection Time: 4.56474
Timestep Consumption Time: 1.29316
PPO Batch Consumption Time: 0.08333
Total Iteration Time: 5.85790
Cumulative Model Updates: 2,881
Cumulative Timesteps: 48,124,816
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 48124816...
Checkpoint 48124816 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61966
Policy Entropy: 5.40466
Value Function Loss: 0.04252
Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01357
Policy Update Magnitude: 0.06579
Value Function Update Magnitude: 0.05484
Collected Steps per Second: 11,132.38452
Overall Steps per Second: 8,738.07222
Timestep Collection Time: 4.49481
Timestep Consumption Time: 1.23162
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.72643
Cumulative Model Updates: 2,884
Cumulative Timesteps: 48,174,854
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82682
Policy Entropy: 5.40703
Value Function Loss: 0.04544
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.05404
Collected Steps per Second: 10,816.77273
Overall Steps per Second: 8,589.40267
Timestep Collection Time: 4.62467
Timestep Consumption Time: 1.19925
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.82392
Cumulative Model Updates: 2,887
Cumulative Timesteps: 48,224,878
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 48224878...
Checkpoint 48224878 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89873
Policy Entropy: 5.41649
Value Function Loss: 0.04779
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.06398
Value Function Update Magnitude: 0.05252
Collected Steps per Second: 10,937.15743
Overall Steps per Second: 8,786.60560
Timestep Collection Time: 4.57431
Timestep Consumption Time: 1.11958
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.69389
Cumulative Model Updates: 2,890
Cumulative Timesteps: 48,274,908
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84077
Policy Entropy: 5.42685
Value Function Loss: 0.04818
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01802
Policy Update Magnitude: 0.07018
Value Function Update Magnitude: 0.05203
Collected Steps per Second: 10,997.19335
Overall Steps per Second: 8,709.23305
Timestep Collection Time: 4.55080
Timestep Consumption Time: 1.19552
PPO Batch Consumption Time: 0.04986
Total Iteration Time: 5.74632
Cumulative Model Updates: 2,893
Cumulative Timesteps: 48,324,954
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 48324954...
Checkpoint 48324954 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.18740
Policy Entropy: 5.42657
Value Function Loss: 0.04391
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01871
Policy Update Magnitude: 0.06842
Value Function Update Magnitude: 0.05363
Collected Steps per Second: 10,913.53143
Overall Steps per Second: 8,656.91858
Timestep Collection Time: 4.58660
Timestep Consumption Time: 1.19560
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.78220
Cumulative Model Updates: 2,896
Cumulative Timesteps: 48,375,010
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55710
Policy Entropy: 5.47294
Value Function Loss: 0.03868
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01615
Policy Update Magnitude: 0.06733
Value Function Update Magnitude: 0.06170
Collected Steps per Second: 10,920.23861
Overall Steps per Second: 8,809.07663
Timestep Collection Time: 4.58250
Timestep Consumption Time: 1.09823
PPO Batch Consumption Time: 0.05058
Total Iteration Time: 5.68073
Cumulative Model Updates: 2,899
Cumulative Timesteps: 48,425,052
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 48425052...
Checkpoint 48425052 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.53667
Policy Entropy: 5.49337
Value Function Loss: 0.04258
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 0.06132
Value Function Update Magnitude: 0.06639
Collected Steps per Second: 10,965.49163
Overall Steps per Second: 8,690.36921
Timestep Collection Time: 4.56122
Timestep Consumption Time: 1.19412
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.75534
Cumulative Model Updates: 2,902
Cumulative Timesteps: 48,475,068
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50505
Policy Entropy: 5.46695
Value Function Loss: 0.04230
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.06102
Value Function Update Magnitude: 0.06310
Collected Steps per Second: 10,859.72293
Overall Steps per Second: 8,515.39853
Timestep Collection Time: 4.60822
Timestep Consumption Time: 1.26866
PPO Batch Consumption Time: 0.07732
Total Iteration Time: 5.87688
Cumulative Model Updates: 2,905
Cumulative Timesteps: 48,525,112
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 48525112...
Checkpoint 48525112 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68536
Policy Entropy: 5.44931
Value Function Loss: 0.04767
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.06210
Value Function Update Magnitude: 0.05947
Collected Steps per Second: 11,181.85045
Overall Steps per Second: 8,767.14667
Timestep Collection Time: 4.47529
Timestep Consumption Time: 1.23261
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.70790
Cumulative Model Updates: 2,908
Cumulative Timesteps: 48,575,154
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59891
Policy Entropy: 5.48696
Value Function Loss: 0.04463
Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04746
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.06043
Collected Steps per Second: 10,949.31880
Overall Steps per Second: 8,663.49199
Timestep Collection Time: 4.57070
Timestep Consumption Time: 1.20596
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.77665
Cumulative Model Updates: 2,911
Cumulative Timesteps: 48,625,200
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 48625200...
Checkpoint 48625200 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03883
Policy Entropy: 5.46673
Value Function Loss: 0.04456
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.06185
Value Function Update Magnitude: 0.05642
Collected Steps per Second: 10,688.82712
Overall Steps per Second: 8,665.68948
Timestep Collection Time: 4.67928
Timestep Consumption Time: 1.09245
PPO Batch Consumption Time: 0.05003
Total Iteration Time: 5.77173
Cumulative Model Updates: 2,914
Cumulative Timesteps: 48,675,216
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47262
Policy Entropy: 5.46325
Value Function Loss: 0.04065
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03074
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.05386
Collected Steps per Second: 10,971.23024
Overall Steps per Second: 8,683.05304
Timestep Collection Time: 4.55920
Timestep Consumption Time: 1.20145
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.76065
Cumulative Model Updates: 2,917
Cumulative Timesteps: 48,725,236
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 48725236...
Checkpoint 48725236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68035
Policy Entropy: 5.48225
Value Function Loss: 0.03712
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01733
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.05588
Collected Steps per Second: 10,898.61990
Overall Steps per Second: 8,670.06574
Timestep Collection Time: 4.59086
Timestep Consumption Time: 1.18003
PPO Batch Consumption Time: 0.05081
Total Iteration Time: 5.77089
Cumulative Model Updates: 2,920
Cumulative Timesteps: 48,775,270
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88578
Policy Entropy: 5.47973
Value Function Loss: 0.04081
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.05705
Collected Steps per Second: 11,135.68448
Overall Steps per Second: 8,803.07599
Timestep Collection Time: 4.49348
Timestep Consumption Time: 1.19067
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.68415
Cumulative Model Updates: 2,923
Cumulative Timesteps: 48,825,308
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 48825308...
Checkpoint 48825308 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88095
Policy Entropy: 5.48923
Value Function Loss: 0.04508
Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04818
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.05801
Collected Steps per Second: 10,917.40304
Overall Steps per Second: 8,645.03531
Timestep Collection Time: 4.58113
Timestep Consumption Time: 1.20416
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78529
Cumulative Model Updates: 2,926
Cumulative Timesteps: 48,875,322
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86132
Policy Entropy: 5.49211
Value Function Loss: 0.04415
Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04076
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.05810
Collected Steps per Second: 10,918.28519
Overall Steps per Second: 8,579.50130
Timestep Collection Time: 4.58131
Timestep Consumption Time: 1.24887
PPO Batch Consumption Time: 0.07320
Total Iteration Time: 5.83018
Cumulative Model Updates: 2,929
Cumulative Timesteps: 48,925,342
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 48925342...
Checkpoint 48925342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.58809
Policy Entropy: 5.51228
Value Function Loss: 0.04386
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03354
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.05399
Collected Steps per Second: 11,149.57640
Overall Steps per Second: 8,765.23454
Timestep Collection Time: 4.48878
Timestep Consumption Time: 1.22105
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.70983
Cumulative Model Updates: 2,932
Cumulative Timesteps: 48,975,390
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54123
Policy Entropy: 5.48180
Value Function Loss: 0.04156
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.05262
Collected Steps per Second: 10,894.40367
Overall Steps per Second: 8,593.32858
Timestep Collection Time: 4.59263
Timestep Consumption Time: 1.22979
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.82242
Cumulative Model Updates: 2,935
Cumulative Timesteps: 49,025,424
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 49025424...
Checkpoint 49025424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62942
Policy Entropy: 5.49456
Value Function Loss: 0.04162
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02168
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.05498
Collected Steps per Second: 10,877.85196
Overall Steps per Second: 8,772.51635
Timestep Collection Time: 4.59889
Timestep Consumption Time: 1.10370
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.70258
Cumulative Model Updates: 2,938
Cumulative Timesteps: 49,075,450
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61959
Policy Entropy: 5.53317
Value Function Loss: 0.04092
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.05291
Collected Steps per Second: 10,946.65796
Overall Steps per Second: 8,637.44429
Timestep Collection Time: 4.57108
Timestep Consumption Time: 1.22207
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.79315
Cumulative Model Updates: 2,941
Cumulative Timesteps: 49,125,488
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 49125488...
Checkpoint 49125488 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50276
Policy Entropy: 5.49922
Value Function Loss: 0.04616
Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01350
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.05161
Collected Steps per Second: 10,973.18266
Overall Steps per Second: 8,751.41301
Timestep Collection Time: 4.55984
Timestep Consumption Time: 1.15763
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.71748
Cumulative Model Updates: 2,944
Cumulative Timesteps: 49,175,524
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52379
Policy Entropy: 5.48354
Value Function Loss: 0.04866
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.06264
Value Function Update Magnitude: 0.05137
Collected Steps per Second: 11,079.74970
Overall Steps per Second: 8,740.62555
Timestep Collection Time: 4.51418
Timestep Consumption Time: 1.20806
PPO Batch Consumption Time: 0.05096
Total Iteration Time: 5.72224
Cumulative Model Updates: 2,947
Cumulative Timesteps: 49,225,540
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 49225540...
Checkpoint 49225540 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66769
Policy Entropy: 5.48953
Value Function Loss: 0.04889
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03049
Policy Update Magnitude: 0.06767
Value Function Update Magnitude: 0.05387
Collected Steps per Second: 10,966.93081
Overall Steps per Second: 8,670.21864
Timestep Collection Time: 4.56244
Timestep Consumption Time: 1.20858
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.77102
Cumulative Model Updates: 2,950
Cumulative Timesteps: 49,275,576
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62627
Policy Entropy: 5.49397
Value Function Loss: 0.04815
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.05823
Collected Steps per Second: 10,792.66660
Overall Steps per Second: 8,463.83694
Timestep Collection Time: 4.63500
Timestep Consumption Time: 1.27532
PPO Batch Consumption Time: 0.08203
Total Iteration Time: 5.91032
Cumulative Model Updates: 2,953
Cumulative Timesteps: 49,325,600
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 49325600...
Checkpoint 49325600 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.21924
Policy Entropy: 5.50606
Value Function Loss: 0.04533
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02318
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.06150
Collected Steps per Second: 11,193.50971
Overall Steps per Second: 8,793.60699
Timestep Collection Time: 4.47063
Timestep Consumption Time: 1.22010
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.69073
Cumulative Model Updates: 2,956
Cumulative Timesteps: 49,375,642
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84781
Policy Entropy: 5.52843
Value Function Loss: 0.04739
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03110
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.06209
Collected Steps per Second: 10,995.21442
Overall Steps per Second: 8,692.56786
Timestep Collection Time: 4.54871
Timestep Consumption Time: 1.20494
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.75365
Cumulative Model Updates: 2,959
Cumulative Timesteps: 49,425,656
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 49425656...
Checkpoint 49425656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52036
Policy Entropy: 5.50110
Value Function Loss: 0.04504
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03120
Policy Update Magnitude: 0.06213
Value Function Update Magnitude: 0.05805
Collected Steps per Second: 10,904.29125
Overall Steps per Second: 8,781.56497
Timestep Collection Time: 4.58737
Timestep Consumption Time: 1.10888
PPO Batch Consumption Time: 0.05134
Total Iteration Time: 5.69625
Cumulative Model Updates: 2,962
Cumulative Timesteps: 49,475,678
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.76784
Policy Entropy: 5.49284
Value Function Loss: 0.04390
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.05420
Collected Steps per Second: 10,932.34791
Overall Steps per Second: 8,644.48378
Timestep Collection Time: 4.57633
Timestep Consumption Time: 1.21118
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.78751
Cumulative Model Updates: 2,965
Cumulative Timesteps: 49,525,708
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 49525708...
Checkpoint 49525708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.19498
Policy Entropy: 5.50520
Value Function Loss: 0.04237
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02076
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.05139
Collected Steps per Second: 10,854.31376
Overall Steps per Second: 8,629.42165
Timestep Collection Time: 4.60996
Timestep Consumption Time: 1.18857
PPO Batch Consumption Time: 0.05153
Total Iteration Time: 5.79853
Cumulative Model Updates: 2,968
Cumulative Timesteps: 49,575,746
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89726
Policy Entropy: 5.49914
Value Function Loss: 0.04212
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01710
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.05382
Collected Steps per Second: 10,887.07851
Overall Steps per Second: 8,780.61899
Timestep Collection Time: 4.59738
Timestep Consumption Time: 1.10290
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.70028
Cumulative Model Updates: 2,971
Cumulative Timesteps: 49,625,798
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 49625798...
Checkpoint 49625798 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65071
Policy Entropy: 5.48051
Value Function Loss: 0.04240
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 0.06744
Value Function Update Magnitude: 0.06233
Collected Steps per Second: 11,012.07146
Overall Steps per Second: 8,704.14390
Timestep Collection Time: 4.54138
Timestep Consumption Time: 1.20416
PPO Batch Consumption Time: 0.05069
Total Iteration Time: 5.74554
Cumulative Model Updates: 2,974
Cumulative Timesteps: 49,675,808
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67064
Policy Entropy: 5.47345
Value Function Loss: 0.04593
Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04022
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.06377
Collected Steps per Second: 10,902.14652
Overall Steps per Second: 8,606.18430
Timestep Collection Time: 4.58735
Timestep Consumption Time: 1.22382
PPO Batch Consumption Time: 0.07100
Total Iteration Time: 5.81117
Cumulative Model Updates: 2,977
Cumulative Timesteps: 49,725,820
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 49725820...
Checkpoint 49725820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55495
Policy Entropy: 5.51028
Value Function Loss: 0.04371
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03526
Policy Update Magnitude: 0.06912
Value Function Update Magnitude: 0.05824
Collected Steps per Second: 11,156.91641
Overall Steps per Second: 8,781.30482
Timestep Collection Time: 4.48206
Timestep Consumption Time: 1.21254
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.69460
Cumulative Model Updates: 2,980
Cumulative Timesteps: 49,775,826
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.72289
Policy Entropy: 5.52213
Value Function Loss: 0.04832
Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.05937
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.05966
Collected Steps per Second: 10,814.50608
Overall Steps per Second: 8,590.40102
Timestep Collection Time: 4.62915
Timestep Consumption Time: 1.19851
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.82767
Cumulative Model Updates: 2,983
Cumulative Timesteps: 49,825,888
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
Saving checkpoint 49825888...
Checkpoint 49825888 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.58122
Policy Entropy: 5.54695
Value Function Loss: 0.04174
Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.03909
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.05934
Collected Steps per Second: 10,886.15234
Overall Steps per Second: 8,765.48880
Timestep Collection Time: 4.59556
Timestep Consumption Time: 1.11182
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.70738
Cumulative Model Updates: 2,986
Cumulative Timesteps: 49,875,916
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57133
Policy Entropy: 5.53657
Value Function Loss: 0.04393
Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05609
Policy Update Magnitude: 0.05875
Value Function Update Magnitude: 0.05810
Collected Steps per Second: 10,993.32558
Overall Steps per Second: 8,673.58411
Timestep Collection Time: 4.55113
Timestep Consumption Time: 1.21719
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.76832
Cumulative Model Updates: 2,989
Cumulative Timesteps: 49,925,948
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 49925948...
Checkpoint 49925948 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66393
Policy Entropy: 5.53736
Value Function Loss: 0.03941
Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03740
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.05628
Collected Steps per Second: 10,908.00583
Overall Steps per Second: 8,624.64799
Timestep Collection Time: 4.58819
Timestep Consumption Time: 1.21471
PPO Batch Consumption Time: 0.05134
Total Iteration Time: 5.80290
Cumulative Model Updates: 2,992
Cumulative Timesteps: 49,975,996
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.54603
Policy Entropy: 5.53949
Value Function Loss: 0.04097
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02964
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.05856
Collected Steps per Second: 10,992.78435
Overall Steps per Second: 8,845.21908
Timestep Collection Time: 4.54953
Timestep Consumption Time: 1.10460
PPO Batch Consumption Time: 0.05096
Total Iteration Time: 5.65413
Cumulative Model Updates: 2,995
Cumulative Timesteps: 50,026,008
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 50026008...
Checkpoint 50026008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47548
Policy Entropy: 5.53711
Value Function Loss: 0.04181
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.06156
Collected Steps per Second: 10,847.22173
Overall Steps per Second: 8,589.91416
Timestep Collection Time: 4.60984
Timestep Consumption Time: 1.21140
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.82125
Cumulative Model Updates: 2,998
Cumulative Timesteps: 50,076,012
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40223
Policy Entropy: 5.53287
Value Function Loss: 0.03991
Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.00606
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.06256
Collected Steps per Second: 10,895.28905
Overall Steps per Second: 8,576.90364
Timestep Collection Time: 4.59061
Timestep Consumption Time: 1.24087
PPO Batch Consumption Time: 0.07900
Total Iteration Time: 5.83148
Cumulative Model Updates: 3,001
Cumulative Timesteps: 50,126,028
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 50126028...
Checkpoint 50126028 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80259
Policy Entropy: 5.53746
Value Function Loss: 0.04000
Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.00762
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.05511
Collected Steps per Second: 11,015.09995
Overall Steps per Second: 8,729.76264
Timestep Collection Time: 4.54068
Timestep Consumption Time: 1.18869
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.72937
Cumulative Model Updates: 3,004
Cumulative Timesteps: 50,176,044
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68068
Policy Entropy: 5.53778
Value Function Loss: 0.03988
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01248
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.05090
Collected Steps per Second: 10,961.53526
Overall Steps per Second: 8,668.93471
Timestep Collection Time: 4.56615
Timestep Consumption Time: 1.20757
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.77372
Cumulative Model Updates: 3,007
Cumulative Timesteps: 50,226,096
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 50226096...
Checkpoint 50226096 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78301
Policy Entropy: 5.52837
Value Function Loss: 0.04339
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01984
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.05326
Collected Steps per Second: 10,947.81816
Overall Steps per Second: 8,811.71142
Timestep Collection Time: 4.56913
Timestep Consumption Time: 1.10763
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.67676
Cumulative Model Updates: 3,010
Cumulative Timesteps: 50,276,118
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.29677
Policy Entropy: 5.49333
Value Function Loss: 0.04360
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03055
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.06046
Collected Steps per Second: 10,906.84735
Overall Steps per Second: 8,601.88069
Timestep Collection Time: 4.58574
Timestep Consumption Time: 1.22880
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.81454
Cumulative Model Updates: 3,013
Cumulative Timesteps: 50,326,134
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 50326134...
Checkpoint 50326134 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66871
Policy Entropy: 5.53253
Value Function Loss: 0.03908
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03020
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.06706
Collected Steps per Second: 10,960.73957
Overall Steps per Second: 8,733.22051
Timestep Collection Time: 4.56338
Timestep Consumption Time: 1.16395
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.72733
Cumulative Model Updates: 3,016
Cumulative Timesteps: 50,376,152
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.01207
Policy Entropy: 5.53935
Value Function Loss: 0.04474
Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03725
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.06753
Collected Steps per Second: 11,097.14790
Overall Steps per Second: 8,749.44496
Timestep Collection Time: 4.50963
Timestep Consumption Time: 1.21005
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.71968
Cumulative Model Updates: 3,019
Cumulative Timesteps: 50,426,196
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 50426196...
Checkpoint 50426196 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41520
Policy Entropy: 5.52839
Value Function Loss: 0.04465
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.06043
Collected Steps per Second: 10,894.76495
Overall Steps per Second: 8,615.96733
Timestep Collection Time: 4.59395
Timestep Consumption Time: 1.21503
PPO Batch Consumption Time: 0.05101
Total Iteration Time: 5.80898
Cumulative Model Updates: 3,022
Cumulative Timesteps: 50,476,246
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.72950
Policy Entropy: 5.52406
Value Function Loss: 0.04713
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02046
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.05569
Collected Steps per Second: 10,961.93188
Overall Steps per Second: 8,582.93793
Timestep Collection Time: 4.56233
Timestep Consumption Time: 1.26457
PPO Batch Consumption Time: 0.08300
Total Iteration Time: 5.82691
Cumulative Model Updates: 3,025
Cumulative Timesteps: 50,526,258
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 50526258...
Checkpoint 50526258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79309
Policy Entropy: 5.52836
Value Function Loss: 0.04114
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03447
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.05584
Collected Steps per Second: 11,235.80238
Overall Steps per Second: 8,804.38754
Timestep Collection Time: 4.45237
Timestep Consumption Time: 1.22957
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.68194
Cumulative Model Updates: 3,028
Cumulative Timesteps: 50,576,284
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67099
Policy Entropy: 5.51849
Value Function Loss: 0.04176
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02399
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.05285
Collected Steps per Second: 10,787.65511
Overall Steps per Second: 8,567.80239
Timestep Collection Time: 4.63901
Timestep Consumption Time: 1.20193
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.84094
Cumulative Model Updates: 3,031
Cumulative Timesteps: 50,626,328
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 50626328...
Checkpoint 50626328 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52680
Policy Entropy: 5.56521
Value Function Loss: 0.04249
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01824
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.05003
Collected Steps per Second: 10,922.29467
Overall Steps per Second: 8,795.42791
Timestep Collection Time: 4.58054
Timestep Consumption Time: 1.10764
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.68818
Cumulative Model Updates: 3,034
Cumulative Timesteps: 50,676,358
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.38613
Policy Entropy: 5.57970
Value Function Loss: 0.04232
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01923
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.05144
Collected Steps per Second: 11,001.70739
Overall Steps per Second: 8,689.64981
Timestep Collection Time: 4.54875
Timestep Consumption Time: 1.21029
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.75904
Cumulative Model Updates: 3,037
Cumulative Timesteps: 50,726,402
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 50726402...
Checkpoint 50726402 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60070
Policy Entropy: 5.56630
Value Function Loss: 0.04035
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02087
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.05344
Collected Steps per Second: 10,972.26739
Overall Steps per Second: 8,709.24449
Timestep Collection Time: 4.55913
Timestep Consumption Time: 1.18465
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.74378
Cumulative Model Updates: 3,040
Cumulative Timesteps: 50,776,426
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57010
Policy Entropy: 5.58120
Value Function Loss: 0.04348
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02087
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.05440
Collected Steps per Second: 10,924.98497
Overall Steps per Second: 8,834.29417
Timestep Collection Time: 4.57905
Timestep Consumption Time: 1.08366
PPO Batch Consumption Time: 0.05164
Total Iteration Time: 5.66270
Cumulative Model Updates: 3,043
Cumulative Timesteps: 50,826,452
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 50826452...
Checkpoint 50826452 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.95267
Policy Entropy: 5.60096
Value Function Loss: 0.04552
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02867
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.05576
Collected Steps per Second: 10,871.47382
Overall Steps per Second: 8,574.89982
Timestep Collection Time: 4.60103
Timestep Consumption Time: 1.23227
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.83330
Cumulative Model Updates: 3,046
Cumulative Timesteps: 50,876,472
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.73500
Policy Entropy: 5.57687
Value Function Loss: 0.04052
Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01201
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.05353
Collected Steps per Second: 10,934.72280
Overall Steps per Second: 8,609.19225
Timestep Collection Time: 4.57661
Timestep Consumption Time: 1.23624
PPO Batch Consumption Time: 0.06737
Total Iteration Time: 5.81286
Cumulative Model Updates: 3,049
Cumulative Timesteps: 50,926,516
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 50926516...
Checkpoint 50926516 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.76988
Policy Entropy: 5.56440
Value Function Loss: 0.03682
Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.00931
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.05523
Collected Steps per Second: 11,142.59245
Overall Steps per Second: 8,755.78987
Timestep Collection Time: 4.49106
Timestep Consumption Time: 1.22425
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.71530
Cumulative Model Updates: 3,052
Cumulative Timesteps: 50,976,558
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89710
Policy Entropy: 5.56496
Value Function Loss: 0.03655
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01486
Policy Update Magnitude: 0.06279
Value Function Update Magnitude: 0.05334
Collected Steps per Second: 10,992.21480
Overall Steps per Second: 8,684.69231
Timestep Collection Time: 4.55159
Timestep Consumption Time: 1.20936
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.76094
Cumulative Model Updates: 3,055
Cumulative Timesteps: 51,026,590
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 51026590...
Checkpoint 51026590 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68386
Policy Entropy: 5.53250
Value Function Loss: 0.04226
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.06526
Value Function Update Magnitude: 0.04811
Collected Steps per Second: 10,924.44700
Overall Steps per Second: 8,759.90934
Timestep Collection Time: 4.58074
Timestep Consumption Time: 1.13188
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.71262
Cumulative Model Updates: 3,058
Cumulative Timesteps: 51,076,632
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74111
Policy Entropy: 5.53771
Value Function Loss: 0.04294
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.07255
Value Function Update Magnitude: 0.05397
Collected Steps per Second: 10,771.15870
Overall Steps per Second: 8,538.42624
Timestep Collection Time: 4.64221
Timestep Consumption Time: 1.21390
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.85611
Cumulative Model Updates: 3,061
Cumulative Timesteps: 51,126,634
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 51126634...
Checkpoint 51126634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69812
Policy Entropy: 5.52701
Value Function Loss: 0.04446
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03513
Policy Update Magnitude: 0.06813
Value Function Update Magnitude: 0.04707
Collected Steps per Second: 10,927.53364
Overall Steps per Second: 8,652.69144
Timestep Collection Time: 4.57633
Timestep Consumption Time: 1.20314
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.77947
Cumulative Model Updates: 3,064
Cumulative Timesteps: 51,176,642
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40452
Policy Entropy: 5.51638
Value Function Loss: 0.04883
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03135
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.04848
Collected Steps per Second: 11,148.76460
Overall Steps per Second: 8,774.31088
Timestep Collection Time: 4.48570
Timestep Consumption Time: 1.21389
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.69959
Cumulative Model Updates: 3,067
Cumulative Timesteps: 51,226,652
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 51226652...
Checkpoint 51226652 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50263
Policy Entropy: 5.51791
Value Function Loss: 0.05474
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02029
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.04533
Collected Steps per Second: 11,058.49268
Overall Steps per Second: 8,710.64709
Timestep Collection Time: 4.52666
Timestep Consumption Time: 1.22010
PPO Batch Consumption Time: 0.05186
Total Iteration Time: 5.74676
Cumulative Model Updates: 3,070
Cumulative Timesteps: 51,276,710
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78361
Policy Entropy: 5.56925
Value Function Loss: 0.05145
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02910
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.04875
Collected Steps per Second: 10,993.42305
Overall Steps per Second: 8,638.05643
Timestep Collection Time: 4.55345
Timestep Consumption Time: 1.24160
PPO Batch Consumption Time: 0.06867
Total Iteration Time: 5.79505
Cumulative Model Updates: 3,073
Cumulative Timesteps: 51,326,768
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 51326768...
Checkpoint 51326768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69013
Policy Entropy: 5.53195
Value Function Loss: 0.04904
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.04596
Collected Steps per Second: 11,193.37821
Overall Steps per Second: 8,774.33553
Timestep Collection Time: 4.46693
Timestep Consumption Time: 1.23151
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.69844
Cumulative Model Updates: 3,076
Cumulative Timesteps: 51,376,768
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.73589
Policy Entropy: 5.55519
Value Function Loss: 0.04643
Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.03969
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.04292
Collected Steps per Second: 10,901.27234
Overall Steps per Second: 8,632.32087
Timestep Collection Time: 4.58754
Timestep Consumption Time: 1.20581
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.79334
Cumulative Model Updates: 3,079
Cumulative Timesteps: 51,426,778
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 51426778...
Checkpoint 51426778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69238
Policy Entropy: 5.55409
Value Function Loss: 0.04957
Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03565
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.04193
Collected Steps per Second: 10,850.23882
Overall Steps per Second: 8,756.18724
Timestep Collection Time: 4.61151
Timestep Consumption Time: 1.10285
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.71436
Cumulative Model Updates: 3,082
Cumulative Timesteps: 51,476,814
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98926
Policy Entropy: 5.53494
Value Function Loss: 0.05004
Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03533
Policy Update Magnitude: 0.06634
Value Function Update Magnitude: 0.05094
Collected Steps per Second: 10,921.84245
Overall Steps per Second: 8,697.42484
Timestep Collection Time: 4.58018
Timestep Consumption Time: 1.17141
PPO Batch Consumption Time: 0.05020
Total Iteration Time: 5.75159
Cumulative Model Updates: 3,085
Cumulative Timesteps: 51,526,838
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 51526838...
Checkpoint 51526838 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.23242
Policy Entropy: 5.50916
Value Function Loss: 0.04434
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03283
Policy Update Magnitude: 0.06125
Value Function Update Magnitude: 0.04996
Collected Steps per Second: 10,849.31972
Overall Steps per Second: 8,627.39224
Timestep Collection Time: 4.60951
Timestep Consumption Time: 1.18715
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.79665
Cumulative Model Updates: 3,088
Cumulative Timesteps: 51,576,848
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65504
Policy Entropy: 5.51154
Value Function Loss: 0.04233
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03340
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.05013
Collected Steps per Second: 11,019.89627
Overall Steps per Second: 8,706.75285
Timestep Collection Time: 4.53888
Timestep Consumption Time: 1.20586
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.74474
Cumulative Model Updates: 3,091
Cumulative Timesteps: 51,626,866
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 51626866...
Checkpoint 51626866 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.02389
Policy Entropy: 5.51853
Value Function Loss: 0.03811
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02089
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.05500
Collected Steps per Second: 10,953.52006
Overall Steps per Second: 8,659.84449
Timestep Collection Time: 4.56712
Timestep Consumption Time: 1.20966
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.77678
Cumulative Model Updates: 3,094
Cumulative Timesteps: 51,676,892
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69531
Policy Entropy: 5.53758
Value Function Loss: 0.04023
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02318
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.04930
Collected Steps per Second: 10,980.77348
Overall Steps per Second: 8,607.26259
Timestep Collection Time: 4.55542
Timestep Consumption Time: 1.25619
PPO Batch Consumption Time: 0.07223
Total Iteration Time: 5.81160
Cumulative Model Updates: 3,097
Cumulative Timesteps: 51,726,914
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 51726914...
Checkpoint 51726914 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83259
Policy Entropy: 5.55421
Value Function Loss: 0.03812
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02979
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.05192
Collected Steps per Second: 11,071.45927
Overall Steps per Second: 8,739.47741
Timestep Collection Time: 4.51810
Timestep Consumption Time: 1.20558
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.72368
Cumulative Model Updates: 3,100
Cumulative Timesteps: 51,776,936
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63687
Policy Entropy: 5.53372
Value Function Loss: 0.03638
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01983
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.05390
Collected Steps per Second: 11,013.89580
Overall Steps per Second: 8,725.25049
Timestep Collection Time: 4.54335
Timestep Consumption Time: 1.19173
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.73508
Cumulative Model Updates: 3,103
Cumulative Timesteps: 51,826,976
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 51826976...
Checkpoint 51826976 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46827
Policy Entropy: 5.54683
Value Function Loss: 0.03888
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01973
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.05084
Collected Steps per Second: 11,019.50698
Overall Steps per Second: 8,857.30641
Timestep Collection Time: 4.54140
Timestep Consumption Time: 1.10862
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.65002
Cumulative Model Updates: 3,106
Cumulative Timesteps: 51,877,020
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60961
Policy Entropy: 5.56323
Value Function Loss: 0.03750
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01792
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.04749
Collected Steps per Second: 10,893.82832
Overall Steps per Second: 8,618.44572
Timestep Collection Time: 4.59398
Timestep Consumption Time: 1.21287
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.80685
Cumulative Model Updates: 3,109
Cumulative Timesteps: 51,927,066
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 51927066...
Checkpoint 51927066 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82495
Policy Entropy: 5.54693
Value Function Loss: 0.03939
Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00889
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.04870
Collected Steps per Second: 10,889.63366
Overall Steps per Second: 8,666.48352
Timestep Collection Time: 4.59428
Timestep Consumption Time: 1.17854
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77281
Cumulative Model Updates: 3,112
Cumulative Timesteps: 51,977,096
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.12269
Policy Entropy: 5.51865
Value Function Loss: 0.03837
Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01321
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.04506
Collected Steps per Second: 11,054.95807
Overall Steps per Second: 8,757.34755
Timestep Collection Time: 4.52412
Timestep Consumption Time: 1.18697
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.71109
Cumulative Model Updates: 3,115
Cumulative Timesteps: 52,027,110
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 52027110...
Checkpoint 52027110 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70897
Policy Entropy: 5.50377
Value Function Loss: 0.04204
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01834
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.04296
Collected Steps per Second: 10,976.61643
Overall Steps per Second: 8,670.81920
Timestep Collection Time: 4.55969
Timestep Consumption Time: 1.21254
PPO Batch Consumption Time: 0.05072
Total Iteration Time: 5.77223
Cumulative Model Updates: 3,118
Cumulative Timesteps: 52,077,160
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46951
Policy Entropy: 5.50385
Value Function Loss: 0.04733
Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01293
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.04108
Collected Steps per Second: 11,003.01647
Overall Steps per Second: 8,612.92217
Timestep Collection Time: 4.54657
Timestep Consumption Time: 1.26168
PPO Batch Consumption Time: 0.08267
Total Iteration Time: 5.80825
Cumulative Model Updates: 3,121
Cumulative Timesteps: 52,127,186
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 52127186...
Checkpoint 52127186 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64434
Policy Entropy: 5.49323
Value Function Loss: 0.04647
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.07034
Value Function Update Magnitude: 0.04458
Collected Steps per Second: 11,044.18813
Overall Steps per Second: 8,694.88808
Timestep Collection Time: 4.52817
Timestep Consumption Time: 1.22348
PPO Batch Consumption Time: 0.05312
Total Iteration Time: 5.75166
Cumulative Model Updates: 3,124
Cumulative Timesteps: 52,177,196
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59899
Policy Entropy: 5.52378
Value Function Loss: 0.04766
Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04237
Policy Update Magnitude: 0.06239
Value Function Update Magnitude: 0.04191
Collected Steps per Second: 10,850.48984
Overall Steps per Second: 8,594.51251
Timestep Collection Time: 4.61288
Timestep Consumption Time: 1.21084
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.82372
Cumulative Model Updates: 3,127
Cumulative Timesteps: 52,227,248
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 52227248...
Checkpoint 52227248 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04066
Policy Entropy: 5.53639
Value Function Loss: 0.04385
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03465
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.04672
Collected Steps per Second: 10,910.52215
Overall Steps per Second: 8,765.17384
Timestep Collection Time: 4.58292
Timestep Consumption Time: 1.12171
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.70462
Cumulative Model Updates: 3,130
Cumulative Timesteps: 52,277,250
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03390
Policy Entropy: 5.54890
Value Function Loss: 0.04538
Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04443
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.04817
Collected Steps per Second: 10,993.30262
Overall Steps per Second: 8,680.70218
Timestep Collection Time: 4.54859
Timestep Consumption Time: 1.21178
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.76036
Cumulative Model Updates: 3,133
Cumulative Timesteps: 52,327,254
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 52327254...
Checkpoint 52327254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77333
Policy Entropy: 5.53891
Value Function Loss: 0.04527
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03205
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.04703
Collected Steps per Second: 10,982.50266
Overall Steps per Second: 8,724.08709
Timestep Collection Time: 4.55342
Timestep Consumption Time: 1.17875
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.73218
Cumulative Model Updates: 3,136
Cumulative Timesteps: 52,377,262
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.92917
Policy Entropy: 5.54314
Value Function Loss: 0.04699
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.04775
Collected Steps per Second: 11,151.33683
Overall Steps per Second: 8,799.93628
Timestep Collection Time: 4.48395
Timestep Consumption Time: 1.19814
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.68209
Cumulative Model Updates: 3,139
Cumulative Timesteps: 52,427,264
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 52427264...
Checkpoint 52427264 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62033
Policy Entropy: 5.56046
Value Function Loss: 0.04332
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03095
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.05181
Collected Steps per Second: 10,950.68429
Overall Steps per Second: 8,648.55494
Timestep Collection Time: 4.57031
Timestep Consumption Time: 1.21655
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.78686
Cumulative Model Updates: 3,142
Cumulative Timesteps: 52,477,312
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.99515
Policy Entropy: 5.57518
Value Function Loss: 0.04216
Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01143
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.04846
Collected Steps per Second: 11,014.56502
Overall Steps per Second: 8,585.29782
Timestep Collection Time: 4.54271
Timestep Consumption Time: 1.28539
PPO Batch Consumption Time: 0.08149
Total Iteration Time: 5.82810
Cumulative Model Updates: 3,145
Cumulative Timesteps: 52,527,348
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 52527348...
Checkpoint 52527348 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59534
Policy Entropy: 5.56182
Value Function Loss: 0.03710
Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.00822
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.04783
Collected Steps per Second: 11,319.38012
Overall Steps per Second: 8,864.05213
Timestep Collection Time: 4.42038
Timestep Consumption Time: 1.22444
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.64482
Cumulative Model Updates: 3,148
Cumulative Timesteps: 52,577,384
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66775
Policy Entropy: 5.56501
Value Function Loss: 0.04001
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01375
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.04452
Collected Steps per Second: 10,898.11754
Overall Steps per Second: 8,607.19168
Timestep Collection Time: 4.59088
Timestep Consumption Time: 1.22193
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.81281
Cumulative Model Updates: 3,151
Cumulative Timesteps: 52,627,416
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 52627416...
Checkpoint 52627416 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47504
Policy Entropy: 5.58261
Value Function Loss: 0.04630
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02108
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.04195
Collected Steps per Second: 10,990.64749
Overall Steps per Second: 8,844.71618
Timestep Collection Time: 4.55205
Timestep Consumption Time: 1.10443
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.65648
Cumulative Model Updates: 3,154
Cumulative Timesteps: 52,677,446
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.11327
Policy Entropy: 5.59566
Value Function Loss: 0.04624
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.04655
Collected Steps per Second: 10,965.90086
Overall Steps per Second: 8,685.60868
Timestep Collection Time: 4.56196
Timestep Consumption Time: 1.19768
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.75964
Cumulative Model Updates: 3,157
Cumulative Timesteps: 52,727,472
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 52727472...
Checkpoint 52727472 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60725
Policy Entropy: 5.57155
Value Function Loss: 0.04403
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02999
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.04051
Collected Steps per Second: 10,930.41437
Overall Steps per Second: 8,679.74706
Timestep Collection Time: 4.57586
Timestep Consumption Time: 1.18652
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.76238
Cumulative Model Updates: 3,160
Cumulative Timesteps: 52,777,488
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.12810
Policy Entropy: 5.57998
Value Function Loss: 0.03786
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.04336
Collected Steps per Second: 11,138.51199
Overall Steps per Second: 8,787.42946
Timestep Collection Time: 4.48911
Timestep Consumption Time: 1.20106
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.69017
Cumulative Model Updates: 3,163
Cumulative Timesteps: 52,827,490
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 52827490...
Checkpoint 52827490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.18160
Policy Entropy: 5.57513
Value Function Loss: 0.04123
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02234
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.04665
Collected Steps per Second: 10,935.03748
Overall Steps per Second: 8,653.46697
Timestep Collection Time: 4.57630
Timestep Consumption Time: 1.20659
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.78288
Cumulative Model Updates: 3,166
Cumulative Timesteps: 52,877,532
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98972
Policy Entropy: 5.56645
Value Function Loss: 0.03962
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01493
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.04594
Collected Steps per Second: 10,868.52913
Overall Steps per Second: 8,561.63095
Timestep Collection Time: 4.60449
Timestep Consumption Time: 1.24066
PPO Batch Consumption Time: 0.07200
Total Iteration Time: 5.84515
Cumulative Model Updates: 3,169
Cumulative Timesteps: 52,927,576
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 52927576...
Checkpoint 52927576 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89154
Policy Entropy: 5.56674
Value Function Loss: 0.04180
Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01054
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.04397
Collected Steps per Second: 11,185.80318
Overall Steps per Second: 8,807.79089
Timestep Collection Time: 4.47031
Timestep Consumption Time: 1.20694
PPO Batch Consumption Time: 0.05433
Total Iteration Time: 5.67725
Cumulative Model Updates: 3,172
Cumulative Timesteps: 52,977,580
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83084
Policy Entropy: 5.58698
Value Function Loss: 0.04194
Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01066
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.04662
Collected Steps per Second: 10,942.80988
Overall Steps per Second: 8,641.03663
Timestep Collection Time: 4.57232
Timestep Consumption Time: 1.21796
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.79028
Cumulative Model Updates: 3,175
Cumulative Timesteps: 53,027,614
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 53027614...
Checkpoint 53027614 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.45734
Policy Entropy: 5.56682
Value Function Loss: 0.04471
Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01118
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.05316
Collected Steps per Second: 10,818.76048
Overall Steps per Second: 8,727.74927
Timestep Collection Time: 4.62382
Timestep Consumption Time: 1.10778
PPO Batch Consumption Time: 0.05146
Total Iteration Time: 5.73160
Cumulative Model Updates: 3,178
Cumulative Timesteps: 53,077,638
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40420
Policy Entropy: 5.58918
Value Function Loss: 0.03867
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01348
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.05717
Collected Steps per Second: 10,959.93515
Overall Steps per Second: 8,605.21420
Timestep Collection Time: 4.56408
Timestep Consumption Time: 1.24891
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.81299
Cumulative Model Updates: 3,181
Cumulative Timesteps: 53,127,660
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 53127660...
Checkpoint 53127660 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65319
Policy Entropy: 5.60770
Value Function Loss: 0.03710
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.01686
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.05502
Collected Steps per Second: 10,901.15543
Overall Steps per Second: 8,678.08533
Timestep Collection Time: 4.59034
Timestep Consumption Time: 1.17591
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.76625
Cumulative Model Updates: 3,184
Cumulative Timesteps: 53,177,700
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.23113
Policy Entropy: 5.62700
Value Function Loss: 0.03526
Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00439
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.05444
Collected Steps per Second: 10,813.69545
Overall Steps per Second: 8,737.65531
Timestep Collection Time: 4.62506
Timestep Consumption Time: 1.09890
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.72396
Cumulative Model Updates: 3,187
Cumulative Timesteps: 53,227,714
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 53227714...
Checkpoint 53227714 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.01533
Policy Entropy: 5.61010
Value Function Loss: 0.04386
Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01281
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.05453
Collected Steps per Second: 10,983.97345
Overall Steps per Second: 8,678.46900
Timestep Collection Time: 4.55482
Timestep Consumption Time: 1.21002
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.76484
Cumulative Model Updates: 3,190
Cumulative Timesteps: 53,277,744
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78181
Policy Entropy: 5.60673
Value Function Loss: 0.04319
Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01291
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.05537
Collected Steps per Second: 10,876.99223
Overall Steps per Second: 8,665.13128
Timestep Collection Time: 4.59998
Timestep Consumption Time: 1.17419
PPO Batch Consumption Time: 0.07833
Total Iteration Time: 5.77418
Cumulative Model Updates: 3,193
Cumulative Timesteps: 53,327,778
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 53327778...
Checkpoint 53327778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78761
Policy Entropy: 5.57753
Value Function Loss: 0.04372
Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01353
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.05734
Collected Steps per Second: 11,055.44532
Overall Steps per Second: 8,740.90094
Timestep Collection Time: 4.52374
Timestep Consumption Time: 1.19786
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.72161
Cumulative Model Updates: 3,196
Cumulative Timesteps: 53,377,790
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89596
Policy Entropy: 5.57024
Value Function Loss: 0.04237
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01882
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.05539
Collected Steps per Second: 10,894.33622
Overall Steps per Second: 8,687.29093
Timestep Collection Time: 4.59303
Timestep Consumption Time: 1.16688
PPO Batch Consumption Time: 0.05225
Total Iteration Time: 5.75991
Cumulative Model Updates: 3,199
Cumulative Timesteps: 53,427,828
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 53427828...
Checkpoint 53427828 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84968
Policy Entropy: 5.59520
Value Function Loss: 0.04091
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03463
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.05625
Collected Steps per Second: 10,820.88705
Overall Steps per Second: 8,708.15440
Timestep Collection Time: 4.62421
Timestep Consumption Time: 1.12190
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.74611
Cumulative Model Updates: 3,202
Cumulative Timesteps: 53,477,866
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89446
Policy Entropy: 5.60410
Value Function Loss: 0.03939
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01815
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.05539
Collected Steps per Second: 10,898.93252
Overall Steps per Second: 8,633.33449
Timestep Collection Time: 4.58999
Timestep Consumption Time: 1.20453
PPO Batch Consumption Time: 0.05124
Total Iteration Time: 5.79452
Cumulative Model Updates: 3,205
Cumulative Timesteps: 53,527,892
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 53527892...
Checkpoint 53527892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57574
Policy Entropy: 5.57768
Value Function Loss: 0.03583
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.05170
Collected Steps per Second: 10,962.74896
Overall Steps per Second: 8,721.81352
Timestep Collection Time: 4.56272
Timestep Consumption Time: 1.17232
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.73505
Cumulative Model Updates: 3,208
Cumulative Timesteps: 53,577,912
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.42916
Policy Entropy: 5.55670
Value Function Loss: 0.03878
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03088
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.05419
Collected Steps per Second: 10,964.27050
Overall Steps per Second: 8,655.91902
Timestep Collection Time: 4.56173
Timestep Consumption Time: 1.21652
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77824
Cumulative Model Updates: 3,211
Cumulative Timesteps: 53,627,928
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 53627928...
Checkpoint 53627928 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.93653
Policy Entropy: 5.52659
Value Function Loss: 0.04590
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02955
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.05942
Collected Steps per Second: 11,031.78453
Overall Steps per Second: 8,718.22247
Timestep Collection Time: 4.53508
Timestep Consumption Time: 1.20348
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.73856
Cumulative Model Updates: 3,214
Cumulative Timesteps: 53,677,958
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79944
Policy Entropy: 5.56858
Value Function Loss: 0.04616
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03223
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.06084
Collected Steps per Second: 10,675.66874
Overall Steps per Second: 8,422.22033
Timestep Collection Time: 4.68467
Timestep Consumption Time: 1.25343
PPO Batch Consumption Time: 0.07600
Total Iteration Time: 5.93810
Cumulative Model Updates: 3,217
Cumulative Timesteps: 53,727,970
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 53727970...
Checkpoint 53727970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80244
Policy Entropy: 5.59202
Value Function Loss: 0.04165
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01717
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.06120
Collected Steps per Second: 11,211.03910
Overall Steps per Second: 8,821.79704
Timestep Collection Time: 4.46381
Timestep Consumption Time: 1.20895
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.67277
Cumulative Model Updates: 3,220
Cumulative Timesteps: 53,778,014
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.94967
Policy Entropy: 5.58768
Value Function Loss: 0.03661
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02791
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.05496
Collected Steps per Second: 10,881.39376
Overall Steps per Second: 8,670.97603
Timestep Collection Time: 4.59757
Timestep Consumption Time: 1.17202
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.76959
Cumulative Model Updates: 3,223
Cumulative Timesteps: 53,828,042
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 53828042...
Checkpoint 53828042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66241
Policy Entropy: 5.56728
Value Function Loss: 0.03574
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.05129
Collected Steps per Second: 10,907.29008
Overall Steps per Second: 8,817.62948
Timestep Collection Time: 4.58739
Timestep Consumption Time: 1.08715
PPO Batch Consumption Time: 0.05029
Total Iteration Time: 5.67454
Cumulative Model Updates: 3,226
Cumulative Timesteps: 53,878,078
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61858
Policy Entropy: 5.56594
Value Function Loss: 0.04217
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02289
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.04717
Collected Steps per Second: 10,820.15218
Overall Steps per Second: 8,578.00302
Timestep Collection Time: 4.62378
Timestep Consumption Time: 1.20858
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.83236
Cumulative Model Updates: 3,229
Cumulative Timesteps: 53,928,108
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 53928108...
Checkpoint 53928108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.81594
Policy Entropy: 5.56075
Value Function Loss: 0.03995
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.04566
Collected Steps per Second: 10,780.62848
Overall Steps per Second: 8,583.54401
Timestep Collection Time: 4.64073
Timestep Consumption Time: 1.18786
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.82859
Cumulative Model Updates: 3,232
Cumulative Timesteps: 53,978,138
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82482
Policy Entropy: 5.57229
Value Function Loss: 0.04341
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02216
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.05162
Collected Steps per Second: 11,000.27008
Overall Steps per Second: 8,724.56642
Timestep Collection Time: 4.55007
Timestep Consumption Time: 1.18683
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.73690
Cumulative Model Updates: 3,235
Cumulative Timesteps: 54,028,190
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 54028190...
Checkpoint 54028190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79973
Policy Entropy: 5.57262
Value Function Loss: 0.03929
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01149
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.05463
Collected Steps per Second: 10,825.58918
Overall Steps per Second: 8,565.09062
Timestep Collection Time: 4.62312
Timestep Consumption Time: 1.22013
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.84325
Cumulative Model Updates: 3,238
Cumulative Timesteps: 54,078,238
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86132
Policy Entropy: 5.57753
Value Function Loss: 0.03604
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.05582
Collected Steps per Second: 10,832.61413
Overall Steps per Second: 8,502.24808
Timestep Collection Time: 4.61809
Timestep Consumption Time: 1.26576
PPO Batch Consumption Time: 0.07952
Total Iteration Time: 5.88386
Cumulative Model Updates: 3,241
Cumulative Timesteps: 54,128,264
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 54128264...
Checkpoint 54128264 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78214
Policy Entropy: 5.57793
Value Function Loss: 0.03236
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01461
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.05430
Collected Steps per Second: 11,200.07922
Overall Steps per Second: 8,815.95266
Timestep Collection Time: 4.46568
Timestep Consumption Time: 1.20767
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.67335
Cumulative Model Updates: 3,244
Cumulative Timesteps: 54,178,280
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75851
Policy Entropy: 5.56727
Value Function Loss: 0.03098
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01971
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.05209
Collected Steps per Second: 10,959.14760
Overall Steps per Second: 8,713.85919
Timestep Collection Time: 4.56368
Timestep Consumption Time: 1.17592
PPO Batch Consumption Time: 0.05153
Total Iteration Time: 5.73959
Cumulative Model Updates: 3,247
Cumulative Timesteps: 54,228,294
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 54228294...
Checkpoint 54228294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79896
Policy Entropy: 5.57746
Value Function Loss: 0.03454
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.05006
Collected Steps per Second: 10,809.40477
Overall Steps per Second: 8,731.85383
Timestep Collection Time: 4.62560
Timestep Consumption Time: 1.10056
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.72616
Cumulative Model Updates: 3,250
Cumulative Timesteps: 54,278,294
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84926
Policy Entropy: 5.54799
Value Function Loss: 0.03888
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03265
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.05051
Collected Steps per Second: 10,874.44987
Overall Steps per Second: 8,605.04020
Timestep Collection Time: 4.59959
Timestep Consumption Time: 1.21305
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.81264
Cumulative Model Updates: 3,253
Cumulative Timesteps: 54,328,312
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 54328312...
Checkpoint 54328312 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.17257
Policy Entropy: 5.55402
Value Function Loss: 0.04043
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01669
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.05302
Collected Steps per Second: 10,927.46678
Overall Steps per Second: 8,671.70512
Timestep Collection Time: 4.58075
Timestep Consumption Time: 1.19159
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.77234
Cumulative Model Updates: 3,256
Cumulative Timesteps: 54,378,368
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.91342
Policy Entropy: 5.57503
Value Function Loss: 0.03790
Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.03976
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.05435
Collected Steps per Second: 11,268.41645
Overall Steps per Second: 8,862.41599
Timestep Collection Time: 4.43860
Timestep Consumption Time: 1.20501
PPO Batch Consumption Time: 0.05099
Total Iteration Time: 5.64361
Cumulative Model Updates: 3,259
Cumulative Timesteps: 54,428,384
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 54428384...
Checkpoint 54428384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.73012
Policy Entropy: 5.59771
Value Function Loss: 0.04035
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03509
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.05399
Collected Steps per Second: 10,878.21440
Overall Steps per Second: 8,618.34217
Timestep Collection Time: 4.59745
Timestep Consumption Time: 1.20553
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.80297
Cumulative Model Updates: 3,262
Cumulative Timesteps: 54,478,396
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.96509
Policy Entropy: 5.60083
Value Function Loss: 0.04287
Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04295
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.05448
Collected Steps per Second: 10,713.09808
Overall Steps per Second: 8,610.54104
Timestep Collection Time: 4.67166
Timestep Consumption Time: 1.14075
PPO Batch Consumption Time: 0.06834
Total Iteration Time: 5.81241
Cumulative Model Updates: 3,265
Cumulative Timesteps: 54,528,444
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 54528444...
Checkpoint 54528444 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67070
Policy Entropy: 5.60881
Value Function Loss: 0.04740
Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04309
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.05847
Collected Steps per Second: 10,906.50467
Overall Steps per Second: 8,624.55619
Timestep Collection Time: 4.58735
Timestep Consumption Time: 1.21376
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.80111
Cumulative Model Updates: 3,268
Cumulative Timesteps: 54,578,476
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70921
Policy Entropy: 5.61263
Value Function Loss: 0.04459
Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04107
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.05889
Collected Steps per Second: 10,916.03510
Overall Steps per Second: 8,701.26973
Timestep Collection Time: 4.58188
Timestep Consumption Time: 1.16624
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.74813
Cumulative Model Updates: 3,271
Cumulative Timesteps: 54,628,492
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 54628492...
Checkpoint 54628492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66208
Policy Entropy: 5.62201
Value Function Loss: 0.04907
Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.05865
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.06206
Collected Steps per Second: 10,892.68092
Overall Steps per Second: 8,774.33155
Timestep Collection Time: 4.59226
Timestep Consumption Time: 1.10869
PPO Batch Consumption Time: 0.05084
Total Iteration Time: 5.70095
Cumulative Model Updates: 3,274
Cumulative Timesteps: 54,678,514
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.58832
Policy Entropy: 5.65283
Value Function Loss: 0.05124
Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05547
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.06204
Collected Steps per Second: 10,954.97490
Overall Steps per Second: 8,683.24751
Timestep Collection Time: 4.56797
Timestep Consumption Time: 1.19508
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76305
Cumulative Model Updates: 3,277
Cumulative Timesteps: 54,728,556
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 54728556...
Checkpoint 54728556 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55446
Policy Entropy: 5.64051
Value Function Loss: 0.04950
Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.05952
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.06535
Collected Steps per Second: 10,852.13062
Overall Steps per Second: 8,675.87031
Timestep Collection Time: 4.61052
Timestep Consumption Time: 1.15651
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.76703
Cumulative Model Updates: 3,280
Cumulative Timesteps: 54,778,590
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.60115
Policy Entropy: 5.60301
Value Function Loss: 0.04814
Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.04795
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.06332
Collected Steps per Second: 11,109.23314
Overall Steps per Second: 8,762.99479
Timestep Collection Time: 4.50130
Timestep Consumption Time: 1.20520
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.70650
Cumulative Model Updates: 3,283
Cumulative Timesteps: 54,828,596
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 54828596...
Checkpoint 54828596 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82973
Policy Entropy: 5.61805
Value Function Loss: 0.04290
Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.05151
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.06244
Collected Steps per Second: 10,894.22865
Overall Steps per Second: 8,628.05075
Timestep Collection Time: 4.59142
Timestep Consumption Time: 1.20595
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.79737
Cumulative Model Updates: 3,286
Cumulative Timesteps: 54,878,616
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70801
Policy Entropy: 5.62721
Value Function Loss: 0.04602
Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.05890
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.06143
Collected Steps per Second: 11,017.63026
Overall Steps per Second: 8,681.73893
Timestep Collection Time: 4.54036
Timestep Consumption Time: 1.22162
PPO Batch Consumption Time: 0.06567
Total Iteration Time: 5.76198
Cumulative Model Updates: 3,289
Cumulative Timesteps: 54,928,640
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 54928640...
Checkpoint 54928640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77280
Policy Entropy: 5.64219
Value Function Loss: 0.04462
Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.05590
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.05931
Collected Steps per Second: 11,211.62152
Overall Steps per Second: 8,805.23964
Timestep Collection Time: 4.45984
Timestep Consumption Time: 1.21883
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.67866
Cumulative Model Updates: 3,292
Cumulative Timesteps: 54,978,642
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77335
Policy Entropy: 5.62203
Value Function Loss: 0.04336
Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04127
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.05692
Collected Steps per Second: 10,831.50689
Overall Steps per Second: 8,616.51432
Timestep Collection Time: 4.62023
Timestep Consumption Time: 1.18769
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.80792
Cumulative Model Updates: 3,295
Cumulative Timesteps: 55,028,686
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 55028686...
Checkpoint 55028686 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78648
Policy Entropy: 5.62226
Value Function Loss: 0.03862
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.01804
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.05568
Collected Steps per Second: 10,813.12360
Overall Steps per Second: 8,700.28694
Timestep Collection Time: 4.62808
Timestep Consumption Time: 1.12391
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.75199
Cumulative Model Updates: 3,298
Cumulative Timesteps: 55,078,730
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77700
Policy Entropy: 5.61214
Value Function Loss: 0.03660
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02827
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.05349
Collected Steps per Second: 10,930.97982
Overall Steps per Second: 8,683.57587
Timestep Collection Time: 4.57452
Timestep Consumption Time: 1.18394
PPO Batch Consumption Time: 0.05096
Total Iteration Time: 5.75846
Cumulative Model Updates: 3,301
Cumulative Timesteps: 55,128,734
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 55128734...
Checkpoint 55128734 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83095
Policy Entropy: 5.61033
Value Function Loss: 0.03622
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01413
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.05018
Collected Steps per Second: 10,763.71312
Overall Steps per Second: 8,611.58450
Timestep Collection Time: 4.64635
Timestep Consumption Time: 1.16117
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.80753
Cumulative Model Updates: 3,304
Cumulative Timesteps: 55,178,746
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78326
Policy Entropy: 5.60084
Value Function Loss: 0.03649
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.04798
Collected Steps per Second: 11,064.63801
Overall Steps per Second: 8,767.88825
Timestep Collection Time: 4.52161
Timestep Consumption Time: 1.18444
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.70605
Cumulative Model Updates: 3,307
Cumulative Timesteps: 55,228,776
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 55228776...
Checkpoint 55228776 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.29381
Policy Entropy: 5.58877
Value Function Loss: 0.03198
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01358
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.04947
Collected Steps per Second: 10,938.46826
Overall Steps per Second: 8,658.31386
Timestep Collection Time: 4.57633
Timestep Consumption Time: 1.20517
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.78150
Cumulative Model Updates: 3,310
Cumulative Timesteps: 55,278,834
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98456
Policy Entropy: 5.55722
Value Function Loss: 0.03601
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02316
Policy Update Magnitude: 0.04384
Value Function Update Magnitude: 0.05107
Collected Steps per Second: 10,886.93317
Overall Steps per Second: 8,514.70467
Timestep Collection Time: 4.59523
Timestep Consumption Time: 1.28025
PPO Batch Consumption Time: 0.08352
Total Iteration Time: 5.87548
Cumulative Model Updates: 3,313
Cumulative Timesteps: 55,328,862
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 55328862...
Checkpoint 55328862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.94077
Policy Entropy: 5.56210
Value Function Loss: 0.03241
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01343
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.05606
Collected Steps per Second: 11,107.34644
Overall Steps per Second: 8,750.06450
Timestep Collection Time: 4.50387
Timestep Consumption Time: 1.21335
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.71722
Cumulative Model Updates: 3,316
Cumulative Timesteps: 55,378,888
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83302
Policy Entropy: 5.56567
Value Function Loss: 0.03909
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.05435
Collected Steps per Second: 10,929.58607
Overall Steps per Second: 8,648.16982
Timestep Collection Time: 4.57767
Timestep Consumption Time: 1.20760
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.78527
Cumulative Model Updates: 3,319
Cumulative Timesteps: 55,428,920
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 55428920...
Checkpoint 55428920 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82135
Policy Entropy: 5.55448
Value Function Loss: 0.04119
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.01831
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.05486
Collected Steps per Second: 10,926.75621
Overall Steps per Second: 8,793.18217
Timestep Collection Time: 4.57666
Timestep Consumption Time: 1.11048
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.68713
Cumulative Model Updates: 3,322
Cumulative Timesteps: 55,478,928
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.20547
Policy Entropy: 5.55855
Value Function Loss: 0.04343
Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01481
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.05399
Collected Steps per Second: 10,917.04319
Overall Steps per Second: 8,625.73353
Timestep Collection Time: 4.58238
Timestep Consumption Time: 1.21725
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.79962
Cumulative Model Updates: 3,325
Cumulative Timesteps: 55,528,954
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 55528954...
Checkpoint 55528954 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.08111
Policy Entropy: 5.56330
Value Function Loss: 0.03760
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.05566
Collected Steps per Second: 10,838.56457
Overall Steps per Second: 8,666.47119
Timestep Collection Time: 4.61316
Timestep Consumption Time: 1.15620
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 5.76936
Cumulative Model Updates: 3,328
Cumulative Timesteps: 55,578,954
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.19158
Policy Entropy: 5.54843
Value Function Loss: 0.03321
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01883
Policy Update Magnitude: 0.04173
Value Function Update Magnitude: 0.05519
Collected Steps per Second: 10,869.80948
Overall Steps per Second: 8,800.87180
Timestep Collection Time: 4.60118
Timestep Consumption Time: 1.08166
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.68285
Cumulative Model Updates: 3,331
Cumulative Timesteps: 55,628,968
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 55628968...
Checkpoint 55628968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75141
Policy Entropy: 5.54941
Value Function Loss: 0.03434
Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01030
Policy Update Magnitude: 0.04178
Value Function Update Magnitude: 0.05728
Collected Steps per Second: 10,887.00947
Overall Steps per Second: 8,600.66701
Timestep Collection Time: 4.59539
Timestep Consumption Time: 1.22161
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.81699
Cumulative Model Updates: 3,334
Cumulative Timesteps: 55,678,998
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.00727
Policy Entropy: 5.55069
Value Function Loss: 0.03991
Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01197
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.05742
Collected Steps per Second: 10,903.66072
Overall Steps per Second: 8,563.32534
Timestep Collection Time: 4.58782
Timestep Consumption Time: 1.25384
PPO Batch Consumption Time: 0.08100
Total Iteration Time: 5.84166
Cumulative Model Updates: 3,337
Cumulative Timesteps: 55,729,022
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 55729022...
Checkpoint 55729022 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68991
Policy Entropy: 5.52923
Value Function Loss: 0.04045
Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01206
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.05458
Collected Steps per Second: 11,185.99505
Overall Steps per Second: 8,801.31660
Timestep Collection Time: 4.47113
Timestep Consumption Time: 1.21143
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.68256
Cumulative Model Updates: 3,340
Cumulative Timesteps: 55,779,036
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.17883
Policy Entropy: 5.51127
Value Function Loss: 0.04272
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01807
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.05871
Collected Steps per Second: 10,816.07542
Overall Steps per Second: 8,590.31953
Timestep Collection Time: 4.62589
Timestep Consumption Time: 1.19857
PPO Batch Consumption Time: 0.05072
Total Iteration Time: 5.82446
Cumulative Model Updates: 3,343
Cumulative Timesteps: 55,829,070
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 55829070...
Checkpoint 55829070 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63801
Policy Entropy: 5.52255
Value Function Loss: 0.03606
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.05751
Collected Steps per Second: 10,912.46378
Overall Steps per Second: 8,660.72845
Timestep Collection Time: 4.58503
Timestep Consumption Time: 1.19208
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.77711
Cumulative Model Updates: 3,346
Cumulative Timesteps: 55,879,104
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.65180
Policy Entropy: 5.51471
Value Function Loss: 0.03712
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01830
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.05356
Collected Steps per Second: 11,095.89144
Overall Steps per Second: 8,775.56526
Timestep Collection Time: 4.51032
Timestep Consumption Time: 1.19256
PPO Batch Consumption Time: 0.05109
Total Iteration Time: 5.70288
Cumulative Model Updates: 3,349
Cumulative Timesteps: 55,929,150
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 55929150...
Checkpoint 55929150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.32294
Policy Entropy: 5.50458
Value Function Loss: 0.03882
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02616
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.05238
Collected Steps per Second: 10,996.98046
Overall Steps per Second: 8,671.66234
Timestep Collection Time: 4.54688
Timestep Consumption Time: 1.21925
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.76614
Cumulative Model Updates: 3,352
Cumulative Timesteps: 55,979,152
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75780
Policy Entropy: 5.51883
Value Function Loss: 0.03777
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03710
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.05592
Collected Steps per Second: 10,925.39144
Overall Steps per Second: 8,782.09972
Timestep Collection Time: 4.58180
Timestep Consumption Time: 1.11820
PPO Batch Consumption Time: 0.05060
Total Iteration Time: 5.70000
Cumulative Model Updates: 3,355
Cumulative Timesteps: 56,029,210
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 56029210...
Checkpoint 56029210 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70721
Policy Entropy: 5.52601
Value Function Loss: 0.03781
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03125
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.06114
Collected Steps per Second: 11,017.50542
Overall Steps per Second: 8,714.44374
Timestep Collection Time: 4.53950
Timestep Consumption Time: 1.19970
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.73921
Cumulative Model Updates: 3,358
Cumulative Timesteps: 56,079,224
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.14569
Policy Entropy: 5.55607
Value Function Loss: 0.04255
Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04507
Policy Update Magnitude: 0.05124
Value Function Update Magnitude: 0.06140
Collected Steps per Second: 10,858.84245
Overall Steps per Second: 8,545.49625
Timestep Collection Time: 4.60509
Timestep Consumption Time: 1.24664
PPO Batch Consumption Time: 0.07733
Total Iteration Time: 5.85174
Cumulative Model Updates: 3,361
Cumulative Timesteps: 56,129,230
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 56129230...
Checkpoint 56129230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.73966
Policy Entropy: 5.56573
Value Function Loss: 0.04576
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02865
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.06438
Collected Steps per Second: 11,109.32598
Overall Steps per Second: 8,766.94239
Timestep Collection Time: 4.50450
Timestep Consumption Time: 1.20353
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.70803
Cumulative Model Updates: 3,364
Cumulative Timesteps: 56,179,272
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55732
Policy Entropy: 5.53057
Value Function Loss: 0.04577
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01898
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.05922
Collected Steps per Second: 10,879.76186
Overall Steps per Second: 8,623.74273
Timestep Collection Time: 4.59753
Timestep Consumption Time: 1.20274
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.80027
Cumulative Model Updates: 3,367
Cumulative Timesteps: 56,229,292
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 56229292...
Checkpoint 56229292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.47043
Policy Entropy: 5.54391
Value Function Loss: 0.03604
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02216
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.05370
Collected Steps per Second: 10,792.41911
Overall Steps per Second: 8,613.71072
Timestep Collection Time: 4.63640
Timestep Consumption Time: 1.17271
PPO Batch Consumption Time: 0.05114
Total Iteration Time: 5.80911
Cumulative Model Updates: 3,370
Cumulative Timesteps: 56,279,330
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.91195
Policy Entropy: 5.55536
Value Function Loss: 0.03360
Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01111
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.05226
Collected Steps per Second: 11,124.22794
Overall Steps per Second: 8,778.03174
Timestep Collection Time: 4.49541
Timestep Consumption Time: 1.20154
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.69695
Cumulative Model Updates: 3,373
Cumulative Timesteps: 56,329,338
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 56329338...
Checkpoint 56329338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87930
Policy Entropy: 5.56172
Value Function Loss: 0.03556
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.05516
Collected Steps per Second: 10,946.11665
Overall Steps per Second: 8,655.02399
Timestep Collection Time: 4.56783
Timestep Consumption Time: 1.20916
PPO Batch Consumption Time: 0.05229
Total Iteration Time: 5.77699
Cumulative Model Updates: 3,376
Cumulative Timesteps: 56,379,338
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70291
Policy Entropy: 5.56395
Value Function Loss: 0.04008
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03389
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.06064
Collected Steps per Second: 10,982.12184
Overall Steps per Second: 8,842.10881
Timestep Collection Time: 4.55358
Timestep Consumption Time: 1.10208
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.65566
Cumulative Model Updates: 3,379
Cumulative Timesteps: 56,429,346
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 56429346...
Checkpoint 56429346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89712
Policy Entropy: 5.60328
Value Function Loss: 0.04231
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.05954
Collected Steps per Second: 10,859.26760
Overall Steps per Second: 8,618.58308
Timestep Collection Time: 4.60712
Timestep Consumption Time: 1.19777
PPO Batch Consumption Time: 0.05112
Total Iteration Time: 5.80490
Cumulative Model Updates: 3,382
Cumulative Timesteps: 56,479,376
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87225
Policy Entropy: 5.60530
Value Function Loss: 0.03696
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01589
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.05578
Collected Steps per Second: 10,793.48611
Overall Steps per Second: 8,572.71025
Timestep Collection Time: 4.63372
Timestep Consumption Time: 1.20037
PPO Batch Consumption Time: 0.07167
Total Iteration Time: 5.83409
Cumulative Model Updates: 3,385
Cumulative Timesteps: 56,529,390
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 56529390...
Checkpoint 56529390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.41948
Policy Entropy: 5.60988
Value Function Loss: 0.04026
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.05291
Collected Steps per Second: 10,946.94654
Overall Steps per Second: 8,815.75868
Timestep Collection Time: 4.57022
Timestep Consumption Time: 1.10484
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.67506
Cumulative Model Updates: 3,388
Cumulative Timesteps: 56,579,420
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.23911
Policy Entropy: 5.61953
Value Function Loss: 0.03570
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02139
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.05123
Collected Steps per Second: 10,871.39449
Overall Steps per Second: 8,641.18042
Timestep Collection Time: 4.60327
Timestep Consumption Time: 1.18807
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.79134
Cumulative Model Updates: 3,391
Cumulative Timesteps: 56,629,464
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 56629464...
Checkpoint 56629464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85286
Policy Entropy: 5.58840
Value Function Loss: 0.04315
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02489
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.05090
Collected Steps per Second: 10,859.80042
Overall Steps per Second: 8,636.66983
Timestep Collection Time: 4.60561
Timestep Consumption Time: 1.18551
PPO Batch Consumption Time: 0.05021
Total Iteration Time: 5.79112
Cumulative Model Updates: 3,394
Cumulative Timesteps: 56,679,480
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85116
Policy Entropy: 5.60328
Value Function Loss: 0.03757
Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01284
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.05404
Collected Steps per Second: 11,146.96159
Overall Steps per Second: 8,831.17164
Timestep Collection Time: 4.48678
Timestep Consumption Time: 1.17656
PPO Batch Consumption Time: 0.05019
Total Iteration Time: 5.66335
Cumulative Model Updates: 3,397
Cumulative Timesteps: 56,729,494
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 56729494...
Checkpoint 56729494 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74032
Policy Entropy: 5.61537
Value Function Loss: 0.04143
Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01792
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.05601
Collected Steps per Second: 10,959.55568
Overall Steps per Second: 8,654.44735
Timestep Collection Time: 4.56643
Timestep Consumption Time: 1.21627
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.78269
Cumulative Model Updates: 3,400
Cumulative Timesteps: 56,779,540
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.76242
Policy Entropy: 5.57930
Value Function Loss: 0.03944
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01107
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.05455
Collected Steps per Second: 10,987.70639
Overall Steps per Second: 8,847.20053
Timestep Collection Time: 4.55109
Timestep Consumption Time: 1.10110
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.65218
Cumulative Model Updates: 3,403
Cumulative Timesteps: 56,829,546
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 56829546...
Checkpoint 56829546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.56399
Policy Entropy: 5.58774
Value Function Loss: 0.03746
Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01279
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.05549
Collected Steps per Second: 10,941.42012
Overall Steps per Second: 8,636.17043
Timestep Collection Time: 4.57217
Timestep Consumption Time: 1.22045
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.79261
Cumulative Model Updates: 3,406
Cumulative Timesteps: 56,879,572
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61430
Policy Entropy: 5.61393
Value Function Loss: 0.03643
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01885
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.05559
Collected Steps per Second: 10,874.00672
Overall Steps per Second: 8,533.93292
Timestep Collection Time: 4.59867
Timestep Consumption Time: 1.26099
PPO Batch Consumption Time: 0.08140
Total Iteration Time: 5.85967
Cumulative Model Updates: 3,409
Cumulative Timesteps: 56,929,578
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 56929578...
Checkpoint 56929578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74290
Policy Entropy: 5.59382
Value Function Loss: 0.03535
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01459
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.05626
Collected Steps per Second: 11,007.58876
Overall Steps per Second: 8,730.09542
Timestep Collection Time: 4.54377
Timestep Consumption Time: 1.18537
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.72915
Cumulative Model Updates: 3,412
Cumulative Timesteps: 56,979,594
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90262
Policy Entropy: 5.57694
Value Function Loss: 0.03913
Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01269
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.05435
Collected Steps per Second: 10,830.92528
Overall Steps per Second: 8,594.46553
Timestep Collection Time: 4.62047
Timestep Consumption Time: 1.20234
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.82282
Cumulative Model Updates: 3,415
Cumulative Timesteps: 57,029,638
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 57029638...
Checkpoint 57029638 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.05488
Policy Entropy: 5.55928
Value Function Loss: 0.03788
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.05359
Collected Steps per Second: 10,941.24030
Overall Steps per Second: 8,684.10672
Timestep Collection Time: 4.57370
Timestep Consumption Time: 1.18878
PPO Batch Consumption Time: 0.05006
Total Iteration Time: 5.76248
Cumulative Model Updates: 3,418
Cumulative Timesteps: 57,079,680
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.07361
Policy Entropy: 5.54562
Value Function Loss: 0.03672
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01952
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.05818
Collected Steps per Second: 11,097.30968
Overall Steps per Second: 8,774.11073
Timestep Collection Time: 4.50686
Timestep Consumption Time: 1.19332
PPO Batch Consumption Time: 0.04922
Total Iteration Time: 5.70018
Cumulative Model Updates: 3,421
Cumulative Timesteps: 57,129,694
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 57129694...
Checkpoint 57129694 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40173
Policy Entropy: 5.54049
Value Function Loss: 0.03463
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01767
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.05826
Collected Steps per Second: 10,987.13115
Overall Steps per Second: 8,686.54428
Timestep Collection Time: 4.55205
Timestep Consumption Time: 1.20559
PPO Batch Consumption Time: 0.04867
Total Iteration Time: 5.75764
Cumulative Model Updates: 3,424
Cumulative Timesteps: 57,179,708
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98719
Policy Entropy: 5.56361
Value Function Loss: 0.03579
Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01385
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.05851
Collected Steps per Second: 10,872.11077
Overall Steps per Second: 8,756.97477
Timestep Collection Time: 4.60223
Timestep Consumption Time: 1.11161
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.71385
Cumulative Model Updates: 3,427
Cumulative Timesteps: 57,229,744
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 57229744...
Checkpoint 57229744 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75156
Policy Entropy: 5.54286
Value Function Loss: 0.03709
Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01115
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.06079
Collected Steps per Second: 10,898.21918
Overall Steps per Second: 8,611.95891
Timestep Collection Time: 4.59103
Timestep Consumption Time: 1.21880
PPO Batch Consumption Time: 0.05235
Total Iteration Time: 5.80983
Cumulative Model Updates: 3,430
Cumulative Timesteps: 57,279,778
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78953
Policy Entropy: 5.54450
Value Function Loss: 0.03524
Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.00995
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.05894
Collected Steps per Second: 10,910.40746
Overall Steps per Second: 8,595.46744
Timestep Collection Time: 4.58663
Timestep Consumption Time: 1.23528
PPO Batch Consumption Time: 0.07300
Total Iteration Time: 5.82191
Cumulative Model Updates: 3,433
Cumulative Timesteps: 57,329,820
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 57329820...
Checkpoint 57329820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75399
Policy Entropy: 5.56235
Value Function Loss: 0.03205
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02752
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.05712
Collected Steps per Second: 11,084.78230
Overall Steps per Second: 8,732.24941
Timestep Collection Time: 4.51267
Timestep Consumption Time: 1.21575
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.72842
Cumulative Model Updates: 3,436
Cumulative Timesteps: 57,379,842
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.27669
Policy Entropy: 5.56897
Value Function Loss: 0.03183
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.05774
Collected Steps per Second: 10,975.75372
Overall Steps per Second: 8,696.22820
Timestep Collection Time: 4.55823
Timestep Consumption Time: 1.19484
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.75307
Cumulative Model Updates: 3,439
Cumulative Timesteps: 57,429,872
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 57429872...
Checkpoint 57429872 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80553
Policy Entropy: 5.58340
Value Function Loss: 0.03011
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01899
Policy Update Magnitude: 0.04407
Value Function Update Magnitude: 0.05971
Collected Steps per Second: 10,944.92547
Overall Steps per Second: 8,683.05777
Timestep Collection Time: 4.56924
Timestep Consumption Time: 1.19025
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.75949
Cumulative Model Updates: 3,442
Cumulative Timesteps: 57,479,882
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.06297
Policy Entropy: 5.59959
Value Function Loss: 0.03316
Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01041
Policy Update Magnitude: 0.04690
Value Function Update Magnitude: 0.05825
Collected Steps per Second: 11,172.16474
Overall Steps per Second: 8,815.36178
Timestep Collection Time: 4.47970
Timestep Consumption Time: 1.19766
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.67736
Cumulative Model Updates: 3,445
Cumulative Timesteps: 57,529,930
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 57529930...
Checkpoint 57529930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68047
Policy Entropy: 5.58906
Value Function Loss: 0.04057
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.05512
Collected Steps per Second: 10,972.45819
Overall Steps per Second: 8,673.85439
Timestep Collection Time: 4.55778
Timestep Consumption Time: 1.20783
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.76560
Cumulative Model Updates: 3,448
Cumulative Timesteps: 57,579,940
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83187
Policy Entropy: 5.55380
Value Function Loss: 0.04395
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01545
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.05963
Collected Steps per Second: 10,830.18382
Overall Steps per Second: 8,736.31307
Timestep Collection Time: 4.62097
Timestep Consumption Time: 1.10753
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.72850
Cumulative Model Updates: 3,451
Cumulative Timesteps: 57,629,986
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 57629986...
Checkpoint 57629986 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84366
Policy Entropy: 5.52865
Value Function Loss: 0.04160
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03019
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.06354
Collected Steps per Second: 10,984.18065
Overall Steps per Second: 8,689.19767
Timestep Collection Time: 4.55455
Timestep Consumption Time: 1.20294
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.75749
Cumulative Model Updates: 3,454
Cumulative Timesteps: 57,680,014
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70014
Policy Entropy: 5.50712
Value Function Loss: 0.03673
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02849
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.05696
Collected Steps per Second: 10,889.30025
Overall Steps per Second: 8,538.20740
Timestep Collection Time: 4.59589
Timestep Consumption Time: 1.26553
PPO Batch Consumption Time: 0.08397
Total Iteration Time: 5.86142
Cumulative Model Updates: 3,457
Cumulative Timesteps: 57,730,060
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 57730060...
Checkpoint 57730060 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79851
Policy Entropy: 5.52026
Value Function Loss: 0.04123
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.05326
Collected Steps per Second: 11,230.95335
Overall Steps per Second: 8,812.26862
Timestep Collection Time: 4.45376
Timestep Consumption Time: 1.22241
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.67618
Cumulative Model Updates: 3,460
Cumulative Timesteps: 57,780,080
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.11779
Policy Entropy: 5.53005
Value Function Loss: 0.04900
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.05747
Collected Steps per Second: 10,893.33298
Overall Steps per Second: 8,620.97020
Timestep Collection Time: 4.59382
Timestep Consumption Time: 1.21086
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.80468
Cumulative Model Updates: 3,463
Cumulative Timesteps: 57,830,122
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 57830122...
Checkpoint 57830122 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.73918
Policy Entropy: 5.49936
Value Function Loss: 0.04603
Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04087
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.06195
Collected Steps per Second: 10,866.86188
Overall Steps per Second: 8,647.30547
Timestep Collection Time: 4.60501
Timestep Consumption Time: 1.18200
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.78701
Cumulative Model Updates: 3,466
Cumulative Timesteps: 57,880,164
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85849
Policy Entropy: 5.50519
Value Function Loss: 0.04137
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02080
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.06204
Collected Steps per Second: 11,234.06680
Overall Steps per Second: 8,843.85895
Timestep Collection Time: 4.45271
Timestep Consumption Time: 1.20342
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.65613
Cumulative Model Updates: 3,469
Cumulative Timesteps: 57,930,186
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 57930186...
Checkpoint 57930186 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.01769
Policy Entropy: 5.54126
Value Function Loss: 0.03386
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03014
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.05743
Collected Steps per Second: 10,926.38344
Overall Steps per Second: 8,656.81097
Timestep Collection Time: 4.57791
Timestep Consumption Time: 1.20020
PPO Batch Consumption Time: 0.05027
Total Iteration Time: 5.77811
Cumulative Model Updates: 3,472
Cumulative Timesteps: 57,980,206
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.13254
Policy Entropy: 5.55474
Value Function Loss: 0.03567
Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03874
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.05488
Collected Steps per Second: 10,830.53705
Overall Steps per Second: 8,725.07773
Timestep Collection Time: 4.61676
Timestep Consumption Time: 1.11408
PPO Batch Consumption Time: 0.05019
Total Iteration Time: 5.73084
Cumulative Model Updates: 3,475
Cumulative Timesteps: 58,030,208
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 58030208...
Checkpoint 58030208 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87620
Policy Entropy: 5.54966
Value Function Loss: 0.03549
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01943
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.05066
Collected Steps per Second: 10,917.33763
Overall Steps per Second: 8,671.89297
Timestep Collection Time: 4.58280
Timestep Consumption Time: 1.18664
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76944
Cumulative Model Updates: 3,478
Cumulative Timesteps: 58,080,240
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04031
Policy Entropy: 5.56821
Value Function Loss: 0.03710
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01799
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.05486
Collected Steps per Second: 10,865.39861
Overall Steps per Second: 8,541.93255
Timestep Collection Time: 4.60729
Timestep Consumption Time: 1.25321
PPO Batch Consumption Time: 0.07800
Total Iteration Time: 5.86050
Cumulative Model Updates: 3,481
Cumulative Timesteps: 58,130,300
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 58130300...
Checkpoint 58130300 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.34247
Policy Entropy: 5.57617
Value Function Loss: 0.03487
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01679
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.05170
Collected Steps per Second: 10,922.48602
Overall Steps per Second: 8,818.45311
Timestep Collection Time: 4.58137
Timestep Consumption Time: 1.09309
PPO Batch Consumption Time: 0.05382
Total Iteration Time: 5.67446
Cumulative Model Updates: 3,484
Cumulative Timesteps: 58,180,340
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.99714
Policy Entropy: 5.56240
Value Function Loss: 0.03428
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02299
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.05047
Collected Steps per Second: 10,934.03461
Overall Steps per Second: 8,705.99879
Timestep Collection Time: 4.57745
Timestep Consumption Time: 1.17146
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.74891
Cumulative Model Updates: 3,487
Cumulative Timesteps: 58,230,390
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 58230390...
Checkpoint 58230390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.27234
Policy Entropy: 5.57729
Value Function Loss: 0.03319
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01891
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.04999
Collected Steps per Second: 10,870.98943
Overall Steps per Second: 8,647.54647
Timestep Collection Time: 4.60436
Timestep Consumption Time: 1.18387
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.78823
Cumulative Model Updates: 3,490
Cumulative Timesteps: 58,280,444
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62310
Policy Entropy: 5.58458
Value Function Loss: 0.03325
Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01108
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.04777
Collected Steps per Second: 11,241.85288
Overall Steps per Second: 8,859.37072
Timestep Collection Time: 4.45051
Timestep Consumption Time: 1.19684
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.64735
Cumulative Model Updates: 3,493
Cumulative Timesteps: 58,330,476
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 58330476...
Checkpoint 58330476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.93347
Policy Entropy: 5.57371
Value Function Loss: 0.03690
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.05014
Collected Steps per Second: 10,924.07760
Overall Steps per Second: 8,662.35658
Timestep Collection Time: 4.58089
Timestep Consumption Time: 1.19606
PPO Batch Consumption Time: 0.05005
Total Iteration Time: 5.77695
Cumulative Model Updates: 3,496
Cumulative Timesteps: 58,380,518
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.34034
Policy Entropy: 5.57539
Value Function Loss: 0.03810
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02316
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.05440
Collected Steps per Second: 10,896.10342
Overall Steps per Second: 8,790.89111
Timestep Collection Time: 4.59026
Timestep Consumption Time: 1.09926
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.68953
Cumulative Model Updates: 3,499
Cumulative Timesteps: 58,430,534
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 58430534...
Checkpoint 58430534 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.99025
Policy Entropy: 5.56969
Value Function Loss: 0.03638
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.05384
Collected Steps per Second: 10,859.12694
Overall Steps per Second: 8,557.59077
Timestep Collection Time: 4.60700
Timestep Consumption Time: 1.23904
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.84604
Cumulative Model Updates: 3,502
Cumulative Timesteps: 58,480,562
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83289
Policy Entropy: 5.54553
Value Function Loss: 0.03838
Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03351
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.05639
Collected Steps per Second: 10,878.67358
Overall Steps per Second: 8,434.87753
Timestep Collection Time: 4.59707
Timestep Consumption Time: 1.33189
PPO Batch Consumption Time: 0.07752
Total Iteration Time: 5.92895
Cumulative Model Updates: 3,505
Cumulative Timesteps: 58,530,572
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 58530572...
Checkpoint 58530572 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.00488
Policy Entropy: 5.55756
Value Function Loss: 0.04223
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03222
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.05478
Collected Steps per Second: 10,893.38770
Overall Steps per Second: 8,644.73325
Timestep Collection Time: 4.59545
Timestep Consumption Time: 1.19536
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.79081
Cumulative Model Updates: 3,508
Cumulative Timesteps: 58,580,632
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.76000
Policy Entropy: 5.54638
Value Function Loss: 0.04857
Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01539
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.05606
Collected Steps per Second: 10,932.65952
Overall Steps per Second: 8,641.44191
Timestep Collection Time: 4.57638
Timestep Consumption Time: 1.21339
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.78977
Cumulative Model Updates: 3,511
Cumulative Timesteps: 58,630,664
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 58630664...
Checkpoint 58630664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84864
Policy Entropy: 5.53396
Value Function Loss: 0.04776
Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05855
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.06334
Collected Steps per Second: 10,863.91076
Overall Steps per Second: 8,666.96780
Timestep Collection Time: 4.60295
Timestep Consumption Time: 1.16678
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.76972
Cumulative Model Updates: 3,514
Cumulative Timesteps: 58,680,670
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.56374
Policy Entropy: 5.54905
Value Function Loss: 0.04313
Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05608
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.06037
Collected Steps per Second: 11,119.42103
Overall Steps per Second: 8,789.62205
Timestep Collection Time: 4.50131
Timestep Consumption Time: 1.19313
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69444
Cumulative Model Updates: 3,517
Cumulative Timesteps: 58,730,722
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 58730722...
Checkpoint 58730722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84617
Policy Entropy: 5.56822
Value Function Loss: 0.03584
Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04477
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.05851
Collected Steps per Second: 10,948.05241
Overall Steps per Second: 8,637.62075
Timestep Collection Time: 4.57031
Timestep Consumption Time: 1.22249
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.79280
Cumulative Model Updates: 3,520
Cumulative Timesteps: 58,780,758
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.94415
Policy Entropy: 5.57576
Value Function Loss: 0.03508
Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05083
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.05673
Collected Steps per Second: 10,826.16978
Overall Steps per Second: 8,766.96700
Timestep Collection Time: 4.61862
Timestep Consumption Time: 1.08483
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.70345
Cumulative Model Updates: 3,523
Cumulative Timesteps: 58,830,760
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 58830760...
Checkpoint 58830760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87265
Policy Entropy: 5.56624
Value Function Loss: 0.03754
Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.04635
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.05504
Collected Steps per Second: 10,922.79979
Overall Steps per Second: 8,666.60647
Timestep Collection Time: 4.58161
Timestep Consumption Time: 1.19274
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.77435
Cumulative Model Updates: 3,526
Cumulative Timesteps: 58,880,804
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67441
Policy Entropy: 5.56375
Value Function Loss: 0.04595
Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03677
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.05155
Collected Steps per Second: 10,857.45090
Overall Steps per Second: 8,592.99149
Timestep Collection Time: 4.60863
Timestep Consumption Time: 1.21449
PPO Batch Consumption Time: 0.06738
Total Iteration Time: 5.82312
Cumulative Model Updates: 3,529
Cumulative Timesteps: 58,930,842
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 58930842...
Checkpoint 58930842 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.94398
Policy Entropy: 5.53487
Value Function Loss: 0.04680
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03639
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.05650
Collected Steps per Second: 10,904.92280
Overall Steps per Second: 8,784.97157
Timestep Collection Time: 4.58582
Timestep Consumption Time: 1.10663
PPO Batch Consumption Time: 0.05225
Total Iteration Time: 5.69245
Cumulative Model Updates: 3,532
Cumulative Timesteps: 58,980,850
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04005
Policy Entropy: 5.51325
Value Function Loss: 0.04667
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03001
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.05669
Collected Steps per Second: 10,993.64888
Overall Steps per Second: 8,708.48507
Timestep Collection Time: 4.54972
Timestep Consumption Time: 1.19388
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.74359
Cumulative Model Updates: 3,535
Cumulative Timesteps: 59,030,868
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 59030868...
Checkpoint 59030868 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.99270
Policy Entropy: 5.49771
Value Function Loss: 0.04576
Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04611
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.05288
Collected Steps per Second: 10,925.56126
Overall Steps per Second: 8,702.42888
Timestep Collection Time: 4.57825
Timestep Consumption Time: 1.16957
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.74782
Cumulative Model Updates: 3,538
Cumulative Timesteps: 59,080,888
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85659
Policy Entropy: 5.54029
Value Function Loss: 0.04325
Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04180
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.05817
Collected Steps per Second: 11,155.65281
Overall Steps per Second: 8,735.84646
Timestep Collection Time: 4.48239
Timestep Consumption Time: 1.24161
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.72400
Cumulative Model Updates: 3,541
Cumulative Timesteps: 59,130,892
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 59130892...
Checkpoint 59130892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61740
Policy Entropy: 5.55461
Value Function Loss: 0.03517
Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04309
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.06172
Collected Steps per Second: 10,831.41630
Overall Steps per Second: 8,546.98241
Timestep Collection Time: 4.61934
Timestep Consumption Time: 1.23466
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.85400
Cumulative Model Updates: 3,544
Cumulative Timesteps: 59,180,926
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87287
Policy Entropy: 5.53688
Value Function Loss: 0.03339
Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03827
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.06194
Collected Steps per Second: 10,857.30106
Overall Steps per Second: 8,747.69685
Timestep Collection Time: 4.60630
Timestep Consumption Time: 1.11086
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.71716
Cumulative Model Updates: 3,547
Cumulative Timesteps: 59,230,938
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 59230938...
Checkpoint 59230938 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61032
Policy Entropy: 5.54438
Value Function Loss: 0.03650
Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04103
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.05714
Collected Steps per Second: 10,974.91825
Overall Steps per Second: 8,670.47136
Timestep Collection Time: 4.55967
Timestep Consumption Time: 1.21187
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77154
Cumulative Model Updates: 3,550
Cumulative Timesteps: 59,280,980
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.01286
Policy Entropy: 5.55226
Value Function Loss: 0.04307
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03164
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.05561
Collected Steps per Second: 10,933.54210
Overall Steps per Second: 8,637.36467
Timestep Collection Time: 4.57692
Timestep Consumption Time: 1.21674
PPO Batch Consumption Time: 0.06915
Total Iteration Time: 5.79367
Cumulative Model Updates: 3,553
Cumulative Timesteps: 59,331,022
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 59331022...
Checkpoint 59331022 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.08997
Policy Entropy: 5.52931
Value Function Loss: 0.04251
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.05554
Collected Steps per Second: 11,122.83667
Overall Steps per Second: 8,763.19070
Timestep Collection Time: 4.49957
Timestep Consumption Time: 1.21159
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.71116
Cumulative Model Updates: 3,556
Cumulative Timesteps: 59,381,070
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68398
Policy Entropy: 5.55187
Value Function Loss: 0.03973
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02122
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.05238
Collected Steps per Second: 10,853.26051
Overall Steps per Second: 8,571.33559
Timestep Collection Time: 4.61096
Timestep Consumption Time: 1.22757
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.83853
Cumulative Model Updates: 3,559
Cumulative Timesteps: 59,431,114
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 59431114...
Checkpoint 59431114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.91621
Policy Entropy: 5.56887
Value Function Loss: 0.03930
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02137
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.04845
Collected Steps per Second: 11,002.43612
Overall Steps per Second: 8,736.84718
Timestep Collection Time: 4.54863
Timestep Consumption Time: 1.17952
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.72815
Cumulative Model Updates: 3,562
Cumulative Timesteps: 59,481,160
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78512
Policy Entropy: 5.58340
Value Function Loss: 0.03446
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03078
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.05038
Collected Steps per Second: 11,138.08843
Overall Steps per Second: 8,797.45153
Timestep Collection Time: 4.49233
Timestep Consumption Time: 1.19522
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.68756
Cumulative Model Updates: 3,565
Cumulative Timesteps: 59,531,196
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 59531196...
Checkpoint 59531196 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03277
Policy Entropy: 5.58078
Value Function Loss: 0.03778
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03518
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.05436
Collected Steps per Second: 10,899.35972
Overall Steps per Second: 8,625.44535
Timestep Collection Time: 4.58963
Timestep Consumption Time: 1.20996
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.79958
Cumulative Model Updates: 3,568
Cumulative Timesteps: 59,581,220
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.81781
Policy Entropy: 5.54548
Value Function Loss: 0.03416
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02949
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.05345
Collected Steps per Second: 10,932.39996
Overall Steps per Second: 8,800.59332
Timestep Collection Time: 4.57539
Timestep Consumption Time: 1.10832
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.68371
Cumulative Model Updates: 3,571
Cumulative Timesteps: 59,631,240
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 59631240...
Checkpoint 59631240 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82267
Policy Entropy: 5.54209
Value Function Loss: 0.03819
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02033
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.05244
Collected Steps per Second: 10,907.40148
Overall Steps per Second: 8,631.56216
Timestep Collection Time: 4.58423
Timestep Consumption Time: 1.20870
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.79293
Cumulative Model Updates: 3,574
Cumulative Timesteps: 59,681,242
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.81685
Policy Entropy: 5.56650
Value Function Loss: 0.03249
Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04102
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.05207
Collected Steps per Second: 10,834.10010
Overall Steps per Second: 8,563.72693
Timestep Collection Time: 4.61746
Timestep Consumption Time: 1.22416
PPO Batch Consumption Time: 0.06633
Total Iteration Time: 5.84162
Cumulative Model Updates: 3,577
Cumulative Timesteps: 59,731,268
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 59731268...
Checkpoint 59731268 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64263
Policy Entropy: 5.54845
Value Function Loss: 0.03757
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.05587
Collected Steps per Second: 10,845.49190
Overall Steps per Second: 8,730.27800
Timestep Collection Time: 4.61150
Timestep Consumption Time: 1.11730
PPO Batch Consumption Time: 0.05281
Total Iteration Time: 5.72880
Cumulative Model Updates: 3,580
Cumulative Timesteps: 59,781,282
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98574
Policy Entropy: 5.54820
Value Function Loss: 0.03905
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.05715
Collected Steps per Second: 10,851.96047
Overall Steps per Second: 8,602.61685
Timestep Collection Time: 4.60931
Timestep Consumption Time: 1.20520
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.81451
Cumulative Model Updates: 3,583
Cumulative Timesteps: 59,831,302
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 59831302...
Checkpoint 59831302 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.58954
Policy Entropy: 5.55226
Value Function Loss: 0.04316
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03092
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.06193
Collected Steps per Second: 10,859.89299
Overall Steps per Second: 8,628.93312
Timestep Collection Time: 4.60833
Timestep Consumption Time: 1.19146
PPO Batch Consumption Time: 0.04989
Total Iteration Time: 5.79979
Cumulative Model Updates: 3,586
Cumulative Timesteps: 59,881,348
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79468
Policy Entropy: 5.55768
Value Function Loss: 0.04268
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.06539
Collected Steps per Second: 11,079.36855
Overall Steps per Second: 8,761.16448
Timestep Collection Time: 4.51668
Timestep Consumption Time: 1.19511
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.71180
Cumulative Model Updates: 3,589
Cumulative Timesteps: 59,931,390
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 59931390...
Checkpoint 59931390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.21741
Policy Entropy: 5.55859
Value Function Loss: 0.03721
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02445
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.06045
Collected Steps per Second: 10,958.59826
Overall Steps per Second: 8,656.54397
Timestep Collection Time: 4.56482
Timestep Consumption Time: 1.21393
PPO Batch Consumption Time: 0.04937
Total Iteration Time: 5.77875
Cumulative Model Updates: 3,592
Cumulative Timesteps: 59,981,414
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.94425
Policy Entropy: 5.60066
Value Function Loss: 0.03658
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.05599
Collected Steps per Second: 10,782.57334
Overall Steps per Second: 8,579.92364
Timestep Collection Time: 4.63804
Timestep Consumption Time: 1.19068
PPO Batch Consumption Time: 0.04935
Total Iteration Time: 5.82872
Cumulative Model Updates: 3,595
Cumulative Timesteps: 60,031,424
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 60031424...
Checkpoint 60031424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.66946
Policy Entropy: 5.56402
Value Function Loss: 0.03583
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01483
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.05570
Collected Steps per Second: 10,905.57527
Overall Steps per Second: 8,602.49463
Timestep Collection Time: 4.58885
Timestep Consumption Time: 1.22854
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.81738
Cumulative Model Updates: 3,598
Cumulative Timesteps: 60,081,468
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.71013
Policy Entropy: 5.54243
Value Function Loss: 0.04454
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01576
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.05410
Collected Steps per Second: 10,906.12804
Overall Steps per Second: 8,501.87792
Timestep Collection Time: 4.58880
Timestep Consumption Time: 1.29767
PPO Batch Consumption Time: 0.07582
Total Iteration Time: 5.88646
Cumulative Model Updates: 3,601
Cumulative Timesteps: 60,131,514
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 60131514...
Checkpoint 60131514 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04988
Policy Entropy: 5.52691
Value Function Loss: 0.04597
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03105
Policy Update Magnitude: 0.06223
Value Function Update Magnitude: 0.05749
Collected Steps per Second: 10,917.13373
Overall Steps per Second: 8,764.39529
Timestep Collection Time: 4.58216
Timestep Consumption Time: 1.12548
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.70764
Cumulative Model Updates: 3,604
Cumulative Timesteps: 60,181,538
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82222
Policy Entropy: 5.53481
Value Function Loss: 0.04102
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02919
Policy Update Magnitude: 0.06636
Value Function Update Magnitude: 0.06411
Collected Steps per Second: 10,641.86468
Overall Steps per Second: 8,433.35089
Timestep Collection Time: 4.70294
Timestep Consumption Time: 1.23160
PPO Batch Consumption Time: 0.05426
Total Iteration Time: 5.93453
Cumulative Model Updates: 3,607
Cumulative Timesteps: 60,231,586
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 60231586...
Checkpoint 60231586 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.32136
Policy Entropy: 5.55151
Value Function Loss: 0.03798
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.07119
Value Function Update Magnitude: 0.06610
Collected Steps per Second: 10,594.39371
Overall Steps per Second: 8,463.83221
Timestep Collection Time: 4.72344
Timestep Consumption Time: 1.18901
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.91245
Cumulative Model Updates: 3,610
Cumulative Timesteps: 60,281,628
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79516
Policy Entropy: 5.53504
Value Function Loss: 0.04132
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.06989
Value Function Update Magnitude: 0.05961
Collected Steps per Second: 11,213.74001
Overall Steps per Second: 8,769.84864
Timestep Collection Time: 4.46220
Timestep Consumption Time: 1.24348
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.70569
Cumulative Model Updates: 3,613
Cumulative Timesteps: 60,331,666
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 60331666...
Checkpoint 60331666 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80840
Policy Entropy: 5.50378
Value Function Loss: 0.04392
Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.03774
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.05778
Collected Steps per Second: 10,849.33529
Overall Steps per Second: 8,560.70705
Timestep Collection Time: 4.61171
Timestep Consumption Time: 1.23290
PPO Batch Consumption Time: 0.05064
Total Iteration Time: 5.84461
Cumulative Model Updates: 3,616
Cumulative Timesteps: 60,381,700
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63916
Policy Entropy: 5.53947
Value Function Loss: 0.04080
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.05925
Collected Steps per Second: 10,996.98626
Overall Steps per Second: 8,713.51097
Timestep Collection Time: 4.54688
Timestep Consumption Time: 1.19156
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.73844
Cumulative Model Updates: 3,619
Cumulative Timesteps: 60,431,702
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 60431702...
Checkpoint 60431702 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.13166
Policy Entropy: 5.52682
Value Function Loss: 0.03409
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02275
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.06013
Collected Steps per Second: 10,997.27725
Overall Steps per Second: 8,637.57476
Timestep Collection Time: 4.54967
Timestep Consumption Time: 1.24293
PPO Batch Consumption Time: 0.05069
Total Iteration Time: 5.79260
Cumulative Model Updates: 3,622
Cumulative Timesteps: 60,481,736
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86321
Policy Entropy: 5.53547
Value Function Loss: 0.03552
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 0.06106
Value Function Update Magnitude: 0.05971
Collected Steps per Second: 10,903.55112
Overall Steps per Second: 8,516.07315
Timestep Collection Time: 4.58915
Timestep Consumption Time: 1.28657
PPO Batch Consumption Time: 0.08233
Total Iteration Time: 5.87571
Cumulative Model Updates: 3,625
Cumulative Timesteps: 60,531,774
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 60531774...
Checkpoint 60531774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.41767
Policy Entropy: 5.53599
Value Function Loss: 0.03693
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03056
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.05329
Collected Steps per Second: 10,853.90722
Overall Steps per Second: 8,734.52533
Timestep Collection Time: 4.60995
Timestep Consumption Time: 1.11858
PPO Batch Consumption Time: 0.05270
Total Iteration Time: 5.72853
Cumulative Model Updates: 3,628
Cumulative Timesteps: 60,581,810
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90269
Policy Entropy: 5.51738
Value Function Loss: 0.03726
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.05409
Collected Steps per Second: 10,842.32869
Overall Steps per Second: 8,613.52827
Timestep Collection Time: 4.61377
Timestep Consumption Time: 1.19384
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.80761
Cumulative Model Updates: 3,631
Cumulative Timesteps: 60,631,834
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 60631834...
Checkpoint 60631834 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.92405
Policy Entropy: 5.52026
Value Function Loss: 0.03571
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01640
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.05992
Collected Steps per Second: 10,880.03512
Overall Steps per Second: 8,659.08153
Timestep Collection Time: 4.59796
Timestep Consumption Time: 1.17932
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77729
Cumulative Model Updates: 3,634
Cumulative Timesteps: 60,681,860
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03832
Policy Entropy: 5.52524
Value Function Loss: 0.03540
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.06273
Collected Steps per Second: 10,914.43545
Overall Steps per Second: 8,806.60645
Timestep Collection Time: 4.58494
Timestep Consumption Time: 1.09739
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.68232
Cumulative Model Updates: 3,637
Cumulative Timesteps: 60,731,902
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 60731902...
Checkpoint 60731902 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04529
Policy Entropy: 5.52563
Value Function Loss: 0.03151
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.05952
Value Function Update Magnitude: 0.05837
Collected Steps per Second: 10,947.92255
Overall Steps per Second: 8,638.95301
Timestep Collection Time: 4.56726
Timestep Consumption Time: 1.22071
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78797
Cumulative Model Updates: 3,640
Cumulative Timesteps: 60,781,904
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03447
Policy Entropy: 5.53726
Value Function Loss: 0.03515
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.05595
Collected Steps per Second: 10,772.20542
Overall Steps per Second: 8,629.71128
Timestep Collection Time: 4.64287
Timestep Consumption Time: 1.15268
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.79556
Cumulative Model Updates: 3,643
Cumulative Timesteps: 60,831,918
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 60831918...
Checkpoint 60831918 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.06788
Policy Entropy: 5.51933
Value Function Loss: 0.03289
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01835
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.04922
Collected Steps per Second: 11,221.51457
Overall Steps per Second: 8,792.93733
Timestep Collection Time: 4.45626
Timestep Consumption Time: 1.23080
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.68706
Cumulative Model Updates: 3,646
Cumulative Timesteps: 60,881,924
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.02893
Policy Entropy: 5.51558
Value Function Loss: 0.04579
Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04009
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.05050
Collected Steps per Second: 10,934.13958
Overall Steps per Second: 8,530.50982
Timestep Collection Time: 4.57667
Timestep Consumption Time: 1.28956
PPO Batch Consumption Time: 0.07200
Total Iteration Time: 5.86624
Cumulative Model Updates: 3,649
Cumulative Timesteps: 60,931,966
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 60931966...
Checkpoint 60931966 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88370
Policy Entropy: 5.52842
Value Function Loss: 0.04356
Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.03793
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.06356
Collected Steps per Second: 10,775.38492
Overall Steps per Second: 8,705.48720
Timestep Collection Time: 4.64095
Timestep Consumption Time: 1.10347
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.74442
Cumulative Model Updates: 3,652
Cumulative Timesteps: 60,981,974
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.06660
Policy Entropy: 5.48852
Value Function Loss: 0.04238
Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.03985
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.06624
Collected Steps per Second: 10,940.85539
Overall Steps per Second: 8,655.81031
Timestep Collection Time: 4.57222
Timestep Consumption Time: 1.20702
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.77924
Cumulative Model Updates: 3,655
Cumulative Timesteps: 61,031,998
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 61031998...
Checkpoint 61031998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.71703
Policy Entropy: 5.50034
Value Function Loss: 0.03739
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01825
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.06373
Collected Steps per Second: 10,908.93942
Overall Steps per Second: 8,682.47321
Timestep Collection Time: 4.58706
Timestep Consumption Time: 1.17627
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.76333
Cumulative Model Updates: 3,658
Cumulative Timesteps: 61,082,038
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62201
Policy Entropy: 5.54496
Value Function Loss: 0.03479
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03443
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.05928
Collected Steps per Second: 11,106.79387
Overall Steps per Second: 8,796.10416
Timestep Collection Time: 4.50571
Timestep Consumption Time: 1.18363
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.68934
Cumulative Model Updates: 3,661
Cumulative Timesteps: 61,132,082
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 61132082...
Checkpoint 61132082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70725
Policy Entropy: 5.49731
Value Function Loss: 0.04634
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01803
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.05983
Collected Steps per Second: 10,817.34643
Overall Steps per Second: 8,592.02636
Timestep Collection Time: 4.62646
Timestep Consumption Time: 1.19824
PPO Batch Consumption Time: 0.05150
Total Iteration Time: 5.82470
Cumulative Model Updates: 3,664
Cumulative Timesteps: 61,182,128
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.81453
Policy Entropy: 5.50261
Value Function Loss: 0.04518
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03020
Policy Update Magnitude: 0.06660
Value Function Update Magnitude: 0.06388
Collected Steps per Second: 10,889.77616
Overall Steps per Second: 8,683.26934
Timestep Collection Time: 4.59458
Timestep Consumption Time: 1.16753
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.76212
Cumulative Model Updates: 3,667
Cumulative Timesteps: 61,232,162
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 61232162...
Checkpoint 61232162 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63249
Policy Entropy: 5.48975
Value Function Loss: 0.04638
Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03488
Policy Update Magnitude: 0.06514
Value Function Update Magnitude: 0.06188
Collected Steps per Second: 11,055.38028
Overall Steps per Second: 8,722.61583
Timestep Collection Time: 4.52594
Timestep Consumption Time: 1.21041
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.73635
Cumulative Model Updates: 3,670
Cumulative Timesteps: 61,282,198
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.26652
Policy Entropy: 5.49972
Value Function Loss: 0.03997
Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05182
Policy Update Magnitude: 0.06757
Value Function Update Magnitude: 0.05739
Collected Steps per Second: 10,931.76307
Overall Steps per Second: 8,540.21753
Timestep Collection Time: 4.57785
Timestep Consumption Time: 1.28195
PPO Batch Consumption Time: 0.08037
Total Iteration Time: 5.85980
Cumulative Model Updates: 3,673
Cumulative Timesteps: 61,332,242
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 61332242...
Checkpoint 61332242 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80948
Policy Entropy: 5.53750
Value Function Loss: 0.03708
Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.04726
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.05693
Collected Steps per Second: 10,862.82766
Overall Steps per Second: 8,747.99526
Timestep Collection Time: 4.60414
Timestep Consumption Time: 1.11305
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.71720
Cumulative Model Updates: 3,676
Cumulative Timesteps: 61,382,256
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64800
Policy Entropy: 5.54363
Value Function Loss: 0.03791
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02977
Policy Update Magnitude: 0.06758
Value Function Update Magnitude: 0.06640
Collected Steps per Second: 10,915.17449
Overall Steps per Second: 8,667.07271
Timestep Collection Time: 4.58426
Timestep Consumption Time: 1.18908
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77334
Cumulative Model Updates: 3,679
Cumulative Timesteps: 61,432,294
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 61432294...
Checkpoint 61432294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.13419
Policy Entropy: 5.53097
Value Function Loss: 0.03520
Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.03973
Policy Update Magnitude: 0.06980
Value Function Update Magnitude: 0.07355
Collected Steps per Second: 10,922.58474
Overall Steps per Second: 8,681.08110
Timestep Collection Time: 4.57895
Timestep Consumption Time: 1.18231
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76126
Cumulative Model Updates: 3,682
Cumulative Timesteps: 61,482,308
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.16514
Policy Entropy: 5.53438
Value Function Loss: 0.03793
Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06196
Policy Update Magnitude: 0.06391
Value Function Update Magnitude: 0.05916
Collected Steps per Second: 11,048.24446
Overall Steps per Second: 8,690.83430
Timestep Collection Time: 4.53031
Timestep Consumption Time: 1.22886
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.75917
Cumulative Model Updates: 3,685
Cumulative Timesteps: 61,532,360
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 61532360...
Checkpoint 61532360 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.27352
Policy Entropy: 5.52260
Value Function Loss: 0.03604
Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.04805
Policy Update Magnitude: 0.06692
Value Function Update Magnitude: 0.06576
Collected Steps per Second: 10,816.86390
Overall Steps per Second: 8,585.83901
Timestep Collection Time: 4.62556
Timestep Consumption Time: 1.20195
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.82750
Cumulative Model Updates: 3,688
Cumulative Timesteps: 61,582,394
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46707
Policy Entropy: 5.55819
Value Function Loss: 0.03466
Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04131
Policy Update Magnitude: 0.07449
Value Function Update Magnitude: 0.06039
Collected Steps per Second: 10,826.73438
Overall Steps per Second: 8,633.60308
Timestep Collection Time: 4.61875
Timestep Consumption Time: 1.17327
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.79202
Cumulative Model Updates: 3,691
Cumulative Timesteps: 61,632,400
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 61632400...
Checkpoint 61632400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69946
Policy Entropy: 5.56251
Value Function Loss: 0.03923
Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05169
Policy Update Magnitude: 0.07510
Value Function Update Magnitude: 0.05936
Collected Steps per Second: 11,143.30903
Overall Steps per Second: 8,764.57526
Timestep Collection Time: 4.48718
Timestep Consumption Time: 1.21783
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.70501
Cumulative Model Updates: 3,694
Cumulative Timesteps: 61,682,402
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75184
Policy Entropy: 5.54589
Value Function Loss: 0.03780
Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05271
Policy Update Magnitude: 0.06647
Value Function Update Magnitude: 0.06470
Collected Steps per Second: 10,930.69078
Overall Steps per Second: 8,563.73986
Timestep Collection Time: 4.57629
Timestep Consumption Time: 1.26485
PPO Batch Consumption Time: 0.07166
Total Iteration Time: 5.84114
Cumulative Model Updates: 3,697
Cumulative Timesteps: 61,732,424
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 61732424...
Checkpoint 61732424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88343
Policy Entropy: 5.54656
Value Function Loss: 0.04123
Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04005
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.05858
Collected Steps per Second: 10,875.41739
Overall Steps per Second: 8,737.93284
Timestep Collection Time: 4.59881
Timestep Consumption Time: 1.12497
PPO Batch Consumption Time: 0.05323
Total Iteration Time: 5.72378
Cumulative Model Updates: 3,700
Cumulative Timesteps: 61,782,438
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.81988
Policy Entropy: 5.54202
Value Function Loss: 0.03782
Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04017
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.05684
Collected Steps per Second: 10,863.51977
Overall Steps per Second: 8,607.96156
Timestep Collection Time: 4.60587
Timestep Consumption Time: 1.20688
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.81276
Cumulative Model Updates: 3,703
Cumulative Timesteps: 61,832,474
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 61832474...
Checkpoint 61832474 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77500
Policy Entropy: 5.53865
Value Function Loss: 0.04046
Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04823
Policy Update Magnitude: 0.06137
Value Function Update Magnitude: 0.05767
Collected Steps per Second: 10,740.67289
Overall Steps per Second: 8,611.22386
Timestep Collection Time: 4.65930
Timestep Consumption Time: 1.15219
PPO Batch Consumption Time: 0.05174
Total Iteration Time: 5.81149
Cumulative Model Updates: 3,706
Cumulative Timesteps: 61,882,518
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04313
Policy Entropy: 5.56345
Value Function Loss: 0.03760
Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04487
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.05658
Collected Steps per Second: 10,727.87256
Overall Steps per Second: 8,644.86894
Timestep Collection Time: 4.66486
Timestep Consumption Time: 1.12401
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.78887
Cumulative Model Updates: 3,709
Cumulative Timesteps: 61,932,562
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 61932562...
Checkpoint 61932562 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55801
Policy Entropy: 5.51811
Value Function Loss: 0.03444
Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03377
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.05661
Collected Steps per Second: 10,886.68788
Overall Steps per Second: 8,636.38505
Timestep Collection Time: 4.59644
Timestep Consumption Time: 1.19765
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.79409
Cumulative Model Updates: 3,712
Cumulative Timesteps: 61,982,602
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83839
Policy Entropy: 5.50989
Value Function Loss: 0.03037
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.06210
Value Function Update Magnitude: 0.06202
Collected Steps per Second: 10,958.76921
Overall Steps per Second: 8,699.55736
Timestep Collection Time: 4.56566
Timestep Consumption Time: 1.18567
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.75133
Cumulative Model Updates: 3,715
Cumulative Timesteps: 62,032,636
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 62032636...
Checkpoint 62032636 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.12407
Policy Entropy: 5.51041
Value Function Loss: 0.03237
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03293
Policy Update Magnitude: 0.06279
Value Function Update Magnitude: 0.05921
Collected Steps per Second: 11,047.86074
Overall Steps per Second: 8,727.32229
Timestep Collection Time: 4.52956
Timestep Consumption Time: 1.20438
PPO Batch Consumption Time: 0.05054
Total Iteration Time: 5.73395
Cumulative Model Updates: 3,718
Cumulative Timesteps: 62,082,678
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55148
Policy Entropy: 5.49315
Value Function Loss: 0.03372
Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04258
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.05435
Collected Steps per Second: 10,960.72399
Overall Steps per Second: 8,589.19171
Timestep Collection Time: 4.56630
Timestep Consumption Time: 1.26079
PPO Batch Consumption Time: 0.06567
Total Iteration Time: 5.82709
Cumulative Model Updates: 3,721
Cumulative Timesteps: 62,132,728
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 62132728...
Checkpoint 62132728 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.14491
Policy Entropy: 5.51817
Value Function Loss: 0.03794
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02968
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.05534
Collected Steps per Second: 10,896.65423
Overall Steps per Second: 8,754.97170
Timestep Collection Time: 4.58930
Timestep Consumption Time: 1.12266
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.71195
Cumulative Model Updates: 3,724
Cumulative Timesteps: 62,182,736
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98343
Policy Entropy: 5.52217
Value Function Loss: 0.03433
Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04103
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.05702
Collected Steps per Second: 10,936.26136
Overall Steps per Second: 8,658.05737
Timestep Collection Time: 4.57304
Timestep Consumption Time: 1.20331
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.77635
Cumulative Model Updates: 3,727
Cumulative Timesteps: 62,232,748
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 62232748...
Checkpoint 62232748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85862
Policy Entropy: 5.50072
Value Function Loss: 0.03776
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03100
Policy Update Magnitude: 0.06136
Value Function Update Magnitude: 0.05407
Collected Steps per Second: 10,892.39111
Overall Steps per Second: 8,668.21559
Timestep Collection Time: 4.59256
Timestep Consumption Time: 1.17840
PPO Batch Consumption Time: 0.04944
Total Iteration Time: 5.77097
Cumulative Model Updates: 3,730
Cumulative Timesteps: 62,282,772
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.32106
Policy Entropy: 5.51679
Value Function Loss: 0.03559
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03318
Policy Update Magnitude: 0.06036
Value Function Update Magnitude: 0.04732
Collected Steps per Second: 10,819.23173
Overall Steps per Second: 8,733.97807
Timestep Collection Time: 4.62362
Timestep Consumption Time: 1.10390
PPO Batch Consumption Time: 0.05074
Total Iteration Time: 5.72752
Cumulative Model Updates: 3,733
Cumulative Timesteps: 62,332,796
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 62332796...
Checkpoint 62332796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55527
Policy Entropy: 5.48460
Value Function Loss: 0.03579
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02863
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.04788
Collected Steps per Second: 10,888.48638
Overall Steps per Second: 8,602.91620
Timestep Collection Time: 4.59274
Timestep Consumption Time: 1.22017
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.81291
Cumulative Model Updates: 3,736
Cumulative Timesteps: 62,382,804
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67808
Policy Entropy: 5.48873
Value Function Loss: 0.03446
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02545
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.04895
Collected Steps per Second: 10,872.56955
Overall Steps per Second: 8,693.97156
Timestep Collection Time: 4.60278
Timestep Consumption Time: 1.15340
PPO Batch Consumption Time: 0.04918
Total Iteration Time: 5.75617
Cumulative Model Updates: 3,739
Cumulative Timesteps: 62,432,848
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 62432848...
Checkpoint 62432848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.00558
Policy Entropy: 5.49750
Value Function Loss: 0.04005
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02763
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.05272
Collected Steps per Second: 11,133.34383
Overall Steps per Second: 8,774.77562
Timestep Collection Time: 4.49443
Timestep Consumption Time: 1.20806
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.70248
Cumulative Model Updates: 3,742
Cumulative Timesteps: 62,482,886
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.46051
Policy Entropy: 5.49523
Value Function Loss: 0.04221
Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04044
Policy Update Magnitude: 0.06323
Value Function Update Magnitude: 0.05567
Collected Steps per Second: 10,981.94467
Overall Steps per Second: 8,517.33165
Timestep Collection Time: 4.55621
Timestep Consumption Time: 1.31840
PPO Batch Consumption Time: 0.07967
Total Iteration Time: 5.87461
Cumulative Model Updates: 3,745
Cumulative Timesteps: 62,532,922
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 62532922...
Checkpoint 62532922 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77583
Policy Entropy: 5.49588
Value Function Loss: 0.03680
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03095
Policy Update Magnitude: 0.06222
Value Function Update Magnitude: 0.06526
Collected Steps per Second: 10,933.35881
Overall Steps per Second: 8,814.56960
Timestep Collection Time: 4.57334
Timestep Consumption Time: 1.09931
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.67265
Cumulative Model Updates: 3,748
Cumulative Timesteps: 62,582,924
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79351
Policy Entropy: 5.52062
Value Function Loss: 0.03244
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02156
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.06343
Collected Steps per Second: 10,212.82068
Overall Steps per Second: 8,163.44857
Timestep Collection Time: 4.89581
Timestep Consumption Time: 1.22906
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 6.12486
Cumulative Model Updates: 3,751
Cumulative Timesteps: 62,632,924
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 62632924...
Checkpoint 62632924 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.56841
Policy Entropy: 5.51157
Value Function Loss: 0.03826
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.05519
Collected Steps per Second: 10,991.08523
Overall Steps per Second: 8,693.60124
Timestep Collection Time: 4.55351
Timestep Consumption Time: 1.20337
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.75688
Cumulative Model Updates: 3,754
Cumulative Timesteps: 62,682,972
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.80338
Policy Entropy: 5.50755
Value Function Loss: 0.04681
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03073
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.05998
Collected Steps per Second: 10,956.87526
Overall Steps per Second: 8,843.88945
Timestep Collection Time: 4.56700
Timestep Consumption Time: 1.09115
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.65814
Cumulative Model Updates: 3,757
Cumulative Timesteps: 62,733,012
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 62733012...
Checkpoint 62733012 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79713
Policy Entropy: 5.48134
Value Function Loss: 0.04326
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03225
Policy Update Magnitude: 0.06200
Value Function Update Magnitude: 0.06334
Collected Steps per Second: 10,913.35097
Overall Steps per Second: 8,622.27344
Timestep Collection Time: 4.58209
Timestep Consumption Time: 1.21754
PPO Batch Consumption Time: 0.05023
Total Iteration Time: 5.79963
Cumulative Model Updates: 3,760
Cumulative Timesteps: 62,783,018
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75083
Policy Entropy: 5.51303
Value Function Loss: 0.03926
Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.03906
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.06370
Collected Steps per Second: 10,858.94856
Overall Steps per Second: 8,651.74186
Timestep Collection Time: 4.60597
Timestep Consumption Time: 1.17506
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78103
Cumulative Model Updates: 3,763
Cumulative Timesteps: 62,833,034
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 62833034...
Checkpoint 62833034 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.08820
Policy Entropy: 5.52340
Value Function Loss: 0.03580
Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03708
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.05892
Collected Steps per Second: 10,986.06503
Overall Steps per Second: 8,674.99376
Timestep Collection Time: 4.55158
Timestep Consumption Time: 1.21257
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.76415
Cumulative Model Updates: 3,766
Cumulative Timesteps: 62,883,038
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.10144
Policy Entropy: 5.49312
Value Function Loss: 0.04027
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02156
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.05852
Collected Steps per Second: 10,952.52152
Overall Steps per Second: 8,607.07104
Timestep Collection Time: 4.56516
Timestep Consumption Time: 1.24402
PPO Batch Consumption Time: 0.06598
Total Iteration Time: 5.80918
Cumulative Model Updates: 3,769
Cumulative Timesteps: 62,933,038
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 62933038...
Checkpoint 62933038 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.36192
Policy Entropy: 5.50540
Value Function Loss: 0.03925
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01470
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.06113
Collected Steps per Second: 10,926.28771
Overall Steps per Second: 8,684.06182
Timestep Collection Time: 4.57996
Timestep Consumption Time: 1.18255
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.76251
Cumulative Model Updates: 3,772
Cumulative Timesteps: 62,983,080
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68533
Policy Entropy: 5.49865
Value Function Loss: 0.03853
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01457
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.05725
Collected Steps per Second: 11,156.76002
Overall Steps per Second: 8,817.40291
Timestep Collection Time: 4.48177
Timestep Consumption Time: 1.18906
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.67083
Cumulative Model Updates: 3,775
Cumulative Timesteps: 63,033,082
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 63033082...
Checkpoint 63033082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70342
Policy Entropy: 5.48461
Value Function Loss: 0.04116
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03655
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.05422
Collected Steps per Second: 10,858.92465
Overall Steps per Second: 8,610.77183
Timestep Collection Time: 4.60451
Timestep Consumption Time: 1.20217
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.80668
Cumulative Model Updates: 3,778
Cumulative Timesteps: 63,083,082
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.17002
Policy Entropy: 5.50250
Value Function Loss: 0.03961
Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03955
Policy Update Magnitude: 0.06005
Value Function Update Magnitude: 0.05592
Collected Steps per Second: 10,885.46320
Overall Steps per Second: 8,766.39023
Timestep Collection Time: 4.59328
Timestep Consumption Time: 1.11032
PPO Batch Consumption Time: 0.04986
Total Iteration Time: 5.70360
Cumulative Model Updates: 3,781
Cumulative Timesteps: 63,133,082
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 63133082...
Checkpoint 63133082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90247
Policy Entropy: 5.48174
Value Function Loss: 0.04190
Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05125
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.05801
Collected Steps per Second: 10,874.73521
Overall Steps per Second: 8,604.13773
Timestep Collection Time: 4.60076
Timestep Consumption Time: 1.21412
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.81488
Cumulative Model Updates: 3,784
Cumulative Timesteps: 63,183,114
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69581
Policy Entropy: 5.48546
Value Function Loss: 0.03555
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03370
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.05874
Collected Steps per Second: 10,929.11344
Overall Steps per Second: 8,743.00345
Timestep Collection Time: 4.57512
Timestep Consumption Time: 1.14397
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 5.71909
Cumulative Model Updates: 3,787
Cumulative Timesteps: 63,233,116
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 63233116...
Checkpoint 63233116 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66962
Policy Entropy: 5.50579
Value Function Loss: 0.03603
Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04655
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.05848
Collected Steps per Second: 11,017.75717
Overall Steps per Second: 8,730.51205
Timestep Collection Time: 4.53958
Timestep Consumption Time: 1.18929
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.72887
Cumulative Model Updates: 3,790
Cumulative Timesteps: 63,283,132
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69354
Policy Entropy: 5.50285
Value Function Loss: 0.03684
Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06320
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.05668
Collected Steps per Second: 11,048.45395
Overall Steps per Second: 8,614.81869
Timestep Collection Time: 4.52932
Timestep Consumption Time: 1.27951
PPO Batch Consumption Time: 0.07100
Total Iteration Time: 5.80883
Cumulative Model Updates: 3,793
Cumulative Timesteps: 63,333,174
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 63333174...
Checkpoint 63333174 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.23132
Policy Entropy: 5.49878
Value Function Loss: 0.04039
Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04314
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.05882
Collected Steps per Second: 10,989.22325
Overall Steps per Second: 8,728.80266
Timestep Collection Time: 4.55064
Timestep Consumption Time: 1.17844
PPO Batch Consumption Time: 0.05356
Total Iteration Time: 5.72908
Cumulative Model Updates: 3,796
Cumulative Timesteps: 63,383,182
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.97516
Policy Entropy: 5.48049
Value Function Loss: 0.03855
Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.04878
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.05795
Collected Steps per Second: 11,037.67839
Overall Steps per Second: 8,727.58450
Timestep Collection Time: 4.53084
Timestep Consumption Time: 1.19926
PPO Batch Consumption Time: 0.05078
Total Iteration Time: 5.73011
Cumulative Model Updates: 3,799
Cumulative Timesteps: 63,433,192
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 63433192...
Checkpoint 63433192 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.29323
Policy Entropy: 5.51728
Value Function Loss: 0.03653
Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03841
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.05319
Collected Steps per Second: 10,947.56158
Overall Steps per Second: 8,647.80093
Timestep Collection Time: 4.57070
Timestep Consumption Time: 1.21551
PPO Batch Consumption Time: 0.05075
Total Iteration Time: 5.78621
Cumulative Model Updates: 3,802
Cumulative Timesteps: 63,483,230
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.43259
Policy Entropy: 5.51770
Value Function Loss: 0.04122
Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05309
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.05011
Collected Steps per Second: 10,939.58142
Overall Steps per Second: 8,812.28248
Timestep Collection Time: 4.57312
Timestep Consumption Time: 1.10396
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.67708
Cumulative Model Updates: 3,805
Cumulative Timesteps: 63,533,258
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 63533258...
Checkpoint 63533258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80577
Policy Entropy: 5.48996
Value Function Loss: 0.04374
Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06036
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.05473
Collected Steps per Second: 10,797.17851
Overall Steps per Second: 8,560.42100
Timestep Collection Time: 4.63232
Timestep Consumption Time: 1.21038
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.84270
Cumulative Model Updates: 3,808
Cumulative Timesteps: 63,583,274
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.25552
Policy Entropy: 5.52229
Value Function Loss: 0.04167
Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.06950
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.05897
Collected Steps per Second: 10,936.48872
Overall Steps per Second: 8,732.44468
Timestep Collection Time: 4.57386
Timestep Consumption Time: 1.15443
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.72829
Cumulative Model Updates: 3,811
Cumulative Timesteps: 63,633,296
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 63633296...
Checkpoint 63633296 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.18926
Policy Entropy: 5.55218
Value Function Loss: 0.03499
Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.05137
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.05847
Collected Steps per Second: 10,861.46365
Overall Steps per Second: 8,759.02172
Timestep Collection Time: 4.60472
Timestep Consumption Time: 1.10528
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.71000
Cumulative Model Updates: 3,814
Cumulative Timesteps: 63,683,310
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.06331
Policy Entropy: 5.54920
Value Function Loss: 0.03752
Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.05035
Collected Steps per Second: 10,923.17923
Overall Steps per Second: 8,536.66768
Timestep Collection Time: 4.57834
Timestep Consumption Time: 1.27992
PPO Batch Consumption Time: 0.07267
Total Iteration Time: 5.85826
Cumulative Model Updates: 3,817
Cumulative Timesteps: 63,733,320
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 63733320...
Checkpoint 63733320 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.68722
Policy Entropy: 5.56648
Value Function Loss: 0.04290
Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.04893
Collected Steps per Second: 11,044.16478
Overall Steps per Second: 8,748.59550
Timestep Collection Time: 4.52764
Timestep Consumption Time: 1.18802
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.71566
Cumulative Model Updates: 3,820
Cumulative Timesteps: 63,783,324
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.91182
Policy Entropy: 5.58575
Value Function Loss: 0.03841
Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.05555
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.04868
Collected Steps per Second: 11,121.23317
Overall Steps per Second: 8,784.77897
Timestep Collection Time: 4.50040
Timestep Consumption Time: 1.19695
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.69735
Cumulative Model Updates: 3,823
Cumulative Timesteps: 63,833,374
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 63833374...
Checkpoint 63833374 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83548
Policy Entropy: 5.57744
Value Function Loss: 0.03423
Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04537
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.05084
Collected Steps per Second: 10,852.58230
Overall Steps per Second: 8,598.85155
Timestep Collection Time: 4.61052
Timestep Consumption Time: 1.20840
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 5.81892
Cumulative Model Updates: 3,826
Cumulative Timesteps: 63,883,410
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.32769
Policy Entropy: 5.56063
Value Function Loss: 0.03091
Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04277
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.05040
Collected Steps per Second: 10,730.58059
Overall Steps per Second: 8,664.06080
Timestep Collection Time: 4.66312
Timestep Consumption Time: 1.11223
PPO Batch Consumption Time: 0.05005
Total Iteration Time: 5.77535
Cumulative Model Updates: 3,829
Cumulative Timesteps: 63,933,448
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 63933448...
Checkpoint 63933448 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03185
Policy Entropy: 5.55413
Value Function Loss: 0.03691
Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03589
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.05141
Collected Steps per Second: 10,899.45784
Overall Steps per Second: 8,628.21328
Timestep Collection Time: 4.58885
Timestep Consumption Time: 1.20794
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.79680
Cumulative Model Updates: 3,832
Cumulative Timesteps: 63,983,464
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.55516
Policy Entropy: 5.54241
Value Function Loss: 0.03901
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.05776
Collected Steps per Second: 10,966.51783
Overall Steps per Second: 8,718.46643
Timestep Collection Time: 4.56407
Timestep Consumption Time: 1.17684
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.74092
Cumulative Model Updates: 3,835
Cumulative Timesteps: 64,033,516
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 64033516...
Checkpoint 64033516 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.10297
Policy Entropy: 5.51558
Value Function Loss: 0.03943
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02278
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.06298
Collected Steps per Second: 11,123.43294
Overall Steps per Second: 8,787.56505
Timestep Collection Time: 4.49843
Timestep Consumption Time: 1.19575
PPO Batch Consumption Time: 0.05089
Total Iteration Time: 5.69418
Cumulative Model Updates: 3,838
Cumulative Timesteps: 64,083,554
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03351
Policy Entropy: 5.51740
Value Function Loss: 0.03417
Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01481
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.06105
Collected Steps per Second: 10,875.57034
Overall Steps per Second: 8,476.05770
Timestep Collection Time: 4.60151
Timestep Consumption Time: 1.30265
PPO Batch Consumption Time: 0.08070
Total Iteration Time: 5.90416
Cumulative Model Updates: 3,841
Cumulative Timesteps: 64,133,598
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 64133598...
Checkpoint 64133598 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74147
Policy Entropy: 5.51446
Value Function Loss: 0.03228
Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01522
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.05337
Collected Steps per Second: 10,909.24457
Overall Steps per Second: 8,669.04139
Timestep Collection Time: 4.58639
Timestep Consumption Time: 1.18519
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.77157
Cumulative Model Updates: 3,844
Cumulative Timesteps: 64,183,632
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.99303
Policy Entropy: 5.52101
Value Function Loss: 0.03116
Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01325
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.05248
Collected Steps per Second: 11,141.82348
Overall Steps per Second: 8,778.49174
Timestep Collection Time: 4.49334
Timestep Consumption Time: 1.20969
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.70303
Cumulative Model Updates: 3,847
Cumulative Timesteps: 64,233,696
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
Saving checkpoint 64233696...
Checkpoint 64233696 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90054
Policy Entropy: 5.51882
Value Function Loss: 0.03507
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02339
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.06013
Collected Steps per Second: 10,901.95931
Overall Steps per Second: 8,638.16465
Timestep Collection Time: 4.59165
Timestep Consumption Time: 1.20333
PPO Batch Consumption Time: 0.05029
Total Iteration Time: 5.79498
Cumulative Model Updates: 3,850
Cumulative Timesteps: 64,283,754
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.71208
Policy Entropy: 5.51578
Value Function Loss: 0.03623
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.06367
Collected Steps per Second: 10,878.61924
Overall Steps per Second: 8,783.60150
Timestep Collection Time: 4.59764
Timestep Consumption Time: 1.09661
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 5.69425
Cumulative Model Updates: 3,853
Cumulative Timesteps: 64,333,770
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 64333770...
Checkpoint 64333770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.15993
Policy Entropy: 5.51430
Value Function Loss: 0.03520
Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01323
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.06208
Collected Steps per Second: 10,869.41127
Overall Steps per Second: 8,573.47978
Timestep Collection Time: 4.60338
Timestep Consumption Time: 1.23276
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.83614
Cumulative Model Updates: 3,856
Cumulative Timesteps: 64,383,806
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.67587
Policy Entropy: 5.50065
Value Function Loss: 0.03282
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01664
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.05959
Collected Steps per Second: 10,892.56392
Overall Steps per Second: 8,678.27686
Timestep Collection Time: 4.59506
Timestep Consumption Time: 1.17244
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.76750
Cumulative Model Updates: 3,859
Cumulative Timesteps: 64,433,858
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 64433858...
Checkpoint 64433858 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.81013
Policy Entropy: 5.54567
Value Function Loss: 0.03144
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02201
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.05335
Collected Steps per Second: 10,879.64412
Overall Steps per Second: 8,776.45149
Timestep Collection Time: 4.60033
Timestep Consumption Time: 1.10243
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.70276
Cumulative Model Updates: 3,862
Cumulative Timesteps: 64,483,908
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55591
Policy Entropy: 5.53855
Value Function Loss: 0.03726
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02470
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.04879
Collected Steps per Second: 10,850.70974
Overall Steps per Second: 8,529.12423
Timestep Collection Time: 4.61168
Timestep Consumption Time: 1.25528
PPO Batch Consumption Time: 0.07134
Total Iteration Time: 5.86696
Cumulative Model Updates: 3,865
Cumulative Timesteps: 64,533,948
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 64533948...
Checkpoint 64533948 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.43802
Policy Entropy: 5.54529
Value Function Loss: 0.03611
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02064
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.05239
Collected Steps per Second: 10,913.83069
Overall Steps per Second: 8,826.73833
Timestep Collection Time: 4.58226
Timestep Consumption Time: 1.08348
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.66574
Cumulative Model Updates: 3,868
Cumulative Timesteps: 64,583,958
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.39175
Policy Entropy: 5.54000
Value Function Loss: 0.03809
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.05281
Collected Steps per Second: 10,895.84654
Overall Steps per Second: 8,620.87268
Timestep Collection Time: 4.59129
Timestep Consumption Time: 1.21160
PPO Batch Consumption Time: 0.05201
Total Iteration Time: 5.80289
Cumulative Model Updates: 3,871
Cumulative Timesteps: 64,633,984
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 64633984...
Checkpoint 64633984 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86709
Policy Entropy: 5.52739
Value Function Loss: 0.03593
Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01379
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.05042
Collected Steps per Second: 10,899.12174
Overall Steps per Second: 8,670.51888
Timestep Collection Time: 4.58789
Timestep Consumption Time: 1.17924
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.76713
Cumulative Model Updates: 3,874
Cumulative Timesteps: 64,683,988
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57927
Policy Entropy: 5.52716
Value Function Loss: 0.03861
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01439
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.05134
Collected Steps per Second: 10,797.12555
Overall Steps per Second: 8,768.80235
Timestep Collection Time: 4.63438
Timestep Consumption Time: 1.07198
PPO Batch Consumption Time: 0.05087
Total Iteration Time: 5.70637
Cumulative Model Updates: 3,877
Cumulative Timesteps: 64,734,026
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 64734026...
Checkpoint 64734026 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59463
Policy Entropy: 5.52646
Value Function Loss: 0.03678
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.01658
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.05749
Collected Steps per Second: 10,846.65801
Overall Steps per Second: 8,590.81631
Timestep Collection Time: 4.61303
Timestep Consumption Time: 1.21133
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.82436
Cumulative Model Updates: 3,880
Cumulative Timesteps: 64,784,062
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.95443
Policy Entropy: 5.55267
Value Function Loss: 0.03483
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01456
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.05741
Collected Steps per Second: 10,932.22666
Overall Steps per Second: 8,706.11886
Timestep Collection Time: 4.57656
Timestep Consumption Time: 1.17020
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.74676
Cumulative Model Updates: 3,883
Cumulative Timesteps: 64,834,094
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 64834094...
Checkpoint 64834094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.15433
Policy Entropy: 5.53665
Value Function Loss: 0.03569
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01505
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.05557
Collected Steps per Second: 11,082.02679
Overall Steps per Second: 8,754.03839
Timestep Collection Time: 4.51614
Timestep Consumption Time: 1.20099
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.71713
Cumulative Model Updates: 3,886
Cumulative Timesteps: 64,884,142
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.76840
Policy Entropy: 5.56488
Value Function Loss: 0.03250
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.05415
Collected Steps per Second: 10,829.92980
Overall Steps per Second: 8,428.53467
Timestep Collection Time: 4.61961
Timestep Consumption Time: 1.31618
PPO Batch Consumption Time: 0.08100
Total Iteration Time: 5.93579
Cumulative Model Updates: 3,889
Cumulative Timesteps: 64,934,172
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 64934172...
Checkpoint 64934172 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61702
Policy Entropy: 5.58051
Value Function Loss: 0.03429
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.05717
Collected Steps per Second: 10,866.05674
Overall Steps per Second: 8,640.87358
Timestep Collection Time: 4.60314
Timestep Consumption Time: 1.18539
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 5.78854
Cumulative Model Updates: 3,892
Cumulative Timesteps: 64,984,190
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78645
Policy Entropy: 5.59701
Value Function Loss: 0.03350
Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01369
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.05059
Collected Steps per Second: 11,093.73224
Overall Steps per Second: 8,744.76051
Timestep Collection Time: 4.50975
Timestep Consumption Time: 1.21139
PPO Batch Consumption Time: 0.05004
Total Iteration Time: 5.72114
Cumulative Model Updates: 3,895
Cumulative Timesteps: 65,034,220
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 65034220...
Checkpoint 65034220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79746
Policy Entropy: 5.60136
Value Function Loss: 0.03264
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02013
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.05376
Collected Steps per Second: 10,890.06139
Overall Steps per Second: 8,623.50898
Timestep Collection Time: 4.59153
Timestep Consumption Time: 1.20681
PPO Batch Consumption Time: 0.05054
Total Iteration Time: 5.79834
Cumulative Model Updates: 3,898
Cumulative Timesteps: 65,084,222
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.77865
Policy Entropy: 5.60882
Value Function Loss: 0.02711
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02038
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.05626
Collected Steps per Second: 10,880.52289
Overall Steps per Second: 8,765.21659
Timestep Collection Time: 4.59684
Timestep Consumption Time: 1.10935
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.70619
Cumulative Model Updates: 3,901
Cumulative Timesteps: 65,134,238
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 65134238...
Checkpoint 65134238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09467
Policy Entropy: 5.59957
Value Function Loss: 0.02853
Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.00902
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.05340
Collected Steps per Second: 10,829.06210
Overall Steps per Second: 8,584.86052
Timestep Collection Time: 4.61924
Timestep Consumption Time: 1.20753
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.82677
Cumulative Model Updates: 3,904
Cumulative Timesteps: 65,184,260
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.15699
Policy Entropy: 5.61937
Value Function Loss: 0.03067
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01959
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.04769
Collected Steps per Second: 10,972.43862
Overall Steps per Second: 8,748.23614
Timestep Collection Time: 4.55942
Timestep Consumption Time: 1.15921
PPO Batch Consumption Time: 0.04934
Total Iteration Time: 5.71864
Cumulative Model Updates: 3,907
Cumulative Timesteps: 65,234,288
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 65234288...
Checkpoint 65234288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.72927
Policy Entropy: 5.61685
Value Function Loss: 0.03398
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02689
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.04350
Collected Steps per Second: 10,841.98807
Overall Steps per Second: 8,741.26790
Timestep Collection Time: 4.61594
Timestep Consumption Time: 1.10931
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.72526
Cumulative Model Updates: 3,910
Cumulative Timesteps: 65,284,334
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.52821
Policy Entropy: 5.57259
Value Function Loss: 0.03447
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02131
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.04363
Collected Steps per Second: 10,865.41525
Overall Steps per Second: 8,505.92759
Timestep Collection Time: 4.60323
Timestep Consumption Time: 1.27691
PPO Batch Consumption Time: 0.07200
Total Iteration Time: 5.88013
Cumulative Model Updates: 3,913
Cumulative Timesteps: 65,334,350
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 65334350...
Checkpoint 65334350 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70596
Policy Entropy: 5.58493
Value Function Loss: 0.03166
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01408
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.04465
Collected Steps per Second: 10,876.55387
Overall Steps per Second: 8,660.39188
Timestep Collection Time: 4.59907
Timestep Consumption Time: 1.17688
PPO Batch Consumption Time: 0.05252
Total Iteration Time: 5.77595
Cumulative Model Updates: 3,916
Cumulative Timesteps: 65,384,372
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61457
Policy Entropy: 5.61187
Value Function Loss: 0.02986
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.04823
Collected Steps per Second: 11,021.80013
Overall Steps per Second: 8,705.01127
Timestep Collection Time: 4.53973
Timestep Consumption Time: 1.20822
PPO Batch Consumption Time: 0.05153
Total Iteration Time: 5.74795
Cumulative Model Updates: 3,919
Cumulative Timesteps: 65,434,408
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 65434408...
Checkpoint 65434408 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.23869
Policy Entropy: 5.58226
Value Function Loss: 0.03450
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02896
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.05173
Collected Steps per Second: 10,926.99066
Overall Steps per Second: 8,649.15341
Timestep Collection Time: 4.57930
Timestep Consumption Time: 1.20600
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.78531
Cumulative Model Updates: 3,922
Cumulative Timesteps: 65,484,446
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.93838
Policy Entropy: 5.60915
Value Function Loss: 0.03982
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01598
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.05231
Collected Steps per Second: 10,867.38837
Overall Steps per Second: 8,776.26850
Timestep Collection Time: 4.60129
Timestep Consumption Time: 1.09635
PPO Batch Consumption Time: 0.04975
Total Iteration Time: 5.69764
Cumulative Model Updates: 3,925
Cumulative Timesteps: 65,534,450
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 65534450...
Checkpoint 65534450 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.00703
Policy Entropy: 5.59231
Value Function Loss: 0.03832
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01926
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.05290
Collected Steps per Second: 10,893.37623
Overall Steps per Second: 8,628.90815
Timestep Collection Time: 4.59050
Timestep Consumption Time: 1.20468
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.79517
Cumulative Model Updates: 3,928
Cumulative Timesteps: 65,584,456
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.49000
Policy Entropy: 5.60302
Value Function Loss: 0.03353
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03347
Policy Update Magnitude: 0.06453
Value Function Update Magnitude: 0.06019
Collected Steps per Second: 10,935.44088
Overall Steps per Second: 8,730.39262
Timestep Collection Time: 4.57576
Timestep Consumption Time: 1.15571
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.73147
Cumulative Model Updates: 3,931
Cumulative Timesteps: 65,634,494
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 65634494...
Checkpoint 65634494 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87387
Policy Entropy: 5.63525
Value Function Loss: 0.03135
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03286
Policy Update Magnitude: 0.06593
Value Function Update Magnitude: 0.06062
Collected Steps per Second: 10,827.79066
Overall Steps per Second: 8,755.22677
Timestep Collection Time: 4.61959
Timestep Consumption Time: 1.09356
PPO Batch Consumption Time: 0.05004
Total Iteration Time: 5.71316
Cumulative Model Updates: 3,934
Cumulative Timesteps: 65,684,514
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03506
Policy Entropy: 5.60308
Value Function Loss: 0.03679
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02085
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.06118
Collected Steps per Second: 10,870.01222
Overall Steps per Second: 8,476.99076
Timestep Collection Time: 4.60312
Timestep Consumption Time: 1.29944
PPO Batch Consumption Time: 0.08233
Total Iteration Time: 5.90257
Cumulative Model Updates: 3,937
Cumulative Timesteps: 65,734,550
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 65734550...
Checkpoint 65734550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98063
Policy Entropy: 5.58729
Value Function Loss: 0.03950
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01421
Policy Update Magnitude: 0.06076
Value Function Update Magnitude: 0.06223
Collected Steps per Second: 10,928.17956
Overall Steps per Second: 8,661.90113
Timestep Collection Time: 4.57734
Timestep Consumption Time: 1.19760
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.77494
Cumulative Model Updates: 3,940
Cumulative Timesteps: 65,784,572
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.16420
Policy Entropy: 5.57412
Value Function Loss: 0.04371
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02209
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.05935
Collected Steps per Second: 10,855.88158
Overall Steps per Second: 8,650.72819
Timestep Collection Time: 4.60746
Timestep Consumption Time: 1.17448
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.78194
Cumulative Model Updates: 3,943
Cumulative Timesteps: 65,834,590
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 65834590...
Checkpoint 65834590 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86614
Policy Entropy: 5.55770
Value Function Loss: 0.04527
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02182
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.05975
Collected Steps per Second: 10,864.06099
Overall Steps per Second: 8,594.84994
Timestep Collection Time: 4.60417
Timestep Consumption Time: 1.21559
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.81976
Cumulative Model Updates: 3,946
Cumulative Timesteps: 65,884,610
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90055
Policy Entropy: 5.55460
Value Function Loss: 0.04486
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.06061
Collected Steps per Second: 10,818.59124
Overall Steps per Second: 8,643.53588
Timestep Collection Time: 4.62574
Timestep Consumption Time: 1.16402
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.78976
Cumulative Model Updates: 3,949
Cumulative Timesteps: 65,934,654
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 65934654...
Checkpoint 65934654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.30977
Policy Entropy: 5.61040
Value Function Loss: 0.03794
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03497
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.05993
Collected Steps per Second: 11,008.74081
Overall Steps per Second: 8,707.65748
Timestep Collection Time: 4.54330
Timestep Consumption Time: 1.20061
PPO Batch Consumption Time: 0.04992
Total Iteration Time: 5.74391
Cumulative Model Updates: 3,952
Cumulative Timesteps: 65,984,670
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88700
Policy Entropy: 5.59036
Value Function Loss: 0.03569
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02055
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.05666
Collected Steps per Second: 10,879.82333
Overall Steps per Second: 8,642.29581
Timestep Collection Time: 4.59732
Timestep Consumption Time: 1.19027
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.78758
Cumulative Model Updates: 3,955
Cumulative Timesteps: 66,034,688
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 66034688...
Checkpoint 66034688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.25530
Policy Entropy: 5.57630
Value Function Loss: 0.03507
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.05718
Collected Steps per Second: 10,818.92737
Overall Steps per Second: 8,730.89016
Timestep Collection Time: 4.62172
Timestep Consumption Time: 1.10531
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.72702
Cumulative Model Updates: 3,958
Cumulative Timesteps: 66,084,690
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.19414
Policy Entropy: 5.58012
Value Function Loss: 0.03413
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03791
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.05646
Collected Steps per Second: 10,873.98337
Overall Steps per Second: 8,540.24523
Timestep Collection Time: 4.59960
Timestep Consumption Time: 1.25690
PPO Batch Consumption Time: 0.07414
Total Iteration Time: 5.85651
Cumulative Model Updates: 3,961
Cumulative Timesteps: 66,134,706
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 66134706...
Checkpoint 66134706 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.02202
Policy Entropy: 5.58467
Value Function Loss: 0.03070
Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04271
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.05526
Collected Steps per Second: 10,828.67631
Overall Steps per Second: 8,659.61655
Timestep Collection Time: 4.61829
Timestep Consumption Time: 1.15679
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.77508
Cumulative Model Updates: 3,964
Cumulative Timesteps: 66,184,716
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59159
Policy Entropy: 5.59191
Value Function Loss: 0.02646
Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03555
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.04763
Collected Steps per Second: 11,037.13386
Overall Steps per Second: 8,769.95269
Timestep Collection Time: 4.53288
Timestep Consumption Time: 1.17183
PPO Batch Consumption Time: 0.05152
Total Iteration Time: 5.70471
Cumulative Model Updates: 3,967
Cumulative Timesteps: 66,234,746
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 66234746...
Checkpoint 66234746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.91420
Policy Entropy: 5.60802
Value Function Loss: 0.02856
Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04563
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.04573
Collected Steps per Second: 11,006.55788
Overall Steps per Second: 8,694.47085
Timestep Collection Time: 4.54475
Timestep Consumption Time: 1.20857
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.75331
Cumulative Model Updates: 3,970
Cumulative Timesteps: 66,284,768
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.45045
Policy Entropy: 5.59891
Value Function Loss: 0.02872
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.05229
Collected Steps per Second: 10,893.94414
Overall Steps per Second: 8,679.81433
Timestep Collection Time: 4.59173
Timestep Consumption Time: 1.17130
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.76303
Cumulative Model Updates: 3,973
Cumulative Timesteps: 66,334,790
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 66334790...
Checkpoint 66334790 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.21056
Policy Entropy: 5.59319
Value Function Loss: 0.03568
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02051
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.05761
Collected Steps per Second: 11,092.41973
Overall Steps per Second: 8,768.71681
Timestep Collection Time: 4.50957
Timestep Consumption Time: 1.19503
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.70460
Cumulative Model Updates: 3,976
Cumulative Timesteps: 66,384,812
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.08014
Policy Entropy: 5.58978
Value Function Loss: 0.03673
Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.03721
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.06152
Collected Steps per Second: 10,886.71242
Overall Steps per Second: 8,626.24171
Timestep Collection Time: 4.59753
Timestep Consumption Time: 1.20476
PPO Batch Consumption Time: 0.05010
Total Iteration Time: 5.80230
Cumulative Model Updates: 3,979
Cumulative Timesteps: 66,434,864
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 66434864...
Checkpoint 66434864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.59937
Policy Entropy: 5.56440
Value Function Loss: 0.04279
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.06721
Collected Steps per Second: 10,818.91183
Overall Steps per Second: 8,753.87770
Timestep Collection Time: 4.62191
Timestep Consumption Time: 1.09030
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.71221
Cumulative Model Updates: 3,982
Cumulative Timesteps: 66,484,868
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.18395
Policy Entropy: 5.56936
Value Function Loss: 0.04059
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02251
Policy Update Magnitude: 0.06335
Value Function Update Magnitude: 0.06962
Collected Steps per Second: 11,001.48209
Overall Steps per Second: 8,576.15350
Timestep Collection Time: 4.54757
Timestep Consumption Time: 1.28605
PPO Batch Consumption Time: 0.07367
Total Iteration Time: 5.83362
Cumulative Model Updates: 3,985
Cumulative Timesteps: 66,534,898
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 66534898...
Checkpoint 66534898 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.40819
Policy Entropy: 5.58076
Value Function Loss: 0.04193
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.07106
Collected Steps per Second: 10,992.77635
Overall Steps per Second: 8,726.67513
Timestep Collection Time: 4.55044
Timestep Consumption Time: 1.18164
PPO Batch Consumption Time: 0.05348
Total Iteration Time: 5.73208
Cumulative Model Updates: 3,988
Cumulative Timesteps: 66,584,920
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98066
Policy Entropy: 5.57705
Value Function Loss: 0.03951
Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03445
Policy Update Magnitude: 0.06715
Value Function Update Magnitude: 0.06637
Collected Steps per Second: 10,733.97271
Overall Steps per Second: 8,675.84229
Timestep Collection Time: 4.66109
Timestep Consumption Time: 1.10573
PPO Batch Consumption Time: 0.05040
Total Iteration Time: 5.76682
Cumulative Model Updates: 3,991
Cumulative Timesteps: 66,634,952
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 66634952...
Checkpoint 66634952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.19799
Policy Entropy: 5.58160
Value Function Loss: 0.03836
Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04326
Policy Update Magnitude: 0.06861
Value Function Update Magnitude: 0.06207
Collected Steps per Second: 10,890.82387
Overall Steps per Second: 8,588.54540
Timestep Collection Time: 4.59102
Timestep Consumption Time: 1.23069
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.82171
Cumulative Model Updates: 3,994
Cumulative Timesteps: 66,684,952
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03600
Policy Entropy: 5.57525
Value Function Loss: 0.03684
Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05326
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.06151
Collected Steps per Second: 10,840.13096
Overall Steps per Second: 8,636.26605
Timestep Collection Time: 4.61249
Timestep Consumption Time: 1.17705
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.78954
Cumulative Model Updates: 3,997
Cumulative Timesteps: 66,734,952
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 66734952...
Checkpoint 66734952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.62331
Policy Entropy: 5.54846
Value Function Loss: 0.03693
Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04359
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.06110
Collected Steps per Second: 11,120.02424
Overall Steps per Second: 8,758.86937
Timestep Collection Time: 4.49711
Timestep Consumption Time: 1.21230
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.70941
Cumulative Model Updates: 4,000
Cumulative Timesteps: 66,784,960
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.72800
Policy Entropy: 5.51722
Value Function Loss: 0.04313
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03492
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.05328
Collected Steps per Second: 10,932.48327
Overall Steps per Second: 8,650.42930
Timestep Collection Time: 4.57700
Timestep Consumption Time: 1.20745
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.78445
Cumulative Model Updates: 4,003
Cumulative Timesteps: 66,834,998
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 66834998...
Checkpoint 66834998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.69928
Policy Entropy: 5.52180
Value Function Loss: 0.04346
Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04629
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.06068
Collected Steps per Second: 10,872.74535
Overall Steps per Second: 8,662.33331
Timestep Collection Time: 4.60160
Timestep Consumption Time: 1.17421
PPO Batch Consumption Time: 0.05020
Total Iteration Time: 5.77581
Cumulative Model Updates: 4,006
Cumulative Timesteps: 66,885,030
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.76642
Policy Entropy: 5.57770
Value Function Loss: 0.03762
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.06286
Collected Steps per Second: 10,919.26264
Overall Steps per Second: 8,539.25640
Timestep Collection Time: 4.57943
Timestep Consumption Time: 1.27635
PPO Batch Consumption Time: 0.07808
Total Iteration Time: 5.85578
Cumulative Model Updates: 4,009
Cumulative Timesteps: 66,935,034
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 66935034...
Checkpoint 66935034 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.83674
Policy Entropy: 5.60148
Value Function Loss: 0.03319
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.05674
Collected Steps per Second: 10,860.01366
Overall Steps per Second: 8,598.08595
Timestep Collection Time: 4.60681
Timestep Consumption Time: 1.21193
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.81874
Cumulative Model Updates: 4,012
Cumulative Timesteps: 66,985,064
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.40521
Policy Entropy: 5.57449
Value Function Loss: 0.03842
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02989
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.05518
Collected Steps per Second: 10,916.72093
Overall Steps per Second: 8,778.26748
Timestep Collection Time: 4.58343
Timestep Consumption Time: 1.11656
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.69999
Cumulative Model Updates: 4,015
Cumulative Timesteps: 67,035,100
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 67035100...
Checkpoint 67035100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.28802
Policy Entropy: 5.55734
Value Function Loss: 0.03988
Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03977
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.04570
Collected Steps per Second: 10,958.77757
Overall Steps per Second: 8,653.17316
Timestep Collection Time: 4.56420
Timestep Consumption Time: 1.21611
PPO Batch Consumption Time: 0.04934
Total Iteration Time: 5.78031
Cumulative Model Updates: 4,018
Cumulative Timesteps: 67,085,118
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84268
Policy Entropy: 5.58191
Value Function Loss: 0.03795
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03265
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.04555
Collected Steps per Second: 10,774.42818
Overall Steps per Second: 8,609.18271
Timestep Collection Time: 4.64210
Timestep Consumption Time: 1.16751
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.80961
Cumulative Model Updates: 4,021
Cumulative Timesteps: 67,135,134
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 67135134...
Checkpoint 67135134 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.54362
Policy Entropy: 5.57162
Value Function Loss: 0.03360
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03729
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.04479
Collected Steps per Second: 11,117.92712
Overall Steps per Second: 8,771.09939
Timestep Collection Time: 4.50084
Timestep Consumption Time: 1.20426
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.70510
Cumulative Model Updates: 4,024
Cumulative Timesteps: 67,185,174
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80020
Policy Entropy: 5.58539
Value Function Loss: 0.03516
Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03669
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.05019
Collected Steps per Second: 10,816.73014
Overall Steps per Second: 8,574.18445
Timestep Collection Time: 4.62561
Timestep Consumption Time: 1.20981
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.83542
Cumulative Model Updates: 4,027
Cumulative Timesteps: 67,235,208
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 67235208...
Checkpoint 67235208 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82167
Policy Entropy: 5.58739
Value Function Loss: 0.04330
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.05165
Collected Steps per Second: 10,897.43361
Overall Steps per Second: 8,625.76198
Timestep Collection Time: 4.59099
Timestep Consumption Time: 1.20908
PPO Batch Consumption Time: 0.05136
Total Iteration Time: 5.80007
Cumulative Model Updates: 4,030
Cumulative Timesteps: 67,285,238
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82298
Policy Entropy: 5.55780
Value Function Loss: 0.04469
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.05297
Collected Steps per Second: 11,121.58997
Overall Steps per Second: 8,651.78670
Timestep Collection Time: 4.49954
Timestep Consumption Time: 1.28447
PPO Batch Consumption Time: 0.08033
Total Iteration Time: 5.78401
Cumulative Model Updates: 4,033
Cumulative Timesteps: 67,335,280
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 67335280...
Checkpoint 67335280 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88698
Policy Entropy: 5.54226
Value Function Loss: 0.04430
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01809
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.05154
Collected Steps per Second: 10,893.20682
Overall Steps per Second: 8,587.76725
Timestep Collection Time: 4.59369
Timestep Consumption Time: 1.23320
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.82689
Cumulative Model Updates: 4,036
Cumulative Timesteps: 67,385,320
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61434
Policy Entropy: 5.55847
Value Function Loss: 0.04463
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.05075
Collected Steps per Second: 10,913.56370
Overall Steps per Second: 8,809.98875
Timestep Collection Time: 4.58457
Timestep Consumption Time: 1.09467
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.67924
Cumulative Model Updates: 4,039
Cumulative Timesteps: 67,435,354
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 67435354...
Checkpoint 67435354 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.33329
Policy Entropy: 5.55468
Value Function Loss: 0.04509
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01858
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.04749
Collected Steps per Second: 10,809.68863
Overall Steps per Second: 8,565.57637
Timestep Collection Time: 4.62807
Timestep Consumption Time: 1.21252
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.84059
Cumulative Model Updates: 4,042
Cumulative Timesteps: 67,485,382
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.62383
Policy Entropy: 5.54818
Value Function Loss: 0.04193
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01747
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.05118
Collected Steps per Second: 10,762.06422
Overall Steps per Second: 8,599.64219
Timestep Collection Time: 4.64762
Timestep Consumption Time: 1.16867
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.81629
Cumulative Model Updates: 4,045
Cumulative Timesteps: 67,535,400
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 67535400...
Checkpoint 67535400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.85074
Policy Entropy: 5.56706
Value Function Loss: 0.03537
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01605
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.05761
Collected Steps per Second: 10,983.64550
Overall Steps per Second: 8,845.69978
Timestep Collection Time: 4.55823
Timestep Consumption Time: 1.10169
PPO Batch Consumption Time: 0.04936
Total Iteration Time: 5.65993
Cumulative Model Updates: 4,048
Cumulative Timesteps: 67,585,466
Timesteps Collected: 50,066
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.57961
Policy Entropy: 5.57074
Value Function Loss: 0.03109
Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.00631
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.06254
Collected Steps per Second: 10,941.18908
Overall Steps per Second: 8,646.01102
Timestep Collection Time: 4.57007
Timestep Consumption Time: 1.21317
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.78325
Cumulative Model Updates: 4,051
Cumulative Timesteps: 67,635,468
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 67635468...
Checkpoint 67635468 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.92671
Policy Entropy: 5.54111
Value Function Loss: 0.03027
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01297
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.06156
Collected Steps per Second: 10,919.30988
Overall Steps per Second: 8,657.22391
Timestep Collection Time: 4.58271
Timestep Consumption Time: 1.19744
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.78014
Cumulative Model Updates: 4,054
Cumulative Timesteps: 67,685,508
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82937
Policy Entropy: 5.55395
Value Function Loss: 0.03299
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.05815
Collected Steps per Second: 11,056.55329
Overall Steps per Second: 8,599.50360
Timestep Collection Time: 4.52600
Timestep Consumption Time: 1.29317
PPO Batch Consumption Time: 0.08178
Total Iteration Time: 5.81917
Cumulative Model Updates: 4,057
Cumulative Timesteps: 67,735,550
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 67735550...
Checkpoint 67735550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.00204
Policy Entropy: 5.53556
Value Function Loss: 0.03485
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01232
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.05912
Collected Steps per Second: 10,932.10350
Overall Steps per Second: 8,634.92433
Timestep Collection Time: 4.57369
Timestep Consumption Time: 1.21675
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.79044
Cumulative Model Updates: 4,060
Cumulative Timesteps: 67,785,550
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90695
Policy Entropy: 5.54378
Value Function Loss: 0.03511
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03179
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.06201
Collected Steps per Second: 10,754.01326
Overall Steps per Second: 8,668.51718
Timestep Collection Time: 4.65054
Timestep Consumption Time: 1.11884
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.76938
Cumulative Model Updates: 4,063
Cumulative Timesteps: 67,835,562
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 67835562...
Checkpoint 67835562 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.97345
Policy Entropy: 5.59212
Value Function Loss: 0.02890
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01746
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.05264
Collected Steps per Second: 10,925.41659
Overall Steps per Second: 8,644.75423
Timestep Collection Time: 4.57978
Timestep Consumption Time: 1.20824
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78802
Cumulative Model Updates: 4,066
Cumulative Timesteps: 67,885,598
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82770
Policy Entropy: 5.58071
Value Function Loss: 0.03320
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01926
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.05289
Collected Steps per Second: 10,655.40022
Overall Steps per Second: 8,542.86134
Timestep Collection Time: 4.69339
Timestep Consumption Time: 1.16062
PPO Batch Consumption Time: 0.04902
Total Iteration Time: 5.85401
Cumulative Model Updates: 4,069
Cumulative Timesteps: 67,935,608
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 67935608...
Checkpoint 67935608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.43680
Policy Entropy: 5.57501
Value Function Loss: 0.03734
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03273
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.06636
Collected Steps per Second: 10,833.74474
Overall Steps per Second: 8,746.34248
Timestep Collection Time: 4.61632
Timestep Consumption Time: 1.10173
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.71805
Cumulative Model Updates: 4,072
Cumulative Timesteps: 67,985,620
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.51036
Policy Entropy: 5.55846
Value Function Loss: 0.04209
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.06959
Collected Steps per Second: 10,879.41976
Overall Steps per Second: 8,580.27859
Timestep Collection Time: 4.59620
Timestep Consumption Time: 1.23158
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.82778
Cumulative Model Updates: 4,075
Cumulative Timesteps: 68,035,624
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 68035624...
Checkpoint 68035624 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.21582
Policy Entropy: 5.54172
Value Function Loss: 0.03810
Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01015
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.06990
Collected Steps per Second: 10,902.43800
Overall Steps per Second: 8,681.36252
Timestep Collection Time: 4.58943
Timestep Consumption Time: 1.17418
PPO Batch Consumption Time: 0.05065
Total Iteration Time: 5.76361
Cumulative Model Updates: 4,078
Cumulative Timesteps: 68,085,660
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.80235
Policy Entropy: 5.55646
Value Function Loss: 0.03621
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01920
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.06648
Collected Steps per Second: 11,047.71650
Overall Steps per Second: 8,664.81100
Timestep Collection Time: 4.53053
Timestep Consumption Time: 1.24594
PPO Batch Consumption Time: 0.07033
Total Iteration Time: 5.77647
Cumulative Model Updates: 4,081
Cumulative Timesteps: 68,135,712
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 68135712...
Checkpoint 68135712 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74567
Policy Entropy: 5.59445
Value Function Loss: 0.03542
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.05698
Collected Steps per Second: 10,928.05610
Overall Steps per Second: 8,621.26556
Timestep Collection Time: 4.57721
Timestep Consumption Time: 1.22472
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.80193
Cumulative Model Updates: 4,084
Cumulative Timesteps: 68,185,732
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.08262
Policy Entropy: 5.59328
Value Function Loss: 0.03454
Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.05431
Collected Steps per Second: 10,838.15326
Overall Steps per Second: 8,641.65078
Timestep Collection Time: 4.61352
Timestep Consumption Time: 1.17265
PPO Batch Consumption Time: 0.05201
Total Iteration Time: 5.78616
Cumulative Model Updates: 4,087
Cumulative Timesteps: 68,235,734
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 68235734...
Checkpoint 68235734 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.50423
Policy Entropy: 5.58478
Value Function Loss: 0.03401
Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01356
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.05786
Collected Steps per Second: 11,071.28729
Overall Steps per Second: 8,710.71279
Timestep Collection Time: 4.51709
Timestep Consumption Time: 1.22412
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.74121
Cumulative Model Updates: 4,090
Cumulative Timesteps: 68,285,744
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75597
Policy Entropy: 5.57966
Value Function Loss: 0.03704
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01661
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.06272
Collected Steps per Second: 10,899.73818
Overall Steps per Second: 8,632.84719
Timestep Collection Time: 4.59020
Timestep Consumption Time: 1.20534
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.79554
Cumulative Model Updates: 4,093
Cumulative Timesteps: 68,335,776
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 68335776...
Checkpoint 68335776 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89910
Policy Entropy: 5.57178
Value Function Loss: 0.03914
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03003
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.06004
Collected Steps per Second: 10,898.26180
Overall Steps per Second: 8,788.80890
Timestep Collection Time: 4.58807
Timestep Consumption Time: 1.10121
PPO Batch Consumption Time: 0.04971
Total Iteration Time: 5.68928
Cumulative Model Updates: 4,096
Cumulative Timesteps: 68,385,778
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.05385
Policy Entropy: 5.58715
Value Function Loss: 0.03995
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01713
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.05844
Collected Steps per Second: 10,906.08420
Overall Steps per Second: 8,646.70222
Timestep Collection Time: 4.58478
Timestep Consumption Time: 1.19800
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.78278
Cumulative Model Updates: 4,099
Cumulative Timesteps: 68,435,780
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 68435780...
Checkpoint 68435780 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.41558
Policy Entropy: 5.58062
Value Function Loss: 0.03744
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01784
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.05989
Collected Steps per Second: 10,713.45738
Overall Steps per Second: 8,580.24338
Timestep Collection Time: 4.67076
Timestep Consumption Time: 1.16124
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.83200
Cumulative Model Updates: 4,102
Cumulative Timesteps: 68,485,820
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09141
Policy Entropy: 5.57981
Value Function Loss: 0.03799
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02408
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.06171
Collected Steps per Second: 10,899.04203
Overall Steps per Second: 8,660.45927
Timestep Collection Time: 4.59141
Timestep Consumption Time: 1.18680
PPO Batch Consumption Time: 0.08042
Total Iteration Time: 5.77822
Cumulative Model Updates: 4,105
Cumulative Timesteps: 68,535,862
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 68535862...
Checkpoint 68535862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.13401
Policy Entropy: 5.56672
Value Function Loss: 0.03533
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.06240
Collected Steps per Second: 10,845.36625
Overall Steps per Second: 8,620.88263
Timestep Collection Time: 4.61285
Timestep Consumption Time: 1.19027
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.80312
Cumulative Model Updates: 4,108
Cumulative Timesteps: 68,585,890
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.23861
Policy Entropy: 5.56406
Value Function Loss: 0.03404
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.06438
Collected Steps per Second: 10,805.55667
Overall Steps per Second: 8,667.28066
Timestep Collection Time: 4.62873
Timestep Consumption Time: 1.14194
PPO Batch Consumption Time: 0.05008
Total Iteration Time: 5.77067
Cumulative Model Updates: 4,111
Cumulative Timesteps: 68,635,906
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 68635906...
Checkpoint 68635906 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.21678
Policy Entropy: 5.54346
Value Function Loss: 0.03354
Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03675
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.06432
Collected Steps per Second: 11,066.50725
Overall Steps per Second: 8,753.27480
Timestep Collection Time: 4.51904
Timestep Consumption Time: 1.19425
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.71329
Cumulative Model Updates: 4,114
Cumulative Timesteps: 68,685,916
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78801
Policy Entropy: 5.56390
Value Function Loss: 0.03799
Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.04770
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.05872
Collected Steps per Second: 10,859.76041
Overall Steps per Second: 8,612.94252
Timestep Collection Time: 4.60710
Timestep Consumption Time: 1.20183
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.80893
Cumulative Model Updates: 4,117
Cumulative Timesteps: 68,735,948
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 68735948...
Checkpoint 68735948 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86950
Policy Entropy: 5.54924
Value Function Loss: 0.04459
Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04581
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.05764
Collected Steps per Second: 10,679.04187
Overall Steps per Second: 8,696.64725
Timestep Collection Time: 4.68619
Timestep Consumption Time: 1.06821
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 5.75440
Cumulative Model Updates: 4,120
Cumulative Timesteps: 68,785,992
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.45005
Policy Entropy: 5.53228
Value Function Loss: 0.05156
Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05475
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.06290
Collected Steps per Second: 10,870.18530
Overall Steps per Second: 8,604.16285
Timestep Collection Time: 4.60139
Timestep Consumption Time: 1.21184
PPO Batch Consumption Time: 0.05005
Total Iteration Time: 5.81323
Cumulative Model Updates: 4,123
Cumulative Timesteps: 68,836,010
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 68836010...
Checkpoint 68836010 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.05328
Policy Entropy: 5.56505
Value Function Loss: 0.04889
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03115
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.06088
Collected Steps per Second: 10,871.91469
Overall Steps per Second: 8,688.82977
Timestep Collection Time: 4.60048
Timestep Consumption Time: 1.15588
PPO Batch Consumption Time: 0.05042
Total Iteration Time: 5.75636
Cumulative Model Updates: 4,126
Cumulative Timesteps: 68,886,026
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.29852
Policy Entropy: 5.56592
Value Function Loss: 0.04094
Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04094
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.05518
Collected Steps per Second: 11,093.23134
Overall Steps per Second: 8,607.19231
Timestep Collection Time: 4.51050
Timestep Consumption Time: 1.30278
PPO Batch Consumption Time: 0.07833
Total Iteration Time: 5.81328
Cumulative Model Updates: 4,129
Cumulative Timesteps: 68,936,062
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 68936062...
Checkpoint 68936062 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09677
Policy Entropy: 5.57732
Value Function Loss: 0.04276
Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04170
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.05333
Collected Steps per Second: 10,925.96851
Overall Steps per Second: 8,633.27315
Timestep Collection Time: 4.57753
Timestep Consumption Time: 1.21563
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.79317
Cumulative Model Updates: 4,132
Cumulative Timesteps: 68,986,076
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.82686
Policy Entropy: 5.59717
Value Function Loss: 0.04421
Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.04495
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.05239
Collected Steps per Second: 10,836.40288
Overall Steps per Second: 8,642.10998
Timestep Collection Time: 4.61832
Timestep Consumption Time: 1.17262
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.79095
Cumulative Model Updates: 4,135
Cumulative Timesteps: 69,036,122
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 69036122...
Checkpoint 69036122 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.91638
Policy Entropy: 5.59271
Value Function Loss: 0.04463
Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04139
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.05433
Collected Steps per Second: 11,038.49202
Overall Steps per Second: 8,747.41625
Timestep Collection Time: 4.52979
Timestep Consumption Time: 1.18642
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.71620
Cumulative Model Updates: 4,138
Cumulative Timesteps: 69,086,124
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.94776
Policy Entropy: 5.59696
Value Function Loss: 0.04123
Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.04615
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.05181
Collected Steps per Second: 10,862.28266
Overall Steps per Second: 8,613.62899
Timestep Collection Time: 4.60511
Timestep Consumption Time: 1.20220
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.80731
Cumulative Model Updates: 4,141
Cumulative Timesteps: 69,136,146
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 69136146...
Checkpoint 69136146 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78803
Policy Entropy: 5.59884
Value Function Loss: 0.03950
Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04233
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.05347
Collected Steps per Second: 10,847.91491
Overall Steps per Second: 8,699.44407
Timestep Collection Time: 4.61084
Timestep Consumption Time: 1.13872
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 5.74956
Cumulative Model Updates: 4,144
Cumulative Timesteps: 69,186,164
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.13415
Policy Entropy: 5.60101
Value Function Loss: 0.04063
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02812
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.05321
Collected Steps per Second: 10,952.00894
Overall Steps per Second: 8,677.64483
Timestep Collection Time: 4.56829
Timestep Consumption Time: 1.19733
PPO Batch Consumption Time: 0.05131
Total Iteration Time: 5.76562
Cumulative Model Updates: 4,147
Cumulative Timesteps: 69,236,196
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 69236196...
Checkpoint 69236196 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.92760
Policy Entropy: 5.59485
Value Function Loss: 0.03653
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02136
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.05270
Collected Steps per Second: 10,743.60344
Overall Steps per Second: 8,603.14129
Timestep Collection Time: 4.65617
Timestep Consumption Time: 1.15845
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.81462
Cumulative Model Updates: 4,150
Cumulative Timesteps: 69,286,220
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.06655
Policy Entropy: 5.60227
Value Function Loss: 0.03495
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02877
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.05351
Collected Steps per Second: 10,855.73860
Overall Steps per Second: 8,635.02352
Timestep Collection Time: 4.60973
Timestep Consumption Time: 1.18551
PPO Batch Consumption Time: 0.08055
Total Iteration Time: 5.79524
Cumulative Model Updates: 4,153
Cumulative Timesteps: 69,336,262
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 69336262...
Checkpoint 69336262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.66157
Policy Entropy: 5.59788
Value Function Loss: 0.03378
Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01255
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.05391
Collected Steps per Second: 10,921.15135
Overall Steps per Second: 8,613.26754
Timestep Collection Time: 4.57845
Timestep Consumption Time: 1.22678
PPO Batch Consumption Time: 0.05253
Total Iteration Time: 5.80523
Cumulative Model Updates: 4,156
Cumulative Timesteps: 69,386,264
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84151
Policy Entropy: 5.58807
Value Function Loss: 0.03863
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.05556
Collected Steps per Second: 10,839.06477
Overall Steps per Second: 8,654.34519
Timestep Collection Time: 4.61387
Timestep Consumption Time: 1.16473
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.77860
Cumulative Model Updates: 4,159
Cumulative Timesteps: 69,436,274
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 69436274...
Checkpoint 69436274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04289
Policy Entropy: 5.57852
Value Function Loss: 0.03577
Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04659
Policy Update Magnitude: 0.06378
Value Function Update Magnitude: 0.05848
Collected Steps per Second: 11,166.03924
Overall Steps per Second: 8,796.56263
Timestep Collection Time: 4.47983
Timestep Consumption Time: 1.20671
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.68654
Cumulative Model Updates: 4,162
Cumulative Timesteps: 69,486,296
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.05201
Policy Entropy: 5.58455
Value Function Loss: 0.03843
Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04242
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.05983
Collected Steps per Second: 10,999.59846
Overall Steps per Second: 8,676.90837
Timestep Collection Time: 4.54653
Timestep Consumption Time: 1.21704
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.76357
Cumulative Model Updates: 4,165
Cumulative Timesteps: 69,536,306
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 69536306...
Checkpoint 69536306 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.10562
Policy Entropy: 5.63255
Value Function Loss: 0.03270
Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.05723
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.05959
Collected Steps per Second: 10,945.74813
Overall Steps per Second: 8,667.86497
Timestep Collection Time: 4.56999
Timestep Consumption Time: 1.20098
PPO Batch Consumption Time: 0.05064
Total Iteration Time: 5.77097
Cumulative Model Updates: 4,168
Cumulative Timesteps: 69,586,328
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64945
Policy Entropy: 5.61212
Value Function Loss: 0.03554
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 0.06126
Value Function Update Magnitude: 0.05720
Collected Steps per Second: 11,139.08899
Overall Steps per Second: 8,753.56222
Timestep Collection Time: 4.49049
Timestep Consumption Time: 1.22375
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.71425
Cumulative Model Updates: 4,171
Cumulative Timesteps: 69,636,348
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 69636348...
Checkpoint 69636348 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74519
Policy Entropy: 5.63869
Value Function Loss: 0.03091
Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05143
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.05278
Collected Steps per Second: 10,959.39457
Overall Steps per Second: 8,726.58050
Timestep Collection Time: 4.56266
Timestep Consumption Time: 1.16742
PPO Batch Consumption Time: 0.05103
Total Iteration Time: 5.73008
Cumulative Model Updates: 4,174
Cumulative Timesteps: 69,686,352
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04805
Policy Entropy: 5.63232
Value Function Loss: 0.02815
Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03717
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.05095
Collected Steps per Second: 10,798.04590
Overall Steps per Second: 8,621.72979
Timestep Collection Time: 4.63102
Timestep Consumption Time: 1.16897
PPO Batch Consumption Time: 0.08019
Total Iteration Time: 5.80000
Cumulative Model Updates: 4,177
Cumulative Timesteps: 69,736,358
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 69736358...
Checkpoint 69736358 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.75157
Policy Entropy: 5.63561
Value Function Loss: 0.02462
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03278
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.05311
Collected Steps per Second: 10,850.72546
Overall Steps per Second: 8,588.54400
Timestep Collection Time: 4.61057
Timestep Consumption Time: 1.21440
PPO Batch Consumption Time: 0.05270
Total Iteration Time: 5.82497
Cumulative Model Updates: 4,180
Cumulative Timesteps: 69,786,386
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98773
Policy Entropy: 5.62376
Value Function Loss: 0.02814
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02279
Policy Update Magnitude: 0.04299
Value Function Update Magnitude: 0.05278
Collected Steps per Second: 10,783.67306
Overall Steps per Second: 8,612.10047
Timestep Collection Time: 4.63979
Timestep Consumption Time: 1.16994
PPO Batch Consumption Time: 0.05091
Total Iteration Time: 5.80973
Cumulative Model Updates: 4,183
Cumulative Timesteps: 69,836,420
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 69836420...
Checkpoint 69836420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.25213
Policy Entropy: 5.60777
Value Function Loss: 0.03391
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02108
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.05403
Collected Steps per Second: 10,977.25284
Overall Steps per Second: 8,680.78269
Timestep Collection Time: 4.55761
Timestep Consumption Time: 1.20570
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.76331
Cumulative Model Updates: 4,186
Cumulative Timesteps: 69,886,450
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.88747
Policy Entropy: 5.59728
Value Function Loss: 0.03616
Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04176
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.05991
Collected Steps per Second: 10,860.63816
Overall Steps per Second: 8,589.41012
Timestep Collection Time: 4.60581
Timestep Consumption Time: 1.21788
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.82368
Cumulative Model Updates: 4,189
Cumulative Timesteps: 69,936,472
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 69936472...
Checkpoint 69936472 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.64968
Policy Entropy: 5.60577
Value Function Loss: 0.03776
Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.06558
Collected Steps per Second: 10,929.13539
Overall Steps per Second: 8,684.22572
Timestep Collection Time: 4.57584
Timestep Consumption Time: 1.18287
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 5.75872
Cumulative Model Updates: 4,192
Cumulative Timesteps: 69,986,482
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.07632
Policy Entropy: 5.57886
Value Function Loss: 0.03417
Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04304
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.06509
Collected Steps per Second: 11,051.39793
Overall Steps per Second: 8,717.95246
Timestep Collection Time: 4.52504
Timestep Consumption Time: 1.21117
PPO Batch Consumption Time: 0.05143
Total Iteration Time: 5.73621
Cumulative Model Updates: 4,195
Cumulative Timesteps: 70,036,490
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 70036490...
Checkpoint 70036490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.33752
Policy Entropy: 5.60226
Value Function Loss: 0.04019
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02075
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.06268
Collected Steps per Second: 10,802.28689
Overall Steps per Second: 8,546.75686
Timestep Collection Time: 4.62939
Timestep Consumption Time: 1.22172
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.85111
Cumulative Model Updates: 4,198
Cumulative Timesteps: 70,086,498
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.16731
Policy Entropy: 5.62648
Value Function Loss: 0.04193
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.06461
Collected Steps per Second: 10,885.58213
Overall Steps per Second: 8,644.28279
Timestep Collection Time: 4.59691
Timestep Consumption Time: 1.19189
PPO Batch Consumption Time: 0.08033
Total Iteration Time: 5.78880
Cumulative Model Updates: 4,201
Cumulative Timesteps: 70,136,538
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 70136538...
Checkpoint 70136538 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.78653
Policy Entropy: 5.61463
Value Function Loss: 0.03906
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02529
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.06177
Collected Steps per Second: 10,930.34907
Overall Steps per Second: 8,618.32120
Timestep Collection Time: 4.57460
Timestep Consumption Time: 1.22722
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 5.80183
Cumulative Model Updates: 4,204
Cumulative Timesteps: 70,186,540
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.31880
Policy Entropy: 5.61494
Value Function Loss: 0.03415
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02013
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.05976
Collected Steps per Second: 10,818.59022
Overall Steps per Second: 8,611.25617
Timestep Collection Time: 4.62371
Timestep Consumption Time: 1.18520
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.80891
Cumulative Model Updates: 4,207
Cumulative Timesteps: 70,236,562
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 70236562...
Checkpoint 70236562 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.86753
Policy Entropy: 5.59886
Value Function Loss: 0.02664
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02839
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.05640
Collected Steps per Second: 10,812.56282
Overall Steps per Second: 8,737.30564
Timestep Collection Time: 4.62666
Timestep Consumption Time: 1.09891
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.72556
Cumulative Model Updates: 4,210
Cumulative Timesteps: 70,286,588
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.50779
Policy Entropy: 5.58443
Value Function Loss: 0.03124
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03011
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.05305
Collected Steps per Second: 10,943.06977
Overall Steps per Second: 8,629.92268
Timestep Collection Time: 4.57276
Timestep Consumption Time: 1.22567
PPO Batch Consumption Time: 0.05072
Total Iteration Time: 5.79843
Cumulative Model Updates: 4,213
Cumulative Timesteps: 70,336,628
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 70336628...
Checkpoint 70336628 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.84130
Policy Entropy: 5.58883
Value Function Loss: 0.03351
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02034
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.05313
Collected Steps per Second: 10,828.02939
Overall Steps per Second: 8,628.20179
Timestep Collection Time: 4.62115
Timestep Consumption Time: 1.17820
PPO Batch Consumption Time: 0.05126
Total Iteration Time: 5.79935
Cumulative Model Updates: 4,216
Cumulative Timesteps: 70,386,666
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.10637
Policy Entropy: 5.58393
Value Function Loss: 0.03756
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01425
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.06134
Collected Steps per Second: 11,034.54153
Overall Steps per Second: 8,724.43860
Timestep Collection Time: 4.53394
Timestep Consumption Time: 1.20052
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 5.73447
Cumulative Model Updates: 4,219
Cumulative Timesteps: 70,436,696
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 70436696...
Checkpoint 70436696 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.39346
Policy Entropy: 5.57383
Value Function Loss: 0.03623
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.06641
Collected Steps per Second: 10,937.02419
Overall Steps per Second: 8,650.17107
Timestep Collection Time: 4.57346
Timestep Consumption Time: 1.20909
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.78254
Cumulative Model Updates: 4,222
Cumulative Timesteps: 70,486,716
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.11383
Policy Entropy: 5.57259
Value Function Loss: 0.03189
Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01535
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.06499
Collected Steps per Second: 10,862.22864
Overall Steps per Second: 8,638.87132
Timestep Collection Time: 4.60587
Timestep Consumption Time: 1.18540
PPO Batch Consumption Time: 0.08100
Total Iteration Time: 5.79127
Cumulative Model Updates: 4,225
Cumulative Timesteps: 70,536,746
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 70536746...
Checkpoint 70536746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.20676
Policy Entropy: 5.55951
Value Function Loss: 0.02771
Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01769
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.06225
Collected Steps per Second: 10,839.92747
Overall Steps per Second: 8,589.95202
Timestep Collection Time: 4.61331
Timestep Consumption Time: 1.20837
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.82169
Cumulative Model Updates: 4,228
Cumulative Timesteps: 70,586,754
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09624
Policy Entropy: 5.57952
Value Function Loss: 0.02871
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02675
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.05642
Collected Steps per Second: 10,900.60971
Overall Steps per Second: 8,671.99998
Timestep Collection Time: 4.58910
Timestep Consumption Time: 1.17935
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 5.76845
Cumulative Model Updates: 4,231
Cumulative Timesteps: 70,636,778
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 70636778...
Checkpoint 70636778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.00942
Policy Entropy: 5.60460
Value Function Loss: 0.03105
Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.03923
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.05306
Collected Steps per Second: 10,882.09519
Overall Steps per Second: 8,743.10487
Timestep Collection Time: 4.59967
Timestep Consumption Time: 1.12530
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 5.72497
Cumulative Model Updates: 4,234
Cumulative Timesteps: 70,686,832
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.14724
Policy Entropy: 5.60342
Value Function Loss: 0.03484
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.05294
Collected Steps per Second: 10,833.93879
Overall Steps per Second: 8,599.69069
Timestep Collection Time: 4.61568
Timestep Consumption Time: 1.19918
PPO Batch Consumption Time: 0.05068
Total Iteration Time: 5.81486
Cumulative Model Updates: 4,237
Cumulative Timesteps: 70,736,838
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 70736838...
Checkpoint 70736838 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.57373
Policy Entropy: 5.58567
Value Function Loss: 0.03625
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03115
Policy Update Magnitude: 0.04342
Value Function Update Magnitude: 0.04968
Collected Steps per Second: 10,872.09403
Overall Steps per Second: 8,677.29889
Timestep Collection Time: 4.60132
Timestep Consumption Time: 1.16384
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76516
Cumulative Model Updates: 4,240
Cumulative Timesteps: 70,786,864
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.90177
Policy Entropy: 5.57434
Value Function Loss: 0.03932
Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01747
Policy Update Magnitude: 0.04338
Value Function Update Magnitude: 0.04918
Collected Steps per Second: 11,033.29424
Overall Steps per Second: 8,714.79577
Timestep Collection Time: 4.53536
Timestep Consumption Time: 1.20660
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.74196
Cumulative Model Updates: 4,243
Cumulative Timesteps: 70,836,904
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 70836904...
Checkpoint 70836904 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.38193
Policy Entropy: 5.57045
Value Function Loss: 0.04014
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01831
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.05551
Collected Steps per Second: 10,972.05457
Overall Steps per Second: 8,667.56074
Timestep Collection Time: 4.55758
Timestep Consumption Time: 1.21175
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 5.76933
Cumulative Model Updates: 4,246
Cumulative Timesteps: 70,886,910
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.12380
Policy Entropy: 5.58201
Value Function Loss: 0.03467
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.05978
Collected Steps per Second: 10,890.66362
Overall Steps per Second: 8,572.93738
Timestep Collection Time: 4.59550
Timestep Consumption Time: 1.24241
PPO Batch Consumption Time: 0.07300
Total Iteration Time: 5.83791
Cumulative Model Updates: 4,249
Cumulative Timesteps: 70,936,958
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 70936958...
Checkpoint 70936958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.19942
Policy Entropy: 5.59542
Value Function Loss: 0.03149
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02049
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.05886
Collected Steps per Second: 11,169.50044
Overall Steps per Second: 8,769.69133
Timestep Collection Time: 4.47666
Timestep Consumption Time: 1.22503
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 5.70168
Cumulative Model Updates: 4,252
Cumulative Timesteps: 70,986,960
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98714
Policy Entropy: 5.58353
Value Function Loss: 0.03204
Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01480
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.05462
Collected Steps per Second: 11,020.45838
Overall Steps per Second: 8,673.67998
Timestep Collection Time: 4.54137
Timestep Consumption Time: 1.22873
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 5.77010
Cumulative Model Updates: 4,255
Cumulative Timesteps: 71,037,008
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 71037008...
Checkpoint 71037008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.87326
Policy Entropy: 5.57830
Value Function Loss: 0.03379
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.05469
Collected Steps per Second: 10,916.09636
Overall Steps per Second: 8,670.67184
Timestep Collection Time: 4.58204
Timestep Consumption Time: 1.18660
PPO Batch Consumption Time: 0.06033
Total Iteration Time: 5.76864
Cumulative Model Updates: 4,258
Cumulative Timesteps: 71,087,026
Timesteps Collected: 50,018
--------END ITERATION REPORT--------