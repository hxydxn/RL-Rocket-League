{"Cumulative Model Updates": 158540, "Collected Steps per Second": 12603.188638461428, "PPO Batch Consumption Time": 0.2339415815141466, "_runtime": 183880.9427037239, "Value Function Loss": 0.002678978463841809, "Policy Reward": 14.050487641884757, "Timestep Collection Time": 3.970265100000006, "Timestep Consumption Time": 3.1390295999999935, "Value Function Update Magnitude": 0.8493451476097107, "x_vel": -2.667151826137044, "y_vel": 280.4490932940915, "Policy Entropy": 4.331116093529595, "Timesteps Collected": 50038, "Cumulative Timesteps": 1247142032, "Total Iteration Time": 7.1092946999999995, "Policy Update Magnitude": 1.0093249082565308, "_step": 49858, "z_vel": 11.034008254358417, "Mean KL Divergence": 0.0036729307224353156, "Overall Steps per Second": 7038.391586158329, "_timestamp": 1714001942.1865618, "SB3 Clip Fraction": 0.03752666566934851, "_wandb": {"runtime": 21082}}