Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)
--------BEGIN ITERATION REPORT--------
Policy Reward: 7,828.56093
Policy Entropy: 3.53271
Value Function Loss: 0.22711
Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.42369
Value Function Update Magnitude: 0.28287
Collected Steps per Second: 8,208.82262
Overall Steps per Second: 5,461.70147
Timestep Collection Time: 6.09174
Timestep Consumption Time: 3.06402
PPO Batch Consumption Time: 0.63029
Total Iteration Time: 9.15575
Cumulative Model Updates: 131,573
Cumulative Timesteps: 1,097,074,468
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7,828.56093
Policy Entropy: 3.57060
Value Function Loss: 0.13052
Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.22855
Policy Update Magnitude: 0.41636
Value Function Update Magnitude: 0.31310
Collected Steps per Second: 9,201.03251
Overall Steps per Second: 6,049.21527
Timestep Collection Time: 5.43504
Timestep Consumption Time: 2.83182
PPO Batch Consumption Time: 0.56316
Total Iteration Time: 8.26686
Cumulative Model Updates: 131,576
Cumulative Timesteps: 1,097,124,476
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1097124476...
Checkpoint 1097124476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7,828.56093
Policy Entropy: 3.60938
Value Function Loss: 0.11832
Mean KL Divergence: 0.02649
SB3 Clip Fraction: 0.28260
Policy Update Magnitude: 0.67840
Value Function Update Magnitude: 0.74549
Collected Steps per Second: 7,223.29580
Overall Steps per Second: 4,000.61480
Timestep Collection Time: 6.92759
Timestep Consumption Time: 5.58049
PPO Batch Consumption Time: 0.55696
Total Iteration Time: 12.50808
Cumulative Model Updates: 131,582
Cumulative Timesteps: 1,097,174,516
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6,343.65168
Policy Entropy: 3.66461
Value Function Loss: 0.10323
Mean KL Divergence: 0.03514
SB3 Clip Fraction: 0.31956
Policy Update Magnitude: 0.77895
Value Function Update Magnitude: 1.00486
Collected Steps per Second: 9,198.14332
Overall Steps per Second: 4,314.17122
Timestep Collection Time: 5.43871
Timestep Consumption Time: 6.15703
PPO Batch Consumption Time: 0.56500
Total Iteration Time: 11.59574
Cumulative Model Updates: 131,591
Cumulative Timesteps: 1,097,224,542
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1097224542...
Checkpoint 1097224542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3,376.53229
Policy Entropy: 3.61500
Value Function Loss: 0.03744
Mean KL Divergence: 0.03170
SB3 Clip Fraction: 0.31060
Policy Update Magnitude: 0.85663
Value Function Update Magnitude: 0.93277
Collected Steps per Second: 10,727.44244
Overall Steps per Second: 6,157.52076
Timestep Collection Time: 4.66486
Timestep Consumption Time: 3.46211
PPO Batch Consumption Time: 0.24269
Total Iteration Time: 8.12697
Cumulative Model Updates: 131,600
Cumulative Timesteps: 1,097,274,584
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.60419
Policy Entropy: 3.59485
Value Function Loss: 0.03840
Mean KL Divergence: 0.03571
SB3 Clip Fraction: 0.33191
Policy Update Magnitude: 0.91415
Value Function Update Magnitude: 1.21605
Collected Steps per Second: 11,330.71415
Overall Steps per Second: 6,543.55227
Timestep Collection Time: 4.41561
Timestep Consumption Time: 3.23039
PPO Batch Consumption Time: 0.23707
Total Iteration Time: 7.64600
Cumulative Model Updates: 131,609
Cumulative Timesteps: 1,097,324,616
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1097324616...
Checkpoint 1097324616 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 349.04293
Policy Entropy: 3.55955
Value Function Loss: 0.02900
Mean KL Divergence: 0.03211
SB3 Clip Fraction: 0.31456
Policy Update Magnitude: 1.35289
Value Function Update Magnitude: 1.27215
Collected Steps per Second: 10,962.74821
Overall Steps per Second: 6,310.16179
Timestep Collection Time: 4.56163
Timestep Consumption Time: 3.36336
PPO Batch Consumption Time: 0.24347
Total Iteration Time: 7.92499
Cumulative Model Updates: 131,618
Cumulative Timesteps: 1,097,374,624
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 65.89458
Policy Entropy: 3.58892
Value Function Loss: 0.02119
Mean KL Divergence: 0.03065
SB3 Clip Fraction: 0.31470
Policy Update Magnitude: 1.33392
Value Function Update Magnitude: 1.23120
Collected Steps per Second: 11,957.56956
Overall Steps per Second: 6,626.60944
Timestep Collection Time: 4.18279
Timestep Consumption Time: 3.36496
PPO Batch Consumption Time: 0.24815
Total Iteration Time: 7.54775
Cumulative Model Updates: 131,627
Cumulative Timesteps: 1,097,424,640
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1097424640...
Checkpoint 1097424640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 23.00127
Policy Entropy: 3.58860
Value Function Loss: 0.01863
Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.24179
Policy Update Magnitude: 1.83611
Value Function Update Magnitude: 1.44581
Collected Steps per Second: 12,110.45422
Overall Steps per Second: 6,800.18032
Timestep Collection Time: 4.12866
Timestep Consumption Time: 3.22408
PPO Batch Consumption Time: 0.23539
Total Iteration Time: 7.35275
Cumulative Model Updates: 131,636
Cumulative Timesteps: 1,097,474,640
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 25.50992
Policy Entropy: 3.60306
Value Function Loss: 0.01551
Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.19944
Policy Update Magnitude: 2.16358
Value Function Update Magnitude: 1.59806
Collected Steps per Second: 12,251.79516
Overall Steps per Second: 6,880.80717
Timestep Collection Time: 4.08299
Timestep Consumption Time: 3.18708
PPO Batch Consumption Time: 0.23110
Total Iteration Time: 7.27008
Cumulative Model Updates: 131,645
Cumulative Timesteps: 1,097,524,664
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1097524664...
Checkpoint 1097524664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41641
Policy Entropy: 3.67755
Value Function Loss: 0.01387
Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.18610
Policy Update Magnitude: 2.19120
Value Function Update Magnitude: 1.51911
Collected Steps per Second: 12,008.32586
Overall Steps per Second: 6,725.01649
Timestep Collection Time: 4.16394
Timestep Consumption Time: 3.27128
PPO Batch Consumption Time: 0.24397
Total Iteration Time: 7.43522
Cumulative Model Updates: 131,654
Cumulative Timesteps: 1,097,574,666
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.34178
Policy Entropy: 3.75015
Value Function Loss: 0.01287
Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.16416
Policy Update Magnitude: 2.15169
Value Function Update Magnitude: 1.42376
Collected Steps per Second: 12,333.97074
Overall Steps per Second: 6,899.10010
Timestep Collection Time: 4.05401
Timestep Consumption Time: 3.19361
PPO Batch Consumption Time: 0.23692
Total Iteration Time: 7.24761
Cumulative Model Updates: 131,663
Cumulative Timesteps: 1,097,624,668
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1097624668...
Checkpoint 1097624668 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.61956
Policy Entropy: 3.81776
Value Function Loss: 0.01144
Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.15996
Policy Update Magnitude: 2.11142
Value Function Update Magnitude: 1.39683
Collected Steps per Second: 11,837.20103
Overall Steps per Second: 6,738.50980
Timestep Collection Time: 4.22651
Timestep Consumption Time: 3.19798
PPO Batch Consumption Time: 0.23383
Total Iteration Time: 7.42449
Cumulative Model Updates: 131,672
Cumulative Timesteps: 1,097,674,698
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.47603
Policy Entropy: 3.86544
Value Function Loss: 0.01029
Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.14826
Policy Update Magnitude: 2.05341
Value Function Update Magnitude: 1.40271
Collected Steps per Second: 11,849.31567
Overall Steps per Second: 6,697.17166
Timestep Collection Time: 4.22168
Timestep Consumption Time: 3.24774
PPO Batch Consumption Time: 0.24142
Total Iteration Time: 7.46942
Cumulative Model Updates: 131,681
Cumulative Timesteps: 1,097,724,722
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1097724722...
Checkpoint 1097724722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.12230
Policy Entropy: 3.92079
Value Function Loss: 0.00866
Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 1.97031
Value Function Update Magnitude: 1.40011
Collected Steps per Second: 12,735.37956
Overall Steps per Second: 6,984.50048
Timestep Collection Time: 3.92843
Timestep Consumption Time: 3.23458
PPO Batch Consumption Time: 0.23250
Total Iteration Time: 7.16300
Cumulative Model Updates: 131,690
Cumulative Timesteps: 1,097,774,752
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.12394
Policy Entropy: 3.96978
Value Function Loss: 0.00797
Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 1.86693
Value Function Update Magnitude: 1.30977
Collected Steps per Second: 11,400.84305
Overall Steps per Second: 6,652.96127
Timestep Collection Time: 4.38915
Timestep Consumption Time: 3.13231
PPO Batch Consumption Time: 0.23681
Total Iteration Time: 7.52146
Cumulative Model Updates: 131,699
Cumulative Timesteps: 1,097,824,792
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1097824792...
Checkpoint 1097824792 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25743
Policy Entropy: 4.00730
Value Function Loss: 0.00741
Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 1.77300
Value Function Update Magnitude: 1.27777
Collected Steps per Second: 11,595.79691
Overall Steps per Second: 6,695.16161
Timestep Collection Time: 4.31398
Timestep Consumption Time: 3.15769
PPO Batch Consumption Time: 0.23294
Total Iteration Time: 7.47166
Cumulative Model Updates: 131,708
Cumulative Timesteps: 1,097,874,816
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.35596
Policy Entropy: 4.03946
Value Function Loss: 0.00654
Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 1.68363
Value Function Update Magnitude: 1.28926
Collected Steps per Second: 12,943.08297
Overall Steps per Second: 7,153.67365
Timestep Collection Time: 3.86338
Timestep Consumption Time: 3.12660
PPO Batch Consumption Time: 0.22787
Total Iteration Time: 6.98997
Cumulative Model Updates: 131,717
Cumulative Timesteps: 1,097,924,820
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1097924820...
Checkpoint 1097924820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.20611
Policy Entropy: 4.07545
Value Function Loss: 0.00571
Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 1.61120
Value Function Update Magnitude: 1.25356
Collected Steps per Second: 12,774.21162
Overall Steps per Second: 7,142.68118
Timestep Collection Time: 3.91539
Timestep Consumption Time: 3.08702
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 7.00241
Cumulative Model Updates: 131,726
Cumulative Timesteps: 1,097,974,836
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.62178
Policy Entropy: 4.10507
Value Function Loss: 0.00515
Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 1.53346
Value Function Update Magnitude: 1.19282
Collected Steps per Second: 13,315.33291
Overall Steps per Second: 7,290.36449
Timestep Collection Time: 3.75702
Timestep Consumption Time: 3.10491
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.86193
Cumulative Model Updates: 131,735
Cumulative Timesteps: 1,098,024,862
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1098024862...
Checkpoint 1098024862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.25729
Policy Entropy: 4.13886
Value Function Loss: 0.00450
Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 1.45155
Value Function Update Magnitude: 1.05580
Collected Steps per Second: 13,104.15990
Overall Steps per Second: 7,167.30785
Timestep Collection Time: 3.81848
Timestep Consumption Time: 3.16294
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.98142
Cumulative Model Updates: 131,744
Cumulative Timesteps: 1,098,074,900
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.28846
Policy Entropy: 4.16711
Value Function Loss: 0.00418
Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 1.38498
Value Function Update Magnitude: 0.98295
Collected Steps per Second: 13,076.38419
Overall Steps per Second: 7,226.19616
Timestep Collection Time: 3.82568
Timestep Consumption Time: 3.09719
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.92287
Cumulative Model Updates: 131,753
Cumulative Timesteps: 1,098,124,926
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1098124926...
Checkpoint 1098124926 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95432
Policy Entropy: 4.19065
Value Function Loss: 0.00397
Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 1.33929
Value Function Update Magnitude: 0.97835
Collected Steps per Second: 13,296.17929
Overall Steps per Second: 7,284.72816
Timestep Collection Time: 3.76304
Timestep Consumption Time: 3.10531
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.86834
Cumulative Model Updates: 131,762
Cumulative Timesteps: 1,098,174,960
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04035
Policy Entropy: 4.21044
Value Function Loss: 0.00388
Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07646
Policy Update Magnitude: 1.29837
Value Function Update Magnitude: 0.99806
Collected Steps per Second: 13,105.94222
Overall Steps per Second: 7,156.41184
Timestep Collection Time: 3.81735
Timestep Consumption Time: 3.17358
PPO Batch Consumption Time: 0.22966
Total Iteration Time: 6.99093
Cumulative Model Updates: 131,771
Cumulative Timesteps: 1,098,224,990
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1098224990...
Checkpoint 1098224990 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.45596
Policy Entropy: 4.22568
Value Function Loss: 0.00354
Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06825
Policy Update Magnitude: 1.25450
Value Function Update Magnitude: 0.95189
Collected Steps per Second: 12,950.11454
Overall Steps per Second: 7,196.33019
Timestep Collection Time: 3.86251
Timestep Consumption Time: 3.08825
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.95076
Cumulative Model Updates: 131,780
Cumulative Timesteps: 1,098,275,010
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77376
Policy Entropy: 4.24652
Value Function Loss: 0.00326
Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05863
Policy Update Magnitude: 1.19086
Value Function Update Magnitude: 0.87992
Collected Steps per Second: 13,340.44824
Overall Steps per Second: 7,314.21178
Timestep Collection Time: 3.74875
Timestep Consumption Time: 3.08862
PPO Batch Consumption Time: 0.22794
Total Iteration Time: 6.83737
Cumulative Model Updates: 131,789
Cumulative Timesteps: 1,098,325,020
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1098325020...
Checkpoint 1098325020 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.06185
Policy Entropy: 4.25658
Value Function Loss: 0.00297
Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05209
Policy Update Magnitude: 1.14394
Value Function Update Magnitude: 0.84004
Collected Steps per Second: 12,849.63492
Overall Steps per Second: 7,150.32522
Timestep Collection Time: 3.89272
Timestep Consumption Time: 3.10277
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.99549
Cumulative Model Updates: 131,798
Cumulative Timesteps: 1,098,375,040
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.57536
Policy Entropy: 4.26870
Value Function Loss: 0.00291
Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04622
Policy Update Magnitude: 1.12029
Value Function Update Magnitude: 0.81075
Collected Steps per Second: 13,062.95032
Overall Steps per Second: 7,298.27447
Timestep Collection Time: 3.82946
Timestep Consumption Time: 3.02477
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.85422
Cumulative Model Updates: 131,807
Cumulative Timesteps: 1,098,425,064
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1098425064...
Checkpoint 1098425064 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.52968
Policy Entropy: 4.27885
Value Function Loss: 0.00281
Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04198
Policy Update Magnitude: 1.09457
Value Function Update Magnitude: 0.77467
Collected Steps per Second: 13,001.19506
Overall Steps per Second: 7,190.68510
Timestep Collection Time: 3.84718
Timestep Consumption Time: 3.10876
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.95594
Cumulative Model Updates: 131,816
Cumulative Timesteps: 1,098,475,082
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18182
Policy Entropy: 4.28872
Value Function Loss: 0.00274
Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04284
Policy Update Magnitude: 1.06815
Value Function Update Magnitude: 0.79526
Collected Steps per Second: 12,969.20229
Overall Steps per Second: 7,197.74736
Timestep Collection Time: 3.85621
Timestep Consumption Time: 3.09207
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.94828
Cumulative Model Updates: 131,825
Cumulative Timesteps: 1,098,525,094
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1098525094...
Checkpoint 1098525094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93108
Policy Entropy: 4.29953
Value Function Loss: 0.00265
Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04218
Policy Update Magnitude: 1.05168
Value Function Update Magnitude: 0.79920
Collected Steps per Second: 12,913.22901
Overall Steps per Second: 7,206.91652
Timestep Collection Time: 3.87308
Timestep Consumption Time: 3.06664
PPO Batch Consumption Time: 0.23313
Total Iteration Time: 6.93972
Cumulative Model Updates: 131,834
Cumulative Timesteps: 1,098,575,108
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.43570
Policy Entropy: 4.30757
Value Function Loss: 0.00259
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03865
Policy Update Magnitude: 1.03237
Value Function Update Magnitude: 0.81032
Collected Steps per Second: 13,053.74710
Overall Steps per Second: 7,187.81419
Timestep Collection Time: 3.83139
Timestep Consumption Time: 3.12678
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.95817
Cumulative Model Updates: 131,843
Cumulative Timesteps: 1,098,625,122
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1098625122...
Checkpoint 1098625122 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.54252
Policy Entropy: 4.31764
Value Function Loss: 0.00236
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03519
Policy Update Magnitude: 1.00340
Value Function Update Magnitude: 0.81555
Collected Steps per Second: 12,921.78595
Overall Steps per Second: 7,123.32791
Timestep Collection Time: 3.87191
Timestep Consumption Time: 3.15177
PPO Batch Consumption Time: 0.23432
Total Iteration Time: 7.02368
Cumulative Model Updates: 131,852
Cumulative Timesteps: 1,098,675,154
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.85990
Policy Entropy: 4.32551
Value Function Loss: 0.00224
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03289
Policy Update Magnitude: 0.95978
Value Function Update Magnitude: 0.84136
Collected Steps per Second: 12,234.22343
Overall Steps per Second: 6,806.75208
Timestep Collection Time: 4.08755
Timestep Consumption Time: 3.25927
PPO Batch Consumption Time: 0.23433
Total Iteration Time: 7.34682
Cumulative Model Updates: 131,861
Cumulative Timesteps: 1,098,725,162
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1098725162...
Checkpoint 1098725162 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.26058
Policy Entropy: 4.32858
Value Function Loss: 0.00215
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02825
Policy Update Magnitude: 0.92742
Value Function Update Magnitude: 0.87695
Collected Steps per Second: 12,258.28655
Overall Steps per Second: 6,853.36987
Timestep Collection Time: 4.08099
Timestep Consumption Time: 3.21848
PPO Batch Consumption Time: 0.23522
Total Iteration Time: 7.29947
Cumulative Model Updates: 131,870
Cumulative Timesteps: 1,098,775,188
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09585
Policy Entropy: 4.33350
Value Function Loss: 0.00211
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.91949
Value Function Update Magnitude: 0.92096
Collected Steps per Second: 12,505.91182
Overall Steps per Second: 7,092.98744
Timestep Collection Time: 4.00131
Timestep Consumption Time: 3.05355
PPO Batch Consumption Time: 0.23055
Total Iteration Time: 7.05486
Cumulative Model Updates: 131,879
Cumulative Timesteps: 1,098,825,228
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1098825228...
Checkpoint 1098825228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.27013
Policy Entropy: 4.33565
Value Function Loss: 0.00201
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.88736
Value Function Update Magnitude: 0.96558
Collected Steps per Second: 12,826.58382
Overall Steps per Second: 7,062.91612
Timestep Collection Time: 3.90127
Timestep Consumption Time: 3.18362
PPO Batch Consumption Time: 0.23138
Total Iteration Time: 7.08489
Cumulative Model Updates: 131,888
Cumulative Timesteps: 1,098,875,268
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.53543
Policy Entropy: 4.33899
Value Function Loss: 0.00191
Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02057
Policy Update Magnitude: 0.85610
Value Function Update Magnitude: 0.99322
Collected Steps per Second: 12,994.67942
Overall Steps per Second: 7,072.84004
Timestep Collection Time: 3.84896
Timestep Consumption Time: 3.22260
PPO Batch Consumption Time: 0.24066
Total Iteration Time: 7.07156
Cumulative Model Updates: 131,897
Cumulative Timesteps: 1,098,925,284
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1098925284...
Checkpoint 1098925284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.56880
Policy Entropy: 4.34038
Value Function Loss: 0.00183
Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02208
Policy Update Magnitude: 0.84396
Value Function Update Magnitude: 0.98222
Collected Steps per Second: 13,182.67226
Overall Steps per Second: 7,262.00005
Timestep Collection Time: 3.79392
Timestep Consumption Time: 3.09316
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.88708
Cumulative Model Updates: 131,906
Cumulative Timesteps: 1,098,975,298
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.89218
Policy Entropy: 4.34153
Value Function Loss: 0.00189
Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.85197
Value Function Update Magnitude: 0.98363
Collected Steps per Second: 13,301.33596
Overall Steps per Second: 7,257.94396
Timestep Collection Time: 3.76098
Timestep Consumption Time: 3.13161
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.89259
Cumulative Model Updates: 131,915
Cumulative Timesteps: 1,099,025,324
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1099025324...
Checkpoint 1099025324 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.70859
Policy Entropy: 4.34504
Value Function Loss: 0.00187
Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.85933
Value Function Update Magnitude: 0.96510
Collected Steps per Second: 13,170.06587
Overall Steps per Second: 7,235.60131
Timestep Collection Time: 3.79770
Timestep Consumption Time: 3.11478
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.91249
Cumulative Model Updates: 131,924
Cumulative Timesteps: 1,099,075,340
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.53288
Policy Entropy: 4.34504
Value Function Loss: 0.00182
Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01702
Policy Update Magnitude: 0.86005
Value Function Update Magnitude: 0.91912
Collected Steps per Second: 12,722.73752
Overall Steps per Second: 7,035.89288
Timestep Collection Time: 3.93359
Timestep Consumption Time: 3.17937
PPO Batch Consumption Time: 0.23080
Total Iteration Time: 7.11296
Cumulative Model Updates: 131,933
Cumulative Timesteps: 1,099,125,386
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1099125386...
Checkpoint 1099125386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77088
Policy Entropy: 4.34762
Value Function Loss: 0.00175
Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01710
Policy Update Magnitude: 0.83930
Value Function Update Magnitude: 0.90258
Collected Steps per Second: 12,116.15135
Overall Steps per Second: 6,753.01534
Timestep Collection Time: 4.12705
Timestep Consumption Time: 3.27764
PPO Batch Consumption Time: 0.23977
Total Iteration Time: 7.40469
Cumulative Model Updates: 131,942
Cumulative Timesteps: 1,099,175,390
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.88268
Policy Entropy: 4.35159
Value Function Loss: 0.00175
Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01807
Policy Update Magnitude: 0.80957
Value Function Update Magnitude: 0.88379
Collected Steps per Second: 11,617.94499
Overall Steps per Second: 6,781.47803
Timestep Collection Time: 4.30730
Timestep Consumption Time: 3.07192
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 7.37922
Cumulative Model Updates: 131,951
Cumulative Timesteps: 1,099,225,432
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1099225432...
Checkpoint 1099225432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.04781
Policy Entropy: 4.35533
Value Function Loss: 0.00172
Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01499
Policy Update Magnitude: 0.79254
Value Function Update Magnitude: 0.89387
Collected Steps per Second: 12,416.49959
Overall Steps per Second: 6,874.63267
Timestep Collection Time: 4.02706
Timestep Consumption Time: 3.24635
PPO Batch Consumption Time: 0.23200
Total Iteration Time: 7.27341
Cumulative Model Updates: 131,960
Cumulative Timesteps: 1,099,275,434
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.76339
Policy Entropy: 4.35737
Value Function Loss: 0.00171
Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01404
Policy Update Magnitude: 0.79831
Value Function Update Magnitude: 0.90128
Collected Steps per Second: 12,366.70582
Overall Steps per Second: 6,831.73727
Timestep Collection Time: 4.04651
Timestep Consumption Time: 3.27842
PPO Batch Consumption Time: 0.24461
Total Iteration Time: 7.32493
Cumulative Model Updates: 131,969
Cumulative Timesteps: 1,099,325,476
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1099325476...
Checkpoint 1099325476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.37901
Policy Entropy: 4.35831
Value Function Loss: 0.00168
Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01601
Policy Update Magnitude: 0.80458
Value Function Update Magnitude: 0.90002
Collected Steps per Second: 11,241.64252
Overall Steps per Second: 6,634.86891
Timestep Collection Time: 4.45095
Timestep Consumption Time: 3.09042
PPO Batch Consumption Time: 0.23027
Total Iteration Time: 7.54137
Cumulative Model Updates: 131,978
Cumulative Timesteps: 1,099,375,512
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.14382
Policy Entropy: 4.36223
Value Function Loss: 0.00166
Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01472
Policy Update Magnitude: 0.80178
Value Function Update Magnitude: 0.87169
Collected Steps per Second: 11,974.38282
Overall Steps per Second: 6,760.32477
Timestep Collection Time: 4.18026
Timestep Consumption Time: 3.22412
PPO Batch Consumption Time: 0.23655
Total Iteration Time: 7.40438
Cumulative Model Updates: 131,987
Cumulative Timesteps: 1,099,425,568
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1099425568...
Checkpoint 1099425568 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55209
Policy Entropy: 4.36411
Value Function Loss: 0.00159
Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01327
Policy Update Magnitude: 0.79173
Value Function Update Magnitude: 0.84523
Collected Steps per Second: 11,766.41023
Overall Steps per Second: 6,789.25180
Timestep Collection Time: 4.25210
Timestep Consumption Time: 3.11719
PPO Batch Consumption Time: 0.22923
Total Iteration Time: 7.36930
Cumulative Model Updates: 131,996
Cumulative Timesteps: 1,099,475,600
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.96481
Policy Entropy: 4.36657
Value Function Loss: 0.00154
Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01339
Policy Update Magnitude: 0.77228
Value Function Update Magnitude: 0.80778
Collected Steps per Second: 12,509.92596
Overall Steps per Second: 7,005.98132
Timestep Collection Time: 3.99986
Timestep Consumption Time: 3.14232
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 7.14218
Cumulative Model Updates: 132,005
Cumulative Timesteps: 1,099,525,638
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1099525638...
Checkpoint 1099525638 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.22158
Policy Entropy: 4.36886
Value Function Loss: 0.00157
Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01178
Policy Update Magnitude: 0.76026
Value Function Update Magnitude: 0.81373
Collected Steps per Second: 12,631.18664
Overall Steps per Second: 6,805.68065
Timestep Collection Time: 3.96146
Timestep Consumption Time: 3.39092
PPO Batch Consumption Time: 0.24728
Total Iteration Time: 7.35239
Cumulative Model Updates: 132,014
Cumulative Timesteps: 1,099,575,676
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.04191
Policy Entropy: 4.36930
Value Function Loss: 0.00163
Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01252
Policy Update Magnitude: 0.76597
Value Function Update Magnitude: 0.86598
Collected Steps per Second: 10,752.47139
Overall Steps per Second: 6,244.36886
Timestep Collection Time: 4.65270
Timestep Consumption Time: 3.35900
PPO Batch Consumption Time: 0.24988
Total Iteration Time: 8.01170
Cumulative Model Updates: 132,023
Cumulative Timesteps: 1,099,625,704
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1099625704...
Checkpoint 1099625704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.99167
Policy Entropy: 4.37174
Value Function Loss: 0.00165
Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01241
Policy Update Magnitude: 0.77305
Value Function Update Magnitude: 0.89742
Collected Steps per Second: 12,082.71888
Overall Steps per Second: 6,856.62640
Timestep Collection Time: 4.14096
Timestep Consumption Time: 3.15622
PPO Batch Consumption Time: 0.22925
Total Iteration Time: 7.29717
Cumulative Model Updates: 132,032
Cumulative Timesteps: 1,099,675,738
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.18045
Policy Entropy: 4.37313
Value Function Loss: 0.00158
Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01206
Policy Update Magnitude: 0.77114
Value Function Update Magnitude: 0.92818
Collected Steps per Second: 12,712.39054
Overall Steps per Second: 7,094.51988
Timestep Collection Time: 3.93585
Timestep Consumption Time: 3.11664
PPO Batch Consumption Time: 0.22965
Total Iteration Time: 7.05249
Cumulative Model Updates: 132,041
Cumulative Timesteps: 1,099,725,772
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1099725772...
Checkpoint 1099725772 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.13763
Policy Entropy: 4.37323
Value Function Loss: 0.00149
Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01090
Policy Update Magnitude: 0.76789
Value Function Update Magnitude: 0.87397
Collected Steps per Second: 12,723.96425
Overall Steps per Second: 7,065.31615
Timestep Collection Time: 3.92991
Timestep Consumption Time: 3.14748
PPO Batch Consumption Time: 0.22973
Total Iteration Time: 7.07739
Cumulative Model Updates: 132,050
Cumulative Timesteps: 1,099,775,776
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09990
Policy Entropy: 4.37186
Value Function Loss: 0.00152
Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01006
Policy Update Magnitude: 0.74735
Value Function Update Magnitude: 0.84205
Collected Steps per Second: 11,905.33277
Overall Steps per Second: 6,769.11300
Timestep Collection Time: 4.19997
Timestep Consumption Time: 3.18682
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 7.38679
Cumulative Model Updates: 132,059
Cumulative Timesteps: 1,099,825,778
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1099825778...
Checkpoint 1099825778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.32296
Policy Entropy: 4.37248
Value Function Loss: 0.00162
Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01005
Policy Update Magnitude: 0.74477
Value Function Update Magnitude: 0.86385
Collected Steps per Second: 11,764.29141
Overall Steps per Second: 6,725.70955
Timestep Collection Time: 4.25202
Timestep Consumption Time: 3.18541
PPO Batch Consumption Time: 0.23270
Total Iteration Time: 7.43743
Cumulative Model Updates: 132,068
Cumulative Timesteps: 1,099,875,800
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.92473
Policy Entropy: 4.37233
Value Function Loss: 0.00167
Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01074
Policy Update Magnitude: 0.74792
Value Function Update Magnitude: 0.86882
Collected Steps per Second: 12,774.08134
Overall Steps per Second: 7,090.03349
Timestep Collection Time: 3.91605
Timestep Consumption Time: 3.13948
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 7.05554
Cumulative Model Updates: 132,077
Cumulative Timesteps: 1,099,925,824
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1099925824...
Checkpoint 1099925824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.62425
Policy Entropy: 4.37421
Value Function Loss: 0.00162
Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01174
Policy Update Magnitude: 0.73707
Value Function Update Magnitude: 0.84494
Collected Steps per Second: 12,781.70796
Overall Steps per Second: 7,012.23472
Timestep Collection Time: 3.91466
Timestep Consumption Time: 3.22087
PPO Batch Consumption Time: 0.23355
Total Iteration Time: 7.13553
Cumulative Model Updates: 132,086
Cumulative Timesteps: 1,099,975,860
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.22857
Policy Entropy: 4.37433
Value Function Loss: 0.00152
Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00958
Policy Update Magnitude: 0.71687
Value Function Update Magnitude: 0.79285
Collected Steps per Second: 11,413.64410
Overall Steps per Second: 6,696.58739
Timestep Collection Time: 4.38107
Timestep Consumption Time: 3.08601
PPO Batch Consumption Time: 0.23274
Total Iteration Time: 7.46709
Cumulative Model Updates: 132,095
Cumulative Timesteps: 1,100,025,864
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1100025864...
Checkpoint 1100025864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.53555
Policy Entropy: 4.37485
Value Function Loss: 0.00150
Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.00920
Policy Update Magnitude: 0.71649
Value Function Update Magnitude: 0.80735
Collected Steps per Second: 11,058.00940
Overall Steps per Second: 6,522.28302
Timestep Collection Time: 4.52450
Timestep Consumption Time: 3.14643
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 7.67093
Cumulative Model Updates: 132,104
Cumulative Timesteps: 1,100,075,896
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79097
Policy Entropy: 4.37681
Value Function Loss: 0.00142
Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01014
Policy Update Magnitude: 0.72136
Value Function Update Magnitude: 0.79740
Collected Steps per Second: 11,776.79824
Overall Steps per Second: 6,801.88307
Timestep Collection Time: 4.24682
Timestep Consumption Time: 3.10614
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 7.35296
Cumulative Model Updates: 132,113
Cumulative Timesteps: 1,100,125,910
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1100125910...
Checkpoint 1100125910 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.78944
Policy Entropy: 4.37603
Value Function Loss: 0.00141
Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00872
Policy Update Magnitude: 0.71057
Value Function Update Magnitude: 0.80043
Collected Steps per Second: 12,521.08391
Overall Steps per Second: 6,953.50242
Timestep Collection Time: 3.99374
Timestep Consumption Time: 3.19774
PPO Batch Consumption Time: 0.23589
Total Iteration Time: 7.19148
Cumulative Model Updates: 132,122
Cumulative Timesteps: 1,100,175,916
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.27476
Policy Entropy: 4.37730
Value Function Loss: 0.00143
Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00902
Policy Update Magnitude: 0.71535
Value Function Update Magnitude: 0.80461
Collected Steps per Second: 12,140.26748
Overall Steps per Second: 6,767.72133
Timestep Collection Time: 4.12133
Timestep Consumption Time: 3.27171
PPO Batch Consumption Time: 0.23934
Total Iteration Time: 7.39303
Cumulative Model Updates: 132,131
Cumulative Timesteps: 1,100,225,950
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1100225950...
Checkpoint 1100225950 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.33205
Policy Entropy: 4.37767
Value Function Loss: 0.00144
Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.00943
Policy Update Magnitude: 0.75276
Value Function Update Magnitude: 0.79502
Collected Steps per Second: 11,993.68833
Overall Steps per Second: 6,844.54285
Timestep Collection Time: 4.16986
Timestep Consumption Time: 3.13698
PPO Batch Consumption Time: 0.23451
Total Iteration Time: 7.30684
Cumulative Model Updates: 132,140
Cumulative Timesteps: 1,100,275,962
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70651
Policy Entropy: 4.37746
Value Function Loss: 0.00142
Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01106
Policy Update Magnitude: 0.74416
Value Function Update Magnitude: 0.80578
Collected Steps per Second: 11,726.12186
Overall Steps per Second: 6,669.48036
Timestep Collection Time: 4.26415
Timestep Consumption Time: 3.23298
PPO Batch Consumption Time: 0.23473
Total Iteration Time: 7.49714
Cumulative Model Updates: 132,149
Cumulative Timesteps: 1,100,325,964
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1100325964...
Checkpoint 1100325964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.27644
Policy Entropy: 4.37712
Value Function Loss: 0.00141
Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01068
Policy Update Magnitude: 0.72018
Value Function Update Magnitude: 0.79721
Collected Steps per Second: 12,384.83697
Overall Steps per Second: 6,986.12222
Timestep Collection Time: 4.03784
Timestep Consumption Time: 3.12035
PPO Batch Consumption Time: 0.22944
Total Iteration Time: 7.15819
Cumulative Model Updates: 132,158
Cumulative Timesteps: 1,100,375,972
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.79872
Policy Entropy: 4.37736
Value Function Loss: 0.00145
Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.00989
Policy Update Magnitude: 0.70876
Value Function Update Magnitude: 0.77318
Collected Steps per Second: 10,735.69953
Overall Steps per Second: 6,476.11518
Timestep Collection Time: 4.65941
Timestep Consumption Time: 3.06467
PPO Batch Consumption Time: 0.22946
Total Iteration Time: 7.72408
Cumulative Model Updates: 132,167
Cumulative Timesteps: 1,100,425,994
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1100425994...
Checkpoint 1100425994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.28472
Policy Entropy: 4.37961
Value Function Loss: 0.00147
Mean KL Divergence: 0.00120
SB3 Clip Fraction: 0.00933
Policy Update Magnitude: 0.71485
Value Function Update Magnitude: 0.77554
Collected Steps per Second: 11,467.61405
Overall Steps per Second: 6,579.66159
Timestep Collection Time: 4.36499
Timestep Consumption Time: 3.24270
PPO Batch Consumption Time: 0.23566
Total Iteration Time: 7.60769
Cumulative Model Updates: 132,176
Cumulative Timesteps: 1,100,476,050
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.51137
Policy Entropy: 4.38027
Value Function Loss: 0.00142
Mean KL Divergence: 0.00119
SB3 Clip Fraction: 0.00926
Policy Update Magnitude: 0.72651
Value Function Update Magnitude: 0.77754
Collected Steps per Second: 11,699.02791
Overall Steps per Second: 6,689.69525
Timestep Collection Time: 4.27711
Timestep Consumption Time: 3.20275
PPO Batch Consumption Time: 0.23476
Total Iteration Time: 7.47986
Cumulative Model Updates: 132,185
Cumulative Timesteps: 1,100,526,088
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1100526088...
Checkpoint 1100526088 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.94019
Policy Entropy: 4.38172
Value Function Loss: 0.00144
Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00850
Policy Update Magnitude: 0.71654
Value Function Update Magnitude: 0.76689
Collected Steps per Second: 12,325.11508
Overall Steps per Second: 6,953.73042
Timestep Collection Time: 4.06033
Timestep Consumption Time: 3.13639
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 7.19671
Cumulative Model Updates: 132,194
Cumulative Timesteps: 1,100,576,132
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09038
Policy Entropy: 4.38190
Value Function Loss: 0.00142
Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.00989
Policy Update Magnitude: 0.71900
Value Function Update Magnitude: 0.74876
Collected Steps per Second: 12,864.15709
Overall Steps per Second: 7,108.73858
Timestep Collection Time: 3.88972
Timestep Consumption Time: 3.14922
PPO Batch Consumption Time: 0.22946
Total Iteration Time: 7.03894
Cumulative Model Updates: 132,203
Cumulative Timesteps: 1,100,626,170
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1100626170...
Checkpoint 1100626170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.56063
Policy Entropy: 4.38412
Value Function Loss: 0.00143
Mean KL Divergence: 0.00114
SB3 Clip Fraction: 0.00914
Policy Update Magnitude: 0.72942
Value Function Update Magnitude: 0.70954
Collected Steps per Second: 12,826.80976
Overall Steps per Second: 7,224.82128
Timestep Collection Time: 3.89933
Timestep Consumption Time: 3.02347
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.92280
Cumulative Model Updates: 132,212
Cumulative Timesteps: 1,100,676,186
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.88994
Policy Entropy: 4.38216
Value Function Loss: 0.00144
Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00907
Policy Update Magnitude: 0.72359
Value Function Update Magnitude: 0.67804
Collected Steps per Second: 13,161.78159
Overall Steps per Second: 7,179.04939
Timestep Collection Time: 3.80161
Timestep Consumption Time: 3.16811
PPO Batch Consumption Time: 0.23021
Total Iteration Time: 6.96972
Cumulative Model Updates: 132,221
Cumulative Timesteps: 1,100,726,222
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1100726222...
Checkpoint 1100726222 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.69960
Policy Entropy: 4.38411
Value Function Loss: 0.00153
Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.00979
Policy Update Magnitude: 0.75251
Value Function Update Magnitude: 0.70543
Collected Steps per Second: 11,077.67659
Overall Steps per Second: 6,540.68700
Timestep Collection Time: 4.51629
Timestep Consumption Time: 3.13275
PPO Batch Consumption Time: 0.23090
Total Iteration Time: 7.64904
Cumulative Model Updates: 132,230
Cumulative Timesteps: 1,100,776,252
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.74535
Policy Entropy: 4.38522
Value Function Loss: 0.00157
Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.01003
Policy Update Magnitude: 0.76236
Value Function Update Magnitude: 0.73951
Collected Steps per Second: 12,182.20739
Overall Steps per Second: 6,980.18471
Timestep Collection Time: 4.10484
Timestep Consumption Time: 3.05915
PPO Batch Consumption Time: 0.22953
Total Iteration Time: 7.16399
Cumulative Model Updates: 132,239
Cumulative Timesteps: 1,100,826,258
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1100826258...
Checkpoint 1100826258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.83638
Policy Entropy: 4.38635
Value Function Loss: 0.00149
Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01046
Policy Update Magnitude: 0.75796
Value Function Update Magnitude: 0.74059
Collected Steps per Second: 12,948.01438
Overall Steps per Second: 7,024.91211
Timestep Collection Time: 3.86654
Timestep Consumption Time: 3.26010
PPO Batch Consumption Time: 0.23205
Total Iteration Time: 7.12664
Cumulative Model Updates: 132,248
Cumulative Timesteps: 1,100,876,322
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.54176
Policy Entropy: 4.38785
Value Function Loss: 0.00148
Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.01014
Policy Update Magnitude: 0.72988
Value Function Update Magnitude: 0.70889
Collected Steps per Second: 12,988.85718
Overall Steps per Second: 7,172.51851
Timestep Collection Time: 3.84992
Timestep Consumption Time: 3.12197
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.97189
Cumulative Model Updates: 132,257
Cumulative Timesteps: 1,100,926,328
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1100926328...
Checkpoint 1100926328 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.76405
Policy Entropy: 4.38665
Value Function Loss: 0.00146
Mean KL Divergence: 0.00116
SB3 Clip Fraction: 0.00907
Policy Update Magnitude: 0.71247
Value Function Update Magnitude: 0.69333
Collected Steps per Second: 13,417.91070
Overall Steps per Second: 7,278.14089
Timestep Collection Time: 3.72785
Timestep Consumption Time: 3.14478
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.87263
Cumulative Model Updates: 132,266
Cumulative Timesteps: 1,100,976,348
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.52833
Policy Entropy: 4.38876
Value Function Loss: 0.00158
Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01013
Policy Update Magnitude: 0.72188
Value Function Update Magnitude: 0.72478
Collected Steps per Second: 13,115.36354
Overall Steps per Second: 7,089.98292
Timestep Collection Time: 3.81324
Timestep Consumption Time: 3.24066
PPO Batch Consumption Time: 0.24103
Total Iteration Time: 7.05390
Cumulative Model Updates: 132,275
Cumulative Timesteps: 1,101,026,360
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1101026360...
Checkpoint 1101026360 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33943
Policy Entropy: 4.38884
Value Function Loss: 0.00164
Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01017
Policy Update Magnitude: 0.75515
Value Function Update Magnitude: 0.78190
Collected Steps per Second: 12,247.05159
Overall Steps per Second: 6,946.99559
Timestep Collection Time: 4.08670
Timestep Consumption Time: 3.11786
PPO Batch Consumption Time: 0.23545
Total Iteration Time: 7.20455
Cumulative Model Updates: 132,284
Cumulative Timesteps: 1,101,076,410
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.49125
Policy Entropy: 4.38790
Value Function Loss: 0.00171
Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01119
Policy Update Magnitude: 0.78398
Value Function Update Magnitude: 0.80052
Collected Steps per Second: 11,597.09311
Overall Steps per Second: 6,679.11914
Timestep Collection Time: 4.31401
Timestep Consumption Time: 3.17650
PPO Batch Consumption Time: 0.23005
Total Iteration Time: 7.49051
Cumulative Model Updates: 132,293
Cumulative Timesteps: 1,101,126,440
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1101126440...
Checkpoint 1101126440 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.67890
Policy Entropy: 4.38657
Value Function Loss: 0.00170
Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01176
Policy Update Magnitude: 0.78816
Value Function Update Magnitude: 0.79052
Collected Steps per Second: 12,302.72262
Overall Steps per Second: 6,957.87099
Timestep Collection Time: 4.06625
Timestep Consumption Time: 3.12359
PPO Batch Consumption Time: 0.23407
Total Iteration Time: 7.18984
Cumulative Model Updates: 132,302
Cumulative Timesteps: 1,101,176,466
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.61531
Policy Entropy: 4.38472
Value Function Loss: 0.00167
Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01176
Policy Update Magnitude: 0.77884
Value Function Update Magnitude: 0.76684
Collected Steps per Second: 11,522.71964
Overall Steps per Second: 6,480.07249
Timestep Collection Time: 4.34255
Timestep Consumption Time: 3.37928
PPO Batch Consumption Time: 0.24462
Total Iteration Time: 7.72183
Cumulative Model Updates: 132,311
Cumulative Timesteps: 1,101,226,504
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1101226504...
Checkpoint 1101226504 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.49476
Policy Entropy: 4.38638
Value Function Loss: 0.00169
Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01072
Policy Update Magnitude: 0.77939
Value Function Update Magnitude: 0.73909
Collected Steps per Second: 12,291.98689
Overall Steps per Second: 6,895.84211
Timestep Collection Time: 4.06899
Timestep Consumption Time: 3.18407
PPO Batch Consumption Time: 0.23473
Total Iteration Time: 7.25307
Cumulative Model Updates: 132,320
Cumulative Timesteps: 1,101,276,520
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.06971
Policy Entropy: 4.38600
Value Function Loss: 0.00175
Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01139
Policy Update Magnitude: 0.77819
Value Function Update Magnitude: 0.76836
Collected Steps per Second: 11,924.10330
Overall Steps per Second: 6,742.69920
Timestep Collection Time: 4.19486
Timestep Consumption Time: 3.22353
PPO Batch Consumption Time: 0.24294
Total Iteration Time: 7.41839
Cumulative Model Updates: 132,329
Cumulative Timesteps: 1,101,326,540
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1101326540...
Checkpoint 1101326540 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.15398
Policy Entropy: 4.38680
Value Function Loss: 0.00190
Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01160
Policy Update Magnitude: 0.79158
Value Function Update Magnitude: 0.81429
Collected Steps per Second: 12,040.12067
Overall Steps per Second: 6,837.63843
Timestep Collection Time: 4.15428
Timestep Consumption Time: 3.16082
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 7.31510
Cumulative Model Updates: 132,338
Cumulative Timesteps: 1,101,376,558
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.75903
Policy Entropy: 4.38564
Value Function Loss: 0.00187
Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01080
Policy Update Magnitude: 0.79948
Value Function Update Magnitude: 0.86317
Collected Steps per Second: 12,389.97928
Overall Steps per Second: 6,847.53272
Timestep Collection Time: 4.03972
Timestep Consumption Time: 3.26978
PPO Batch Consumption Time: 0.23722
Total Iteration Time: 7.30949
Cumulative Model Updates: 132,347
Cumulative Timesteps: 1,101,426,610
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1101426610...
Checkpoint 1101426610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.26732
Policy Entropy: 4.38729
Value Function Loss: 0.00192
Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01162
Policy Update Magnitude: 0.81200
Value Function Update Magnitude: 0.84413
Collected Steps per Second: 11,954.92109
Overall Steps per Second: 6,843.67142
Timestep Collection Time: 4.18539
Timestep Consumption Time: 3.12589
PPO Batch Consumption Time: 0.23585
Total Iteration Time: 7.31128
Cumulative Model Updates: 132,356
Cumulative Timesteps: 1,101,476,646
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.35834
Policy Entropy: 4.38618
Value Function Loss: 0.00188
Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01287
Policy Update Magnitude: 0.79974
Value Function Update Magnitude: 0.82876
Collected Steps per Second: 12,111.80044
Overall Steps per Second: 6,830.30249
Timestep Collection Time: 4.12936
Timestep Consumption Time: 3.19301
PPO Batch Consumption Time: 0.23707
Total Iteration Time: 7.32237
Cumulative Model Updates: 132,365
Cumulative Timesteps: 1,101,526,660
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1101526660...
Checkpoint 1101526660 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.68410
Policy Entropy: 4.38549
Value Function Loss: 0.00187
Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01246
Policy Update Magnitude: 0.79101
Value Function Update Magnitude: 0.84224
Collected Steps per Second: 12,086.50023
Overall Steps per Second: 6,807.55108
Timestep Collection Time: 4.13949
Timestep Consumption Time: 3.20999
PPO Batch Consumption Time: 0.23687
Total Iteration Time: 7.34949
Cumulative Model Updates: 132,374
Cumulative Timesteps: 1,101,576,692
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 2.93814
Policy Entropy: 4.38430
Value Function Loss: 0.00180
Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01217
Policy Update Magnitude: 0.78398
Value Function Update Magnitude: 0.84080
Collected Steps per Second: 12,600.03592
Overall Steps per Second: 7,075.83622
Timestep Collection Time: 3.97062
Timestep Consumption Time: 3.09992
PPO Batch Consumption Time: 0.23312
Total Iteration Time: 7.07054
Cumulative Model Updates: 132,383
Cumulative Timesteps: 1,101,626,722
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1101626722...
Checkpoint 1101626722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93787
Policy Entropy: 4.38306
Value Function Loss: 0.00180
Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01238
Policy Update Magnitude: 0.78225
Value Function Update Magnitude: 0.79619
Collected Steps per Second: 12,326.85762
Overall Steps per Second: 6,904.16263
Timestep Collection Time: 4.05829
Timestep Consumption Time: 3.18748
PPO Batch Consumption Time: 0.23533
Total Iteration Time: 7.24577
Cumulative Model Updates: 132,392
Cumulative Timesteps: 1,101,676,748
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76497
Policy Entropy: 4.38167
Value Function Loss: 0.00186
Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01362
Policy Update Magnitude: 0.77216
Value Function Update Magnitude: 0.80542
Collected Steps per Second: 12,691.74025
Overall Steps per Second: 7,104.63868
Timestep Collection Time: 3.94020
Timestep Consumption Time: 3.09858
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 7.03878
Cumulative Model Updates: 132,401
Cumulative Timesteps: 1,101,726,756
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1101726756...
Checkpoint 1101726756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.73776
Policy Entropy: 4.37874
Value Function Loss: 0.00195
Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01323
Policy Update Magnitude: 0.77617
Value Function Update Magnitude: 0.82457
Collected Steps per Second: 13,141.44826
Overall Steps per Second: 7,079.25369
Timestep Collection Time: 3.80765
Timestep Consumption Time: 3.26061
PPO Batch Consumption Time: 0.24236
Total Iteration Time: 7.06826
Cumulative Model Updates: 132,410
Cumulative Timesteps: 1,101,776,794
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.97721
Policy Entropy: 4.37895
Value Function Loss: 0.00195
Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01276
Policy Update Magnitude: 0.78964
Value Function Update Magnitude: 0.82774
Collected Steps per Second: 11,629.29361
Overall Steps per Second: 6,705.51678
Timestep Collection Time: 4.30104
Timestep Consumption Time: 3.15820
PPO Batch Consumption Time: 0.22964
Total Iteration Time: 7.45923
Cumulative Model Updates: 132,419
Cumulative Timesteps: 1,101,826,812
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1101826812...
Checkpoint 1101826812 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.63928
Policy Entropy: 4.37822
Value Function Loss: 0.00192
Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01283
Policy Update Magnitude: 0.78559
Value Function Update Magnitude: 0.80990
Collected Steps per Second: 12,744.05007
Overall Steps per Second: 7,195.58461
Timestep Collection Time: 3.92591
Timestep Consumption Time: 3.02724
PPO Batch Consumption Time: 0.22925
Total Iteration Time: 6.95315
Cumulative Model Updates: 132,428
Cumulative Timesteps: 1,101,876,844
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.86100
Policy Entropy: 4.37785
Value Function Loss: 0.00193
Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01204
Policy Update Magnitude: 0.79012
Value Function Update Magnitude: 0.82455
Collected Steps per Second: 12,916.86977
Overall Steps per Second: 7,088.31086
Timestep Collection Time: 3.87571
Timestep Consumption Time: 3.18691
PPO Batch Consumption Time: 0.23023
Total Iteration Time: 7.06261
Cumulative Model Updates: 132,437
Cumulative Timesteps: 1,101,926,906
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
Saving checkpoint 1101926906...
Checkpoint 1101926906 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.46193
Policy Entropy: 4.37366
Value Function Loss: 0.00196
Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01338
Policy Update Magnitude: 0.80890
Value Function Update Magnitude: 0.84947
Collected Steps per Second: 12,795.91612
Overall Steps per Second: 7,140.47131
Timestep Collection Time: 3.90750
Timestep Consumption Time: 3.09484
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 7.00234
Cumulative Model Updates: 132,446
Cumulative Timesteps: 1,101,976,906
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.93060
Policy Entropy: 4.37296
Value Function Loss: 0.00209
Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01370
Policy Update Magnitude: 0.82800
Value Function Update Magnitude: 0.87264
Collected Steps per Second: 12,934.26446
Overall Steps per Second: 7,141.62026
Timestep Collection Time: 3.86586
Timestep Consumption Time: 3.13564
PPO Batch Consumption Time: 0.24162
Total Iteration Time: 7.00149
Cumulative Model Updates: 132,455
Cumulative Timesteps: 1,102,026,908
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1102026908...
Checkpoint 1102026908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.85515
Policy Entropy: 4.37056
Value Function Loss: 0.00213
Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01449
Policy Update Magnitude: 0.83835
Value Function Update Magnitude: 0.87464
Collected Steps per Second: 11,958.61074
Overall Steps per Second: 6,818.53212
Timestep Collection Time: 4.18309
Timestep Consumption Time: 3.15338
PPO Batch Consumption Time: 0.23014
Total Iteration Time: 7.33648
Cumulative Model Updates: 132,464
Cumulative Timesteps: 1,102,076,932
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.17176
Policy Entropy: 4.36900
Value Function Loss: 0.00210
Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.82385
Value Function Update Magnitude: 0.85458
Collected Steps per Second: 12,208.14827
Overall Steps per Second: 6,845.60626
Timestep Collection Time: 4.09874
Timestep Consumption Time: 3.21077
PPO Batch Consumption Time: 0.23320
Total Iteration Time: 7.30951
Cumulative Model Updates: 132,473
Cumulative Timesteps: 1,102,126,970
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1102126970...
Checkpoint 1102126970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.74837
Policy Entropy: 4.36662
Value Function Loss: 0.00212
Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01812
Policy Update Magnitude: 0.81060
Value Function Update Magnitude: 0.82108
Collected Steps per Second: 11,995.91620
Overall Steps per Second: 6,790.04398
Timestep Collection Time: 4.16925
Timestep Consumption Time: 3.19653
PPO Batch Consumption Time: 0.23364
Total Iteration Time: 7.36578
Cumulative Model Updates: 132,482
Cumulative Timesteps: 1,102,176,984
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.23848
Policy Entropy: 4.36489
Value Function Loss: 0.00215
Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01791
Policy Update Magnitude: 0.81653
Value Function Update Magnitude: 0.81951
Collected Steps per Second: 11,366.34970
Overall Steps per Second: 6,535.61000
Timestep Collection Time: 4.40124
Timestep Consumption Time: 3.25314
PPO Batch Consumption Time: 0.23758
Total Iteration Time: 7.65437
Cumulative Model Updates: 132,491
Cumulative Timesteps: 1,102,227,010
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1102227010...
Checkpoint 1102227010 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93418
Policy Entropy: 4.36301
Value Function Loss: 0.00230
Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01770
Policy Update Magnitude: 0.84739
Value Function Update Magnitude: 0.84321
Collected Steps per Second: 11,808.71739
Overall Steps per Second: 6,754.04652
Timestep Collection Time: 4.23467
Timestep Consumption Time: 3.16919
PPO Batch Consumption Time: 0.23466
Total Iteration Time: 7.40386
Cumulative Model Updates: 132,500
Cumulative Timesteps: 1,102,277,016
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.30360
Policy Entropy: 4.35854
Value Function Loss: 0.00232
Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01865
Policy Update Magnitude: 0.87981
Value Function Update Magnitude: 0.91155
Collected Steps per Second: 12,613.18311
Overall Steps per Second: 6,951.08517
Timestep Collection Time: 3.96680
Timestep Consumption Time: 3.23121
PPO Batch Consumption Time: 0.23906
Total Iteration Time: 7.19801
Cumulative Model Updates: 132,509
Cumulative Timesteps: 1,102,327,050
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1102327050...
Checkpoint 1102327050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.16361
Policy Entropy: 4.35756
Value Function Loss: 0.00243
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02144
Policy Update Magnitude: 0.88079
Value Function Update Magnitude: 0.92986
Collected Steps per Second: 12,677.46126
Overall Steps per Second: 7,094.85385
Timestep Collection Time: 3.94448
Timestep Consumption Time: 3.10373
PPO Batch Consumption Time: 0.22930
Total Iteration Time: 7.04821
Cumulative Model Updates: 132,518
Cumulative Timesteps: 1,102,377,056
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.05951
Policy Entropy: 4.35523
Value Function Loss: 0.00247
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01997
Policy Update Magnitude: 0.88657
Value Function Update Magnitude: 0.95042
Collected Steps per Second: 12,505.17259
Overall Steps per Second: 7,050.90561
Timestep Collection Time: 4.00186
Timestep Consumption Time: 3.09566
PPO Batch Consumption Time: 0.23510
Total Iteration Time: 7.09753
Cumulative Model Updates: 132,527
Cumulative Timesteps: 1,102,427,100
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1102427100...
Checkpoint 1102427100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.99251
Policy Entropy: 4.35502
Value Function Loss: 0.00259
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02042
Policy Update Magnitude: 0.89164
Value Function Update Magnitude: 0.95063
Collected Steps per Second: 12,854.49165
Overall Steps per Second: 7,098.85054
Timestep Collection Time: 3.89047
Timestep Consumption Time: 3.15433
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 7.04480
Cumulative Model Updates: 132,536
Cumulative Timesteps: 1,102,477,110
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.54422
Policy Entropy: 4.35206
Value Function Loss: 0.00260
Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01923
Policy Update Magnitude: 0.88934
Value Function Update Magnitude: 0.91216
Collected Steps per Second: 12,644.08452
Overall Steps per Second: 7,155.06855
Timestep Collection Time: 3.95553
Timestep Consumption Time: 3.03448
PPO Batch Consumption Time: 0.23174
Total Iteration Time: 6.99001
Cumulative Model Updates: 132,545
Cumulative Timesteps: 1,102,527,124
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1102527124...
Checkpoint 1102527124 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 4.09162
Policy Entropy: 4.35077
Value Function Loss: 0.00266
Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01928
Policy Update Magnitude: 0.88946
Value Function Update Magnitude: 0.91315
Collected Steps per Second: 12,576.57169
Overall Steps per Second: 6,922.94808
Timestep Collection Time: 3.97660
Timestep Consumption Time: 3.24749
PPO Batch Consumption Time: 0.23678
Total Iteration Time: 7.22409
Cumulative Model Updates: 132,554
Cumulative Timesteps: 1,102,577,136
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.10037
Policy Entropy: 4.34756
Value Function Loss: 0.00264
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02134
Policy Update Magnitude: 0.88234
Value Function Update Magnitude: 0.92659
Collected Steps per Second: 12,859.16787
Overall Steps per Second: 7,090.52177
Timestep Collection Time: 3.88937
Timestep Consumption Time: 3.16428
PPO Batch Consumption Time: 0.23282
Total Iteration Time: 7.05364
Cumulative Model Updates: 132,563
Cumulative Timesteps: 1,102,627,150
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1102627150...
Checkpoint 1102627150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96419
Policy Entropy: 4.34736
Value Function Loss: 0.00265
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02221
Policy Update Magnitude: 0.88348
Value Function Update Magnitude: 0.92527
Collected Steps per Second: 12,479.33691
Overall Steps per Second: 7,089.39233
Timestep Collection Time: 4.00999
Timestep Consumption Time: 3.04873
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 7.05872
Cumulative Model Updates: 132,572
Cumulative Timesteps: 1,102,677,192
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.26649
Policy Entropy: 4.34445
Value Function Loss: 0.00274
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02152
Policy Update Magnitude: 0.90003
Value Function Update Magnitude: 0.94731
Collected Steps per Second: 11,330.09057
Overall Steps per Second: 6,630.48075
Timestep Collection Time: 4.41479
Timestep Consumption Time: 3.12916
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 7.54395
Cumulative Model Updates: 132,581
Cumulative Timesteps: 1,102,727,212
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1102727212...
Checkpoint 1102727212 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.08711
Policy Entropy: 4.34320
Value Function Loss: 0.00277
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.91681
Value Function Update Magnitude: 0.93483
Collected Steps per Second: 12,998.24280
Overall Steps per Second: 7,181.95244
Timestep Collection Time: 3.84714
Timestep Consumption Time: 3.11560
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.96273
Cumulative Model Updates: 132,590
Cumulative Timesteps: 1,102,777,218
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.89392
Policy Entropy: 4.33966
Value Function Loss: 0.00298
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.94158
Value Function Update Magnitude: 0.92922
Collected Steps per Second: 13,256.08595
Overall Steps per Second: 7,240.31148
Timestep Collection Time: 3.77261
Timestep Consumption Time: 3.13455
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.90716
Cumulative Model Updates: 132,599
Cumulative Timesteps: 1,102,827,228
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1102827228...
Checkpoint 1102827228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.18374
Policy Entropy: 4.33797
Value Function Loss: 0.00299
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02168
Policy Update Magnitude: 0.94932
Value Function Update Magnitude: 0.94559
Collected Steps per Second: 12,355.81385
Overall Steps per Second: 6,869.01525
Timestep Collection Time: 4.04911
Timestep Consumption Time: 3.23433
PPO Batch Consumption Time: 0.23557
Total Iteration Time: 7.28343
Cumulative Model Updates: 132,608
Cumulative Timesteps: 1,102,877,258
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.74173
Policy Entropy: 4.33208
Value Function Loss: 0.00316
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.95821
Value Function Update Magnitude: 0.94124
Collected Steps per Second: 12,011.26095
Overall Steps per Second: 6,876.05825
Timestep Collection Time: 4.16309
Timestep Consumption Time: 3.10910
PPO Batch Consumption Time: 0.23098
Total Iteration Time: 7.27219
Cumulative Model Updates: 132,617
Cumulative Timesteps: 1,102,927,262
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1102927262...
Checkpoint 1102927262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.79535
Policy Entropy: 4.33414
Value Function Loss: 0.00304
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.96548
Value Function Update Magnitude: 0.94626
Collected Steps per Second: 11,946.68630
Overall Steps per Second: 6,808.31865
Timestep Collection Time: 4.18560
Timestep Consumption Time: 3.15895
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 7.34454
Cumulative Model Updates: 132,626
Cumulative Timesteps: 1,102,977,266
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.21226
Policy Entropy: 4.32988
Value Function Loss: 0.00297
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.96017
Value Function Update Magnitude: 0.96206
Collected Steps per Second: 12,952.43030
Overall Steps per Second: 7,159.08835
Timestep Collection Time: 3.86151
Timestep Consumption Time: 3.12485
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.98636
Cumulative Model Updates: 132,635
Cumulative Timesteps: 1,103,027,282
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1103027282...
Checkpoint 1103027282 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.56879
Policy Entropy: 4.33002
Value Function Loss: 0.00292
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.95337
Value Function Update Magnitude: 0.98574
Collected Steps per Second: 13,144.25482
Overall Steps per Second: 7,206.85265
Timestep Collection Time: 3.80501
Timestep Consumption Time: 3.13478
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.93978
Cumulative Model Updates: 132,644
Cumulative Timesteps: 1,103,077,296
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64101
Policy Entropy: 4.32690
Value Function Loss: 0.00292
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.95480
Value Function Update Magnitude: 0.96058
Collected Steps per Second: 13,030.71514
Overall Steps per Second: 7,173.45077
Timestep Collection Time: 3.83939
Timestep Consumption Time: 3.13494
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.97433
Cumulative Model Updates: 132,653
Cumulative Timesteps: 1,103,127,326
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1103127326...
Checkpoint 1103127326 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.31472
Policy Entropy: 4.32721
Value Function Loss: 0.00301
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02250
Policy Update Magnitude: 0.96333
Value Function Update Magnitude: 0.95970
Collected Steps per Second: 12,898.26834
Overall Steps per Second: 7,148.34916
Timestep Collection Time: 3.87711
Timestep Consumption Time: 3.11863
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.99574
Cumulative Model Updates: 132,662
Cumulative Timesteps: 1,103,177,334
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.30218
Policy Entropy: 4.32768
Value Function Loss: 0.00298
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.96156
Value Function Update Magnitude: 0.96690
Collected Steps per Second: 12,827.87025
Overall Steps per Second: 6,998.99870
Timestep Collection Time: 3.89995
Timestep Consumption Time: 3.24793
PPO Batch Consumption Time: 0.23118
Total Iteration Time: 7.14788
Cumulative Model Updates: 132,671
Cumulative Timesteps: 1,103,227,362
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1103227362...
Checkpoint 1103227362 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.63089
Policy Entropy: 4.32820
Value Function Loss: 0.00296
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02302
Policy Update Magnitude: 0.95658
Value Function Update Magnitude: 0.95186
Collected Steps per Second: 11,683.01923
Overall Steps per Second: 6,616.00852
Timestep Collection Time: 4.28468
Timestep Consumption Time: 3.28151
PPO Batch Consumption Time: 0.23735
Total Iteration Time: 7.56619
Cumulative Model Updates: 132,680
Cumulative Timesteps: 1,103,277,420
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.19619
Policy Entropy: 4.32664
Value Function Loss: 0.00288
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.95283
Value Function Update Magnitude: 0.96351
Collected Steps per Second: 12,414.33412
Overall Steps per Second: 7,015.62007
Timestep Collection Time: 4.02970
Timestep Consumption Time: 3.10096
PPO Batch Consumption Time: 0.23466
Total Iteration Time: 7.13066
Cumulative Model Updates: 132,689
Cumulative Timesteps: 1,103,327,446
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1103327446...
Checkpoint 1103327446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.83188
Policy Entropy: 4.32410
Value Function Loss: 0.00294
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.94635
Value Function Update Magnitude: 0.94998
Collected Steps per Second: 11,598.38321
Overall Steps per Second: 6,686.91596
Timestep Collection Time: 4.31560
Timestep Consumption Time: 3.16976
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 7.48536
Cumulative Model Updates: 132,698
Cumulative Timesteps: 1,103,377,500
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65986
Policy Entropy: 4.31894
Value Function Loss: 0.00303
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.95047
Value Function Update Magnitude: 0.96264
Collected Steps per Second: 12,731.26947
Overall Steps per Second: 6,935.09262
Timestep Collection Time: 3.92797
Timestep Consumption Time: 3.28290
PPO Batch Consumption Time: 0.23035
Total Iteration Time: 7.21086
Cumulative Model Updates: 132,707
Cumulative Timesteps: 1,103,427,508
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1103427508...
Checkpoint 1103427508 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.08588
Policy Entropy: 4.31758
Value Function Loss: 0.00300
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.95678
Value Function Update Magnitude: 0.96218
Collected Steps per Second: 13,159.09708
Overall Steps per Second: 7,211.15333
Timestep Collection Time: 3.80178
Timestep Consumption Time: 3.13581
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.93759
Cumulative Model Updates: 132,716
Cumulative Timesteps: 1,103,477,536
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.14459
Policy Entropy: 4.31869
Value Function Loss: 0.00291
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.95681
Value Function Update Magnitude: 0.96412
Collected Steps per Second: 12,948.31583
Overall Steps per Second: 7,119.06652
Timestep Collection Time: 3.86444
Timestep Consumption Time: 3.16429
PPO Batch Consumption Time: 0.22944
Total Iteration Time: 7.02873
Cumulative Model Updates: 132,725
Cumulative Timesteps: 1,103,527,574
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1103527574...
Checkpoint 1103527574 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.90087
Policy Entropy: 4.31695
Value Function Loss: 0.00289
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.95544
Value Function Update Magnitude: 0.97543
Collected Steps per Second: 12,874.04285
Overall Steps per Second: 7,150.89966
Timestep Collection Time: 3.88689
Timestep Consumption Time: 3.11083
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.99772
Cumulative Model Updates: 132,734
Cumulative Timesteps: 1,103,577,614
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.87190
Policy Entropy: 4.32118
Value Function Loss: 0.00291
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02255
Policy Update Magnitude: 0.95826
Value Function Update Magnitude: 0.96676
Collected Steps per Second: 13,130.05683
Overall Steps per Second: 7,092.49271
Timestep Collection Time: 3.80851
Timestep Consumption Time: 3.24204
PPO Batch Consumption Time: 0.23820
Total Iteration Time: 7.05055
Cumulative Model Updates: 132,743
Cumulative Timesteps: 1,103,627,620
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1103627620...
Checkpoint 1103627620 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.32597
Policy Entropy: 4.31530
Value Function Loss: 0.00299
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02201
Policy Update Magnitude: 0.94789
Value Function Update Magnitude: 0.96301
Collected Steps per Second: 12,941.96058
Overall Steps per Second: 7,136.02517
Timestep Collection Time: 3.86649
Timestep Consumption Time: 3.14581
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 7.01231
Cumulative Model Updates: 132,752
Cumulative Timesteps: 1,103,677,660
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.84652
Policy Entropy: 4.31777
Value Function Loss: 0.00303
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.93269
Value Function Update Magnitude: 0.94728
Collected Steps per Second: 12,832.92620
Overall Steps per Second: 7,214.56823
Timestep Collection Time: 3.89654
Timestep Consumption Time: 3.03444
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.93098
Cumulative Model Updates: 132,761
Cumulative Timesteps: 1,103,727,664
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1103727664...
Checkpoint 1103727664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.85449
Policy Entropy: 4.31023
Value Function Loss: 0.00318
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.92061
Value Function Update Magnitude: 0.97564
Collected Steps per Second: 12,955.21462
Overall Steps per Second: 7,139.15574
Timestep Collection Time: 3.86130
Timestep Consumption Time: 3.14569
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 7.00699
Cumulative Model Updates: 132,770
Cumulative Timesteps: 1,103,777,688
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.66009
Policy Entropy: 4.30858
Value Function Loss: 0.00330
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.93668
Value Function Update Magnitude: 1.00980
Collected Steps per Second: 12,951.88254
Overall Steps per Second: 7,167.88503
Timestep Collection Time: 3.86245
Timestep Consumption Time: 3.11674
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.97919
Cumulative Model Updates: 132,779
Cumulative Timesteps: 1,103,827,714
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1103827714...
Checkpoint 1103827714 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.80847
Policy Entropy: 4.30937
Value Function Loss: 0.00331
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02922
Policy Update Magnitude: 0.94840
Value Function Update Magnitude: 1.01144
Collected Steps per Second: 13,297.18659
Overall Steps per Second: 7,255.81830
Timestep Collection Time: 3.76200
Timestep Consumption Time: 3.13233
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.89433
Cumulative Model Updates: 132,788
Cumulative Timesteps: 1,103,877,738
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.48789
Policy Entropy: 4.31459
Value Function Loss: 0.00322
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.94767
Value Function Update Magnitude: 1.00893
Collected Steps per Second: 12,790.81415
Overall Steps per Second: 7,074.76284
Timestep Collection Time: 3.90952
Timestep Consumption Time: 3.15870
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 7.06822
Cumulative Model Updates: 132,797
Cumulative Timesteps: 1,103,927,744
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1103927744...
Checkpoint 1103927744 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.26712
Policy Entropy: 4.31422
Value Function Loss: 0.00315
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02383
Policy Update Magnitude: 0.94060
Value Function Update Magnitude: 1.00398
Collected Steps per Second: 12,909.65794
Overall Steps per Second: 7,062.59040
Timestep Collection Time: 3.87570
Timestep Consumption Time: 3.20867
PPO Batch Consumption Time: 0.23760
Total Iteration Time: 7.08437
Cumulative Model Updates: 132,806
Cumulative Timesteps: 1,103,977,778
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.91744
Policy Entropy: 4.30543
Value Function Loss: 0.00327
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.93343
Value Function Update Magnitude: 1.00954
Collected Steps per Second: 13,248.35773
Overall Steps per Second: 7,237.57566
Timestep Collection Time: 3.77556
Timestep Consumption Time: 3.13559
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.91115
Cumulative Model Updates: 132,815
Cumulative Timesteps: 1,104,027,798
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1104027798...
Checkpoint 1104027798 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.89437
Policy Entropy: 4.29957
Value Function Loss: 0.00351
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.94707
Value Function Update Magnitude: 1.04934
Collected Steps per Second: 12,681.98999
Overall Steps per Second: 7,064.81850
Timestep Collection Time: 3.94591
Timestep Consumption Time: 3.13736
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 7.08327
Cumulative Model Updates: 132,824
Cumulative Timesteps: 1,104,077,840
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.90015
Policy Entropy: 4.30064
Value Function Loss: 0.00349
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02479
Policy Update Magnitude: 0.96423
Value Function Update Magnitude: 1.06366
Collected Steps per Second: 12,906.25769
Overall Steps per Second: 7,238.29091
Timestep Collection Time: 3.87409
Timestep Consumption Time: 3.03362
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.90771
Cumulative Model Updates: 132,833
Cumulative Timesteps: 1,104,127,840
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1104127840...
Checkpoint 1104127840 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.86373
Policy Entropy: 4.30625
Value Function Loss: 0.00337
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.95065
Value Function Update Magnitude: 1.01590
Collected Steps per Second: 12,798.02258
Overall Steps per Second: 7,110.19000
Timestep Collection Time: 3.90779
Timestep Consumption Time: 3.12606
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 7.03385
Cumulative Model Updates: 132,842
Cumulative Timesteps: 1,104,177,852
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.44756
Policy Entropy: 4.31000
Value Function Loss: 0.00321
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02254
Policy Update Magnitude: 0.92828
Value Function Update Magnitude: 0.96845
Collected Steps per Second: 12,999.91346
Overall Steps per Second: 7,215.62952
Timestep Collection Time: 3.84895
Timestep Consumption Time: 3.08544
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.93439
Cumulative Model Updates: 132,851
Cumulative Timesteps: 1,104,227,888
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1104227888...
Checkpoint 1104227888 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.32689
Policy Entropy: 4.30951
Value Function Loss: 0.00335
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.92903
Value Function Update Magnitude: 0.92735
Collected Steps per Second: 13,233.39131
Overall Steps per Second: 7,230.03089
Timestep Collection Time: 3.78165
Timestep Consumption Time: 3.14004
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.92169
Cumulative Model Updates: 132,860
Cumulative Timesteps: 1,104,277,932
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.76701
Policy Entropy: 4.30885
Value Function Loss: 0.00334
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.93475
Value Function Update Magnitude: 0.93405
Collected Steps per Second: 12,798.57313
Overall Steps per Second: 6,982.21644
Timestep Collection Time: 3.90762
Timestep Consumption Time: 3.25515
PPO Batch Consumption Time: 0.23894
Total Iteration Time: 7.16277
Cumulative Model Updates: 132,869
Cumulative Timesteps: 1,104,327,944
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1104327944...
Checkpoint 1104327944 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.26047
Policy Entropy: 4.30915
Value Function Loss: 0.00336
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02430
Policy Update Magnitude: 0.94295
Value Function Update Magnitude: 0.92433
Collected Steps per Second: 12,928.19743
Overall Steps per Second: 7,175.31060
Timestep Collection Time: 3.86860
Timestep Consumption Time: 3.10169
PPO Batch Consumption Time: 0.22955
Total Iteration Time: 6.97029
Cumulative Model Updates: 132,878
Cumulative Timesteps: 1,104,377,958
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.08864
Policy Entropy: 4.30812
Value Function Loss: 0.00321
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.94244
Value Function Update Magnitude: 0.87793
Collected Steps per Second: 13,146.59831
Overall Steps per Second: 7,218.28439
Timestep Collection Time: 3.80570
Timestep Consumption Time: 3.12559
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.93129
Cumulative Model Updates: 132,887
Cumulative Timesteps: 1,104,427,990
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1104427990...
Checkpoint 1104427990 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85870
Policy Entropy: 4.30279
Value Function Loss: 0.00336
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.94956
Value Function Update Magnitude: 0.92572
Collected Steps per Second: 12,986.74802
Overall Steps per Second: 7,141.66229
Timestep Collection Time: 3.85254
Timestep Consumption Time: 3.15311
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 7.00565
Cumulative Model Updates: 132,896
Cumulative Timesteps: 1,104,478,022
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.42640
Policy Entropy: 4.29878
Value Function Loss: 0.00345
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.96768
Value Function Update Magnitude: 0.95594
Collected Steps per Second: 13,011.52558
Overall Steps per Second: 7,251.61837
Timestep Collection Time: 3.84536
Timestep Consumption Time: 3.05434
PPO Batch Consumption Time: 0.22916
Total Iteration Time: 6.89970
Cumulative Model Updates: 132,905
Cumulative Timesteps: 1,104,528,056
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1104528056...
Checkpoint 1104528056 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.18807
Policy Entropy: 4.29740
Value Function Loss: 0.00360
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02412
Policy Update Magnitude: 0.97218
Value Function Update Magnitude: 0.96198
Collected Steps per Second: 12,775.45511
Overall Steps per Second: 7,086.32699
Timestep Collection Time: 3.91657
Timestep Consumption Time: 3.14435
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 7.06092
Cumulative Model Updates: 132,914
Cumulative Timesteps: 1,104,578,092
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.66300
Policy Entropy: 4.30040
Value Function Loss: 0.00350
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.95282
Value Function Update Magnitude: 0.95178
Collected Steps per Second: 13,153.71664
Overall Steps per Second: 7,235.35077
Timestep Collection Time: 3.80273
Timestep Consumption Time: 3.11055
PPO Batch Consumption Time: 0.22921
Total Iteration Time: 6.91328
Cumulative Model Updates: 132,923
Cumulative Timesteps: 1,104,628,112
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1104628112...
Checkpoint 1104628112 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.01992
Policy Entropy: 4.29915
Value Function Loss: 0.00345
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.95062
Value Function Update Magnitude: 0.95295
Collected Steps per Second: 13,127.58442
Overall Steps per Second: 7,049.15133
Timestep Collection Time: 3.81197
Timestep Consumption Time: 3.28704
PPO Batch Consumption Time: 0.24088
Total Iteration Time: 7.09901
Cumulative Model Updates: 132,932
Cumulative Timesteps: 1,104,678,154
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.84672
Policy Entropy: 4.30093
Value Function Loss: 0.00335
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.95223
Value Function Update Magnitude: 0.94667
Collected Steps per Second: 12,920.76290
Overall Steps per Second: 7,153.58644
Timestep Collection Time: 3.87330
Timestep Consumption Time: 3.12263
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.99593
Cumulative Model Updates: 132,941
Cumulative Timesteps: 1,104,728,200
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1104728200...
Checkpoint 1104728200 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.70934
Policy Entropy: 4.29656
Value Function Loss: 0.00328
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02244
Policy Update Magnitude: 0.94606
Value Function Update Magnitude: 0.95323
Collected Steps per Second: 12,500.50032
Overall Steps per Second: 7,001.61435
Timestep Collection Time: 4.00240
Timestep Consumption Time: 3.14338
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 7.14578
Cumulative Model Updates: 132,950
Cumulative Timesteps: 1,104,778,232
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.25064
Policy Entropy: 4.29811
Value Function Loss: 0.00312
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02187
Policy Update Magnitude: 0.94105
Value Function Update Magnitude: 0.94418
Collected Steps per Second: 13,116.53215
Overall Steps per Second: 7,203.35320
Timestep Collection Time: 3.81336
Timestep Consumption Time: 3.13036
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.94371
Cumulative Model Updates: 132,959
Cumulative Timesteps: 1,104,828,250
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1104828250...
Checkpoint 1104828250 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.50551
Policy Entropy: 4.29310
Value Function Loss: 0.00325
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02270
Policy Update Magnitude: 0.94079
Value Function Update Magnitude: 0.94038
Collected Steps per Second: 12,807.11580
Overall Steps per Second: 7,102.89733
Timestep Collection Time: 3.90424
Timestep Consumption Time: 3.13543
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 7.03966
Cumulative Model Updates: 132,968
Cumulative Timesteps: 1,104,878,252
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.42464
Policy Entropy: 4.29526
Value Function Loss: 0.00322
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.93856
Value Function Update Magnitude: 0.95244
Collected Steps per Second: 12,906.15307
Overall Steps per Second: 7,232.71156
Timestep Collection Time: 3.87459
Timestep Consumption Time: 3.03928
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 6.91387
Cumulative Model Updates: 132,977
Cumulative Timesteps: 1,104,928,258
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1104928258...
Checkpoint 1104928258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.48803
Policy Entropy: 4.29268
Value Function Loss: 0.00327
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.95626
Value Function Update Magnitude: 0.92397
Collected Steps per Second: 12,969.49054
Overall Steps per Second: 7,134.91407
Timestep Collection Time: 3.85813
Timestep Consumption Time: 3.15499
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 7.01312
Cumulative Model Updates: 132,986
Cumulative Timesteps: 1,104,978,296
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.97457
Policy Entropy: 4.29323
Value Function Loss: 0.00323
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.96901
Value Function Update Magnitude: 0.94496
Collected Steps per Second: 12,783.86102
Overall Steps per Second: 6,968.10392
Timestep Collection Time: 3.91368
Timestep Consumption Time: 3.26646
PPO Batch Consumption Time: 0.24051
Total Iteration Time: 7.18015
Cumulative Model Updates: 132,995
Cumulative Timesteps: 1,105,028,328
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1105028328...
Checkpoint 1105028328 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.43902
Policy Entropy: 4.29216
Value Function Loss: 0.00331
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.97549
Value Function Update Magnitude: 0.96615
Collected Steps per Second: 12,925.55436
Overall Steps per Second: 7,239.21646
Timestep Collection Time: 3.86908
Timestep Consumption Time: 3.03913
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.90821
Cumulative Model Updates: 133,004
Cumulative Timesteps: 1,105,078,338
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.52898
Policy Entropy: 4.29097
Value Function Loss: 0.00344
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02075
Policy Update Magnitude: 0.98399
Value Function Update Magnitude: 0.96316
Collected Steps per Second: 12,825.98426
Overall Steps per Second: 7,101.06064
Timestep Collection Time: 3.89974
Timestep Consumption Time: 3.14400
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 7.04374
Cumulative Model Updates: 133,013
Cumulative Timesteps: 1,105,128,356
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1105128356...
Checkpoint 1105128356 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.91533
Policy Entropy: 4.29192
Value Function Loss: 0.00344
Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.01930
Policy Update Magnitude: 0.97637
Value Function Update Magnitude: 0.96136
Collected Steps per Second: 12,928.18471
Overall Steps per Second: 7,187.47320
Timestep Collection Time: 3.86783
Timestep Consumption Time: 3.08928
PPO Batch Consumption Time: 0.22797
Total Iteration Time: 6.95710
Cumulative Model Updates: 133,022
Cumulative Timesteps: 1,105,178,360
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.17764
Policy Entropy: 4.29176
Value Function Loss: 0.00342
Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02083
Policy Update Magnitude: 0.96164
Value Function Update Magnitude: 0.95584
Collected Steps per Second: 12,949.98251
Overall Steps per Second: 7,130.21970
Timestep Collection Time: 3.86302
Timestep Consumption Time: 3.15304
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 7.01605
Cumulative Model Updates: 133,031
Cumulative Timesteps: 1,105,228,386
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1105228386...
Checkpoint 1105228386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.58458
Policy Entropy: 4.29308
Value Function Loss: 0.00329
Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02168
Policy Update Magnitude: 0.96312
Value Function Update Magnitude: 0.94433
Collected Steps per Second: 12,923.63759
Overall Steps per Second: 7,112.15453
Timestep Collection Time: 3.86981
Timestep Consumption Time: 3.16210
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 7.03191
Cumulative Model Updates: 133,040
Cumulative Timesteps: 1,105,278,398
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.37327
Policy Entropy: 4.28874
Value Function Loss: 0.00325
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02261
Policy Update Magnitude: 0.96263
Value Function Update Magnitude: 0.94985
Collected Steps per Second: 12,997.37063
Overall Steps per Second: 7,275.43458
Timestep Collection Time: 3.84709
Timestep Consumption Time: 3.02563
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.87272
Cumulative Model Updates: 133,049
Cumulative Timesteps: 1,105,328,400
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1105328400...
Checkpoint 1105328400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.05511
Policy Entropy: 4.28641
Value Function Loss: 0.00333
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02293
Policy Update Magnitude: 0.95901
Value Function Update Magnitude: 0.93298
Collected Steps per Second: 13,018.91002
Overall Steps per Second: 7,027.91601
Timestep Collection Time: 3.84333
Timestep Consumption Time: 3.27627
PPO Batch Consumption Time: 0.23846
Total Iteration Time: 7.11961
Cumulative Model Updates: 133,058
Cumulative Timesteps: 1,105,378,436
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.96412
Policy Entropy: 4.28551
Value Function Loss: 0.00328
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02327
Policy Update Magnitude: 0.95491
Value Function Update Magnitude: 0.92521
Collected Steps per Second: 12,858.72370
Overall Steps per Second: 7,138.79912
Timestep Collection Time: 3.88888
Timestep Consumption Time: 3.11594
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 7.00482
Cumulative Model Updates: 133,067
Cumulative Timesteps: 1,105,428,442
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1105428442...
Checkpoint 1105428442 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.28749
Policy Entropy: 4.28877
Value Function Loss: 0.00339
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02127
Policy Update Magnitude: 0.96029
Value Function Update Magnitude: 0.94673
Collected Steps per Second: 13,365.41975
Overall Steps per Second: 7,252.71974
Timestep Collection Time: 3.74190
Timestep Consumption Time: 3.15372
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.89562
Cumulative Model Updates: 133,076
Cumulative Timesteps: 1,105,478,454
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.20286
Policy Entropy: 4.29476
Value Function Loss: 0.00336
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.95565
Value Function Update Magnitude: 0.91469
Collected Steps per Second: 12,914.93277
Overall Steps per Second: 7,118.11789
Timestep Collection Time: 3.87164
Timestep Consumption Time: 3.15297
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 7.02461
Cumulative Model Updates: 133,085
Cumulative Timesteps: 1,105,528,456
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1105528456...
Checkpoint 1105528456 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.07568
Policy Entropy: 4.29461
Value Function Loss: 0.00332
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.95475
Value Function Update Magnitude: 0.89735
Collected Steps per Second: 12,823.08070
Overall Steps per Second: 7,137.37950
Timestep Collection Time: 3.90125
Timestep Consumption Time: 3.10777
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 7.00901
Cumulative Model Updates: 133,094
Cumulative Timesteps: 1,105,578,482
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.36017
Policy Entropy: 4.29438
Value Function Loss: 0.00322
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.93139
Value Function Update Magnitude: 0.86949
Collected Steps per Second: 11,304.97214
Overall Steps per Second: 6,564.56389
Timestep Collection Time: 4.42336
Timestep Consumption Time: 3.19420
PPO Batch Consumption Time: 0.23481
Total Iteration Time: 7.61757
Cumulative Model Updates: 133,103
Cumulative Timesteps: 1,105,628,488
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1105628488...
Checkpoint 1105628488 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.66765
Policy Entropy: 4.29336
Value Function Loss: 0.00316
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02305
Policy Update Magnitude: 0.91314
Value Function Update Magnitude: 0.82600
Collected Steps per Second: 11,764.30843
Overall Steps per Second: 6,702.49264
Timestep Collection Time: 4.25065
Timestep Consumption Time: 3.21015
PPO Batch Consumption Time: 0.23405
Total Iteration Time: 7.46081
Cumulative Model Updates: 133,112
Cumulative Timesteps: 1,105,678,494
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25150
Policy Entropy: 4.29431
Value Function Loss: 0.00322
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02272
Policy Update Magnitude: 0.90342
Value Function Update Magnitude: 0.82047
Collected Steps per Second: 12,543.89593
Overall Steps per Second: 7,112.52255
Timestep Collection Time: 3.98855
Timestep Consumption Time: 3.04580
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 7.03435
Cumulative Model Updates: 133,121
Cumulative Timesteps: 1,105,728,526
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1105728526...
Checkpoint 1105728526 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.87686
Policy Entropy: 4.29637
Value Function Loss: 0.00322
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02352
Policy Update Magnitude: 0.89944
Value Function Update Magnitude: 0.83398
Collected Steps per Second: 12,769.34426
Overall Steps per Second: 7,085.72087
Timestep Collection Time: 3.91845
Timestep Consumption Time: 3.14308
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 7.06153
Cumulative Model Updates: 133,130
Cumulative Timesteps: 1,105,778,562
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.91251
Policy Entropy: 4.29409
Value Function Loss: 0.00331
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.90294
Value Function Update Magnitude: 0.84813
Collected Steps per Second: 12,974.91484
Overall Steps per Second: 7,174.72382
Timestep Collection Time: 3.85698
Timestep Consumption Time: 3.11806
PPO Batch Consumption Time: 0.22945
Total Iteration Time: 6.97504
Cumulative Model Updates: 133,139
Cumulative Timesteps: 1,105,828,606
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1105828606...
Checkpoint 1105828606 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.59078
Policy Entropy: 4.29216
Value Function Loss: 0.00333
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.92108
Value Function Update Magnitude: 0.82233
Collected Steps per Second: 13,059.68512
Overall Steps per Second: 7,214.43463
Timestep Collection Time: 3.82919
Timestep Consumption Time: 3.10247
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.93166
Cumulative Model Updates: 133,148
Cumulative Timesteps: 1,105,878,614
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.21532
Policy Entropy: 4.28748
Value Function Loss: 0.00347
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02184
Policy Update Magnitude: 0.94850
Value Function Update Magnitude: 0.82468
Collected Steps per Second: 12,966.28434
Overall Steps per Second: 7,145.04955
Timestep Collection Time: 3.85939
Timestep Consumption Time: 3.14434
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 7.00373
Cumulative Model Updates: 133,157
Cumulative Timesteps: 1,105,928,656
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1105928656...
Checkpoint 1105928656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.46808
Policy Entropy: 4.28848
Value Function Loss: 0.00343
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.95241
Value Function Update Magnitude: 0.84597
Collected Steps per Second: 13,057.36751
Overall Steps per Second: 7,204.80411
Timestep Collection Time: 3.83017
Timestep Consumption Time: 3.11130
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.94148
Cumulative Model Updates: 133,166
Cumulative Timesteps: 1,105,978,668
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.63184
Policy Entropy: 4.28872
Value Function Loss: 0.00350
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.95365
Value Function Update Magnitude: 0.86762
Collected Steps per Second: 13,229.06302
Overall Steps per Second: 7,090.60119
Timestep Collection Time: 3.78016
Timestep Consumption Time: 3.27255
PPO Batch Consumption Time: 0.24069
Total Iteration Time: 7.05272
Cumulative Model Updates: 133,175
Cumulative Timesteps: 1,106,028,676
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1106028676...
Checkpoint 1106028676 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.99808
Policy Entropy: 4.29137
Value Function Loss: 0.00352
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.95025
Value Function Update Magnitude: 0.86381
Collected Steps per Second: 13,004.52915
Overall Steps per Second: 7,152.99412
Timestep Collection Time: 3.84743
Timestep Consumption Time: 3.14740
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.99483
Cumulative Model Updates: 133,184
Cumulative Timesteps: 1,106,078,710
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.18875
Policy Entropy: 4.28968
Value Function Loss: 0.00347
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.95357
Value Function Update Magnitude: 0.86795
Collected Steps per Second: 13,097.29380
Overall Steps per Second: 7,299.89361
Timestep Collection Time: 3.82079
Timestep Consumption Time: 3.03438
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.85517
Cumulative Model Updates: 133,193
Cumulative Timesteps: 1,106,128,752
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1106128752...
Checkpoint 1106128752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.43930
Policy Entropy: 4.29018
Value Function Loss: 0.00351
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.94735
Value Function Update Magnitude: 0.87464
Collected Steps per Second: 13,057.44183
Overall Steps per Second: 7,212.06118
Timestep Collection Time: 3.83015
Timestep Consumption Time: 3.10434
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.93449
Cumulative Model Updates: 133,202
Cumulative Timesteps: 1,106,178,764
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.59952
Policy Entropy: 4.28931
Value Function Loss: 0.00357
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.95969
Value Function Update Magnitude: 0.88858
Collected Steps per Second: 13,024.68450
Overall Steps per Second: 7,225.95186
Timestep Collection Time: 3.84286
Timestep Consumption Time: 3.08384
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.92670
Cumulative Model Updates: 133,211
Cumulative Timesteps: 1,106,228,816
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1106228816...
Checkpoint 1106228816 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.73037
Policy Entropy: 4.29275
Value Function Loss: 0.00359
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.97196
Value Function Update Magnitude: 0.92375
Collected Steps per Second: 12,930.37415
Overall Steps per Second: 7,171.09914
Timestep Collection Time: 3.86949
Timestep Consumption Time: 3.10768
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.97717
Cumulative Model Updates: 133,220
Cumulative Timesteps: 1,106,278,850
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.39820
Policy Entropy: 4.29389
Value Function Loss: 0.00349
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02842
Policy Update Magnitude: 0.95937
Value Function Update Magnitude: 0.90419
Collected Steps per Second: 13,085.80451
Overall Steps per Second: 7,172.83662
Timestep Collection Time: 3.82399
Timestep Consumption Time: 3.15233
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.97632
Cumulative Model Updates: 133,229
Cumulative Timesteps: 1,106,328,890
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1106328890...
Checkpoint 1106328890 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.53006
Policy Entropy: 4.29407
Value Function Loss: 0.00335
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.92937
Value Function Update Magnitude: 0.88624
Collected Steps per Second: 12,898.61811
Overall Steps per Second: 7,083.92961
Timestep Collection Time: 3.87654
Timestep Consumption Time: 3.18197
PPO Batch Consumption Time: 0.23365
Total Iteration Time: 7.05851
Cumulative Model Updates: 133,238
Cumulative Timesteps: 1,106,378,892
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.73827
Policy Entropy: 4.28994
Value Function Loss: 0.00333
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.90574
Value Function Update Magnitude: 0.84751
Collected Steps per Second: 13,248.52540
Overall Steps per Second: 7,236.33885
Timestep Collection Time: 3.77672
Timestep Consumption Time: 3.13782
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.91455
Cumulative Model Updates: 133,247
Cumulative Timesteps: 1,106,428,928
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1106428928...
Checkpoint 1106428928 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.01537
Policy Entropy: 4.28927
Value Function Loss: 0.00317
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.89961
Value Function Update Magnitude: 0.83480
Collected Steps per Second: 12,976.69530
Overall Steps per Second: 7,120.95709
Timestep Collection Time: 3.85368
Timestep Consumption Time: 3.16897
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 7.02265
Cumulative Model Updates: 133,256
Cumulative Timesteps: 1,106,478,936
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.00076
Policy Entropy: 4.29330
Value Function Loss: 0.00306
Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02221
Policy Update Magnitude: 0.91015
Value Function Update Magnitude: 0.83978
Collected Steps per Second: 13,075.70505
Overall Steps per Second: 7,277.43489
Timestep Collection Time: 3.82587
Timestep Consumption Time: 3.04825
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.87413
Cumulative Model Updates: 133,265
Cumulative Timesteps: 1,106,528,962
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1106528962...
Checkpoint 1106528962 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.55545
Policy Entropy: 4.29302
Value Function Loss: 0.00310
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02152
Policy Update Magnitude: 0.91023
Value Function Update Magnitude: 0.84185
Collected Steps per Second: 13,135.92565
Overall Steps per Second: 7,137.11737
Timestep Collection Time: 3.80696
Timestep Consumption Time: 3.19979
PPO Batch Consumption Time: 0.23717
Total Iteration Time: 7.00675
Cumulative Model Updates: 133,274
Cumulative Timesteps: 1,106,578,970
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.94754
Policy Entropy: 4.29768
Value Function Loss: 0.00316
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02308
Policy Update Magnitude: 0.92207
Value Function Update Magnitude: 0.83796
Collected Steps per Second: 12,264.04446
Overall Steps per Second: 6,839.85834
Timestep Collection Time: 4.08055
Timestep Consumption Time: 3.23598
PPO Batch Consumption Time: 0.24377
Total Iteration Time: 7.31653
Cumulative Model Updates: 133,283
Cumulative Timesteps: 1,106,629,014
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1106629014...
Checkpoint 1106629014 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.37803
Policy Entropy: 4.29999
Value Function Loss: 0.00307
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02245
Policy Update Magnitude: 0.92143
Value Function Update Magnitude: 0.80646
Collected Steps per Second: 11,996.36594
Overall Steps per Second: 6,804.56662
Timestep Collection Time: 4.17010
Timestep Consumption Time: 3.18173
PPO Batch Consumption Time: 0.23428
Total Iteration Time: 7.35183
Cumulative Model Updates: 133,292
Cumulative Timesteps: 1,106,679,040
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.78563
Policy Entropy: 4.29939
Value Function Loss: 0.00307
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.91183
Value Function Update Magnitude: 0.78882
Collected Steps per Second: 11,629.28738
Overall Steps per Second: 6,693.03745
Timestep Collection Time: 4.30276
Timestep Consumption Time: 3.17337
PPO Batch Consumption Time: 0.23191
Total Iteration Time: 7.47613
Cumulative Model Updates: 133,301
Cumulative Timesteps: 1,106,729,078
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1106729078...
Checkpoint 1106729078 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.20018
Policy Entropy: 4.29525
Value Function Loss: 0.00304
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02126
Policy Update Magnitude: 0.90857
Value Function Update Magnitude: 0.80706
Collected Steps per Second: 13,002.72644
Overall Steps per Second: 7,168.64936
Timestep Collection Time: 3.84673
Timestep Consumption Time: 3.13059
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.97733
Cumulative Model Updates: 133,310
Cumulative Timesteps: 1,106,779,096
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.04938
Policy Entropy: 4.29893
Value Function Loss: 0.00308
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02137
Policy Update Magnitude: 0.91125
Value Function Update Magnitude: 0.81093
Collected Steps per Second: 13,169.49057
Overall Steps per Second: 7,216.08980
Timestep Collection Time: 3.79787
Timestep Consumption Time: 3.13331
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.93118
Cumulative Model Updates: 133,319
Cumulative Timesteps: 1,106,829,112
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1106829112...
Checkpoint 1106829112 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.93859
Policy Entropy: 4.30272
Value Function Loss: 0.00295
Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01930
Policy Update Magnitude: 0.90467
Value Function Update Magnitude: 0.82949
Collected Steps per Second: 12,869.12157
Overall Steps per Second: 7,115.63137
Timestep Collection Time: 3.88713
Timestep Consumption Time: 3.14302
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 7.03016
Cumulative Model Updates: 133,328
Cumulative Timesteps: 1,106,879,136
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.60676
Policy Entropy: 4.30184
Value Function Loss: 0.00304
Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01864
Policy Update Magnitude: 0.90874
Value Function Update Magnitude: 0.81279
Collected Steps per Second: 12,959.86146
Overall Steps per Second: 7,247.91718
Timestep Collection Time: 3.85853
Timestep Consumption Time: 3.04083
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.89936
Cumulative Model Updates: 133,337
Cumulative Timesteps: 1,106,929,142
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1106929142...
Checkpoint 1106929142 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.24316
Policy Entropy: 4.29850
Value Function Loss: 0.00326
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02140
Policy Update Magnitude: 0.93159
Value Function Update Magnitude: 0.84503
Collected Steps per Second: 12,860.15262
Overall Steps per Second: 7,140.74164
Timestep Collection Time: 3.89171
Timestep Consumption Time: 3.11708
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 7.00880
Cumulative Model Updates: 133,346
Cumulative Timesteps: 1,106,979,190
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.99422
Policy Entropy: 4.29727
Value Function Loss: 0.00333
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02328
Policy Update Magnitude: 0.94235
Value Function Update Magnitude: 0.81333
Collected Steps per Second: 13,016.87959
Overall Steps per Second: 7,127.82297
Timestep Collection Time: 3.84393
Timestep Consumption Time: 3.17588
PPO Batch Consumption Time: 0.22951
Total Iteration Time: 7.01982
Cumulative Model Updates: 133,355
Cumulative Timesteps: 1,107,029,226
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1107029226...
Checkpoint 1107029226 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.80461
Policy Entropy: 4.30026
Value Function Loss: 0.00321
Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.92836
Value Function Update Magnitude: 0.79917
Collected Steps per Second: 12,853.23565
Overall Steps per Second: 7,239.74792
Timestep Collection Time: 3.89241
Timestep Consumption Time: 3.01806
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.91046
Cumulative Model Updates: 133,364
Cumulative Timesteps: 1,107,079,256
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.24898
Policy Entropy: 4.30435
Value Function Loss: 0.00300
Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.91577
Value Function Update Magnitude: 0.77539
Collected Steps per Second: 12,803.08806
Overall Steps per Second: 7,096.12079
Timestep Collection Time: 3.90749
Timestep Consumption Time: 3.14255
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 7.05005
Cumulative Model Updates: 133,373
Cumulative Timesteps: 1,107,129,284
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1107129284...
Checkpoint 1107129284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.56714
Policy Entropy: 4.30395
Value Function Loss: 0.00318
Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02048
Policy Update Magnitude: 0.90524
Value Function Update Magnitude: 0.76006
Collected Steps per Second: 12,783.72827
Overall Steps per Second: 7,124.04090
Timestep Collection Time: 3.91232
Timestep Consumption Time: 3.10814
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 7.02045
Cumulative Model Updates: 133,382
Cumulative Timesteps: 1,107,179,298
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.31968
Policy Entropy: 4.30008
Value Function Loss: 0.00337
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02216
Policy Update Magnitude: 0.92644
Value Function Update Magnitude: 0.80673
Collected Steps per Second: 13,430.09280
Overall Steps per Second: 7,279.98013
Timestep Collection Time: 3.72402
Timestep Consumption Time: 3.14605
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.87007
Cumulative Model Updates: 133,391
Cumulative Timesteps: 1,107,229,312
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1107229312...
Checkpoint 1107229312 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.70185
Policy Entropy: 4.29574
Value Function Loss: 0.00345
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.94635
Value Function Update Magnitude: 0.79860
Collected Steps per Second: 12,948.15921
Overall Steps per Second: 7,123.34556
Timestep Collection Time: 3.86263
Timestep Consumption Time: 3.15851
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 7.02114
Cumulative Model Updates: 133,400
Cumulative Timesteps: 1,107,279,326
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.03616
Policy Entropy: 4.29664
Value Function Loss: 0.00336
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.92727
Value Function Update Magnitude: 0.78834
Collected Steps per Second: 12,880.03009
Overall Steps per Second: 7,223.63700
Timestep Collection Time: 3.88353
Timestep Consumption Time: 3.04096
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.92449
Cumulative Model Updates: 133,409
Cumulative Timesteps: 1,107,329,346
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1107329346...
Checkpoint 1107329346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.03542
Policy Entropy: 4.29894
Value Function Loss: 0.00331
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.92422
Value Function Update Magnitude: 0.78060
Collected Steps per Second: 12,957.37425
Overall Steps per Second: 6,992.78742
Timestep Collection Time: 3.86205
Timestep Consumption Time: 3.29418
PPO Batch Consumption Time: 0.24074
Total Iteration Time: 7.15623
Cumulative Model Updates: 133,418
Cumulative Timesteps: 1,107,379,388
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.16867
Policy Entropy: 4.29972
Value Function Loss: 0.00319
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02360
Policy Update Magnitude: 0.90662
Value Function Update Magnitude: 0.76975
Collected Steps per Second: 12,936.34297
Overall Steps per Second: 7,192.75089
Timestep Collection Time: 3.86694
Timestep Consumption Time: 3.08784
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.95478
Cumulative Model Updates: 133,427
Cumulative Timesteps: 1,107,429,412
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1107429412...
Checkpoint 1107429412 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.07313
Policy Entropy: 4.30174
Value Function Loss: 0.00315
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02080
Policy Update Magnitude: 0.90663
Value Function Update Magnitude: 0.75626
Collected Steps per Second: 13,130.12216
Overall Steps per Second: 7,214.11055
Timestep Collection Time: 3.80956
Timestep Consumption Time: 3.12407
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.93363
Cumulative Model Updates: 133,436
Cumulative Timesteps: 1,107,479,432
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83435
Policy Entropy: 4.30256
Value Function Loss: 0.00310
Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01894
Policy Update Magnitude: 0.91393
Value Function Update Magnitude: 0.77772
Collected Steps per Second: 13,072.84700
Overall Steps per Second: 7,182.77202
Timestep Collection Time: 3.82717
Timestep Consumption Time: 3.13839
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.96556
Cumulative Model Updates: 133,445
Cumulative Timesteps: 1,107,529,464
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1107529464...
Checkpoint 1107529464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85309
Policy Entropy: 4.30083
Value Function Loss: 0.00315
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02283
Policy Update Magnitude: 0.92569
Value Function Update Magnitude: 0.81100
Collected Steps per Second: 13,092.33143
Overall Steps per Second: 7,212.88629
Timestep Collection Time: 3.82102
Timestep Consumption Time: 3.11463
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.93564
Cumulative Model Updates: 133,454
Cumulative Timesteps: 1,107,579,490
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.73159
Policy Entropy: 4.30356
Value Function Loss: 0.00319
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.92029
Value Function Update Magnitude: 0.80084
Collected Steps per Second: 13,371.21568
Overall Steps per Second: 7,264.79518
Timestep Collection Time: 3.74222
Timestep Consumption Time: 3.14552
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.88774
Cumulative Model Updates: 133,463
Cumulative Timesteps: 1,107,629,528
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1107629528...
Checkpoint 1107629528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.66149
Policy Entropy: 4.30633
Value Function Loss: 0.00328
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02145
Policy Update Magnitude: 0.92742
Value Function Update Magnitude: 0.79289
Collected Steps per Second: 12,971.97642
Overall Steps per Second: 7,090.52826
Timestep Collection Time: 3.85847
Timestep Consumption Time: 3.20052
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 7.05899
Cumulative Model Updates: 133,472
Cumulative Timesteps: 1,107,679,580
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.12197
Policy Entropy: 4.30924
Value Function Loss: 0.00318
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.93131
Value Function Update Magnitude: 0.79688
Collected Steps per Second: 12,917.22800
Overall Steps per Second: 7,086.58201
Timestep Collection Time: 3.87359
Timestep Consumption Time: 3.18708
PPO Batch Consumption Time: 0.24009
Total Iteration Time: 7.06067
Cumulative Model Updates: 133,481
Cumulative Timesteps: 1,107,729,616
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1107729616...
Checkpoint 1107729616 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.67633
Policy Entropy: 4.30877
Value Function Loss: 0.00314
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02197
Policy Update Magnitude: 0.92705
Value Function Update Magnitude: 0.81251
Collected Steps per Second: 12,775.90475
Overall Steps per Second: 7,105.52630
Timestep Collection Time: 3.91377
Timestep Consumption Time: 3.12328
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 7.03706
Cumulative Model Updates: 133,490
Cumulative Timesteps: 1,107,779,618
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.94826
Policy Entropy: 4.30411
Value Function Loss: 0.00305
Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02186
Policy Update Magnitude: 0.91833
Value Function Update Magnitude: 0.77924
Collected Steps per Second: 13,004.10225
Overall Steps per Second: 7,191.76094
Timestep Collection Time: 3.84786
Timestep Consumption Time: 3.10982
PPO Batch Consumption Time: 0.22939
Total Iteration Time: 6.95768
Cumulative Model Updates: 133,499
Cumulative Timesteps: 1,107,829,656
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1107829656...
Checkpoint 1107829656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.48882
Policy Entropy: 4.30367
Value Function Loss: 0.00316
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.90344
Value Function Update Magnitude: 0.74623
Collected Steps per Second: 13,327.24971
Overall Steps per Second: 7,278.72451
Timestep Collection Time: 3.75456
Timestep Consumption Time: 3.11999
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.87456
Cumulative Model Updates: 133,508
Cumulative Timesteps: 1,107,879,694
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.24845
Policy Entropy: 4.30205
Value Function Loss: 0.00324
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02137
Policy Update Magnitude: 0.92311
Value Function Update Magnitude: 0.76660
Collected Steps per Second: 12,999.19333
Overall Steps per Second: 7,185.33120
Timestep Collection Time: 3.84855
Timestep Consumption Time: 3.11397
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.96252
Cumulative Model Updates: 133,517
Cumulative Timesteps: 1,107,929,722
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1107929722...
Checkpoint 1107929722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.57150
Policy Entropy: 4.30334
Value Function Loss: 0.00334
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02333
Policy Update Magnitude: 0.95547
Value Function Update Magnitude: 0.81654
Collected Steps per Second: 12,790.80355
Overall Steps per Second: 7,108.42321
Timestep Collection Time: 3.91093
Timestep Consumption Time: 3.12635
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 7.03729
Cumulative Model Updates: 133,526
Cumulative Timesteps: 1,107,979,746
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.04444
Policy Entropy: 4.30391
Value Function Loss: 0.00333
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02256
Policy Update Magnitude: 0.96229
Value Function Update Magnitude: 0.82119
Collected Steps per Second: 13,347.08420
Overall Steps per Second: 7,263.51043
Timestep Collection Time: 3.74629
Timestep Consumption Time: 3.13771
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.88400
Cumulative Model Updates: 133,535
Cumulative Timesteps: 1,108,029,748
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1108029748...
Checkpoint 1108029748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.42418
Policy Entropy: 4.30377
Value Function Loss: 0.00309
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.93995
Value Function Update Magnitude: 0.79605
Collected Steps per Second: 12,872.54112
Overall Steps per Second: 6,995.81801
Timestep Collection Time: 3.88455
Timestep Consumption Time: 3.26315
PPO Batch Consumption Time: 0.23820
Total Iteration Time: 7.14770
Cumulative Model Updates: 133,544
Cumulative Timesteps: 1,108,079,752
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.64386
Policy Entropy: 4.30489
Value Function Loss: 0.00298
Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02025
Policy Update Magnitude: 0.91057
Value Function Update Magnitude: 0.75558
Collected Steps per Second: 13,030.14668
Overall Steps per Second: 7,267.98790
Timestep Collection Time: 3.83956
Timestep Consumption Time: 3.04405
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.88361
Cumulative Model Updates: 133,553
Cumulative Timesteps: 1,108,129,782
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1108129782...
Checkpoint 1108129782 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.26325
Policy Entropy: 4.30655
Value Function Loss: 0.00290
Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02021
Policy Update Magnitude: 0.89319
Value Function Update Magnitude: 0.76392
Collected Steps per Second: 12,921.33154
Overall Steps per Second: 7,144.57914
Timestep Collection Time: 3.87174
Timestep Consumption Time: 3.13049
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 7.00223
Cumulative Model Updates: 133,562
Cumulative Timesteps: 1,108,179,810
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.96030
Policy Entropy: 4.30404
Value Function Loss: 0.00306
Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.89208
Value Function Update Magnitude: 0.74021
Collected Steps per Second: 12,898.59755
Overall Steps per Second: 7,159.50324
Timestep Collection Time: 3.87717
Timestep Consumption Time: 3.10796
PPO Batch Consumption Time: 0.22948
Total Iteration Time: 6.98512
Cumulative Model Updates: 133,571
Cumulative Timesteps: 1,108,229,820
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1108229820...
Checkpoint 1108229820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.53007
Policy Entropy: 4.30558
Value Function Loss: 0.00305
Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01959
Policy Update Magnitude: 0.88301
Value Function Update Magnitude: 0.74387
Collected Steps per Second: 13,219.23023
Overall Steps per Second: 7,235.27727
Timestep Collection Time: 3.78237
Timestep Consumption Time: 3.12822
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.91059
Cumulative Model Updates: 133,580
Cumulative Timesteps: 1,108,279,820
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.21017
Policy Entropy: 4.30345
Value Function Loss: 0.00321
Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01922
Policy Update Magnitude: 0.88479
Value Function Update Magnitude: 0.75654
Collected Steps per Second: 12,957.46177
Overall Steps per Second: 7,171.17267
Timestep Collection Time: 3.86017
Timestep Consumption Time: 3.11470
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.97487
Cumulative Model Updates: 133,589
Cumulative Timesteps: 1,108,329,838
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1108329838...
Checkpoint 1108329838 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.18965
Policy Entropy: 4.30226
Value Function Loss: 0.00328
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02209
Policy Update Magnitude: 0.89103
Value Function Update Magnitude: 0.80636
Collected Steps per Second: 12,991.44695
Overall Steps per Second: 7,204.06982
Timestep Collection Time: 3.84869
Timestep Consumption Time: 3.09184
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.94052
Cumulative Model Updates: 133,598
Cumulative Timesteps: 1,108,379,838
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.16549
Policy Entropy: 4.30611
Value Function Loss: 0.00336
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02260
Policy Update Magnitude: 0.91614
Value Function Update Magnitude: 0.82628
Collected Steps per Second: 13,067.95128
Overall Steps per Second: 7,149.05175
Timestep Collection Time: 3.82631
Timestep Consumption Time: 3.16791
PPO Batch Consumption Time: 0.23301
Total Iteration Time: 6.99421
Cumulative Model Updates: 133,607
Cumulative Timesteps: 1,108,429,840
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1108429840...
Checkpoint 1108429840 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.73723
Policy Entropy: 4.30764
Value Function Loss: 0.00320
Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02025
Policy Update Magnitude: 0.91409
Value Function Update Magnitude: 0.83551
Collected Steps per Second: 12,730.92238
Overall Steps per Second: 7,058.51395
Timestep Collection Time: 3.92745
Timestep Consumption Time: 3.15620
PPO Batch Consumption Time: 0.22961
Total Iteration Time: 7.08364
Cumulative Model Updates: 133,616
Cumulative Timesteps: 1,108,479,840
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.39895
Policy Entropy: 4.31039
Value Function Loss: 0.00308
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02176
Policy Update Magnitude: 0.90578
Value Function Update Magnitude: 0.78944
Collected Steps per Second: 12,934.44276
Overall Steps per Second: 7,228.26505
Timestep Collection Time: 3.86812
Timestep Consumption Time: 3.05359
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.92172
Cumulative Model Updates: 133,625
Cumulative Timesteps: 1,108,529,872
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1108529872...
Checkpoint 1108529872 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.97775
Policy Entropy: 4.30746
Value Function Loss: 0.00308
Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02002
Policy Update Magnitude: 0.89066
Value Function Update Magnitude: 0.75252
Collected Steps per Second: 12,912.02207
Overall Steps per Second: 7,139.39776
Timestep Collection Time: 3.87437
Timestep Consumption Time: 3.13266
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 7.00703
Cumulative Model Updates: 133,634
Cumulative Timesteps: 1,108,579,898
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.07537
Policy Entropy: 4.30510
Value Function Loss: 0.00323
Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01992
Policy Update Magnitude: 0.87951
Value Function Update Magnitude: 0.75091
Collected Steps per Second: 12,924.43856
Overall Steps per Second: 7,184.72056
Timestep Collection Time: 3.86864
Timestep Consumption Time: 3.09057
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.95921
Cumulative Model Updates: 133,643
Cumulative Timesteps: 1,108,629,898
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1108629898...
Checkpoint 1108629898 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.35617
Policy Entropy: 4.30509
Value Function Loss: 0.00324
Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01983
Policy Update Magnitude: 0.88367
Value Function Update Magnitude: 0.77472
Collected Steps per Second: 12,910.10433
Overall Steps per Second: 7,162.83276
Timestep Collection Time: 3.87386
Timestep Consumption Time: 3.10829
PPO Batch Consumption Time: 0.22763
Total Iteration Time: 6.98215
Cumulative Model Updates: 133,652
Cumulative Timesteps: 1,108,679,910
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.91972
Policy Entropy: 4.30675
Value Function Loss: 0.00316
Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02134
Policy Update Magnitude: 0.89820
Value Function Update Magnitude: 0.79820
Collected Steps per Second: 12,901.87712
Overall Steps per Second: 7,151.91296
Timestep Collection Time: 3.87665
Timestep Consumption Time: 3.11673
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.99337
Cumulative Model Updates: 133,661
Cumulative Timesteps: 1,108,729,926
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1108729926...
Checkpoint 1108729926 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.30561
Policy Entropy: 4.31122
Value Function Loss: 0.00308
Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01947
Policy Update Magnitude: 0.90508
Value Function Update Magnitude: 0.80618
Collected Steps per Second: 12,898.59016
Overall Steps per Second: 7,128.19683
Timestep Collection Time: 3.87934
Timestep Consumption Time: 3.14039
PPO Batch Consumption Time: 0.23429
Total Iteration Time: 7.01973
Cumulative Model Updates: 133,670
Cumulative Timesteps: 1,108,779,964
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.73444
Policy Entropy: 4.31041
Value Function Loss: 0.00307
Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01998
Policy Update Magnitude: 0.90489
Value Function Update Magnitude: 0.79234
Collected Steps per Second: 13,377.33804
Overall Steps per Second: 7,297.62236
Timestep Collection Time: 3.74021
Timestep Consumption Time: 3.11600
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.85621
Cumulative Model Updates: 133,679
Cumulative Timesteps: 1,108,829,998
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1108829998...
Checkpoint 1108829998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.74897
Policy Entropy: 4.30803
Value Function Loss: 0.00311
Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01981
Policy Update Magnitude: 0.90859
Value Function Update Magnitude: 0.79328
Collected Steps per Second: 12,983.75740
Overall Steps per Second: 7,138.79390
Timestep Collection Time: 3.85112
Timestep Consumption Time: 3.15314
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 7.00426
Cumulative Model Updates: 133,688
Cumulative Timesteps: 1,108,880,000
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.69502
Policy Entropy: 4.30203
Value Function Loss: 0.00321
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.90479
Value Function Update Magnitude: 0.81527
Collected Steps per Second: 13,040.40538
Overall Steps per Second: 7,264.86674
Timestep Collection Time: 3.83439
Timestep Consumption Time: 3.04832
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.88271
Cumulative Model Updates: 133,697
Cumulative Timesteps: 1,108,930,002
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1108930002...
Checkpoint 1108930002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.35225
Policy Entropy: 4.30264
Value Function Loss: 0.00315
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02125
Policy Update Magnitude: 0.91180
Value Function Update Magnitude: 0.82208
Collected Steps per Second: 13,154.24542
Overall Steps per Second: 7,225.84355
Timestep Collection Time: 3.80425
Timestep Consumption Time: 3.12117
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.92542
Cumulative Model Updates: 133,706
Cumulative Timesteps: 1,108,980,044
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.18570
Policy Entropy: 4.30565
Value Function Loss: 0.00298
Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02150
Policy Update Magnitude: 0.91151
Value Function Update Magnitude: 0.80980
Collected Steps per Second: 12,884.71661
Overall Steps per Second: 7,144.01953
Timestep Collection Time: 3.88243
Timestep Consumption Time: 3.11979
PPO Batch Consumption Time: 0.22941
Total Iteration Time: 7.00222
Cumulative Model Updates: 133,715
Cumulative Timesteps: 1,109,030,068
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1109030068...
Checkpoint 1109030068 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.16772
Policy Entropy: 4.30920
Value Function Loss: 0.00288
Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01774
Policy Update Magnitude: 0.90628
Value Function Update Magnitude: 0.78787
Collected Steps per Second: 12,860.31919
Overall Steps per Second: 7,215.61047
Timestep Collection Time: 3.88808
Timestep Consumption Time: 3.04161
PPO Batch Consumption Time: 0.22971
Total Iteration Time: 6.92970
Cumulative Model Updates: 133,724
Cumulative Timesteps: 1,109,080,070
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.44771
Policy Entropy: 4.30906
Value Function Loss: 0.00289
Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01976
Policy Update Magnitude: 0.90395
Value Function Update Magnitude: 0.76648
Collected Steps per Second: 12,787.77806
Overall Steps per Second: 7,057.35490
Timestep Collection Time: 3.91139
Timestep Consumption Time: 3.17597
PPO Batch Consumption Time: 0.23108
Total Iteration Time: 7.08736
Cumulative Model Updates: 133,733
Cumulative Timesteps: 1,109,130,088
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1109130088...
Checkpoint 1109130088 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.85355
Policy Entropy: 4.30847
Value Function Loss: 0.00291
Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02163
Policy Update Magnitude: 0.88505
Value Function Update Magnitude: 0.77564
Collected Steps per Second: 13,000.88512
Overall Steps per Second: 7,303.17318
Timestep Collection Time: 3.84851
Timestep Consumption Time: 3.00249
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.85099
Cumulative Model Updates: 133,742
Cumulative Timesteps: 1,109,180,122
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.74257
Policy Entropy: 4.31253
Value Function Loss: 0.00287
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.88683
Value Function Update Magnitude: 0.78481
Collected Steps per Second: 12,868.49043
Overall Steps per Second: 7,136.89591
Timestep Collection Time: 3.88779
Timestep Consumption Time: 3.12226
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 7.01005
Cumulative Model Updates: 133,751
Cumulative Timesteps: 1,109,230,152
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1109230152...
Checkpoint 1109230152 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.73554
Policy Entropy: 4.31417
Value Function Loss: 0.00287
Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01989
Policy Update Magnitude: 0.90316
Value Function Update Magnitude: 0.77976
Collected Steps per Second: 12,829.37744
Overall Steps per Second: 7,157.51733
Timestep Collection Time: 3.89824
Timestep Consumption Time: 3.08910
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.98734
Cumulative Model Updates: 133,760
Cumulative Timesteps: 1,109,280,164
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.53933
Policy Entropy: 4.31230
Value Function Loss: 0.00304
Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01978
Policy Update Magnitude: 0.90704
Value Function Update Magnitude: 0.83771
Collected Steps per Second: 12,942.35564
Overall Steps per Second: 7,234.77312
Timestep Collection Time: 3.86452
Timestep Consumption Time: 3.04876
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.91328
Cumulative Model Updates: 133,769
Cumulative Timesteps: 1,109,330,180
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1109330180...
Checkpoint 1109330180 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.04201
Policy Entropy: 4.30775
Value Function Loss: 0.00313
Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.91569
Value Function Update Magnitude: 0.87668
Collected Steps per Second: 13,075.96373
Overall Steps per Second: 7,163.05868
Timestep Collection Time: 3.82488
Timestep Consumption Time: 3.15733
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.98221
Cumulative Model Updates: 133,778
Cumulative Timesteps: 1,109,380,194
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.53601
Policy Entropy: 4.30584
Value Function Loss: 0.00322
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.91370
Value Function Update Magnitude: 0.83716
Collected Steps per Second: 12,993.43342
Overall Steps per Second: 7,176.06634
Timestep Collection Time: 3.85195
Timestep Consumption Time: 3.12263
PPO Batch Consumption Time: 0.22939
Total Iteration Time: 6.97457
Cumulative Model Updates: 133,787
Cumulative Timesteps: 1,109,430,244
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1109430244...
Checkpoint 1109430244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.56279
Policy Entropy: 4.29975
Value Function Loss: 0.00334
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02411
Policy Update Magnitude: 0.92292
Value Function Update Magnitude: 0.84606
Collected Steps per Second: 13,265.40177
Overall Steps per Second: 7,180.85898
Timestep Collection Time: 3.77011
Timestep Consumption Time: 3.19452
PPO Batch Consumption Time: 0.22933
Total Iteration Time: 6.96463
Cumulative Model Updates: 133,796
Cumulative Timesteps: 1,109,480,256
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.20790
Policy Entropy: 4.29383
Value Function Loss: 0.00337
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.92469
Value Function Update Magnitude: 0.84532
Collected Steps per Second: 13,018.26972
Overall Steps per Second: 7,152.10785
Timestep Collection Time: 3.84183
Timestep Consumption Time: 3.15107
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.99290
Cumulative Model Updates: 133,805
Cumulative Timesteps: 1,109,530,270
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1109530270...
Checkpoint 1109530270 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.19748
Policy Entropy: 4.29470
Value Function Loss: 0.00324
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.92259
Value Function Update Magnitude: 0.82601
Collected Steps per Second: 12,927.22573
Overall Steps per Second: 7,251.34574
Timestep Collection Time: 3.87028
Timestep Consumption Time: 3.02940
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.89968
Cumulative Model Updates: 133,814
Cumulative Timesteps: 1,109,580,302
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.82119
Policy Entropy: 4.29742
Value Function Loss: 0.00317
Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01985
Policy Update Magnitude: 0.92055
Value Function Update Magnitude: 0.79287
Collected Steps per Second: 12,982.98207
Overall Steps per Second: 7,150.80692
Timestep Collection Time: 3.85366
Timestep Consumption Time: 3.14303
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.99669
Cumulative Model Updates: 133,823
Cumulative Timesteps: 1,109,630,334
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1109630334...
Checkpoint 1109630334 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.19813
Policy Entropy: 4.30240
Value Function Loss: 0.00304
Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02118
Policy Update Magnitude: 0.90513
Value Function Update Magnitude: 0.79642
Collected Steps per Second: 12,823.52222
Overall Steps per Second: 7,125.31160
Timestep Collection Time: 3.90018
Timestep Consumption Time: 3.11903
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 7.01920
Cumulative Model Updates: 133,832
Cumulative Timesteps: 1,109,680,348
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.50090
Policy Entropy: 4.29790
Value Function Loss: 0.00304
Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02186
Policy Update Magnitude: 0.89796
Value Function Update Magnitude: 0.80636
Collected Steps per Second: 13,175.80232
Overall Steps per Second: 7,208.83858
Timestep Collection Time: 3.79757
Timestep Consumption Time: 3.14336
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.94092
Cumulative Model Updates: 133,841
Cumulative Timesteps: 1,109,730,384
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1109730384...
Checkpoint 1109730384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.97057
Policy Entropy: 4.30374
Value Function Loss: 0.00293
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02217
Policy Update Magnitude: 0.89106
Value Function Update Magnitude: 0.82481
Collected Steps per Second: 12,816.06355
Overall Steps per Second: 7,094.10833
Timestep Collection Time: 3.90182
Timestep Consumption Time: 3.14713
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 7.04895
Cumulative Model Updates: 133,850
Cumulative Timesteps: 1,109,780,390
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.84109
Policy Entropy: 4.30442
Value Function Loss: 0.00299
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.88583
Value Function Update Magnitude: 0.80979
Collected Steps per Second: 12,930.20221
Overall Steps per Second: 7,109.07468
Timestep Collection Time: 3.86924
Timestep Consumption Time: 3.16825
PPO Batch Consumption Time: 0.23942
Total Iteration Time: 7.03748
Cumulative Model Updates: 133,859
Cumulative Timesteps: 1,109,830,420
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1109830420...
Checkpoint 1109830420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.29114
Policy Entropy: 4.30655
Value Function Loss: 0.00310
Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02022
Policy Update Magnitude: 0.90357
Value Function Update Magnitude: 0.80663
Collected Steps per Second: 12,877.66369
Overall Steps per Second: 7,110.62635
Timestep Collection Time: 3.88347
Timestep Consumption Time: 3.14967
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 7.03314
Cumulative Model Updates: 133,868
Cumulative Timesteps: 1,109,880,430
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.11676
Policy Entropy: 4.30389
Value Function Loss: 0.00309
Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02191
Policy Update Magnitude: 0.90716
Value Function Update Magnitude: 0.84006
Collected Steps per Second: 13,018.59430
Overall Steps per Second: 7,179.97828
Timestep Collection Time: 3.84281
Timestep Consumption Time: 3.12490
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.96771
Cumulative Model Updates: 133,877
Cumulative Timesteps: 1,109,930,458
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1109930458...
Checkpoint 1109930458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.80866
Policy Entropy: 4.30285
Value Function Loss: 0.00297
Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02044
Policy Update Magnitude: 0.89366
Value Function Update Magnitude: 0.82238
Collected Steps per Second: 13,015.96867
Overall Steps per Second: 7,267.49076
Timestep Collection Time: 3.84174
Timestep Consumption Time: 3.03876
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.88050
Cumulative Model Updates: 133,886
Cumulative Timesteps: 1,109,980,462
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.60633
Policy Entropy: 4.30481
Value Function Loss: 0.00283
Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02024
Policy Update Magnitude: 0.90402
Value Function Update Magnitude: 0.80831
Collected Steps per Second: 13,018.77516
Overall Steps per Second: 7,189.75517
Timestep Collection Time: 3.84076
Timestep Consumption Time: 3.11386
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.95462
Cumulative Model Updates: 133,895
Cumulative Timesteps: 1,110,030,464
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1110030464...
Checkpoint 1110030464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.49056
Policy Entropy: 4.30012
Value Function Loss: 0.00308
Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.92712
Value Function Update Magnitude: 0.81410
Collected Steps per Second: 12,951.45647
Overall Steps per Second: 7,200.40896
Timestep Collection Time: 3.86350
Timestep Consumption Time: 3.08582
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.94933
Cumulative Model Updates: 133,904
Cumulative Timesteps: 1,110,080,502
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.70655
Policy Entropy: 4.30163
Value Function Loss: 0.00309
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02230
Policy Update Magnitude: 0.92967
Value Function Update Magnitude: 0.80610
Collected Steps per Second: 13,277.68487
Overall Steps per Second: 7,261.72116
Timestep Collection Time: 3.76767
Timestep Consumption Time: 3.12133
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.88900
Cumulative Model Updates: 133,913
Cumulative Timesteps: 1,110,130,528
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1110130528...
Checkpoint 1110130528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.84868
Policy Entropy: 4.29689
Value Function Loss: 0.00309
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.93303
Value Function Update Magnitude: 0.79504
Collected Steps per Second: 13,060.86760
Overall Steps per Second: 7,131.65624
Timestep Collection Time: 3.83083
Timestep Consumption Time: 3.18493
PPO Batch Consumption Time: 0.23289
Total Iteration Time: 7.01576
Cumulative Model Updates: 133,922
Cumulative Timesteps: 1,110,180,562
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.20237
Policy Entropy: 4.30269
Value Function Loss: 0.00294
Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02139
Policy Update Magnitude: 0.93434
Value Function Update Magnitude: 0.79199
Collected Steps per Second: 13,082.33143
Overall Steps per Second: 7,216.82626
Timestep Collection Time: 3.82424
Timestep Consumption Time: 3.10817
PPO Batch Consumption Time: 0.22763
Total Iteration Time: 6.93241
Cumulative Model Updates: 133,931
Cumulative Timesteps: 1,110,230,592
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1110230592...
Checkpoint 1110230592 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.91578
Policy Entropy: 4.30008
Value Function Loss: 0.00301
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02348
Policy Update Magnitude: 0.93103
Value Function Update Magnitude: 0.79136
Collected Steps per Second: 13,212.67447
Overall Steps per Second: 7,208.83448
Timestep Collection Time: 3.78879
Timestep Consumption Time: 3.15547
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.94426
Cumulative Model Updates: 133,940
Cumulative Timesteps: 1,110,280,652
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.98987
Policy Entropy: 4.29705
Value Function Loss: 0.00303
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.92927
Value Function Update Magnitude: 0.76589
Collected Steps per Second: 12,877.38161
Overall Steps per Second: 7,104.96428
Timestep Collection Time: 3.88402
Timestep Consumption Time: 3.15557
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 7.03958
Cumulative Model Updates: 133,949
Cumulative Timesteps: 1,110,330,668
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1110330668...
Checkpoint 1110330668 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.47249
Policy Entropy: 4.29698
Value Function Loss: 0.00314
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02191
Policy Update Magnitude: 0.92240
Value Function Update Magnitude: 0.74197
Collected Steps per Second: 12,995.74801
Overall Steps per Second: 7,287.19604
Timestep Collection Time: 3.84926
Timestep Consumption Time: 3.01538
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.86464
Cumulative Model Updates: 133,958
Cumulative Timesteps: 1,110,380,692
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60823
Policy Entropy: 4.29738
Value Function Loss: 0.00310
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02139
Policy Update Magnitude: 0.91061
Value Function Update Magnitude: 0.75389
Collected Steps per Second: 13,075.43827
Overall Steps per Second: 7,171.53159
Timestep Collection Time: 3.82396
Timestep Consumption Time: 3.14805
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.97201
Cumulative Model Updates: 133,967
Cumulative Timesteps: 1,110,430,692
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1110430692...
Checkpoint 1110430692 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.98334
Policy Entropy: 4.29401
Value Function Loss: 0.00316
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02068
Policy Update Magnitude: 0.91860
Value Function Update Magnitude: 0.75771
Collected Steps per Second: 12,990.25295
Overall Steps per Second: 7,199.40643
Timestep Collection Time: 3.84966
Timestep Consumption Time: 3.09647
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.94613
Cumulative Model Updates: 133,976
Cumulative Timesteps: 1,110,480,700
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.56969
Policy Entropy: 4.29614
Value Function Loss: 0.00311
Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02152
Policy Update Magnitude: 0.92464
Value Function Update Magnitude: 0.80893
Collected Steps per Second: 13,348.06181
Overall Steps per Second: 7,183.03876
Timestep Collection Time: 3.74766
Timestep Consumption Time: 3.21652
PPO Batch Consumption Time: 0.23421
Total Iteration Time: 6.96418
Cumulative Model Updates: 133,985
Cumulative Timesteps: 1,110,530,724
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1110530724...
Checkpoint 1110530724 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01602
Policy Entropy: 4.29621
Value Function Loss: 0.00299
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02289
Policy Update Magnitude: 0.91940
Value Function Update Magnitude: 0.80243
Collected Steps per Second: 11,259.59356
Overall Steps per Second: 6,589.75901
Timestep Collection Time: 4.44385
Timestep Consumption Time: 3.14914
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 7.59299
Cumulative Model Updates: 133,994
Cumulative Timesteps: 1,110,580,760
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.45803
Policy Entropy: 4.29762
Value Function Loss: 0.00306
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02314
Policy Update Magnitude: 0.92570
Value Function Update Magnitude: 0.77854
Collected Steps per Second: 12,653.21033
Overall Steps per Second: 7,088.24521
Timestep Collection Time: 3.95172
Timestep Consumption Time: 3.10249
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 7.05421
Cumulative Model Updates: 134,003
Cumulative Timesteps: 1,110,630,762
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1110630762...
Checkpoint 1110630762 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.72724
Policy Entropy: 4.29563
Value Function Loss: 0.00302
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02340
Policy Update Magnitude: 0.93645
Value Function Update Magnitude: 0.78771
Collected Steps per Second: 13,267.82538
Overall Steps per Second: 7,245.89591
Timestep Collection Time: 3.76897
Timestep Consumption Time: 3.13232
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.90129
Cumulative Model Updates: 134,012
Cumulative Timesteps: 1,110,680,768
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.70329
Policy Entropy: 4.29617
Value Function Loss: 0.00296
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.92580
Value Function Update Magnitude: 0.77260
Collected Steps per Second: 13,077.61663
Overall Steps per Second: 7,191.88730
Timestep Collection Time: 3.82547
Timestep Consumption Time: 3.13070
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.95617
Cumulative Model Updates: 134,021
Cumulative Timesteps: 1,110,730,796
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1110730796...
Checkpoint 1110730796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04047
Policy Entropy: 4.29807
Value Function Loss: 0.00288
Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02092
Policy Update Magnitude: 0.92083
Value Function Update Magnitude: 0.75074
Collected Steps per Second: 12,701.55911
Overall Steps per Second: 7,181.38896
Timestep Collection Time: 3.93857
Timestep Consumption Time: 3.02749
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.96606
Cumulative Model Updates: 134,030
Cumulative Timesteps: 1,110,780,822
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.97599
Policy Entropy: 4.29606
Value Function Loss: 0.00287
Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.91089
Value Function Update Magnitude: 0.72915
Collected Steps per Second: 12,493.00365
Overall Steps per Second: 6,940.91262
Timestep Collection Time: 4.00512
Timestep Consumption Time: 3.20373
PPO Batch Consumption Time: 0.23031
Total Iteration Time: 7.20885
Cumulative Model Updates: 134,039
Cumulative Timesteps: 1,110,830,858
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1110830858...
Checkpoint 1110830858 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.83570
Policy Entropy: 4.29418
Value Function Loss: 0.00293
Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.92409
Value Function Update Magnitude: 0.73384
Collected Steps per Second: 12,254.02409
Overall Steps per Second: 6,837.55526
Timestep Collection Time: 4.08323
Timestep Consumption Time: 3.23459
PPO Batch Consumption Time: 0.23124
Total Iteration Time: 7.31782
Cumulative Model Updates: 134,048
Cumulative Timesteps: 1,110,880,894
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 7.59286
Policy Entropy: 4.29227
Value Function Loss: 0.00291
Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02035
Policy Update Magnitude: 0.92487
Value Function Update Magnitude: 0.75678
Collected Steps per Second: 12,210.35120
Overall Steps per Second: 6,951.20861
Timestep Collection Time: 4.09538
Timestep Consumption Time: 3.09848
PPO Batch Consumption Time: 0.22963
Total Iteration Time: 7.19386
Cumulative Model Updates: 134,057
Cumulative Timesteps: 1,110,930,900
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1110930900...
Checkpoint 1110930900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.55463
Policy Entropy: 4.29211
Value Function Loss: 0.00300
Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02003
Policy Update Magnitude: 0.93274
Value Function Update Magnitude: 0.74591
Collected Steps per Second: 12,776.46251
Overall Steps per Second: 7,100.01371
Timestep Collection Time: 3.91673
Timestep Consumption Time: 3.13142
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 7.04816
Cumulative Model Updates: 134,066
Cumulative Timesteps: 1,110,980,942
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.62583
Policy Entropy: 4.29664
Value Function Loss: 0.00300
Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.94725
Value Function Update Magnitude: 0.75074
Collected Steps per Second: 12,833.75531
Overall Steps per Second: 7,179.67239
Timestep Collection Time: 3.89800
Timestep Consumption Time: 3.06973
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.96773
Cumulative Model Updates: 134,075
Cumulative Timesteps: 1,111,030,968
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1111030968...
Checkpoint 1111030968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.58170
Policy Entropy: 4.30034
Value Function Loss: 0.00303
Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02079
Policy Update Magnitude: 0.93323
Value Function Update Magnitude: 0.75960
Collected Steps per Second: 12,986.25202
Overall Steps per Second: 7,188.88734
Timestep Collection Time: 3.85361
Timestep Consumption Time: 3.10769
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.96130
Cumulative Model Updates: 134,084
Cumulative Timesteps: 1,111,081,012
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.84380
Policy Entropy: 4.30057
Value Function Loss: 0.00307
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02261
Policy Update Magnitude: 0.92884
Value Function Update Magnitude: 0.75106
Collected Steps per Second: 13,103.12108
Overall Steps per Second: 7,195.14546
Timestep Collection Time: 3.81650
Timestep Consumption Time: 3.13375
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.95024
Cumulative Model Updates: 134,093
Cumulative Timesteps: 1,111,131,020
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1111131020...
Checkpoint 1111131020 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.03175
Policy Entropy: 4.29495
Value Function Loss: 0.00319
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.93155
Value Function Update Magnitude: 0.75048
Collected Steps per Second: 12,941.32134
Overall Steps per Second: 7,227.81981
Timestep Collection Time: 3.86637
Timestep Consumption Time: 3.05632
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.92270
Cumulative Model Updates: 134,102
Cumulative Timesteps: 1,111,181,056
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.38570
Policy Entropy: 4.28998
Value Function Loss: 0.00340
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02996
Policy Update Magnitude: 0.94441
Value Function Update Magnitude: 0.80580
Collected Steps per Second: 12,937.94627
Overall Steps per Second: 7,101.58549
Timestep Collection Time: 3.86646
Timestep Consumption Time: 3.17760
PPO Batch Consumption Time: 0.23320
Total Iteration Time: 7.04406
Cumulative Model Updates: 134,111
Cumulative Timesteps: 1,111,231,080
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1111231080...
Checkpoint 1111231080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.50146
Policy Entropy: 4.29225
Value Function Loss: 0.00326
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02792
Policy Update Magnitude: 0.94072
Value Function Update Magnitude: 0.82642
Collected Steps per Second: 12,956.36383
Overall Steps per Second: 7,192.87340
Timestep Collection Time: 3.86142
Timestep Consumption Time: 3.09407
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.95550
Cumulative Model Updates: 134,120
Cumulative Timesteps: 1,111,281,110
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.58036
Policy Entropy: 4.29494
Value Function Loss: 0.00323
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.93951
Value Function Update Magnitude: 0.83027
Collected Steps per Second: 13,041.61344
Overall Steps per Second: 7,267.91987
Timestep Collection Time: 3.83649
Timestep Consumption Time: 3.04774
PPO Batch Consumption Time: 0.22988
Total Iteration Time: 6.88423
Cumulative Model Updates: 134,129
Cumulative Timesteps: 1,111,331,144
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1111331144...
Checkpoint 1111331144 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.64933
Policy Entropy: 4.29605
Value Function Loss: 0.00310
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.93656
Value Function Update Magnitude: 0.82566
Collected Steps per Second: 11,526.33218
Overall Steps per Second: 6,644.11304
Timestep Collection Time: 4.33928
Timestep Consumption Time: 3.18859
PPO Batch Consumption Time: 0.23192
Total Iteration Time: 7.52787
Cumulative Model Updates: 134,138
Cumulative Timesteps: 1,111,381,160
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51850
Policy Entropy: 4.29445
Value Function Loss: 0.00310
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03045
Policy Update Magnitude: 0.92669
Value Function Update Magnitude: 0.84024
Collected Steps per Second: 12,386.13658
Overall Steps per Second: 6,927.93069
Timestep Collection Time: 4.03758
Timestep Consumption Time: 3.18103
PPO Batch Consumption Time: 0.23512
Total Iteration Time: 7.21861
Cumulative Model Updates: 134,147
Cumulative Timesteps: 1,111,431,170
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1111431170...
Checkpoint 1111431170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.84137
Policy Entropy: 4.29606
Value Function Loss: 0.00306
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.92000
Value Function Update Magnitude: 0.84035
Collected Steps per Second: 12,908.76564
Overall Steps per Second: 7,062.11639
Timestep Collection Time: 3.87551
Timestep Consumption Time: 3.20849
PPO Batch Consumption Time: 0.23550
Total Iteration Time: 7.08400
Cumulative Model Updates: 134,156
Cumulative Timesteps: 1,111,481,198
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.83402
Policy Entropy: 4.29875
Value Function Loss: 0.00303
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.92539
Value Function Update Magnitude: 0.81861
Collected Steps per Second: 12,550.66165
Overall Steps per Second: 6,952.86375
Timestep Collection Time: 3.98529
Timestep Consumption Time: 3.20858
PPO Batch Consumption Time: 0.23419
Total Iteration Time: 7.19387
Cumulative Model Updates: 134,165
Cumulative Timesteps: 1,111,531,216
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1111531216...
Checkpoint 1111531216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13834
Policy Entropy: 4.29584
Value Function Loss: 0.00320
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.94150
Value Function Update Magnitude: 0.81321
Collected Steps per Second: 12,516.48979
Overall Steps per Second: 7,009.78928
Timestep Collection Time: 3.99649
Timestep Consumption Time: 3.13953
PPO Batch Consumption Time: 0.23590
Total Iteration Time: 7.13602
Cumulative Model Updates: 134,174
Cumulative Timesteps: 1,111,581,238
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.46119
Policy Entropy: 4.29387
Value Function Loss: 0.00324
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02211
Policy Update Magnitude: 0.95446
Value Function Update Magnitude: 0.82099
Collected Steps per Second: 12,645.28264
Overall Steps per Second: 7,005.73259
Timestep Collection Time: 3.95689
Timestep Consumption Time: 3.18526
PPO Batch Consumption Time: 0.23422
Total Iteration Time: 7.14215
Cumulative Model Updates: 134,183
Cumulative Timesteps: 1,111,631,274
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1111631274...
Checkpoint 1111631274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.11310
Policy Entropy: 4.29618
Value Function Loss: 0.00322
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.95983
Value Function Update Magnitude: 0.80760
Collected Steps per Second: 12,408.45909
Overall Steps per Second: 7,001.82508
Timestep Collection Time: 4.03193
Timestep Consumption Time: 3.11335
PPO Batch Consumption Time: 0.23399
Total Iteration Time: 7.14528
Cumulative Model Updates: 134,192
Cumulative Timesteps: 1,111,681,304
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.76360
Policy Entropy: 4.29894
Value Function Loss: 0.00324
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02262
Policy Update Magnitude: 0.96361
Value Function Update Magnitude: 0.80838
Collected Steps per Second: 12,845.77756
Overall Steps per Second: 7,096.67277
Timestep Collection Time: 3.89420
Timestep Consumption Time: 3.15474
PPO Batch Consumption Time: 0.23463
Total Iteration Time: 7.04894
Cumulative Model Updates: 134,201
Cumulative Timesteps: 1,111,731,328
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1111731328...
Checkpoint 1111731328 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.04096
Policy Entropy: 4.29864
Value Function Loss: 0.00325
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.97484
Value Function Update Magnitude: 0.81126
Collected Steps per Second: 12,684.12929
Overall Steps per Second: 7,004.71933
Timestep Collection Time: 3.94304
Timestep Consumption Time: 3.19701
PPO Batch Consumption Time: 0.23497
Total Iteration Time: 7.14004
Cumulative Model Updates: 134,210
Cumulative Timesteps: 1,111,781,342
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.05536
Policy Entropy: 4.29429
Value Function Loss: 0.00342
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.97661
Value Function Update Magnitude: 0.79208
Collected Steps per Second: 12,664.05215
Overall Steps per Second: 7,009.72012
Timestep Collection Time: 3.94897
Timestep Consumption Time: 3.18541
PPO Batch Consumption Time: 0.23454
Total Iteration Time: 7.13438
Cumulative Model Updates: 134,219
Cumulative Timesteps: 1,111,831,352
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1111831352...
Checkpoint 1111831352 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.74963
Policy Entropy: 4.29620
Value Function Loss: 0.00331
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.95471
Value Function Update Magnitude: 0.73842
Collected Steps per Second: 12,828.68309
Overall Steps per Second: 7,060.18652
Timestep Collection Time: 3.90095
Timestep Consumption Time: 3.18725
PPO Batch Consumption Time: 0.23491
Total Iteration Time: 7.08820
Cumulative Model Updates: 134,228
Cumulative Timesteps: 1,111,881,396
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.55025
Policy Entropy: 4.29475
Value Function Loss: 0.00332
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02409
Policy Update Magnitude: 0.93057
Value Function Update Magnitude: 0.72088
Collected Steps per Second: 12,428.87291
Overall Steps per Second: 6,776.28320
Timestep Collection Time: 4.02370
Timestep Consumption Time: 3.35646
PPO Batch Consumption Time: 0.24567
Total Iteration Time: 7.38015
Cumulative Model Updates: 134,237
Cumulative Timesteps: 1,111,931,406
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1111931406...
Checkpoint 1111931406 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.19279
Policy Entropy: 4.29279
Value Function Loss: 0.00333
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.93427
Value Function Update Magnitude: 0.75233
Collected Steps per Second: 12,609.91976
Overall Steps per Second: 7,092.65515
Timestep Collection Time: 3.96846
Timestep Consumption Time: 3.08700
PPO Batch Consumption Time: 0.23459
Total Iteration Time: 7.05547
Cumulative Model Updates: 134,246
Cumulative Timesteps: 1,111,981,448
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.33771
Policy Entropy: 4.28943
Value Function Loss: 0.00339
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02751
Policy Update Magnitude: 0.96922
Value Function Update Magnitude: 0.81342
Collected Steps per Second: 12,660.03980
Overall Steps per Second: 7,022.50069
Timestep Collection Time: 3.95196
Timestep Consumption Time: 3.17257
PPO Batch Consumption Time: 0.23474
Total Iteration Time: 7.12453
Cumulative Model Updates: 134,255
Cumulative Timesteps: 1,112,031,480
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1112031480...
Checkpoint 1112031480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.31035
Policy Entropy: 4.29122
Value Function Loss: 0.00328
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.97328
Value Function Update Magnitude: 0.80206
Collected Steps per Second: 12,631.38017
Overall Steps per Second: 7,017.48543
Timestep Collection Time: 3.96315
Timestep Consumption Time: 3.17046
PPO Batch Consumption Time: 0.23510
Total Iteration Time: 7.13361
Cumulative Model Updates: 134,264
Cumulative Timesteps: 1,112,081,540
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.50453
Policy Entropy: 4.29308
Value Function Loss: 0.00329
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.95828
Value Function Update Magnitude: 0.78810
Collected Steps per Second: 12,606.40005
Overall Steps per Second: 7,084.61104
Timestep Collection Time: 3.96830
Timestep Consumption Time: 3.09292
PPO Batch Consumption Time: 0.23408
Total Iteration Time: 7.06122
Cumulative Model Updates: 134,273
Cumulative Timesteps: 1,112,131,566
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1112131566...
Checkpoint 1112131566 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.84916
Policy Entropy: 4.29268
Value Function Loss: 0.00319
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.96583
Value Function Update Magnitude: 0.78158
Collected Steps per Second: 12,682.47026
Overall Steps per Second: 6,991.36294
Timestep Collection Time: 3.94371
Timestep Consumption Time: 3.21026
PPO Batch Consumption Time: 0.23430
Total Iteration Time: 7.15397
Cumulative Model Updates: 134,282
Cumulative Timesteps: 1,112,181,582
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.73551
Policy Entropy: 4.29089
Value Function Loss: 0.00311
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.95843
Value Function Update Magnitude: 0.78921
Collected Steps per Second: 12,240.21263
Overall Steps per Second: 6,879.71562
Timestep Collection Time: 4.08718
Timestep Consumption Time: 3.18463
PPO Batch Consumption Time: 0.23592
Total Iteration Time: 7.27181
Cumulative Model Updates: 134,291
Cumulative Timesteps: 1,112,231,610
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1112231610...
Checkpoint 1112231610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.54986
Policy Entropy: 4.29036
Value Function Loss: 0.00287
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02399
Policy Update Magnitude: 0.92950
Value Function Update Magnitude: 0.77129
Collected Steps per Second: 12,695.47160
Overall Steps per Second: 6,929.75276
Timestep Collection Time: 3.93936
Timestep Consumption Time: 3.27764
PPO Batch Consumption Time: 0.24358
Total Iteration Time: 7.21700
Cumulative Model Updates: 134,300
Cumulative Timesteps: 1,112,281,622
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47645
Policy Entropy: 4.29529
Value Function Loss: 0.00279
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.90532
Value Function Update Magnitude: 0.75730
Collected Steps per Second: 12,679.06956
Overall Steps per Second: 7,001.60489
Timestep Collection Time: 3.94650
Timestep Consumption Time: 3.20014
PPO Batch Consumption Time: 0.23578
Total Iteration Time: 7.14665
Cumulative Model Updates: 134,309
Cumulative Timesteps: 1,112,331,660
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1112331660...
Checkpoint 1112331660 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.12448
Policy Entropy: 4.29532
Value Function Loss: 0.00278
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02196
Policy Update Magnitude: 0.89393
Value Function Update Magnitude: 0.75059
Collected Steps per Second: 12,632.66878
Overall Steps per Second: 7,085.45864
Timestep Collection Time: 3.96005
Timestep Consumption Time: 3.10033
PPO Batch Consumption Time: 0.23501
Total Iteration Time: 7.06038
Cumulative Model Updates: 134,318
Cumulative Timesteps: 1,112,381,686
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.06939
Policy Entropy: 4.29633
Value Function Loss: 0.00285
Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02048
Policy Update Magnitude: 0.88601
Value Function Update Magnitude: 0.73993
Collected Steps per Second: 12,700.42267
Overall Steps per Second: 6,997.51825
Timestep Collection Time: 3.93845
Timestep Consumption Time: 3.20980
PPO Batch Consumption Time: 0.23474
Total Iteration Time: 7.14825
Cumulative Model Updates: 134,327
Cumulative Timesteps: 1,112,431,706
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1112431706...
Checkpoint 1112431706 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.99441
Policy Entropy: 4.29151
Value Function Loss: 0.00293
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.88157
Value Function Update Magnitude: 0.75407
Collected Steps per Second: 12,456.07707
Overall Steps per Second: 6,976.63512
Timestep Collection Time: 4.01410
Timestep Consumption Time: 3.15267
PPO Batch Consumption Time: 0.23456
Total Iteration Time: 7.16678
Cumulative Model Updates: 134,336
Cumulative Timesteps: 1,112,481,706
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.67306
Policy Entropy: 4.29419
Value Function Loss: 0.00289
Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02133
Policy Update Magnitude: 0.87328
Value Function Update Magnitude: 0.76835
Collected Steps per Second: 12,516.69441
Overall Steps per Second: 7,076.63472
Timestep Collection Time: 3.99482
Timestep Consumption Time: 3.07096
PPO Batch Consumption Time: 0.23461
Total Iteration Time: 7.06579
Cumulative Model Updates: 134,345
Cumulative Timesteps: 1,112,531,708
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1112531708...
Checkpoint 1112531708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.29809
Policy Entropy: 4.29397
Value Function Loss: 0.00300
Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02152
Policy Update Magnitude: 0.88965
Value Function Update Magnitude: 0.77847
Collected Steps per Second: 12,558.93495
Overall Steps per Second: 6,987.95321
Timestep Collection Time: 3.98410
Timestep Consumption Time: 3.17623
PPO Batch Consumption Time: 0.23503
Total Iteration Time: 7.16032
Cumulative Model Updates: 134,354
Cumulative Timesteps: 1,112,581,744
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.66278
Policy Entropy: 4.29670
Value Function Loss: 0.00297
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02186
Policy Update Magnitude: 0.89280
Value Function Update Magnitude: 0.77232
Collected Steps per Second: 12,466.86814
Overall Steps per Second: 6,905.74482
Timestep Collection Time: 4.01272
Timestep Consumption Time: 3.23140
PPO Batch Consumption Time: 0.24628
Total Iteration Time: 7.24411
Cumulative Model Updates: 134,363
Cumulative Timesteps: 1,112,631,770
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1112631770...
Checkpoint 1112631770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.36117
Policy Entropy: 4.29674
Value Function Loss: 0.00297
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02144
Policy Update Magnitude: 0.90056
Value Function Update Magnitude: 0.77952
Collected Steps per Second: 12,596.28618
Overall Steps per Second: 6,985.00011
Timestep Collection Time: 3.97387
Timestep Consumption Time: 3.19234
PPO Batch Consumption Time: 0.23526
Total Iteration Time: 7.16621
Cumulative Model Updates: 134,372
Cumulative Timesteps: 1,112,681,826
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.12106
Policy Entropy: 4.29716
Value Function Loss: 0.00289
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02367
Policy Update Magnitude: 0.90226
Value Function Update Magnitude: 0.80255
Collected Steps per Second: 12,560.87918
Overall Steps per Second: 6,993.45935
Timestep Collection Time: 3.98332
Timestep Consumption Time: 3.17108
PPO Batch Consumption Time: 0.23449
Total Iteration Time: 7.15440
Cumulative Model Updates: 134,381
Cumulative Timesteps: 1,112,731,860
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1112731860...
Checkpoint 1112731860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.60087
Policy Entropy: 4.29616
Value Function Loss: 0.00301
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.90177
Value Function Update Magnitude: 0.78851
Collected Steps per Second: 11,592.96654
Overall Steps per Second: 6,712.90258
Timestep Collection Time: 4.31469
Timestep Consumption Time: 3.13664
PPO Batch Consumption Time: 0.23715
Total Iteration Time: 7.45132
Cumulative Model Updates: 134,390
Cumulative Timesteps: 1,112,781,880
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.66299
Policy Entropy: 4.29135
Value Function Loss: 0.00309
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02219
Policy Update Magnitude: 0.90380
Value Function Update Magnitude: 0.79924
Collected Steps per Second: 12,355.73764
Overall Steps per Second: 6,947.68286
Timestep Collection Time: 4.04800
Timestep Consumption Time: 3.15095
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 7.19895
Cumulative Model Updates: 134,399
Cumulative Timesteps: 1,112,831,896
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1112831896...
Checkpoint 1112831896 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.10532
Policy Entropy: 4.29164
Value Function Loss: 0.00319
Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.90892
Value Function Update Magnitude: 0.81882
Collected Steps per Second: 12,964.63037
Overall Steps per Second: 7,187.00610
Timestep Collection Time: 3.85973
Timestep Consumption Time: 3.10283
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.96257
Cumulative Model Updates: 134,408
Cumulative Timesteps: 1,112,881,936
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.38713
Policy Entropy: 4.29129
Value Function Loss: 0.00300
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02184
Policy Update Magnitude: 0.90853
Value Function Update Magnitude: 0.77107
Collected Steps per Second: 13,050.96323
Overall Steps per Second: 7,122.82843
Timestep Collection Time: 3.83267
Timestep Consumption Time: 3.18982
PPO Batch Consumption Time: 0.22989
Total Iteration Time: 7.02249
Cumulative Model Updates: 134,417
Cumulative Timesteps: 1,112,931,956
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1112931956...
Checkpoint 1112931956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01417
Policy Entropy: 4.29090
Value Function Loss: 0.00296
Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.88500
Value Function Update Magnitude: 0.74783
Collected Steps per Second: 12,361.45811
Overall Steps per Second: 6,766.14696
Timestep Collection Time: 4.04661
Timestep Consumption Time: 3.34637
PPO Batch Consumption Time: 0.24122
Total Iteration Time: 7.39298
Cumulative Model Updates: 134,426
Cumulative Timesteps: 1,112,981,978
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.95218
Policy Entropy: 4.29134
Value Function Loss: 0.00291
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.87877
Value Function Update Magnitude: 0.76087
Collected Steps per Second: 12,889.82905
Overall Steps per Second: 7,252.19948
Timestep Collection Time: 3.87980
Timestep Consumption Time: 3.01604
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.89584
Cumulative Model Updates: 134,435
Cumulative Timesteps: 1,113,031,988
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1113031988...
Checkpoint 1113031988 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.82949
Policy Entropy: 4.28963
Value Function Loss: 0.00300
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.89017
Value Function Update Magnitude: 0.76407
Collected Steps per Second: 13,020.46955
Overall Steps per Second: 7,167.41180
Timestep Collection Time: 3.84057
Timestep Consumption Time: 3.13629
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.97686
Cumulative Model Updates: 134,444
Cumulative Timesteps: 1,113,081,994
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.40441
Policy Entropy: 4.28882
Value Function Loss: 0.00305
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.90236
Value Function Update Magnitude: 0.77800
Collected Steps per Second: 12,958.29188
Overall Steps per Second: 7,204.39548
Timestep Collection Time: 3.86285
Timestep Consumption Time: 3.08513
PPO Batch Consumption Time: 0.22773
Total Iteration Time: 6.94798
Cumulative Model Updates: 134,453
Cumulative Timesteps: 1,113,132,050
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1113132050...
Checkpoint 1113132050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.76460
Policy Entropy: 4.28596
Value Function Loss: 0.00311
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02286
Policy Update Magnitude: 0.90373
Value Function Update Magnitude: 0.77395
Collected Steps per Second: 13,040.71190
Overall Steps per Second: 7,179.56165
Timestep Collection Time: 3.83599
Timestep Consumption Time: 3.13157
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.96756
Cumulative Model Updates: 134,462
Cumulative Timesteps: 1,113,182,074
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.72319
Policy Entropy: 4.28948
Value Function Loss: 0.00304
Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02235
Policy Update Magnitude: 0.89095
Value Function Update Magnitude: 0.75129
Collected Steps per Second: 12,976.96731
Overall Steps per Second: 7,162.77126
Timestep Collection Time: 3.85421
Timestep Consumption Time: 3.12856
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.98277
Cumulative Model Updates: 134,471
Cumulative Timesteps: 1,113,232,090
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1113232090...
Checkpoint 1113232090 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.64357
Policy Entropy: 4.28763
Value Function Loss: 0.00305
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.88754
Value Function Update Magnitude: 0.73175
Collected Steps per Second: 13,049.30000
Overall Steps per Second: 7,210.44669
Timestep Collection Time: 3.83316
Timestep Consumption Time: 3.10400
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.93716
Cumulative Model Updates: 134,480
Cumulative Timesteps: 1,113,282,110
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.92840
Policy Entropy: 4.28865
Value Function Loss: 0.00305
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.90001
Value Function Update Magnitude: 0.76831
Collected Steps per Second: 13,371.66012
Overall Steps per Second: 7,113.26145
Timestep Collection Time: 3.74120
Timestep Consumption Time: 3.29158
PPO Batch Consumption Time: 0.24112
Total Iteration Time: 7.03278
Cumulative Model Updates: 134,489
Cumulative Timesteps: 1,113,332,136
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1113332136...
Checkpoint 1113332136 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.79737
Policy Entropy: 4.28993
Value Function Loss: 0.00299
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.91550
Value Function Update Magnitude: 0.79469
Collected Steps per Second: 12,951.53742
Overall Steps per Second: 7,152.11663
Timestep Collection Time: 3.86240
Timestep Consumption Time: 3.13189
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.99429
Cumulative Model Updates: 134,498
Cumulative Timesteps: 1,113,382,160
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.68591
Policy Entropy: 4.29039
Value Function Loss: 0.00296
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.91352
Value Function Update Magnitude: 0.77848
Collected Steps per Second: 12,955.57384
Overall Steps per Second: 7,250.87420
Timestep Collection Time: 3.85965
Timestep Consumption Time: 3.03662
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.89627
Cumulative Model Updates: 134,507
Cumulative Timesteps: 1,113,432,164
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1113432164...
Checkpoint 1113432164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.93882
Policy Entropy: 4.29801
Value Function Loss: 0.00283
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.89814
Value Function Update Magnitude: 0.75698
Collected Steps per Second: 12,823.37789
Overall Steps per Second: 7,124.41021
Timestep Collection Time: 3.89975
Timestep Consumption Time: 3.11950
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 7.01925
Cumulative Model Updates: 134,516
Cumulative Timesteps: 1,113,482,172
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.09163
Policy Entropy: 4.29832
Value Function Loss: 0.00286
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02216
Policy Update Magnitude: 0.90533
Value Function Update Magnitude: 0.75367
Collected Steps per Second: 12,874.45746
Overall Steps per Second: 7,167.72649
Timestep Collection Time: 3.88366
Timestep Consumption Time: 3.09205
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.97571
Cumulative Model Updates: 134,525
Cumulative Timesteps: 1,113,532,172
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1113532172...
Checkpoint 1113532172 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.57320
Policy Entropy: 4.30142
Value Function Loss: 0.00298
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.91998
Value Function Update Magnitude: 0.78570
Collected Steps per Second: 13,319.83310
Overall Steps per Second: 7,141.63642
Timestep Collection Time: 3.75470
Timestep Consumption Time: 3.24818
PPO Batch Consumption Time: 0.24026
Total Iteration Time: 7.00288
Cumulative Model Updates: 134,534
Cumulative Timesteps: 1,113,582,184
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.15587
Policy Entropy: 4.29924
Value Function Loss: 0.00300
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02626
Policy Update Magnitude: 0.93852
Value Function Update Magnitude: 0.79105
Collected Steps per Second: 12,443.37020
Overall Steps per Second: 6,989.26616
Timestep Collection Time: 4.02045
Timestep Consumption Time: 3.13738
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 7.15783
Cumulative Model Updates: 134,543
Cumulative Timesteps: 1,113,632,212
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1113632212...
Checkpoint 1113632212 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.32790
Policy Entropy: 4.30149
Value Function Loss: 0.00303
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02799
Policy Update Magnitude: 0.92566
Value Function Update Magnitude: 0.77673
Collected Steps per Second: 13,038.45996
Overall Steps per Second: 7,173.67565
Timestep Collection Time: 3.83527
Timestep Consumption Time: 3.13550
PPO Batch Consumption Time: 0.23235
Total Iteration Time: 6.97076
Cumulative Model Updates: 134,552
Cumulative Timesteps: 1,113,682,218
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.46656
Policy Entropy: 4.30550
Value Function Loss: 0.00285
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02718
Policy Update Magnitude: 0.90980
Value Function Update Magnitude: 0.75284
Collected Steps per Second: 12,465.53901
Overall Steps per Second: 6,926.65974
Timestep Collection Time: 4.01218
Timestep Consumption Time: 3.20833
PPO Batch Consumption Time: 0.23461
Total Iteration Time: 7.22051
Cumulative Model Updates: 134,561
Cumulative Timesteps: 1,113,732,232
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1113732232...
Checkpoint 1113732232 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.00414
Policy Entropy: 4.30231
Value Function Loss: 0.00302
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02574
Policy Update Magnitude: 0.91210
Value Function Update Magnitude: 0.73198
Collected Steps per Second: 12,245.81181
Overall Steps per Second: 6,918.82493
Timestep Collection Time: 4.08678
Timestep Consumption Time: 3.14652
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 7.23331
Cumulative Model Updates: 134,570
Cumulative Timesteps: 1,113,782,278
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.45682
Policy Entropy: 4.29861
Value Function Loss: 0.00320
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.93740
Value Function Update Magnitude: 0.74961
Collected Steps per Second: 12,181.36824
Overall Steps per Second: 6,947.45289
Timestep Collection Time: 4.10594
Timestep Consumption Time: 3.09324
PPO Batch Consumption Time: 0.23327
Total Iteration Time: 7.19919
Cumulative Model Updates: 134,579
Cumulative Timesteps: 1,113,832,294
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1113832294...
Checkpoint 1113832294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.08553
Policy Entropy: 4.29819
Value Function Loss: 0.00326
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.94454
Value Function Update Magnitude: 0.77166
Collected Steps per Second: 11,838.44168
Overall Steps per Second: 6,763.27984
Timestep Collection Time: 4.22454
Timestep Consumption Time: 3.17009
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 7.39464
Cumulative Model Updates: 134,588
Cumulative Timesteps: 1,113,882,306
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.61807
Policy Entropy: 4.29754
Value Function Loss: 0.00311
Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02248
Policy Update Magnitude: 0.91899
Value Function Update Magnitude: 0.75424
Collected Steps per Second: 12,841.41938
Overall Steps per Second: 7,163.40531
Timestep Collection Time: 3.89677
Timestep Consumption Time: 3.08874
PPO Batch Consumption Time: 0.22923
Total Iteration Time: 6.98550
Cumulative Model Updates: 134,597
Cumulative Timesteps: 1,113,932,346
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1113932346...
Checkpoint 1113932346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.76270
Policy Entropy: 4.30073
Value Function Loss: 0.00288
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02250
Policy Update Magnitude: 0.87882
Value Function Update Magnitude: 0.73434
Collected Steps per Second: 13,122.12407
Overall Steps per Second: 7,241.34729
Timestep Collection Time: 3.81112
Timestep Consumption Time: 3.09505
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.90617
Cumulative Model Updates: 134,606
Cumulative Timesteps: 1,113,982,356
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.98846
Policy Entropy: 4.30055
Value Function Loss: 0.00284
Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02154
Policy Update Magnitude: 0.87875
Value Function Update Magnitude: 0.73070
Collected Steps per Second: 12,905.55964
Overall Steps per Second: 7,108.38990
Timestep Collection Time: 3.87678
Timestep Consumption Time: 3.16166
PPO Batch Consumption Time: 0.22974
Total Iteration Time: 7.03844
Cumulative Model Updates: 134,615
Cumulative Timesteps: 1,114,032,388
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1114032388...
Checkpoint 1114032388 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.53188
Policy Entropy: 4.30144
Value Function Loss: 0.00289
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02159
Policy Update Magnitude: 0.88910
Value Function Update Magnitude: 0.74626
Collected Steps per Second: 12,810.45422
Overall Steps per Second: 7,228.35177
Timestep Collection Time: 3.90494
Timestep Consumption Time: 3.01559
PPO Batch Consumption Time: 0.22925
Total Iteration Time: 6.92053
Cumulative Model Updates: 134,624
Cumulative Timesteps: 1,114,082,412
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.29464
Policy Entropy: 4.30492
Value Function Loss: 0.00285
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.89653
Value Function Update Magnitude: 0.75501
Collected Steps per Second: 12,917.94017
Overall Steps per Second: 7,140.22245
Timestep Collection Time: 3.87306
Timestep Consumption Time: 3.13400
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 7.00706
Cumulative Model Updates: 134,633
Cumulative Timesteps: 1,114,132,444
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1114132444...
Checkpoint 1114132444 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.38636
Policy Entropy: 4.30091
Value Function Loss: 0.00281
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02299
Policy Update Magnitude: 0.88596
Value Function Update Magnitude: 0.77272
Collected Steps per Second: 12,886.30055
Overall Steps per Second: 7,159.85173
Timestep Collection Time: 3.88257
Timestep Consumption Time: 3.10528
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.98785
Cumulative Model Updates: 134,642
Cumulative Timesteps: 1,114,182,476
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.31707
Policy Entropy: 4.29839
Value Function Loss: 0.00286
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02326
Policy Update Magnitude: 0.88283
Value Function Update Magnitude: 0.77094
Collected Steps per Second: 12,954.87970
Overall Steps per Second: 7,259.88624
Timestep Collection Time: 3.86248
Timestep Consumption Time: 3.02991
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.89239
Cumulative Model Updates: 134,651
Cumulative Timesteps: 1,114,232,514
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1114232514...
Checkpoint 1114232514 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.84524
Policy Entropy: 4.29283
Value Function Loss: 0.00294
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.89004
Value Function Update Magnitude: 0.79375
Collected Steps per Second: 12,962.77283
Overall Steps per Second: 7,131.23752
Timestep Collection Time: 3.85890
Timestep Consumption Time: 3.15559
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 7.01449
Cumulative Model Updates: 134,660
Cumulative Timesteps: 1,114,282,536
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.03022
Policy Entropy: 4.29275
Value Function Loss: 0.00298
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.89240
Value Function Update Magnitude: 0.80255
Collected Steps per Second: 12,936.91344
Overall Steps per Second: 7,279.37882
Timestep Collection Time: 3.86599
Timestep Consumption Time: 3.00465
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.87064
Cumulative Model Updates: 134,669
Cumulative Timesteps: 1,114,332,550
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1114332550...
Checkpoint 1114332550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.04358
Policy Entropy: 4.29411
Value Function Loss: 0.00309
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.91194
Value Function Update Magnitude: 0.79910
Collected Steps per Second: 12,176.81558
Overall Steps per Second: 6,729.93621
Timestep Collection Time: 4.10879
Timestep Consumption Time: 3.32545
PPO Batch Consumption Time: 0.24093
Total Iteration Time: 7.43425
Cumulative Model Updates: 134,678
Cumulative Timesteps: 1,114,382,582
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.50358
Policy Entropy: 4.29952
Value Function Loss: 0.00297
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02512
Policy Update Magnitude: 0.90681
Value Function Update Magnitude: 0.79906
Collected Steps per Second: 12,637.80345
Overall Steps per Second: 7,110.99608
Timestep Collection Time: 3.95686
Timestep Consumption Time: 3.07535
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 7.03221
Cumulative Model Updates: 134,687
Cumulative Timesteps: 1,114,432,588
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1114432588...
Checkpoint 1114432588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.70502
Policy Entropy: 4.30189
Value Function Loss: 0.00295
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02236
Policy Update Magnitude: 0.90735
Value Function Update Magnitude: 0.76509
Collected Steps per Second: 12,815.34024
Overall Steps per Second: 7,199.02397
Timestep Collection Time: 3.90298
Timestep Consumption Time: 3.04491
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.94789
Cumulative Model Updates: 134,696
Cumulative Timesteps: 1,114,482,606
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35333
Policy Entropy: 4.30044
Value Function Loss: 0.00296
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02574
Policy Update Magnitude: 0.90892
Value Function Update Magnitude: 0.73867
Collected Steps per Second: 13,050.85544
Overall Steps per Second: 7,174.73502
Timestep Collection Time: 3.83285
Timestep Consumption Time: 3.13911
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.97196
Cumulative Model Updates: 134,705
Cumulative Timesteps: 1,114,532,628
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1114532628...
Checkpoint 1114532628 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.38679
Policy Entropy: 4.29822
Value Function Loss: 0.00303
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02721
Policy Update Magnitude: 0.90638
Value Function Update Magnitude: 0.76018
Collected Steps per Second: 12,878.20324
Overall Steps per Second: 7,139.35798
Timestep Collection Time: 3.88393
Timestep Consumption Time: 3.12203
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 7.00595
Cumulative Model Updates: 134,714
Cumulative Timesteps: 1,114,582,646
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.80327
Policy Entropy: 4.29735
Value Function Loss: 0.00305
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.90176
Value Function Update Magnitude: 0.76844
Collected Steps per Second: 13,212.30942
Overall Steps per Second: 7,245.49647
Timestep Collection Time: 3.78586
Timestep Consumption Time: 3.11774
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.90360
Cumulative Model Updates: 134,723
Cumulative Timesteps: 1,114,632,666
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1114632666...
Checkpoint 1114632666 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.02131
Policy Entropy: 4.29079
Value Function Loss: 0.00310
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.89411
Value Function Update Magnitude: 0.78073
Collected Steps per Second: 12,938.92122
Overall Steps per Second: 7,145.90831
Timestep Collection Time: 3.86539
Timestep Consumption Time: 3.13358
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.99897
Cumulative Model Updates: 134,732
Cumulative Timesteps: 1,114,682,680
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.72285
Policy Entropy: 4.29074
Value Function Loss: 0.00308
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.90041
Value Function Update Magnitude: 0.78067
Collected Steps per Second: 12,917.60452
Overall Steps per Second: 7,118.11641
Timestep Collection Time: 3.87239
Timestep Consumption Time: 3.15503
PPO Batch Consumption Time: 0.23064
Total Iteration Time: 7.02742
Cumulative Model Updates: 134,741
Cumulative Timesteps: 1,114,732,702
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1114732702...
Checkpoint 1114732702 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.87110
Policy Entropy: 4.29238
Value Function Loss: 0.00297
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.89629
Value Function Update Magnitude: 0.76199
Collected Steps per Second: 13,222.44327
Overall Steps per Second: 7,244.86925
Timestep Collection Time: 3.78357
Timestep Consumption Time: 3.12173
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.90530
Cumulative Model Updates: 134,750
Cumulative Timesteps: 1,114,782,730
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.74481
Policy Entropy: 4.29600
Value Function Loss: 0.00294
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02274
Policy Update Magnitude: 0.88273
Value Function Update Magnitude: 0.77938
Collected Steps per Second: 12,804.22116
Overall Steps per Second: 7,085.83828
Timestep Collection Time: 3.90809
Timestep Consumption Time: 3.15389
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 7.06197
Cumulative Model Updates: 134,759
Cumulative Timesteps: 1,114,832,770
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1114832770...
Checkpoint 1114832770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.58227
Policy Entropy: 4.29814
Value Function Loss: 0.00302
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.89467
Value Function Update Magnitude: 0.79202
Collected Steps per Second: 12,802.30596
Overall Steps per Second: 7,233.37452
Timestep Collection Time: 3.90695
Timestep Consumption Time: 3.00794
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.91489
Cumulative Model Updates: 134,768
Cumulative Timesteps: 1,114,882,788
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.27043
Policy Entropy: 4.29108
Value Function Loss: 0.00319
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02603
Policy Update Magnitude: 0.90834
Value Function Update Magnitude: 0.81151
Collected Steps per Second: 12,995.27569
Overall Steps per Second: 7,171.39906
Timestep Collection Time: 3.84909
Timestep Consumption Time: 3.12584
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.97493
Cumulative Model Updates: 134,777
Cumulative Timesteps: 1,114,932,808
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1114932808...
Checkpoint 1114932808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.83725
Policy Entropy: 4.29147
Value Function Loss: 0.00332
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.92797
Value Function Update Magnitude: 0.79840
Collected Steps per Second: 12,834.38225
Overall Steps per Second: 7,153.75099
Timestep Collection Time: 3.89688
Timestep Consumption Time: 3.09442
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.99130
Cumulative Model Updates: 134,786
Cumulative Timesteps: 1,114,982,822
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.34762
Policy Entropy: 4.28956
Value Function Loss: 0.00335
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03059
Policy Update Magnitude: 0.93476
Value Function Update Magnitude: 0.79641
Collected Steps per Second: 13,200.10772
Overall Steps per Second: 7,232.13140
Timestep Collection Time: 3.79027
Timestep Consumption Time: 3.12774
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.91802
Cumulative Model Updates: 134,795
Cumulative Timesteps: 1,115,032,854
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1115032854...
Checkpoint 1115032854 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.96044
Policy Entropy: 4.29210
Value Function Loss: 0.00345
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02916
Policy Update Magnitude: 0.93231
Value Function Update Magnitude: 0.76734
Collected Steps per Second: 12,449.76486
Overall Steps per Second: 6,781.22623
Timestep Collection Time: 4.01646
Timestep Consumption Time: 3.35743
PPO Batch Consumption Time: 0.24830
Total Iteration Time: 7.37389
Cumulative Model Updates: 134,804
Cumulative Timesteps: 1,115,082,858
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.37850
Policy Entropy: 4.29308
Value Function Loss: 0.00321
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.93819
Value Function Update Magnitude: 0.75308
Collected Steps per Second: 12,346.32214
Overall Steps per Second: 6,909.63973
Timestep Collection Time: 4.05044
Timestep Consumption Time: 3.18699
PPO Batch Consumption Time: 0.22952
Total Iteration Time: 7.23743
Cumulative Model Updates: 134,813
Cumulative Timesteps: 1,115,132,866
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1115132866...
Checkpoint 1115132866 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.91097
Policy Entropy: 4.29174
Value Function Loss: 0.00320
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.94461
Value Function Update Magnitude: 0.74970
Collected Steps per Second: 12,364.57873
Overall Steps per Second: 6,742.79475
Timestep Collection Time: 4.04559
Timestep Consumption Time: 3.37300
PPO Batch Consumption Time: 0.24330
Total Iteration Time: 7.41859
Cumulative Model Updates: 134,822
Cumulative Timesteps: 1,115,182,888
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.36254
Policy Entropy: 4.29649
Value Function Loss: 0.00305
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.94266
Value Function Update Magnitude: 0.76263
Collected Steps per Second: 11,167.65753
Overall Steps per Second: 6,508.30816
Timestep Collection Time: 4.47972
Timestep Consumption Time: 3.20707
PPO Batch Consumption Time: 0.22923
Total Iteration Time: 7.68679
Cumulative Model Updates: 134,831
Cumulative Timesteps: 1,115,232,916
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1115232916...
Checkpoint 1115232916 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.06297
Policy Entropy: 4.29077
Value Function Loss: 0.00322
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02456
Policy Update Magnitude: 0.94572
Value Function Update Magnitude: 0.77438
Collected Steps per Second: 12,675.59385
Overall Steps per Second: 7,132.11694
Timestep Collection Time: 3.94711
Timestep Consumption Time: 3.06792
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 7.01503
Cumulative Model Updates: 134,840
Cumulative Timesteps: 1,115,282,948
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.49315
Policy Entropy: 4.29165
Value Function Loss: 0.00319
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.95039
Value Function Update Magnitude: 0.75642
Collected Steps per Second: 13,105.82779
Overall Steps per Second: 7,207.34804
Timestep Collection Time: 3.81616
Timestep Consumption Time: 3.12314
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.93931
Cumulative Model Updates: 134,849
Cumulative Timesteps: 1,115,332,962
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1115332962...
Checkpoint 1115332962 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64168
Policy Entropy: 4.29224
Value Function Loss: 0.00318
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.95874
Value Function Update Magnitude: 0.75413
Collected Steps per Second: 12,871.17302
Overall Steps per Second: 7,169.44686
Timestep Collection Time: 3.88714
Timestep Consumption Time: 3.09137
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.97850
Cumulative Model Updates: 134,858
Cumulative Timesteps: 1,115,382,994
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.69433
Policy Entropy: 4.29318
Value Function Loss: 0.00312
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.96051
Value Function Update Magnitude: 0.76171
Collected Steps per Second: 12,823.30687
Overall Steps per Second: 7,162.03277
Timestep Collection Time: 3.89977
Timestep Consumption Time: 3.08260
PPO Batch Consumption Time: 0.23337
Total Iteration Time: 6.98238
Cumulative Model Updates: 134,867
Cumulative Timesteps: 1,115,433,002
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1115433002...
Checkpoint 1115433002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.26956
Policy Entropy: 4.29270
Value Function Loss: 0.00313
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02636
Policy Update Magnitude: 0.94169
Value Function Update Magnitude: 0.74169
Collected Steps per Second: 12,995.38744
Overall Steps per Second: 7,179.78382
Timestep Collection Time: 3.84860
Timestep Consumption Time: 3.11735
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.96595
Cumulative Model Updates: 134,876
Cumulative Timesteps: 1,115,483,016
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.20483
Policy Entropy: 4.28979
Value Function Loss: 0.00321
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.94226
Value Function Update Magnitude: 0.76112
Collected Steps per Second: 12,952.35052
Overall Steps per Second: 7,179.04073
Timestep Collection Time: 3.86046
Timestep Consumption Time: 3.10454
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.96500
Cumulative Model Updates: 134,885
Cumulative Timesteps: 1,115,533,018
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1115533018...
Checkpoint 1115533018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36860
Policy Entropy: 4.28745
Value Function Loss: 0.00333
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03125
Policy Update Magnitude: 0.94520
Value Function Update Magnitude: 0.78006
Collected Steps per Second: 13,257.15550
Overall Steps per Second: 7,251.63372
Timestep Collection Time: 3.77245
Timestep Consumption Time: 3.12420
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.89665
Cumulative Model Updates: 134,894
Cumulative Timesteps: 1,115,583,030
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.00777
Policy Entropy: 4.28783
Value Function Loss: 0.00342
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.96012
Value Function Update Magnitude: 0.82407
Collected Steps per Second: 13,222.74414
Overall Steps per Second: 7,223.95414
Timestep Collection Time: 3.78151
Timestep Consumption Time: 3.14018
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.92169
Cumulative Model Updates: 134,903
Cumulative Timesteps: 1,115,633,032
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1115633032...
Checkpoint 1115633032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.55855
Policy Entropy: 4.28967
Value Function Loss: 0.00343
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02810
Policy Update Magnitude: 0.96431
Value Function Update Magnitude: 0.86319
Collected Steps per Second: 12,884.88599
Overall Steps per Second: 7,235.13955
Timestep Collection Time: 3.88191
Timestep Consumption Time: 3.03129
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.91320
Cumulative Model Updates: 134,912
Cumulative Timesteps: 1,115,683,050
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.72675
Policy Entropy: 4.28723
Value Function Loss: 0.00344
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02844
Policy Update Magnitude: 0.97335
Value Function Update Magnitude: 0.86368
Collected Steps per Second: 12,861.04727
Overall Steps per Second: 7,124.57806
Timestep Collection Time: 3.88802
Timestep Consumption Time: 3.13050
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 7.01852
Cumulative Model Updates: 134,921
Cumulative Timesteps: 1,115,733,054
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1115733054...
Checkpoint 1115733054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.20617
Policy Entropy: 4.28486
Value Function Loss: 0.00356
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.96910
Value Function Update Magnitude: 0.83244
Collected Steps per Second: 12,957.05219
Overall Steps per Second: 7,109.20790
Timestep Collection Time: 3.86106
Timestep Consumption Time: 3.17601
PPO Batch Consumption Time: 0.23046
Total Iteration Time: 7.03707
Cumulative Model Updates: 134,930
Cumulative Timesteps: 1,115,783,082
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.53569
Policy Entropy: 4.28326
Value Function Loss: 0.00347
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02860
Policy Update Magnitude: 0.96473
Value Function Update Magnitude: 0.82365
Collected Steps per Second: 12,958.40366
Overall Steps per Second: 7,249.17016
Timestep Collection Time: 3.86097
Timestep Consumption Time: 3.04079
PPO Batch Consumption Time: 0.22984
Total Iteration Time: 6.90176
Cumulative Model Updates: 134,939
Cumulative Timesteps: 1,115,833,114
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1115833114...
Checkpoint 1115833114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.90255
Policy Entropy: 4.28802
Value Function Loss: 0.00338
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.94921
Value Function Update Magnitude: 0.83353
Collected Steps per Second: 12,919.69908
Overall Steps per Second: 7,168.82526
Timestep Collection Time: 3.87145
Timestep Consumption Time: 3.10570
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.97715
Cumulative Model Updates: 134,948
Cumulative Timesteps: 1,115,883,132
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.69711
Policy Entropy: 4.29024
Value Function Loss: 0.00313
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.94754
Value Function Update Magnitude: 0.81944
Collected Steps per Second: 12,934.54885
Overall Steps per Second: 7,267.83870
Timestep Collection Time: 3.86701
Timestep Consumption Time: 3.01509
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.88210
Cumulative Model Updates: 134,957
Cumulative Timesteps: 1,115,933,150
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1115933150...
Checkpoint 1115933150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.83477
Policy Entropy: 4.28960
Value Function Loss: 0.00321
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.93764
Value Function Update Magnitude: 0.77975
Collected Steps per Second: 13,054.36509
Overall Steps per Second: 7,181.43838
Timestep Collection Time: 3.83060
Timestep Consumption Time: 3.13263
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.96323
Cumulative Model Updates: 134,966
Cumulative Timesteps: 1,115,983,156
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.50814
Policy Entropy: 4.28941
Value Function Loss: 0.00313
Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.93411
Value Function Update Magnitude: 0.78685
Collected Steps per Second: 12,658.94669
Overall Steps per Second: 7,102.73410
Timestep Collection Time: 3.95151
Timestep Consumption Time: 3.09113
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 7.04264
Cumulative Model Updates: 134,975
Cumulative Timesteps: 1,116,033,178
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1116033178...
Checkpoint 1116033178 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.29798
Policy Entropy: 4.28766
Value Function Loss: 0.00314
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.93209
Value Function Update Magnitude: 0.81499
Collected Steps per Second: 12,892.15607
Overall Steps per Second: 7,258.26609
Timestep Collection Time: 3.88003
Timestep Consumption Time: 3.01169
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.89173
Cumulative Model Updates: 134,984
Cumulative Timesteps: 1,116,083,200
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.96444
Policy Entropy: 4.28846
Value Function Loss: 0.00310
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02513
Policy Update Magnitude: 0.93173
Value Function Update Magnitude: 0.79695
Collected Steps per Second: 12,897.22911
Overall Steps per Second: 7,098.70515
Timestep Collection Time: 3.87913
Timestep Consumption Time: 3.16864
PPO Batch Consumption Time: 0.22953
Total Iteration Time: 7.04776
Cumulative Model Updates: 134,993
Cumulative Timesteps: 1,116,133,230
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1116133230...
Checkpoint 1116133230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.45729
Policy Entropy: 4.28869
Value Function Loss: 0.00317
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.92840
Value Function Update Magnitude: 0.78302
Collected Steps per Second: 12,894.90485
Overall Steps per Second: 7,138.68209
Timestep Collection Time: 3.87983
Timestep Consumption Time: 3.12847
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 7.00830
Cumulative Model Updates: 135,002
Cumulative Timesteps: 1,116,183,260
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.08762
Policy Entropy: 4.28971
Value Function Loss: 0.00314
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03076
Policy Update Magnitude: 0.92943
Value Function Update Magnitude: 0.76074
Collected Steps per Second: 13,191.16192
Overall Steps per Second: 7,216.85957
Timestep Collection Time: 3.79163
Timestep Consumption Time: 3.13881
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.93044
Cumulative Model Updates: 135,011
Cumulative Timesteps: 1,116,233,276
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1116233276...
Checkpoint 1116233276 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.92925
Policy Entropy: 4.29119
Value Function Loss: 0.00315
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 0.92456
Value Function Update Magnitude: 0.76220
Collected Steps per Second: 13,009.44821
Overall Steps per Second: 7,179.31406
Timestep Collection Time: 3.84582
Timestep Consumption Time: 3.12309
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.96891
Cumulative Model Updates: 135,020
Cumulative Timesteps: 1,116,283,308
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.96629
Policy Entropy: 4.28913
Value Function Loss: 0.00319
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.92348
Value Function Update Magnitude: 0.75290
Collected Steps per Second: 12,835.32380
Overall Steps per Second: 7,163.72053
Timestep Collection Time: 3.89784
Timestep Consumption Time: 3.08596
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.98380
Cumulative Model Updates: 135,029
Cumulative Timesteps: 1,116,333,338
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1116333338...
Checkpoint 1116333338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.98782
Policy Entropy: 4.29353
Value Function Loss: 0.00309
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 0.92253
Value Function Update Magnitude: 0.76176
Collected Steps per Second: 13,152.28580
Overall Steps per Second: 7,227.72637
Timestep Collection Time: 3.80314
Timestep Consumption Time: 3.11743
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.92057
Cumulative Model Updates: 135,038
Cumulative Timesteps: 1,116,383,358
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.00088
Policy Entropy: 4.29384
Value Function Loss: 0.00306
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02834
Policy Update Magnitude: 0.92226
Value Function Update Magnitude: 0.73966
Collected Steps per Second: 12,794.25305
Overall Steps per Second: 7,115.85498
Timestep Collection Time: 3.90941
Timestep Consumption Time: 3.11968
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 7.02909
Cumulative Model Updates: 135,047
Cumulative Timesteps: 1,116,433,376
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1116433376...
Checkpoint 1116433376 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.09605
Policy Entropy: 4.29788
Value Function Loss: 0.00301
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.92903
Value Function Update Magnitude: 0.76244
Collected Steps per Second: 12,869.63287
Overall Steps per Second: 7,086.27082
Timestep Collection Time: 3.88807
Timestep Consumption Time: 3.17319
PPO Batch Consumption Time: 0.24118
Total Iteration Time: 7.06126
Cumulative Model Updates: 135,056
Cumulative Timesteps: 1,116,483,414
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.58936
Policy Entropy: 4.29940
Value Function Loss: 0.00301
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.92419
Value Function Update Magnitude: 0.77577
Collected Steps per Second: 13,009.44518
Overall Steps per Second: 7,184.57523
Timestep Collection Time: 3.84674
Timestep Consumption Time: 3.11873
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.96548
Cumulative Model Updates: 135,065
Cumulative Timesteps: 1,116,533,458
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1116533458...
Checkpoint 1116533458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.07540
Policy Entropy: 4.29969
Value Function Loss: 0.00302
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.90962
Value Function Update Magnitude: 0.74036
Collected Steps per Second: 12,894.34363
Overall Steps per Second: 7,165.45139
Timestep Collection Time: 3.88077
Timestep Consumption Time: 3.10274
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.98351
Cumulative Model Updates: 135,074
Cumulative Timesteps: 1,116,583,498
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.05757
Policy Entropy: 4.29731
Value Function Loss: 0.00303
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.90923
Value Function Update Magnitude: 0.73722
Collected Steps per Second: 13,067.65143
Overall Steps per Second: 7,298.91409
Timestep Collection Time: 3.82640
Timestep Consumption Time: 3.02421
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.85061
Cumulative Model Updates: 135,083
Cumulative Timesteps: 1,116,633,500
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1116633500...
Checkpoint 1116633500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.52730
Policy Entropy: 4.29761
Value Function Loss: 0.00301
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02435
Policy Update Magnitude: 0.91611
Value Function Update Magnitude: 0.75056
Collected Steps per Second: 12,908.32863
Overall Steps per Second: 7,150.58596
Timestep Collection Time: 3.87641
Timestep Consumption Time: 3.12134
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.99775
Cumulative Model Updates: 135,092
Cumulative Timesteps: 1,116,683,538
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.05520
Policy Entropy: 4.30027
Value Function Loss: 0.00292
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02545
Policy Update Magnitude: 0.91600
Value Function Update Magnitude: 0.74544
Collected Steps per Second: 13,038.14703
Overall Steps per Second: 7,213.48441
Timestep Collection Time: 3.83736
Timestep Consumption Time: 3.09854
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.93590
Cumulative Model Updates: 135,101
Cumulative Timesteps: 1,116,733,570
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1116733570...
Checkpoint 1116733570 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.10720
Policy Entropy: 4.30040
Value Function Loss: 0.00296
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.91157
Value Function Update Magnitude: 0.73963
Collected Steps per Second: 13,175.59901
Overall Steps per Second: 7,236.71457
Timestep Collection Time: 3.79763
Timestep Consumption Time: 3.11656
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.91419
Cumulative Model Updates: 135,110
Cumulative Timesteps: 1,116,783,606
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.59500
Policy Entropy: 4.29793
Value Function Loss: 0.00302
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.90697
Value Function Update Magnitude: 0.73530
Collected Steps per Second: 12,882.21696
Overall Steps per Second: 6,985.40508
Timestep Collection Time: 3.88365
Timestep Consumption Time: 3.27843
PPO Batch Consumption Time: 0.24029
Total Iteration Time: 7.16208
Cumulative Model Updates: 135,119
Cumulative Timesteps: 1,116,833,636
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1116833636...
Checkpoint 1116833636 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.98760
Policy Entropy: 4.29630
Value Function Loss: 0.00299
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.91758
Value Function Update Magnitude: 0.76426
Collected Steps per Second: 12,724.51514
Overall Steps per Second: 7,217.42465
Timestep Collection Time: 3.93084
Timestep Consumption Time: 2.99934
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.93017
Cumulative Model Updates: 135,128
Cumulative Timesteps: 1,116,883,654
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.35058
Policy Entropy: 4.29627
Value Function Loss: 0.00292
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.91303
Value Function Update Magnitude: 0.74258
Collected Steps per Second: 12,479.20465
Overall Steps per Second: 6,818.96673
Timestep Collection Time: 4.01099
Timestep Consumption Time: 3.32942
PPO Batch Consumption Time: 0.24901
Total Iteration Time: 7.34041
Cumulative Model Updates: 135,137
Cumulative Timesteps: 1,116,933,708
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1116933708...
Checkpoint 1116933708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.19169
Policy Entropy: 4.30226
Value Function Loss: 0.00299
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.91084
Value Function Update Magnitude: 0.76799
Collected Steps per Second: 11,346.34003
Overall Steps per Second: 6,510.74621
Timestep Collection Time: 4.40865
Timestep Consumption Time: 3.27434
PPO Batch Consumption Time: 0.24422
Total Iteration Time: 7.68299
Cumulative Model Updates: 135,146
Cumulative Timesteps: 1,116,983,730
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.94612
Policy Entropy: 4.30173
Value Function Loss: 0.00312
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.92775
Value Function Update Magnitude: 0.79738
Collected Steps per Second: 12,034.84793
Overall Steps per Second: 6,788.34723
Timestep Collection Time: 4.15593
Timestep Consumption Time: 3.21199
PPO Batch Consumption Time: 0.23056
Total Iteration Time: 7.36792
Cumulative Model Updates: 135,155
Cumulative Timesteps: 1,117,033,746
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1117033746...
Checkpoint 1117033746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.71835
Policy Entropy: 4.30215
Value Function Loss: 0.00317
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.92378
Value Function Update Magnitude: 0.78142
Collected Steps per Second: 12,907.04396
Overall Steps per Second: 7,115.09425
Timestep Collection Time: 3.87385
Timestep Consumption Time: 3.15346
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 7.02731
Cumulative Model Updates: 135,164
Cumulative Timesteps: 1,117,083,746
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.96826
Policy Entropy: 4.29829
Value Function Loss: 0.00315
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02621
Policy Update Magnitude: 0.91168
Value Function Update Magnitude: 0.76315
Collected Steps per Second: 12,947.51248
Overall Steps per Second: 7,178.19530
Timestep Collection Time: 3.86252
Timestep Consumption Time: 3.10441
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.96693
Cumulative Model Updates: 135,173
Cumulative Timesteps: 1,117,133,756
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1117133756...
Checkpoint 1117133756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.26163
Policy Entropy: 4.29479
Value Function Loss: 0.00299
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.90035
Value Function Update Magnitude: 0.72139
Collected Steps per Second: 13,268.19640
Overall Steps per Second: 7,191.32358
Timestep Collection Time: 3.76841
Timestep Consumption Time: 3.18441
PPO Batch Consumption Time: 0.23117
Total Iteration Time: 6.95282
Cumulative Model Updates: 135,182
Cumulative Timesteps: 1,117,183,756
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.48489
Policy Entropy: 4.29444
Value Function Loss: 0.00295
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.88934
Value Function Update Magnitude: 0.69177
Collected Steps per Second: 12,829.29921
Overall Steps per Second: 7,086.17727
Timestep Collection Time: 3.89982
Timestep Consumption Time: 3.16068
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 7.06051
Cumulative Model Updates: 135,191
Cumulative Timesteps: 1,117,233,788
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1117233788...
Checkpoint 1117233788 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.51881
Policy Entropy: 4.29495
Value Function Loss: 0.00289
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.88337
Value Function Update Magnitude: 0.69578
Collected Steps per Second: 13,004.74410
Overall Steps per Second: 7,258.10946
Timestep Collection Time: 3.84752
Timestep Consumption Time: 3.04629
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.89381
Cumulative Model Updates: 135,200
Cumulative Timesteps: 1,117,283,824
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.63552
Policy Entropy: 4.29879
Value Function Loss: 0.00288
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.89836
Value Function Update Magnitude: 0.71971
Collected Steps per Second: 12,940.54685
Overall Steps per Second: 7,143.55892
Timestep Collection Time: 3.86398
Timestep Consumption Time: 3.13561
PPO Batch Consumption Time: 0.22797
Total Iteration Time: 6.99959
Cumulative Model Updates: 135,209
Cumulative Timesteps: 1,117,333,826
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1117333826...
Checkpoint 1117333826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.40311
Policy Entropy: 4.29802
Value Function Loss: 0.00293
Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.89697
Value Function Update Magnitude: 0.75075
Collected Steps per Second: 13,123.49727
Overall Steps per Second: 7,251.39661
Timestep Collection Time: 3.81240
Timestep Consumption Time: 3.08724
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.89964
Cumulative Model Updates: 135,218
Cumulative Timesteps: 1,117,383,858
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.76215
Policy Entropy: 4.30095
Value Function Loss: 0.00294
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02451
Policy Update Magnitude: 0.91143
Value Function Update Magnitude: 0.76352
Collected Steps per Second: 13,156.03598
Overall Steps per Second: 7,204.00832
Timestep Collection Time: 3.80419
Timestep Consumption Time: 3.14306
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.94724
Cumulative Model Updates: 135,227
Cumulative Timesteps: 1,117,433,906
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1117433906...
Checkpoint 1117433906 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.50799
Policy Entropy: 4.30291
Value Function Loss: 0.00304
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02567
Policy Update Magnitude: 0.91970
Value Function Update Magnitude: 0.78581
Collected Steps per Second: 12,964.22746
Overall Steps per Second: 7,190.74383
Timestep Collection Time: 3.85908
Timestep Consumption Time: 3.09847
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.95756
Cumulative Model Updates: 135,236
Cumulative Timesteps: 1,117,483,936
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.08656
Policy Entropy: 4.30616
Value Function Loss: 0.00307
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.93041
Value Function Update Magnitude: 0.78108
Collected Steps per Second: 13,063.74739
Overall Steps per Second: 7,170.21112
Timestep Collection Time: 3.82754
Timestep Consumption Time: 3.14604
PPO Batch Consumption Time: 0.23009
Total Iteration Time: 6.97357
Cumulative Model Updates: 135,245
Cumulative Timesteps: 1,117,533,938
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1117533938...
Checkpoint 1117533938 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.43658
Policy Entropy: 4.30308
Value Function Loss: 0.00312
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02691
Policy Update Magnitude: 0.92477
Value Function Update Magnitude: 0.77382
Collected Steps per Second: 13,149.54630
Overall Steps per Second: 7,227.99689
Timestep Collection Time: 3.80500
Timestep Consumption Time: 3.11725
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.92225
Cumulative Model Updates: 135,254
Cumulative Timesteps: 1,117,583,972
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.68918
Policy Entropy: 4.29815
Value Function Loss: 0.00313
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02633
Policy Update Magnitude: 0.91600
Value Function Update Magnitude: 0.76837
Collected Steps per Second: 13,089.99932
Overall Steps per Second: 7,189.74796
Timestep Collection Time: 3.81971
Timestep Consumption Time: 3.13464
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.95435
Cumulative Model Updates: 135,263
Cumulative Timesteps: 1,117,633,972
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1117633972...
Checkpoint 1117633972 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.07542
Policy Entropy: 4.29436
Value Function Loss: 0.00297
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02372
Policy Update Magnitude: 0.90400
Value Function Update Magnitude: 0.74480
Collected Steps per Second: 12,887.95064
Overall Steps per Second: 7,241.87797
Timestep Collection Time: 3.88208
Timestep Consumption Time: 3.02663
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.90871
Cumulative Model Updates: 135,272
Cumulative Timesteps: 1,117,684,004
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.01537
Policy Entropy: 4.29576
Value Function Loss: 0.00295
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.89148
Value Function Update Magnitude: 0.70647
Collected Steps per Second: 13,019.15183
Overall Steps per Second: 7,185.73469
Timestep Collection Time: 3.84080
Timestep Consumption Time: 3.11798
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.95879
Cumulative Model Updates: 135,281
Cumulative Timesteps: 1,117,734,008
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1117734008...
Checkpoint 1117734008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.92893
Policy Entropy: 4.29720
Value Function Loss: 0.00293
Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.89428
Value Function Update Magnitude: 0.71103
Collected Steps per Second: 12,879.71277
Overall Steps per Second: 7,182.27201
Timestep Collection Time: 3.88254
Timestep Consumption Time: 3.07988
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.96242
Cumulative Model Updates: 135,290
Cumulative Timesteps: 1,117,784,014
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.74534
Policy Entropy: 4.29947
Value Function Loss: 0.00301
Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.91058
Value Function Update Magnitude: 0.72439
Collected Steps per Second: 13,294.99527
Overall Steps per Second: 7,272.60060
Timestep Collection Time: 3.76232
Timestep Consumption Time: 3.11555
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.87787
Cumulative Model Updates: 135,299
Cumulative Timesteps: 1,117,834,034
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1117834034...
Checkpoint 1117834034 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.14006
Policy Entropy: 4.29807
Value Function Loss: 0.00303
Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.91798
Value Function Update Magnitude: 0.71481
Collected Steps per Second: 12,942.69321
Overall Steps per Second: 7,061.82920
Timestep Collection Time: 3.86550
Timestep Consumption Time: 3.21907
PPO Batch Consumption Time: 0.23056
Total Iteration Time: 7.08457
Cumulative Model Updates: 135,308
Cumulative Timesteps: 1,117,884,064
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.02464
Policy Entropy: 4.29919
Value Function Loss: 0.00303
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.92793
Value Function Update Magnitude: 0.73724
Collected Steps per Second: 12,995.48400
Overall Steps per Second: 7,206.71459
Timestep Collection Time: 3.84980
Timestep Consumption Time: 3.09234
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.94214
Cumulative Model Updates: 135,317
Cumulative Timesteps: 1,117,934,094
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1117934094...
Checkpoint 1117934094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.17038
Policy Entropy: 4.29838
Value Function Loss: 0.00304
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.93129
Value Function Update Magnitude: 0.73223
Collected Steps per Second: 13,178.66677
Overall Steps per Second: 7,221.34621
Timestep Collection Time: 3.79629
Timestep Consumption Time: 3.13178
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.92807
Cumulative Model Updates: 135,326
Cumulative Timesteps: 1,117,984,124
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.60524
Policy Entropy: 4.29838
Value Function Loss: 0.00311
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.93424
Value Function Update Magnitude: 0.73217
Collected Steps per Second: 13,081.23643
Overall Steps per Second: 7,192.20258
Timestep Collection Time: 3.82487
Timestep Consumption Time: 3.13183
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.95670
Cumulative Model Updates: 135,335
Cumulative Timesteps: 1,118,034,158
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1118034158...
Checkpoint 1118034158 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.07506
Policy Entropy: 4.29669
Value Function Loss: 0.00309
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.93021
Value Function Update Magnitude: 0.73670
Collected Steps per Second: 12,881.61515
Overall Steps per Second: 7,244.63694
Timestep Collection Time: 3.88476
Timestep Consumption Time: 3.02269
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.90745
Cumulative Model Updates: 135,344
Cumulative Timesteps: 1,118,084,200
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.01179
Policy Entropy: 4.29502
Value Function Loss: 0.00314
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.94032
Value Function Update Magnitude: 0.74767
Collected Steps per Second: 12,973.24816
Overall Steps per Second: 7,168.86515
Timestep Collection Time: 3.85624
Timestep Consumption Time: 3.12227
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.97851
Cumulative Model Updates: 135,353
Cumulative Timesteps: 1,118,134,228
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1118134228...
Checkpoint 1118134228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.05134
Policy Entropy: 4.29596
Value Function Loss: 0.00305
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.93726
Value Function Update Magnitude: 0.74679
Collected Steps per Second: 12,824.28583
Overall Steps per Second: 7,172.19749
Timestep Collection Time: 3.90119
Timestep Consumption Time: 3.07436
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.97555
Cumulative Model Updates: 135,362
Cumulative Timesteps: 1,118,184,258
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.69440
Policy Entropy: 4.29546
Value Function Loss: 0.00303
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.93073
Value Function Update Magnitude: 0.74866
Collected Steps per Second: 13,247.56485
Overall Steps per Second: 7,126.18531
Timestep Collection Time: 3.77669
Timestep Consumption Time: 3.24417
PPO Batch Consumption Time: 0.23997
Total Iteration Time: 7.02087
Cumulative Model Updates: 135,371
Cumulative Timesteps: 1,118,234,290
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1118234290...
Checkpoint 1118234290 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.43384
Policy Entropy: 4.29913
Value Function Loss: 0.00293
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.92982
Value Function Update Magnitude: 0.74217
Collected Steps per Second: 12,875.32931
Overall Steps per Second: 7,158.11401
Timestep Collection Time: 3.88635
Timestep Consumption Time: 3.10404
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.99039
Cumulative Model Updates: 135,380
Cumulative Timesteps: 1,118,284,328
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.31871
Policy Entropy: 4.29754
Value Function Loss: 0.00291
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.91974
Value Function Update Magnitude: 0.73377
Collected Steps per Second: 12,863.72977
Overall Steps per Second: 7,240.79189
Timestep Collection Time: 3.88736
Timestep Consumption Time: 3.01879
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.90615
Cumulative Model Updates: 135,389
Cumulative Timesteps: 1,118,334,334
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1118334334...
Checkpoint 1118334334 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.31906
Policy Entropy: 4.29774
Value Function Loss: 0.00295
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.92012
Value Function Update Magnitude: 0.74689
Collected Steps per Second: 12,900.93311
Overall Steps per Second: 7,145.81008
Timestep Collection Time: 3.87879
Timestep Consumption Time: 3.12392
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 7.00271
Cumulative Model Updates: 135,398
Cumulative Timesteps: 1,118,384,374
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.68300
Policy Entropy: 4.29798
Value Function Loss: 0.00293
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.92886
Value Function Update Magnitude: 0.74682
Collected Steps per Second: 12,894.23719
Overall Steps per Second: 7,160.95685
Timestep Collection Time: 3.87817
Timestep Consumption Time: 3.10498
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.98315
Cumulative Model Updates: 135,407
Cumulative Timesteps: 1,118,434,380
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1118434380...
Checkpoint 1118434380 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.96685
Policy Entropy: 4.30450
Value Function Loss: 0.00291
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.92145
Value Function Update Magnitude: 0.72649
Collected Steps per Second: 12,798.87762
Overall Steps per Second: 7,224.74580
Timestep Collection Time: 3.90769
Timestep Consumption Time: 3.01491
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.92260
Cumulative Model Updates: 135,416
Cumulative Timesteps: 1,118,484,394
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.52368
Policy Entropy: 4.30187
Value Function Loss: 0.00297
Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.92941
Value Function Update Magnitude: 0.72205
Collected Steps per Second: 13,008.30606
Overall Steps per Second: 7,170.26532
Timestep Collection Time: 3.84754
Timestep Consumption Time: 3.13267
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.98022
Cumulative Model Updates: 135,425
Cumulative Timesteps: 1,118,534,444
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1118534444...
Checkpoint 1118534444 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.63730
Policy Entropy: 4.30016
Value Function Loss: 0.00286
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02582
Policy Update Magnitude: 0.94135
Value Function Update Magnitude: 0.74381
Collected Steps per Second: 12,968.99297
Overall Steps per Second: 7,043.41951
Timestep Collection Time: 3.85581
Timestep Consumption Time: 3.24386
PPO Batch Consumption Time: 0.23989
Total Iteration Time: 7.09968
Cumulative Model Updates: 135,434
Cumulative Timesteps: 1,118,584,450
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.65474
Policy Entropy: 4.29394
Value Function Loss: 0.00300
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02774
Policy Update Magnitude: 0.93876
Value Function Update Magnitude: 0.74693
Collected Steps per Second: 13,052.84675
Overall Steps per Second: 7,184.92435
Timestep Collection Time: 3.83181
Timestep Consumption Time: 3.12943
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.96124
Cumulative Model Updates: 135,443
Cumulative Timesteps: 1,118,634,466
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1118634466...
Checkpoint 1118634466 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.77562
Policy Entropy: 4.29673
Value Function Loss: 0.00293
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.94565
Value Function Update Magnitude: 0.78832
Collected Steps per Second: 13,042.25479
Overall Steps per Second: 7,152.96107
Timestep Collection Time: 3.83584
Timestep Consumption Time: 3.15819
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.99403
Cumulative Model Updates: 135,452
Cumulative Timesteps: 1,118,684,494
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19427
Policy Entropy: 4.29860
Value Function Loss: 0.00304
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.95134
Value Function Update Magnitude: 0.80252
Collected Steps per Second: 12,907.78430
Overall Steps per Second: 7,182.54088
Timestep Collection Time: 3.87565
Timestep Consumption Time: 3.08930
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.96494
Cumulative Model Updates: 135,461
Cumulative Timesteps: 1,118,734,520
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1118734520...
Checkpoint 1118734520 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.04388
Policy Entropy: 4.30299
Value Function Loss: 0.00286
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.95237
Value Function Update Magnitude: 0.76751
Collected Steps per Second: 13,261.52498
Overall Steps per Second: 7,276.19051
Timestep Collection Time: 3.77332
Timestep Consumption Time: 3.10390
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.87723
Cumulative Model Updates: 135,470
Cumulative Timesteps: 1,118,784,560
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.98817
Policy Entropy: 4.29865
Value Function Loss: 0.00296
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.95092
Value Function Update Magnitude: 0.73489
Collected Steps per Second: 12,910.84926
Overall Steps per Second: 7,150.77828
Timestep Collection Time: 3.87395
Timestep Consumption Time: 3.12053
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.99448
Cumulative Model Updates: 135,479
Cumulative Timesteps: 1,118,834,576
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1118834576...
Checkpoint 1118834576 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.14964
Policy Entropy: 4.29968
Value Function Loss: 0.00292
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.95003
Value Function Update Magnitude: 0.73619
Collected Steps per Second: 12,885.84052
Overall Steps per Second: 7,262.08988
Timestep Collection Time: 3.88085
Timestep Consumption Time: 3.00532
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.88617
Cumulative Model Updates: 135,488
Cumulative Timesteps: 1,118,884,584
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.40624
Policy Entropy: 4.29983
Value Function Loss: 0.00301
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.95812
Value Function Update Magnitude: 0.73448
Collected Steps per Second: 12,934.04318
Overall Steps per Second: 7,084.17779
Timestep Collection Time: 3.86824
Timestep Consumption Time: 3.19426
PPO Batch Consumption Time: 0.23464
Total Iteration Time: 7.06250
Cumulative Model Updates: 135,497
Cumulative Timesteps: 1,118,934,616
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1118934616...
Checkpoint 1118934616 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.72781
Policy Entropy: 4.30366
Value Function Loss: 0.00301
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.96519
Value Function Update Magnitude: 0.74484
Collected Steps per Second: 12,893.70909
Overall Steps per Second: 7,137.49659
Timestep Collection Time: 3.88112
Timestep Consumption Time: 3.13002
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 7.01114
Cumulative Model Updates: 135,506
Cumulative Timesteps: 1,118,984,658
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.48740
Policy Entropy: 4.30229
Value Function Loss: 0.00307
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.96419
Value Function Update Magnitude: 0.74360
Collected Steps per Second: 13,314.24536
Overall Steps per Second: 7,235.10925
Timestep Collection Time: 3.75748
Timestep Consumption Time: 3.15714
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.91462
Cumulative Model Updates: 135,515
Cumulative Timesteps: 1,119,034,686
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1119034686...
Checkpoint 1119034686 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.82052
Policy Entropy: 4.29885
Value Function Loss: 0.00304
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02534
Policy Update Magnitude: 0.94404
Value Function Update Magnitude: 0.75345
Collected Steps per Second: 13,051.37730
Overall Steps per Second: 7,197.19486
Timestep Collection Time: 3.83178
Timestep Consumption Time: 3.11676
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.94854
Cumulative Model Updates: 135,524
Cumulative Timesteps: 1,119,084,696
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.28392
Policy Entropy: 4.30250
Value Function Loss: 0.00305
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.93392
Value Function Update Magnitude: 0.76748
Collected Steps per Second: 12,867.14064
Overall Steps per Second: 7,165.11181
Timestep Collection Time: 3.88758
Timestep Consumption Time: 3.09375
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.98133
Cumulative Model Updates: 135,533
Cumulative Timesteps: 1,119,134,718
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1119134718...
Checkpoint 1119134718 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.74959
Policy Entropy: 4.30492
Value Function Loss: 0.00308
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02512
Policy Update Magnitude: 0.95169
Value Function Update Magnitude: 0.74403
Collected Steps per Second: 13,322.65568
Overall Steps per Second: 7,280.56724
Timestep Collection Time: 3.75451
Timestep Consumption Time: 3.11584
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.87034
Cumulative Model Updates: 135,542
Cumulative Timesteps: 1,119,184,738
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.06842
Policy Entropy: 4.30585
Value Function Loss: 0.00319
Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.96830
Value Function Update Magnitude: 0.74718
Collected Steps per Second: 12,785.56747
Overall Steps per Second: 7,088.33052
Timestep Collection Time: 3.91285
Timestep Consumption Time: 3.14495
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 7.05780
Cumulative Model Updates: 135,551
Cumulative Timesteps: 1,119,234,766
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1119234766...
Checkpoint 1119234766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87525
Policy Entropy: 4.30372
Value Function Loss: 0.00326
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.97734
Value Function Update Magnitude: 0.77271
Collected Steps per Second: 12,805.88003
Overall Steps per Second: 7,173.19279
Timestep Collection Time: 3.90649
Timestep Consumption Time: 3.06753
PPO Batch Consumption Time: 0.22962
Total Iteration Time: 6.97402
Cumulative Model Updates: 135,560
Cumulative Timesteps: 1,119,284,792
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.88471
Policy Entropy: 4.30394
Value Function Loss: 0.00310
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02832
Policy Update Magnitude: 0.97345
Value Function Update Magnitude: 0.77429
Collected Steps per Second: 12,935.35919
Overall Steps per Second: 7,119.37404
Timestep Collection Time: 3.86831
Timestep Consumption Time: 3.16012
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 7.02843
Cumulative Model Updates: 135,569
Cumulative Timesteps: 1,119,334,830
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1119334830...
Checkpoint 1119334830 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28091
Policy Entropy: 4.30507
Value Function Loss: 0.00302
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.95677
Value Function Update Magnitude: 0.76992
Collected Steps per Second: 13,070.30085
Overall Steps per Second: 7,229.66278
Timestep Collection Time: 3.82669
Timestep Consumption Time: 3.09147
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.91817
Cumulative Model Updates: 135,578
Cumulative Timesteps: 1,119,384,846
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.73368
Policy Entropy: 4.30919
Value Function Loss: 0.00298
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02430
Policy Update Magnitude: 0.95275
Value Function Update Magnitude: 0.74951
Collected Steps per Second: 13,012.37359
Overall Steps per Second: 7,279.79800
Timestep Collection Time: 3.84511
Timestep Consumption Time: 3.02788
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.87299
Cumulative Model Updates: 135,587
Cumulative Timesteps: 1,119,434,880
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1119434880...
Checkpoint 1119434880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16727
Policy Entropy: 4.30736
Value Function Loss: 0.00299
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.96218
Value Function Update Magnitude: 0.73998
Collected Steps per Second: 12,964.06964
Overall Steps per Second: 7,157.10120
Timestep Collection Time: 3.85789
Timestep Consumption Time: 3.13013
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.98802
Cumulative Model Updates: 135,596
Cumulative Timesteps: 1,119,484,894
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18870
Policy Entropy: 4.30455
Value Function Loss: 0.00316
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.96070
Value Function Update Magnitude: 0.73427
Collected Steps per Second: 12,998.72078
Overall Steps per Second: 7,206.12540
Timestep Collection Time: 3.84992
Timestep Consumption Time: 3.09473
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.94465
Cumulative Model Updates: 135,605
Cumulative Timesteps: 1,119,534,938
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1119534938...
Checkpoint 1119534938 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.15223
Policy Entropy: 4.30153
Value Function Loss: 0.00308
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02366
Policy Update Magnitude: 0.97020
Value Function Update Magnitude: 0.75950
Collected Steps per Second: 13,208.27981
Overall Steps per Second: 7,241.51773
Timestep Collection Time: 3.78778
Timestep Consumption Time: 3.12100
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.90877
Cumulative Model Updates: 135,614
Cumulative Timesteps: 1,119,584,968
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.42479
Policy Entropy: 4.29996
Value Function Loss: 0.00312
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02410
Policy Update Magnitude: 0.98294
Value Function Update Magnitude: 0.75601
Collected Steps per Second: 13,044.89256
Overall Steps per Second: 7,031.97440
Timestep Collection Time: 3.83537
Timestep Consumption Time: 3.27956
PPO Batch Consumption Time: 0.24040
Total Iteration Time: 7.11493
Cumulative Model Updates: 135,623
Cumulative Timesteps: 1,119,635,000
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1119635000...
Checkpoint 1119635000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.03268
Policy Entropy: 4.29815
Value Function Loss: 0.00309
Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.97161
Value Function Update Magnitude: 0.73013
Collected Steps per Second: 12,946.37080
Overall Steps per Second: 7,157.57177
Timestep Collection Time: 3.86394
Timestep Consumption Time: 3.12502
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.98896
Cumulative Model Updates: 135,632
Cumulative Timesteps: 1,119,685,024
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83368
Policy Entropy: 4.29733
Value Function Loss: 0.00298
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.96196
Value Function Update Magnitude: 0.71806
Collected Steps per Second: 13,242.51462
Overall Steps per Second: 7,260.30778
Timestep Collection Time: 3.77919
Timestep Consumption Time: 3.11390
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.89310
Cumulative Model Updates: 135,641
Cumulative Timesteps: 1,119,735,070
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1119735070...
Checkpoint 1119735070 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.83096
Policy Entropy: 4.29682
Value Function Loss: 0.00297
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.96678
Value Function Update Magnitude: 0.73464
Collected Steps per Second: 13,014.60002
Overall Steps per Second: 7,179.11724
Timestep Collection Time: 3.84276
Timestep Consumption Time: 3.12355
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.96632
Cumulative Model Updates: 135,650
Cumulative Timesteps: 1,119,785,082
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.58491
Policy Entropy: 4.29976
Value Function Loss: 0.00285
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.96432
Value Function Update Magnitude: 0.73306
Collected Steps per Second: 12,822.28046
Overall Steps per Second: 7,241.51190
Timestep Collection Time: 3.90352
Timestep Consumption Time: 3.00830
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.91182
Cumulative Model Updates: 135,659
Cumulative Timesteps: 1,119,835,134
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1119835134...
Checkpoint 1119835134 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.91059
Policy Entropy: 4.30322
Value Function Loss: 0.00293
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.96097
Value Function Update Magnitude: 0.73270
Collected Steps per Second: 12,820.33273
Overall Steps per Second: 7,128.12662
Timestep Collection Time: 3.90115
Timestep Consumption Time: 3.11528
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 7.01643
Cumulative Model Updates: 135,668
Cumulative Timesteps: 1,119,885,148
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.68207
Policy Entropy: 4.29934
Value Function Loss: 0.00303
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.97041
Value Function Update Magnitude: 0.70595
Collected Steps per Second: 13,050.24346
Overall Steps per Second: 7,216.70672
Timestep Collection Time: 3.83349
Timestep Consumption Time: 3.09876
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.93225
Cumulative Model Updates: 135,677
Cumulative Timesteps: 1,119,935,176
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1119935176...
Checkpoint 1119935176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.92445
Policy Entropy: 4.29948
Value Function Loss: 0.00309
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.96997
Value Function Update Magnitude: 0.71996
Collected Steps per Second: 13,325.91696
Overall Steps per Second: 7,204.18546
Timestep Collection Time: 3.75224
Timestep Consumption Time: 3.18845
PPO Batch Consumption Time: 0.23490
Total Iteration Time: 6.94069
Cumulative Model Updates: 135,686
Cumulative Timesteps: 1,119,985,178
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.53102
Policy Entropy: 4.29702
Value Function Loss: 0.00309
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.97080
Value Function Update Magnitude: 0.74023
Collected Steps per Second: 13,117.24499
Overall Steps per Second: 7,201.86076
Timestep Collection Time: 3.81193
Timestep Consumption Time: 3.13100
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.94293
Cumulative Model Updates: 135,695
Cumulative Timesteps: 1,120,035,180
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1120035180...
Checkpoint 1120035180 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.72679
Policy Entropy: 4.30664
Value Function Loss: 0.00292
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.95995
Value Function Update Magnitude: 0.75204
Collected Steps per Second: 12,818.74097
Overall Steps per Second: 7,151.67826
Timestep Collection Time: 3.90148
Timestep Consumption Time: 3.09157
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.99304
Cumulative Model Updates: 135,704
Cumulative Timesteps: 1,120,085,192
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.54215
Policy Entropy: 4.30719
Value Function Loss: 0.00297
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.96835
Value Function Update Magnitude: 0.75487
Collected Steps per Second: 13,275.58530
Overall Steps per Second: 7,265.24835
Timestep Collection Time: 3.76722
Timestep Consumption Time: 3.11651
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.88373
Cumulative Model Updates: 135,713
Cumulative Timesteps: 1,120,135,204
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1120135204...
Checkpoint 1120135204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.59442
Policy Entropy: 4.30922
Value Function Loss: 0.00298
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.96427
Value Function Update Magnitude: 0.75005
Collected Steps per Second: 13,008.95157
Overall Steps per Second: 7,190.40269
Timestep Collection Time: 3.84551
Timestep Consumption Time: 3.11182
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.95733
Cumulative Model Updates: 135,722
Cumulative Timesteps: 1,120,185,230
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.28731
Policy Entropy: 4.30571
Value Function Loss: 0.00290
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.96247
Value Function Update Magnitude: 0.74778
Collected Steps per Second: 12,996.68409
Overall Steps per Second: 7,295.13696
Timestep Collection Time: 3.84960
Timestep Consumption Time: 3.00867
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.85827
Cumulative Model Updates: 135,731
Cumulative Timesteps: 1,120,235,262
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1120235262...
Checkpoint 1120235262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.10842
Policy Entropy: 4.30623
Value Function Loss: 0.00275
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.95102
Value Function Update Magnitude: 0.71584
Collected Steps per Second: 12,969.91747
Overall Steps per Second: 7,167.80136
Timestep Collection Time: 3.85785
Timestep Consumption Time: 3.12281
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.98066
Cumulative Model Updates: 135,740
Cumulative Timesteps: 1,120,285,298
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04183
Policy Entropy: 4.30277
Value Function Loss: 0.00289
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02668
Policy Update Magnitude: 0.93621
Value Function Update Magnitude: 0.69987
Collected Steps per Second: 13,027.20869
Overall Steps per Second: 7,106.94888
Timestep Collection Time: 3.84027
Timestep Consumption Time: 3.19904
PPO Batch Consumption Time: 0.23716
Total Iteration Time: 7.03931
Cumulative Model Updates: 135,749
Cumulative Timesteps: 1,120,335,326
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1120335326...
Checkpoint 1120335326 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.80296
Policy Entropy: 4.30196
Value Function Loss: 0.00300
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.93774
Value Function Update Magnitude: 0.68657
Collected Steps per Second: 13,208.43775
Overall Steps per Second: 7,264.91125
Timestep Collection Time: 3.78682
Timestep Consumption Time: 3.09805
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.88487
Cumulative Model Updates: 135,758
Cumulative Timesteps: 1,120,385,344
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.44378
Policy Entropy: 4.29841
Value Function Loss: 0.00326
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.95204
Value Function Update Magnitude: 0.68101
Collected Steps per Second: 13,043.26995
Overall Steps per Second: 7,203.41111
Timestep Collection Time: 3.83615
Timestep Consumption Time: 3.11000
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.94615
Cumulative Model Updates: 135,767
Cumulative Timesteps: 1,120,435,380
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1120435380...
Checkpoint 1120435380 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.56959
Policy Entropy: 4.29876
Value Function Loss: 0.00322
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.97349
Value Function Update Magnitude: 0.69831
Collected Steps per Second: 12,910.13250
Overall Steps per Second: 7,162.51925
Timestep Collection Time: 3.87525
Timestep Consumption Time: 3.10972
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.98497
Cumulative Model Updates: 135,776
Cumulative Timesteps: 1,120,485,410
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.64618
Policy Entropy: 4.29748
Value Function Loss: 0.00318
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 0.96580
Value Function Update Magnitude: 0.72056
Collected Steps per Second: 13,133.36209
Overall Steps per Second: 7,224.94498
Timestep Collection Time: 3.80771
Timestep Consumption Time: 3.11387
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.92158
Cumulative Model Updates: 135,785
Cumulative Timesteps: 1,120,535,418
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1120535418...
Checkpoint 1120535418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.54790
Policy Entropy: 4.30117
Value Function Loss: 0.00298
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02930
Policy Update Magnitude: 0.94259
Value Function Update Magnitude: 0.70652
Collected Steps per Second: 12,935.68635
Overall Steps per Second: 7,153.92249
Timestep Collection Time: 3.86729
Timestep Consumption Time: 3.12552
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.99281
Cumulative Model Updates: 135,794
Cumulative Timesteps: 1,120,585,444
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 8.72770
Policy Entropy: 4.30734
Value Function Loss: 0.00289
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.93946
Value Function Update Magnitude: 0.71919
Collected Steps per Second: 12,829.79107
Overall Steps per Second: 7,234.93328
Timestep Collection Time: 3.90201
Timestep Consumption Time: 3.01747
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.91948
Cumulative Model Updates: 135,803
Cumulative Timesteps: 1,120,635,506
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
Saving checkpoint 1120635506...
Checkpoint 1120635506 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.24192
Policy Entropy: 4.30874
Value Function Loss: 0.00295
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 0.97371
Value Function Update Magnitude: 0.76254
Collected Steps per Second: 12,998.31970
Overall Steps per Second: 7,115.31259
Timestep Collection Time: 3.84819
Timestep Consumption Time: 3.18172
PPO Batch Consumption Time: 0.23045
Total Iteration Time: 7.02991
Cumulative Model Updates: 135,812
Cumulative Timesteps: 1,120,685,526
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.04821
Policy Entropy: 4.30801
Value Function Loss: 0.00294
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02951
Policy Update Magnitude: 0.97493
Value Function Update Magnitude: 0.77034
Collected Steps per Second: 12,923.82528
Overall Steps per Second: 7,173.35678
Timestep Collection Time: 3.86975
Timestep Consumption Time: 3.10216
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.97191
Cumulative Model Updates: 135,821
Cumulative Timesteps: 1,120,735,538
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1120735538...
Checkpoint 1120735538 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.66534
Policy Entropy: 4.30379
Value Function Loss: 0.00290
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02934
Policy Update Magnitude: 0.95858
Value Function Update Magnitude: 0.75019
Collected Steps per Second: 12,840.19979
Overall Steps per Second: 7,234.96281
Timestep Collection Time: 3.89682
Timestep Consumption Time: 3.01904
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.91586
Cumulative Model Updates: 135,830
Cumulative Timesteps: 1,120,785,574
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.87028
Policy Entropy: 4.30428
Value Function Loss: 0.00272
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 0.93904
Value Function Update Magnitude: 0.72102
Collected Steps per Second: 13,140.66352
Overall Steps per Second: 7,205.65826
Timestep Collection Time: 3.80498
Timestep Consumption Time: 3.13401
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.93899
Cumulative Model Updates: 135,839
Cumulative Timesteps: 1,120,835,574
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1120835574...
Checkpoint 1120835574 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.41522
Policy Entropy: 4.30252
Value Function Loss: 0.00282
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.94689
Value Function Update Magnitude: 0.69196
Collected Steps per Second: 12,984.07083
Overall Steps per Second: 7,228.84027
Timestep Collection Time: 3.85087
Timestep Consumption Time: 3.06587
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.91674
Cumulative Model Updates: 135,848
Cumulative Timesteps: 1,120,885,574
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.18964
Policy Entropy: 4.30496
Value Function Loss: 0.00288
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.96357
Value Function Update Magnitude: 0.72178
Collected Steps per Second: 13,233.00799
Overall Steps per Second: 7,254.69423
Timestep Collection Time: 3.77873
Timestep Consumption Time: 3.11391
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.89264
Cumulative Model Updates: 135,857
Cumulative Timesteps: 1,120,935,578
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1120935578...
Checkpoint 1120935578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.07011
Policy Entropy: 4.30899
Value Function Loss: 0.00282
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02798
Policy Update Magnitude: 0.97012
Value Function Update Magnitude: 0.76188
Collected Steps per Second: 12,921.83281
Overall Steps per Second: 7,158.63695
Timestep Collection Time: 3.87097
Timestep Consumption Time: 3.11640
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.98736
Cumulative Model Updates: 135,866
Cumulative Timesteps: 1,120,985,598
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.08145
Policy Entropy: 4.31059
Value Function Loss: 0.00272
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.94976
Value Function Update Magnitude: 0.73354
Collected Steps per Second: 12,872.55287
Overall Steps per Second: 7,051.79292
Timestep Collection Time: 3.88532
Timestep Consumption Time: 3.20706
PPO Batch Consumption Time: 0.23697
Total Iteration Time: 7.09238
Cumulative Model Updates: 135,875
Cumulative Timesteps: 1,121,035,612
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1121035612...
Checkpoint 1121035612 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.85541
Policy Entropy: 4.31150
Value Function Loss: 0.00272
Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.94743
Value Function Update Magnitude: 0.72314
Collected Steps per Second: 13,318.44143
Overall Steps per Second: 7,277.34617
Timestep Collection Time: 3.75434
Timestep Consumption Time: 3.11657
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.87091
Cumulative Model Updates: 135,884
Cumulative Timesteps: 1,121,085,614
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.93917
Policy Entropy: 4.30421
Value Function Loss: 0.00284
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.95774
Value Function Update Magnitude: 0.70375
Collected Steps per Second: 13,062.38207
Overall Steps per Second: 7,194.14763
Timestep Collection Time: 3.82840
Timestep Consumption Time: 3.12281
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.95121
Cumulative Model Updates: 135,893
Cumulative Timesteps: 1,121,135,622
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1121135622...
Checkpoint 1121135622 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69984
Policy Entropy: 4.30560
Value Function Loss: 0.00279
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.96772
Value Function Update Magnitude: 0.66655
Collected Steps per Second: 12,699.93157
Overall Steps per Second: 7,190.59614
Timestep Collection Time: 3.93860
Timestep Consumption Time: 3.01770
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.95631
Cumulative Model Updates: 135,902
Cumulative Timesteps: 1,121,185,642
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.49202
Policy Entropy: 4.30362
Value Function Loss: 0.00271
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.95349
Value Function Update Magnitude: 0.66901
Collected Steps per Second: 13,071.81482
Overall Steps per Second: 7,205.31639
Timestep Collection Time: 3.82747
Timestep Consumption Time: 3.11629
PPO Batch Consumption Time: 0.22951
Total Iteration Time: 6.94376
Cumulative Model Updates: 135,911
Cumulative Timesteps: 1,121,235,674
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1121235674...
Checkpoint 1121235674 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.48990
Policy Entropy: 4.30520
Value Function Loss: 0.00272
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.94714
Value Function Update Magnitude: 0.68693
Collected Steps per Second: 12,994.09251
Overall Steps per Second: 7,224.85628
Timestep Collection Time: 3.84867
Timestep Consumption Time: 3.07326
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.92194
Cumulative Model Updates: 135,920
Cumulative Timesteps: 1,121,285,684
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.46970
Policy Entropy: 4.30036
Value Function Loss: 0.00284
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02748
Policy Update Magnitude: 0.95267
Value Function Update Magnitude: 0.72830
Collected Steps per Second: 13,431.03379
Overall Steps per Second: 7,340.40842
Timestep Collection Time: 3.72391
Timestep Consumption Time: 3.08988
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.81379
Cumulative Model Updates: 135,929
Cumulative Timesteps: 1,121,335,700
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1121335700...
Checkpoint 1121335700 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.32902
Policy Entropy: 4.29633
Value Function Loss: 0.00292
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.96999
Value Function Update Magnitude: 0.71800
Collected Steps per Second: 13,079.66868
Overall Steps per Second: 7,035.30411
Timestep Collection Time: 3.82441
Timestep Consumption Time: 3.28573
PPO Batch Consumption Time: 0.24107
Total Iteration Time: 7.11014
Cumulative Model Updates: 135,938
Cumulative Timesteps: 1,121,385,722
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.46744
Policy Entropy: 4.29333
Value Function Loss: 0.00300
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02730
Policy Update Magnitude: 0.97662
Value Function Update Magnitude: 0.73012
Collected Steps per Second: 12,951.19943
Overall Steps per Second: 7,215.23571
Timestep Collection Time: 3.86312
Timestep Consumption Time: 3.07110
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 6.93422
Cumulative Model Updates: 135,947
Cumulative Timesteps: 1,121,435,754
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1121435754...
Checkpoint 1121435754 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.66006
Policy Entropy: 4.29396
Value Function Loss: 0.00296
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02836
Policy Update Magnitude: 0.97277
Value Function Update Magnitude: 0.71689
Collected Steps per Second: 13,279.99807
Overall Steps per Second: 7,257.91353
Timestep Collection Time: 3.76581
Timestep Consumption Time: 3.12460
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.89041
Cumulative Model Updates: 135,956
Cumulative Timesteps: 1,121,485,764
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.97220
Policy Entropy: 4.29530
Value Function Loss: 0.00294
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.96232
Value Function Update Magnitude: 0.71636
Collected Steps per Second: 13,127.41724
Overall Steps per Second: 7,213.33672
Timestep Collection Time: 3.80958
Timestep Consumption Time: 3.12341
PPO Batch Consumption Time: 0.22776
Total Iteration Time: 6.93299
Cumulative Model Updates: 135,965
Cumulative Timesteps: 1,121,535,774
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1121535774...
Checkpoint 1121535774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.44324
Policy Entropy: 4.29749
Value Function Loss: 0.00297
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.96523
Value Function Update Magnitude: 0.74144
Collected Steps per Second: 12,830.81251
Overall Steps per Second: 7,207.79189
Timestep Collection Time: 3.89718
Timestep Consumption Time: 3.04031
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.93749
Cumulative Model Updates: 135,974
Cumulative Timesteps: 1,121,585,778
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.26328
Policy Entropy: 4.30245
Value Function Loss: 0.00285
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.96283
Value Function Update Magnitude: 0.76044
Collected Steps per Second: 13,024.01845
Overall Steps per Second: 7,183.64531
Timestep Collection Time: 3.84275
Timestep Consumption Time: 3.12419
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.96694
Cumulative Model Updates: 135,983
Cumulative Timesteps: 1,121,635,826
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1121635826...
Checkpoint 1121635826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.76502
Policy Entropy: 4.30423
Value Function Loss: 0.00278
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.95522
Value Function Update Magnitude: 0.74066
Collected Steps per Second: 12,900.99034
Overall Steps per Second: 7,194.78654
Timestep Collection Time: 3.87939
Timestep Consumption Time: 3.07676
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.95615
Cumulative Model Updates: 135,992
Cumulative Timesteps: 1,121,685,874
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.99213
Policy Entropy: 4.30400
Value Function Loss: 0.00280
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.94924
Value Function Update Magnitude: 0.71035
Collected Steps per Second: 12,964.34251
Overall Steps per Second: 7,148.27422
Timestep Collection Time: 3.85781
Timestep Consumption Time: 3.13884
PPO Batch Consumption Time: 0.23763
Total Iteration Time: 6.99665
Cumulative Model Updates: 136,001
Cumulative Timesteps: 1,121,735,888
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1121735888...
Checkpoint 1121735888 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.91270
Policy Entropy: 4.30066
Value Function Loss: 0.00292
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.95733
Value Function Update Magnitude: 0.71504
Collected Steps per Second: 12,878.58713
Overall Steps per Second: 7,150.93619
Timestep Collection Time: 3.88505
Timestep Consumption Time: 3.11179
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.99685
Cumulative Model Updates: 136,010
Cumulative Timesteps: 1,121,785,922
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.15302
Policy Entropy: 4.29774
Value Function Loss: 0.00308
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.96798
Value Function Update Magnitude: 0.71335
Collected Steps per Second: 12,907.27161
Overall Steps per Second: 7,167.20329
Timestep Collection Time: 3.87657
Timestep Consumption Time: 3.10467
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.98124
Cumulative Model Updates: 136,019
Cumulative Timesteps: 1,121,835,958
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1121835958...
Checkpoint 1121835958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.95112
Policy Entropy: 4.29944
Value Function Loss: 0.00298
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.96154
Value Function Update Magnitude: 0.71209
Collected Steps per Second: 12,864.76193
Overall Steps per Second: 7,255.14060
Timestep Collection Time: 3.88752
Timestep Consumption Time: 3.00580
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.89332
Cumulative Model Updates: 136,028
Cumulative Timesteps: 1,121,885,970
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57388
Policy Entropy: 4.30541
Value Function Loss: 0.00275
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.94159
Value Function Update Magnitude: 0.72837
Collected Steps per Second: 12,991.00958
Overall Steps per Second: 7,184.02753
Timestep Collection Time: 3.85036
Timestep Consumption Time: 3.11231
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.96267
Cumulative Model Updates: 136,037
Cumulative Timesteps: 1,121,935,990
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1121935990...
Checkpoint 1121935990 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.51661
Policy Entropy: 4.31077
Value Function Loss: 0.00267
Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.93684
Value Function Update Magnitude: 0.70889
Collected Steps per Second: 12,958.74202
Overall Steps per Second: 7,206.71622
Timestep Collection Time: 3.85963
Timestep Consumption Time: 3.08056
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.94019
Cumulative Model Updates: 136,046
Cumulative Timesteps: 1,121,986,006
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.89121
Policy Entropy: 4.30906
Value Function Loss: 0.00275
Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.93279
Value Function Update Magnitude: 0.70668
Collected Steps per Second: 13,313.07239
Overall Steps per Second: 7,261.69756
Timestep Collection Time: 3.75856
Timestep Consumption Time: 3.13211
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.89068
Cumulative Model Updates: 136,055
Cumulative Timesteps: 1,122,036,044
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1122036044...
Checkpoint 1122036044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.27489
Policy Entropy: 4.30920
Value Function Loss: 0.00287
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.94760
Value Function Update Magnitude: 0.69458
Collected Steps per Second: 12,961.49154
Overall Steps per Second: 7,099.11025
Timestep Collection Time: 3.86098
Timestep Consumption Time: 3.18836
PPO Batch Consumption Time: 0.23442
Total Iteration Time: 7.04933
Cumulative Model Updates: 136,064
Cumulative Timesteps: 1,122,086,088
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.02123
Policy Entropy: 4.30243
Value Function Loss: 0.00299
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.95606
Value Function Update Magnitude: 0.70700
Collected Steps per Second: 13,127.40580
Overall Steps per Second: 7,319.09113
Timestep Collection Time: 3.81355
Timestep Consumption Time: 3.02637
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.83992
Cumulative Model Updates: 136,073
Cumulative Timesteps: 1,122,136,150
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
Saving checkpoint 1122136150...
Checkpoint 1122136150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.03803
Policy Entropy: 4.30189
Value Function Loss: 0.00290
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.94714
Value Function Update Magnitude: 0.70894
Collected Steps per Second: 13,012.75451
Overall Steps per Second: 7,201.02962
Timestep Collection Time: 3.84638
Timestep Consumption Time: 3.10429
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.95067
Cumulative Model Updates: 136,082
Cumulative Timesteps: 1,122,186,202
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.31390
Policy Entropy: 4.29979
Value Function Loss: 0.00295
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.93916
Value Function Update Magnitude: 0.68716
Collected Steps per Second: 12,990.79703
Overall Steps per Second: 7,216.96262
Timestep Collection Time: 3.85042
Timestep Consumption Time: 3.08048
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.93089
Cumulative Model Updates: 136,091
Cumulative Timesteps: 1,122,236,222
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1122236222...
Checkpoint 1122236222 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.92529
Policy Entropy: 4.30485
Value Function Loss: 0.00278
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02649
Policy Update Magnitude: 0.92759
Value Function Update Magnitude: 0.68008
Collected Steps per Second: 12,913.86619
Overall Steps per Second: 7,261.00596
Timestep Collection Time: 3.87289
Timestep Consumption Time: 3.01514
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.88803
Cumulative Model Updates: 136,100
Cumulative Timesteps: 1,122,286,236
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.68450
Policy Entropy: 4.30182
Value Function Loss: 0.00291
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.92619
Value Function Update Magnitude: 0.67286
Collected Steps per Second: 13,094.93000
Overall Steps per Second: 7,214.10225
Timestep Collection Time: 3.81949
Timestep Consumption Time: 3.11359
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.93309
Cumulative Model Updates: 136,109
Cumulative Timesteps: 1,122,336,252
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1122336252...
Checkpoint 1122336252 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.75236
Policy Entropy: 4.30011
Value Function Loss: 0.00295
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.93865
Value Function Update Magnitude: 0.67006
Collected Steps per Second: 12,977.69419
Overall Steps per Second: 7,168.68845
Timestep Collection Time: 3.85508
Timestep Consumption Time: 3.12389
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.97896
Cumulative Model Updates: 136,118
Cumulative Timesteps: 1,122,386,282
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.45685
Policy Entropy: 4.29761
Value Function Loss: 0.00287
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.93825
Value Function Update Magnitude: 0.66622
Collected Steps per Second: 13,260.17478
Overall Steps per Second: 7,208.86416
Timestep Collection Time: 3.77144
Timestep Consumption Time: 3.16585
PPO Batch Consumption Time: 0.22973
Total Iteration Time: 6.93729
Cumulative Model Updates: 136,127
Cumulative Timesteps: 1,122,436,292
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1122436292...
Checkpoint 1122436292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.13031
Policy Entropy: 4.30222
Value Function Loss: 0.00278
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.94127
Value Function Update Magnitude: 0.68655
Collected Steps per Second: 12,931.13164
Overall Steps per Second: 7,149.73475
Timestep Collection Time: 3.86849
Timestep Consumption Time: 3.12813
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.99662
Cumulative Model Updates: 136,136
Cumulative Timesteps: 1,122,486,316
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.55164
Policy Entropy: 4.30909
Value Function Loss: 0.00279
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.94779
Value Function Update Magnitude: 0.69370
Collected Steps per Second: 13,061.98314
Overall Steps per Second: 7,223.91376
Timestep Collection Time: 3.83020
Timestep Consumption Time: 3.09541
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.92561
Cumulative Model Updates: 136,145
Cumulative Timesteps: 1,122,536,346
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1122536346...
Checkpoint 1122536346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.76477
Policy Entropy: 4.31190
Value Function Loss: 0.00273
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02839
Policy Update Magnitude: 0.93810
Value Function Update Magnitude: 0.71264
Collected Steps per Second: 13,303.82435
Overall Steps per Second: 7,255.25013
Timestep Collection Time: 3.76057
Timestep Consumption Time: 3.13512
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.89570
Cumulative Model Updates: 136,154
Cumulative Timesteps: 1,122,586,376
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18158
Policy Entropy: 4.31244
Value Function Loss: 0.00281
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02583
Policy Update Magnitude: 0.93617
Value Function Update Magnitude: 0.69192
Collected Steps per Second: 13,049.96096
Overall Steps per Second: 7,197.61229
Timestep Collection Time: 3.83281
Timestep Consumption Time: 3.11644
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.94925
Cumulative Model Updates: 136,163
Cumulative Timesteps: 1,122,636,394
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1122636394...
Checkpoint 1122636394 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.00203
Policy Entropy: 4.31527
Value Function Loss: 0.00276
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.94156
Value Function Update Magnitude: 0.76268
Collected Steps per Second: 12,902.76981
Overall Steps per Second: 7,249.78306
Timestep Collection Time: 3.87669
Timestep Consumption Time: 3.02283
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.89952
Cumulative Model Updates: 136,172
Cumulative Timesteps: 1,122,686,414
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.65136
Policy Entropy: 4.31137
Value Function Loss: 0.00293
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.96383
Value Function Update Magnitude: 0.72582
Collected Steps per Second: 12,870.09635
Overall Steps per Second: 7,123.10077
Timestep Collection Time: 3.88529
Timestep Consumption Time: 3.13469
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 7.01998
Cumulative Model Updates: 136,181
Cumulative Timesteps: 1,122,736,418
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1122736418...
Checkpoint 1122736418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.16749
Policy Entropy: 4.30857
Value Function Loss: 0.00306
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02999
Policy Update Magnitude: 0.97301
Value Function Update Magnitude: 0.73345
Collected Steps per Second: 13,022.47044
Overall Steps per Second: 7,150.26147
Timestep Collection Time: 3.83998
Timestep Consumption Time: 3.15361
PPO Batch Consumption Time: 0.22973
Total Iteration Time: 6.99359
Cumulative Model Updates: 136,190
Cumulative Timesteps: 1,122,786,424
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.49800
Policy Entropy: 4.30632
Value Function Loss: 0.00315
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 0.97548
Value Function Update Magnitude: 0.77294
Collected Steps per Second: 12,888.03355
Overall Steps per Second: 7,262.75964
Timestep Collection Time: 3.88407
Timestep Consumption Time: 3.00835
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.89242
Cumulative Model Updates: 136,199
Cumulative Timesteps: 1,122,836,482
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 1122836482...
Checkpoint 1122836482 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.82083
Policy Entropy: 4.30460
Value Function Loss: 0.00315
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 0.98937
Value Function Update Magnitude: 0.75581
Collected Steps per Second: 12,908.15339
Overall Steps per Second: 7,147.37005
Timestep Collection Time: 3.87523
Timestep Consumption Time: 3.12343
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.99866
Cumulative Model Updates: 136,208
Cumulative Timesteps: 1,122,886,504
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.04514
Policy Entropy: 4.30919
Value Function Loss: 0.00290
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02717
Policy Update Magnitude: 0.97341
Value Function Update Magnitude: 0.74328
Collected Steps per Second: 13,017.76186
Overall Steps per Second: 7,232.66138
Timestep Collection Time: 3.84290
Timestep Consumption Time: 3.07378
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.91668
Cumulative Model Updates: 136,217
Cumulative Timesteps: 1,122,936,530
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1122936530...
Checkpoint 1122936530 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.49478
Policy Entropy: 4.30732
Value Function Loss: 0.00296
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.94988
Value Function Update Magnitude: 0.73956
Collected Steps per Second: 13,273.85266
Overall Steps per Second: 7,298.56470
Timestep Collection Time: 3.76952
Timestep Consumption Time: 3.08608
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.85559
Cumulative Model Updates: 136,226
Cumulative Timesteps: 1,122,986,566
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.25228
Policy Entropy: 4.30851
Value Function Loss: 0.00301
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02889
Policy Update Magnitude: 0.96938
Value Function Update Magnitude: 0.74507
Collected Steps per Second: 13,072.14761
Overall Steps per Second: 7,182.58087
Timestep Collection Time: 3.82539
Timestep Consumption Time: 3.13674
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.96212
Cumulative Model Updates: 136,235
Cumulative Timesteps: 1,123,036,572
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1123036572...
Checkpoint 1123036572 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.16537
Policy Entropy: 4.30919
Value Function Loss: 0.00300
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03135
Policy Update Magnitude: 0.96857
Value Function Update Magnitude: 0.74330
Collected Steps per Second: 12,896.25001
Overall Steps per Second: 7,250.55161
Timestep Collection Time: 3.88144
Timestep Consumption Time: 3.02231
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.90375
Cumulative Model Updates: 136,244
Cumulative Timesteps: 1,123,086,628
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.76122
Policy Entropy: 4.31166
Value Function Loss: 0.00291
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02852
Policy Update Magnitude: 0.95693
Value Function Update Magnitude: 0.71475
Collected Steps per Second: 12,946.74581
Overall Steps per Second: 7,010.04311
Timestep Collection Time: 3.86661
Timestep Consumption Time: 3.27457
PPO Batch Consumption Time: 0.24096
Total Iteration Time: 7.14118
Cumulative Model Updates: 136,253
Cumulative Timesteps: 1,123,136,688
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 1123136688...
Checkpoint 1123136688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68166
Policy Entropy: 4.31647
Value Function Loss: 0.00276
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02582
Policy Update Magnitude: 0.94436
Value Function Update Magnitude: 0.70653
Collected Steps per Second: 12,895.93429
Overall Steps per Second: 7,119.91977
Timestep Collection Time: 3.88184
Timestep Consumption Time: 3.14913
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 7.03098
Cumulative Model Updates: 136,262
Cumulative Timesteps: 1,123,186,748
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.75667
Policy Entropy: 4.31033
Value Function Loss: 0.00278
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.92994
Value Function Update Magnitude: 0.71689
Collected Steps per Second: 13,006.05280
Overall Steps per Second: 7,281.75762
Timestep Collection Time: 3.84805
Timestep Consumption Time: 3.02501
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.87307
Cumulative Model Updates: 136,271
Cumulative Timesteps: 1,123,236,796
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1123236796...
Checkpoint 1123236796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.66904
Policy Entropy: 4.30766
Value Function Loss: 0.00286
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.93540
Value Function Update Magnitude: 0.72793
Collected Steps per Second: 13,071.41388
Overall Steps per Second: 7,181.85459
Timestep Collection Time: 3.82759
Timestep Consumption Time: 3.13886
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.96645
Cumulative Model Updates: 136,280
Cumulative Timesteps: 1,123,286,828
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.09538
Policy Entropy: 4.30553
Value Function Loss: 0.00284
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02944
Policy Update Magnitude: 0.93376
Value Function Update Magnitude: 0.74493
Collected Steps per Second: 13,090.70737
Overall Steps per Second: 7,254.93459
Timestep Collection Time: 3.81950
Timestep Consumption Time: 3.07236
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.89186
Cumulative Model Updates: 136,289
Cumulative Timesteps: 1,123,336,828
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1123336828...
Checkpoint 1123336828 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.65237
Policy Entropy: 4.31149
Value Function Loss: 0.00281
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02648
Policy Update Magnitude: 0.93167
Value Function Update Magnitude: 0.72923
Collected Steps per Second: 13,037.75764
Overall Steps per Second: 7,191.56914
Timestep Collection Time: 3.83517
Timestep Consumption Time: 3.11769
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.95286
Cumulative Model Updates: 136,298
Cumulative Timesteps: 1,123,386,830
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.13994
Policy Entropy: 4.30881
Value Function Loss: 0.00285
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.94631
Value Function Update Magnitude: 0.74361
Collected Steps per Second: 13,083.10370
Overall Steps per Second: 7,179.23070
Timestep Collection Time: 3.82432
Timestep Consumption Time: 3.14495
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.96927
Cumulative Model Updates: 136,307
Cumulative Timesteps: 1,123,436,864
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1123436864...
Checkpoint 1123436864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.51453
Policy Entropy: 4.30701
Value Function Loss: 0.00290
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02826
Policy Update Magnitude: 0.95224
Value Function Update Magnitude: 0.75654
Collected Steps per Second: 13,027.03169
Overall Steps per Second: 7,284.06668
Timestep Collection Time: 3.83817
Timestep Consumption Time: 3.02612
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.86430
Cumulative Model Updates: 136,316
Cumulative Timesteps: 1,123,486,864
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.83031
Policy Entropy: 4.30387
Value Function Loss: 0.00299
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02864
Policy Update Magnitude: 0.95709
Value Function Update Magnitude: 0.76920
Collected Steps per Second: 13,057.18132
Overall Steps per Second: 7,194.27255
Timestep Collection Time: 3.82977
Timestep Consumption Time: 3.12104
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.95081
Cumulative Model Updates: 136,325
Cumulative Timesteps: 1,123,536,870
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1123536870...
Checkpoint 1123536870 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.45328
Policy Entropy: 4.30497
Value Function Loss: 0.00297
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.95532
Value Function Update Magnitude: 0.77831
Collected Steps per Second: 12,759.88085
Overall Steps per Second: 7,101.62093
Timestep Collection Time: 3.92010
Timestep Consumption Time: 3.12336
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 7.04346
Cumulative Model Updates: 136,334
Cumulative Timesteps: 1,123,586,890
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.50544
Policy Entropy: 4.30562
Value Function Loss: 0.00290
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02713
Policy Update Magnitude: 0.95610
Value Function Update Magnitude: 0.75553
Collected Steps per Second: 13,301.57956
Overall Steps per Second: 7,287.66327
Timestep Collection Time: 3.75955
Timestep Consumption Time: 3.10245
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.86201
Cumulative Model Updates: 136,343
Cumulative Timesteps: 1,123,636,898
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1123636898...
Checkpoint 1123636898 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.29368
Policy Entropy: 4.30927
Value Function Loss: 0.00291
Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02608
Policy Update Magnitude: 0.95560
Value Function Update Magnitude: 0.73790
Collected Steps per Second: 12,861.82560
Overall Steps per Second: 7,136.90310
Timestep Collection Time: 3.89012
Timestep Consumption Time: 3.12049
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 7.01060
Cumulative Model Updates: 136,352
Cumulative Timesteps: 1,123,686,932
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.22176
Policy Entropy: 4.31458
Value Function Loss: 0.00282
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.96362
Value Function Update Magnitude: 0.76230
Collected Steps per Second: 12,820.06125
Overall Steps per Second: 7,162.62346
Timestep Collection Time: 3.90092
Timestep Consumption Time: 3.08116
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.98208
Cumulative Model Updates: 136,361
Cumulative Timesteps: 1,123,736,942
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1123736942...
Checkpoint 1123736942 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.12042
Policy Entropy: 4.31540
Value Function Loss: 0.00292
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.95581
Value Function Update Magnitude: 0.76465
Collected Steps per Second: 13,113.48141
Overall Steps per Second: 7,194.29428
Timestep Collection Time: 3.81379
Timestep Consumption Time: 3.13783
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.95162
Cumulative Model Updates: 136,370
Cumulative Timesteps: 1,123,786,954
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.59004
Policy Entropy: 4.31501
Value Function Loss: 0.00285
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.95246
Value Function Update Magnitude: 0.75289
Collected Steps per Second: 12,882.67498
Overall Steps per Second: 6,990.61091
Timestep Collection Time: 3.88211
Timestep Consumption Time: 3.27205
PPO Batch Consumption Time: 0.23985
Total Iteration Time: 7.15417
Cumulative Model Updates: 136,379
Cumulative Timesteps: 1,123,836,966
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1123836966...
Checkpoint 1123836966 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.89878
Policy Entropy: 4.30921
Value Function Loss: 0.00295
Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.95718
Value Function Update Magnitude: 0.74541
Collected Steps per Second: 12,944.47286
Overall Steps per Second: 7,262.25665
Timestep Collection Time: 3.86605
Timestep Consumption Time: 3.02492
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.89097
Cumulative Model Updates: 136,388
Cumulative Timesteps: 1,123,887,010
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.43226
Policy Entropy: 4.31040
Value Function Loss: 0.00288
Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02558
Policy Update Magnitude: 0.95551
Value Function Update Magnitude: 0.75610
Collected Steps per Second: 12,911.11091
Overall Steps per Second: 7,123.62864
Timestep Collection Time: 3.87403
Timestep Consumption Time: 3.14739
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 7.02142
Cumulative Model Updates: 136,397
Cumulative Timesteps: 1,123,937,028
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1123937028...
Checkpoint 1123937028 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.88231
Policy Entropy: 4.30871
Value Function Loss: 0.00302
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.96926
Value Function Update Magnitude: 0.79242
Collected Steps per Second: 12,959.18104
Overall Steps per Second: 7,143.40831
Timestep Collection Time: 3.85827
Timestep Consumption Time: 3.14119
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 6.99946
Cumulative Model Updates: 136,406
Cumulative Timesteps: 1,123,987,028
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.61537
Policy Entropy: 4.31408
Value Function Loss: 0.00280
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.96036
Value Function Update Magnitude: 0.76986
Collected Steps per Second: 12,210.34490
Overall Steps per Second: 6,971.69811
Timestep Collection Time: 4.09587
Timestep Consumption Time: 3.07770
PPO Batch Consumption Time: 0.23015
Total Iteration Time: 7.17358
Cumulative Model Updates: 136,415
Cumulative Timesteps: 1,124,037,040
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1124037040...
Checkpoint 1124037040 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.83595
Policy Entropy: 4.31105
Value Function Loss: 0.00280
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.93873
Value Function Update Magnitude: 0.71758
Collected Steps per Second: 11,969.73436
Overall Steps per Second: 6,824.71294
Timestep Collection Time: 4.17921
Timestep Consumption Time: 3.15062
PPO Batch Consumption Time: 0.22930
Total Iteration Time: 7.32983
Cumulative Model Updates: 136,424
Cumulative Timesteps: 1,124,087,064
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.08474
Policy Entropy: 4.31143
Value Function Loss: 0.00269
Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02404
Policy Update Magnitude: 0.94357
Value Function Update Magnitude: 0.72932
Collected Steps per Second: 12,258.64596
Overall Steps per Second: 6,939.08963
Timestep Collection Time: 4.08202
Timestep Consumption Time: 3.12930
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 7.21132
Cumulative Model Updates: 136,433
Cumulative Timesteps: 1,124,137,104
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1124137104...
Checkpoint 1124137104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.37861
Policy Entropy: 4.30764
Value Function Loss: 0.00275
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02567
Policy Update Magnitude: 0.94853
Value Function Update Magnitude: 0.73671
Collected Steps per Second: 13,178.93650
Overall Steps per Second: 7,163.54646
Timestep Collection Time: 3.79621
Timestep Consumption Time: 3.18776
PPO Batch Consumption Time: 0.23103
Total Iteration Time: 6.98397
Cumulative Model Updates: 136,442
Cumulative Timesteps: 1,124,187,134
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.30070
Policy Entropy: 4.30684
Value Function Loss: 0.00284
Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.95261
Value Function Update Magnitude: 0.72207
Collected Steps per Second: 13,148.54514
Overall Steps per Second: 7,210.49233
Timestep Collection Time: 3.80301
Timestep Consumption Time: 3.13189
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.93489
Cumulative Model Updates: 136,451
Cumulative Timesteps: 1,124,237,138
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1124237138...
Checkpoint 1124237138 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.80612
Policy Entropy: 4.30664
Value Function Loss: 0.00291
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.96208
Value Function Update Magnitude: 0.75300
Collected Steps per Second: 12,904.87204
Overall Steps per Second: 7,188.07139
Timestep Collection Time: 3.87590
Timestep Consumption Time: 3.08257
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.95847
Cumulative Model Updates: 136,460
Cumulative Timesteps: 1,124,287,156
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.05786
Policy Entropy: 4.30977
Value Function Loss: 0.00295
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.98527
Value Function Update Magnitude: 0.80321
Collected Steps per Second: 13,158.68939
Overall Steps per Second: 7,242.93286
Timestep Collection Time: 3.80175
Timestep Consumption Time: 3.10512
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.90687
Cumulative Model Updates: 136,469
Cumulative Timesteps: 1,124,337,182
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1124337182...
Checkpoint 1124337182 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.29293
Policy Entropy: 4.31129
Value Function Loss: 0.00276
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.98858
Value Function Update Magnitude: 0.75206
Collected Steps per Second: 13,142.63315
Overall Steps per Second: 7,227.52833
Timestep Collection Time: 3.80806
Timestep Consumption Time: 3.11657
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.92464
Cumulative Model Updates: 136,478
Cumulative Timesteps: 1,124,387,230
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01524
Policy Entropy: 4.31491
Value Function Loss: 0.00273
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.96683
Value Function Update Magnitude: 0.73534
Collected Steps per Second: 12,552.11020
Overall Steps per Second: 7,097.53796
Timestep Collection Time: 3.98578
Timestep Consumption Time: 3.06314
PPO Batch Consumption Time: 0.23155
Total Iteration Time: 7.04892
Cumulative Model Updates: 136,487
Cumulative Timesteps: 1,124,437,260
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1124437260...
Checkpoint 1124437260 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47174
Policy Entropy: 4.31100
Value Function Loss: 0.00276
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.96464
Value Function Update Magnitude: 0.73129
Collected Steps per Second: 12,749.71269
Overall Steps per Second: 7,121.49875
Timestep Collection Time: 3.92166
Timestep Consumption Time: 3.09934
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 7.02099
Cumulative Model Updates: 136,496
Cumulative Timesteps: 1,124,487,260
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.14526
Policy Entropy: 4.31018
Value Function Loss: 0.00278
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02761
Policy Update Magnitude: 0.95874
Value Function Update Magnitude: 0.74219
Collected Steps per Second: 13,018.01107
Overall Steps per Second: 7,090.89473
Timestep Collection Time: 3.84222
Timestep Consumption Time: 3.21162
PPO Batch Consumption Time: 0.23850
Total Iteration Time: 7.05383
Cumulative Model Updates: 136,505
Cumulative Timesteps: 1,124,537,278
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1124537278...
Checkpoint 1124537278 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.18156
Policy Entropy: 4.30905
Value Function Loss: 0.00281
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.96177
Value Function Update Magnitude: 0.72602
Collected Steps per Second: 12,899.27841
Overall Steps per Second: 7,210.42293
Timestep Collection Time: 3.88006
Timestep Consumption Time: 3.06128
PPO Batch Consumption Time: 0.23249
Total Iteration Time: 6.94134
Cumulative Model Updates: 136,514
Cumulative Timesteps: 1,124,587,328
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.88852
Policy Entropy: 4.30778
Value Function Loss: 0.00295
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.96354
Value Function Update Magnitude: 0.73660
Collected Steps per Second: 12,743.44274
Overall Steps per Second: 7,061.82334
Timestep Collection Time: 3.92500
Timestep Consumption Time: 3.15787
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 7.08287
Cumulative Model Updates: 136,523
Cumulative Timesteps: 1,124,637,346
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1124637346...
Checkpoint 1124637346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.56957
Policy Entropy: 4.30755
Value Function Loss: 0.00305
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03196
Policy Update Magnitude: 0.96484
Value Function Update Magnitude: 0.75416
Collected Steps per Second: 12,908.32644
Overall Steps per Second: 7,188.02658
Timestep Collection Time: 3.87378
Timestep Consumption Time: 3.08279
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.95657
Cumulative Model Updates: 136,532
Cumulative Timesteps: 1,124,687,350
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64847
Policy Entropy: 4.30568
Value Function Loss: 0.00307
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03203
Policy Update Magnitude: 0.97094
Value Function Update Magnitude: 0.75985
Collected Steps per Second: 13,161.42299
Overall Steps per Second: 7,219.17777
Timestep Collection Time: 3.80202
Timestep Consumption Time: 3.12952
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.93154
Cumulative Model Updates: 136,541
Cumulative Timesteps: 1,124,737,390
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1124737390...
Checkpoint 1124737390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46066
Policy Entropy: 4.30808
Value Function Loss: 0.00286
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03005
Policy Update Magnitude: 0.97300
Value Function Update Magnitude: 0.74539
Collected Steps per Second: 12,988.47846
Overall Steps per Second: 7,181.82085
Timestep Collection Time: 3.85141
Timestep Consumption Time: 3.11395
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.96536
Cumulative Model Updates: 136,550
Cumulative Timesteps: 1,124,787,414
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.27191
Policy Entropy: 4.30642
Value Function Loss: 0.00282
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02788
Policy Update Magnitude: 0.95899
Value Function Update Magnitude: 0.72031
Collected Steps per Second: 12,926.55359
Overall Steps per Second: 7,187.89951
Timestep Collection Time: 3.86940
Timestep Consumption Time: 3.08924
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.95864
Cumulative Model Updates: 136,559
Cumulative Timesteps: 1,124,837,432
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1124837432...
Checkpoint 1124837432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.76758
Policy Entropy: 4.30750
Value Function Loss: 0.00266
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.94295
Value Function Update Magnitude: 0.69815
Collected Steps per Second: 12,947.76468
Overall Steps per Second: 6,978.79058
Timestep Collection Time: 3.86414
Timestep Consumption Time: 3.30501
PPO Batch Consumption Time: 0.24444
Total Iteration Time: 7.16915
Cumulative Model Updates: 136,568
Cumulative Timesteps: 1,124,887,464
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75346
Policy Entropy: 4.30879
Value Function Loss: 0.00270
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.92795
Value Function Update Magnitude: 0.68094
Collected Steps per Second: 12,893.35662
Overall Steps per Second: 7,154.12759
Timestep Collection Time: 3.88122
Timestep Consumption Time: 3.11362
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.99484
Cumulative Model Updates: 136,577
Cumulative Timesteps: 1,124,937,506
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1124937506...
Checkpoint 1124937506 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13456
Policy Entropy: 4.31093
Value Function Loss: 0.00270
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.93390
Value Function Update Magnitude: 0.68635
Collected Steps per Second: 13,011.96024
Overall Steps per Second: 7,266.95296
Timestep Collection Time: 3.84369
Timestep Consumption Time: 3.03869
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.88239
Cumulative Model Updates: 136,586
Cumulative Timesteps: 1,124,987,520
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66740
Policy Entropy: 4.30953
Value Function Loss: 0.00294
Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.96516
Value Function Update Magnitude: 0.70625
Collected Steps per Second: 13,077.36768
Overall Steps per Second: 7,162.26925
Timestep Collection Time: 3.82416
Timestep Consumption Time: 3.15826
PPO Batch Consumption Time: 0.23183
Total Iteration Time: 6.98242
Cumulative Model Updates: 136,595
Cumulative Timesteps: 1,125,037,530
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1125037530...
Checkpoint 1125037530 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.96772
Policy Entropy: 4.30861
Value Function Loss: 0.00306
Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.98476
Value Function Update Magnitude: 0.72763
Collected Steps per Second: 12,642.46473
Overall Steps per Second: 7,090.76613
Timestep Collection Time: 3.95572
Timestep Consumption Time: 3.09712
PPO Batch Consumption Time: 0.22789
Total Iteration Time: 7.05283
Cumulative Model Updates: 136,604
Cumulative Timesteps: 1,125,087,540
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.65740
Policy Entropy: 4.30409
Value Function Loss: 0.00319
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02653
Policy Update Magnitude: 1.00544
Value Function Update Magnitude: 0.73952
Collected Steps per Second: 12,695.90575
Overall Steps per Second: 7,145.78484
Timestep Collection Time: 3.94080
Timestep Consumption Time: 3.06081
PPO Batch Consumption Time: 0.23167
Total Iteration Time: 7.00161
Cumulative Model Updates: 136,613
Cumulative Timesteps: 1,125,137,572
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1125137572...
Checkpoint 1125137572 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.15798
Policy Entropy: 4.30462
Value Function Loss: 0.00307
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.99977
Value Function Update Magnitude: 0.74918
Collected Steps per Second: 12,886.64077
Overall Steps per Second: 7,147.73881
Timestep Collection Time: 3.88123
Timestep Consumption Time: 3.11623
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.99746
Cumulative Model Updates: 136,622
Cumulative Timesteps: 1,125,187,588
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.95937
Policy Entropy: 4.30402
Value Function Loss: 0.00314
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02964
Policy Update Magnitude: 0.98493
Value Function Update Magnitude: 0.73738
Collected Steps per Second: 12,954.52389
Overall Steps per Second: 7,143.40465
Timestep Collection Time: 3.86243
Timestep Consumption Time: 3.14207
PPO Batch Consumption Time: 0.22947
Total Iteration Time: 7.00450
Cumulative Model Updates: 136,631
Cumulative Timesteps: 1,125,237,624
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1125237624...
Checkpoint 1125237624 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.44630
Policy Entropy: 4.31124
Value Function Loss: 0.00299
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.98180
Value Function Update Magnitude: 0.73360
Collected Steps per Second: 13,030.95812
Overall Steps per Second: 7,216.01121
Timestep Collection Time: 3.83702
Timestep Consumption Time: 3.09202
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.92904
Cumulative Model Updates: 136,640
Cumulative Timesteps: 1,125,287,624
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38864
Policy Entropy: 4.31056
Value Function Loss: 0.00300
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 0.98642
Value Function Update Magnitude: 0.73809
Collected Steps per Second: 12,567.59238
Overall Steps per Second: 7,016.36035
Timestep Collection Time: 3.98103
Timestep Consumption Time: 3.14973
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 7.13076
Cumulative Model Updates: 136,649
Cumulative Timesteps: 1,125,337,656
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1125337656...
Checkpoint 1125337656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.52646
Policy Entropy: 4.30963
Value Function Loss: 0.00299
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.99672
Value Function Update Magnitude: 0.72394
Collected Steps per Second: 13,111.53468
Overall Steps per Second: 7,270.38921
Timestep Collection Time: 3.81618
Timestep Consumption Time: 3.06598
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.88216
Cumulative Model Updates: 136,658
Cumulative Timesteps: 1,125,387,692
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.48000
Policy Entropy: 4.30534
Value Function Loss: 0.00307
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.99423
Value Function Update Magnitude: 0.72141
Collected Steps per Second: 13,302.45088
Overall Steps per Second: 7,282.27528
Timestep Collection Time: 3.75916
Timestep Consumption Time: 3.10765
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.86681
Cumulative Model Updates: 136,667
Cumulative Timesteps: 1,125,437,698
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1125437698...
Checkpoint 1125437698 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.92431
Policy Entropy: 4.30477
Value Function Loss: 0.00299
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02871
Policy Update Magnitude: 0.98455
Value Function Update Magnitude: 0.70687
Collected Steps per Second: 13,109.33948
Overall Steps per Second: 7,185.58064
Timestep Collection Time: 3.81530
Timestep Consumption Time: 3.14531
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.96061
Cumulative Model Updates: 136,676
Cumulative Timesteps: 1,125,487,714
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.08281
Policy Entropy: 4.30988
Value Function Loss: 0.00282
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.97181
Value Function Update Magnitude: 0.67785
Collected Steps per Second: 12,809.98154
Overall Steps per Second: 7,249.69412
Timestep Collection Time: 3.90680
Timestep Consumption Time: 2.99639
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.90319
Cumulative Model Updates: 136,685
Cumulative Timesteps: 1,125,537,760
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1125537760...
Checkpoint 1125537760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.85244
Policy Entropy: 4.31127
Value Function Loss: 0.00277
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.95989
Value Function Update Magnitude: 0.69914
Collected Steps per Second: 12,890.86132
Overall Steps per Second: 7,109.27207
Timestep Collection Time: 3.88104
Timestep Consumption Time: 3.15624
PPO Batch Consumption Time: 0.23191
Total Iteration Time: 7.03729
Cumulative Model Updates: 136,694
Cumulative Timesteps: 1,125,587,790
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.99441
Policy Entropy: 4.31560
Value Function Loss: 0.00270
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.95901
Value Function Update Magnitude: 0.70783
Collected Steps per Second: 12,997.10435
Overall Steps per Second: 7,216.51508
Timestep Collection Time: 3.84809
Timestep Consumption Time: 3.08240
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.93049
Cumulative Model Updates: 136,703
Cumulative Timesteps: 1,125,637,804
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1125637804...
Checkpoint 1125637804 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.47266
Policy Entropy: 4.31527
Value Function Loss: 0.00266
Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.95759
Value Function Update Magnitude: 0.67809
Collected Steps per Second: 12,988.10907
Overall Steps per Second: 7,272.82760
Timestep Collection Time: 3.85198
Timestep Consumption Time: 3.02705
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.87903
Cumulative Model Updates: 136,712
Cumulative Timesteps: 1,125,687,834
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38807
Policy Entropy: 4.31539
Value Function Loss: 0.00271
Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.96354
Value Function Update Magnitude: 0.69404
Collected Steps per Second: 13,073.51924
Overall Steps per Second: 7,196.08610
Timestep Collection Time: 3.82621
Timestep Consumption Time: 3.12507
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.95128
Cumulative Model Updates: 136,721
Cumulative Timesteps: 1,125,737,856
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1125737856...
Checkpoint 1125737856 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.38780
Policy Entropy: 4.31665
Value Function Loss: 0.00275
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02823
Policy Update Magnitude: 0.97623
Value Function Update Magnitude: 0.71361
Collected Steps per Second: 12,876.24426
Overall Steps per Second: 7,182.43893
Timestep Collection Time: 3.88390
Timestep Consumption Time: 3.07892
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.96282
Cumulative Model Updates: 136,730
Cumulative Timesteps: 1,125,787,866
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.78340
Policy Entropy: 4.31576
Value Function Loss: 0.00278
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02934
Policy Update Magnitude: 0.97538
Value Function Update Magnitude: 0.73443
Collected Steps per Second: 13,154.47123
Overall Steps per Second: 7,257.06057
Timestep Collection Time: 3.80342
Timestep Consumption Time: 3.09083
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.89425
Cumulative Model Updates: 136,739
Cumulative Timesteps: 1,125,837,898
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1125837898...
Checkpoint 1125837898 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.98342
Policy Entropy: 4.31750
Value Function Loss: 0.00281
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.97814
Value Function Update Magnitude: 0.73231
Collected Steps per Second: 12,995.75742
Overall Steps per Second: 7,190.50039
Timestep Collection Time: 3.84987
Timestep Consumption Time: 3.10820
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.95807
Cumulative Model Updates: 136,748
Cumulative Timesteps: 1,125,887,930
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.87284
Policy Entropy: 4.31670
Value Function Loss: 0.00282
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02934
Policy Update Magnitude: 0.97921
Value Function Update Magnitude: 0.71718
Collected Steps per Second: 13,025.55611
Overall Steps per Second: 7,078.02062
Timestep Collection Time: 3.84137
Timestep Consumption Time: 3.22784
PPO Batch Consumption Time: 0.23928
Total Iteration Time: 7.06921
Cumulative Model Updates: 136,757
Cumulative Timesteps: 1,125,937,966
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1125937966...
Checkpoint 1125937966 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90123
Policy Entropy: 4.31820
Value Function Loss: 0.00283
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.97343
Value Function Update Magnitude: 0.71503
Collected Steps per Second: 13,252.66248
Overall Steps per Second: 7,268.92654
Timestep Collection Time: 3.77298
Timestep Consumption Time: 3.10589
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.87887
Cumulative Model Updates: 136,766
Cumulative Timesteps: 1,125,987,968
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.68385
Policy Entropy: 4.31698
Value Function Loss: 0.00269
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02894
Policy Update Magnitude: 0.95924
Value Function Update Magnitude: 0.72819
Collected Steps per Second: 13,054.43175
Overall Steps per Second: 7,183.02250
Timestep Collection Time: 3.83257
Timestep Consumption Time: 3.13274
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.96531
Cumulative Model Updates: 136,775
Cumulative Timesteps: 1,126,038,000
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1126038000...
Checkpoint 1126038000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.66864
Policy Entropy: 4.31752
Value Function Loss: 0.00266
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02581
Policy Update Magnitude: 0.93883
Value Function Update Magnitude: 0.70330
Collected Steps per Second: 13,007.56125
Overall Steps per Second: 7,305.69592
Timestep Collection Time: 3.84530
Timestep Consumption Time: 3.00114
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.84644
Cumulative Model Updates: 136,784
Cumulative Timesteps: 1,126,088,018
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.00939
Policy Entropy: 4.31975
Value Function Loss: 0.00275
Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.95883
Value Function Update Magnitude: 0.70710
Collected Steps per Second: 13,076.64928
Overall Steps per Second: 7,216.15989
Timestep Collection Time: 3.82544
Timestep Consumption Time: 3.10677
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.93222
Cumulative Model Updates: 136,793
Cumulative Timesteps: 1,126,138,042
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1126138042...
Checkpoint 1126138042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.21155
Policy Entropy: 4.30802
Value Function Loss: 0.00295
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.98303
Value Function Update Magnitude: 0.72246
Collected Steps per Second: 12,893.05957
Overall Steps per Second: 7,190.44034
Timestep Collection Time: 3.88116
Timestep Consumption Time: 3.07808
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.95924
Cumulative Model Updates: 136,802
Cumulative Timesteps: 1,126,188,082
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.34905
Policy Entropy: 4.30674
Value Function Loss: 0.00295
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03062
Policy Update Magnitude: 0.98486
Value Function Update Magnitude: 0.74822
Collected Steps per Second: 12,978.13084
Overall Steps per Second: 7,276.20334
Timestep Collection Time: 3.85510
Timestep Consumption Time: 3.02101
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.87611
Cumulative Model Updates: 136,811
Cumulative Timesteps: 1,126,238,114
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1126238114...
Checkpoint 1126238114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.48194
Policy Entropy: 4.30369
Value Function Loss: 0.00284
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.97638
Value Function Update Magnitude: 0.73787
Collected Steps per Second: 12,719.88258
Overall Steps per Second: 7,052.64728
Timestep Collection Time: 3.93133
Timestep Consumption Time: 3.15906
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 7.09039
Cumulative Model Updates: 136,820
Cumulative Timesteps: 1,126,288,120
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.84846
Policy Entropy: 4.31372
Value Function Loss: 0.00275
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03001
Policy Update Magnitude: 0.95657
Value Function Update Magnitude: 0.70889
Collected Steps per Second: 12,989.41610
Overall Steps per Second: 7,201.41797
Timestep Collection Time: 3.84944
Timestep Consumption Time: 3.09391
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.94335
Cumulative Model Updates: 136,829
Cumulative Timesteps: 1,126,338,122
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1126338122...
Checkpoint 1126338122 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.37424
Policy Entropy: 4.31016
Value Function Loss: 0.00283
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03128
Policy Update Magnitude: 0.94608
Value Function Update Magnitude: 0.69803
Collected Steps per Second: 13,348.34068
Overall Steps per Second: 7,288.15024
Timestep Collection Time: 3.74803
Timestep Consumption Time: 3.11654
PPO Batch Consumption Time: 0.22786
Total Iteration Time: 6.86457
Cumulative Model Updates: 136,838
Cumulative Timesteps: 1,126,388,152
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.18843
Policy Entropy: 4.31535
Value Function Loss: 0.00278
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 0.93894
Value Function Update Magnitude: 0.68675
Collected Steps per Second: 13,047.16734
Overall Steps per Second: 7,188.24629
Timestep Collection Time: 3.83317
Timestep Consumption Time: 3.12430
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.95747
Cumulative Model Updates: 136,847
Cumulative Timesteps: 1,126,438,164
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1126438164...
Checkpoint 1126438164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.20541
Policy Entropy: 4.31385
Value Function Loss: 0.00282
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.92847
Value Function Update Magnitude: 0.68710
Collected Steps per Second: 12,900.36345
Overall Steps per Second: 7,172.89874
Timestep Collection Time: 3.87679
Timestep Consumption Time: 3.09557
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.97236
Cumulative Model Updates: 136,856
Cumulative Timesteps: 1,126,488,176
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.21158
Policy Entropy: 4.31772
Value Function Loss: 0.00277
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.94866
Value Function Update Magnitude: 0.69229
Collected Steps per Second: 13,453.99779
Overall Steps per Second: 7,308.79593
Timestep Collection Time: 3.71666
Timestep Consumption Time: 3.12495
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.84162
Cumulative Model Updates: 136,865
Cumulative Timesteps: 1,126,538,180
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1126538180...
Checkpoint 1126538180 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.49318
Policy Entropy: 4.31331
Value Function Loss: 0.00280
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03007
Policy Update Magnitude: 0.95951
Value Function Update Magnitude: 0.69618
Collected Steps per Second: 12,984.39272
Overall Steps per Second: 7,180.50028
Timestep Collection Time: 3.85309
Timestep Consumption Time: 3.11439
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.96748
Cumulative Model Updates: 136,874
Cumulative Timesteps: 1,126,588,210
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.23137
Policy Entropy: 4.31133
Value Function Loss: 0.00282
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02889
Policy Update Magnitude: 0.96730
Value Function Update Magnitude: 0.69872
Collected Steps per Second: 12,920.98210
Overall Steps per Second: 7,212.88110
Timestep Collection Time: 3.87076
Timestep Consumption Time: 3.06323
PPO Batch Consumption Time: 0.22988
Total Iteration Time: 6.93398
Cumulative Model Updates: 136,883
Cumulative Timesteps: 1,126,638,224
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1126638224...
Checkpoint 1126638224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.14076
Policy Entropy: 4.30891
Value Function Loss: 0.00292
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.98362
Value Function Update Magnitude: 0.70142
Collected Steps per Second: 12,919.17538
Overall Steps per Second: 7,152.09100
Timestep Collection Time: 3.87099
Timestep Consumption Time: 3.12137
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.99236
Cumulative Model Updates: 136,892
Cumulative Timesteps: 1,126,688,234
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.80844
Policy Entropy: 4.31140
Value Function Loss: 0.00297
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.98811
Value Function Update Magnitude: 0.71768
Collected Steps per Second: 12,975.97127
Overall Steps per Second: 7,208.64542
Timestep Collection Time: 3.85574
Timestep Consumption Time: 3.08481
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.94056
Cumulative Model Updates: 136,901
Cumulative Timesteps: 1,126,738,266
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1126738266...
Checkpoint 1126738266 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71251
Policy Entropy: 4.31324
Value Function Loss: 0.00286
Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.98097
Value Function Update Magnitude: 0.68846
Collected Steps per Second: 12,920.79206
Overall Steps per Second: 7,268.86601
Timestep Collection Time: 3.87128
Timestep Consumption Time: 3.01012
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.88140
Cumulative Model Updates: 136,910
Cumulative Timesteps: 1,126,788,286
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.00523
Policy Entropy: 4.31226
Value Function Loss: 0.00282
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02568
Policy Update Magnitude: 0.97290
Value Function Update Magnitude: 0.70563
Collected Steps per Second: 12,992.40333
Overall Steps per Second: 7,190.56024
Timestep Collection Time: 3.85056
Timestep Consumption Time: 3.10690
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.95746
Cumulative Model Updates: 136,919
Cumulative Timesteps: 1,126,838,314
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1126838314...
Checkpoint 1126838314 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.18804
Policy Entropy: 4.30940
Value Function Loss: 0.00269
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.96365
Value Function Update Magnitude: 0.72881
Collected Steps per Second: 12,853.18398
Overall Steps per Second: 7,161.67666
Timestep Collection Time: 3.89024
Timestep Consumption Time: 3.09164
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.98188
Cumulative Model Updates: 136,928
Cumulative Timesteps: 1,126,888,316
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.49475
Policy Entropy: 4.30726
Value Function Loss: 0.00276
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02847
Policy Update Magnitude: 0.96367
Value Function Update Magnitude: 0.72364
Collected Steps per Second: 13,242.21473
Overall Steps per Second: 7,260.79377
Timestep Collection Time: 3.77746
Timestep Consumption Time: 3.11186
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.88933
Cumulative Model Updates: 136,937
Cumulative Timesteps: 1,126,938,338
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1126938338...
Checkpoint 1126938338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.25695
Policy Entropy: 4.30829
Value Function Loss: 0.00272
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02627
Policy Update Magnitude: 0.95356
Value Function Update Magnitude: 0.68294
Collected Steps per Second: 12,861.75683
Overall Steps per Second: 7,077.03031
Timestep Collection Time: 3.88983
Timestep Consumption Time: 3.17952
PPO Batch Consumption Time: 0.23294
Total Iteration Time: 7.06935
Cumulative Model Updates: 136,946
Cumulative Timesteps: 1,126,988,368
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.39307
Policy Entropy: 4.30699
Value Function Loss: 0.00279
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.95614
Value Function Update Magnitude: 0.68983
Collected Steps per Second: 13,034.74967
Overall Steps per Second: 7,219.63443
Timestep Collection Time: 3.83851
Timestep Consumption Time: 3.09176
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.93027
Cumulative Model Updates: 136,955
Cumulative Timesteps: 1,127,038,402
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1127038402...
Checkpoint 1127038402 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.62068
Policy Entropy: 4.30797
Value Function Loss: 0.00277
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02818
Policy Update Magnitude: 0.97545
Value Function Update Magnitude: 0.71030
Collected Steps per Second: 13,295.99274
Overall Steps per Second: 7,263.47677
Timestep Collection Time: 3.76098
Timestep Consumption Time: 3.12360
PPO Batch Consumption Time: 0.22952
Total Iteration Time: 6.88458
Cumulative Model Updates: 136,964
Cumulative Timesteps: 1,127,088,408
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.56694
Policy Entropy: 4.30723
Value Function Loss: 0.00281
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.97306
Value Function Update Magnitude: 0.72120
Collected Steps per Second: 13,012.67194
Overall Steps per Second: 7,174.25741
Timestep Collection Time: 3.84256
Timestep Consumption Time: 3.12708
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.96964
Cumulative Model Updates: 136,973
Cumulative Timesteps: 1,127,138,410
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1127138410...
Checkpoint 1127138410 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.51718
Policy Entropy: 4.30759
Value Function Loss: 0.00290
Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.97687
Value Function Update Magnitude: 0.72832
Collected Steps per Second: 12,868.54466
Overall Steps per Second: 7,226.11639
Timestep Collection Time: 3.88762
Timestep Consumption Time: 3.03560
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.92322
Cumulative Model Updates: 136,982
Cumulative Timesteps: 1,127,188,438
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.47344
Policy Entropy: 4.30836
Value Function Loss: 0.00292
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02730
Policy Update Magnitude: 0.99399
Value Function Update Magnitude: 0.72066
Collected Steps per Second: 12,998.94872
Overall Steps per Second: 7,188.43056
Timestep Collection Time: 3.84646
Timestep Consumption Time: 3.10916
PPO Batch Consumption Time: 0.22795
Total Iteration Time: 6.95562
Cumulative Model Updates: 136,991
Cumulative Timesteps: 1,127,238,438
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1127238438...
Checkpoint 1127238438 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.49319
Policy Entropy: 4.30844
Value Function Loss: 0.00288
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.97378
Value Function Update Magnitude: 0.71101
Collected Steps per Second: 12,712.64317
Overall Steps per Second: 7,112.58968
Timestep Collection Time: 3.93388
Timestep Consumption Time: 3.09732
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 7.03119
Cumulative Model Updates: 137,000
Cumulative Timesteps: 1,127,288,448
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.95177
Policy Entropy: 4.30393
Value Function Loss: 0.00287
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.95537
Value Function Update Magnitude: 0.67785
Collected Steps per Second: 12,861.44176
Overall Steps per Second: 7,076.81701
Timestep Collection Time: 3.89023
Timestep Consumption Time: 3.17990
PPO Batch Consumption Time: 0.24040
Total Iteration Time: 7.07013
Cumulative Model Updates: 137,009
Cumulative Timesteps: 1,127,338,482
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1127338482...
Checkpoint 1127338482 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.81415
Policy Entropy: 4.30211
Value Function Loss: 0.00289
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03242
Policy Update Magnitude: 0.95806
Value Function Update Magnitude: 0.68060
Collected Steps per Second: 13,043.36055
Overall Steps per Second: 7,192.18050
Timestep Collection Time: 3.83413
Timestep Consumption Time: 3.11925
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.95338
Cumulative Model Updates: 137,018
Cumulative Timesteps: 1,127,388,492
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.77084
Policy Entropy: 4.30022
Value Function Loss: 0.00291
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03297
Policy Update Magnitude: 0.94532
Value Function Update Magnitude: 0.69145
Collected Steps per Second: 13,135.18571
Overall Steps per Second: 7,240.21250
Timestep Collection Time: 3.81068
Timestep Consumption Time: 3.10265
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.91333
Cumulative Model Updates: 137,027
Cumulative Timesteps: 1,127,438,546
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1127438546...
Checkpoint 1127438546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.32464
Policy Entropy: 4.30345
Value Function Loss: 0.00292
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03245
Policy Update Magnitude: 0.95639
Value Function Update Magnitude: 0.69539
Collected Steps per Second: 13,082.72334
Overall Steps per Second: 7,162.76515
Timestep Collection Time: 3.82550
Timestep Consumption Time: 3.16174
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.98725
Cumulative Model Updates: 137,036
Cumulative Timesteps: 1,127,488,594
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84619
Policy Entropy: 4.30433
Value Function Loss: 0.00291
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 0.97956
Value Function Update Magnitude: 0.70481
Collected Steps per Second: 12,921.06900
Overall Steps per Second: 7,158.55302
Timestep Collection Time: 3.87259
Timestep Consumption Time: 3.11737
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.98996
Cumulative Model Updates: 137,045
Cumulative Timesteps: 1,127,538,632
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1127538632...
Checkpoint 1127538632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.35184
Policy Entropy: 4.30348
Value Function Loss: 0.00297
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03151
Policy Update Magnitude: 0.98291
Value Function Update Magnitude: 0.71813
Collected Steps per Second: 12,850.93298
Overall Steps per Second: 7,174.42068
Timestep Collection Time: 3.89232
Timestep Consumption Time: 3.07967
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.97199
Cumulative Model Updates: 137,054
Cumulative Timesteps: 1,127,588,652
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93590
Policy Entropy: 4.30444
Value Function Loss: 0.00300
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03164
Policy Update Magnitude: 0.97567
Value Function Update Magnitude: 0.72800
Collected Steps per Second: 13,164.87160
Overall Steps per Second: 7,217.54517
Timestep Collection Time: 3.80072
Timestep Consumption Time: 3.13183
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.93255
Cumulative Model Updates: 137,063
Cumulative Timesteps: 1,127,638,688
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1127638688...
Checkpoint 1127638688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.75891
Policy Entropy: 4.30863
Value Function Loss: 0.00295
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03130
Policy Update Magnitude: 0.96394
Value Function Update Magnitude: 0.74402
Collected Steps per Second: 12,858.78785
Overall Steps per Second: 6,994.73522
Timestep Collection Time: 3.88886
Timestep Consumption Time: 3.26023
PPO Batch Consumption Time: 0.24053
Total Iteration Time: 7.14909
Cumulative Model Updates: 137,072
Cumulative Timesteps: 1,127,688,694
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.95899
Policy Entropy: 4.30873
Value Function Loss: 0.00287
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.95878
Value Function Update Magnitude: 0.72186
Collected Steps per Second: 12,868.71513
Overall Steps per Second: 7,226.99899
Timestep Collection Time: 3.88757
Timestep Consumption Time: 3.03481
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.92238
Cumulative Model Updates: 137,081
Cumulative Timesteps: 1,127,738,722
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1127738722...
Checkpoint 1127738722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01575
Policy Entropy: 4.31047
Value Function Loss: 0.00280
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02788
Policy Update Magnitude: 0.95689
Value Function Update Magnitude: 0.67958
Collected Steps per Second: 12,935.03092
Overall Steps per Second: 7,159.73581
Timestep Collection Time: 3.86702
Timestep Consumption Time: 3.11927
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.98629
Cumulative Model Updates: 137,090
Cumulative Timesteps: 1,127,788,742
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.93687
Policy Entropy: 4.30900
Value Function Loss: 0.00283
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02702
Policy Update Magnitude: 0.96960
Value Function Update Magnitude: 0.67299
Collected Steps per Second: 12,960.92436
Overall Steps per Second: 7,195.58846
Timestep Collection Time: 3.85868
Timestep Consumption Time: 3.09169
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.95037
Cumulative Model Updates: 137,099
Cumulative Timesteps: 1,127,838,754
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1127838754...
Checkpoint 1127838754 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.29114
Policy Entropy: 4.31454
Value Function Loss: 0.00271
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.95576
Value Function Update Magnitude: 0.68323
Collected Steps per Second: 12,811.44162
Overall Steps per Second: 7,227.74401
Timestep Collection Time: 3.90557
Timestep Consumption Time: 3.01720
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.92277
Cumulative Model Updates: 137,108
Cumulative Timesteps: 1,127,888,790
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.31408
Policy Entropy: 4.31603
Value Function Loss: 0.00271
Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.94373
Value Function Update Magnitude: 0.66055
Collected Steps per Second: 13,017.98171
Overall Steps per Second: 7,188.34950
Timestep Collection Time: 3.84284
Timestep Consumption Time: 3.11648
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.95932
Cumulative Model Updates: 137,117
Cumulative Timesteps: 1,127,938,816
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1127938816...
Checkpoint 1127938816 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.09511
Policy Entropy: 4.31685
Value Function Loss: 0.00268
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.94845
Value Function Update Magnitude: 0.68166
Collected Steps per Second: 12,981.14349
Overall Steps per Second: 7,207.82633
Timestep Collection Time: 3.85174
Timestep Consumption Time: 3.08516
PPO Batch Consumption Time: 0.22947
Total Iteration Time: 6.93690
Cumulative Model Updates: 137,126
Cumulative Timesteps: 1,127,988,816
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.81434
Policy Entropy: 4.31593
Value Function Loss: 0.00270
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02942
Policy Update Magnitude: 0.95988
Value Function Update Magnitude: 0.69523
Collected Steps per Second: 13,306.49789
Overall Steps per Second: 7,219.83602
Timestep Collection Time: 3.75816
Timestep Consumption Time: 3.16831
PPO Batch Consumption Time: 0.23262
Total Iteration Time: 6.92647
Cumulative Model Updates: 137,135
Cumulative Timesteps: 1,128,038,824
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1128038824...
Checkpoint 1128038824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.22337
Policy Entropy: 4.31369
Value Function Loss: 0.00277
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02837
Policy Update Magnitude: 0.97494
Value Function Update Magnitude: 0.71767
Collected Steps per Second: 12,908.45793
Overall Steps per Second: 7,157.69000
Timestep Collection Time: 3.87482
Timestep Consumption Time: 3.11318
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.98801
Cumulative Model Updates: 137,144
Cumulative Timesteps: 1,128,088,842
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.30881
Policy Entropy: 4.31409
Value Function Loss: 0.00290
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.98517
Value Function Update Magnitude: 0.71850
Collected Steps per Second: 13,029.46973
Overall Steps per Second: 7,226.96074
Timestep Collection Time: 3.83838
Timestep Consumption Time: 3.08182
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.92020
Cumulative Model Updates: 137,153
Cumulative Timesteps: 1,128,138,854
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1128138854...
Checkpoint 1128138854 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44940
Policy Entropy: 4.31341
Value Function Loss: 0.00281
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 0.98471
Value Function Update Magnitude: 0.70569
Collected Steps per Second: 13,192.31691
Overall Steps per Second: 7,237.96778
Timestep Collection Time: 3.79387
Timestep Consumption Time: 3.12105
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.91492
Cumulative Model Updates: 137,162
Cumulative Timesteps: 1,128,188,904
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13095
Policy Entropy: 4.31631
Value Function Loss: 0.00272
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.96314
Value Function Update Magnitude: 0.70771
Collected Steps per Second: 12,914.79317
Overall Steps per Second: 7,154.96300
Timestep Collection Time: 3.87308
Timestep Consumption Time: 3.11787
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.99095
Cumulative Model Updates: 137,171
Cumulative Timesteps: 1,128,238,924
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1128238924...
Checkpoint 1128238924 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50268
Policy Entropy: 4.31503
Value Function Loss: 0.00269
Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.94749
Value Function Update Magnitude: 0.69314
Collected Steps per Second: 12,899.81085
Overall Steps per Second: 7,178.43683
Timestep Collection Time: 3.87820
Timestep Consumption Time: 3.09101
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.96921
Cumulative Model Updates: 137,180
Cumulative Timesteps: 1,128,288,952
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.56622
Policy Entropy: 4.31104
Value Function Loss: 0.00284
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.97328
Value Function Update Magnitude: 0.70785
Collected Steps per Second: 13,428.92628
Overall Steps per Second: 7,294.79189
Timestep Collection Time: 3.72345
Timestep Consumption Time: 3.13102
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.85448
Cumulative Model Updates: 137,189
Cumulative Timesteps: 1,128,338,954
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1128338954...
Checkpoint 1128338954 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.02717
Policy Entropy: 4.30751
Value Function Loss: 0.00288
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.98552
Value Function Update Magnitude: 0.69820
Collected Steps per Second: 12,951.70609
Overall Steps per Second: 7,032.28414
Timestep Collection Time: 3.86158
Timestep Consumption Time: 3.25048
PPO Batch Consumption Time: 0.23941
Total Iteration Time: 7.11206
Cumulative Model Updates: 137,198
Cumulative Timesteps: 1,128,388,968
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.52528
Policy Entropy: 4.30770
Value Function Loss: 0.00297
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02787
Policy Update Magnitude: 0.99355
Value Function Update Magnitude: 0.69756
Collected Steps per Second: 12,815.64872
Overall Steps per Second: 7,232.42692
Timestep Collection Time: 3.90195
Timestep Consumption Time: 3.01219
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.91414
Cumulative Model Updates: 137,207
Cumulative Timesteps: 1,128,438,974
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1128438974...
Checkpoint 1128438974 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.93080
Policy Entropy: 4.30732
Value Function Loss: 0.00298
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 1.00064
Value Function Update Magnitude: 0.72208
Collected Steps per Second: 13,007.00187
Overall Steps per Second: 7,183.67942
Timestep Collection Time: 3.84577
Timestep Consumption Time: 3.11751
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.96328
Cumulative Model Updates: 137,216
Cumulative Timesteps: 1,128,488,996
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.48530
Policy Entropy: 4.30553
Value Function Loss: 0.00294
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 1.00529
Value Function Update Magnitude: 0.73899
Collected Steps per Second: 12,901.64672
Overall Steps per Second: 7,183.26746
Timestep Collection Time: 3.87811
Timestep Consumption Time: 3.08724
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.96535
Cumulative Model Updates: 137,225
Cumulative Timesteps: 1,128,539,030
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1128539030...
Checkpoint 1128539030 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.19081
Policy Entropy: 4.30603
Value Function Loss: 0.00284
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 0.98972
Value Function Update Magnitude: 0.69295
Collected Steps per Second: 12,920.22546
Overall Steps per Second: 7,250.06606
Timestep Collection Time: 3.87021
Timestep Consumption Time: 3.02683
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.89704
Cumulative Model Updates: 137,234
Cumulative Timesteps: 1,128,589,034
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.78037
Policy Entropy: 4.30772
Value Function Loss: 0.00292
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.98585
Value Function Update Magnitude: 0.67395
Collected Steps per Second: 12,982.51661
Overall Steps per Second: 7,156.86574
Timestep Collection Time: 3.85534
Timestep Consumption Time: 3.13823
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.99356
Cumulative Model Updates: 137,243
Cumulative Timesteps: 1,128,639,086
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1128639086...
Checkpoint 1128639086 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.67827
Policy Entropy: 4.31090
Value Function Loss: 0.00294
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03128
Policy Update Magnitude: 0.99051
Value Function Update Magnitude: 0.71180
Collected Steps per Second: 13,129.50135
Overall Steps per Second: 7,257.76512
Timestep Collection Time: 3.80852
Timestep Consumption Time: 3.08120
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.88972
Cumulative Model Updates: 137,252
Cumulative Timesteps: 1,128,689,090
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44213
Policy Entropy: 4.31047
Value Function Loss: 0.00298
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02816
Policy Update Magnitude: 0.99236
Value Function Update Magnitude: 0.71899
Collected Steps per Second: 13,265.12797
Overall Steps per Second: 7,205.76972
Timestep Collection Time: 3.77290
Timestep Consumption Time: 3.17265
PPO Batch Consumption Time: 0.23034
Total Iteration Time: 6.94555
Cumulative Model Updates: 137,261
Cumulative Timesteps: 1,128,739,138
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1128739138...
Checkpoint 1128739138 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69089
Policy Entropy: 4.31251
Value Function Loss: 0.00282
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 1.00215
Value Function Update Magnitude: 0.70543
Collected Steps per Second: 12,877.88548
Overall Steps per Second: 7,134.95124
Timestep Collection Time: 3.88604
Timestep Consumption Time: 3.12788
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 7.01392
Cumulative Model Updates: 137,270
Cumulative Timesteps: 1,128,789,182
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.82878
Policy Entropy: 4.31015
Value Function Loss: 0.00278
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 0.98736
Value Function Update Magnitude: 0.68895
Collected Steps per Second: 13,051.47008
Overall Steps per Second: 7,230.76617
Timestep Collection Time: 3.83267
Timestep Consumption Time: 3.08527
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.91794
Cumulative Model Updates: 137,279
Cumulative Timesteps: 1,128,839,204
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1128839204...
Checkpoint 1128839204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.59527
Policy Entropy: 4.31395
Value Function Loss: 0.00267
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03093
Policy Update Magnitude: 0.96276
Value Function Update Magnitude: 0.70066
Collected Steps per Second: 13,102.11881
Overall Steps per Second: 7,219.80272
Timestep Collection Time: 3.81923
Timestep Consumption Time: 3.11171
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.93094
Cumulative Model Updates: 137,288
Cumulative Timesteps: 1,128,889,244
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.57989
Policy Entropy: 4.31484
Value Function Loss: 0.00270
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02801
Policy Update Magnitude: 0.95921
Value Function Update Magnitude: 0.71932
Collected Steps per Second: 12,953.07707
Overall Steps per Second: 7,161.71040
Timestep Collection Time: 3.86194
Timestep Consumption Time: 3.12298
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.98492
Cumulative Model Updates: 137,297
Cumulative Timesteps: 1,128,939,268
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1128939268...
Checkpoint 1128939268 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60173
Policy Entropy: 4.31216
Value Function Loss: 0.00281
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03145
Policy Update Magnitude: 0.96680
Value Function Update Magnitude: 0.71926
Collected Steps per Second: 12,849.74812
Overall Steps per Second: 7,167.35469
Timestep Collection Time: 3.89128
Timestep Consumption Time: 3.08507
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.97635
Cumulative Model Updates: 137,306
Cumulative Timesteps: 1,128,989,270
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04423
Policy Entropy: 4.30824
Value Function Loss: 0.00283
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 0.98111
Value Function Update Magnitude: 0.73281
Collected Steps per Second: 13,314.84307
Overall Steps per Second: 7,270.68117
Timestep Collection Time: 3.75686
Timestep Consumption Time: 3.12310
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.87996
Cumulative Model Updates: 137,315
Cumulative Timesteps: 1,129,039,292
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1129039292...
Checkpoint 1129039292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.81680
Policy Entropy: 4.30944
Value Function Loss: 0.00280
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03094
Policy Update Magnitude: 0.96911
Value Function Update Magnitude: 0.72641
Collected Steps per Second: 12,829.88716
Overall Steps per Second: 7,091.73433
Timestep Collection Time: 3.89949
Timestep Consumption Time: 3.15520
PPO Batch Consumption Time: 0.23152
Total Iteration Time: 7.05469
Cumulative Model Updates: 137,324
Cumulative Timesteps: 1,129,089,322
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.90628
Policy Entropy: 4.31050
Value Function Loss: 0.00278
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02995
Policy Update Magnitude: 0.97289
Value Function Update Magnitude: 0.72284
Collected Steps per Second: 13,012.34820
Overall Steps per Second: 7,292.03542
Timestep Collection Time: 3.84250
Timestep Consumption Time: 3.01429
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.85680
Cumulative Model Updates: 137,333
Cumulative Timesteps: 1,129,139,322
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1129139322...
Checkpoint 1129139322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.85677
Policy Entropy: 4.31329
Value Function Loss: 0.00284
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02770
Policy Update Magnitude: 0.97864
Value Function Update Magnitude: 0.71757
Collected Steps per Second: 12,866.99281
Overall Steps per Second: 7,144.19196
Timestep Collection Time: 3.88778
Timestep Consumption Time: 3.11427
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 7.00205
Cumulative Model Updates: 137,342
Cumulative Timesteps: 1,129,189,346
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12790
Policy Entropy: 4.31102
Value Function Loss: 0.00287
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.97617
Value Function Update Magnitude: 0.73044
Collected Steps per Second: 13,013.28752
Overall Steps per Second: 7,229.01462
Timestep Collection Time: 3.84422
Timestep Consumption Time: 3.07594
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.92017
Cumulative Model Updates: 137,351
Cumulative Timesteps: 1,129,239,372
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1129239372...
Checkpoint 1129239372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.48342
Policy Entropy: 4.31430
Value Function Loss: 0.00281
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 0.97691
Value Function Update Magnitude: 0.73005
Collected Steps per Second: 12,873.89674
Overall Steps per Second: 7,255.23136
Timestep Collection Time: 3.88631
Timestep Consumption Time: 3.00968
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.89599
Cumulative Model Updates: 137,360
Cumulative Timesteps: 1,129,289,404
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.05038
Policy Entropy: 4.31115
Value Function Loss: 0.00282
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03004
Policy Update Magnitude: 0.97151
Value Function Update Magnitude: 0.71960
Collected Steps per Second: 12,998.26093
Overall Steps per Second: 7,179.58203
Timestep Collection Time: 3.84959
Timestep Consumption Time: 3.11989
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.96949
Cumulative Model Updates: 137,369
Cumulative Timesteps: 1,129,339,442
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1129339442...
Checkpoint 1129339442 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.44525
Policy Entropy: 4.31740
Value Function Loss: 0.00275
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02863
Policy Update Magnitude: 0.97275
Value Function Update Magnitude: 0.70469
Collected Steps per Second: 12,997.01140
Overall Steps per Second: 7,215.95394
Timestep Collection Time: 3.84996
Timestep Consumption Time: 3.08439
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.93436
Cumulative Model Updates: 137,378
Cumulative Timesteps: 1,129,389,480
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28528
Policy Entropy: 4.31533
Value Function Loss: 0.00289
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 0.98550
Value Function Update Magnitude: 0.68562
Collected Steps per Second: 13,239.41186
Overall Steps per Second: 7,104.30670
Timestep Collection Time: 3.77706
Timestep Consumption Time: 3.26177
PPO Batch Consumption Time: 0.23983
Total Iteration Time: 7.03883
Cumulative Model Updates: 137,387
Cumulative Timesteps: 1,129,439,486
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1129439486...
Checkpoint 1129439486 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.37378
Policy Entropy: 4.31719
Value Function Loss: 0.00289
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02862
Policy Update Magnitude: 1.00633
Value Function Update Magnitude: 0.69227
Collected Steps per Second: 12,825.81123
Overall Steps per Second: 7,130.31853
Timestep Collection Time: 3.90151
Timestep Consumption Time: 3.11641
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 7.01792
Cumulative Model Updates: 137,396
Cumulative Timesteps: 1,129,489,526
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.69191
Policy Entropy: 4.31361
Value Function Loss: 0.00298
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 1.01614
Value Function Update Magnitude: 0.70658
Collected Steps per Second: 12,949.16963
Overall Steps per Second: 7,189.92707
Timestep Collection Time: 3.86388
Timestep Consumption Time: 3.09503
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.95890
Cumulative Model Updates: 137,405
Cumulative Timesteps: 1,129,539,560
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1129539560...
Checkpoint 1129539560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28621
Policy Entropy: 4.31301
Value Function Loss: 0.00293
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02971
Policy Update Magnitude: 1.00522
Value Function Update Magnitude: 0.70321
Collected Steps per Second: 13,332.91702
Overall Steps per Second: 7,316.88313
Timestep Collection Time: 3.75042
Timestep Consumption Time: 3.08364
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.83406
Cumulative Model Updates: 137,414
Cumulative Timesteps: 1,129,589,564
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.00079
Policy Entropy: 4.31529
Value Function Loss: 0.00289
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03001
Policy Update Magnitude: 1.00150
Value Function Update Magnitude: 0.71104
Collected Steps per Second: 13,068.73306
Overall Steps per Second: 7,215.22613
Timestep Collection Time: 3.82853
Timestep Consumption Time: 3.10597
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.93450
Cumulative Model Updates: 137,423
Cumulative Timesteps: 1,129,639,598
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1129639598...
Checkpoint 1129639598 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04219
Policy Entropy: 4.31036
Value Function Loss: 0.00281
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03037
Policy Update Magnitude: 0.99852
Value Function Update Magnitude: 0.71840
Collected Steps per Second: 12,944.42051
Overall Steps per Second: 7,267.79561
Timestep Collection Time: 3.86298
Timestep Consumption Time: 3.01724
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.88022
Cumulative Model Updates: 137,432
Cumulative Timesteps: 1,129,689,602
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.18200
Policy Entropy: 4.30500
Value Function Loss: 0.00294
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 0.99795
Value Function Update Magnitude: 0.70972
Collected Steps per Second: 12,955.44771
Overall Steps per Second: 7,185.09116
Timestep Collection Time: 3.85953
Timestep Consumption Time: 3.09960
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.95913
Cumulative Model Updates: 137,441
Cumulative Timesteps: 1,129,739,604
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1129739604...
Checkpoint 1129739604 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.26222
Policy Entropy: 4.30170
Value Function Loss: 0.00289
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 0.99737
Value Function Update Magnitude: 0.70897
Collected Steps per Second: 12,874.02529
Overall Steps per Second: 7,038.67332
Timestep Collection Time: 3.88659
Timestep Consumption Time: 3.22214
PPO Batch Consumption Time: 0.24204
Total Iteration Time: 7.10873
Cumulative Model Updates: 137,450
Cumulative Timesteps: 1,129,789,640
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.26649
Policy Entropy: 4.30183
Value Function Loss: 0.00292
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03202
Policy Update Magnitude: 1.00816
Value Function Update Magnitude: 0.71360
Collected Steps per Second: 12,967.23783
Overall Steps per Second: 7,288.41870
Timestep Collection Time: 3.85726
Timestep Consumption Time: 3.00541
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.86267
Cumulative Model Updates: 137,459
Cumulative Timesteps: 1,129,839,658
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1129839658...
Checkpoint 1129839658 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.81698
Policy Entropy: 4.30600
Value Function Loss: 0.00284
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 1.00322
Value Function Update Magnitude: 0.72986
Collected Steps per Second: 12,917.73614
Overall Steps per Second: 7,168.28347
Timestep Collection Time: 3.87328
Timestep Consumption Time: 3.10663
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.97991
Cumulative Model Updates: 137,468
Cumulative Timesteps: 1,129,889,692
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.70428
Policy Entropy: 4.30821
Value Function Loss: 0.00279
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03044
Policy Update Magnitude: 1.00702
Value Function Update Magnitude: 0.72707
Collected Steps per Second: 12,927.44002
Overall Steps per Second: 7,180.86198
Timestep Collection Time: 3.86790
Timestep Consumption Time: 3.09533
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.96323
Cumulative Model Updates: 137,477
Cumulative Timesteps: 1,129,939,694
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1129939694...
Checkpoint 1129939694 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.90937
Policy Entropy: 4.30668
Value Function Loss: 0.00292
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02959
Policy Update Magnitude: 1.02553
Value Function Update Magnitude: 0.75131
Collected Steps per Second: 13,326.72965
Overall Steps per Second: 7,274.46814
Timestep Collection Time: 3.75306
Timestep Consumption Time: 3.12250
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.87555
Cumulative Model Updates: 137,486
Cumulative Timesteps: 1,129,989,710
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.53608
Policy Entropy: 4.30313
Value Function Loss: 0.00283
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 1.01578
Value Function Update Magnitude: 0.77602
Collected Steps per Second: 13,064.36288
Overall Steps per Second: 7,190.13003
Timestep Collection Time: 3.82965
Timestep Consumption Time: 3.12877
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.95843
Cumulative Model Updates: 137,495
Cumulative Timesteps: 1,130,039,742
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1130039742...
Checkpoint 1130039742 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.88142
Policy Entropy: 4.30585
Value Function Loss: 0.00283
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02914
Policy Update Magnitude: 0.99307
Value Function Update Magnitude: 0.72432
Collected Steps per Second: 12,997.07667
Overall Steps per Second: 7,213.13634
Timestep Collection Time: 3.84887
Timestep Consumption Time: 3.08626
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.93512
Cumulative Model Updates: 137,504
Cumulative Timesteps: 1,130,089,766
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.78367
Policy Entropy: 4.31273
Value Function Loss: 0.00278
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.97891
Value Function Update Magnitude: 0.72810
Collected Steps per Second: 13,379.48019
Overall Steps per Second: 7,135.85485
Timestep Collection Time: 3.73931
Timestep Consumption Time: 3.27176
PPO Batch Consumption Time: 0.24103
Total Iteration Time: 7.01107
Cumulative Model Updates: 137,513
Cumulative Timesteps: 1,130,139,796
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1130139796...
Checkpoint 1130139796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10183
Policy Entropy: 4.31409
Value Function Loss: 0.00289
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.98839
Value Function Update Magnitude: 0.73017
Collected Steps per Second: 12,798.52808
Overall Steps per Second: 7,134.72552
Timestep Collection Time: 3.90936
Timestep Consumption Time: 3.10339
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 7.01274
Cumulative Model Updates: 137,522
Cumulative Timesteps: 1,130,189,830
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.35887
Policy Entropy: 4.31203
Value Function Loss: 0.00299
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.99665
Value Function Update Magnitude: 0.71626
Collected Steps per Second: 12,836.92698
Overall Steps per Second: 7,225.78377
Timestep Collection Time: 3.89595
Timestep Consumption Time: 3.02538
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.92133
Cumulative Model Updates: 137,531
Cumulative Timesteps: 1,130,239,842
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1130239842...
Checkpoint 1130239842 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.99533
Policy Entropy: 4.30950
Value Function Loss: 0.00301
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02753
Policy Update Magnitude: 0.98992
Value Function Update Magnitude: 0.73490
Collected Steps per Second: 12,982.21702
Overall Steps per Second: 7,187.82900
Timestep Collection Time: 3.85389
Timestep Consumption Time: 3.10677
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.96066
Cumulative Model Updates: 137,540
Cumulative Timesteps: 1,130,289,874
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.99371
Policy Entropy: 4.31022
Value Function Loss: 0.00293
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 1.00187
Value Function Update Magnitude: 0.73914
Collected Steps per Second: 13,016.39805
Overall Steps per Second: 7,194.56117
Timestep Collection Time: 3.84377
Timestep Consumption Time: 3.11038
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.95414
Cumulative Model Updates: 137,549
Cumulative Timesteps: 1,130,339,906
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1130339906...
Checkpoint 1130339906 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00365
Policy Entropy: 4.31301
Value Function Loss: 0.00291
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.99803
Value Function Update Magnitude: 0.73408
Collected Steps per Second: 12,907.51625
Overall Steps per Second: 7,258.50505
Timestep Collection Time: 3.87418
Timestep Consumption Time: 3.01512
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.88930
Cumulative Model Updates: 137,558
Cumulative Timesteps: 1,130,389,912
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.34751
Policy Entropy: 4.31528
Value Function Loss: 0.00285
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03014
Policy Update Magnitude: 0.99152
Value Function Update Magnitude: 0.73756
Collected Steps per Second: 13,143.68908
Overall Steps per Second: 7,232.43654
Timestep Collection Time: 3.80593
Timestep Consumption Time: 3.11068
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.91662
Cumulative Model Updates: 137,567
Cumulative Timesteps: 1,130,439,936
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1130439936...
Checkpoint 1130439936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.77177
Policy Entropy: 4.31328
Value Function Loss: 0.00297
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03069
Policy Update Magnitude: 0.96904
Value Function Update Magnitude: 0.74366
Collected Steps per Second: 12,895.87009
Overall Steps per Second: 7,041.29261
Timestep Collection Time: 3.87954
Timestep Consumption Time: 3.22569
PPO Batch Consumption Time: 0.23896
Total Iteration Time: 7.10523
Cumulative Model Updates: 137,576
Cumulative Timesteps: 1,130,489,966
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71853
Policy Entropy: 4.31141
Value Function Loss: 0.00297
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.98799
Value Function Update Magnitude: 0.75192
Collected Steps per Second: 13,199.38345
Overall Steps per Second: 7,236.17277
Timestep Collection Time: 3.78927
Timestep Consumption Time: 3.12267
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.91194
Cumulative Model Updates: 137,585
Cumulative Timesteps: 1,130,539,982
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1130539982...
Checkpoint 1130539982 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.63550
Policy Entropy: 4.31043
Value Function Loss: 0.00294
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 0.99733
Value Function Update Magnitude: 0.75970
Collected Steps per Second: 12,961.54014
Overall Steps per Second: 7,186.36025
Timestep Collection Time: 3.85957
Timestep Consumption Time: 3.10167
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.96124
Cumulative Model Updates: 137,594
Cumulative Timesteps: 1,130,590,008
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27974
Policy Entropy: 4.30853
Value Function Loss: 0.00294
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02966
Policy Update Magnitude: 0.99556
Value Function Update Magnitude: 0.74238
Collected Steps per Second: 12,929.45450
Overall Steps per Second: 7,209.56115
Timestep Collection Time: 3.86900
Timestep Consumption Time: 3.06957
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.93856
Cumulative Model Updates: 137,603
Cumulative Timesteps: 1,130,640,032
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1130640032...
Checkpoint 1130640032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.29115
Policy Entropy: 4.30834
Value Function Loss: 0.00289
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.99035
Value Function Update Magnitude: 0.71511
Collected Steps per Second: 13,204.77531
Overall Steps per Second: 7,267.38315
Timestep Collection Time: 3.78787
Timestep Consumption Time: 3.09466
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.88253
Cumulative Model Updates: 137,612
Cumulative Timesteps: 1,130,690,050
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.21906
Policy Entropy: 4.30987
Value Function Loss: 0.00291
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.98767
Value Function Update Magnitude: 0.68821
Collected Steps per Second: 12,997.13158
Overall Steps per Second: 7,192.17628
Timestep Collection Time: 3.84762
Timestep Consumption Time: 3.10549
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.95311
Cumulative Model Updates: 137,621
Cumulative Timesteps: 1,130,740,058
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1130740058...
Checkpoint 1130740058 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.38286
Policy Entropy: 4.31440
Value Function Loss: 0.00282
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02717
Policy Update Magnitude: 0.97358
Value Function Update Magnitude: 0.69485
Collected Steps per Second: 12,963.56754
Overall Steps per Second: 7,276.44570
Timestep Collection Time: 3.85820
Timestep Consumption Time: 3.01549
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.87369
Cumulative Model Updates: 137,630
Cumulative Timesteps: 1,130,790,074
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12061
Policy Entropy: 4.31398
Value Function Loss: 0.00285
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.97470
Value Function Update Magnitude: 0.70947
Collected Steps per Second: 13,026.20017
Overall Steps per Second: 7,124.08518
Timestep Collection Time: 3.83965
Timestep Consumption Time: 3.18104
PPO Batch Consumption Time: 0.23617
Total Iteration Time: 7.02069
Cumulative Model Updates: 137,639
Cumulative Timesteps: 1,130,840,090
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1130840090...
Checkpoint 1130840090 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.44527
Policy Entropy: 4.31527
Value Function Loss: 0.00280
Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.97988
Value Function Update Magnitude: 0.73931
Collected Steps per Second: 13,002.75224
Overall Steps per Second: 7,197.62239
Timestep Collection Time: 3.84596
Timestep Consumption Time: 3.10189
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.94785
Cumulative Model Updates: 137,648
Cumulative Timesteps: 1,130,890,098
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.78065
Policy Entropy: 4.31530
Value Function Loss: 0.00273
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.96700
Value Function Update Magnitude: 0.76092
Collected Steps per Second: 12,928.17636
Overall Steps per Second: 7,273.07548
Timestep Collection Time: 3.86814
Timestep Consumption Time: 3.00763
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.87577
Cumulative Model Updates: 137,657
Cumulative Timesteps: 1,130,940,106
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1130940106...
Checkpoint 1130940106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.43602
Policy Entropy: 4.31087
Value Function Loss: 0.00288
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.98096
Value Function Update Magnitude: 0.78137
Collected Steps per Second: 13,088.95967
Overall Steps per Second: 7,207.51895
Timestep Collection Time: 3.82047
Timestep Consumption Time: 3.11756
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.93803
Cumulative Model Updates: 137,666
Cumulative Timesteps: 1,130,990,112
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.25530
Policy Entropy: 4.31174
Value Function Loss: 0.00286
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02856
Policy Update Magnitude: 0.99194
Value Function Update Magnitude: 0.76585
Collected Steps per Second: 12,849.27446
Overall Steps per Second: 7,158.35268
Timestep Collection Time: 3.89252
Timestep Consumption Time: 3.09457
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.98708
Cumulative Model Updates: 137,675
Cumulative Timesteps: 1,131,040,128
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1131040128...
Checkpoint 1131040128 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.37630
Policy Entropy: 4.30995
Value Function Loss: 0.00296
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 0.98544
Value Function Update Magnitude: 0.76025
Collected Steps per Second: 12,997.91327
Overall Steps per Second: 7,282.00369
Timestep Collection Time: 3.84846
Timestep Consumption Time: 3.02080
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.86926
Cumulative Model Updates: 137,684
Cumulative Timesteps: 1,131,090,150
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.09687
Policy Entropy: 4.31641
Value Function Loss: 0.00272
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03066
Policy Update Magnitude: 0.98189
Value Function Update Magnitude: 0.74674
Collected Steps per Second: 13,136.22864
Overall Steps per Second: 7,229.06819
Timestep Collection Time: 3.80870
Timestep Consumption Time: 3.11224
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.92095
Cumulative Model Updates: 137,693
Cumulative Timesteps: 1,131,140,182
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1131140182...
Checkpoint 1131140182 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80088
Policy Entropy: 4.31459
Value Function Loss: 0.00273
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.98474
Value Function Update Magnitude: 0.75617
Collected Steps per Second: 12,847.26825
Overall Steps per Second: 7,022.05555
Timestep Collection Time: 3.89219
Timestep Consumption Time: 3.22880
PPO Batch Consumption Time: 0.23989
Total Iteration Time: 7.12099
Cumulative Model Updates: 137,702
Cumulative Timesteps: 1,131,190,186
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.97027
Policy Entropy: 4.31513
Value Function Loss: 0.00258
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.97448
Value Function Update Magnitude: 0.73860
Collected Steps per Second: 13,203.49640
Overall Steps per Second: 7,226.44543
Timestep Collection Time: 3.78884
Timestep Consumption Time: 3.13378
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.92263
Cumulative Model Updates: 137,711
Cumulative Timesteps: 1,131,240,212
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1131240212...
Checkpoint 1131240212 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.07690
Policy Entropy: 4.31794
Value Function Loss: 0.00264
Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.98245
Value Function Update Magnitude: 0.73427
Collected Steps per Second: 12,907.37649
Overall Steps per Second: 7,149.64755
Timestep Collection Time: 3.87592
Timestep Consumption Time: 3.12134
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.99727
Cumulative Model Updates: 137,720
Cumulative Timesteps: 1,131,290,240
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.49409
Policy Entropy: 4.32158
Value Function Loss: 0.00267
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.99003
Value Function Update Magnitude: 0.74808
Collected Steps per Second: 12,703.18856
Overall Steps per Second: 7,122.21108
Timestep Collection Time: 3.93885
Timestep Consumption Time: 3.08649
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 7.02535
Cumulative Model Updates: 137,729
Cumulative Timesteps: 1,131,340,276
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1131340276...
Checkpoint 1131340276 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04256
Policy Entropy: 4.31570
Value Function Loss: 0.00282
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02883
Policy Update Magnitude: 1.00518
Value Function Update Magnitude: 0.75107
Collected Steps per Second: 13,170.44592
Overall Steps per Second: 7,238.07867
Timestep Collection Time: 3.79866
Timestep Consumption Time: 3.11340
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.91206
Cumulative Model Updates: 137,738
Cumulative Timesteps: 1,131,390,306
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.93203
Policy Entropy: 4.31749
Value Function Loss: 0.00276
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 1.01235
Value Function Update Magnitude: 0.75421
Collected Steps per Second: 12,987.65487
Overall Steps per Second: 7,174.08265
Timestep Collection Time: 3.85227
Timestep Consumption Time: 3.12172
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.97399
Cumulative Model Updates: 137,747
Cumulative Timesteps: 1,131,440,338
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1131440338...
Checkpoint 1131440338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.39759
Policy Entropy: 4.31839
Value Function Loss: 0.00277
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 1.02159
Value Function Update Magnitude: 0.73571
Collected Steps per Second: 12,948.26938
Overall Steps per Second: 7,184.15946
Timestep Collection Time: 3.86353
Timestep Consumption Time: 3.09985
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.96338
Cumulative Model Updates: 137,756
Cumulative Timesteps: 1,131,490,364
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05297
Policy Entropy: 4.31957
Value Function Loss: 0.00282
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02748
Policy Update Magnitude: 1.02147
Value Function Update Magnitude: 0.73326
Collected Steps per Second: 13,249.10882
Overall Steps per Second: 7,204.84611
Timestep Collection Time: 3.77686
Timestep Consumption Time: 3.16847
PPO Batch Consumption Time: 0.22949
Total Iteration Time: 6.94533
Cumulative Model Updates: 137,765
Cumulative Timesteps: 1,131,540,404
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1131540404...
Checkpoint 1131540404 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67378
Policy Entropy: 4.31742
Value Function Loss: 0.00284
Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 1.01982
Value Function Update Magnitude: 0.72924
Collected Steps per Second: 12,877.22398
Overall Steps per Second: 7,147.77792
Timestep Collection Time: 3.88593
Timestep Consumption Time: 3.11485
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 7.00078
Cumulative Model Updates: 137,774
Cumulative Timesteps: 1,131,590,444
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64741
Policy Entropy: 4.31770
Value Function Loss: 0.00285
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02628
Policy Update Magnitude: 1.00492
Value Function Update Magnitude: 0.72675
Collected Steps per Second: 13,033.32811
Overall Steps per Second: 7,295.32759
Timestep Collection Time: 3.83785
Timestep Consumption Time: 3.01859
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.85644
Cumulative Model Updates: 137,783
Cumulative Timesteps: 1,131,640,464
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1131640464...
Checkpoint 1131640464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79253
Policy Entropy: 4.32014
Value Function Loss: 0.00270
Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.99573
Value Function Update Magnitude: 0.74258
Collected Steps per Second: 12,939.92192
Overall Steps per Second: 7,175.27592
Timestep Collection Time: 3.86695
Timestep Consumption Time: 3.10672
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.97367
Cumulative Model Updates: 137,792
Cumulative Timesteps: 1,131,690,502
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12289
Policy Entropy: 4.31860
Value Function Loss: 0.00275
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 1.00801
Value Function Update Magnitude: 0.73668
Collected Steps per Second: 12,946.44154
Overall Steps per Second: 7,191.30717
Timestep Collection Time: 3.86469
Timestep Consumption Time: 3.09288
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.95757
Cumulative Model Updates: 137,801
Cumulative Timesteps: 1,131,740,536
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1131740536...
Checkpoint 1131740536 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.05415
Policy Entropy: 4.31707
Value Function Loss: 0.00269
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 1.01344
Value Function Update Magnitude: 0.73516
Collected Steps per Second: 12,922.84721
Overall Steps per Second: 7,268.07672
Timestep Collection Time: 3.87128
Timestep Consumption Time: 3.01197
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.88325
Cumulative Model Updates: 137,810
Cumulative Timesteps: 1,131,790,564
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.12500
Policy Entropy: 4.31142
Value Function Loss: 0.00281
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03058
Policy Update Magnitude: 1.01660
Value Function Update Magnitude: 0.74815
Collected Steps per Second: 12,946.18935
Overall Steps per Second: 7,161.91827
Timestep Collection Time: 3.86353
Timestep Consumption Time: 3.12035
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.98388
Cumulative Model Updates: 137,819
Cumulative Timesteps: 1,131,840,582
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1131840582...
Checkpoint 1131840582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.57524
Policy Entropy: 4.31187
Value Function Loss: 0.00277
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02978
Policy Update Magnitude: 0.99997
Value Function Update Magnitude: 0.76283
Collected Steps per Second: 12,868.34016
Overall Steps per Second: 7,026.48211
Timestep Collection Time: 3.88706
Timestep Consumption Time: 3.23172
PPO Batch Consumption Time: 0.23979
Total Iteration Time: 7.11878
Cumulative Model Updates: 137,828
Cumulative Timesteps: 1,131,890,602
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.12392
Policy Entropy: 4.31198
Value Function Loss: 0.00268
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02937
Policy Update Magnitude: 0.98404
Value Function Update Magnitude: 0.73857
Collected Steps per Second: 13,180.48405
Overall Steps per Second: 7,238.40507
Timestep Collection Time: 3.79546
Timestep Consumption Time: 3.11573
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.91119
Cumulative Model Updates: 137,837
Cumulative Timesteps: 1,131,940,628
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1131940628...
Checkpoint 1131940628 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35858
Policy Entropy: 4.31816
Value Function Loss: 0.00260
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.99110
Value Function Update Magnitude: 0.71375
Collected Steps per Second: 12,942.83439
Overall Steps per Second: 7,189.31871
Timestep Collection Time: 3.86345
Timestep Consumption Time: 3.09187
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.95532
Cumulative Model Updates: 137,846
Cumulative Timesteps: 1,131,990,632
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.93005
Policy Entropy: 4.31723
Value Function Loss: 0.00278
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 1.00793
Value Function Update Magnitude: 0.73338
Collected Steps per Second: 12,952.65713
Overall Steps per Second: 7,224.04194
Timestep Collection Time: 3.86191
Timestep Consumption Time: 3.06247
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.92438
Cumulative Model Updates: 137,855
Cumulative Timesteps: 1,132,040,654
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1132040654...
Checkpoint 1132040654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.05334
Policy Entropy: 4.32141
Value Function Loss: 0.00285
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 1.02038
Value Function Update Magnitude: 0.75188
Collected Steps per Second: 13,067.66234
Overall Steps per Second: 7,216.02003
Timestep Collection Time: 3.82792
Timestep Consumption Time: 3.10415
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.93208
Cumulative Model Updates: 137,864
Cumulative Timesteps: 1,132,090,676
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.06868
Policy Entropy: 4.32012
Value Function Loss: 0.00295
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03073
Policy Update Magnitude: 1.02658
Value Function Update Magnitude: 0.76610
Collected Steps per Second: 12,930.88659
Overall Steps per Second: 7,148.93933
Timestep Collection Time: 3.86764
Timestep Consumption Time: 3.12808
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.99572
Cumulative Model Updates: 137,873
Cumulative Timesteps: 1,132,140,688
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1132140688...
Checkpoint 1132140688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47902
Policy Entropy: 4.32225
Value Function Loss: 0.00278
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02925
Policy Update Magnitude: 1.01515
Value Function Update Magnitude: 0.74902
Collected Steps per Second: 12,934.93860
Overall Steps per Second: 7,196.41471
Timestep Collection Time: 3.86550
Timestep Consumption Time: 3.08240
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.94790
Cumulative Model Updates: 137,882
Cumulative Timesteps: 1,132,190,688
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01622
Policy Entropy: 4.32247
Value Function Loss: 0.00276
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02970
Policy Update Magnitude: 1.01490
Value Function Update Magnitude: 0.73169
Collected Steps per Second: 13,216.17788
Overall Steps per Second: 7,186.24888
Timestep Collection Time: 3.78703
Timestep Consumption Time: 3.17767
PPO Batch Consumption Time: 0.23372
Total Iteration Time: 6.96469
Cumulative Model Updates: 137,891
Cumulative Timesteps: 1,132,240,738
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1132240738...
Checkpoint 1132240738 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.67485
Policy Entropy: 4.32082
Value Function Loss: 0.00281
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02922
Policy Update Magnitude: 1.00432
Value Function Update Magnitude: 0.71495
Collected Steps per Second: 13,067.19465
Overall Steps per Second: 7,209.34408
Timestep Collection Time: 3.82638
Timestep Consumption Time: 3.10907
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.93544
Cumulative Model Updates: 137,900
Cumulative Timesteps: 1,132,290,738
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53027
Policy Entropy: 4.31683
Value Function Loss: 0.00290
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02961
Policy Update Magnitude: 1.01698
Value Function Update Magnitude: 0.69590
Collected Steps per Second: 13,155.95608
Overall Steps per Second: 7,346.10457
Timestep Collection Time: 3.80147
Timestep Consumption Time: 3.00649
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.80796
Cumulative Model Updates: 137,909
Cumulative Timesteps: 1,132,340,750
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1132340750...
Checkpoint 1132340750 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83384
Policy Entropy: 4.31778
Value Function Loss: 0.00284
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 1.02062
Value Function Update Magnitude: 0.70932
Collected Steps per Second: 12,960.86645
Overall Steps per Second: 7,180.60503
Timestep Collection Time: 3.85808
Timestep Consumption Time: 3.10568
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.96376
Cumulative Model Updates: 137,918
Cumulative Timesteps: 1,132,390,754
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.08668
Policy Entropy: 4.31894
Value Function Loss: 0.00288
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03022
Policy Update Magnitude: 1.02601
Value Function Update Magnitude: 0.71336
Collected Steps per Second: 12,890.98500
Overall Steps per Second: 7,169.20295
Timestep Collection Time: 3.87914
Timestep Consumption Time: 3.09597
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.97511
Cumulative Model Updates: 137,927
Cumulative Timesteps: 1,132,440,760
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1132440760...
Checkpoint 1132440760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71556
Policy Entropy: 4.32124
Value Function Loss: 0.00271
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02828
Policy Update Magnitude: 1.02168
Value Function Update Magnitude: 0.70594
Collected Steps per Second: 12,933.51599
Overall Steps per Second: 7,269.49656
Timestep Collection Time: 3.86809
Timestep Consumption Time: 3.01382
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 6.88191
Cumulative Model Updates: 137,936
Cumulative Timesteps: 1,132,490,788
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.71652
Policy Entropy: 4.31359
Value Function Loss: 0.00275
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 1.02275
Value Function Update Magnitude: 0.70706
Collected Steps per Second: 13,024.19338
Overall Steps per Second: 7,189.76392
Timestep Collection Time: 3.83993
Timestep Consumption Time: 3.11607
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.95600
Cumulative Model Updates: 137,945
Cumulative Timesteps: 1,132,540,800
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1132540800...
Checkpoint 1132540800 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70278
Policy Entropy: 4.30983
Value Function Loss: 0.00273
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02803
Policy Update Magnitude: 1.01752
Value Function Update Magnitude: 0.69236
Collected Steps per Second: 12,837.54209
Overall Steps per Second: 7,019.95382
Timestep Collection Time: 3.89638
Timestep Consumption Time: 3.22902
PPO Batch Consumption Time: 0.24093
Total Iteration Time: 7.12540
Cumulative Model Updates: 137,954
Cumulative Timesteps: 1,132,590,820
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.33613
Policy Entropy: 4.30737
Value Function Loss: 0.00282
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02908
Policy Update Magnitude: 1.01868
Value Function Update Magnitude: 0.69597
Collected Steps per Second: 13,215.40983
Overall Steps per Second: 7,257.56776
Timestep Collection Time: 3.78649
Timestep Consumption Time: 3.10838
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.89487
Cumulative Model Updates: 137,963
Cumulative Timesteps: 1,132,640,860
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1132640860...
Checkpoint 1132640860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.64238
Policy Entropy: 4.30764
Value Function Loss: 0.00286
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03114
Policy Update Magnitude: 1.00259
Value Function Update Magnitude: 0.69125
Collected Steps per Second: 12,882.82733
Overall Steps per Second: 7,144.77276
Timestep Collection Time: 3.88176
Timestep Consumption Time: 3.11749
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.99924
Cumulative Model Updates: 137,972
Cumulative Timesteps: 1,132,690,868
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.38841
Policy Entropy: 4.30804
Value Function Loss: 0.00290
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02996
Policy Update Magnitude: 0.99861
Value Function Update Magnitude: 0.71339
Collected Steps per Second: 13,002.00075
Overall Steps per Second: 7,301.06582
Timestep Collection Time: 3.84556
Timestep Consumption Time: 3.00275
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.84832
Cumulative Model Updates: 137,981
Cumulative Timesteps: 1,132,740,868
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1132740868...
Checkpoint 1132740868 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.45871
Policy Entropy: 4.30742
Value Function Loss: 0.00298
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02969
Policy Update Magnitude: 1.01963
Value Function Update Magnitude: 0.74884
Collected Steps per Second: 13,002.03027
Overall Steps per Second: 7,179.29122
Timestep Collection Time: 3.84925
Timestep Consumption Time: 3.12192
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.97116
Cumulative Model Updates: 137,990
Cumulative Timesteps: 1,132,790,916
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.08471
Policy Entropy: 4.30879
Value Function Loss: 0.00287
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 1.01348
Value Function Update Magnitude: 0.72209
Collected Steps per Second: 13,004.93997
Overall Steps per Second: 7,174.03217
Timestep Collection Time: 3.84685
Timestep Consumption Time: 3.12664
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.97348
Cumulative Model Updates: 137,999
Cumulative Timesteps: 1,132,840,944
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1132840944...
Checkpoint 1132840944 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.59704
Policy Entropy: 4.31142
Value Function Loss: 0.00280
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03052
Policy Update Magnitude: 0.99436
Value Function Update Magnitude: 0.71218
Collected Steps per Second: 12,849.49319
Overall Steps per Second: 7,258.45101
Timestep Collection Time: 3.89167
Timestep Consumption Time: 2.99768
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.88935
Cumulative Model Updates: 138,008
Cumulative Timesteps: 1,132,890,950
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02957
Policy Entropy: 4.31161
Value Function Loss: 0.00274
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03238
Policy Update Magnitude: 1.00107
Value Function Update Magnitude: 0.68956
Collected Steps per Second: 12,890.31439
Overall Steps per Second: 7,114.40847
Timestep Collection Time: 3.87904
Timestep Consumption Time: 3.14924
PPO Batch Consumption Time: 0.23017
Total Iteration Time: 7.02827
Cumulative Model Updates: 138,017
Cumulative Timesteps: 1,132,940,952
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1132940952...
Checkpoint 1132940952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.19753
Policy Entropy: 4.30895
Value Function Loss: 0.00273
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03016
Policy Update Magnitude: 0.99636
Value Function Update Magnitude: 0.68894
Collected Steps per Second: 12,926.51385
Overall Steps per Second: 7,210.08048
Timestep Collection Time: 3.87018
Timestep Consumption Time: 3.06843
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.93862
Cumulative Model Updates: 138,026
Cumulative Timesteps: 1,132,990,980
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.44674
Policy Entropy: 4.30705
Value Function Loss: 0.00275
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 1.01700
Value Function Update Magnitude: 0.70137
Collected Steps per Second: 12,889.74375
Overall Steps per Second: 7,257.82635
Timestep Collection Time: 3.88014
Timestep Consumption Time: 3.01090
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.89104
Cumulative Model Updates: 138,035
Cumulative Timesteps: 1,133,040,994
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1133040994...
Checkpoint 1133040994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28629
Policy Entropy: 4.30689
Value Function Loss: 0.00271
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 1.01725
Value Function Update Magnitude: 0.71938
Collected Steps per Second: 12,885.51139
Overall Steps per Second: 7,146.59737
Timestep Collection Time: 3.88064
Timestep Consumption Time: 3.11626
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.99690
Cumulative Model Updates: 138,044
Cumulative Timesteps: 1,133,090,998
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.88205
Policy Entropy: 4.31231
Value Function Loss: 0.00260
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 1.01445
Value Function Update Magnitude: 0.72719
Collected Steps per Second: 12,922.55681
Overall Steps per Second: 7,176.60823
Timestep Collection Time: 3.87183
Timestep Consumption Time: 3.09998
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.97182
Cumulative Model Updates: 138,053
Cumulative Timesteps: 1,133,141,032
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1133141032...
Checkpoint 1133141032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95075
Policy Entropy: 4.31037
Value Function Loss: 0.00249
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02805
Policy Update Magnitude: 1.01064
Value Function Update Magnitude: 0.72023
Collected Steps per Second: 13,127.75250
Overall Steps per Second: 7,230.50584
Timestep Collection Time: 3.81101
Timestep Consumption Time: 3.10828
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.91929
Cumulative Model Updates: 138,062
Cumulative Timesteps: 1,133,191,062
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28054
Policy Entropy: 4.31326
Value Function Loss: 0.00253
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.99214
Value Function Update Magnitude: 0.68878
Collected Steps per Second: 12,891.38983
Overall Steps per Second: 7,149.65440
Timestep Collection Time: 3.88166
Timestep Consumption Time: 3.11728
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.99894
Cumulative Model Updates: 138,071
Cumulative Timesteps: 1,133,241,102
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1133241102...
Checkpoint 1133241102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46911
Policy Entropy: 4.30636
Value Function Loss: 0.00278
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02924
Policy Update Magnitude: 1.01469
Value Function Update Magnitude: 0.69243
Collected Steps per Second: 12,985.84559
Overall Steps per Second: 7,077.40986
Timestep Collection Time: 3.85250
Timestep Consumption Time: 3.21619
PPO Batch Consumption Time: 0.23826
Total Iteration Time: 7.06869
Cumulative Model Updates: 138,080
Cumulative Timesteps: 1,133,291,130
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.48488
Policy Entropy: 4.30594
Value Function Loss: 0.00301
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03130
Policy Update Magnitude: 1.04343
Value Function Update Magnitude: 0.75959
Collected Steps per Second: 13,247.77439
Overall Steps per Second: 7,265.09749
Timestep Collection Time: 3.77694
Timestep Consumption Time: 3.11024
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.88718
Cumulative Model Updates: 138,089
Cumulative Timesteps: 1,133,341,166
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1133341166...
Checkpoint 1133341166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95195
Policy Entropy: 4.30481
Value Function Loss: 0.00295
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03146
Policy Update Magnitude: 1.06085
Value Function Update Magnitude: 0.77279
Collected Steps per Second: 13,080.33530
Overall Steps per Second: 7,210.40707
Timestep Collection Time: 3.82483
Timestep Consumption Time: 3.11376
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.93858
Cumulative Model Updates: 138,098
Cumulative Timesteps: 1,133,391,196
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.24311
Policy Entropy: 4.30723
Value Function Loss: 0.00280
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 1.04733
Value Function Update Magnitude: 0.76427
Collected Steps per Second: 12,868.70351
Overall Steps per Second: 7,251.36993
Timestep Collection Time: 3.88648
Timestep Consumption Time: 3.01070
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.89718
Cumulative Model Updates: 138,107
Cumulative Timesteps: 1,133,441,210
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1133441210...
Checkpoint 1133441210 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.37794
Policy Entropy: 4.31240
Value Function Loss: 0.00268
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 1.05260
Value Function Update Magnitude: 0.74900
Collected Steps per Second: 13,007.59409
Overall Steps per Second: 7,203.41183
Timestep Collection Time: 3.84668
Timestep Consumption Time: 3.09948
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.94615
Cumulative Model Updates: 138,116
Cumulative Timesteps: 1,133,491,246
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.24623
Policy Entropy: 4.31723
Value Function Loss: 0.00260
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03263
Policy Update Magnitude: 1.04125
Value Function Update Magnitude: 0.74123
Collected Steps per Second: 12,974.56445
Overall Steps per Second: 7,217.36899
Timestep Collection Time: 3.85431
Timestep Consumption Time: 3.07453
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.92884
Cumulative Model Updates: 138,125
Cumulative Timesteps: 1,133,541,254
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1133541254...
Checkpoint 1133541254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.41110
Policy Entropy: 4.31544
Value Function Loss: 0.00268
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03039
Policy Update Magnitude: 1.02048
Value Function Update Magnitude: 0.72388
Collected Steps per Second: 12,984.74971
Overall Steps per Second: 7,301.10575
Timestep Collection Time: 3.85144
Timestep Consumption Time: 2.99821
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.84965
Cumulative Model Updates: 138,134
Cumulative Timesteps: 1,133,591,264
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.74310
Policy Entropy: 4.31386
Value Function Loss: 0.00273
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 1.02144
Value Function Update Magnitude: 0.71475
Collected Steps per Second: 13,099.02255
Overall Steps per Second: 7,129.73485
Timestep Collection Time: 3.81891
Timestep Consumption Time: 3.19734
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 7.01625
Cumulative Model Updates: 138,143
Cumulative Timesteps: 1,133,641,288
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1133641288...
Checkpoint 1133641288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.79960
Policy Entropy: 4.31135
Value Function Loss: 0.00293
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02998
Policy Update Magnitude: 1.05093
Value Function Update Magnitude: 0.73465
Collected Steps per Second: 12,863.19597
Overall Steps per Second: 7,176.57560
Timestep Collection Time: 3.88768
Timestep Consumption Time: 3.08055
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.96823
Cumulative Model Updates: 138,152
Cumulative Timesteps: 1,133,691,296
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84149
Policy Entropy: 4.31192
Value Function Loss: 0.00286
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03195
Policy Update Magnitude: 1.06051
Value Function Update Magnitude: 0.74102
Collected Steps per Second: 13,344.60714
Overall Steps per Second: 7,293.00539
Timestep Collection Time: 3.75088
Timestep Consumption Time: 3.11241
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.86329
Cumulative Model Updates: 138,161
Cumulative Timesteps: 1,133,741,350
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1133741350...
Checkpoint 1133741350 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.16644
Policy Entropy: 4.31289
Value Function Loss: 0.00289
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03114
Policy Update Magnitude: 1.05333
Value Function Update Magnitude: 0.72683
Collected Steps per Second: 13,004.83025
Overall Steps per Second: 7,178.44472
Timestep Collection Time: 3.84765
Timestep Consumption Time: 3.12294
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.97059
Cumulative Model Updates: 138,170
Cumulative Timesteps: 1,133,791,388
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03326
Policy Entropy: 4.31698
Value Function Loss: 0.00273
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03004
Policy Update Magnitude: 1.03455
Value Function Update Magnitude: 0.71390
Collected Steps per Second: 13,063.26929
Overall Steps per Second: 7,205.14962
Timestep Collection Time: 3.83013
Timestep Consumption Time: 3.11407
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.94420
Cumulative Model Updates: 138,179
Cumulative Timesteps: 1,133,841,422
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1133841422...
Checkpoint 1133841422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.50829
Policy Entropy: 4.31702
Value Function Loss: 0.00266
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03157
Policy Update Magnitude: 1.00248
Value Function Update Magnitude: 0.70596
Collected Steps per Second: 13,215.26708
Overall Steps per Second: 7,257.32437
Timestep Collection Time: 3.78502
Timestep Consumption Time: 3.10733
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.89235
Cumulative Model Updates: 138,188
Cumulative Timesteps: 1,133,891,442
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.47696
Policy Entropy: 4.31809
Value Function Loss: 0.00271
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03246
Policy Update Magnitude: 1.01056
Value Function Update Magnitude: 0.72577
Collected Steps per Second: 13,004.42333
Overall Steps per Second: 7,206.39070
Timestep Collection Time: 3.84515
Timestep Consumption Time: 3.09369
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.93884
Cumulative Model Updates: 138,197
Cumulative Timesteps: 1,133,941,446
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1133941446...
Checkpoint 1133941446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.24086
Policy Entropy: 4.31561
Value Function Loss: 0.00278
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03226
Policy Update Magnitude: 1.03814
Value Function Update Magnitude: 0.71212
Collected Steps per Second: 12,763.82598
Overall Steps per Second: 7,167.17059
Timestep Collection Time: 3.91998
Timestep Consumption Time: 3.06101
PPO Batch Consumption Time: 0.23010
Total Iteration Time: 6.98100
Cumulative Model Updates: 138,206
Cumulative Timesteps: 1,133,991,480
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03143
Policy Entropy: 4.31446
Value Function Loss: 0.00295
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03426
Policy Update Magnitude: 1.04686
Value Function Update Magnitude: 0.73622
Collected Steps per Second: 13,006.06432
Overall Steps per Second: 7,148.27962
Timestep Collection Time: 3.84559
Timestep Consumption Time: 3.15134
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.99693
Cumulative Model Updates: 138,215
Cumulative Timesteps: 1,134,041,496
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1134041496...
Checkpoint 1134041496 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.70866
Policy Entropy: 4.31632
Value Function Loss: 0.00290
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 1.05434
Value Function Update Magnitude: 0.73863
Collected Steps per Second: 12,998.53637
Overall Steps per Second: 7,226.40050
Timestep Collection Time: 3.84920
Timestep Consumption Time: 3.07458
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.92378
Cumulative Model Updates: 138,224
Cumulative Timesteps: 1,134,091,530
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.20810
Policy Entropy: 4.31437
Value Function Loss: 0.00287
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 1.06510
Value Function Update Magnitude: 0.73408
Collected Steps per Second: 12,875.65990
Overall Steps per Second: 7,266.69530
Timestep Collection Time: 3.88423
Timestep Consumption Time: 2.99813
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.88236
Cumulative Model Updates: 138,233
Cumulative Timesteps: 1,134,141,542
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1134141542...
Checkpoint 1134141542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.98540
Policy Entropy: 4.32006
Value Function Loss: 0.00275
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03206
Policy Update Magnitude: 1.06797
Value Function Update Magnitude: 0.74125
Collected Steps per Second: 12,955.62194
Overall Steps per Second: 7,162.83555
Timestep Collection Time: 3.86118
Timestep Consumption Time: 3.12265
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.98383
Cumulative Model Updates: 138,242
Cumulative Timesteps: 1,134,191,566
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.16171
Policy Entropy: 4.32114
Value Function Loss: 0.00269
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03154
Policy Update Magnitude: 1.05439
Value Function Update Magnitude: 0.72893
Collected Steps per Second: 13,022.75377
Overall Steps per Second: 7,224.66432
Timestep Collection Time: 3.83959
Timestep Consumption Time: 3.08143
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.92101
Cumulative Model Updates: 138,251
Cumulative Timesteps: 1,134,241,568
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1134241568...
Checkpoint 1134241568 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.67913
Policy Entropy: 4.31786
Value Function Loss: 0.00284
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 1.06277
Value Function Update Magnitude: 0.74913
Collected Steps per Second: 12,696.52217
Overall Steps per Second: 7,189.68055
Timestep Collection Time: 3.93809
Timestep Consumption Time: 3.01633
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.95441
Cumulative Model Updates: 138,260
Cumulative Timesteps: 1,134,291,568
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79679
Policy Entropy: 4.31529
Value Function Loss: 0.00285
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 1.07183
Value Function Update Magnitude: 0.76680
Collected Steps per Second: 12,795.58901
Overall Steps per Second: 7,073.62493
Timestep Collection Time: 3.90791
Timestep Consumption Time: 3.16117
PPO Batch Consumption Time: 0.23275
Total Iteration Time: 7.06908
Cumulative Model Updates: 138,269
Cumulative Timesteps: 1,134,341,572
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1134341572...
Checkpoint 1134341572 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.65650
Policy Entropy: 4.31564
Value Function Loss: 0.00294
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03316
Policy Update Magnitude: 1.06094
Value Function Update Magnitude: 0.78492
Collected Steps per Second: 12,907.54074
Overall Steps per Second: 7,193.13178
Timestep Collection Time: 3.87401
Timestep Consumption Time: 3.07762
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.95163
Cumulative Model Updates: 138,278
Cumulative Timesteps: 1,134,391,576
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.72952
Policy Entropy: 4.31692
Value Function Loss: 0.00288
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 1.06756
Value Function Update Magnitude: 0.78006
Collected Steps per Second: 13,327.99034
Overall Steps per Second: 7,297.68618
Timestep Collection Time: 3.75345
Timestep Consumption Time: 3.10160
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.85505
Cumulative Model Updates: 138,287
Cumulative Timesteps: 1,134,441,602
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1134441602...
Checkpoint 1134441602 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69038
Policy Entropy: 4.31537
Value Function Loss: 0.00282
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03306
Policy Update Magnitude: 1.06347
Value Function Update Magnitude: 0.79522
Collected Steps per Second: 13,002.41662
Overall Steps per Second: 7,168.32578
Timestep Collection Time: 3.84805
Timestep Consumption Time: 3.13182
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.97987
Cumulative Model Updates: 138,296
Cumulative Timesteps: 1,134,491,636
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.81042
Policy Entropy: 4.31572
Value Function Loss: 0.00276
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02968
Policy Update Magnitude: 1.04790
Value Function Update Magnitude: 0.79601
Collected Steps per Second: 12,857.91518
Overall Steps per Second: 7,173.40159
Timestep Collection Time: 3.89068
Timestep Consumption Time: 3.08314
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.97382
Cumulative Model Updates: 138,305
Cumulative Timesteps: 1,134,541,662
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1134541662...
Checkpoint 1134541662 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61327
Policy Entropy: 4.31456
Value Function Loss: 0.00282
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02731
Policy Update Magnitude: 1.04856
Value Function Update Magnitude: 0.78152
Collected Steps per Second: 13,277.79549
Overall Steps per Second: 7,268.15426
Timestep Collection Time: 3.76704
Timestep Consumption Time: 3.11476
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.88180
Cumulative Model Updates: 138,314
Cumulative Timesteps: 1,134,591,680
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.78572
Policy Entropy: 4.31655
Value Function Loss: 0.00288
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 1.05871
Value Function Update Magnitude: 0.77551
Collected Steps per Second: 12,911.98646
Overall Steps per Second: 7,150.83224
Timestep Collection Time: 3.87392
Timestep Consumption Time: 3.12107
PPO Batch Consumption Time: 0.22788
Total Iteration Time: 6.99499
Cumulative Model Updates: 138,323
Cumulative Timesteps: 1,134,641,700
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1134641700...
Checkpoint 1134641700 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.93550
Policy Entropy: 4.31835
Value Function Loss: 0.00283
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 1.06406
Value Function Update Magnitude: 0.75315
Collected Steps per Second: 13,003.62352
Overall Steps per Second: 7,233.05720
Timestep Collection Time: 3.84524
Timestep Consumption Time: 3.06775
PPO Batch Consumption Time: 0.22967
Total Iteration Time: 6.91298
Cumulative Model Updates: 138,332
Cumulative Timesteps: 1,134,691,702
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.95645
Policy Entropy: 4.32155
Value Function Loss: 0.00280
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02827
Policy Update Magnitude: 1.06045
Value Function Update Magnitude: 0.74857
Collected Steps per Second: 13,030.80427
Overall Steps per Second: 7,198.93313
Timestep Collection Time: 3.83706
Timestep Consumption Time: 3.10841
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.94547
Cumulative Model Updates: 138,341
Cumulative Timesteps: 1,134,741,702
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1134741702...
Checkpoint 1134741702 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.14105
Policy Entropy: 4.32004
Value Function Loss: 0.00280
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02969
Policy Update Magnitude: 1.06574
Value Function Update Magnitude: 0.75499
Collected Steps per Second: 12,996.61710
Overall Steps per Second: 7,165.94189
Timestep Collection Time: 3.84900
Timestep Consumption Time: 3.13180
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.98080
Cumulative Model Updates: 138,350
Cumulative Timesteps: 1,134,791,726
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.20888
Policy Entropy: 4.31552
Value Function Loss: 0.00288
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 1.06483
Value Function Update Magnitude: 0.73612
Collected Steps per Second: 12,751.99498
Overall Steps per Second: 7,199.09900
Timestep Collection Time: 3.92252
Timestep Consumption Time: 3.02557
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.94809
Cumulative Model Updates: 138,359
Cumulative Timesteps: 1,134,841,746
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1134841746...
Checkpoint 1134841746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75134
Policy Entropy: 4.31486
Value Function Loss: 0.00291
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 1.06102
Value Function Update Magnitude: 0.73085
Collected Steps per Second: 12,935.31137
Overall Steps per Second: 7,159.11234
Timestep Collection Time: 3.86833
Timestep Consumption Time: 3.12109
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.98941
Cumulative Model Updates: 138,368
Cumulative Timesteps: 1,134,891,784
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.11766
Policy Entropy: 4.31622
Value Function Loss: 0.00278
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03695
Policy Update Magnitude: 1.04809
Value Function Update Magnitude: 0.74064
Collected Steps per Second: 13,117.51085
Overall Steps per Second: 7,277.77746
Timestep Collection Time: 3.81490
Timestep Consumption Time: 3.06110
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.87600
Cumulative Model Updates: 138,377
Cumulative Timesteps: 1,134,941,826
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1134941826...
Checkpoint 1134941826 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.51802
Policy Entropy: 4.31982
Value Function Loss: 0.00262
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03589
Policy Update Magnitude: 1.02555
Value Function Update Magnitude: 0.74391
Collected Steps per Second: 12,958.31124
Overall Steps per Second: 7,284.16364
Timestep Collection Time: 3.86161
Timestep Consumption Time: 3.00808
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.86970
Cumulative Model Updates: 138,386
Cumulative Timesteps: 1,134,991,866
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.49527
Policy Entropy: 4.32233
Value Function Loss: 0.00265
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03196
Policy Update Magnitude: 1.03175
Value Function Update Magnitude: 0.73569
Collected Steps per Second: 13,006.73524
Overall Steps per Second: 7,073.06512
Timestep Collection Time: 3.84693
Timestep Consumption Time: 3.22723
PPO Batch Consumption Time: 0.23724
Total Iteration Time: 7.07416
Cumulative Model Updates: 138,395
Cumulative Timesteps: 1,135,041,902
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1135041902...
Checkpoint 1135041902 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.68484
Policy Entropy: 4.32326
Value Function Loss: 0.00283
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 1.05272
Value Function Update Magnitude: 0.76654
Collected Steps per Second: 13,048.67286
Overall Steps per Second: 7,234.59652
Timestep Collection Time: 3.83349
Timestep Consumption Time: 3.08078
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.91428
Cumulative Model Updates: 138,404
Cumulative Timesteps: 1,135,091,924
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.31025
Policy Entropy: 4.32412
Value Function Loss: 0.00291
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03086
Policy Update Magnitude: 1.06166
Value Function Update Magnitude: 0.79899
Collected Steps per Second: 13,241.25562
Overall Steps per Second: 7,271.20931
Timestep Collection Time: 3.77910
Timestep Consumption Time: 3.10284
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.88194
Cumulative Model Updates: 138,413
Cumulative Timesteps: 1,135,141,964
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1135141964...
Checkpoint 1135141964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.57206
Policy Entropy: 4.32036
Value Function Loss: 0.00280
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03020
Policy Update Magnitude: 1.03959
Value Function Update Magnitude: 0.78261
Collected Steps per Second: 12,902.61485
Overall Steps per Second: 7,154.03596
Timestep Collection Time: 3.87549
Timestep Consumption Time: 3.11413
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.98962
Cumulative Model Updates: 138,422
Cumulative Timesteps: 1,135,191,968
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.65672
Policy Entropy: 4.31589
Value Function Loss: 0.00287
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02868
Policy Update Magnitude: 1.03463
Value Function Update Magnitude: 0.73371
Collected Steps per Second: 13,002.38397
Overall Steps per Second: 7,219.72270
Timestep Collection Time: 3.84837
Timestep Consumption Time: 3.08237
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.93074
Cumulative Model Updates: 138,431
Cumulative Timesteps: 1,135,242,006
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1135242006...
Checkpoint 1135242006 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19573
Policy Entropy: 4.31219
Value Function Loss: 0.00289
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03202
Policy Update Magnitude: 1.03540
Value Function Update Magnitude: 0.73332
Collected Steps per Second: 13,328.48096
Overall Steps per Second: 7,270.01269
Timestep Collection Time: 3.75212
Timestep Consumption Time: 3.12683
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.87894
Cumulative Model Updates: 138,440
Cumulative Timesteps: 1,135,292,016
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53628
Policy Entropy: 4.31326
Value Function Loss: 0.00289
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 1.04883
Value Function Update Magnitude: 0.74855
Collected Steps per Second: 12,846.65385
Overall Steps per Second: 7,141.61560
Timestep Collection Time: 3.89455
Timestep Consumption Time: 3.11114
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 7.00570
Cumulative Model Updates: 138,449
Cumulative Timesteps: 1,135,342,048
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1135342048...
Checkpoint 1135342048 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10254
Policy Entropy: 4.32102
Value Function Loss: 0.00273
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02920
Policy Update Magnitude: 1.03200
Value Function Update Magnitude: 0.76437
Collected Steps per Second: 12,901.35194
Overall Steps per Second: 7,210.77649
Timestep Collection Time: 3.87882
Timestep Consumption Time: 3.06107
PPO Batch Consumption Time: 0.22985
Total Iteration Time: 6.93989
Cumulative Model Updates: 138,458
Cumulative Timesteps: 1,135,392,090
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.56342
Policy Entropy: 4.32403
Value Function Loss: 0.00274
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02855
Policy Update Magnitude: 1.02675
Value Function Update Magnitude: 0.76106
Collected Steps per Second: 13,049.03050
Overall Steps per Second: 7,206.19554
Timestep Collection Time: 3.83308
Timestep Consumption Time: 3.10789
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.94097
Cumulative Model Updates: 138,467
Cumulative Timesteps: 1,135,442,108
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1135442108...
Checkpoint 1135442108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.45956
Policy Entropy: 4.32718
Value Function Loss: 0.00270
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 1.00925
Value Function Update Magnitude: 0.76812
Collected Steps per Second: 12,951.73729
Overall Steps per Second: 7,218.65562
Timestep Collection Time: 3.86157
Timestep Consumption Time: 3.06687
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.92844
Cumulative Model Updates: 138,476
Cumulative Timesteps: 1,135,492,122
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.85749
Policy Entropy: 4.31596
Value Function Loss: 0.00285
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 1.02220
Value Function Update Magnitude: 0.77139
Collected Steps per Second: 12,919.96434
Overall Steps per Second: 7,263.78653
Timestep Collection Time: 3.87400
Timestep Consumption Time: 3.01662
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.89062
Cumulative Model Updates: 138,485
Cumulative Timesteps: 1,135,542,174
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1135542174...
Checkpoint 1135542174 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01063
Policy Entropy: 4.31413
Value Function Loss: 0.00286
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03043
Policy Update Magnitude: 1.03448
Value Function Update Magnitude: 0.76897
Collected Steps per Second: 12,968.07934
Overall Steps per Second: 7,160.95286
Timestep Collection Time: 3.85578
Timestep Consumption Time: 3.12682
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.98259
Cumulative Model Updates: 138,494
Cumulative Timesteps: 1,135,592,176
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.06855
Policy Entropy: 4.31043
Value Function Loss: 0.00286
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 1.03623
Value Function Update Magnitude: 0.77075
Collected Steps per Second: 12,890.20403
Overall Steps per Second: 7,187.59557
Timestep Collection Time: 3.88124
Timestep Consumption Time: 3.07936
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.96060
Cumulative Model Updates: 138,503
Cumulative Timesteps: 1,135,642,206
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1135642206...
Checkpoint 1135642206 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10408
Policy Entropy: 4.31238
Value Function Loss: 0.00280
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03134
Policy Update Magnitude: 1.03250
Value Function Update Magnitude: 0.75138
Collected Steps per Second: 13,400.47182
Overall Steps per Second: 7,305.68045
Timestep Collection Time: 3.73181
Timestep Consumption Time: 3.11328
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.84508
Cumulative Model Updates: 138,512
Cumulative Timesteps: 1,135,692,214
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.66333
Policy Entropy: 4.31281
Value Function Loss: 0.00283
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03022
Policy Update Magnitude: 1.02947
Value Function Update Magnitude: 0.78689
Collected Steps per Second: 12,874.38169
Overall Steps per Second: 7,119.46188
Timestep Collection Time: 3.88679
Timestep Consumption Time: 3.14183
PPO Batch Consumption Time: 0.23195
Total Iteration Time: 7.02862
Cumulative Model Updates: 138,521
Cumulative Timesteps: 1,135,742,254
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1135742254...
Checkpoint 1135742254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.14129
Policy Entropy: 4.31480
Value Function Loss: 0.00286
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02978
Policy Update Magnitude: 1.04681
Value Function Update Magnitude: 0.83689
Collected Steps per Second: 13,011.23269
Overall Steps per Second: 7,244.37168
Timestep Collection Time: 3.84360
Timestep Consumption Time: 3.05969
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.90329
Cumulative Model Updates: 138,530
Cumulative Timesteps: 1,135,792,264
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70426
Policy Entropy: 4.31894
Value Function Loss: 0.00282
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02997
Policy Update Magnitude: 1.06097
Value Function Update Magnitude: 0.83257
Collected Steps per Second: 13,288.51317
Overall Steps per Second: 7,283.81228
Timestep Collection Time: 3.76551
Timestep Consumption Time: 3.10425
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.86975
Cumulative Model Updates: 138,539
Cumulative Timesteps: 1,135,842,302
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1135842302...
Checkpoint 1135842302 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.06588
Policy Entropy: 4.31612
Value Function Loss: 0.00284
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 1.06000
Value Function Update Magnitude: 0.83695
Collected Steps per Second: 12,852.38417
Overall Steps per Second: 7,136.98118
Timestep Collection Time: 3.89297
Timestep Consumption Time: 3.11755
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 7.01053
Cumulative Model Updates: 138,548
Cumulative Timesteps: 1,135,892,336
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.96340
Policy Entropy: 4.31200
Value Function Loss: 0.00287
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 1.04767
Value Function Update Magnitude: 0.84069
Collected Steps per Second: 12,860.18274
Overall Steps per Second: 7,170.11615
Timestep Collection Time: 3.89264
Timestep Consumption Time: 3.08912
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.98176
Cumulative Model Updates: 138,557
Cumulative Timesteps: 1,135,942,396
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 1135942396...
Checkpoint 1135942396 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.61266
Policy Entropy: 4.30830
Value Function Loss: 0.00295
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 1.04980
Value Function Update Magnitude: 0.79896
Collected Steps per Second: 13,275.15684
Overall Steps per Second: 7,263.76452
Timestep Collection Time: 3.76658
Timestep Consumption Time: 3.11717
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.88376
Cumulative Model Updates: 138,566
Cumulative Timesteps: 1,135,992,398
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.86868
Policy Entropy: 4.30728
Value Function Loss: 0.00302
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03292
Policy Update Magnitude: 1.07465
Value Function Update Magnitude: 0.77396
Collected Steps per Second: 12,903.76636
Overall Steps per Second: 7,143.52701
Timestep Collection Time: 3.87654
Timestep Consumption Time: 3.12588
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 7.00242
Cumulative Model Updates: 138,575
Cumulative Timesteps: 1,136,042,420
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1136042420...
Checkpoint 1136042420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.31296
Policy Entropy: 4.30916
Value Function Loss: 0.00289
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 1.04781
Value Function Update Magnitude: 0.78575
Collected Steps per Second: 12,862.17582
Overall Steps per Second: 7,178.51057
Timestep Collection Time: 3.88939
Timestep Consumption Time: 3.07947
PPO Batch Consumption Time: 0.22953
Total Iteration Time: 6.96886
Cumulative Model Updates: 138,584
Cumulative Timesteps: 1,136,092,446
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.00929
Policy Entropy: 4.31264
Value Function Loss: 0.00288
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03304
Policy Update Magnitude: 1.04607
Value Function Update Magnitude: 0.79099
Collected Steps per Second: 13,053.91354
Overall Steps per Second: 7,166.91291
Timestep Collection Time: 3.83211
Timestep Consumption Time: 3.14775
PPO Batch Consumption Time: 0.23045
Total Iteration Time: 6.97985
Cumulative Model Updates: 138,593
Cumulative Timesteps: 1,136,142,470
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1136142470...
Checkpoint 1136142470 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.15771
Policy Entropy: 4.31297
Value Function Loss: 0.00297
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 1.04254
Value Function Update Magnitude: 0.80220
Collected Steps per Second: 13,044.79612
Overall Steps per Second: 7,227.09583
Timestep Collection Time: 3.83494
Timestep Consumption Time: 3.08707
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.92201
Cumulative Model Updates: 138,602
Cumulative Timesteps: 1,136,192,496
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.28483
Policy Entropy: 4.31580
Value Function Loss: 0.00303
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03432
Policy Update Magnitude: 1.05801
Value Function Update Magnitude: 0.80767
Collected Steps per Second: 12,877.20609
Overall Steps per Second: 7,242.15003
Timestep Collection Time: 3.88361
Timestep Consumption Time: 3.02180
PPO Batch Consumption Time: 0.22923
Total Iteration Time: 6.90541
Cumulative Model Updates: 138,611
Cumulative Timesteps: 1,136,242,506
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1136242506...
Checkpoint 1136242506 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01349
Policy Entropy: 4.31274
Value Function Loss: 0.00299
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 1.06607
Value Function Update Magnitude: 0.78482
Collected Steps per Second: 12,928.46198
Overall Steps per Second: 7,154.43970
Timestep Collection Time: 3.87084
Timestep Consumption Time: 3.12398
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.99482
Cumulative Model Updates: 138,620
Cumulative Timesteps: 1,136,292,550
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71907
Policy Entropy: 4.31492
Value Function Loss: 0.00293
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03233
Policy Update Magnitude: 1.05676
Value Function Update Magnitude: 0.79428
Collected Steps per Second: 12,946.46917
Overall Steps per Second: 7,222.48592
Timestep Collection Time: 3.86252
Timestep Consumption Time: 3.06113
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.92365
Cumulative Model Updates: 138,629
Cumulative Timesteps: 1,136,342,556
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1136342556...
Checkpoint 1136342556 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.39098
Policy Entropy: 4.31390
Value Function Loss: 0.00281
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 1.04059
Value Function Update Magnitude: 0.80278
Collected Steps per Second: 12,874.74298
Overall Steps per Second: 7,253.20767
Timestep Collection Time: 3.88404
Timestep Consumption Time: 3.01029
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.89433
Cumulative Model Updates: 138,638
Cumulative Timesteps: 1,136,392,562
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87642
Policy Entropy: 4.31784
Value Function Loss: 0.00276
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02944
Policy Update Magnitude: 1.03919
Value Function Update Magnitude: 0.78556
Collected Steps per Second: 12,930.53883
Overall Steps per Second: 7,112.82188
Timestep Collection Time: 3.86898
Timestep Consumption Time: 3.16452
PPO Batch Consumption Time: 0.23094
Total Iteration Time: 7.03350
Cumulative Model Updates: 138,647
Cumulative Timesteps: 1,136,442,590
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1136442590...
Checkpoint 1136442590 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.73506
Policy Entropy: 4.31678
Value Function Loss: 0.00270
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02945
Policy Update Magnitude: 1.02837
Value Function Update Magnitude: 0.77067
Collected Steps per Second: 12,831.92281
Overall Steps per Second: 7,156.74718
Timestep Collection Time: 3.90043
Timestep Consumption Time: 3.09297
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.99340
Cumulative Model Updates: 138,656
Cumulative Timesteps: 1,136,492,640
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36906
Policy Entropy: 4.31609
Value Function Loss: 0.00279
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 1.04917
Value Function Update Magnitude: 0.76043
Collected Steps per Second: 13,207.51782
Overall Steps per Second: 7,246.50637
Timestep Collection Time: 3.78678
Timestep Consumption Time: 3.11503
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.90181
Cumulative Model Updates: 138,665
Cumulative Timesteps: 1,136,542,654
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1136542654...
Checkpoint 1136542654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.97440
Policy Entropy: 4.31398
Value Function Loss: 0.00278
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02926
Policy Update Magnitude: 1.05129
Value Function Update Magnitude: 0.78478
Collected Steps per Second: 12,902.73870
Overall Steps per Second: 7,145.68866
Timestep Collection Time: 3.87809
Timestep Consumption Time: 3.12445
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 7.00254
Cumulative Model Updates: 138,674
Cumulative Timesteps: 1,136,592,692
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.39936
Policy Entropy: 4.31530
Value Function Loss: 0.00283
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02978
Policy Update Magnitude: 1.05198
Value Function Update Magnitude: 0.77884
Collected Steps per Second: 13,038.82266
Overall Steps per Second: 7,232.10341
Timestep Collection Time: 3.83792
Timestep Consumption Time: 3.08150
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.91943
Cumulative Model Updates: 138,683
Cumulative Timesteps: 1,136,642,734
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1136642734...
Checkpoint 1136642734 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.55406
Policy Entropy: 4.31710
Value Function Loss: 0.00273
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02766
Policy Update Magnitude: 1.04432
Value Function Update Magnitude: 0.77925
Collected Steps per Second: 13,315.26609
Overall Steps per Second: 7,287.94585
Timestep Collection Time: 3.75899
Timestep Consumption Time: 3.10879
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.86778
Cumulative Model Updates: 138,692
Cumulative Timesteps: 1,136,692,786
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.82980
Policy Entropy: 4.31835
Value Function Loss: 0.00270
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02884
Policy Update Magnitude: 1.02389
Value Function Update Magnitude: 0.74274
Collected Steps per Second: 12,934.33323
Overall Steps per Second: 7,160.97941
Timestep Collection Time: 3.86785
Timestep Consumption Time: 3.11835
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.98620
Cumulative Model Updates: 138,701
Cumulative Timesteps: 1,136,742,814
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1136742814...
Checkpoint 1136742814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.52006
Policy Entropy: 4.31663
Value Function Loss: 0.00268
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 1.03102
Value Function Update Magnitude: 0.73592
Collected Steps per Second: 12,999.96403
Overall Steps per Second: 7,151.86085
Timestep Collection Time: 3.84786
Timestep Consumption Time: 3.14641
PPO Batch Consumption Time: 0.23400
Total Iteration Time: 6.99426
Cumulative Model Updates: 138,710
Cumulative Timesteps: 1,136,792,836
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.91246
Policy Entropy: 4.31881
Value Function Loss: 0.00266
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 1.03116
Value Function Update Magnitude: 0.77563
Collected Steps per Second: 13,354.22251
Overall Steps per Second: 7,277.72945
Timestep Collection Time: 3.74503
Timestep Consumption Time: 3.12689
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.87192
Cumulative Model Updates: 138,719
Cumulative Timesteps: 1,136,842,848
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1136842848...
Checkpoint 1136842848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.91494
Policy Entropy: 4.32003
Value Function Loss: 0.00267
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02932
Policy Update Magnitude: 1.03067
Value Function Update Magnitude: 0.77289
Collected Steps per Second: 13,027.59480
Overall Steps per Second: 7,203.14473
Timestep Collection Time: 3.84031
Timestep Consumption Time: 3.10527
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.94558
Cumulative Model Updates: 138,728
Cumulative Timesteps: 1,136,892,878
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36271
Policy Entropy: 4.31869
Value Function Loss: 0.00272
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 1.03501
Value Function Update Magnitude: 0.80572
Collected Steps per Second: 13,019.32706
Overall Steps per Second: 7,310.76622
Timestep Collection Time: 3.84244
Timestep Consumption Time: 3.00034
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.84278
Cumulative Model Updates: 138,737
Cumulative Timesteps: 1,136,942,904
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1136942904...
Checkpoint 1136942904 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.72473
Policy Entropy: 4.31637
Value Function Loss: 0.00272
Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02689
Policy Update Magnitude: 1.03817
Value Function Update Magnitude: 0.76587
Collected Steps per Second: 12,735.38160
Overall Steps per Second: 7,111.03042
Timestep Collection Time: 3.92670
Timestep Consumption Time: 3.10576
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 7.03245
Cumulative Model Updates: 138,746
Cumulative Timesteps: 1,136,992,912
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.69402
Policy Entropy: 4.31618
Value Function Loss: 0.00269
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02929
Policy Update Magnitude: 1.02710
Value Function Update Magnitude: 0.75290
Collected Steps per Second: 13,081.13601
Overall Steps per Second: 7,243.49453
Timestep Collection Time: 3.82230
Timestep Consumption Time: 3.08045
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.90275
Cumulative Model Updates: 138,755
Cumulative Timesteps: 1,137,042,912
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1137042912...
Checkpoint 1137042912 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.00189
Policy Entropy: 4.31712
Value Function Loss: 0.00264
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 1.00689
Value Function Update Magnitude: 0.75629
Collected Steps per Second: 12,948.40840
Overall Steps per Second: 7,267.24083
Timestep Collection Time: 3.86318
Timestep Consumption Time: 3.02004
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.88322
Cumulative Model Updates: 138,764
Cumulative Timesteps: 1,137,092,934
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.38724
Policy Entropy: 4.31961
Value Function Loss: 0.00259
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02981
Policy Update Magnitude: 0.99951
Value Function Update Magnitude: 0.73602
Collected Steps per Second: 13,025.36693
Overall Steps per Second: 7,129.66657
Timestep Collection Time: 3.83882
Timestep Consumption Time: 3.17441
PPO Batch Consumption Time: 0.22958
Total Iteration Time: 7.01323
Cumulative Model Updates: 138,773
Cumulative Timesteps: 1,137,142,936
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1137142936...
Checkpoint 1137142936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.85048
Policy Entropy: 4.31517
Value Function Loss: 0.00266
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02770
Policy Update Magnitude: 1.01235
Value Function Update Magnitude: 0.74847
Collected Steps per Second: 13,014.11922
Overall Steps per Second: 7,193.39498
Timestep Collection Time: 3.84490
Timestep Consumption Time: 3.11120
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.95610
Cumulative Model Updates: 138,782
Cumulative Timesteps: 1,137,192,974
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00786
Policy Entropy: 4.31586
Value Function Loss: 0.00268
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 1.02978
Value Function Update Magnitude: 0.76423
Collected Steps per Second: 12,838.32463
Overall Steps per Second: 7,254.37416
Timestep Collection Time: 3.89521
Timestep Consumption Time: 2.99828
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.89350
Cumulative Model Updates: 138,791
Cumulative Timesteps: 1,137,242,982
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1137242982...
Checkpoint 1137242982 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82328
Policy Entropy: 4.31558
Value Function Loss: 0.00268
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03241
Policy Update Magnitude: 1.04022
Value Function Update Magnitude: 0.76947
Collected Steps per Second: 12,908.28518
Overall Steps per Second: 7,149.07314
Timestep Collection Time: 3.87426
Timestep Consumption Time: 3.12106
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.99531
Cumulative Model Updates: 138,800
Cumulative Timesteps: 1,137,292,992
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.80019
Policy Entropy: 4.31727
Value Function Loss: 0.00281
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 1.04830
Value Function Update Magnitude: 0.75633
Collected Steps per Second: 12,998.77334
Overall Steps per Second: 7,219.68032
Timestep Collection Time: 3.84729
Timestep Consumption Time: 3.07961
PPO Batch Consumption Time: 0.22786
Total Iteration Time: 6.92690
Cumulative Model Updates: 138,809
Cumulative Timesteps: 1,137,343,002
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1137343002...
Checkpoint 1137343002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04835
Policy Entropy: 4.31626
Value Function Loss: 0.00285
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03301
Policy Update Magnitude: 1.04333
Value Function Update Magnitude: 0.74257
Collected Steps per Second: 13,345.21531
Overall Steps per Second: 7,322.75831
Timestep Collection Time: 3.74831
Timestep Consumption Time: 3.08272
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.83103
Cumulative Model Updates: 138,818
Cumulative Timesteps: 1,137,393,024
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.55638
Policy Entropy: 4.31910
Value Function Loss: 0.00297
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 1.03510
Value Function Update Magnitude: 0.75720
Collected Steps per Second: 12,697.56068
Overall Steps per Second: 7,110.50266
Timestep Collection Time: 3.94060
Timestep Consumption Time: 3.09632
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 7.03691
Cumulative Model Updates: 138,827
Cumulative Timesteps: 1,137,443,060
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1137443060...
Checkpoint 1137443060 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.23914
Policy Entropy: 4.32456
Value Function Loss: 0.00280
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03184
Policy Update Magnitude: 1.05001
Value Function Update Magnitude: 0.77178
Collected Steps per Second: 12,662.82680
Overall Steps per Second: 7,052.91080
Timestep Collection Time: 3.95109
Timestep Consumption Time: 3.14272
PPO Batch Consumption Time: 0.23856
Total Iteration Time: 7.09381
Cumulative Model Updates: 138,836
Cumulative Timesteps: 1,137,493,092
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77285
Policy Entropy: 4.32188
Value Function Loss: 0.00279
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03074
Policy Update Magnitude: 1.06121
Value Function Update Magnitude: 0.73464
Collected Steps per Second: 13,024.88054
Overall Steps per Second: 7,208.46873
Timestep Collection Time: 3.83881
Timestep Consumption Time: 3.09748
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.93629
Cumulative Model Updates: 138,845
Cumulative Timesteps: 1,137,543,092
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1137543092...
Checkpoint 1137543092 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.34219
Policy Entropy: 4.31710
Value Function Loss: 0.00279
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 1.05826
Value Function Update Magnitude: 0.71048
Collected Steps per Second: 12,926.19439
Overall Steps per Second: 7,210.65866
Timestep Collection Time: 3.86997
Timestep Consumption Time: 3.06754
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.93751
Cumulative Model Updates: 138,854
Cumulative Timesteps: 1,137,593,116
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65048
Policy Entropy: 4.31661
Value Function Loss: 0.00287
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03092
Policy Update Magnitude: 1.05152
Value Function Update Magnitude: 0.72201
Collected Steps per Second: 12,893.59437
Overall Steps per Second: 7,247.44975
Timestep Collection Time: 3.87789
Timestep Consumption Time: 3.02108
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.89898
Cumulative Model Updates: 138,863
Cumulative Timesteps: 1,137,643,116
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1137643116...
Checkpoint 1137643116 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.34922
Policy Entropy: 4.31711
Value Function Loss: 0.00278
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03016
Policy Update Magnitude: 1.04185
Value Function Update Magnitude: 0.72251
Collected Steps per Second: 12,929.98775
Overall Steps per Second: 7,155.73743
Timestep Collection Time: 3.86837
Timestep Consumption Time: 3.12154
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.98992
Cumulative Model Updates: 138,872
Cumulative Timesteps: 1,137,693,134
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.05024
Policy Entropy: 4.32043
Value Function Loss: 0.00278
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02987
Policy Update Magnitude: 1.02586
Value Function Update Magnitude: 0.72184
Collected Steps per Second: 12,909.11947
Overall Steps per Second: 7,179.56539
Timestep Collection Time: 3.87447
Timestep Consumption Time: 3.09197
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.96644
Cumulative Model Updates: 138,881
Cumulative Timesteps: 1,137,743,150
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1137743150...
Checkpoint 1137743150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.49120
Policy Entropy: 4.31938
Value Function Loss: 0.00271
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03171
Policy Update Magnitude: 1.03719
Value Function Update Magnitude: 0.73913
Collected Steps per Second: 13,083.12213
Overall Steps per Second: 7,211.20370
Timestep Collection Time: 3.82340
Timestep Consumption Time: 3.11331
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.93671
Cumulative Model Updates: 138,890
Cumulative Timesteps: 1,137,793,172
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.17682
Policy Entropy: 4.31664
Value Function Loss: 0.00273
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03198
Policy Update Magnitude: 1.05339
Value Function Update Magnitude: 0.78302
Collected Steps per Second: 12,926.28799
Overall Steps per Second: 7,061.58645
Timestep Collection Time: 3.87010
Timestep Consumption Time: 3.21415
PPO Batch Consumption Time: 0.23611
Total Iteration Time: 7.08424
Cumulative Model Updates: 138,899
Cumulative Timesteps: 1,137,843,198
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1137843198...
Checkpoint 1137843198 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07495
Policy Entropy: 4.31405
Value Function Loss: 0.00273
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 1.05456
Value Function Update Magnitude: 0.77174
Collected Steps per Second: 12,854.70583
Overall Steps per Second: 7,180.92669
Timestep Collection Time: 3.89227
Timestep Consumption Time: 3.07535
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.96762
Cumulative Model Updates: 138,908
Cumulative Timesteps: 1,137,893,232
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36151
Policy Entropy: 4.31084
Value Function Loss: 0.00280
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03097
Policy Update Magnitude: 1.04402
Value Function Update Magnitude: 0.73742
Collected Steps per Second: 13,351.79140
Overall Steps per Second: 7,284.70055
Timestep Collection Time: 3.74571
Timestep Consumption Time: 3.11963
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.86535
Cumulative Model Updates: 138,917
Cumulative Timesteps: 1,137,943,244
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1137943244...
Checkpoint 1137943244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36468
Policy Entropy: 4.31764
Value Function Loss: 0.00267
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03053
Policy Update Magnitude: 1.04560
Value Function Update Magnitude: 0.71681
Collected Steps per Second: 12,950.79101
Overall Steps per Second: 7,153.20230
Timestep Collection Time: 3.86108
Timestep Consumption Time: 3.12936
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.99044
Cumulative Model Updates: 138,926
Cumulative Timesteps: 1,137,993,248
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.72814
Policy Entropy: 4.32115
Value Function Loss: 0.00263
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 1.01925
Value Function Update Magnitude: 0.71122
Collected Steps per Second: 13,147.95073
Overall Steps per Second: 7,238.69023
Timestep Collection Time: 3.80592
Timestep Consumption Time: 3.10694
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.91285
Cumulative Model Updates: 138,935
Cumulative Timesteps: 1,138,043,288
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1138043288...
Checkpoint 1138043288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65440
Policy Entropy: 4.32280
Value Function Loss: 0.00260
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02825
Policy Update Magnitude: 1.01244
Value Function Update Magnitude: 0.73100
Collected Steps per Second: 13,306.02787
Overall Steps per Second: 7,272.67620
Timestep Collection Time: 3.75920
Timestep Consumption Time: 3.11860
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.87780
Cumulative Model Updates: 138,944
Cumulative Timesteps: 1,138,093,308
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.34421
Policy Entropy: 4.31910
Value Function Loss: 0.00269
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02964
Policy Update Magnitude: 1.02982
Value Function Update Magnitude: 0.73431
Collected Steps per Second: 13,091.97394
Overall Steps per Second: 7,209.51213
Timestep Collection Time: 3.82127
Timestep Consumption Time: 3.11789
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.93917
Cumulative Model Updates: 138,953
Cumulative Timesteps: 1,138,143,336
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1138143336...
Checkpoint 1138143336 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79889
Policy Entropy: 4.31801
Value Function Loss: 0.00295
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03102
Policy Update Magnitude: 1.04965
Value Function Update Magnitude: 0.76967
Collected Steps per Second: 12,851.49026
Overall Steps per Second: 7,129.79090
Timestep Collection Time: 3.89075
Timestep Consumption Time: 3.12235
PPO Batch Consumption Time: 0.22997
Total Iteration Time: 7.01311
Cumulative Model Updates: 138,962
Cumulative Timesteps: 1,138,193,338
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.10730
Policy Entropy: 4.31833
Value Function Loss: 0.00285
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02991
Policy Update Magnitude: 1.05238
Value Function Update Magnitude: 0.79275
Collected Steps per Second: 13,340.82947
Overall Steps per Second: 7,294.16458
Timestep Collection Time: 3.74984
Timestep Consumption Time: 3.10852
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.85836
Cumulative Model Updates: 138,971
Cumulative Timesteps: 1,138,243,364
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1138243364...
Checkpoint 1138243364 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.88707
Policy Entropy: 4.31888
Value Function Loss: 0.00280
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03053
Policy Update Magnitude: 1.03997
Value Function Update Magnitude: 0.78157
Collected Steps per Second: 12,945.49546
Overall Steps per Second: 7,161.16280
Timestep Collection Time: 3.86343
Timestep Consumption Time: 3.12063
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.98406
Cumulative Model Updates: 138,980
Cumulative Timesteps: 1,138,293,378
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89274
Policy Entropy: 4.31593
Value Function Loss: 0.00270
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02974
Policy Update Magnitude: 1.00941
Value Function Update Magnitude: 0.71513
Collected Steps per Second: 12,984.40647
Overall Steps per Second: 7,297.62675
Timestep Collection Time: 3.85447
Timestep Consumption Time: 3.00365
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.85812
Cumulative Model Updates: 138,989
Cumulative Timesteps: 1,138,343,426
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1138343426...
Checkpoint 1138343426 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.17577
Policy Entropy: 4.31712
Value Function Loss: 0.00272
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03010
Policy Update Magnitude: 1.00763
Value Function Update Magnitude: 0.69456
Collected Steps per Second: 13,020.11706
Overall Steps per Second: 7,182.10628
Timestep Collection Time: 3.84298
Timestep Consumption Time: 3.12378
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.96676
Cumulative Model Updates: 138,998
Cumulative Timesteps: 1,138,393,462
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06885
Policy Entropy: 4.31936
Value Function Loss: 0.00276
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02753
Policy Update Magnitude: 1.00660
Value Function Update Magnitude: 0.72366
Collected Steps per Second: 12,985.55805
Overall Steps per Second: 7,210.30820
Timestep Collection Time: 3.85074
Timestep Consumption Time: 3.08433
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.93507
Cumulative Model Updates: 139,007
Cumulative Timesteps: 1,138,443,466
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1138443466...
Checkpoint 1138443466 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.29618
Policy Entropy: 4.32686
Value Function Loss: 0.00266
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 1.01304
Value Function Update Magnitude: 0.75638
Collected Steps per Second: 12,878.56986
Overall Steps per Second: 7,276.48285
Timestep Collection Time: 3.88552
Timestep Consumption Time: 2.99142
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.87695
Cumulative Model Updates: 139,016
Cumulative Timesteps: 1,138,493,506
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06530
Policy Entropy: 4.32329
Value Function Loss: 0.00263
Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 1.00453
Value Function Update Magnitude: 0.74452
Collected Steps per Second: 13,001.36629
Overall Steps per Second: 7,126.80397
Timestep Collection Time: 3.84852
Timestep Consumption Time: 3.17230
PPO Batch Consumption Time: 0.23069
Total Iteration Time: 7.02082
Cumulative Model Updates: 139,025
Cumulative Timesteps: 1,138,543,542
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1138543542...
Checkpoint 1138543542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.30314
Policy Entropy: 4.32108
Value Function Loss: 0.00260
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 1.00164
Value Function Update Magnitude: 0.72857
Collected Steps per Second: 12,899.92094
Overall Steps per Second: 7,182.27511
Timestep Collection Time: 3.87894
Timestep Consumption Time: 3.08793
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.96687
Cumulative Model Updates: 139,034
Cumulative Timesteps: 1,138,593,580
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06145
Policy Entropy: 4.31251
Value Function Loss: 0.00275
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03069
Policy Update Magnitude: 1.01129
Value Function Update Magnitude: 0.70809
Collected Steps per Second: 12,882.79961
Overall Steps per Second: 7,249.65093
Timestep Collection Time: 3.88363
Timestep Consumption Time: 3.01767
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.90130
Cumulative Model Updates: 139,043
Cumulative Timesteps: 1,138,643,612
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1138643612...
Checkpoint 1138643612 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.67923
Policy Entropy: 4.31509
Value Function Loss: 0.00272
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 1.01631
Value Function Update Magnitude: 0.70652
Collected Steps per Second: 12,995.70522
Overall Steps per Second: 7,168.36743
Timestep Collection Time: 3.84804
Timestep Consumption Time: 3.12816
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.97620
Cumulative Model Updates: 139,052
Cumulative Timesteps: 1,138,693,620
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.87970
Policy Entropy: 4.31494
Value Function Loss: 0.00279
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 1.01242
Value Function Update Magnitude: 0.72105
Collected Steps per Second: 12,890.13314
Overall Steps per Second: 7,178.41040
Timestep Collection Time: 3.87925
Timestep Consumption Time: 3.08664
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.96589
Cumulative Model Updates: 139,061
Cumulative Timesteps: 1,138,743,624
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1138743624...
Checkpoint 1138743624 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69903
Policy Entropy: 4.32287
Value Function Loss: 0.00267
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02766
Policy Update Magnitude: 1.00667
Value Function Update Magnitude: 0.76531
Collected Steps per Second: 13,210.16037
Overall Steps per Second: 7,259.51538
Timestep Collection Time: 3.78557
Timestep Consumption Time: 3.10304
PPO Batch Consumption Time: 0.22782
Total Iteration Time: 6.88861
Cumulative Model Updates: 139,070
Cumulative Timesteps: 1,138,793,632
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.45515
Policy Entropy: 4.32300
Value Function Loss: 0.00270
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 1.00476
Value Function Update Magnitude: 0.76536
Collected Steps per Second: 12,965.03598
Overall Steps per Second: 7,154.98891
Timestep Collection Time: 3.85822
Timestep Consumption Time: 3.13298
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.99121
Cumulative Model Updates: 139,079
Cumulative Timesteps: 1,138,843,654
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1138843654...
Checkpoint 1138843654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.29093
Policy Entropy: 4.32241
Value Function Loss: 0.00265
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 1.00070
Value Function Update Magnitude: 0.76281
Collected Steps per Second: 12,918.99500
Overall Steps per Second: 7,155.90860
Timestep Collection Time: 3.87321
Timestep Consumption Time: 3.11933
PPO Batch Consumption Time: 0.22963
Total Iteration Time: 6.99254
Cumulative Model Updates: 139,088
Cumulative Timesteps: 1,138,893,692
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.17675
Policy Entropy: 4.31998
Value Function Loss: 0.00270
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 1.00877
Value Function Update Magnitude: 0.76125
Collected Steps per Second: 13,185.32137
Overall Steps per Second: 7,253.69988
Timestep Collection Time: 3.79270
Timestep Consumption Time: 3.10143
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.89414
Cumulative Model Updates: 139,097
Cumulative Timesteps: 1,138,943,700
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1138943700...
Checkpoint 1138943700 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.15377
Policy Entropy: 4.31628
Value Function Loss: 0.00284
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03068
Policy Update Magnitude: 1.02127
Value Function Update Magnitude: 0.76632
Collected Steps per Second: 12,977.06369
Overall Steps per Second: 7,165.24236
Timestep Collection Time: 3.85526
Timestep Consumption Time: 3.12705
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.98232
Cumulative Model Updates: 139,106
Cumulative Timesteps: 1,138,993,730
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.32158
Policy Entropy: 4.31924
Value Function Loss: 0.00293
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03283
Policy Update Magnitude: 1.03565
Value Function Update Magnitude: 0.74674
Collected Steps per Second: 12,874.12847
Overall Steps per Second: 7,263.14203
Timestep Collection Time: 3.88671
Timestep Consumption Time: 3.00260
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.88930
Cumulative Model Updates: 139,115
Cumulative Timesteps: 1,139,043,768
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1139043768...
Checkpoint 1139043768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.21464
Policy Entropy: 4.31770
Value Function Loss: 0.00296
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 1.01958
Value Function Update Magnitude: 0.74872
Collected Steps per Second: 12,971.84819
Overall Steps per Second: 7,185.84257
Timestep Collection Time: 3.85651
Timestep Consumption Time: 3.10524
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.96174
Cumulative Model Updates: 139,124
Cumulative Timesteps: 1,139,093,794
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03116
Policy Entropy: 4.31902
Value Function Loss: 0.00298
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03084
Policy Update Magnitude: 1.03471
Value Function Update Magnitude: 0.75307
Collected Steps per Second: 12,901.79535
Overall Steps per Second: 7,196.60388
Timestep Collection Time: 3.87605
Timestep Consumption Time: 3.07278
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.94883
Cumulative Model Updates: 139,133
Cumulative Timesteps: 1,139,143,802
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1139143802...
Checkpoint 1139143802 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76029
Policy Entropy: 4.31365
Value Function Loss: 0.00301
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03172
Policy Update Magnitude: 1.03718
Value Function Update Magnitude: 0.74853
Collected Steps per Second: 12,964.60462
Overall Steps per Second: 7,288.69227
Timestep Collection Time: 3.85959
Timestep Consumption Time: 3.00557
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.86515
Cumulative Model Updates: 139,142
Cumulative Timesteps: 1,139,193,840
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51534
Policy Entropy: 4.31333
Value Function Loss: 0.00303
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 1.04511
Value Function Update Magnitude: 0.75608
Collected Steps per Second: 13,066.43844
Overall Steps per Second: 7,067.83670
Timestep Collection Time: 3.82935
Timestep Consumption Time: 3.25004
PPO Batch Consumption Time: 0.23851
Total Iteration Time: 7.07939
Cumulative Model Updates: 139,151
Cumulative Timesteps: 1,139,243,876
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1139243876...
Checkpoint 1139243876 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.90050
Policy Entropy: 4.31559
Value Function Loss: 0.00291
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03324
Policy Update Magnitude: 1.03078
Value Function Update Magnitude: 0.74193
Collected Steps per Second: 12,927.04193
Overall Steps per Second: 7,203.18388
Timestep Collection Time: 3.87003
Timestep Consumption Time: 3.07524
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.94526
Cumulative Model Updates: 139,160
Cumulative Timesteps: 1,139,293,904
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.67009
Policy Entropy: 4.31831
Value Function Loss: 0.00284
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03193
Policy Update Magnitude: 1.02634
Value Function Update Magnitude: 0.77751
Collected Steps per Second: 13,210.78818
Overall Steps per Second: 7,245.49878
Timestep Collection Time: 3.78539
Timestep Consumption Time: 3.11655
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.90194
Cumulative Model Updates: 139,169
Cumulative Timesteps: 1,139,343,912
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1139343912...
Checkpoint 1139343912 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.48001
Policy Entropy: 4.31962
Value Function Loss: 0.00273
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03160
Policy Update Magnitude: 1.00560
Value Function Update Magnitude: 0.77479
Collected Steps per Second: 12,955.66224
Overall Steps per Second: 7,171.47437
Timestep Collection Time: 3.86225
Timestep Consumption Time: 3.11512
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.97737
Cumulative Model Updates: 139,178
Cumulative Timesteps: 1,139,393,950
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.60162
Policy Entropy: 4.31976
Value Function Loss: 0.00282
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 1.01622
Value Function Update Magnitude: 0.75973
Collected Steps per Second: 12,945.79232
Overall Steps per Second: 7,206.57292
Timestep Collection Time: 3.86349
Timestep Consumption Time: 3.07684
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.94033
Cumulative Model Updates: 139,187
Cumulative Timesteps: 1,139,443,966
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1139443966...
Checkpoint 1139443966 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56648
Policy Entropy: 4.31337
Value Function Loss: 0.00289
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 1.04474
Value Function Update Magnitude: 0.76685
Collected Steps per Second: 13,237.54838
Overall Steps per Second: 7,260.36360
Timestep Collection Time: 3.77970
Timestep Consumption Time: 3.11169
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.89139
Cumulative Model Updates: 139,196
Cumulative Timesteps: 1,139,494,000
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.62311
Policy Entropy: 4.31625
Value Function Loss: 0.00286
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03504
Policy Update Magnitude: 1.03179
Value Function Update Magnitude: 0.75032
Collected Steps per Second: 13,036.23931
Overall Steps per Second: 7,183.70876
Timestep Collection Time: 3.83577
Timestep Consumption Time: 3.12498
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.96075
Cumulative Model Updates: 139,205
Cumulative Timesteps: 1,139,544,004
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1139544004...
Checkpoint 1139544004 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.13664
Policy Entropy: 4.31740
Value Function Loss: 0.00267
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 1.00740
Value Function Update Magnitude: 0.72996
Collected Steps per Second: 12,738.64069
Overall Steps per Second: 7,079.76215
Timestep Collection Time: 3.92679
Timestep Consumption Time: 3.13870
PPO Batch Consumption Time: 0.23009
Total Iteration Time: 7.06549
Cumulative Model Updates: 139,214
Cumulative Timesteps: 1,139,594,026
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.35267
Policy Entropy: 4.31908
Value Function Loss: 0.00268
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03132
Policy Update Magnitude: 1.00719
Value Function Update Magnitude: 0.73685
Collected Steps per Second: 13,108.67746
Overall Steps per Second: 7,203.78539
Timestep Collection Time: 3.81747
Timestep Consumption Time: 3.12915
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.94663
Cumulative Model Updates: 139,223
Cumulative Timesteps: 1,139,644,068
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1139644068...
Checkpoint 1139644068 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05217
Policy Entropy: 4.31685
Value Function Loss: 0.00273
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03085
Policy Update Magnitude: 1.00827
Value Function Update Magnitude: 0.76617
Collected Steps per Second: 12,903.76503
Overall Steps per Second: 7,148.35324
Timestep Collection Time: 3.87654
Timestep Consumption Time: 3.12115
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.99770
Cumulative Model Updates: 139,232
Cumulative Timesteps: 1,139,694,090
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.24748
Policy Entropy: 4.31135
Value Function Loss: 0.00278
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03004
Policy Update Magnitude: 1.00415
Value Function Update Magnitude: 0.77634
Collected Steps per Second: 12,912.07095
Overall Steps per Second: 7,275.15865
Timestep Collection Time: 3.87513
Timestep Consumption Time: 3.00252
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.87765
Cumulative Model Updates: 139,241
Cumulative Timesteps: 1,139,744,126
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1139744126...
Checkpoint 1139744126 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.16003
Policy Entropy: 4.31298
Value Function Loss: 0.00283
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03212
Policy Update Magnitude: 1.01689
Value Function Update Magnitude: 0.76001
Collected Steps per Second: 13,066.06539
Overall Steps per Second: 7,197.17272
Timestep Collection Time: 3.82962
Timestep Consumption Time: 3.12284
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.95245
Cumulative Model Updates: 139,250
Cumulative Timesteps: 1,139,794,164
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51703
Policy Entropy: 4.31533
Value Function Loss: 0.00271
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03262
Policy Update Magnitude: 0.99811
Value Function Update Magnitude: 0.77267
Collected Steps per Second: 12,852.14032
Overall Steps per Second: 7,187.32097
Timestep Collection Time: 3.89243
Timestep Consumption Time: 3.06789
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.96031
Cumulative Model Updates: 139,259
Cumulative Timesteps: 1,139,844,190
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1139844190...
Checkpoint 1139844190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25753
Policy Entropy: 4.31906
Value Function Loss: 0.00277
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03118
Policy Update Magnitude: 0.99295
Value Function Update Magnitude: 0.75066
Collected Steps per Second: 12,736.87114
Overall Steps per Second: 7,148.57691
Timestep Collection Time: 3.92828
Timestep Consumption Time: 3.07088
PPO Batch Consumption Time: 0.23277
Total Iteration Time: 6.99916
Cumulative Model Updates: 139,268
Cumulative Timesteps: 1,139,894,224
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35932
Policy Entropy: 4.31968
Value Function Loss: 0.00280
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03151
Policy Update Magnitude: 1.00955
Value Function Update Magnitude: 0.76052
Collected Steps per Second: 12,860.60758
Overall Steps per Second: 7,079.61394
Timestep Collection Time: 3.88784
Timestep Consumption Time: 3.17469
PPO Batch Consumption Time: 0.23240
Total Iteration Time: 7.06253
Cumulative Model Updates: 139,277
Cumulative Timesteps: 1,139,944,224
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1139944224...
Checkpoint 1139944224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.71901
Policy Entropy: 4.31980
Value Function Loss: 0.00278
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 1.00519
Value Function Update Magnitude: 0.78121
Collected Steps per Second: 13,098.58205
Overall Steps per Second: 7,254.74941
Timestep Collection Time: 3.81812
Timestep Consumption Time: 3.07557
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.89369
Cumulative Model Updates: 139,286
Cumulative Timesteps: 1,139,994,236
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.96874
Policy Entropy: 4.32214
Value Function Loss: 0.00267
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 1.01405
Value Function Update Magnitude: 0.81607
Collected Steps per Second: 12,991.58108
Overall Steps per Second: 7,111.20460
Timestep Collection Time: 3.85111
Timestep Consumption Time: 3.18455
PPO Batch Consumption Time: 0.23168
Total Iteration Time: 7.03566
Cumulative Model Updates: 139,295
Cumulative Timesteps: 1,140,044,268
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1140044268...
Checkpoint 1140044268 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97371
Policy Entropy: 4.32047
Value Function Loss: 0.00270
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03000
Policy Update Magnitude: 1.02776
Value Function Update Magnitude: 0.82369
Collected Steps per Second: 11,961.20461
Overall Steps per Second: 6,824.87122
Timestep Collection Time: 4.18068
Timestep Consumption Time: 3.14634
PPO Batch Consumption Time: 0.22941
Total Iteration Time: 7.32702
Cumulative Model Updates: 139,304
Cumulative Timesteps: 1,140,094,274
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42736
Policy Entropy: 4.31648
Value Function Loss: 0.00285
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03243
Policy Update Magnitude: 1.04235
Value Function Update Magnitude: 0.82503
Collected Steps per Second: 12,795.64505
Overall Steps per Second: 7,240.88724
Timestep Collection Time: 3.90867
Timestep Consumption Time: 2.99849
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.90716
Cumulative Model Updates: 139,313
Cumulative Timesteps: 1,140,144,288
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1140144288...
Checkpoint 1140144288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.30119
Policy Entropy: 4.31607
Value Function Loss: 0.00284
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03301
Policy Update Magnitude: 1.03811
Value Function Update Magnitude: 0.82454
Collected Steps per Second: 12,924.36289
Overall Steps per Second: 7,152.92158
Timestep Collection Time: 3.87315
Timestep Consumption Time: 3.12511
PPO Batch Consumption Time: 0.23184
Total Iteration Time: 6.99826
Cumulative Model Updates: 139,322
Cumulative Timesteps: 1,140,194,346
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.05512
Policy Entropy: 4.31660
Value Function Loss: 0.00277
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02955
Policy Update Magnitude: 1.02777
Value Function Update Magnitude: 0.78712
Collected Steps per Second: 12,578.03836
Overall Steps per Second: 7,065.50325
Timestep Collection Time: 3.97820
Timestep Consumption Time: 3.10381
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 7.08201
Cumulative Model Updates: 139,331
Cumulative Timesteps: 1,140,244,384
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1140244384...
Checkpoint 1140244384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86737
Policy Entropy: 4.32102
Value Function Loss: 0.00268
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02994
Policy Update Magnitude: 1.02402
Value Function Update Magnitude: 0.74477
Collected Steps per Second: 12,863.93353
Overall Steps per Second: 7,186.10867
Timestep Collection Time: 3.88979
Timestep Consumption Time: 3.07337
PPO Batch Consumption Time: 0.23030
Total Iteration Time: 6.96316
Cumulative Model Updates: 139,340
Cumulative Timesteps: 1,140,294,422
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.22021
Policy Entropy: 4.31817
Value Function Loss: 0.00277
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02972
Policy Update Magnitude: 1.02062
Value Function Update Magnitude: 0.73934
Collected Steps per Second: 12,948.90593
Overall Steps per Second: 7,161.62141
Timestep Collection Time: 3.86226
Timestep Consumption Time: 3.12108
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.98333
Cumulative Model Updates: 139,349
Cumulative Timesteps: 1,140,344,434
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1140344434...
Checkpoint 1140344434 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.92011
Policy Entropy: 4.31546
Value Function Loss: 0.00284
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 1.03325
Value Function Update Magnitude: 0.73092
Collected Steps per Second: 12,893.03191
Overall Steps per Second: 7,190.33680
Timestep Collection Time: 3.87961
Timestep Consumption Time: 3.07694
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.95656
Cumulative Model Updates: 139,358
Cumulative Timesteps: 1,140,394,454
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64164
Policy Entropy: 4.30912
Value Function Loss: 0.00288
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03228
Policy Update Magnitude: 1.04825
Value Function Update Magnitude: 0.71551
Collected Steps per Second: 12,897.40410
Overall Steps per Second: 7,251.91890
Timestep Collection Time: 3.87892
Timestep Consumption Time: 3.01967
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.89859
Cumulative Model Updates: 139,367
Cumulative Timesteps: 1,140,444,482
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1140444482...
Checkpoint 1140444482 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.05706
Policy Entropy: 4.30647
Value Function Loss: 0.00284
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 1.03833
Value Function Update Magnitude: 0.72692
Collected Steps per Second: 12,835.30331
Overall Steps per Second: 7,130.93163
Timestep Collection Time: 3.89769
Timestep Consumption Time: 3.11795
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 7.01563
Cumulative Model Updates: 139,376
Cumulative Timesteps: 1,140,494,510
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80585
Policy Entropy: 4.31134
Value Function Loss: 0.00285
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03092
Policy Update Magnitude: 1.03740
Value Function Update Magnitude: 0.74495
Collected Steps per Second: 12,960.75514
Overall Steps per Second: 7,213.61888
Timestep Collection Time: 3.86027
Timestep Consumption Time: 3.07550
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.93577
Cumulative Model Updates: 139,385
Cumulative Timesteps: 1,140,544,542
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1140544542...
Checkpoint 1140544542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.33003
Policy Entropy: 4.31414
Value Function Loss: 0.00281
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03088
Policy Update Magnitude: 1.04359
Value Function Update Magnitude: 0.72695
Collected Steps per Second: 13,239.64383
Overall Steps per Second: 7,264.18747
Timestep Collection Time: 3.77865
Timestep Consumption Time: 3.10829
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.88694
Cumulative Model Updates: 139,394
Cumulative Timesteps: 1,140,594,570
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13765
Policy Entropy: 4.31756
Value Function Loss: 0.00288
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03247
Policy Update Magnitude: 1.05005
Value Function Update Magnitude: 0.71838
Collected Steps per Second: 12,930.11187
Overall Steps per Second: 7,004.39879
Timestep Collection Time: 3.86741
Timestep Consumption Time: 3.27182
PPO Batch Consumption Time: 0.24123
Total Iteration Time: 7.13923
Cumulative Model Updates: 139,403
Cumulative Timesteps: 1,140,644,576
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1140644576...
Checkpoint 1140644576 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.90105
Policy Entropy: 4.31369
Value Function Loss: 0.00287
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 1.05130
Value Function Update Magnitude: 0.71412
Collected Steps per Second: 12,990.18596
Overall Steps per Second: 7,204.05198
Timestep Collection Time: 3.85275
Timestep Consumption Time: 3.09445
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.94720
Cumulative Model Updates: 139,412
Cumulative Timesteps: 1,140,694,624
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.25399
Policy Entropy: 4.31360
Value Function Loss: 0.00280
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03791
Policy Update Magnitude: 1.04983
Value Function Update Magnitude: 0.75248
Collected Steps per Second: 13,242.67963
Overall Steps per Second: 7,262.16149
Timestep Collection Time: 3.77854
Timestep Consumption Time: 3.11169
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.89024
Cumulative Model Updates: 139,421
Cumulative Timesteps: 1,140,744,662
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1140744662...
Checkpoint 1140744662 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71206
Policy Entropy: 4.30947
Value Function Loss: 0.00279
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03192
Policy Update Magnitude: 1.03005
Value Function Update Magnitude: 0.76109
Collected Steps per Second: 12,993.51368
Overall Steps per Second: 7,152.99401
Timestep Collection Time: 3.85054
Timestep Consumption Time: 3.14402
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.99455
Cumulative Model Updates: 139,430
Cumulative Timesteps: 1,140,794,694
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87161
Policy Entropy: 4.30767
Value Function Loss: 0.00285
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03076
Policy Update Magnitude: 1.03223
Value Function Update Magnitude: 0.76568
Collected Steps per Second: 12,941.79235
Overall Steps per Second: 7,271.15084
Timestep Collection Time: 3.86670
Timestep Consumption Time: 3.01557
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.88227
Cumulative Model Updates: 139,439
Cumulative Timesteps: 1,140,844,736
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1140844736...
Checkpoint 1140844736 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.40763
Policy Entropy: 4.30469
Value Function Loss: 0.00293
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03202
Policy Update Magnitude: 1.04612
Value Function Update Magnitude: 0.76636
Collected Steps per Second: 12,937.16991
Overall Steps per Second: 7,171.18403
Timestep Collection Time: 3.86499
Timestep Consumption Time: 3.10764
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.97263
Cumulative Model Updates: 139,448
Cumulative Timesteps: 1,140,894,738
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06758
Policy Entropy: 4.30660
Value Function Loss: 0.00298
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03503
Policy Update Magnitude: 1.07003
Value Function Update Magnitude: 0.78147
Collected Steps per Second: 12,888.97210
Overall Steps per Second: 7,192.69785
Timestep Collection Time: 3.88146
Timestep Consumption Time: 3.07393
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.95539
Cumulative Model Updates: 139,457
Cumulative Timesteps: 1,140,944,766
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1140944766...
Checkpoint 1140944766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.82062
Policy Entropy: 4.30870
Value Function Loss: 0.00271
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03514
Policy Update Magnitude: 1.06119
Value Function Update Magnitude: 0.78169
Collected Steps per Second: 12,868.51381
Overall Steps per Second: 7,213.59906
Timestep Collection Time: 3.88747
Timestep Consumption Time: 3.04748
PPO Batch Consumption Time: 0.22949
Total Iteration Time: 6.93496
Cumulative Model Updates: 139,466
Cumulative Timesteps: 1,140,994,792
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77170
Policy Entropy: 4.31219
Value Function Loss: 0.00267
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 1.02881
Value Function Update Magnitude: 0.74703
Collected Steps per Second: 13,025.67232
Overall Steps per Second: 7,186.73334
Timestep Collection Time: 3.84088
Timestep Consumption Time: 3.12056
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.96144
Cumulative Model Updates: 139,475
Cumulative Timesteps: 1,141,044,822
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1141044822...
Checkpoint 1141044822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.92237
Policy Entropy: 4.31402
Value Function Loss: 0.00277
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 1.04691
Value Function Update Magnitude: 0.73896
Collected Steps per Second: 12,911.21148
Overall Steps per Second: 7,209.47356
Timestep Collection Time: 3.87694
Timestep Consumption Time: 3.06615
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.94309
Cumulative Model Updates: 139,484
Cumulative Timesteps: 1,141,094,878
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.65093
Policy Entropy: 4.31153
Value Function Loss: 0.00292
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 1.07428
Value Function Update Magnitude: 0.77222
Collected Steps per Second: 12,776.73266
Overall Steps per Second: 7,214.70726
Timestep Collection Time: 3.91446
Timestep Consumption Time: 3.01777
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.93223
Cumulative Model Updates: 139,493
Cumulative Timesteps: 1,141,144,892
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1141144892...
Checkpoint 1141144892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93770
Policy Entropy: 4.31457
Value Function Loss: 0.00278
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03440
Policy Update Magnitude: 1.05494
Value Function Update Magnitude: 0.77056
Collected Steps per Second: 12,928.31340
Overall Steps per Second: 7,166.09246
Timestep Collection Time: 3.86794
Timestep Consumption Time: 3.11020
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.97814
Cumulative Model Updates: 139,502
Cumulative Timesteps: 1,141,194,898
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.43769
Policy Entropy: 4.31545
Value Function Loss: 0.00271
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03303
Policy Update Magnitude: 1.03660
Value Function Update Magnitude: 0.74375
Collected Steps per Second: 12,915.06167
Overall Steps per Second: 7,266.63480
Timestep Collection Time: 3.87439
Timestep Consumption Time: 3.01160
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.88599
Cumulative Model Updates: 139,511
Cumulative Timesteps: 1,141,244,936
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1141244936...
Checkpoint 1141244936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.39041
Policy Entropy: 4.31659
Value Function Loss: 0.00268
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03011
Policy Update Magnitude: 1.02977
Value Function Update Magnitude: 0.70459
Collected Steps per Second: 12,887.27281
Overall Steps per Second: 7,144.71883
Timestep Collection Time: 3.88197
Timestep Consumption Time: 3.12013
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 7.00209
Cumulative Model Updates: 139,520
Cumulative Timesteps: 1,141,294,964
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.43331
Policy Entropy: 4.31693
Value Function Loss: 0.00269
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 1.03424
Value Function Update Magnitude: 0.70969
Collected Steps per Second: 13,071.76356
Overall Steps per Second: 7,139.80263
Timestep Collection Time: 3.82657
Timestep Consumption Time: 3.17923
PPO Batch Consumption Time: 0.23347
Total Iteration Time: 7.00580
Cumulative Model Updates: 139,529
Cumulative Timesteps: 1,141,344,984
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1141344984...
Checkpoint 1141344984 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.31420
Policy Entropy: 4.31493
Value Function Loss: 0.00281
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03078
Policy Update Magnitude: 1.03066
Value Function Update Magnitude: 0.72273
Collected Steps per Second: 13,012.06558
Overall Steps per Second: 7,295.59635
Timestep Collection Time: 3.84443
Timestep Consumption Time: 3.01231
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.85674
Cumulative Model Updates: 139,538
Cumulative Timesteps: 1,141,395,008
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.20078
Policy Entropy: 4.31815
Value Function Loss: 0.00277
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 1.03494
Value Function Update Magnitude: 0.74499
Collected Steps per Second: 13,032.51270
Overall Steps per Second: 7,191.44198
Timestep Collection Time: 3.83779
Timestep Consumption Time: 3.11715
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.95493
Cumulative Model Updates: 139,547
Cumulative Timesteps: 1,141,445,024
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1141445024...
Checkpoint 1141445024 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79317
Policy Entropy: 4.31256
Value Function Loss: 0.00285
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03435
Policy Update Magnitude: 1.02252
Value Function Update Magnitude: 0.75904
Collected Steps per Second: 12,917.86946
Overall Steps per Second: 7,185.14866
Timestep Collection Time: 3.87370
Timestep Consumption Time: 3.09066
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.96437
Cumulative Model Updates: 139,556
Cumulative Timesteps: 1,141,495,064
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.94830
Policy Entropy: 4.31513
Value Function Loss: 0.00280
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03106
Policy Update Magnitude: 1.02575
Value Function Update Magnitude: 0.74370
Collected Steps per Second: 13,051.04685
Overall Steps per Second: 7,316.38133
Timestep Collection Time: 3.83111
Timestep Consumption Time: 3.00287
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.83398
Cumulative Model Updates: 139,565
Cumulative Timesteps: 1,141,545,064
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1141545064...
Checkpoint 1141545064 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05764
Policy Entropy: 4.31540
Value Function Loss: 0.00266
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 1.01642
Value Function Update Magnitude: 0.70707
Collected Steps per Second: 12,908.93600
Overall Steps per Second: 7,154.59289
Timestep Collection Time: 3.87468
Timestep Consumption Time: 3.11635
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.99103
Cumulative Model Updates: 139,574
Cumulative Timesteps: 1,141,595,082
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.63650
Policy Entropy: 4.31684
Value Function Loss: 0.00262
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03250
Policy Update Magnitude: 1.00147
Value Function Update Magnitude: 0.70009
Collected Steps per Second: 13,041.81829
Overall Steps per Second: 7,222.33134
Timestep Collection Time: 3.83689
Timestep Consumption Time: 3.09162
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.92851
Cumulative Model Updates: 139,583
Cumulative Timesteps: 1,141,645,122
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1141645122...
Checkpoint 1141645122 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56270
Policy Entropy: 4.31731
Value Function Loss: 0.00257
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 0.98485
Value Function Update Magnitude: 0.70103
Collected Steps per Second: 13,164.93614
Overall Steps per Second: 7,203.58424
Timestep Collection Time: 3.79933
Timestep Consumption Time: 3.14415
PPO Batch Consumption Time: 0.22971
Total Iteration Time: 6.94349
Cumulative Model Updates: 139,592
Cumulative Timesteps: 1,141,695,140
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28765
Policy Entropy: 4.31851
Value Function Loss: 0.00256
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03154
Policy Update Magnitude: 0.97473
Value Function Update Magnitude: 0.73478
Collected Steps per Second: 13,083.18935
Overall Steps per Second: 7,230.50921
Timestep Collection Time: 3.82460
Timestep Consumption Time: 3.09580
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.92040
Cumulative Model Updates: 139,601
Cumulative Timesteps: 1,141,745,178
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1141745178...
Checkpoint 1141745178 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.32112
Policy Entropy: 4.31835
Value Function Loss: 0.00253
Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.99175
Value Function Update Magnitude: 0.72904
Collected Steps per Second: 12,832.36965
Overall Steps per Second: 7,237.29308
Timestep Collection Time: 3.89811
Timestep Consumption Time: 3.01359
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.91170
Cumulative Model Updates: 139,610
Cumulative Timesteps: 1,141,795,200
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.39833
Policy Entropy: 4.31414
Value Function Loss: 0.00254
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 1.00482
Value Function Update Magnitude: 0.73608
Collected Steps per Second: 13,038.08803
Overall Steps per Second: 7,198.45833
Timestep Collection Time: 3.83569
Timestep Consumption Time: 3.11164
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.94732
Cumulative Model Updates: 139,619
Cumulative Timesteps: 1,141,845,210
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1141845210...
Checkpoint 1141845210 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.25440
Policy Entropy: 4.31311
Value Function Loss: 0.00269
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03011
Policy Update Magnitude: 1.01255
Value Function Update Magnitude: 0.72337
Collected Steps per Second: 13,241.53335
Overall Steps per Second: 7,308.77062
Timestep Collection Time: 3.77736
Timestep Consumption Time: 3.06620
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.84356
Cumulative Model Updates: 139,628
Cumulative Timesteps: 1,141,895,228
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.15254
Policy Entropy: 4.31616
Value Function Loss: 0.00268
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03036
Policy Update Magnitude: 1.00367
Value Function Update Magnitude: 0.70409
Collected Steps per Second: 13,100.19330
Overall Steps per Second: 7,329.05920
Timestep Collection Time: 3.81811
Timestep Consumption Time: 3.00650
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.82461
Cumulative Model Updates: 139,637
Cumulative Timesteps: 1,141,945,246
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1141945246...
Checkpoint 1141945246 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.43992
Policy Entropy: 4.32000
Value Function Loss: 0.00264
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.99497
Value Function Update Magnitude: 0.69675
Collected Steps per Second: 13,037.40131
Overall Steps per Second: 7,198.14671
Timestep Collection Time: 3.83788
Timestep Consumption Time: 3.11335
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.95123
Cumulative Model Updates: 139,646
Cumulative Timesteps: 1,141,995,282
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.51282
Policy Entropy: 4.32152
Value Function Loss: 0.00253
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 0.98993
Value Function Update Magnitude: 0.68792
Collected Steps per Second: 12,860.65274
Overall Steps per Second: 7,109.02840
Timestep Collection Time: 3.89203
Timestep Consumption Time: 3.14888
PPO Batch Consumption Time: 0.23039
Total Iteration Time: 7.04091
Cumulative Model Updates: 139,655
Cumulative Timesteps: 1,142,045,336
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1142045336...
Checkpoint 1142045336 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.48407
Policy Entropy: 4.32170
Value Function Loss: 0.00269
Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02751
Policy Update Magnitude: 1.00979
Value Function Update Magnitude: 0.68984
Collected Steps per Second: 12,936.93289
Overall Steps per Second: 7,276.60394
Timestep Collection Time: 3.86552
Timestep Consumption Time: 3.00691
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.87244
Cumulative Model Updates: 139,664
Cumulative Timesteps: 1,142,095,344
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.26635
Policy Entropy: 4.31835
Value Function Loss: 0.00278
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02875
Policy Update Magnitude: 1.01898
Value Function Update Magnitude: 0.69496
Collected Steps per Second: 12,915.00774
Overall Steps per Second: 7,158.19695
Timestep Collection Time: 3.87208
Timestep Consumption Time: 3.11403
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.98612
Cumulative Model Updates: 139,673
Cumulative Timesteps: 1,142,145,352
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1142145352...
Checkpoint 1142145352 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.13736
Policy Entropy: 4.31649
Value Function Loss: 0.00290
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 1.02803
Value Function Update Magnitude: 0.70404
Collected Steps per Second: 13,039.26493
Overall Steps per Second: 7,217.40743
Timestep Collection Time: 3.83534
Timestep Consumption Time: 3.09374
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.92908
Cumulative Model Updates: 139,682
Cumulative Timesteps: 1,142,195,362
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.80296
Policy Entropy: 4.31415
Value Function Loss: 0.00288
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 1.03612
Value Function Update Magnitude: 0.70042
Collected Steps per Second: 13,164.47596
Overall Steps per Second: 7,239.11881
Timestep Collection Time: 3.80068
Timestep Consumption Time: 3.11093
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.91161
Cumulative Model Updates: 139,691
Cumulative Timesteps: 1,142,245,396
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1142245396...
Checkpoint 1142245396 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.22428
Policy Entropy: 4.32132
Value Function Loss: 0.00283
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03005
Policy Update Magnitude: 1.02892
Value Function Update Magnitude: 0.69817
Collected Steps per Second: 12,875.41334
Overall Steps per Second: 7,160.27435
Timestep Collection Time: 3.88617
Timestep Consumption Time: 3.10183
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.98800
Cumulative Model Updates: 139,700
Cumulative Timesteps: 1,142,295,432
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.73190
Policy Entropy: 4.31911
Value Function Loss: 0.00286
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03076
Policy Update Magnitude: 1.02265
Value Function Update Magnitude: 0.72238
Collected Steps per Second: 12,850.56684
Overall Steps per Second: 7,156.66183
Timestep Collection Time: 3.89244
Timestep Consumption Time: 3.09686
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.98929
Cumulative Model Updates: 139,709
Cumulative Timesteps: 1,142,345,452
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1142345452...
Checkpoint 1142345452 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.47041
Policy Entropy: 4.32226
Value Function Loss: 0.00283
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03156
Policy Update Magnitude: 1.02870
Value Function Update Magnitude: 0.74518
Collected Steps per Second: 13,091.68310
Overall Steps per Second: 7,073.15695
Timestep Collection Time: 3.82182
Timestep Consumption Time: 3.25197
PPO Batch Consumption Time: 0.23853
Total Iteration Time: 7.07379
Cumulative Model Updates: 139,718
Cumulative Timesteps: 1,142,395,486
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76533
Policy Entropy: 4.31249
Value Function Loss: 0.00291
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03151
Policy Update Magnitude: 1.02999
Value Function Update Magnitude: 0.74514
Collected Steps per Second: 13,060.22927
Overall Steps per Second: 7,181.57243
Timestep Collection Time: 3.83087
Timestep Consumption Time: 3.13585
PPO Batch Consumption Time: 0.22966
Total Iteration Time: 6.96672
Cumulative Model Updates: 139,727
Cumulative Timesteps: 1,142,445,518
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1142445518...
Checkpoint 1142445518 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.58454
Policy Entropy: 4.31068
Value Function Loss: 0.00292
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 1.02998
Value Function Update Magnitude: 0.73692
Collected Steps per Second: 12,885.67867
Overall Steps per Second: 7,251.48580
Timestep Collection Time: 3.88167
Timestep Consumption Time: 3.01595
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.89762
Cumulative Model Updates: 139,736
Cumulative Timesteps: 1,142,495,536
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.00665
Policy Entropy: 4.31018
Value Function Loss: 0.00292
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03212
Policy Update Magnitude: 1.02882
Value Function Update Magnitude: 0.71437
Collected Steps per Second: 13,029.60609
Overall Steps per Second: 7,201.82632
Timestep Collection Time: 3.83972
Timestep Consumption Time: 3.10713
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.94685
Cumulative Model Updates: 139,745
Cumulative Timesteps: 1,142,545,566
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1142545566...
Checkpoint 1142545566 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02816
Policy Entropy: 4.31187
Value Function Loss: 0.00291
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03402
Policy Update Magnitude: 1.02080
Value Function Update Magnitude: 0.73069
Collected Steps per Second: 12,791.53438
Overall Steps per Second: 7,168.05570
Timestep Collection Time: 3.91056
Timestep Consumption Time: 3.06791
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.97846
Cumulative Model Updates: 139,754
Cumulative Timesteps: 1,142,595,588
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.21658
Policy Entropy: 4.31628
Value Function Loss: 0.00285
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03156
Policy Update Magnitude: 1.01593
Value Function Update Magnitude: 0.75365
Collected Steps per Second: 12,898.62249
Overall Steps per Second: 7,255.73473
Timestep Collection Time: 3.87855
Timestep Consumption Time: 3.01641
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.89496
Cumulative Model Updates: 139,763
Cumulative Timesteps: 1,142,645,616
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1142645616...
Checkpoint 1142645616 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71461
Policy Entropy: 4.30949
Value Function Loss: 0.00300
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03079
Policy Update Magnitude: 1.03252
Value Function Update Magnitude: 0.79402
Collected Steps per Second: 12,970.86908
Overall Steps per Second: 7,157.87403
Timestep Collection Time: 3.85695
Timestep Consumption Time: 3.13228
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.98923
Cumulative Model Updates: 139,772
Cumulative Timesteps: 1,142,695,644
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.25129
Policy Entropy: 4.31288
Value Function Loss: 0.00290
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 1.03716
Value Function Update Magnitude: 0.79270
Collected Steps per Second: 13,042.86150
Overall Steps per Second: 7,159.89073
Timestep Collection Time: 3.83351
Timestep Consumption Time: 3.14983
PPO Batch Consumption Time: 0.23327
Total Iteration Time: 6.98335
Cumulative Model Updates: 139,781
Cumulative Timesteps: 1,142,745,644
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1142745644...
Checkpoint 1142745644 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79443
Policy Entropy: 4.31253
Value Function Loss: 0.00296
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03619
Policy Update Magnitude: 1.03277
Value Function Update Magnitude: 0.79034
Collected Steps per Second: 13,229.78291
Overall Steps per Second: 7,242.60210
Timestep Collection Time: 3.78056
Timestep Consumption Time: 3.12524
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.90581
Cumulative Model Updates: 139,790
Cumulative Timesteps: 1,142,795,660
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64118
Policy Entropy: 4.31549
Value Function Loss: 0.00297
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03351
Policy Update Magnitude: 1.03957
Value Function Update Magnitude: 0.76469
Collected Steps per Second: 12,915.88059
Overall Steps per Second: 7,133.19180
Timestep Collection Time: 3.87399
Timestep Consumption Time: 3.14054
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 7.01453
Cumulative Model Updates: 139,799
Cumulative Timesteps: 1,142,845,696
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1142845696...
Checkpoint 1142845696 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.57536
Policy Entropy: 4.31806
Value Function Loss: 0.00291
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03184
Policy Update Magnitude: 1.03279
Value Function Update Magnitude: 0.78143
Collected Steps per Second: 13,012.75965
Overall Steps per Second: 7,224.69250
Timestep Collection Time: 3.84254
Timestep Consumption Time: 3.07845
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.92099
Cumulative Model Updates: 139,808
Cumulative Timesteps: 1,142,895,698
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.85148
Policy Entropy: 4.31850
Value Function Loss: 0.00289
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03014
Policy Update Magnitude: 1.02304
Value Function Update Magnitude: 0.78159
Collected Steps per Second: 13,118.30076
Overall Steps per Second: 7,219.70765
Timestep Collection Time: 3.81315
Timestep Consumption Time: 3.11539
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.92854
Cumulative Model Updates: 139,817
Cumulative Timesteps: 1,142,945,720
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1142945720...
Checkpoint 1142945720 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.02148
Policy Entropy: 4.32363
Value Function Loss: 0.00269
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03013
Policy Update Magnitude: 1.00025
Value Function Update Magnitude: 0.78418
Collected Steps per Second: 12,885.04581
Overall Steps per Second: 7,144.30431
Timestep Collection Time: 3.88311
Timestep Consumption Time: 3.12023
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 7.00334
Cumulative Model Updates: 139,826
Cumulative Timesteps: 1,142,995,754
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64686
Policy Entropy: 4.32872
Value Function Loss: 0.00273
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03026
Policy Update Magnitude: 1.00871
Value Function Update Magnitude: 0.78888
Collected Steps per Second: 12,820.55851
Overall Steps per Second: 7,188.20413
Timestep Collection Time: 3.90045
Timestep Consumption Time: 3.05622
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.95667
Cumulative Model Updates: 139,835
Cumulative Timesteps: 1,143,045,760
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1143045760...
Checkpoint 1143045760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.67642
Policy Entropy: 4.32898
Value Function Loss: 0.00267
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02967
Policy Update Magnitude: 1.02556
Value Function Update Magnitude: 0.77969
Collected Steps per Second: 13,049.69423
Overall Steps per Second: 7,046.43484
Timestep Collection Time: 3.83151
Timestep Consumption Time: 3.26428
PPO Batch Consumption Time: 0.24146
Total Iteration Time: 7.09579
Cumulative Model Updates: 139,844
Cumulative Timesteps: 1,143,095,760
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.41644
Policy Entropy: 4.32380
Value Function Loss: 0.00272
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03048
Policy Update Magnitude: 1.02800
Value Function Update Magnitude: 0.78367
Collected Steps per Second: 13,098.36508
Overall Steps per Second: 7,219.00371
Timestep Collection Time: 3.81727
Timestep Consumption Time: 3.10889
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.92616
Cumulative Model Updates: 139,853
Cumulative Timesteps: 1,143,145,760
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1143145760...
Checkpoint 1143145760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36615
Policy Entropy: 4.31898
Value Function Loss: 0.00272
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03305
Policy Update Magnitude: 1.01861
Value Function Update Magnitude: 0.76861
Collected Steps per Second: 12,876.01675
Overall Steps per Second: 7,189.08480
Timestep Collection Time: 3.88552
Timestep Consumption Time: 3.07364
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.95916
Cumulative Model Updates: 139,862
Cumulative Timesteps: 1,143,195,790
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.03968
Policy Entropy: 4.31884
Value Function Loss: 0.00263
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03505
Policy Update Magnitude: 1.00054
Value Function Update Magnitude: 0.76438
Collected Steps per Second: 13,281.58210
Overall Steps per Second: 7,276.72358
Timestep Collection Time: 3.76702
Timestep Consumption Time: 3.10860
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.87562
Cumulative Model Updates: 139,871
Cumulative Timesteps: 1,143,245,822
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1143245822...
Checkpoint 1143245822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.53443
Policy Entropy: 4.31727
Value Function Loss: 0.00271
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03232
Policy Update Magnitude: 1.00424
Value Function Update Magnitude: 0.78647
Collected Steps per Second: 12,896.01464
Overall Steps per Second: 7,153.90959
Timestep Collection Time: 3.87732
Timestep Consumption Time: 3.11214
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.98946
Cumulative Model Updates: 139,880
Cumulative Timesteps: 1,143,295,824
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.48514
Policy Entropy: 4.31543
Value Function Loss: 0.00273
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 1.02637
Value Function Update Magnitude: 0.78311
Collected Steps per Second: 12,883.03054
Overall Steps per Second: 7,180.77002
Timestep Collection Time: 3.88433
Timestep Consumption Time: 3.08456
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.96889
Cumulative Model Updates: 139,889
Cumulative Timesteps: 1,143,345,866
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1143345866...
Checkpoint 1143345866 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.84106
Policy Entropy: 4.31280
Value Function Loss: 0.00292
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03258
Policy Update Magnitude: 1.02908
Value Function Update Magnitude: 0.76968
Collected Steps per Second: 13,114.37974
Overall Steps per Second: 7,220.06240
Timestep Collection Time: 3.81505
Timestep Consumption Time: 3.11453
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.92958
Cumulative Model Updates: 139,898
Cumulative Timesteps: 1,143,395,898
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76711
Policy Entropy: 4.31461
Value Function Loss: 0.00286
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03048
Policy Update Magnitude: 1.03481
Value Function Update Magnitude: 0.76791
Collected Steps per Second: 12,737.66379
Overall Steps per Second: 6,981.49046
Timestep Collection Time: 3.92537
Timestep Consumption Time: 3.23643
PPO Batch Consumption Time: 0.23846
Total Iteration Time: 7.16179
Cumulative Model Updates: 139,907
Cumulative Timesteps: 1,143,445,898
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1143445898...
Checkpoint 1143445898 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01441
Policy Entropy: 4.31966
Value Function Loss: 0.00286
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 1.02471
Value Function Update Magnitude: 0.76863
Collected Steps per Second: 12,981.69289
Overall Steps per Second: 7,302.63641
Timestep Collection Time: 3.85404
Timestep Consumption Time: 2.99718
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.85122
Cumulative Model Updates: 139,916
Cumulative Timesteps: 1,143,495,930
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13308
Policy Entropy: 4.32020
Value Function Loss: 0.00273
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02835
Policy Update Magnitude: 1.01714
Value Function Update Magnitude: 0.74067
Collected Steps per Second: 13,011.02560
Overall Steps per Second: 7,207.66310
Timestep Collection Time: 3.84289
Timestep Consumption Time: 3.09417
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.93706
Cumulative Model Updates: 139,925
Cumulative Timesteps: 1,143,545,930
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1143545930...
Checkpoint 1143545930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65348
Policy Entropy: 4.31836
Value Function Loss: 0.00279
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 1.01002
Value Function Update Magnitude: 0.73722
Collected Steps per Second: 12,896.81828
Overall Steps per Second: 7,194.89885
Timestep Collection Time: 3.87770
Timestep Consumption Time: 3.07306
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.95076
Cumulative Model Updates: 139,934
Cumulative Timesteps: 1,143,595,940
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33118
Policy Entropy: 4.31717
Value Function Loss: 0.00279
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02958
Policy Update Magnitude: 1.01644
Value Function Update Magnitude: 0.74207
Collected Steps per Second: 13,000.23615
Overall Steps per Second: 7,281.55803
Timestep Collection Time: 3.84793
Timestep Consumption Time: 3.02203
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.86996
Cumulative Model Updates: 139,943
Cumulative Timesteps: 1,143,645,964
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1143645964...
Checkpoint 1143645964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.88259
Policy Entropy: 4.31733
Value Function Loss: 0.00292
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02798
Policy Update Magnitude: 1.03381
Value Function Update Magnitude: 0.75022
Collected Steps per Second: 12,941.11621
Overall Steps per Second: 7,163.62499
Timestep Collection Time: 3.86783
Timestep Consumption Time: 3.11942
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.98724
Cumulative Model Updates: 139,952
Cumulative Timesteps: 1,143,696,018
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.46734
Policy Entropy: 4.31893
Value Function Loss: 0.00285
Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02856
Policy Update Magnitude: 1.04538
Value Function Update Magnitude: 0.76674
Collected Steps per Second: 12,949.66579
Overall Steps per Second: 7,195.94650
Timestep Collection Time: 3.86527
Timestep Consumption Time: 3.09059
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.95586
Cumulative Model Updates: 139,961
Cumulative Timesteps: 1,143,746,072
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1143746072...
Checkpoint 1143746072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.80861
Policy Entropy: 4.31853
Value Function Loss: 0.00281
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 1.02279
Value Function Update Magnitude: 0.78850
Collected Steps per Second: 13,239.52681
Overall Steps per Second: 7,109.79158
Timestep Collection Time: 3.77989
Timestep Consumption Time: 3.25885
PPO Batch Consumption Time: 0.23929
Total Iteration Time: 7.03874
Cumulative Model Updates: 139,970
Cumulative Timesteps: 1,143,796,116
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50356
Policy Entropy: 4.31878
Value Function Loss: 0.00268
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03011
Policy Update Magnitude: 1.01102
Value Function Update Magnitude: 0.75005
Collected Steps per Second: 13,124.38417
Overall Steps per Second: 7,244.96906
Timestep Collection Time: 3.81306
Timestep Consumption Time: 3.09436
PPO Batch Consumption Time: 0.22787
Total Iteration Time: 6.90741
Cumulative Model Updates: 139,979
Cumulative Timesteps: 1,143,846,160
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1143846160...
Checkpoint 1143846160 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28175
Policy Entropy: 4.31496
Value Function Loss: 0.00275
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02933
Policy Update Magnitude: 1.01640
Value Function Update Magnitude: 0.75474
Collected Steps per Second: 13,023.55118
Overall Steps per Second: 7,305.63315
Timestep Collection Time: 3.84227
Timestep Consumption Time: 3.00724
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.84951
Cumulative Model Updates: 139,988
Cumulative Timesteps: 1,143,896,200
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79434
Policy Entropy: 4.31489
Value Function Loss: 0.00276
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03008
Policy Update Magnitude: 1.02948
Value Function Update Magnitude: 0.75721
Collected Steps per Second: 13,026.53513
Overall Steps per Second: 7,195.56397
Timestep Collection Time: 3.84062
Timestep Consumption Time: 3.11227
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.95289
Cumulative Model Updates: 139,997
Cumulative Timesteps: 1,143,946,230
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1143946230...
Checkpoint 1143946230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.68010
Policy Entropy: 4.31244
Value Function Loss: 0.00288
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03138
Policy Update Magnitude: 1.02835
Value Function Update Magnitude: 0.76210
Collected Steps per Second: 12,919.41598
Overall Steps per Second: 7,196.69502
Timestep Collection Time: 3.87061
Timestep Consumption Time: 3.07786
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.94847
Cumulative Model Updates: 140,006
Cumulative Timesteps: 1,143,996,236
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.75484
Policy Entropy: 4.31146
Value Function Loss: 0.00284
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03625
Policy Update Magnitude: 1.01568
Value Function Update Magnitude: 0.77321
Collected Steps per Second: 12,903.88358
Overall Steps per Second: 7,253.56503
Timestep Collection Time: 3.87620
Timestep Consumption Time: 3.01945
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.89564
Cumulative Model Updates: 140,015
Cumulative Timesteps: 1,144,046,254
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1144046254...
Checkpoint 1144046254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51328
Policy Entropy: 4.31302
Value Function Loss: 0.00281
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03590
Policy Update Magnitude: 1.01380
Value Function Update Magnitude: 0.81865
Collected Steps per Second: 12,980.15500
Overall Steps per Second: 7,173.31188
Timestep Collection Time: 3.85388
Timestep Consumption Time: 3.11974
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.97363
Cumulative Model Updates: 140,024
Cumulative Timesteps: 1,144,096,278
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.61390
Policy Entropy: 4.31922
Value Function Loss: 0.00270
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 1.01807
Value Function Update Magnitude: 0.79957
Collected Steps per Second: 12,873.60767
Overall Steps per Second: 7,126.21501
Timestep Collection Time: 3.88485
Timestep Consumption Time: 3.13318
PPO Batch Consumption Time: 0.23032
Total Iteration Time: 7.01803
Cumulative Model Updates: 140,033
Cumulative Timesteps: 1,144,146,290
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1144146290...
Checkpoint 1144146290 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42571
Policy Entropy: 4.32176
Value Function Loss: 0.00274
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03027
Policy Update Magnitude: 1.01504
Value Function Update Magnitude: 0.77722
Collected Steps per Second: 12,916.66659
Overall Steps per Second: 7,247.06424
Timestep Collection Time: 3.87391
Timestep Consumption Time: 3.03068
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.90459
Cumulative Model Updates: 140,042
Cumulative Timesteps: 1,144,196,328
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.09494
Policy Entropy: 4.32345
Value Function Loss: 0.00278
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03106
Policy Update Magnitude: 1.01183
Value Function Update Magnitude: 0.76620
Collected Steps per Second: 13,201.85370
Overall Steps per Second: 7,237.71097
Timestep Collection Time: 3.79038
Timestep Consumption Time: 3.12341
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.91379
Cumulative Model Updates: 140,051
Cumulative Timesteps: 1,144,246,368
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1144246368...
Checkpoint 1144246368 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.61606
Policy Entropy: 4.32183
Value Function Loss: 0.00284
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02990
Policy Update Magnitude: 1.02199
Value Function Update Magnitude: 0.75793
Collected Steps per Second: 13,026.54721
Overall Steps per Second: 7,210.43822
Timestep Collection Time: 3.84139
Timestep Consumption Time: 3.09855
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.93994
Cumulative Model Updates: 140,060
Cumulative Timesteps: 1,144,296,408
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10114
Policy Entropy: 4.32271
Value Function Loss: 0.00278
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02935
Policy Update Magnitude: 1.01824
Value Function Update Magnitude: 0.74498
Collected Steps per Second: 13,278.68445
Overall Steps per Second: 7,279.60992
Timestep Collection Time: 3.76845
Timestep Consumption Time: 3.10555
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.87399
Cumulative Model Updates: 140,069
Cumulative Timesteps: 1,144,346,448
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1144346448...
Checkpoint 1144346448 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.72809
Policy Entropy: 4.32414
Value Function Loss: 0.00273
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 1.02507
Value Function Update Magnitude: 0.75048
Collected Steps per Second: 12,901.12660
Overall Steps per Second: 7,172.99834
Timestep Collection Time: 3.87796
Timestep Consumption Time: 3.09681
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.97477
Cumulative Model Updates: 140,078
Cumulative Timesteps: 1,144,396,478
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.04652
Policy Entropy: 4.32270
Value Function Loss: 0.00274
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02932
Policy Update Magnitude: 1.03638
Value Function Update Magnitude: 0.73613
Collected Steps per Second: 12,801.97986
Overall Steps per Second: 7,150.09219
Timestep Collection Time: 3.90815
Timestep Consumption Time: 3.08925
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.99739
Cumulative Model Updates: 140,087
Cumulative Timesteps: 1,144,446,510
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1144446510...
Checkpoint 1144446510 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.32233
Policy Entropy: 4.32249
Value Function Loss: 0.00275
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 1.03647
Value Function Update Magnitude: 0.74619
Collected Steps per Second: 13,231.09819
Overall Steps per Second: 7,199.44622
Timestep Collection Time: 3.78049
Timestep Consumption Time: 3.16727
PPO Batch Consumption Time: 0.23005
Total Iteration Time: 6.94776
Cumulative Model Updates: 140,096
Cumulative Timesteps: 1,144,496,530
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.20521
Policy Entropy: 4.31611
Value Function Loss: 0.00287
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03054
Policy Update Magnitude: 1.04256
Value Function Update Magnitude: 0.75585
Collected Steps per Second: 12,960.84341
Overall Steps per Second: 7,156.43600
Timestep Collection Time: 3.86009
Timestep Consumption Time: 3.13082
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.99091
Cumulative Model Updates: 140,105
Cumulative Timesteps: 1,144,546,560
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1144546560...
Checkpoint 1144546560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.63052
Policy Entropy: 4.31837
Value Function Loss: 0.00278
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03164
Policy Update Magnitude: 1.03243
Value Function Update Magnitude: 0.79525
Collected Steps per Second: 12,721.19757
Overall Steps per Second: 7,131.67109
Timestep Collection Time: 3.93076
Timestep Consumption Time: 3.08078
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 7.01154
Cumulative Model Updates: 140,114
Cumulative Timesteps: 1,144,596,564
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.14495
Policy Entropy: 4.31679
Value Function Loss: 0.00286
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03018
Policy Update Magnitude: 1.04008
Value Function Update Magnitude: 0.82920
Collected Steps per Second: 13,245.42182
Overall Steps per Second: 7,249.16341
Timestep Collection Time: 3.77549
Timestep Consumption Time: 3.12296
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.89845
Cumulative Model Updates: 140,123
Cumulative Timesteps: 1,144,646,572
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1144646572...
Checkpoint 1144646572 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.87122
Policy Entropy: 4.32031
Value Function Loss: 0.00276
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03000
Policy Update Magnitude: 1.05349
Value Function Update Magnitude: 0.80255
Collected Steps per Second: 13,011.15034
Overall Steps per Second: 7,188.80721
Timestep Collection Time: 3.84332
Timestep Consumption Time: 3.11277
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.95609
Cumulative Model Updates: 140,132
Cumulative Timesteps: 1,144,696,578
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06660
Policy Entropy: 4.32134
Value Function Loss: 0.00279
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02993
Policy Update Magnitude: 1.03559
Value Function Update Magnitude: 0.78952
Collected Steps per Second: 12,969.91295
Overall Steps per Second: 7,288.04984
Timestep Collection Time: 3.85554
Timestep Consumption Time: 3.00583
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.86137
Cumulative Model Updates: 140,141
Cumulative Timesteps: 1,144,746,584
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1144746584...
Checkpoint 1144746584 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.87611
Policy Entropy: 4.32574
Value Function Loss: 0.00273
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03045
Policy Update Magnitude: 1.01297
Value Function Update Magnitude: 0.77383
Collected Steps per Second: 13,072.30669
Overall Steps per Second: 7,203.74986
Timestep Collection Time: 3.82687
Timestep Consumption Time: 3.11757
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.94444
Cumulative Model Updates: 140,150
Cumulative Timesteps: 1,144,796,610
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56069
Policy Entropy: 4.32612
Value Function Loss: 0.00264
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02940
Policy Update Magnitude: 1.00423
Value Function Update Magnitude: 0.75817
Collected Steps per Second: 12,933.03964
Overall Steps per Second: 7,147.16976
Timestep Collection Time: 3.86761
Timestep Consumption Time: 3.13096
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 6.99857
Cumulative Model Updates: 140,159
Cumulative Timesteps: 1,144,846,630
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1144846630...
Checkpoint 1144846630 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25972
Policy Entropy: 4.32287
Value Function Loss: 0.00268
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02812
Policy Update Magnitude: 1.01162
Value Function Update Magnitude: 0.75538
Collected Steps per Second: 12,900.17008
Overall Steps per Second: 7,272.21410
Timestep Collection Time: 3.87638
Timestep Consumption Time: 2.99993
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.87631
Cumulative Model Updates: 140,168
Cumulative Timesteps: 1,144,896,636
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.52283
Policy Entropy: 4.32336
Value Function Loss: 0.00269
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02915
Policy Update Magnitude: 1.01621
Value Function Update Magnitude: 0.75841
Collected Steps per Second: 12,920.84594
Overall Steps per Second: 7,177.20711
Timestep Collection Time: 3.87064
Timestep Consumption Time: 3.09753
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.96817
Cumulative Model Updates: 140,177
Cumulative Timesteps: 1,144,946,648
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1144946648...
Checkpoint 1144946648 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.28586
Policy Entropy: 4.32342
Value Function Loss: 0.00273
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 1.00850
Value Function Update Magnitude: 0.75630
Collected Steps per Second: 13,004.11042
Overall Steps per Second: 7,228.40504
Timestep Collection Time: 3.84678
Timestep Consumption Time: 3.07369
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.92048
Cumulative Model Updates: 140,186
Cumulative Timesteps: 1,144,996,672
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.82458
Policy Entropy: 4.32677
Value Function Loss: 0.00271
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 1.02797
Value Function Update Magnitude: 0.77222
Collected Steps per Second: 12,922.50493
Overall Steps per Second: 7,266.64933
Timestep Collection Time: 3.87355
Timestep Consumption Time: 3.01490
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.88846
Cumulative Model Updates: 140,195
Cumulative Timesteps: 1,145,046,728
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1145046728...
Checkpoint 1145046728 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.69181
Policy Entropy: 4.32824
Value Function Loss: 0.00265
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02867
Policy Update Magnitude: 1.04171
Value Function Update Magnitude: 0.75748
Collected Steps per Second: 12,827.85037
Overall Steps per Second: 7,133.94414
Timestep Collection Time: 3.90073
Timestep Consumption Time: 3.11334
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 7.01407
Cumulative Model Updates: 140,204
Cumulative Timesteps: 1,145,096,766
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.43280
Policy Entropy: 4.32439
Value Function Loss: 0.00262
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02877
Policy Update Magnitude: 1.02327
Value Function Update Magnitude: 0.73428
Collected Steps per Second: 13,099.16689
Overall Steps per Second: 7,235.15201
Timestep Collection Time: 3.81902
Timestep Consumption Time: 3.09528
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.91430
Cumulative Model Updates: 140,213
Cumulative Timesteps: 1,145,146,792
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1145146792...
Checkpoint 1145146792 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.03233
Policy Entropy: 4.32518
Value Function Loss: 0.00255
Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02836
Policy Update Magnitude: 1.02425
Value Function Update Magnitude: 0.71329
Collected Steps per Second: 13,251.93184
Overall Steps per Second: 7,195.99256
Timestep Collection Time: 3.77303
Timestep Consumption Time: 3.17528
PPO Batch Consumption Time: 0.23000
Total Iteration Time: 6.94831
Cumulative Model Updates: 140,222
Cumulative Timesteps: 1,145,196,792
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35925
Policy Entropy: 4.32271
Value Function Loss: 0.00262
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02993
Policy Update Magnitude: 1.02483
Value Function Update Magnitude: 0.73777
Collected Steps per Second: 12,944.60026
Overall Steps per Second: 7,174.32855
Timestep Collection Time: 3.86431
Timestep Consumption Time: 3.10805
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.97236
Cumulative Model Updates: 140,231
Cumulative Timesteps: 1,145,246,814
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1145246814...
Checkpoint 1145246814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25155
Policy Entropy: 4.32253
Value Function Loss: 0.00275
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02971
Policy Update Magnitude: 1.03500
Value Function Update Magnitude: 0.74018
Collected Steps per Second: 12,910.87913
Overall Steps per Second: 7,188.02426
Timestep Collection Time: 3.87704
Timestep Consumption Time: 3.08676
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.96381
Cumulative Model Updates: 140,240
Cumulative Timesteps: 1,145,296,870
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60086
Policy Entropy: 4.32172
Value Function Loss: 0.00285
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03114
Policy Update Magnitude: 1.04854
Value Function Update Magnitude: 0.74811
Collected Steps per Second: 13,304.28986
Overall Steps per Second: 7,284.07804
Timestep Collection Time: 3.75924
Timestep Consumption Time: 3.10697
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.86621
Cumulative Model Updates: 140,249
Cumulative Timesteps: 1,145,346,884
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1145346884...
Checkpoint 1145346884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74813
Policy Entropy: 4.32270
Value Function Loss: 0.00283
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03068
Policy Update Magnitude: 1.04923
Value Function Update Magnitude: 0.74740
Collected Steps per Second: 12,985.82253
Overall Steps per Second: 7,189.72741
Timestep Collection Time: 3.85205
Timestep Consumption Time: 3.10538
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.95743
Cumulative Model Updates: 140,258
Cumulative Timesteps: 1,145,396,906
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71473
Policy Entropy: 4.31805
Value Function Loss: 0.00273
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 1.05533
Value Function Update Magnitude: 0.74853
Collected Steps per Second: 12,910.05233
Overall Steps per Second: 7,264.07702
Timestep Collection Time: 3.87558
Timestep Consumption Time: 3.01228
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.88787
Cumulative Model Updates: 140,267
Cumulative Timesteps: 1,145,446,940
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1145446940...
Checkpoint 1145446940 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.09930
Policy Entropy: 4.31590
Value Function Loss: 0.00274
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03145
Policy Update Magnitude: 1.06563
Value Function Update Magnitude: 0.76662
Collected Steps per Second: 13,010.75693
Overall Steps per Second: 7,187.81542
Timestep Collection Time: 3.84497
Timestep Consumption Time: 3.11486
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.95983
Cumulative Model Updates: 140,276
Cumulative Timesteps: 1,145,496,966
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.42466
Policy Entropy: 4.31523
Value Function Loss: 0.00276
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03111
Policy Update Magnitude: 1.06893
Value Function Update Magnitude: 0.79577
Collected Steps per Second: 12,846.86833
Overall Steps per Second: 7,128.66136
Timestep Collection Time: 3.89667
Timestep Consumption Time: 3.12569
PPO Batch Consumption Time: 0.22978
Total Iteration Time: 7.02236
Cumulative Model Updates: 140,285
Cumulative Timesteps: 1,145,547,026
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 1145547026...
Checkpoint 1145547026 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75982
Policy Entropy: 4.31869
Value Function Loss: 0.00278
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 1.06054
Value Function Update Magnitude: 0.79435
Collected Steps per Second: 12,866.75994
Overall Steps per Second: 7,239.69592
Timestep Collection Time: 3.88878
Timestep Consumption Time: 3.02256
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.91134
Cumulative Model Updates: 140,294
Cumulative Timesteps: 1,145,597,062
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.95258
Policy Entropy: 4.31993
Value Function Loss: 0.00268
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03108
Policy Update Magnitude: 1.05231
Value Function Update Magnitude: 0.75076
Collected Steps per Second: 12,952.98289
Overall Steps per Second: 7,177.88856
Timestep Collection Time: 3.86259
Timestep Consumption Time: 3.10771
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.97029
Cumulative Model Updates: 140,303
Cumulative Timesteps: 1,145,647,094
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1145647094...
Checkpoint 1145647094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90763
Policy Entropy: 4.32035
Value Function Loss: 0.00278
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02997
Policy Update Magnitude: 1.06357
Value Function Update Magnitude: 0.73567
Collected Steps per Second: 12,896.60626
Overall Steps per Second: 7,264.13879
Timestep Collection Time: 3.88195
Timestep Consumption Time: 3.00999
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.89194
Cumulative Model Updates: 140,312
Cumulative Timesteps: 1,145,697,158
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.82362
Policy Entropy: 4.31993
Value Function Loss: 0.00272
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03106
Policy Update Magnitude: 1.06673
Value Function Update Magnitude: 0.74882
Collected Steps per Second: 12,813.84338
Overall Steps per Second: 7,115.81504
Timestep Collection Time: 3.90453
Timestep Consumption Time: 3.12657
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 7.03110
Cumulative Model Updates: 140,321
Cumulative Timesteps: 1,145,747,190
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1145747190...
Checkpoint 1145747190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.20032
Policy Entropy: 4.31721
Value Function Loss: 0.00279
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03208
Policy Update Magnitude: 1.07798
Value Function Update Magnitude: 0.77549
Collected Steps per Second: 12,939.62203
Overall Steps per Second: 7,161.83397
Timestep Collection Time: 3.86626
Timestep Consumption Time: 3.11910
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.98536
Cumulative Model Updates: 140,330
Cumulative Timesteps: 1,145,797,218
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.86036
Policy Entropy: 4.31940
Value Function Loss: 0.00268
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03083
Policy Update Magnitude: 1.07440
Value Function Update Magnitude: 0.75847
Collected Steps per Second: 13,079.75614
Overall Steps per Second: 7,315.45728
Timestep Collection Time: 3.82576
Timestep Consumption Time: 3.01455
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.84031
Cumulative Model Updates: 140,339
Cumulative Timesteps: 1,145,847,258
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1145847258...
Checkpoint 1145847258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97863
Policy Entropy: 4.32654
Value Function Loss: 0.00265
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03181
Policy Update Magnitude: 1.05657
Value Function Update Magnitude: 0.76006
Collected Steps per Second: 12,893.78588
Overall Steps per Second: 7,037.88644
Timestep Collection Time: 3.88125
Timestep Consumption Time: 3.22941
PPO Batch Consumption Time: 0.23723
Total Iteration Time: 7.11066
Cumulative Model Updates: 140,348
Cumulative Timesteps: 1,145,897,302
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28195
Policy Entropy: 4.32818
Value Function Loss: 0.00272
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03074
Policy Update Magnitude: 1.04960
Value Function Update Magnitude: 0.74110
Collected Steps per Second: 12,970.36631
Overall Steps per Second: 7,158.23894
Timestep Collection Time: 3.85756
Timestep Consumption Time: 3.13215
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.98971
Cumulative Model Updates: 140,357
Cumulative Timesteps: 1,145,947,336
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1145947336...
Checkpoint 1145947336 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.89176
Policy Entropy: 4.32396
Value Function Loss: 0.00277
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03218
Policy Update Magnitude: 1.07883
Value Function Update Magnitude: 0.75767
Collected Steps per Second: 13,021.67151
Overall Steps per Second: 7,283.65035
Timestep Collection Time: 3.84175
Timestep Consumption Time: 3.02651
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.86826
Cumulative Model Updates: 140,366
Cumulative Timesteps: 1,145,997,362
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.32077
Policy Entropy: 4.31752
Value Function Loss: 0.00277
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03286
Policy Update Magnitude: 1.10239
Value Function Update Magnitude: 0.74514
Collected Steps per Second: 13,151.76649
Overall Steps per Second: 7,223.01096
Timestep Collection Time: 3.80679
Timestep Consumption Time: 3.12467
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.93146
Cumulative Model Updates: 140,375
Cumulative Timesteps: 1,146,047,428
Timesteps Collected: 50,066
--------END ITERATION REPORT--------
Saving checkpoint 1146047428...
Checkpoint 1146047428 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.00870
Policy Entropy: 4.32157
Value Function Loss: 0.00270
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 1.09262
Value Function Update Magnitude: 0.72099
Collected Steps per Second: 12,913.70108
Overall Steps per Second: 7,188.73194
Timestep Collection Time: 3.87666
Timestep Consumption Time: 3.08730
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.96395
Cumulative Model Updates: 140,384
Cumulative Timesteps: 1,146,097,490
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22817
Policy Entropy: 4.32138
Value Function Loss: 0.00264
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 1.06233
Value Function Update Magnitude: 0.71186
Collected Steps per Second: 12,952.82699
Overall Steps per Second: 7,287.98418
Timestep Collection Time: 3.86047
Timestep Consumption Time: 3.00069
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.86116
Cumulative Model Updates: 140,393
Cumulative Timesteps: 1,146,147,494
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1146147494...
Checkpoint 1146147494 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.03209
Policy Entropy: 4.32210
Value Function Loss: 0.00261
Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 1.05726
Value Function Update Magnitude: 0.71643
Collected Steps per Second: 12,943.01947
Overall Steps per Second: 7,169.46423
Timestep Collection Time: 3.86633
Timestep Consumption Time: 3.11355
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.97988
Cumulative Model Updates: 140,402
Cumulative Timesteps: 1,146,197,536
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.36586
Policy Entropy: 4.31697
Value Function Loss: 0.00270
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03305
Policy Update Magnitude: 1.06620
Value Function Update Magnitude: 0.72515
Collected Steps per Second: 13,012.41658
Overall Steps per Second: 7,173.59384
Timestep Collection Time: 3.84387
Timestep Consumption Time: 3.12865
PPO Batch Consumption Time: 0.22965
Total Iteration Time: 6.97252
Cumulative Model Updates: 140,411
Cumulative Timesteps: 1,146,247,554
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1146247554...
Checkpoint 1146247554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.25197
Policy Entropy: 4.31880
Value Function Loss: 0.00273
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 1.06877
Value Function Update Magnitude: 0.76340
Collected Steps per Second: 13,200.43522
Overall Steps per Second: 7,255.36547
Timestep Collection Time: 3.78775
Timestep Consumption Time: 3.10370
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.89145
Cumulative Model Updates: 140,420
Cumulative Timesteps: 1,146,297,554
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86137
Policy Entropy: 4.31878
Value Function Loss: 0.00269
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 1.06306
Value Function Update Magnitude: 0.75755
Collected Steps per Second: 12,968.07135
Overall Steps per Second: 7,187.68028
Timestep Collection Time: 3.85717
Timestep Consumption Time: 3.10196
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.95913
Cumulative Model Updates: 140,429
Cumulative Timesteps: 1,146,347,574
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1146347574...
Checkpoint 1146347574 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.29331
Policy Entropy: 4.31804
Value Function Loss: 0.00270
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03301
Policy Update Magnitude: 1.06254
Value Function Update Magnitude: 0.72359
Collected Steps per Second: 12,939.70958
Overall Steps per Second: 7,287.91368
Timestep Collection Time: 3.86516
Timestep Consumption Time: 2.99744
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.86260
Cumulative Model Updates: 140,438
Cumulative Timesteps: 1,146,397,588
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.87263
Policy Entropy: 4.31964
Value Function Loss: 0.00277
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03506
Policy Update Magnitude: 1.05951
Value Function Update Magnitude: 0.70422
Collected Steps per Second: 12,956.09539
Overall Steps per Second: 7,163.95538
Timestep Collection Time: 3.86058
Timestep Consumption Time: 3.12132
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.98190
Cumulative Model Updates: 140,447
Cumulative Timesteps: 1,146,447,606
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1146447606...
Checkpoint 1146447606 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82795
Policy Entropy: 4.32045
Value Function Loss: 0.00284
Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04421
Policy Update Magnitude: 1.05598
Value Function Update Magnitude: 0.71162
Collected Steps per Second: 13,029.09747
Overall Steps per Second: 7,187.75620
Timestep Collection Time: 3.84033
Timestep Consumption Time: 3.12095
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.96128
Cumulative Model Updates: 140,456
Cumulative Timesteps: 1,146,497,642
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.68076
Policy Entropy: 4.32287
Value Function Loss: 0.00281
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03520
Policy Update Magnitude: 1.05610
Value Function Update Magnitude: 0.72089
Collected Steps per Second: 13,017.17821
Overall Steps per Second: 7,292.41078
Timestep Collection Time: 3.84200
Timestep Consumption Time: 3.01609
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.85809
Cumulative Model Updates: 140,465
Cumulative Timesteps: 1,146,547,654
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1146547654...
Checkpoint 1146547654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.82512
Policy Entropy: 4.32497
Value Function Loss: 0.00270
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 1.05690
Value Function Update Magnitude: 0.72763
Collected Steps per Second: 13,131.24816
Overall Steps per Second: 7,069.00109
Timestep Collection Time: 3.81045
Timestep Consumption Time: 3.26778
PPO Batch Consumption Time: 0.24001
Total Iteration Time: 7.07823
Cumulative Model Updates: 140,474
Cumulative Timesteps: 1,146,597,690
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86501
Policy Entropy: 4.32414
Value Function Loss: 0.00282
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 1.05119
Value Function Update Magnitude: 0.72920
Collected Steps per Second: 12,964.10717
Overall Steps per Second: 7,203.82821
Timestep Collection Time: 3.85696
Timestep Consumption Time: 3.08407
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.94103
Cumulative Model Updates: 140,483
Cumulative Timesteps: 1,146,647,692
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1146647692...
Checkpoint 1146647692 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58401
Policy Entropy: 4.32473
Value Function Loss: 0.00275
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03118
Policy Update Magnitude: 1.04498
Value Function Update Magnitude: 0.72148
Collected Steps per Second: 12,723.89593
Overall Steps per Second: 7,211.90941
Timestep Collection Time: 3.93197
Timestep Consumption Time: 3.00516
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.93714
Cumulative Model Updates: 140,492
Cumulative Timesteps: 1,146,697,722
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.28686
Policy Entropy: 4.31899
Value Function Loss: 0.00288
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 1.04682
Value Function Update Magnitude: 0.70997
Collected Steps per Second: 12,720.34938
Overall Steps per Second: 7,081.71008
Timestep Collection Time: 3.93212
Timestep Consumption Time: 3.13086
PPO Batch Consumption Time: 0.22985
Total Iteration Time: 7.06298
Cumulative Model Updates: 140,501
Cumulative Timesteps: 1,146,747,740
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1146747740...
Checkpoint 1146747740 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54560
Policy Entropy: 4.32005
Value Function Loss: 0.00269
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03003
Policy Update Magnitude: 1.04994
Value Function Update Magnitude: 0.71047
Collected Steps per Second: 12,772.02605
Overall Steps per Second: 7,161.53148
Timestep Collection Time: 3.91622
Timestep Consumption Time: 3.06805
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.98426
Cumulative Model Updates: 140,510
Cumulative Timesteps: 1,146,797,758
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.40799
Policy Entropy: 4.31702
Value Function Loss: 0.00273
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 1.04769
Value Function Update Magnitude: 0.71028
Collected Steps per Second: 12,969.50049
Overall Steps per Second: 7,253.10834
Timestep Collection Time: 3.85736
Timestep Consumption Time: 3.04010
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.89746
Cumulative Model Updates: 140,519
Cumulative Timesteps: 1,146,847,786
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1146847786...
Checkpoint 1146847786 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.66045
Policy Entropy: 4.31973
Value Function Loss: 0.00259
Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02766
Policy Update Magnitude: 1.04713
Value Function Update Magnitude: 0.69017
Collected Steps per Second: 12,841.27162
Overall Steps per Second: 7,150.32087
Timestep Collection Time: 3.89603
Timestep Consumption Time: 3.10086
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.99689
Cumulative Model Updates: 140,528
Cumulative Timesteps: 1,146,897,816
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65056
Policy Entropy: 4.31862
Value Function Loss: 0.00270
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 1.04004
Value Function Update Magnitude: 0.68970
Collected Steps per Second: 12,904.15890
Overall Steps per Second: 7,132.43834
Timestep Collection Time: 3.87751
Timestep Consumption Time: 3.13776
PPO Batch Consumption Time: 0.23072
Total Iteration Time: 7.01527
Cumulative Model Updates: 140,537
Cumulative Timesteps: 1,146,947,852
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1146947852...
Checkpoint 1146947852 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58975
Policy Entropy: 4.31717
Value Function Loss: 0.00294
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03198
Policy Update Magnitude: 1.07290
Value Function Update Magnitude: 0.71346
Collected Steps per Second: 13,212.03724
Overall Steps per Second: 7,253.50956
Timestep Collection Time: 3.78458
Timestep Consumption Time: 3.10891
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.89349
Cumulative Model Updates: 140,546
Cumulative Timesteps: 1,146,997,854
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.27639
Policy Entropy: 4.31959
Value Function Loss: 0.00291
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 1.07149
Value Function Update Magnitude: 0.72310
Collected Steps per Second: 12,940.67083
Overall Steps per Second: 7,163.22501
Timestep Collection Time: 3.86580
Timestep Consumption Time: 3.11793
PPO Batch Consumption Time: 0.22796
Total Iteration Time: 6.98373
Cumulative Model Updates: 140,555
Cumulative Timesteps: 1,147,047,880
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1147047880...
Checkpoint 1147047880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.91090
Policy Entropy: 4.32352
Value Function Loss: 0.00275
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 1.04030
Value Function Update Magnitude: 0.71320
Collected Steps per Second: 13,005.41490
Overall Steps per Second: 7,205.30562
Timestep Collection Time: 3.84517
Timestep Consumption Time: 3.09527
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.94044
Cumulative Model Updates: 140,564
Cumulative Timesteps: 1,147,097,888
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.06422
Policy Entropy: 4.32595
Value Function Loss: 0.00261
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03104
Policy Update Magnitude: 1.02926
Value Function Update Magnitude: 0.71293
Collected Steps per Second: 13,586.77173
Overall Steps per Second: 7,373.58844
Timestep Collection Time: 3.68358
Timestep Consumption Time: 3.10389
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.78747
Cumulative Model Updates: 140,573
Cumulative Timesteps: 1,147,147,936
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1147147936...
Checkpoint 1147147936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.04286
Policy Entropy: 4.32331
Value Function Loss: 0.00265
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 1.03767
Value Function Update Magnitude: 0.71068
Collected Steps per Second: 12,854.74333
Overall Steps per Second: 7,120.43868
Timestep Collection Time: 3.89273
Timestep Consumption Time: 3.13493
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 7.02766
Cumulative Model Updates: 140,582
Cumulative Timesteps: 1,147,197,976
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86511
Policy Entropy: 4.31894
Value Function Loss: 0.00287
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03094
Policy Update Magnitude: 1.05444
Value Function Update Magnitude: 0.70931
Collected Steps per Second: 12,981.23518
Overall Steps per Second: 7,281.62345
Timestep Collection Time: 3.85218
Timestep Consumption Time: 3.01525
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.86742
Cumulative Model Updates: 140,591
Cumulative Timesteps: 1,147,247,982
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1147247982...
Checkpoint 1147247982 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.56616
Policy Entropy: 4.31832
Value Function Loss: 0.00294
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03238
Policy Update Magnitude: 1.07105
Value Function Update Magnitude: 0.73225
Collected Steps per Second: 12,751.24647
Overall Steps per Second: 6,967.27740
Timestep Collection Time: 3.92322
Timestep Consumption Time: 3.25691
PPO Batch Consumption Time: 0.24039
Total Iteration Time: 7.18014
Cumulative Model Updates: 140,600
Cumulative Timesteps: 1,147,298,008
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.68278
Policy Entropy: 4.31897
Value Function Loss: 0.00282
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03217
Policy Update Magnitude: 1.06816
Value Function Update Magnitude: 0.75376
Collected Steps per Second: 13,017.40596
Overall Steps per Second: 7,219.28998
Timestep Collection Time: 3.84163
Timestep Consumption Time: 3.08537
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.92700
Cumulative Model Updates: 140,609
Cumulative Timesteps: 1,147,348,016
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1147348016...
Checkpoint 1147348016 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.75521
Policy Entropy: 4.31821
Value Function Loss: 0.00290
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 1.06453
Value Function Update Magnitude: 0.76121
Collected Steps per Second: 12,935.92083
Overall Steps per Second: 7,272.80562
Timestep Collection Time: 3.86722
Timestep Consumption Time: 3.01128
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.87850
Cumulative Model Updates: 140,618
Cumulative Timesteps: 1,147,398,042
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.99135
Policy Entropy: 4.31923
Value Function Loss: 0.00285
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03346
Policy Update Magnitude: 1.05952
Value Function Update Magnitude: 0.74965
Collected Steps per Second: 13,025.98895
Overall Steps per Second: 7,176.95705
Timestep Collection Time: 3.83986
Timestep Consumption Time: 3.12939
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.96925
Cumulative Model Updates: 140,627
Cumulative Timesteps: 1,147,448,060
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1147448060...
Checkpoint 1147448060 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.23376
Policy Entropy: 4.31519
Value Function Loss: 0.00294
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03529
Policy Update Magnitude: 1.05564
Value Function Update Magnitude: 0.70900
Collected Steps per Second: 13,022.12973
Overall Steps per Second: 7,208.41921
Timestep Collection Time: 3.83977
Timestep Consumption Time: 3.09684
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.93661
Cumulative Model Updates: 140,636
Cumulative Timesteps: 1,147,498,062
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.61591
Policy Entropy: 4.31655
Value Function Loss: 0.00277
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 1.04554
Value Function Update Magnitude: 0.70107
Collected Steps per Second: 13,286.86171
Overall Steps per Second: 7,253.55981
Timestep Collection Time: 3.76583
Timestep Consumption Time: 3.13230
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.89813
Cumulative Model Updates: 140,645
Cumulative Timesteps: 1,147,548,098
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1147548098...
Checkpoint 1147548098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.58723
Policy Entropy: 4.31648
Value Function Loss: 0.00275
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03680
Policy Update Magnitude: 1.04134
Value Function Update Magnitude: 0.71654
Collected Steps per Second: 13,137.34323
Overall Steps per Second: 7,225.74187
Timestep Collection Time: 3.80731
Timestep Consumption Time: 3.11488
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.92220
Cumulative Model Updates: 140,654
Cumulative Timesteps: 1,147,598,116
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.11405
Policy Entropy: 4.31570
Value Function Loss: 0.00274
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03509
Policy Update Magnitude: 1.04090
Value Function Update Magnitude: 0.73522
Collected Steps per Second: 12,932.85422
Overall Steps per Second: 7,064.33977
Timestep Collection Time: 3.86922
Timestep Consumption Time: 3.21425
PPO Batch Consumption Time: 0.23950
Total Iteration Time: 7.08346
Cumulative Model Updates: 140,663
Cumulative Timesteps: 1,147,648,156
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1147648156...
Checkpoint 1147648156 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.81912
Policy Entropy: 4.31449
Value Function Loss: 0.00262
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 1.05004
Value Function Update Magnitude: 0.74697
Collected Steps per Second: 13,157.08417
Overall Steps per Second: 7,254.89907
Timestep Collection Time: 3.80175
Timestep Consumption Time: 3.09290
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.89465
Cumulative Model Updates: 140,672
Cumulative Timesteps: 1,147,698,176
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.74949
Policy Entropy: 4.31642
Value Function Loss: 0.00259
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03489
Policy Update Magnitude: 1.02774
Value Function Update Magnitude: 0.71612
Collected Steps per Second: 12,802.37069
Overall Steps per Second: 7,123.67980
Timestep Collection Time: 3.90584
Timestep Consumption Time: 3.11357
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 7.01941
Cumulative Model Updates: 140,681
Cumulative Timesteps: 1,147,748,180
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1147748180...
Checkpoint 1147748180 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01606
Policy Entropy: 4.31380
Value Function Loss: 0.00259
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03166
Policy Update Magnitude: 1.03164
Value Function Update Magnitude: 0.67530
Collected Steps per Second: 13,011.45517
Overall Steps per Second: 7,273.66301
Timestep Collection Time: 3.84384
Timestep Consumption Time: 3.03220
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.87604
Cumulative Model Updates: 140,690
Cumulative Timesteps: 1,147,798,194
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.34554
Policy Entropy: 4.31304
Value Function Loss: 0.00267
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03105
Policy Update Magnitude: 1.02976
Value Function Update Magnitude: 0.69829
Collected Steps per Second: 11,994.60109
Overall Steps per Second: 6,814.06010
Timestep Collection Time: 4.16921
Timestep Consumption Time: 3.16973
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 7.33894
Cumulative Model Updates: 140,699
Cumulative Timesteps: 1,147,848,202
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1147848202...
Checkpoint 1147848202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.57452
Policy Entropy: 4.31084
Value Function Loss: 0.00271
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03178
Policy Update Magnitude: 1.02229
Value Function Update Magnitude: 0.74013
Collected Steps per Second: 12,748.97173
Overall Steps per Second: 7,093.74783
Timestep Collection Time: 3.92267
Timestep Consumption Time: 3.12720
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 7.04987
Cumulative Model Updates: 140,708
Cumulative Timesteps: 1,147,898,212
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.95583
Policy Entropy: 4.31183
Value Function Loss: 0.00266
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03178
Policy Update Magnitude: 1.02379
Value Function Update Magnitude: 0.76836
Collected Steps per Second: 12,693.49768
Overall Steps per Second: 7,172.12673
Timestep Collection Time: 3.94076
Timestep Consumption Time: 3.03374
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.97450
Cumulative Model Updates: 140,717
Cumulative Timesteps: 1,147,948,234
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1147948234...
Checkpoint 1147948234 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.66081
Policy Entropy: 4.31603
Value Function Loss: 0.00263
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03451
Policy Update Magnitude: 1.01247
Value Function Update Magnitude: 0.77224
Collected Steps per Second: 12,891.86513
Overall Steps per Second: 7,095.28265
Timestep Collection Time: 3.88198
Timestep Consumption Time: 3.17144
PPO Batch Consumption Time: 0.23068
Total Iteration Time: 7.05342
Cumulative Model Updates: 140,726
Cumulative Timesteps: 1,147,998,280
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.88740
Policy Entropy: 4.31987
Value Function Loss: 0.00251
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02970
Policy Update Magnitude: 1.01196
Value Function Update Magnitude: 0.75729
Collected Steps per Second: 12,912.72125
Overall Steps per Second: 7,188.19398
Timestep Collection Time: 3.87432
Timestep Consumption Time: 3.08543
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.95975
Cumulative Model Updates: 140,735
Cumulative Timesteps: 1,148,048,308
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1148048308...
Checkpoint 1148048308 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.22916
Policy Entropy: 4.32148
Value Function Loss: 0.00247
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 1.00783
Value Function Update Magnitude: 0.74332
Collected Steps per Second: 12,889.75843
Overall Steps per Second: 7,267.91184
Timestep Collection Time: 3.88169
Timestep Consumption Time: 3.00255
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.88423
Cumulative Model Updates: 140,744
Cumulative Timesteps: 1,148,098,342
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.16292
Policy Entropy: 4.32169
Value Function Loss: 0.00250
Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 1.01230
Value Function Update Magnitude: 0.73030
Collected Steps per Second: 12,411.25055
Overall Steps per Second: 6,886.61701
Timestep Collection Time: 4.03005
Timestep Consumption Time: 3.23302
PPO Batch Consumption Time: 0.23867
Total Iteration Time: 7.26307
Cumulative Model Updates: 140,753
Cumulative Timesteps: 1,148,148,360
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1148148360...
Checkpoint 1148148360 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22612
Policy Entropy: 4.32366
Value Function Loss: 0.00245
Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 1.00276
Value Function Update Magnitude: 0.72316
Collected Steps per Second: 11,537.55927
Overall Steps per Second: 6,617.19473
Timestep Collection Time: 4.33437
Timestep Consumption Time: 3.22292
PPO Batch Consumption Time: 0.23997
Total Iteration Time: 7.55728
Cumulative Model Updates: 140,762
Cumulative Timesteps: 1,148,198,368
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.12395
Policy Entropy: 4.32033
Value Function Loss: 0.00264
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02799
Policy Update Magnitude: 1.01188
Value Function Update Magnitude: 0.72900
Collected Steps per Second: 12,710.25967
Overall Steps per Second: 7,164.85705
Timestep Collection Time: 3.93698
Timestep Consumption Time: 3.04711
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.98409
Cumulative Model Updates: 140,771
Cumulative Timesteps: 1,148,248,408
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1148248408...
Checkpoint 1148248408 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.50811
Policy Entropy: 4.31722
Value Function Loss: 0.00259
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02994
Policy Update Magnitude: 1.02870
Value Function Update Magnitude: 0.72416
Collected Steps per Second: 12,700.59968
Overall Steps per Second: 7,007.54154
Timestep Collection Time: 3.93729
Timestep Consumption Time: 3.19873
PPO Batch Consumption Time: 0.23610
Total Iteration Time: 7.13603
Cumulative Model Updates: 140,780
Cumulative Timesteps: 1,148,298,414
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46909
Policy Entropy: 4.31493
Value Function Loss: 0.00264
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03141
Policy Update Magnitude: 1.02909
Value Function Update Magnitude: 0.74021
Collected Steps per Second: 11,314.39753
Overall Steps per Second: 6,504.16811
Timestep Collection Time: 4.42198
Timestep Consumption Time: 3.27032
PPO Batch Consumption Time: 0.23930
Total Iteration Time: 7.69230
Cumulative Model Updates: 140,789
Cumulative Timesteps: 1,148,348,446
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1148348446...
Checkpoint 1148348446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.57942
Policy Entropy: 4.31982
Value Function Loss: 0.00264
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03056
Policy Update Magnitude: 1.01617
Value Function Update Magnitude: 0.73857
Collected Steps per Second: 12,974.82051
Overall Steps per Second: 7,166.63694
Timestep Collection Time: 3.85377
Timestep Consumption Time: 3.12328
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.97705
Cumulative Model Updates: 140,798
Cumulative Timesteps: 1,148,398,448
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69843
Policy Entropy: 4.31773
Value Function Loss: 0.00283
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02991
Policy Update Magnitude: 1.03740
Value Function Update Magnitude: 0.79351
Collected Steps per Second: 12,787.97948
Overall Steps per Second: 7,097.48650
Timestep Collection Time: 3.91086
Timestep Consumption Time: 3.13558
PPO Batch Consumption Time: 0.22952
Total Iteration Time: 7.04644
Cumulative Model Updates: 140,807
Cumulative Timesteps: 1,148,448,460
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1148448460...
Checkpoint 1148448460 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54186
Policy Entropy: 4.31948
Value Function Loss: 0.00282
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 1.04953
Value Function Update Magnitude: 0.82002
Collected Steps per Second: 12,990.89035
Overall Steps per Second: 7,215.81147
Timestep Collection Time: 3.85085
Timestep Consumption Time: 3.08198
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.93283
Cumulative Model Updates: 140,816
Cumulative Timesteps: 1,148,498,486
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.63573
Policy Entropy: 4.31749
Value Function Loss: 0.00268
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 1.04102
Value Function Update Magnitude: 0.80069
Collected Steps per Second: 13,215.80548
Overall Steps per Second: 7,275.28777
Timestep Collection Time: 3.78441
Timestep Consumption Time: 3.09010
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.87450
Cumulative Model Updates: 140,825
Cumulative Timesteps: 1,148,548,500
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1148548500...
Checkpoint 1148548500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04535
Policy Entropy: 4.32136
Value Function Loss: 0.00259
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03197
Policy Update Magnitude: 1.04171
Value Function Update Magnitude: 0.76789
Collected Steps per Second: 12,688.99303
Overall Steps per Second: 7,097.91356
Timestep Collection Time: 3.94042
Timestep Consumption Time: 3.10390
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 7.04432
Cumulative Model Updates: 140,834
Cumulative Timesteps: 1,148,598,500
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83716
Policy Entropy: 4.32130
Value Function Loss: 0.00262
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03224
Policy Update Magnitude: 1.03482
Value Function Update Magnitude: 0.74869
Collected Steps per Second: 12,682.47013
Overall Steps per Second: 7,206.21421
Timestep Collection Time: 3.94671
Timestep Consumption Time: 2.99924
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.94595
Cumulative Model Updates: 140,843
Cumulative Timesteps: 1,148,648,554
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1148648554...
Checkpoint 1148648554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.88703
Policy Entropy: 4.31778
Value Function Loss: 0.00289
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03181
Policy Update Magnitude: 1.05791
Value Function Update Magnitude: 0.75802
Collected Steps per Second: 12,881.25042
Overall Steps per Second: 7,108.19703
Timestep Collection Time: 3.88223
Timestep Consumption Time: 3.15303
PPO Batch Consumption Time: 0.23022
Total Iteration Time: 7.03526
Cumulative Model Updates: 140,852
Cumulative Timesteps: 1,148,698,562
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60642
Policy Entropy: 4.31544
Value Function Loss: 0.00292
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03392
Policy Update Magnitude: 1.08143
Value Function Update Magnitude: 0.77468
Collected Steps per Second: 13,027.35766
Overall Steps per Second: 7,236.60586
Timestep Collection Time: 3.83900
Timestep Consumption Time: 3.07198
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.91097
Cumulative Model Updates: 140,861
Cumulative Timesteps: 1,148,748,574
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1148748574...
Checkpoint 1148748574 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80799
Policy Entropy: 4.30753
Value Function Loss: 0.00308
Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03697
Policy Update Magnitude: 1.07577
Value Function Update Magnitude: 0.78519
Collected Steps per Second: 13,017.98046
Overall Steps per Second: 7,293.94209
Timestep Collection Time: 3.84207
Timestep Consumption Time: 3.01513
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.85720
Cumulative Model Updates: 140,870
Cumulative Timesteps: 1,148,798,590
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.19910
Policy Entropy: 4.31016
Value Function Loss: 0.00289
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03557
Policy Update Magnitude: 1.06862
Value Function Update Magnitude: 0.79383
Collected Steps per Second: 13,017.14921
Overall Steps per Second: 7,170.78777
Timestep Collection Time: 3.84109
Timestep Consumption Time: 3.13165
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.97273
Cumulative Model Updates: 140,879
Cumulative Timesteps: 1,148,848,590
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1148848590...
Checkpoint 1148848590 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.41326
Policy Entropy: 4.31035
Value Function Loss: 0.00286
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03441
Policy Update Magnitude: 1.05463
Value Function Update Magnitude: 0.78831
Collected Steps per Second: 12,969.31913
Overall Steps per Second: 7,221.43349
Timestep Collection Time: 3.85679
Timestep Consumption Time: 3.06981
PPO Batch Consumption Time: 0.22779
Total Iteration Time: 6.92660
Cumulative Model Updates: 140,888
Cumulative Timesteps: 1,148,898,610
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19906
Policy Entropy: 4.31760
Value Function Loss: 0.00276
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03192
Policy Update Magnitude: 1.05372
Value Function Update Magnitude: 0.78071
Collected Steps per Second: 13,137.63863
Overall Steps per Second: 7,249.93271
Timestep Collection Time: 3.80814
Timestep Consumption Time: 3.09261
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.90075
Cumulative Model Updates: 140,897
Cumulative Timesteps: 1,148,948,640
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1148948640...
Checkpoint 1148948640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.31115
Policy Entropy: 4.32035
Value Function Loss: 0.00282
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03101
Policy Update Magnitude: 1.07138
Value Function Update Magnitude: 0.74744
Collected Steps per Second: 12,889.66063
Overall Steps per Second: 7,159.81525
Timestep Collection Time: 3.88110
Timestep Consumption Time: 3.10596
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.98705
Cumulative Model Updates: 140,906
Cumulative Timesteps: 1,148,998,666
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36972
Policy Entropy: 4.31746
Value Function Loss: 0.00281
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03202
Policy Update Magnitude: 1.06258
Value Function Update Magnitude: 0.73450
Collected Steps per Second: 12,982.36225
Overall Steps per Second: 7,163.65783
Timestep Collection Time: 3.85277
Timestep Consumption Time: 3.12942
PPO Batch Consumption Time: 0.23337
Total Iteration Time: 6.98219
Cumulative Model Updates: 140,915
Cumulative Timesteps: 1,149,048,684
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1149048684...
Checkpoint 1149048684 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.11804
Policy Entropy: 4.31963
Value Function Loss: 0.00273
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03470
Policy Update Magnitude: 1.05076
Value Function Update Magnitude: 0.75913
Collected Steps per Second: 13,063.89935
Overall Steps per Second: 7,199.34157
Timestep Collection Time: 3.82933
Timestep Consumption Time: 3.11936
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.94869
Cumulative Model Updates: 140,924
Cumulative Timesteps: 1,149,098,710
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.50236
Policy Entropy: 4.31704
Value Function Loss: 0.00272
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03397
Policy Update Magnitude: 1.04501
Value Function Update Magnitude: 0.76701
Collected Steps per Second: 13,144.24022
Overall Steps per Second: 7,242.00890
Timestep Collection Time: 3.80547
Timestep Consumption Time: 3.10145
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.90692
Cumulative Model Updates: 140,933
Cumulative Timesteps: 1,149,148,730
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1149148730...
Checkpoint 1149148730 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79999
Policy Entropy: 4.31757
Value Function Loss: 0.00271
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 1.04889
Value Function Update Magnitude: 0.76056
Collected Steps per Second: 13,123.99875
Overall Steps per Second: 7,267.45569
Timestep Collection Time: 3.81073
Timestep Consumption Time: 3.07091
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.88164
Cumulative Model Updates: 140,942
Cumulative Timesteps: 1,149,198,742
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.19548
Policy Entropy: 4.31475
Value Function Loss: 0.00280
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 1.05072
Value Function Update Magnitude: 0.75743
Collected Steps per Second: 13,127.94639
Overall Steps per Second: 7,215.92535
Timestep Collection Time: 3.80928
Timestep Consumption Time: 3.12095
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.93023
Cumulative Model Updates: 140,951
Cumulative Timesteps: 1,149,248,750
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1149248750...
Checkpoint 1149248750 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58486
Policy Entropy: 4.31507
Value Function Loss: 0.00277
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03030
Policy Update Magnitude: 1.05065
Value Function Update Magnitude: 0.77788
Collected Steps per Second: 12,976.64075
Overall Steps per Second: 7,175.21638
Timestep Collection Time: 3.85570
Timestep Consumption Time: 3.11747
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.97317
Cumulative Model Updates: 140,960
Cumulative Timesteps: 1,149,298,784
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.83304
Policy Entropy: 4.30888
Value Function Loss: 0.00284
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03326
Policy Update Magnitude: 1.06330
Value Function Update Magnitude: 0.77806
Collected Steps per Second: 12,891.15347
Overall Steps per Second: 7,253.41026
Timestep Collection Time: 3.88080
Timestep Consumption Time: 3.01637
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.89717
Cumulative Model Updates: 140,969
Cumulative Timesteps: 1,149,348,812
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1149348812...
Checkpoint 1149348812 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.10940
Policy Entropy: 4.31331
Value Function Loss: 0.00275
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03443
Policy Update Magnitude: 1.06639
Value Function Update Magnitude: 0.76753
Collected Steps per Second: 13,008.02348
Overall Steps per Second: 7,135.12033
Timestep Collection Time: 3.84378
Timestep Consumption Time: 3.16381
PPO Batch Consumption Time: 0.22963
Total Iteration Time: 7.00759
Cumulative Model Updates: 140,978
Cumulative Timesteps: 1,149,398,812
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.16914
Policy Entropy: 4.31212
Value Function Loss: 0.00282
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03431
Policy Update Magnitude: 1.05402
Value Function Update Magnitude: 0.77184
Collected Steps per Second: 12,809.85485
Overall Steps per Second: 7,165.55947
Timestep Collection Time: 3.90559
Timestep Consumption Time: 3.07642
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.98201
Cumulative Model Updates: 140,987
Cumulative Timesteps: 1,149,448,842
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1149448842...
Checkpoint 1149448842 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.87246
Policy Entropy: 4.31432
Value Function Loss: 0.00278
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03242
Policy Update Magnitude: 1.04932
Value Function Update Magnitude: 0.80402
Collected Steps per Second: 13,124.34418
Overall Steps per Second: 7,229.37514
Timestep Collection Time: 3.81200
Timestep Consumption Time: 3.10838
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.92038
Cumulative Model Updates: 140,996
Cumulative Timesteps: 1,149,498,872
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.63425
Policy Entropy: 4.31456
Value Function Loss: 0.00273
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03258
Policy Update Magnitude: 1.04379
Value Function Update Magnitude: 0.78268
Collected Steps per Second: 12,876.46756
Overall Steps per Second: 7,158.56173
Timestep Collection Time: 3.88492
Timestep Consumption Time: 3.10308
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.98800
Cumulative Model Updates: 141,005
Cumulative Timesteps: 1,149,548,896
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1149548896...
Checkpoint 1149548896 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.92859
Policy Entropy: 4.31441
Value Function Loss: 0.00279
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 1.04782
Value Function Update Magnitude: 0.76647
Collected Steps per Second: 12,964.56073
Overall Steps per Second: 7,225.32079
Timestep Collection Time: 3.85759
Timestep Consumption Time: 3.06418
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.92177
Cumulative Model Updates: 141,014
Cumulative Timesteps: 1,149,598,908
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19286
Policy Entropy: 4.31447
Value Function Loss: 0.00284
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03584
Policy Update Magnitude: 1.03407
Value Function Update Magnitude: 0.78360
Collected Steps per Second: 13,236.09579
Overall Steps per Second: 7,255.63844
Timestep Collection Time: 3.77997
Timestep Consumption Time: 3.11564
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.89560
Cumulative Model Updates: 141,023
Cumulative Timesteps: 1,149,648,940
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1149648940...
Checkpoint 1149648940 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.51926
Policy Entropy: 4.31238
Value Function Loss: 0.00284
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03521
Policy Update Magnitude: 1.03262
Value Function Update Magnitude: 0.78622
Collected Steps per Second: 12,828.89691
Overall Steps per Second: 7,153.88144
Timestep Collection Time: 3.89963
Timestep Consumption Time: 3.09349
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.99313
Cumulative Model Updates: 141,032
Cumulative Timesteps: 1,149,698,968
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.74838
Policy Entropy: 4.31370
Value Function Loss: 0.00279
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03133
Policy Update Magnitude: 1.02036
Value Function Update Magnitude: 0.76083
Collected Steps per Second: 12,811.04417
Overall Steps per Second: 7,094.59367
Timestep Collection Time: 3.90398
Timestep Consumption Time: 3.14562
PPO Batch Consumption Time: 0.23619
Total Iteration Time: 7.04959
Cumulative Model Updates: 141,041
Cumulative Timesteps: 1,149,748,982
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1149748982...
Checkpoint 1149748982 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.50892
Policy Entropy: 4.31758
Value Function Loss: 0.00274
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 1.01016
Value Function Update Magnitude: 0.76095
Collected Steps per Second: 13,177.92229
Overall Steps per Second: 7,247.84783
Timestep Collection Time: 3.79635
Timestep Consumption Time: 3.10611
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.90246
Cumulative Model Updates: 141,050
Cumulative Timesteps: 1,149,799,010
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.68323
Policy Entropy: 4.31768
Value Function Loss: 0.00280
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03100
Policy Update Magnitude: 1.01815
Value Function Update Magnitude: 0.75922
Collected Steps per Second: 12,790.10205
Overall Steps per Second: 7,116.72517
Timestep Collection Time: 3.91224
Timestep Consumption Time: 3.11880
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 7.03104
Cumulative Model Updates: 141,059
Cumulative Timesteps: 1,149,849,048
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1149849048...
Checkpoint 1149849048 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.02255
Policy Entropy: 4.31736
Value Function Loss: 0.00286
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03386
Policy Update Magnitude: 1.04968
Value Function Update Magnitude: 0.75765
Collected Steps per Second: 12,724.75697
Overall Steps per Second: 7,121.43618
Timestep Collection Time: 3.93013
Timestep Consumption Time: 3.09233
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 7.02246
Cumulative Model Updates: 141,068
Cumulative Timesteps: 1,149,899,058
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42783
Policy Entropy: 4.31373
Value Function Loss: 0.00289
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03489
Policy Update Magnitude: 1.06038
Value Function Update Magnitude: 0.76502
Collected Steps per Second: 13,258.75085
Overall Steps per Second: 7,292.03115
Timestep Collection Time: 3.77275
Timestep Consumption Time: 3.08706
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.85982
Cumulative Model Updates: 141,077
Cumulative Timesteps: 1,149,949,080
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1149949080...
Checkpoint 1149949080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79353
Policy Entropy: 4.31711
Value Function Loss: 0.00280
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03611
Policy Update Magnitude: 1.05134
Value Function Update Magnitude: 0.76891
Collected Steps per Second: 12,918.04717
Overall Steps per Second: 7,174.49934
Timestep Collection Time: 3.87148
Timestep Consumption Time: 3.09932
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.97080
Cumulative Model Updates: 141,086
Cumulative Timesteps: 1,149,999,092
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06105
Policy Entropy: 4.31547
Value Function Loss: 0.00273
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03290
Policy Update Magnitude: 1.04571
Value Function Update Magnitude: 0.74659
Collected Steps per Second: 13,005.07973
Overall Steps per Second: 7,220.93254
Timestep Collection Time: 3.84527
Timestep Consumption Time: 3.08015
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.92542
Cumulative Model Updates: 141,095
Cumulative Timesteps: 1,150,049,100
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1150049100...
Checkpoint 1150049100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70192
Policy Entropy: 4.31731
Value Function Loss: 0.00275
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03250
Policy Update Magnitude: 1.06172
Value Function Update Magnitude: 0.73676
Collected Steps per Second: 13,155.47964
Overall Steps per Second: 7,210.64612
Timestep Collection Time: 3.80283
Timestep Consumption Time: 3.13525
PPO Batch Consumption Time: 0.23053
Total Iteration Time: 6.93807
Cumulative Model Updates: 141,104
Cumulative Timesteps: 1,150,099,128
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.38259
Policy Entropy: 4.31957
Value Function Loss: 0.00270
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03150
Policy Update Magnitude: 1.07143
Value Function Update Magnitude: 0.75567
Collected Steps per Second: 12,911.97844
Overall Steps per Second: 7,160.74295
Timestep Collection Time: 3.87408
Timestep Consumption Time: 3.11151
PPO Batch Consumption Time: 0.22779
Total Iteration Time: 6.98559
Cumulative Model Updates: 141,113
Cumulative Timesteps: 1,150,149,150
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1150149150...
Checkpoint 1150149150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04584
Policy Entropy: 4.31717
Value Function Loss: 0.00293
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03203
Policy Update Magnitude: 1.09194
Value Function Update Magnitude: 0.79222
Collected Steps per Second: 12,836.86937
Overall Steps per Second: 7,158.32076
Timestep Collection Time: 3.89784
Timestep Consumption Time: 3.09207
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.98991
Cumulative Model Updates: 141,122
Cumulative Timesteps: 1,150,199,186
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.63069
Policy Entropy: 4.31316
Value Function Loss: 0.00298
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03427
Policy Update Magnitude: 1.10521
Value Function Update Magnitude: 0.81631
Collected Steps per Second: 13,407.38264
Overall Steps per Second: 7,308.46124
Timestep Collection Time: 3.73063
Timestep Consumption Time: 3.11322
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.84385
Cumulative Model Updates: 141,131
Cumulative Timesteps: 1,150,249,204
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1150249204...
Checkpoint 1150249204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.73554
Policy Entropy: 4.30978
Value Function Loss: 0.00296
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03679
Policy Update Magnitude: 1.10156
Value Function Update Magnitude: 0.81719
Collected Steps per Second: 13,033.68165
Overall Steps per Second: 7,200.79285
Timestep Collection Time: 3.83744
Timestep Consumption Time: 3.10846
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.94590
Cumulative Model Updates: 141,140
Cumulative Timesteps: 1,150,299,220
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79442
Policy Entropy: 4.31011
Value Function Loss: 0.00280
Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03853
Policy Update Magnitude: 1.08083
Value Function Update Magnitude: 0.78874
Collected Steps per Second: 12,683.20338
Overall Steps per Second: 7,197.32106
Timestep Collection Time: 3.94269
Timestep Consumption Time: 3.00517
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.94786
Cumulative Model Updates: 141,149
Cumulative Timesteps: 1,150,349,226
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1150349226...
Checkpoint 1150349226 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.03016
Policy Entropy: 4.31501
Value Function Loss: 0.00262
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 1.04839
Value Function Update Magnitude: 0.77956
Collected Steps per Second: 12,754.39448
Overall Steps per Second: 7,124.72487
Timestep Collection Time: 3.92084
Timestep Consumption Time: 3.09809
PPO Batch Consumption Time: 0.22782
Total Iteration Time: 7.01894
Cumulative Model Updates: 141,158
Cumulative Timesteps: 1,150,399,234
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04042
Policy Entropy: 4.31802
Value Function Loss: 0.00267
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03220
Policy Update Magnitude: 1.03374
Value Function Update Magnitude: 0.74747
Collected Steps per Second: 12,977.63523
Overall Steps per Second: 7,160.42008
Timestep Collection Time: 3.85355
Timestep Consumption Time: 3.13067
PPO Batch Consumption Time: 0.23023
Total Iteration Time: 6.98423
Cumulative Model Updates: 141,167
Cumulative Timesteps: 1,150,449,244
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1150449244...
Checkpoint 1150449244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13542
Policy Entropy: 4.31559
Value Function Loss: 0.00276
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03377
Policy Update Magnitude: 1.05188
Value Function Update Magnitude: 0.74629
Collected Steps per Second: 12,793.08634
Overall Steps per Second: 7,255.16000
Timestep Collection Time: 3.91008
Timestep Consumption Time: 2.98460
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.89468
Cumulative Model Updates: 141,176
Cumulative Timesteps: 1,150,499,266
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.06865
Policy Entropy: 4.31690
Value Function Loss: 0.00300
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03463
Policy Update Magnitude: 1.06752
Value Function Update Magnitude: 0.75719
Collected Steps per Second: 12,864.52687
Overall Steps per Second: 7,165.63887
Timestep Collection Time: 3.88681
Timestep Consumption Time: 3.09121
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.97802
Cumulative Model Updates: 141,185
Cumulative Timesteps: 1,150,549,268
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1150549268...
Checkpoint 1150549268 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07811
Policy Entropy: 4.31514
Value Function Loss: 0.00294
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03336
Policy Update Magnitude: 1.05943
Value Function Update Magnitude: 0.78032
Collected Steps per Second: 12,643.44183
Overall Steps per Second: 7,115.16049
Timestep Collection Time: 3.95747
Timestep Consumption Time: 3.07484
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 7.03231
Cumulative Model Updates: 141,194
Cumulative Timesteps: 1,150,599,304
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.70805
Policy Entropy: 4.31629
Value Function Loss: 0.00294
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03147
Policy Update Magnitude: 1.04725
Value Function Update Magnitude: 0.76287
Collected Steps per Second: 12,890.43650
Overall Steps per Second: 7,272.66158
Timestep Collection Time: 3.87884
Timestep Consumption Time: 2.99622
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.87506
Cumulative Model Updates: 141,203
Cumulative Timesteps: 1,150,649,304
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1150649304...
Checkpoint 1150649304 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03675
Policy Entropy: 4.31726
Value Function Loss: 0.00275
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03034
Policy Update Magnitude: 1.04198
Value Function Update Magnitude: 0.74354
Collected Steps per Second: 12,917.10195
Overall Steps per Second: 7,165.02266
Timestep Collection Time: 3.87316
Timestep Consumption Time: 3.10937
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.98253
Cumulative Model Updates: 141,212
Cumulative Timesteps: 1,150,699,334
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.29527
Policy Entropy: 4.31526
Value Function Loss: 0.00282
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 1.02920
Value Function Update Magnitude: 0.74707
Collected Steps per Second: 12,839.40715
Overall Steps per Second: 7,168.16999
Timestep Collection Time: 3.89691
Timestep Consumption Time: 3.08312
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.98002
Cumulative Model Updates: 141,221
Cumulative Timesteps: 1,150,749,368
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1150749368...
Checkpoint 1150749368 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.55915
Policy Entropy: 4.31999
Value Function Loss: 0.00271
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03331
Policy Update Magnitude: 1.02011
Value Function Update Magnitude: 0.73756
Collected Steps per Second: 12,800.86725
Overall Steps per Second: 7,185.89083
Timestep Collection Time: 3.90974
Timestep Consumption Time: 3.05502
PPO Batch Consumption Time: 0.23018
Total Iteration Time: 6.96476
Cumulative Model Updates: 141,230
Cumulative Timesteps: 1,150,799,416
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.74713
Policy Entropy: 4.32399
Value Function Loss: 0.00270
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 1.01540
Value Function Update Magnitude: 0.74326
Collected Steps per Second: 12,815.97271
Overall Steps per Second: 7,141.18318
Timestep Collection Time: 3.90169
Timestep Consumption Time: 3.10051
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 7.00220
Cumulative Model Updates: 141,239
Cumulative Timesteps: 1,150,849,420
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1150849420...
Checkpoint 1150849420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.44860
Policy Entropy: 4.32242
Value Function Loss: 0.00273
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02960
Policy Update Magnitude: 1.02136
Value Function Update Magnitude: 0.74685
Collected Steps per Second: 11,230.51994
Overall Steps per Second: 6,506.78747
Timestep Collection Time: 4.45625
Timestep Consumption Time: 3.23510
PPO Batch Consumption Time: 0.24272
Total Iteration Time: 7.69135
Cumulative Model Updates: 141,248
Cumulative Timesteps: 1,150,899,466
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79427
Policy Entropy: 4.31845
Value Function Loss: 0.00269
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03073
Policy Update Magnitude: 1.02602
Value Function Update Magnitude: 0.76647
Collected Steps per Second: 12,123.25154
Overall Steps per Second: 6,831.61292
Timestep Collection Time: 4.12596
Timestep Consumption Time: 3.19589
PPO Batch Consumption Time: 0.23560
Total Iteration Time: 7.32184
Cumulative Model Updates: 141,257
Cumulative Timesteps: 1,150,949,486
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1150949486...
Checkpoint 1150949486 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.71141
Policy Entropy: 4.31637
Value Function Loss: 0.00275
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03077
Policy Update Magnitude: 1.03824
Value Function Update Magnitude: 0.77088
Collected Steps per Second: 12,326.08958
Overall Steps per Second: 6,912.24770
Timestep Collection Time: 4.05692
Timestep Consumption Time: 3.17748
PPO Batch Consumption Time: 0.23521
Total Iteration Time: 7.23441
Cumulative Model Updates: 141,266
Cumulative Timesteps: 1,150,999,492
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.73109
Policy Entropy: 4.31964
Value Function Loss: 0.00272
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02801
Policy Update Magnitude: 1.03539
Value Function Update Magnitude: 0.77454
Collected Steps per Second: 11,553.13930
Overall Steps per Second: 6,790.79543
Timestep Collection Time: 4.32887
Timestep Consumption Time: 3.03581
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 7.36467
Cumulative Model Updates: 141,275
Cumulative Timesteps: 1,151,049,504
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1151049504...
Checkpoint 1151049504 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.18297
Policy Entropy: 4.31938
Value Function Loss: 0.00280
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03128
Policy Update Magnitude: 1.05406
Value Function Update Magnitude: 0.76610
Collected Steps per Second: 12,821.15947
Overall Steps per Second: 7,102.71372
Timestep Collection Time: 3.89980
Timestep Consumption Time: 3.13976
PPO Batch Consumption Time: 0.23146
Total Iteration Time: 7.03956
Cumulative Model Updates: 141,284
Cumulative Timesteps: 1,151,099,504
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84598
Policy Entropy: 4.32184
Value Function Loss: 0.00281
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 1.05488
Value Function Update Magnitude: 0.73402
Collected Steps per Second: 12,679.16438
Overall Steps per Second: 6,965.19738
Timestep Collection Time: 3.94774
Timestep Consumption Time: 3.23856
PPO Batch Consumption Time: 0.23842
Total Iteration Time: 7.18630
Cumulative Model Updates: 141,293
Cumulative Timesteps: 1,151,149,558
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1151149558...
Checkpoint 1151149558 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.62779
Policy Entropy: 4.32392
Value Function Loss: 0.00263
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 1.03970
Value Function Update Magnitude: 0.70009
Collected Steps per Second: 12,667.98824
Overall Steps per Second: 7,153.51202
Timestep Collection Time: 3.94854
Timestep Consumption Time: 3.04383
PPO Batch Consumption Time: 0.22918
Total Iteration Time: 6.99237
Cumulative Model Updates: 141,302
Cumulative Timesteps: 1,151,199,578
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.44730
Policy Entropy: 4.32361
Value Function Loss: 0.00263
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 1.01312
Value Function Update Magnitude: 0.70700
Collected Steps per Second: 11,965.71785
Overall Steps per Second: 6,700.41911
Timestep Collection Time: 4.18128
Timestep Consumption Time: 3.28572
PPO Batch Consumption Time: 0.24017
Total Iteration Time: 7.46700
Cumulative Model Updates: 141,311
Cumulative Timesteps: 1,151,249,610
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1151249610...
Checkpoint 1151249610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.11841
Policy Entropy: 4.31870
Value Function Loss: 0.00255
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02948
Policy Update Magnitude: 1.01684
Value Function Update Magnitude: 0.71216
Collected Steps per Second: 12,356.84251
Overall Steps per Second: 6,854.40017
Timestep Collection Time: 4.04747
Timestep Consumption Time: 3.24915
PPO Batch Consumption Time: 0.24288
Total Iteration Time: 7.29663
Cumulative Model Updates: 141,320
Cumulative Timesteps: 1,151,299,624
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58504
Policy Entropy: 4.31890
Value Function Loss: 0.00267
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 1.03586
Value Function Update Magnitude: 0.73627
Collected Steps per Second: 11,712.92872
Overall Steps per Second: 6,857.48921
Timestep Collection Time: 4.27049
Timestep Consumption Time: 3.02372
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 7.29421
Cumulative Model Updates: 141,329
Cumulative Timesteps: 1,151,349,644
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1151349644...
Checkpoint 1151349644 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.17123
Policy Entropy: 4.32112
Value Function Loss: 0.00262
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03057
Policy Update Magnitude: 1.04417
Value Function Update Magnitude: 0.73739
Collected Steps per Second: 12,808.83202
Overall Steps per Second: 7,073.61718
Timestep Collection Time: 3.90637
Timestep Consumption Time: 3.16724
PPO Batch Consumption Time: 0.23482
Total Iteration Time: 7.07361
Cumulative Model Updates: 141,338
Cumulative Timesteps: 1,151,399,680
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79734
Policy Entropy: 4.32026
Value Function Loss: 0.00269
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03072
Policy Update Magnitude: 1.06370
Value Function Update Magnitude: 0.73238
Collected Steps per Second: 11,314.08248
Overall Steps per Second: 6,508.96927
Timestep Collection Time: 4.41927
Timestep Consumption Time: 3.26244
PPO Batch Consumption Time: 0.24395
Total Iteration Time: 7.68171
Cumulative Model Updates: 141,347
Cumulative Timesteps: 1,151,449,680
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1151449680...
Checkpoint 1151449680 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.72816
Policy Entropy: 4.32029
Value Function Loss: 0.00259
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 1.06565
Value Function Update Magnitude: 0.73506
Collected Steps per Second: 12,657.09209
Overall Steps per Second: 7,112.01877
Timestep Collection Time: 3.95209
Timestep Consumption Time: 3.08135
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 7.03345
Cumulative Model Updates: 141,356
Cumulative Timesteps: 1,151,499,702
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71139
Policy Entropy: 4.31966
Value Function Loss: 0.00268
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03315
Policy Update Magnitude: 1.06894
Value Function Update Magnitude: 0.73555
Collected Steps per Second: 12,447.20275
Overall Steps per Second: 6,983.93558
Timestep Collection Time: 4.01761
Timestep Consumption Time: 3.14282
PPO Batch Consumption Time: 0.23107
Total Iteration Time: 7.16043
Cumulative Model Updates: 141,365
Cumulative Timesteps: 1,151,549,710
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1151549710...
Checkpoint 1151549710 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.94346
Policy Entropy: 4.32025
Value Function Loss: 0.00269
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03912
Policy Update Magnitude: 1.07573
Value Function Update Magnitude: 0.72611
Collected Steps per Second: 12,598.65613
Overall Steps per Second: 7,169.58233
Timestep Collection Time: 3.96884
Timestep Consumption Time: 3.00535
PPO Batch Consumption Time: 0.22926
Total Iteration Time: 6.97419
Cumulative Model Updates: 141,374
Cumulative Timesteps: 1,151,599,712
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.22395
Policy Entropy: 4.32414
Value Function Loss: 0.00270
Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03941
Policy Update Magnitude: 1.07935
Value Function Update Magnitude: 0.71644
Collected Steps per Second: 12,787.46712
Overall Steps per Second: 7,110.17514
Timestep Collection Time: 3.91102
Timestep Consumption Time: 3.12285
PPO Batch Consumption Time: 0.22947
Total Iteration Time: 7.03386
Cumulative Model Updates: 141,383
Cumulative Timesteps: 1,151,649,724
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1151649724...
Checkpoint 1151649724 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44553
Policy Entropy: 4.32438
Value Function Loss: 0.00280
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03611
Policy Update Magnitude: 1.07931
Value Function Update Magnitude: 0.74969
Collected Steps per Second: 12,643.49493
Overall Steps per Second: 7,039.24577
Timestep Collection Time: 3.95524
Timestep Consumption Time: 3.14893
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 7.10417
Cumulative Model Updates: 141,392
Cumulative Timesteps: 1,151,699,732
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.37662
Policy Entropy: 4.32406
Value Function Loss: 0.00276
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03339
Policy Update Magnitude: 1.09157
Value Function Update Magnitude: 0.77719
Collected Steps per Second: 12,824.32397
Overall Steps per Second: 7,149.78585
Timestep Collection Time: 3.89915
Timestep Consumption Time: 3.09462
PPO Batch Consumption Time: 0.23656
Total Iteration Time: 6.99378
Cumulative Model Updates: 141,401
Cumulative Timesteps: 1,151,749,736
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1151749736...
Checkpoint 1151749736 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53649
Policy Entropy: 4.31865
Value Function Loss: 0.00286
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03274
Policy Update Magnitude: 1.09409
Value Function Update Magnitude: 0.78434
Collected Steps per Second: 11,723.03241
Overall Steps per Second: 6,582.23873
Timestep Collection Time: 4.26681
Timestep Consumption Time: 3.33242
PPO Batch Consumption Time: 0.24039
Total Iteration Time: 7.59924
Cumulative Model Updates: 141,410
Cumulative Timesteps: 1,151,799,756
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.48243
Policy Entropy: 4.31583
Value Function Loss: 0.00276
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03169
Policy Update Magnitude: 1.09059
Value Function Update Magnitude: 0.77687
Collected Steps per Second: 12,692.20980
Overall Steps per Second: 7,068.61485
Timestep Collection Time: 3.94163
Timestep Consumption Time: 3.13585
PPO Batch Consumption Time: 0.23063
Total Iteration Time: 7.07748
Cumulative Model Updates: 141,419
Cumulative Timesteps: 1,151,849,784
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1151849784...
Checkpoint 1151849784 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25340
Policy Entropy: 4.31451
Value Function Loss: 0.00271
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03204
Policy Update Magnitude: 1.09020
Value Function Update Magnitude: 0.76616
Collected Steps per Second: 12,758.43969
Overall Steps per Second: 7,173.28148
Timestep Collection Time: 3.92133
Timestep Consumption Time: 3.05317
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.97449
Cumulative Model Updates: 141,428
Cumulative Timesteps: 1,151,899,814
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.93210
Policy Entropy: 4.31946
Value Function Loss: 0.00272
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 1.07700
Value Function Update Magnitude: 0.74115
Collected Steps per Second: 12,945.43664
Overall Steps per Second: 7,177.23930
Timestep Collection Time: 3.86499
Timestep Consumption Time: 3.10621
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.97120
Cumulative Model Updates: 141,437
Cumulative Timesteps: 1,151,949,848
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1151949848...
Checkpoint 1151949848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.08716
Policy Entropy: 4.31760
Value Function Loss: 0.00279
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03264
Policy Update Magnitude: 1.08525
Value Function Update Magnitude: 0.76566
Collected Steps per Second: 12,829.76185
Overall Steps per Second: 7,114.80353
Timestep Collection Time: 3.89937
Timestep Consumption Time: 3.13217
PPO Batch Consumption Time: 0.22987
Total Iteration Time: 7.03154
Cumulative Model Updates: 141,446
Cumulative Timesteps: 1,151,999,876
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.36268
Policy Entropy: 4.31554
Value Function Loss: 0.00288
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03359
Policy Update Magnitude: 1.09403
Value Function Update Magnitude: 0.78313
Collected Steps per Second: 13,091.62783
Overall Steps per Second: 7,222.85177
Timestep Collection Time: 3.82000
Timestep Consumption Time: 3.10386
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.92386
Cumulative Model Updates: 141,455
Cumulative Timesteps: 1,152,049,886
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1152049886...
Checkpoint 1152049886 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84245
Policy Entropy: 4.31436
Value Function Loss: 0.00290
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03352
Policy Update Magnitude: 1.08857
Value Function Update Magnitude: 0.77104
Collected Steps per Second: 12,766.98236
Overall Steps per Second: 7,139.02706
Timestep Collection Time: 3.91855
Timestep Consumption Time: 3.08913
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 7.00768
Cumulative Model Updates: 141,464
Cumulative Timesteps: 1,152,099,914
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80161
Policy Entropy: 4.31300
Value Function Loss: 0.00290
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03372
Policy Update Magnitude: 1.08695
Value Function Update Magnitude: 0.77934
Collected Steps per Second: 12,721.34262
Overall Steps per Second: 6,977.95741
Timestep Collection Time: 3.93480
Timestep Consumption Time: 3.23864
PPO Batch Consumption Time: 0.24087
Total Iteration Time: 7.17345
Cumulative Model Updates: 141,473
Cumulative Timesteps: 1,152,149,970
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1152149970...
Checkpoint 1152149970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41386
Policy Entropy: 4.31539
Value Function Loss: 0.00287
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03577
Policy Update Magnitude: 1.06843
Value Function Update Magnitude: 0.77616
Collected Steps per Second: 13,266.32054
Overall Steps per Second: 7,244.48173
Timestep Collection Time: 3.76985
Timestep Consumption Time: 3.13361
PPO Batch Consumption Time: 0.23052
Total Iteration Time: 6.90346
Cumulative Model Updates: 141,482
Cumulative Timesteps: 1,152,199,982
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.21717
Policy Entropy: 4.31721
Value Function Loss: 0.00287
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03784
Policy Update Magnitude: 1.08435
Value Function Update Magnitude: 0.77408
Collected Steps per Second: 12,850.15490
Overall Steps per Second: 7,148.04660
Timestep Collection Time: 3.89225
Timestep Consumption Time: 3.10491
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.99716
Cumulative Model Updates: 141,491
Cumulative Timesteps: 1,152,249,998
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1152249998...
Checkpoint 1152249998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.96016
Policy Entropy: 4.32261
Value Function Loss: 0.00269
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03661
Policy Update Magnitude: 1.06065
Value Function Update Magnitude: 0.76451
Collected Steps per Second: 12,867.97652
Overall Steps per Second: 7,073.42821
Timestep Collection Time: 3.88561
Timestep Consumption Time: 3.18309
PPO Batch Consumption Time: 0.23545
Total Iteration Time: 7.06871
Cumulative Model Updates: 141,500
Cumulative Timesteps: 1,152,299,998
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.38833
Policy Entropy: 4.32770
Value Function Loss: 0.00264
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03178
Policy Update Magnitude: 1.05470
Value Function Update Magnitude: 0.77379
Collected Steps per Second: 12,656.08411
Overall Steps per Second: 7,027.59254
Timestep Collection Time: 3.95146
Timestep Consumption Time: 3.16478
PPO Batch Consumption Time: 0.23444
Total Iteration Time: 7.11624
Cumulative Model Updates: 141,509
Cumulative Timesteps: 1,152,350,008
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1152350008...
Checkpoint 1152350008 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.07157
Policy Entropy: 4.32414
Value Function Loss: 0.00262
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 1.05653
Value Function Update Magnitude: 0.77728
Collected Steps per Second: 11,783.26678
Overall Steps per Second: 6,775.98480
Timestep Collection Time: 4.24415
Timestep Consumption Time: 3.13632
PPO Batch Consumption Time: 0.23078
Total Iteration Time: 7.38048
Cumulative Model Updates: 141,518
Cumulative Timesteps: 1,152,400,018
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.58962
Policy Entropy: 4.32054
Value Function Loss: 0.00267
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 1.06140
Value Function Update Magnitude: 0.75432
Collected Steps per Second: 12,200.60223
Overall Steps per Second: 6,963.02199
Timestep Collection Time: 4.10029
Timestep Consumption Time: 3.08423
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 7.18452
Cumulative Model Updates: 141,527
Cumulative Timesteps: 1,152,450,044
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1152450044...
Checkpoint 1152450044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69328
Policy Entropy: 4.31561
Value Function Loss: 0.00270
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03286
Policy Update Magnitude: 1.04483
Value Function Update Magnitude: 0.75332
Collected Steps per Second: 12,450.88830
Overall Steps per Second: 6,889.67634
Timestep Collection Time: 4.01819
Timestep Consumption Time: 3.24340
PPO Batch Consumption Time: 0.24106
Total Iteration Time: 7.26159
Cumulative Model Updates: 141,536
Cumulative Timesteps: 1,152,500,074
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44562
Policy Entropy: 4.32086
Value Function Loss: 0.00263
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03326
Policy Update Magnitude: 1.04081
Value Function Update Magnitude: 0.75817
Collected Steps per Second: 11,855.41231
Overall Steps per Second: 6,779.73286
Timestep Collection Time: 4.22035
Timestep Consumption Time: 3.15959
PPO Batch Consumption Time: 0.23379
Total Iteration Time: 7.37994
Cumulative Model Updates: 141,545
Cumulative Timesteps: 1,152,550,108
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1152550108...
Checkpoint 1152550108 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75683
Policy Entropy: 4.32556
Value Function Loss: 0.00262
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03362
Policy Update Magnitude: 1.03938
Value Function Update Magnitude: 0.74328
Collected Steps per Second: 12,795.96389
Overall Steps per Second: 7,219.20865
Timestep Collection Time: 3.90998
Timestep Consumption Time: 3.02042
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.93040
Cumulative Model Updates: 141,554
Cumulative Timesteps: 1,152,600,140
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.48460
Policy Entropy: 4.33005
Value Function Loss: 0.00268
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03192
Policy Update Magnitude: 1.05110
Value Function Update Magnitude: 0.75235
Collected Steps per Second: 13,006.75147
Overall Steps per Second: 7,194.69356
Timestep Collection Time: 3.84693
Timestep Consumption Time: 3.10764
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.95457
Cumulative Model Updates: 141,563
Cumulative Timesteps: 1,152,650,176
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1152650176...
Checkpoint 1152650176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.29141
Policy Entropy: 4.32836
Value Function Loss: 0.00276
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03295
Policy Update Magnitude: 1.06964
Value Function Update Magnitude: 0.76288
Collected Steps per Second: 12,627.29702
Overall Steps per Second: 7,098.17948
Timestep Collection Time: 3.96221
Timestep Consumption Time: 3.08636
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 7.04857
Cumulative Model Updates: 141,572
Cumulative Timesteps: 1,152,700,208
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87163
Policy Entropy: 4.32638
Value Function Loss: 0.00270
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 1.07201
Value Function Update Magnitude: 0.75377
Collected Steps per Second: 12,958.96418
Overall Steps per Second: 7,273.52913
Timestep Collection Time: 3.86127
Timestep Consumption Time: 3.01820
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.87947
Cumulative Model Updates: 141,581
Cumulative Timesteps: 1,152,750,246
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1152750246...
Checkpoint 1152750246 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.58374
Policy Entropy: 4.32103
Value Function Loss: 0.00279
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03294
Policy Update Magnitude: 1.07606
Value Function Update Magnitude: 0.76192
Collected Steps per Second: 12,916.29453
Overall Steps per Second: 7,140.09548
Timestep Collection Time: 3.87154
Timestep Consumption Time: 3.13200
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 7.00355
Cumulative Model Updates: 141,590
Cumulative Timesteps: 1,152,800,252
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.67678
Policy Entropy: 4.32010
Value Function Loss: 0.00271
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03661
Policy Update Magnitude: 1.08376
Value Function Update Magnitude: 0.79433
Collected Steps per Second: 12,951.71670
Overall Steps per Second: 7,196.03750
Timestep Collection Time: 3.86049
Timestep Consumption Time: 3.08778
PPO Batch Consumption Time: 0.23132
Total Iteration Time: 6.94827
Cumulative Model Updates: 141,599
Cumulative Timesteps: 1,152,850,252
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1152850252...
Checkpoint 1152850252 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97854
Policy Entropy: 4.31646
Value Function Loss: 0.00279
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03690
Policy Update Magnitude: 1.09416
Value Function Update Magnitude: 0.77174
Collected Steps per Second: 12,858.98690
Overall Steps per Second: 7,232.99837
Timestep Collection Time: 3.89113
Timestep Consumption Time: 3.02661
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.91774
Cumulative Model Updates: 141,608
Cumulative Timesteps: 1,152,900,288
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56551
Policy Entropy: 4.31822
Value Function Loss: 0.00274
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03566
Policy Update Magnitude: 1.08447
Value Function Update Magnitude: 0.75386
Collected Steps per Second: 12,830.24606
Overall Steps per Second: 7,125.75356
Timestep Collection Time: 3.89954
Timestep Consumption Time: 3.12176
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 7.02129
Cumulative Model Updates: 141,617
Cumulative Timesteps: 1,152,950,320
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1152950320...
Checkpoint 1152950320 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.15261
Policy Entropy: 4.31764
Value Function Loss: 0.00283
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03705
Policy Update Magnitude: 1.08314
Value Function Update Magnitude: 0.73901
Collected Steps per Second: 12,878.19995
Overall Steps per Second: 7,181.23134
Timestep Collection Time: 3.88486
Timestep Consumption Time: 3.08191
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.96677
Cumulative Model Updates: 141,626
Cumulative Timesteps: 1,153,000,350
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.91202
Policy Entropy: 4.32180
Value Function Loss: 0.00281
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03642
Policy Update Magnitude: 1.08284
Value Function Update Magnitude: 0.71728
Collected Steps per Second: 13,135.36004
Overall Steps per Second: 7,215.01824
Timestep Collection Time: 3.80956
Timestep Consumption Time: 3.12597
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 6.93553
Cumulative Model Updates: 141,635
Cumulative Timesteps: 1,153,050,390
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1153050390...
Checkpoint 1153050390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.98570
Policy Entropy: 4.32221
Value Function Loss: 0.00285
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03446
Policy Update Magnitude: 1.06880
Value Function Update Magnitude: 0.73073
Collected Steps per Second: 12,916.54168
Overall Steps per Second: 7,148.41638
Timestep Collection Time: 3.87178
Timestep Consumption Time: 3.12418
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.99596
Cumulative Model Updates: 141,644
Cumulative Timesteps: 1,153,100,400
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.47096
Policy Entropy: 4.32019
Value Function Loss: 0.00292
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03391
Policy Update Magnitude: 1.07861
Value Function Update Magnitude: 0.75724
Collected Steps per Second: 12,721.70291
Overall Steps per Second: 7,128.62568
Timestep Collection Time: 3.93249
Timestep Consumption Time: 3.08541
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 7.01790
Cumulative Model Updates: 141,653
Cumulative Timesteps: 1,153,150,428
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1153150428...
Checkpoint 1153150428 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35843
Policy Entropy: 4.31951
Value Function Loss: 0.00285
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03561
Policy Update Magnitude: 1.07030
Value Function Update Magnitude: 0.75545
Collected Steps per Second: 13,041.15911
Overall Steps per Second: 7,142.45108
Timestep Collection Time: 3.83724
Timestep Consumption Time: 3.16904
PPO Batch Consumption Time: 0.23015
Total Iteration Time: 7.00628
Cumulative Model Updates: 141,662
Cumulative Timesteps: 1,153,200,470
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80004
Policy Entropy: 4.32187
Value Function Loss: 0.00281
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03396
Policy Update Magnitude: 1.06415
Value Function Update Magnitude: 0.72235
Collected Steps per Second: 12,791.32085
Overall Steps per Second: 7,109.17758
Timestep Collection Time: 3.90984
Timestep Consumption Time: 3.12501
PPO Batch Consumption Time: 0.22983
Total Iteration Time: 7.03485
Cumulative Model Updates: 141,671
Cumulative Timesteps: 1,153,250,482
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1153250482...
Checkpoint 1153250482 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.70095
Policy Entropy: 4.32083
Value Function Loss: 0.00271
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03238
Policy Update Magnitude: 1.05122
Value Function Update Magnitude: 0.71882
Collected Steps per Second: 12,981.99229
Overall Steps per Second: 7,211.94851
Timestep Collection Time: 3.85211
Timestep Consumption Time: 3.08194
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.93405
Cumulative Model Updates: 141,680
Cumulative Timesteps: 1,153,300,490
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.88355
Policy Entropy: 4.32088
Value Function Loss: 0.00276
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 1.04840
Value Function Update Magnitude: 0.72503
Collected Steps per Second: 13,182.68016
Overall Steps per Second: 7,239.48054
Timestep Collection Time: 3.79361
Timestep Consumption Time: 3.11434
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.90795
Cumulative Model Updates: 141,689
Cumulative Timesteps: 1,153,350,500
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1153350500...
Checkpoint 1153350500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57805
Policy Entropy: 4.31806
Value Function Loss: 0.00281
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03384
Policy Update Magnitude: 1.06216
Value Function Update Magnitude: 0.75146
Collected Steps per Second: 12,874.00058
Overall Steps per Second: 7,150.39955
Timestep Collection Time: 3.88582
Timestep Consumption Time: 3.11044
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.99625
Cumulative Model Updates: 141,698
Cumulative Timesteps: 1,153,400,526
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41753
Policy Entropy: 4.32255
Value Function Loss: 0.00281
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 1.06970
Value Function Update Magnitude: 0.76849
Collected Steps per Second: 12,827.26021
Overall Steps per Second: 7,162.41601
Timestep Collection Time: 3.90122
Timestep Consumption Time: 3.08553
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.98675
Cumulative Model Updates: 141,707
Cumulative Timesteps: 1,153,450,568
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1153450568...
Checkpoint 1153450568 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10687
Policy Entropy: 4.32643
Value Function Loss: 0.00281
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03585
Policy Update Magnitude: 1.05426
Value Function Update Magnitude: 0.74836
Collected Steps per Second: 13,030.94922
Overall Steps per Second: 7,211.19491
Timestep Collection Time: 3.84116
Timestep Consumption Time: 3.09999
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.94115
Cumulative Model Updates: 141,716
Cumulative Timesteps: 1,153,500,622
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.38042
Policy Entropy: 4.32457
Value Function Loss: 0.00283
Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03959
Policy Update Magnitude: 1.04229
Value Function Update Magnitude: 0.78572
Collected Steps per Second: 12,931.75756
Overall Steps per Second: 7,004.00981
Timestep Collection Time: 3.86815
Timestep Consumption Time: 3.27376
PPO Batch Consumption Time: 0.24097
Total Iteration Time: 7.14191
Cumulative Model Updates: 141,725
Cumulative Timesteps: 1,153,550,644
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1153550644...
Checkpoint 1153550644 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.13100
Policy Entropy: 4.32598
Value Function Loss: 0.00274
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03608
Policy Update Magnitude: 1.03573
Value Function Update Magnitude: 0.80365
Collected Steps per Second: 12,920.33465
Overall Steps per Second: 7,198.81308
Timestep Collection Time: 3.87296
Timestep Consumption Time: 3.07818
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.95115
Cumulative Model Updates: 141,734
Cumulative Timesteps: 1,153,600,684
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.24821
Policy Entropy: 4.32067
Value Function Loss: 0.00270
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03141
Policy Update Magnitude: 1.02814
Value Function Update Magnitude: 0.77641
Collected Steps per Second: 13,207.20602
Overall Steps per Second: 7,266.66387
Timestep Collection Time: 3.78687
Timestep Consumption Time: 3.09579
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.88266
Cumulative Model Updates: 141,743
Cumulative Timesteps: 1,153,650,698
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1153650698...
Checkpoint 1153650698 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.65014
Policy Entropy: 4.32444
Value Function Loss: 0.00269
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03062
Policy Update Magnitude: 1.02597
Value Function Update Magnitude: 0.74430
Collected Steps per Second: 12,861.93347
Overall Steps per Second: 7,148.50533
Timestep Collection Time: 3.88853
Timestep Consumption Time: 3.10790
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.99643
Cumulative Model Updates: 141,752
Cumulative Timesteps: 1,153,700,712
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.40516
Policy Entropy: 4.32347
Value Function Loss: 0.00277
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 1.03310
Value Function Update Magnitude: 0.75774
Collected Steps per Second: 12,679.56537
Overall Steps per Second: 7,124.54385
Timestep Collection Time: 3.94367
Timestep Consumption Time: 3.07489
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 7.01855
Cumulative Model Updates: 141,761
Cumulative Timesteps: 1,153,750,716
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1153750716...
Checkpoint 1153750716 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13603
Policy Entropy: 4.32227
Value Function Loss: 0.00281
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03260
Policy Update Magnitude: 1.05669
Value Function Update Magnitude: 0.76654
Collected Steps per Second: 13,037.36398
Overall Steps per Second: 7,203.60139
Timestep Collection Time: 3.83820
Timestep Consumption Time: 3.10833
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.94653
Cumulative Model Updates: 141,770
Cumulative Timesteps: 1,153,800,756
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.85031
Policy Entropy: 4.32079
Value Function Loss: 0.00282
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 1.05934
Value Function Update Magnitude: 0.77980
Collected Steps per Second: 13,030.69227
Overall Steps per Second: 7,194.42075
Timestep Collection Time: 3.83786
Timestep Consumption Time: 3.11336
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.95122
Cumulative Model Updates: 141,779
Cumulative Timesteps: 1,153,850,766
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1153850766...
Checkpoint 1153850766 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.92030
Policy Entropy: 4.31729
Value Function Loss: 0.00286
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03543
Policy Update Magnitude: 1.06544
Value Function Update Magnitude: 0.79674
Collected Steps per Second: 12,750.51125
Overall Steps per Second: 6,986.02631
Timestep Collection Time: 3.92173
Timestep Consumption Time: 3.23599
PPO Batch Consumption Time: 0.24055
Total Iteration Time: 7.15772
Cumulative Model Updates: 141,788
Cumulative Timesteps: 1,153,900,770
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.46628
Policy Entropy: 4.31744
Value Function Loss: 0.00285
Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03743
Policy Update Magnitude: 1.06124
Value Function Update Magnitude: 0.80589
Collected Steps per Second: 12,975.66468
Overall Steps per Second: 7,182.39362
Timestep Collection Time: 3.85537
Timestep Consumption Time: 3.10972
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.96509
Cumulative Model Updates: 141,797
Cumulative Timesteps: 1,153,950,796
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1153950796...
Checkpoint 1153950796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.92487
Policy Entropy: 4.31818
Value Function Loss: 0.00293
Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03748
Policy Update Magnitude: 1.07823
Value Function Update Magnitude: 0.80316
Collected Steps per Second: 12,959.96187
Overall Steps per Second: 7,186.24493
Timestep Collection Time: 3.85989
Timestep Consumption Time: 3.10119
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.96108
Cumulative Model Updates: 141,806
Cumulative Timesteps: 1,154,000,820
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05657
Policy Entropy: 4.31825
Value Function Loss: 0.00286
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03625
Policy Update Magnitude: 1.08937
Value Function Update Magnitude: 0.83459
Collected Steps per Second: 12,880.17774
Overall Steps per Second: 7,184.93715
Timestep Collection Time: 3.88473
Timestep Consumption Time: 3.07928
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.96401
Cumulative Model Updates: 141,815
Cumulative Timesteps: 1,154,050,856
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1154050856...
Checkpoint 1154050856 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68186
Policy Entropy: 4.31921
Value Function Loss: 0.00290
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03743
Policy Update Magnitude: 1.09136
Value Function Update Magnitude: 0.82675
Collected Steps per Second: 12,954.52348
Overall Steps per Second: 7,175.01219
Timestep Collection Time: 3.86043
Timestep Consumption Time: 3.10960
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.97002
Cumulative Model Updates: 141,824
Cumulative Timesteps: 1,154,100,866
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04785
Policy Entropy: 4.32007
Value Function Loss: 0.00284
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03566
Policy Update Magnitude: 1.10505
Value Function Update Magnitude: 0.84320
Collected Steps per Second: 13,019.39098
Overall Steps per Second: 7,196.56237
Timestep Collection Time: 3.84119
Timestep Consumption Time: 3.10796
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.94915
Cumulative Model Updates: 141,833
Cumulative Timesteps: 1,154,150,876
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1154150876...
Checkpoint 1154150876 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.73302
Policy Entropy: 4.32057
Value Function Loss: 0.00281
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03553
Policy Update Magnitude: 1.11376
Value Function Update Magnitude: 0.83238
Collected Steps per Second: 12,823.45980
Overall Steps per Second: 7,257.85828
Timestep Collection Time: 3.89926
Timestep Consumption Time: 2.99010
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.88936
Cumulative Model Updates: 141,842
Cumulative Timesteps: 1,154,200,878
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.91908
Policy Entropy: 4.32101
Value Function Loss: 0.00272
Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03657
Policy Update Magnitude: 1.11372
Value Function Update Magnitude: 0.81326
Collected Steps per Second: 12,822.87180
Overall Steps per Second: 7,092.73967
Timestep Collection Time: 3.90053
Timestep Consumption Time: 3.15119
PPO Batch Consumption Time: 0.23237
Total Iteration Time: 7.05172
Cumulative Model Updates: 141,851
Cumulative Timesteps: 1,154,250,894
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1154250894...
Checkpoint 1154250894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.98187
Policy Entropy: 4.32019
Value Function Loss: 0.00280
Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03800
Policy Update Magnitude: 1.09442
Value Function Update Magnitude: 0.80416
Collected Steps per Second: 12,891.21338
Overall Steps per Second: 7,178.82073
Timestep Collection Time: 3.88125
Timestep Consumption Time: 3.08842
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.96967
Cumulative Model Updates: 141,860
Cumulative Timesteps: 1,154,300,928
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.47376
Policy Entropy: 4.31444
Value Function Loss: 0.00289
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03649
Policy Update Magnitude: 1.09446
Value Function Update Magnitude: 0.79010
Collected Steps per Second: 12,915.32186
Overall Steps per Second: 7,258.19152
Timestep Collection Time: 3.87276
Timestep Consumption Time: 3.01848
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.89125
Cumulative Model Updates: 141,869
Cumulative Timesteps: 1,154,350,946
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1154350946...
Checkpoint 1154350946 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.66368
Policy Entropy: 4.31816
Value Function Loss: 0.00275
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03978
Policy Update Magnitude: 1.07803
Value Function Update Magnitude: 0.78735
Collected Steps per Second: 12,518.92433
Overall Steps per Second: 7,060.87325
Timestep Collection Time: 3.99459
Timestep Consumption Time: 3.08782
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 7.08241
Cumulative Model Updates: 141,878
Cumulative Timesteps: 1,154,400,954
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.69826
Policy Entropy: 4.31684
Value Function Loss: 0.00284
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03723
Policy Update Magnitude: 1.08456
Value Function Update Magnitude: 0.77356
Collected Steps per Second: 12,805.26859
Overall Steps per Second: 7,142.32230
Timestep Collection Time: 3.90699
Timestep Consumption Time: 3.09774
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 7.00472
Cumulative Model Updates: 141,887
Cumulative Timesteps: 1,154,450,984
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1154450984...
Checkpoint 1154450984 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.48432
Policy Entropy: 4.32000
Value Function Loss: 0.00284
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03448
Policy Update Magnitude: 1.09058
Value Function Update Magnitude: 0.76923
Collected Steps per Second: 13,243.54083
Overall Steps per Second: 7,256.63635
Timestep Collection Time: 3.77573
Timestep Consumption Time: 3.11507
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.89080
Cumulative Model Updates: 141,896
Cumulative Timesteps: 1,154,500,988
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.42616
Policy Entropy: 4.31359
Value Function Loss: 0.00297
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03569
Policy Update Magnitude: 1.10234
Value Function Update Magnitude: 0.77866
Collected Steps per Second: 12,906.29664
Overall Steps per Second: 7,170.39677
Timestep Collection Time: 3.87454
Timestep Consumption Time: 3.09941
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.97395
Cumulative Model Updates: 141,905
Cumulative Timesteps: 1,154,550,994
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1154550994...
Checkpoint 1154550994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.63301
Policy Entropy: 4.31193
Value Function Loss: 0.00301
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03664
Policy Update Magnitude: 1.10827
Value Function Update Magnitude: 0.82362
Collected Steps per Second: 12,472.95670
Overall Steps per Second: 7,022.10817
Timestep Collection Time: 4.00963
Timestep Consumption Time: 3.11244
PPO Batch Consumption Time: 0.22952
Total Iteration Time: 7.12208
Cumulative Model Updates: 141,914
Cumulative Timesteps: 1,154,601,006
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.66026
Policy Entropy: 4.31030
Value Function Loss: 0.00291
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03513
Policy Update Magnitude: 1.11236
Value Function Update Magnitude: 0.82867
Collected Steps per Second: 13,132.44623
Overall Steps per Second: 7,247.82552
Timestep Collection Time: 3.80934
Timestep Consumption Time: 3.09286
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.90221
Cumulative Model Updates: 141,923
Cumulative Timesteps: 1,154,651,032
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1154651032...
Checkpoint 1154651032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.00032
Policy Entropy: 4.31267
Value Function Loss: 0.00285
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03487
Policy Update Magnitude: 1.09786
Value Function Update Magnitude: 0.79720
Collected Steps per Second: 12,802.63876
Overall Steps per Second: 7,135.17096
Timestep Collection Time: 3.90826
Timestep Consumption Time: 3.10433
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 7.01259
Cumulative Model Updates: 141,932
Cumulative Timesteps: 1,154,701,068
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99195
Policy Entropy: 4.31303
Value Function Loss: 0.00278
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03493
Policy Update Magnitude: 1.08592
Value Function Update Magnitude: 0.80040
Collected Steps per Second: 13,048.28596
Overall Steps per Second: 7,243.41098
Timestep Collection Time: 3.83407
Timestep Consumption Time: 3.07262
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.90669
Cumulative Model Updates: 141,941
Cumulative Timesteps: 1,154,751,096
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1154751096...
Checkpoint 1154751096 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61039
Policy Entropy: 4.30979
Value Function Loss: 0.00293
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03460
Policy Update Magnitude: 1.10187
Value Function Update Magnitude: 0.81828
Collected Steps per Second: 13,250.91722
Overall Steps per Second: 7,265.25014
Timestep Collection Time: 3.77332
Timestep Consumption Time: 3.10875
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.88208
Cumulative Model Updates: 141,950
Cumulative Timesteps: 1,154,801,096
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.86669
Policy Entropy: 4.31088
Value Function Loss: 0.00292
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03644
Policy Update Magnitude: 1.10947
Value Function Update Magnitude: 0.82903
Collected Steps per Second: 12,978.59140
Overall Steps per Second: 7,177.51819
Timestep Collection Time: 3.85311
Timestep Consumption Time: 3.11420
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.96731
Cumulative Model Updates: 141,959
Cumulative Timesteps: 1,154,851,104
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1154851104...
Checkpoint 1154851104 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90753
Policy Entropy: 4.31569
Value Function Loss: 0.00297
Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03805
Policy Update Magnitude: 1.12185
Value Function Update Magnitude: 0.81290
Collected Steps per Second: 12,787.40599
Overall Steps per Second: 7,157.36187
Timestep Collection Time: 3.91119
Timestep Consumption Time: 3.07658
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.98777
Cumulative Model Updates: 141,968
Cumulative Timesteps: 1,154,901,118
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.99463
Policy Entropy: 4.31483
Value Function Loss: 0.00310
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03782
Policy Update Magnitude: 1.14224
Value Function Update Magnitude: 0.82774
Collected Steps per Second: 13,149.53765
Overall Steps per Second: 7,104.27179
Timestep Collection Time: 3.80515
Timestep Consumption Time: 3.23793
PPO Batch Consumption Time: 0.23827
Total Iteration Time: 7.04309
Cumulative Model Updates: 141,977
Cumulative Timesteps: 1,154,951,154
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1154951154...
Checkpoint 1154951154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47047
Policy Entropy: 4.31654
Value Function Loss: 0.00296
Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04310
Policy Update Magnitude: 1.13659
Value Function Update Magnitude: 0.84295
Collected Steps per Second: 12,751.39110
Overall Steps per Second: 7,116.16315
Timestep Collection Time: 3.92318
Timestep Consumption Time: 3.10673
PPO Batch Consumption Time: 0.22918
Total Iteration Time: 7.02991
Cumulative Model Updates: 141,986
Cumulative Timesteps: 1,155,001,180
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.92207
Policy Entropy: 4.31461
Value Function Loss: 0.00306
Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04027
Policy Update Magnitude: 1.13603
Value Function Update Magnitude: 0.82022
Collected Steps per Second: 12,941.64347
Overall Steps per Second: 7,290.29046
Timestep Collection Time: 3.86721
Timestep Consumption Time: 2.99782
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.86502
Cumulative Model Updates: 141,995
Cumulative Timesteps: 1,155,051,228
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1155051228...
Checkpoint 1155051228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.65372
Policy Entropy: 4.31645
Value Function Loss: 0.00285
Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04246
Policy Update Magnitude: 1.13178
Value Function Update Magnitude: 0.79331
Collected Steps per Second: 12,810.75102
Overall Steps per Second: 7,121.52889
Timestep Collection Time: 3.90625
Timestep Consumption Time: 3.12061
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 7.02686
Cumulative Model Updates: 142,004
Cumulative Timesteps: 1,155,101,270
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.43238
Policy Entropy: 4.31371
Value Function Loss: 0.00308
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04045
Policy Update Magnitude: 1.12679
Value Function Update Magnitude: 0.76418
Collected Steps per Second: 11,187.94627
Overall Steps per Second: 6,628.59037
Timestep Collection Time: 4.47142
Timestep Consumption Time: 3.07558
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 7.54700
Cumulative Model Updates: 142,013
Cumulative Timesteps: 1,155,151,296
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1155151296...
Checkpoint 1155151296 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.35190
Policy Entropy: 4.31467
Value Function Loss: 0.00289
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03832
Policy Update Magnitude: 1.11872
Value Function Update Magnitude: 0.78338
Collected Steps per Second: 12,780.23376
Overall Steps per Second: 7,229.80779
Timestep Collection Time: 3.91433
Timestep Consumption Time: 3.00508
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.91941
Cumulative Model Updates: 142,022
Cumulative Timesteps: 1,155,201,322
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.78103
Policy Entropy: 4.31500
Value Function Loss: 0.00297
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03602
Policy Update Magnitude: 1.10765
Value Function Update Magnitude: 0.81136
Collected Steps per Second: 12,952.74778
Overall Steps per Second: 7,195.32497
Timestep Collection Time: 3.86451
Timestep Consumption Time: 3.09223
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.95674
Cumulative Model Updates: 142,031
Cumulative Timesteps: 1,155,251,378
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1155251378...
Checkpoint 1155251378 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12600
Policy Entropy: 4.31228
Value Function Loss: 0.00285
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03444
Policy Update Magnitude: 1.08118
Value Function Update Magnitude: 0.79835
Collected Steps per Second: 12,314.78502
Overall Steps per Second: 6,810.61093
Timestep Collection Time: 4.06016
Timestep Consumption Time: 3.28133
PPO Batch Consumption Time: 0.23739
Total Iteration Time: 7.34149
Cumulative Model Updates: 142,040
Cumulative Timesteps: 1,155,301,378
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.08832
Policy Entropy: 4.30873
Value Function Loss: 0.00292
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 1.07425
Value Function Update Magnitude: 0.78606
Collected Steps per Second: 13,180.35185
Overall Steps per Second: 7,240.29520
Timestep Collection Time: 3.79413
Timestep Consumption Time: 3.11277
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.90690
Cumulative Model Updates: 142,049
Cumulative Timesteps: 1,155,351,386
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1155351386...
Checkpoint 1155351386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90491
Policy Entropy: 4.31070
Value Function Loss: 0.00292
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03251
Policy Update Magnitude: 1.08592
Value Function Update Magnitude: 0.77138
Collected Steps per Second: 12,797.87383
Overall Steps per Second: 7,086.68144
Timestep Collection Time: 3.90862
Timestep Consumption Time: 3.14997
PPO Batch Consumption Time: 0.23162
Total Iteration Time: 7.05859
Cumulative Model Updates: 142,058
Cumulative Timesteps: 1,155,401,408
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.96990
Policy Entropy: 4.31430
Value Function Loss: 0.00291
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 1.08572
Value Function Update Magnitude: 0.78797
Collected Steps per Second: 12,802.10829
Overall Steps per Second: 7,155.87872
Timestep Collection Time: 3.90686
Timestep Consumption Time: 3.08264
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.98950
Cumulative Model Updates: 142,067
Cumulative Timesteps: 1,155,451,424
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1155451424...
Checkpoint 1155451424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95081
Policy Entropy: 4.31645
Value Function Loss: 0.00294
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03443
Policy Update Magnitude: 1.08197
Value Function Update Magnitude: 0.81724
Collected Steps per Second: 12,761.51618
Overall Steps per Second: 6,938.58916
Timestep Collection Time: 3.91991
Timestep Consumption Time: 3.28962
PPO Batch Consumption Time: 0.23713
Total Iteration Time: 7.20953
Cumulative Model Updates: 142,076
Cumulative Timesteps: 1,155,501,448
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.14850
Policy Entropy: 4.31376
Value Function Loss: 0.00294
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 1.07439
Value Function Update Magnitude: 0.80989
Collected Steps per Second: 12,611.85492
Overall Steps per Second: 7,056.56720
Timestep Collection Time: 3.96770
Timestep Consumption Time: 3.12357
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 7.09127
Cumulative Model Updates: 142,085
Cumulative Timesteps: 1,155,551,488
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1155551488...
Checkpoint 1155551488 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.59216
Policy Entropy: 4.31262
Value Function Loss: 0.00300
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03386
Policy Update Magnitude: 1.08423
Value Function Update Magnitude: 0.81169
Collected Steps per Second: 12,637.67140
Overall Steps per Second: 7,183.92867
Timestep Collection Time: 3.95927
Timestep Consumption Time: 3.00572
PPO Batch Consumption Time: 0.22949
Total Iteration Time: 6.96499
Cumulative Model Updates: 142,094
Cumulative Timesteps: 1,155,601,524
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.58247
Policy Entropy: 4.31232
Value Function Loss: 0.00295
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 1.08342
Value Function Update Magnitude: 0.79362
Collected Steps per Second: 12,719.69005
Overall Steps per Second: 6,858.48252
Timestep Collection Time: 3.93437
Timestep Consumption Time: 3.36229
PPO Batch Consumption Time: 0.25082
Total Iteration Time: 7.29666
Cumulative Model Updates: 142,103
Cumulative Timesteps: 1,155,651,568
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1155651568...
Checkpoint 1155651568 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.07426
Policy Entropy: 4.31191
Value Function Loss: 0.00286
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03517
Policy Update Magnitude: 1.06881
Value Function Update Magnitude: 0.78823
Collected Steps per Second: 11,323.88120
Overall Steps per Second: 6,631.75342
Timestep Collection Time: 4.41704
Timestep Consumption Time: 3.12516
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 7.54220
Cumulative Model Updates: 142,112
Cumulative Timesteps: 1,155,701,586
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.18551
Policy Entropy: 4.31445
Value Function Loss: 0.00269
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03498
Policy Update Magnitude: 1.05456
Value Function Update Magnitude: 0.79577
Collected Steps per Second: 12,873.46358
Overall Steps per Second: 7,249.80813
Timestep Collection Time: 3.88520
Timestep Consumption Time: 3.01374
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.89894
Cumulative Model Updates: 142,121
Cumulative Timesteps: 1,155,751,602
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1155751602...
Checkpoint 1155751602 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.45862
Policy Entropy: 4.31913
Value Function Loss: 0.00267
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03362
Policy Update Magnitude: 1.05808
Value Function Update Magnitude: 0.79088
Collected Steps per Second: 12,836.83178
Overall Steps per Second: 7,097.40187
Timestep Collection Time: 3.89644
Timestep Consumption Time: 3.15092
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 7.04737
Cumulative Model Updates: 142,130
Cumulative Timesteps: 1,155,801,620
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89829
Policy Entropy: 4.31942
Value Function Loss: 0.00273
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03436
Policy Update Magnitude: 1.06404
Value Function Update Magnitude: 0.78101
Collected Steps per Second: 12,910.89682
Overall Steps per Second: 7,197.38744
Timestep Collection Time: 3.87332
Timestep Consumption Time: 3.07476
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.94808
Cumulative Model Updates: 142,139
Cumulative Timesteps: 1,155,851,628
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1155851628...
Checkpoint 1155851628 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.28290
Policy Entropy: 4.31696
Value Function Loss: 0.00288
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03600
Policy Update Magnitude: 1.07656
Value Function Update Magnitude: 0.79203
Collected Steps per Second: 13,184.22382
Overall Steps per Second: 7,234.91773
Timestep Collection Time: 3.79438
Timestep Consumption Time: 3.12014
PPO Batch Consumption Time: 0.22949
Total Iteration Time: 6.91452
Cumulative Model Updates: 142,148
Cumulative Timesteps: 1,155,901,654
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.12238
Policy Entropy: 4.31639
Value Function Loss: 0.00283
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03382
Policy Update Magnitude: 1.08083
Value Function Update Magnitude: 0.79948
Collected Steps per Second: 13,010.28947
Overall Steps per Second: 7,183.65728
Timestep Collection Time: 3.84542
Timestep Consumption Time: 3.11900
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.96442
Cumulative Model Updates: 142,157
Cumulative Timesteps: 1,155,951,684
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1155951684...
Checkpoint 1155951684 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.98238
Policy Entropy: 4.31797
Value Function Loss: 0.00286
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 1.07852
Value Function Update Magnitude: 0.78271
Collected Steps per Second: 12,817.52672
Overall Steps per Second: 7,010.57030
Timestep Collection Time: 3.90356
Timestep Consumption Time: 3.23338
PPO Batch Consumption Time: 0.24023
Total Iteration Time: 7.13694
Cumulative Model Updates: 142,166
Cumulative Timesteps: 1,156,001,718
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76127
Policy Entropy: 4.31447
Value Function Loss: 0.00298
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03372
Policy Update Magnitude: 1.09341
Value Function Update Magnitude: 0.78230
Collected Steps per Second: 13,144.48156
Overall Steps per Second: 7,238.01709
Timestep Collection Time: 3.80449
Timestep Consumption Time: 3.10459
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.90907
Cumulative Model Updates: 142,175
Cumulative Timesteps: 1,156,051,726
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1156051726...
Checkpoint 1156051726 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07088
Policy Entropy: 4.31456
Value Function Loss: 0.00305
Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03900
Policy Update Magnitude: 1.11141
Value Function Update Magnitude: 0.79604
Collected Steps per Second: 12,955.78276
Overall Steps per Second: 7,160.56141
Timestep Collection Time: 3.86098
Timestep Consumption Time: 3.12479
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.98577
Cumulative Model Updates: 142,184
Cumulative Timesteps: 1,156,101,748
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66681
Policy Entropy: 4.31535
Value Function Loss: 0.00289
Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04246
Policy Update Magnitude: 1.08033
Value Function Update Magnitude: 0.78341
Collected Steps per Second: 13,005.75449
Overall Steps per Second: 7,205.23337
Timestep Collection Time: 3.84507
Timestep Consumption Time: 3.09544
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.94051
Cumulative Model Updates: 142,193
Cumulative Timesteps: 1,156,151,756
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1156151756...
Checkpoint 1156151756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31269
Policy Entropy: 4.31722
Value Function Loss: 0.00284
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03470
Policy Update Magnitude: 1.06925
Value Function Update Magnitude: 0.77274
Collected Steps per Second: 13,064.90965
Overall Steps per Second: 7,209.83753
Timestep Collection Time: 3.83057
Timestep Consumption Time: 3.11078
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.94135
Cumulative Model Updates: 142,202
Cumulative Timesteps: 1,156,201,802
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.18945
Policy Entropy: 4.31776
Value Function Loss: 0.00273
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03102
Policy Update Magnitude: 1.06927
Value Function Update Magnitude: 0.76845
Collected Steps per Second: 12,873.46891
Overall Steps per Second: 7,171.61877
Timestep Collection Time: 3.88629
Timestep Consumption Time: 3.08982
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.97611
Cumulative Model Updates: 142,211
Cumulative Timesteps: 1,156,251,832
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1156251832...
Checkpoint 1156251832 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97352
Policy Entropy: 4.32005
Value Function Loss: 0.00278
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03195
Policy Update Magnitude: 1.06845
Value Function Update Magnitude: 0.75153
Collected Steps per Second: 12,892.78532
Overall Steps per Second: 7,267.12675
Timestep Collection Time: 3.87907
Timestep Consumption Time: 3.00288
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.88195
Cumulative Model Updates: 142,220
Cumulative Timesteps: 1,156,301,844
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28864
Policy Entropy: 4.31911
Value Function Loss: 0.00271
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03469
Policy Update Magnitude: 1.06836
Value Function Update Magnitude: 0.76904
Collected Steps per Second: 12,983.48635
Overall Steps per Second: 7,024.31444
Timestep Collection Time: 3.85490
Timestep Consumption Time: 3.27035
PPO Batch Consumption Time: 0.24129
Total Iteration Time: 7.12525
Cumulative Model Updates: 142,229
Cumulative Timesteps: 1,156,351,894
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1156351894...
Checkpoint 1156351894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.36299
Policy Entropy: 4.31645
Value Function Loss: 0.00286
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03444
Policy Update Magnitude: 1.08009
Value Function Update Magnitude: 0.78826
Collected Steps per Second: 12,888.26763
Overall Steps per Second: 7,184.77531
Timestep Collection Time: 3.88214
Timestep Consumption Time: 3.08176
PPO Batch Consumption Time: 0.22945
Total Iteration Time: 6.96389
Cumulative Model Updates: 142,238
Cumulative Timesteps: 1,156,401,928
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68203
Policy Entropy: 4.31557
Value Function Loss: 0.00291
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03389
Policy Update Magnitude: 1.08533
Value Function Update Magnitude: 0.80780
Collected Steps per Second: 12,821.38156
Overall Steps per Second: 7,261.62263
Timestep Collection Time: 3.90192
Timestep Consumption Time: 2.98745
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.88937
Cumulative Model Updates: 142,247
Cumulative Timesteps: 1,156,451,956
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1156451956...
Checkpoint 1156451956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57836
Policy Entropy: 4.31616
Value Function Loss: 0.00298
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03429
Policy Update Magnitude: 1.09734
Value Function Update Magnitude: 0.84716
Collected Steps per Second: 12,860.67810
Overall Steps per Second: 7,159.63784
Timestep Collection Time: 3.89046
Timestep Consumption Time: 3.09788
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.98834
Cumulative Model Updates: 142,256
Cumulative Timesteps: 1,156,501,990
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.62266
Policy Entropy: 4.32037
Value Function Loss: 0.00295
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03500
Policy Update Magnitude: 1.08023
Value Function Update Magnitude: 0.81492
Collected Steps per Second: 12,996.33542
Overall Steps per Second: 7,214.56418
Timestep Collection Time: 3.84939
Timestep Consumption Time: 3.08491
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.93431
Cumulative Model Updates: 142,265
Cumulative Timesteps: 1,156,552,018
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1156552018...
Checkpoint 1156552018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.88643
Policy Entropy: 4.31532
Value Function Loss: 0.00296
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03400
Policy Update Magnitude: 1.07814
Value Function Update Magnitude: 0.79846
Collected Steps per Second: 12,917.87278
Overall Steps per Second: 7,269.38075
Timestep Collection Time: 3.87432
Timestep Consumption Time: 3.01045
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.88477
Cumulative Model Updates: 142,274
Cumulative Timesteps: 1,156,602,066
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52371
Policy Entropy: 4.31329
Value Function Loss: 0.00296
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 1.09112
Value Function Update Magnitude: 0.79959
Collected Steps per Second: 13,009.71689
Overall Steps per Second: 7,180.81586
Timestep Collection Time: 3.84636
Timestep Consumption Time: 3.12221
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.96857
Cumulative Model Updates: 142,283
Cumulative Timesteps: 1,156,652,106
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1156652106...
Checkpoint 1156652106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44323
Policy Entropy: 4.31124
Value Function Loss: 0.00291
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03844
Policy Update Magnitude: 1.10231
Value Function Update Magnitude: 0.79297
Collected Steps per Second: 12,938.46600
Overall Steps per Second: 7,049.06806
Timestep Collection Time: 3.86553
Timestep Consumption Time: 3.22959
PPO Batch Consumption Time: 0.24129
Total Iteration Time: 7.09512
Cumulative Model Updates: 142,292
Cumulative Timesteps: 1,156,702,120
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46174
Policy Entropy: 4.31573
Value Function Loss: 0.00296
Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03903
Policy Update Magnitude: 1.09021
Value Function Update Magnitude: 0.77622
Collected Steps per Second: 12,856.49313
Overall Steps per Second: 7,258.74877
Timestep Collection Time: 3.89173
Timestep Consumption Time: 3.00119
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.89292
Cumulative Model Updates: 142,301
Cumulative Timesteps: 1,156,752,154
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1156752154...
Checkpoint 1156752154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.82020
Policy Entropy: 4.31688
Value Function Loss: 0.00298
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03673
Policy Update Magnitude: 1.09332
Value Function Update Magnitude: 0.78634
Collected Steps per Second: 12,991.58604
Overall Steps per Second: 7,199.70258
Timestep Collection Time: 3.85034
Timestep Consumption Time: 3.09745
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.94779
Cumulative Model Updates: 142,310
Cumulative Timesteps: 1,156,802,176
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.42413
Policy Entropy: 4.31782
Value Function Loss: 0.00292
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03630
Policy Update Magnitude: 1.08755
Value Function Update Magnitude: 0.79199
Collected Steps per Second: 12,747.24742
Overall Steps per Second: 7,150.42631
Timestep Collection Time: 3.92398
Timestep Consumption Time: 3.07140
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.99539
Cumulative Model Updates: 142,319
Cumulative Timesteps: 1,156,852,196
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1156852196...
Checkpoint 1156852196 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18565
Policy Entropy: 4.31560
Value Function Loss: 0.00285
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 1.08794
Value Function Update Magnitude: 0.77810
Collected Steps per Second: 13,001.65332
Overall Steps per Second: 7,189.50941
Timestep Collection Time: 3.84705
Timestep Consumption Time: 3.11003
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.95708
Cumulative Model Updates: 142,328
Cumulative Timesteps: 1,156,902,214
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.26942
Policy Entropy: 4.31359
Value Function Loss: 0.00285
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03372
Policy Update Magnitude: 1.09123
Value Function Update Magnitude: 0.77739
Collected Steps per Second: 12,914.40014
Overall Steps per Second: 7,156.22400
Timestep Collection Time: 3.87397
Timestep Consumption Time: 3.11715
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.99112
Cumulative Model Updates: 142,337
Cumulative Timesteps: 1,156,952,244
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1156952244...
Checkpoint 1156952244 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01119
Policy Entropy: 4.31504
Value Function Loss: 0.00276
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03381
Policy Update Magnitude: 1.07912
Value Function Update Magnitude: 0.78002
Collected Steps per Second: 12,531.51089
Overall Steps per Second: 7,043.65472
Timestep Collection Time: 3.99473
Timestep Consumption Time: 3.11238
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 7.10711
Cumulative Model Updates: 142,346
Cumulative Timesteps: 1,157,002,304
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13336
Policy Entropy: 4.31305
Value Function Loss: 0.00278
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03370
Policy Update Magnitude: 1.06909
Value Function Update Magnitude: 0.79448
Collected Steps per Second: 13,061.23208
Overall Steps per Second: 7,049.87629
Timestep Collection Time: 3.82889
Timestep Consumption Time: 3.26485
PPO Batch Consumption Time: 0.23962
Total Iteration Time: 7.09374
Cumulative Model Updates: 142,355
Cumulative Timesteps: 1,157,052,314
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1157052314...
Checkpoint 1157052314 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79060
Policy Entropy: 4.31520
Value Function Loss: 0.00269
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03271
Policy Update Magnitude: 1.05901
Value Function Update Magnitude: 0.80862
Collected Steps per Second: 12,795.95047
Overall Steps per Second: 7,127.36901
Timestep Collection Time: 3.91014
Timestep Consumption Time: 3.10984
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 7.01998
Cumulative Model Updates: 142,364
Cumulative Timesteps: 1,157,102,348
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.91480
Policy Entropy: 4.31722
Value Function Loss: 0.00274
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 1.04078
Value Function Update Magnitude: 0.77659
Collected Steps per Second: 12,879.35670
Overall Steps per Second: 7,283.02453
Timestep Collection Time: 3.88311
Timestep Consumption Time: 2.98381
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.86693
Cumulative Model Updates: 142,373
Cumulative Timesteps: 1,157,152,360
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1157152360...
Checkpoint 1157152360 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68498
Policy Entropy: 4.31820
Value Function Loss: 0.00275
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03079
Policy Update Magnitude: 1.04437
Value Function Update Magnitude: 0.76281
Collected Steps per Second: 12,927.99117
Overall Steps per Second: 7,178.21271
Timestep Collection Time: 3.86758
Timestep Consumption Time: 3.09795
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.96552
Cumulative Model Updates: 142,382
Cumulative Timesteps: 1,157,202,360
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.22470
Policy Entropy: 4.31721
Value Function Loss: 0.00291
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03068
Policy Update Magnitude: 1.07492
Value Function Update Magnitude: 0.80295
Collected Steps per Second: 12,838.41355
Overall Steps per Second: 7,183.13889
Timestep Collection Time: 3.89892
Timestep Consumption Time: 3.06962
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.96854
Cumulative Model Updates: 142,391
Cumulative Timesteps: 1,157,252,416
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1157252416...
Checkpoint 1157252416 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.44501
Policy Entropy: 4.31454
Value Function Loss: 0.00287
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03398
Policy Update Magnitude: 1.08121
Value Function Update Magnitude: 0.78636
Collected Steps per Second: 12,844.35993
Overall Steps per Second: 7,247.15892
Timestep Collection Time: 3.89307
Timestep Consumption Time: 3.00674
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.89981
Cumulative Model Updates: 142,400
Cumulative Timesteps: 1,157,302,420
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.02079
Policy Entropy: 4.31827
Value Function Loss: 0.00272
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 1.05641
Value Function Update Magnitude: 0.78798
Collected Steps per Second: 12,906.89074
Overall Steps per Second: 7,165.55163
Timestep Collection Time: 3.87808
Timestep Consumption Time: 3.10728
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.98537
Cumulative Model Updates: 142,409
Cumulative Timesteps: 1,157,352,474
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1157352474...
Checkpoint 1157352474 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02930
Policy Entropy: 4.31314
Value Function Loss: 0.00284
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 1.06990
Value Function Update Magnitude: 0.79697
Collected Steps per Second: 12,903.49331
Overall Steps per Second: 7,126.70439
Timestep Collection Time: 3.87817
Timestep Consumption Time: 3.14358
PPO Batch Consumption Time: 0.23141
Total Iteration Time: 7.02176
Cumulative Model Updates: 142,418
Cumulative Timesteps: 1,157,402,516
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24601
Policy Entropy: 4.31199
Value Function Loss: 0.00290
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 1.10228
Value Function Update Magnitude: 0.82396
Collected Steps per Second: 13,181.08819
Overall Steps per Second: 7,242.93385
Timestep Collection Time: 3.79650
Timestep Consumption Time: 3.11258
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.90908
Cumulative Model Updates: 142,427
Cumulative Timesteps: 1,157,452,558
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1157452558...
Checkpoint 1157452558 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36912
Policy Entropy: 4.31362
Value Function Loss: 0.00290
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03479
Policy Update Magnitude: 1.09889
Value Function Update Magnitude: 0.80539
Collected Steps per Second: 12,857.22454
Overall Steps per Second: 7,143.45785
Timestep Collection Time: 3.89120
Timestep Consumption Time: 3.11241
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 7.00361
Cumulative Model Updates: 142,436
Cumulative Timesteps: 1,157,502,588
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87474
Policy Entropy: 4.31776
Value Function Loss: 0.00284
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03792
Policy Update Magnitude: 1.08552
Value Function Update Magnitude: 0.79954
Collected Steps per Second: 13,084.47731
Overall Steps per Second: 7,252.38225
Timestep Collection Time: 3.82270
Timestep Consumption Time: 3.07407
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.89677
Cumulative Model Updates: 142,445
Cumulative Timesteps: 1,157,552,606
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1157552606...
Checkpoint 1157552606 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33223
Policy Entropy: 4.31630
Value Function Loss: 0.00288
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03444
Policy Update Magnitude: 1.08234
Value Function Update Magnitude: 0.79844
Collected Steps per Second: 13,191.66451
Overall Steps per Second: 7,252.72077
Timestep Collection Time: 3.79088
Timestep Consumption Time: 3.10419
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.89507
Cumulative Model Updates: 142,454
Cumulative Timesteps: 1,157,602,614
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.55870
Policy Entropy: 4.31584
Value Function Loss: 0.00290
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 1.08323
Value Function Update Magnitude: 0.78961
Collected Steps per Second: 12,894.45183
Overall Steps per Second: 7,150.65128
Timestep Collection Time: 3.87965
Timestep Consumption Time: 3.11635
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.99601
Cumulative Model Updates: 142,463
Cumulative Timesteps: 1,157,652,640
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1157652640...
Checkpoint 1157652640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35438
Policy Entropy: 4.31514
Value Function Loss: 0.00298
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03403
Policy Update Magnitude: 1.09536
Value Function Update Magnitude: 0.81881
Collected Steps per Second: 12,937.98387
Overall Steps per Second: 7,210.55513
Timestep Collection Time: 3.86706
Timestep Consumption Time: 3.07165
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.93872
Cumulative Model Updates: 142,472
Cumulative Timesteps: 1,157,702,672
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.65963
Policy Entropy: 4.31169
Value Function Loss: 0.00300
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03903
Policy Update Magnitude: 1.09952
Value Function Update Magnitude: 0.78648
Collected Steps per Second: 13,280.50450
Overall Steps per Second: 7,241.53332
Timestep Collection Time: 3.76552
Timestep Consumption Time: 3.14020
PPO Batch Consumption Time: 0.23233
Total Iteration Time: 6.90572
Cumulative Model Updates: 142,481
Cumulative Timesteps: 1,157,752,680
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1157752680...
Checkpoint 1157752680 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56063
Policy Entropy: 4.31108
Value Function Loss: 0.00294
Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04058
Policy Update Magnitude: 1.08150
Value Function Update Magnitude: 0.77756
Collected Steps per Second: 12,952.37499
Overall Steps per Second: 7,174.76887
Timestep Collection Time: 3.86169
Timestep Consumption Time: 3.10969
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.97137
Cumulative Model Updates: 142,490
Cumulative Timesteps: 1,157,802,698
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.12064
Policy Entropy: 4.31553
Value Function Loss: 0.00288
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03807
Policy Update Magnitude: 1.07362
Value Function Update Magnitude: 0.80109
Collected Steps per Second: 12,785.42034
Overall Steps per Second: 7,174.46812
Timestep Collection Time: 3.91274
Timestep Consumption Time: 3.06004
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.97278
Cumulative Model Updates: 142,499
Cumulative Timesteps: 1,157,852,724
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1157852724...
Checkpoint 1157852724 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.38616
Policy Entropy: 4.31755
Value Function Loss: 0.00272
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03580
Policy Update Magnitude: 1.05520
Value Function Update Magnitude: 0.79689
Collected Steps per Second: 13,214.58054
Overall Steps per Second: 7,263.22868
Timestep Collection Time: 3.78476
Timestep Consumption Time: 3.10116
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.88592
Cumulative Model Updates: 142,508
Cumulative Timesteps: 1,157,902,738
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.91238
Policy Entropy: 4.31987
Value Function Loss: 0.00283
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03787
Policy Update Magnitude: 1.05194
Value Function Update Magnitude: 0.79129
Collected Steps per Second: 12,826.16386
Overall Steps per Second: 7,133.75962
Timestep Collection Time: 3.90171
Timestep Consumption Time: 3.11338
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 7.01509
Cumulative Model Updates: 142,517
Cumulative Timesteps: 1,157,952,782
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1157952782...
Checkpoint 1157952782 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36246
Policy Entropy: 4.31412
Value Function Loss: 0.00286
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03465
Policy Update Magnitude: 1.06534
Value Function Update Magnitude: 0.80178
Collected Steps per Second: 12,886.79386
Overall Steps per Second: 7,184.84540
Timestep Collection Time: 3.88072
Timestep Consumption Time: 3.07977
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.96048
Cumulative Model Updates: 142,526
Cumulative Timesteps: 1,158,002,792
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.25227
Policy Entropy: 4.31280
Value Function Loss: 0.00289
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03432
Policy Update Magnitude: 1.08082
Value Function Update Magnitude: 0.79839
Collected Steps per Second: 13,321.12390
Overall Steps per Second: 7,278.04526
Timestep Collection Time: 3.75524
Timestep Consumption Time: 3.11804
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.87327
Cumulative Model Updates: 142,535
Cumulative Timesteps: 1,158,052,816
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1158052816...
Checkpoint 1158052816 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.91688
Policy Entropy: 4.31141
Value Function Loss: 0.00286
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 1.08258
Value Function Update Magnitude: 0.75468
Collected Steps per Second: 12,818.68720
Overall Steps per Second: 7,083.47164
Timestep Collection Time: 3.90383
Timestep Consumption Time: 3.16078
PPO Batch Consumption Time: 0.22949
Total Iteration Time: 7.06461
Cumulative Model Updates: 142,544
Cumulative Timesteps: 1,158,102,858
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.94935
Policy Entropy: 4.31432
Value Function Loss: 0.00286
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03370
Policy Update Magnitude: 1.06777
Value Function Update Magnitude: 0.76241
Collected Steps per Second: 12,991.42707
Overall Steps per Second: 7,321.39011
Timestep Collection Time: 3.85131
Timestep Consumption Time: 2.98264
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.83395
Cumulative Model Updates: 142,553
Cumulative Timesteps: 1,158,152,892
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1158152892...
Checkpoint 1158152892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.38019
Policy Entropy: 4.31462
Value Function Loss: 0.00271
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03190
Policy Update Magnitude: 1.03474
Value Function Update Magnitude: 0.77027
Collected Steps per Second: 12,900.90430
Overall Steps per Second: 7,120.78424
Timestep Collection Time: 3.87957
Timestep Consumption Time: 3.14915
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 7.02872
Cumulative Model Updates: 142,562
Cumulative Timesteps: 1,158,202,942
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.37832
Policy Entropy: 4.31724
Value Function Loss: 0.00260
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03133
Policy Update Magnitude: 1.01123
Value Function Update Magnitude: 0.74396
Collected Steps per Second: 13,005.14735
Overall Steps per Second: 7,232.49183
Timestep Collection Time: 3.84740
Timestep Consumption Time: 3.07082
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.91822
Cumulative Model Updates: 142,571
Cumulative Timesteps: 1,158,252,978
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1158252978...
Checkpoint 1158252978 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38383
Policy Entropy: 4.32094
Value Function Loss: 0.00248
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03067
Policy Update Magnitude: 0.99486
Value Function Update Magnitude: 0.72133
Collected Steps per Second: 12,906.61180
Overall Steps per Second: 7,263.48732
Timestep Collection Time: 3.87631
Timestep Consumption Time: 3.01157
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.88788
Cumulative Model Updates: 142,580
Cumulative Timesteps: 1,158,303,008
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61886
Policy Entropy: 4.32240
Value Function Loss: 0.00266
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03158
Policy Update Magnitude: 1.01122
Value Function Update Magnitude: 0.72967
Collected Steps per Second: 12,948.73681
Overall Steps per Second: 7,163.52991
Timestep Collection Time: 3.86246
Timestep Consumption Time: 3.11929
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.98175
Cumulative Model Updates: 142,589
Cumulative Timesteps: 1,158,353,022
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1158353022...
Checkpoint 1158353022 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89825
Policy Entropy: 4.32062
Value Function Loss: 0.00270
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03419
Policy Update Magnitude: 1.04037
Value Function Update Magnitude: 0.75376
Collected Steps per Second: 12,870.79558
Overall Steps per Second: 7,186.18272
Timestep Collection Time: 3.88709
Timestep Consumption Time: 3.07488
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.96197
Cumulative Model Updates: 142,598
Cumulative Timesteps: 1,158,403,052
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.10220
Policy Entropy: 4.31952
Value Function Loss: 0.00276
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03703
Policy Update Magnitude: 1.05097
Value Function Update Magnitude: 0.78973
Collected Steps per Second: 12,905.09505
Overall Steps per Second: 7,124.27419
Timestep Collection Time: 3.87599
Timestep Consumption Time: 3.14508
PPO Batch Consumption Time: 0.24030
Total Iteration Time: 7.02107
Cumulative Model Updates: 142,607
Cumulative Timesteps: 1,158,453,072
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1158453072...
Checkpoint 1158453072 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60931
Policy Entropy: 4.32063
Value Function Loss: 0.00289
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03478
Policy Update Magnitude: 1.07019
Value Function Update Magnitude: 0.82410
Collected Steps per Second: 12,848.35989
Overall Steps per Second: 7,156.75829
Timestep Collection Time: 3.89310
Timestep Consumption Time: 3.09609
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.98920
Cumulative Model Updates: 142,616
Cumulative Timesteps: 1,158,503,092
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19667
Policy Entropy: 4.32039
Value Function Loss: 0.00298
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03382
Policy Update Magnitude: 1.09862
Value Function Update Magnitude: 0.82779
Collected Steps per Second: 13,077.45531
Overall Steps per Second: 7,329.59663
Timestep Collection Time: 3.82337
Timestep Consumption Time: 2.99828
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.82166
Cumulative Model Updates: 142,625
Cumulative Timesteps: 1,158,553,092
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1158553092...
Checkpoint 1158553092 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01274
Policy Entropy: 4.31963
Value Function Loss: 0.00312
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03354
Policy Update Magnitude: 1.12794
Value Function Update Magnitude: 0.83154
Collected Steps per Second: 13,091.11550
Overall Steps per Second: 7,236.18815
Timestep Collection Time: 3.82076
Timestep Consumption Time: 3.09144
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.91220
Cumulative Model Updates: 142,634
Cumulative Timesteps: 1,158,603,110
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44635
Policy Entropy: 4.31493
Value Function Loss: 0.00314
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03409
Policy Update Magnitude: 1.14057
Value Function Update Magnitude: 0.82249
Collected Steps per Second: 12,905.44601
Overall Steps per Second: 7,200.53294
Timestep Collection Time: 3.87526
Timestep Consumption Time: 3.07033
PPO Batch Consumption Time: 0.22771
Total Iteration Time: 6.94560
Cumulative Model Updates: 142,643
Cumulative Timesteps: 1,158,653,122
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1158653122...
Checkpoint 1158653122 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.15170
Policy Entropy: 4.31362
Value Function Loss: 0.00305
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03389
Policy Update Magnitude: 1.13971
Value Function Update Magnitude: 0.81358
Collected Steps per Second: 12,966.17179
Overall Steps per Second: 7,301.97638
Timestep Collection Time: 3.85650
Timestep Consumption Time: 2.99151
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.84801
Cumulative Model Updates: 142,652
Cumulative Timesteps: 1,158,703,126
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.24692
Policy Entropy: 4.31118
Value Function Loss: 0.00304
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 1.14171
Value Function Update Magnitude: 0.80428
Collected Steps per Second: 13,047.80199
Overall Steps per Second: 7,203.97331
Timestep Collection Time: 3.83344
Timestep Consumption Time: 3.10967
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.94311
Cumulative Model Updates: 142,661
Cumulative Timesteps: 1,158,753,144
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1158753144...
Checkpoint 1158753144 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77809
Policy Entropy: 4.31379
Value Function Loss: 0.00288
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03350
Policy Update Magnitude: 1.12114
Value Function Update Magnitude: 0.79577
Collected Steps per Second: 12,920.92561
Overall Steps per Second: 7,049.52448
Timestep Collection Time: 3.87232
Timestep Consumption Time: 3.22518
PPO Batch Consumption Time: 0.24238
Total Iteration Time: 7.09750
Cumulative Model Updates: 142,670
Cumulative Timesteps: 1,158,803,178
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67086
Policy Entropy: 4.31654
Value Function Loss: 0.00289
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03475
Policy Update Magnitude: 1.09292
Value Function Update Magnitude: 0.78753
Collected Steps per Second: 12,997.52926
Overall Steps per Second: 7,284.41060
Timestep Collection Time: 3.84735
Timestep Consumption Time: 3.01745
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.86480
Cumulative Model Updates: 142,679
Cumulative Timesteps: 1,158,853,184
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1158853184...
Checkpoint 1158853184 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.79444
Policy Entropy: 4.31600
Value Function Loss: 0.00299
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03491
Policy Update Magnitude: 1.10934
Value Function Update Magnitude: 0.78155
Collected Steps per Second: 13,120.64196
Overall Steps per Second: 7,238.09981
Timestep Collection Time: 3.81201
Timestep Consumption Time: 3.09809
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.91010
Cumulative Model Updates: 142,688
Cumulative Timesteps: 1,158,903,200
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49764
Policy Entropy: 4.31396
Value Function Loss: 0.00306
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03460
Policy Update Magnitude: 1.12042
Value Function Update Magnitude: 0.75921
Collected Steps per Second: 13,019.98056
Overall Steps per Second: 7,222.30422
Timestep Collection Time: 3.84317
Timestep Consumption Time: 3.08509
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.92826
Cumulative Model Updates: 142,697
Cumulative Timesteps: 1,158,953,238
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1158953238...
Checkpoint 1158953238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.55736
Policy Entropy: 4.30831
Value Function Loss: 0.00299
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03639
Policy Update Magnitude: 1.10855
Value Function Update Magnitude: 0.78184
Collected Steps per Second: 12,928.22917
Overall Steps per Second: 7,290.20298
Timestep Collection Time: 3.86751
Timestep Consumption Time: 2.99101
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.85852
Cumulative Model Updates: 142,706
Cumulative Timesteps: 1,159,003,238
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.14231
Policy Entropy: 4.30858
Value Function Loss: 0.00288
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03727
Policy Update Magnitude: 1.10020
Value Function Update Magnitude: 0.77280
Collected Steps per Second: 12,977.88077
Overall Steps per Second: 7,169.40528
Timestep Collection Time: 3.85548
Timestep Consumption Time: 3.12362
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.97910
Cumulative Model Updates: 142,715
Cumulative Timesteps: 1,159,053,274
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1159053274...
Checkpoint 1159053274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.48740
Policy Entropy: 4.30991
Value Function Loss: 0.00291
Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03890
Policy Update Magnitude: 1.10304
Value Function Update Magnitude: 0.82360
Collected Steps per Second: 12,908.72990
Overall Steps per Second: 7,198.06759
Timestep Collection Time: 3.87583
Timestep Consumption Time: 3.07493
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.95075
Cumulative Model Updates: 142,724
Cumulative Timesteps: 1,159,103,306
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.73499
Policy Entropy: 4.30980
Value Function Loss: 0.00287
Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03944
Policy Update Magnitude: 1.10157
Value Function Update Magnitude: 0.81180
Collected Steps per Second: 13,060.94095
Overall Steps per Second: 7,176.40198
Timestep Collection Time: 3.83035
Timestep Consumption Time: 3.14083
PPO Batch Consumption Time: 0.22965
Total Iteration Time: 6.97118
Cumulative Model Updates: 142,733
Cumulative Timesteps: 1,159,153,334
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1159153334...
Checkpoint 1159153334 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19883
Policy Entropy: 4.31339
Value Function Loss: 0.00287
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03802
Policy Update Magnitude: 1.09639
Value Function Update Magnitude: 0.80657
Collected Steps per Second: 13,039.97397
Overall Steps per Second: 7,198.18332
Timestep Collection Time: 3.83666
Timestep Consumption Time: 3.11370
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.95036
Cumulative Model Updates: 142,742
Cumulative Timesteps: 1,159,203,364
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97364
Policy Entropy: 4.31503
Value Function Loss: 0.00280
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03649
Policy Update Magnitude: 1.08799
Value Function Update Magnitude: 0.81060
Collected Steps per Second: 12,899.85294
Overall Steps per Second: 7,203.22092
Timestep Collection Time: 3.87648
Timestep Consumption Time: 3.06569
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.94217
Cumulative Model Updates: 142,751
Cumulative Timesteps: 1,159,253,370
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1159253370...
Checkpoint 1159253370 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.59237
Policy Entropy: 4.31454
Value Function Loss: 0.00303
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03540
Policy Update Magnitude: 1.11263
Value Function Update Magnitude: 0.80121
Collected Steps per Second: 13,234.49720
Overall Steps per Second: 7,277.13222
Timestep Collection Time: 3.77906
Timestep Consumption Time: 3.09370
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.87276
Cumulative Model Updates: 142,760
Cumulative Timesteps: 1,159,303,384
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.66072
Policy Entropy: 4.31658
Value Function Loss: 0.00292
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03720
Policy Update Magnitude: 1.09760
Value Function Update Magnitude: 0.83898
Collected Steps per Second: 12,901.89666
Overall Steps per Second: 7,170.10169
Timestep Collection Time: 3.87540
Timestep Consumption Time: 3.09800
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.97340
Cumulative Model Updates: 142,769
Cumulative Timesteps: 1,159,353,384
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1159353384...
Checkpoint 1159353384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.31345
Policy Entropy: 4.31999
Value Function Loss: 0.00294
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03361
Policy Update Magnitude: 1.07243
Value Function Update Magnitude: 0.81698
Collected Steps per Second: 12,980.42308
Overall Steps per Second: 7,304.39182
Timestep Collection Time: 3.85457
Timestep Consumption Time: 2.99528
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.84985
Cumulative Model Updates: 142,778
Cumulative Timesteps: 1,159,403,418
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49702
Policy Entropy: 4.32303
Value Function Loss: 0.00279
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03112
Policy Update Magnitude: 1.07720
Value Function Update Magnitude: 0.78349
Collected Steps per Second: 13,153.61825
Overall Steps per Second: 7,235.21699
Timestep Collection Time: 3.80139
Timestep Consumption Time: 3.10953
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.91092
Cumulative Model Updates: 142,787
Cumulative Timesteps: 1,159,453,420
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1159453420...
Checkpoint 1159453420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.18476
Policy Entropy: 4.32368
Value Function Loss: 0.00285
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 1.07581
Value Function Update Magnitude: 0.77244
Collected Steps per Second: 12,810.76124
Overall Steps per Second: 7,085.49430
Timestep Collection Time: 3.90391
Timestep Consumption Time: 3.15446
PPO Batch Consumption Time: 0.23465
Total Iteration Time: 7.05836
Cumulative Model Updates: 142,796
Cumulative Timesteps: 1,159,503,432
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99241
Policy Entropy: 4.32169
Value Function Loss: 0.00286
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03229
Policy Update Magnitude: 1.06873
Value Function Update Magnitude: 0.75712
Collected Steps per Second: 12,900.33260
Overall Steps per Second: 7,260.56547
Timestep Collection Time: 3.87649
Timestep Consumption Time: 3.01113
PPO Batch Consumption Time: 0.22941
Total Iteration Time: 6.88762
Cumulative Model Updates: 142,805
Cumulative Timesteps: 1,159,553,440
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1159553440...
Checkpoint 1159553440 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.49608
Policy Entropy: 4.31819
Value Function Loss: 0.00285
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03110
Policy Update Magnitude: 1.07880
Value Function Update Magnitude: 0.76590
Collected Steps per Second: 12,991.76605
Overall Steps per Second: 7,172.80143
Timestep Collection Time: 3.84905
Timestep Consumption Time: 3.12256
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.97161
Cumulative Model Updates: 142,814
Cumulative Timesteps: 1,159,603,446
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.40564
Policy Entropy: 4.31876
Value Function Loss: 0.00279
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03099
Policy Update Magnitude: 1.07009
Value Function Update Magnitude: 0.76454
Collected Steps per Second: 12,849.80074
Overall Steps per Second: 7,182.17955
Timestep Collection Time: 3.89454
Timestep Consumption Time: 3.07327
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.96780
Cumulative Model Updates: 142,823
Cumulative Timesteps: 1,159,653,490
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1159653490...
Checkpoint 1159653490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.41601
Policy Entropy: 4.31850
Value Function Loss: 0.00290
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 1.08540
Value Function Update Magnitude: 0.74942
Collected Steps per Second: 12,759.76558
Overall Steps per Second: 7,222.53273
Timestep Collection Time: 3.92155
Timestep Consumption Time: 3.00650
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.92804
Cumulative Model Updates: 142,832
Cumulative Timesteps: 1,159,703,528
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01819
Policy Entropy: 4.31715
Value Function Loss: 0.00299
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 1.09570
Value Function Update Magnitude: 0.80392
Collected Steps per Second: 12,938.40157
Overall Steps per Second: 7,199.26232
Timestep Collection Time: 3.86663
Timestep Consumption Time: 3.08242
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.94905
Cumulative Model Updates: 142,841
Cumulative Timesteps: 1,159,753,556
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1159753556...
Checkpoint 1159753556 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16803
Policy Entropy: 4.31827
Value Function Loss: 0.00296
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03451
Policy Update Magnitude: 1.09089
Value Function Update Magnitude: 0.80957
Collected Steps per Second: 12,835.40794
Overall Steps per Second: 7,194.23384
Timestep Collection Time: 3.89579
Timestep Consumption Time: 3.05478
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.95057
Cumulative Model Updates: 142,850
Cumulative Timesteps: 1,159,803,560
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01334
Policy Entropy: 4.31991
Value Function Loss: 0.00289
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03212
Policy Update Magnitude: 1.08586
Value Function Update Magnitude: 0.75517
Collected Steps per Second: 12,953.06690
Overall Steps per Second: 7,214.64830
Timestep Collection Time: 3.86055
Timestep Consumption Time: 3.07062
PPO Batch Consumption Time: 0.22993
Total Iteration Time: 6.93118
Cumulative Model Updates: 142,859
Cumulative Timesteps: 1,159,853,566
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1159853566...
Checkpoint 1159853566 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.17437
Policy Entropy: 4.32373
Value Function Loss: 0.00283
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03274
Policy Update Magnitude: 1.07584
Value Function Update Magnitude: 0.74839
Collected Steps per Second: 13,053.52981
Overall Steps per Second: 7,218.71763
Timestep Collection Time: 3.83069
Timestep Consumption Time: 3.09630
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.92699
Cumulative Model Updates: 142,868
Cumulative Timesteps: 1,159,903,570
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.69595
Policy Entropy: 4.32184
Value Function Loss: 0.00274
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03247
Policy Update Magnitude: 1.08131
Value Function Update Magnitude: 0.75796
Collected Steps per Second: 12,988.19553
Overall Steps per Second: 7,219.64458
Timestep Collection Time: 3.85258
Timestep Consumption Time: 3.07824
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.93081
Cumulative Model Updates: 142,877
Cumulative Timesteps: 1,159,953,608
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1159953608...
Checkpoint 1159953608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04267
Policy Entropy: 4.32512
Value Function Loss: 0.00262
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03338
Policy Update Magnitude: 1.07774
Value Function Update Magnitude: 0.74347
Collected Steps per Second: 12,880.36822
Overall Steps per Second: 7,250.77340
Timestep Collection Time: 3.88374
Timestep Consumption Time: 3.01539
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.89913
Cumulative Model Updates: 142,886
Cumulative Timesteps: 1,160,003,632
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.84044
Policy Entropy: 4.32604
Value Function Loss: 0.00267
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 1.09577
Value Function Update Magnitude: 0.77177
Collected Steps per Second: 13,029.51592
Overall Steps per Second: 7,201.67989
Timestep Collection Time: 3.83790
Timestep Consumption Time: 3.10576
PPO Batch Consumption Time: 0.22933
Total Iteration Time: 6.94366
Cumulative Model Updates: 142,895
Cumulative Timesteps: 1,160,053,638
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1160053638...
Checkpoint 1160053638 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.78115
Policy Entropy: 4.33128
Value Function Loss: 0.00271
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 1.11206
Value Function Update Magnitude: 0.77324
Collected Steps per Second: 12,825.60026
Overall Steps per Second: 7,169.10359
Timestep Collection Time: 3.90126
Timestep Consumption Time: 3.07813
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.97939
Cumulative Model Updates: 142,904
Cumulative Timesteps: 1,160,103,674
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.97612
Policy Entropy: 4.32641
Value Function Loss: 0.00280
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 1.10701
Value Function Update Magnitude: 0.76058
Collected Steps per Second: 12,862.76470
Overall Steps per Second: 7,255.29671
Timestep Collection Time: 3.88843
Timestep Consumption Time: 3.00529
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.89372
Cumulative Model Updates: 142,913
Cumulative Timesteps: 1,160,153,690
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1160153690...
Checkpoint 1160153690 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.89127
Policy Entropy: 4.32272
Value Function Loss: 0.00284
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03471
Policy Update Magnitude: 1.08849
Value Function Update Magnitude: 0.76810
Collected Steps per Second: 12,882.99879
Overall Steps per Second: 7,071.49209
Timestep Collection Time: 3.88372
Timestep Consumption Time: 3.19173
PPO Batch Consumption Time: 0.23146
Total Iteration Time: 7.07545
Cumulative Model Updates: 142,922
Cumulative Timesteps: 1,160,203,724
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47387
Policy Entropy: 4.31938
Value Function Loss: 0.00288
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03481
Policy Update Magnitude: 1.09265
Value Function Update Magnitude: 0.77874
Collected Steps per Second: 13,012.96429
Overall Steps per Second: 7,232.26396
Timestep Collection Time: 3.84401
Timestep Consumption Time: 3.07249
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.91651
Cumulative Model Updates: 142,931
Cumulative Timesteps: 1,160,253,746
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1160253746...
Checkpoint 1160253746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.33538
Policy Entropy: 4.32170
Value Function Loss: 0.00285
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03336
Policy Update Magnitude: 1.08856
Value Function Update Magnitude: 0.76493
Collected Steps per Second: 12,845.09241
Overall Steps per Second: 7,256.93133
Timestep Collection Time: 3.89285
Timestep Consumption Time: 2.99767
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.89052
Cumulative Model Updates: 142,940
Cumulative Timesteps: 1,160,303,750
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.36583
Policy Entropy: 4.32428
Value Function Loss: 0.00280
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03324
Policy Update Magnitude: 1.08542
Value Function Update Magnitude: 0.74664
Collected Steps per Second: 12,883.33247
Overall Steps per Second: 7,141.13997
Timestep Collection Time: 3.88160
Timestep Consumption Time: 3.12120
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 7.00280
Cumulative Model Updates: 142,949
Cumulative Timesteps: 1,160,353,758
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1160353758...
Checkpoint 1160353758 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.70580
Policy Entropy: 4.31998
Value Function Loss: 0.00275
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03256
Policy Update Magnitude: 1.08418
Value Function Update Magnitude: 0.75997
Collected Steps per Second: 12,921.22735
Overall Steps per Second: 7,199.50726
Timestep Collection Time: 3.87099
Timestep Consumption Time: 3.07643
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.94742
Cumulative Model Updates: 142,958
Cumulative Timesteps: 1,160,403,776
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44676
Policy Entropy: 4.32008
Value Function Loss: 0.00276
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03677
Policy Update Magnitude: 1.09002
Value Function Update Magnitude: 0.78231
Collected Steps per Second: 13,337.28109
Overall Steps per Second: 7,304.29763
Timestep Collection Time: 3.75234
Timestep Consumption Time: 3.09924
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.85158
Cumulative Model Updates: 142,967
Cumulative Timesteps: 1,160,453,822
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1160453822...
Checkpoint 1160453822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.56221
Policy Entropy: 4.32201
Value Function Loss: 0.00277
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03460
Policy Update Magnitude: 1.08864
Value Function Update Magnitude: 0.77799
Collected Steps per Second: 12,993.63417
Overall Steps per Second: 7,204.17062
Timestep Collection Time: 3.84912
Timestep Consumption Time: 3.09325
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.94237
Cumulative Model Updates: 142,976
Cumulative Timesteps: 1,160,503,836
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.00882
Policy Entropy: 4.32082
Value Function Loss: 0.00284
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 1.09680
Value Function Update Magnitude: 0.78090
Collected Steps per Second: 13,016.46190
Overall Steps per Second: 7,181.44532
Timestep Collection Time: 3.84421
Timestep Consumption Time: 3.12347
PPO Batch Consumption Time: 0.22993
Total Iteration Time: 6.96768
Cumulative Model Updates: 142,985
Cumulative Timesteps: 1,160,553,874
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1160553874...
Checkpoint 1160553874 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.30501
Policy Entropy: 4.31998
Value Function Loss: 0.00290
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03390
Policy Update Magnitude: 1.09019
Value Function Update Magnitude: 0.79606
Collected Steps per Second: 13,143.61373
Overall Steps per Second: 7,233.39077
Timestep Collection Time: 3.80428
Timestep Consumption Time: 3.10838
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.91266
Cumulative Model Updates: 142,994
Cumulative Timesteps: 1,160,603,876
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.43143
Policy Entropy: 4.31870
Value Function Loss: 0.00280
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03203
Policy Update Magnitude: 1.08977
Value Function Update Magnitude: 0.77257
Collected Steps per Second: 13,020.17438
Overall Steps per Second: 7,203.61735
Timestep Collection Time: 3.84526
Timestep Consumption Time: 3.10486
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.95012
Cumulative Model Updates: 143,003
Cumulative Timesteps: 1,160,653,942
Timesteps Collected: 50,066
--------END ITERATION REPORT--------
Saving checkpoint 1160653942...
Checkpoint 1160653942 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.14495
Policy Entropy: 4.32026
Value Function Loss: 0.00276
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03175
Policy Update Magnitude: 1.08149
Value Function Update Magnitude: 0.75804
Collected Steps per Second: 12,867.59742
Overall Steps per Second: 7,176.86875
Timestep Collection Time: 3.88853
Timestep Consumption Time: 3.08332
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.97184
Cumulative Model Updates: 143,012
Cumulative Timesteps: 1,160,703,978
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79368
Policy Entropy: 4.32230
Value Function Loss: 0.00280
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 1.09779
Value Function Update Magnitude: 0.78354
Collected Steps per Second: 13,404.75424
Overall Steps per Second: 7,313.86949
Timestep Collection Time: 3.73106
Timestep Consumption Time: 3.10718
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.83824
Cumulative Model Updates: 143,021
Cumulative Timesteps: 1,160,753,992
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1160753992...
Checkpoint 1160753992 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54119
Policy Entropy: 4.32189
Value Function Loss: 0.00294
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03488
Policy Update Magnitude: 1.11201
Value Function Update Magnitude: 0.76171
Collected Steps per Second: 12,789.40053
Overall Steps per Second: 7,126.47254
Timestep Collection Time: 3.91011
Timestep Consumption Time: 3.10710
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 7.01722
Cumulative Model Updates: 143,030
Cumulative Timesteps: 1,160,804,000
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.39765
Policy Entropy: 4.31895
Value Function Loss: 0.00307
Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03831
Policy Update Magnitude: 1.11458
Value Function Update Magnitude: 0.76387
Collected Steps per Second: 12,956.48622
Overall Steps per Second: 7,212.78209
Timestep Collection Time: 3.86108
Timestep Consumption Time: 3.07466
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.93574
Cumulative Model Updates: 143,039
Cumulative Timesteps: 1,160,854,026
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1160854026...
Checkpoint 1160854026 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76683
Policy Entropy: 4.31935
Value Function Loss: 0.00296
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03607
Policy Update Magnitude: 1.10255
Value Function Update Magnitude: 0.78471
Collected Steps per Second: 13,268.47819
Overall Steps per Second: 7,216.13184
Timestep Collection Time: 3.76893
Timestep Consumption Time: 3.16110
PPO Batch Consumption Time: 0.22993
Total Iteration Time: 6.93003
Cumulative Model Updates: 143,048
Cumulative Timesteps: 1,160,904,034
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.71159
Policy Entropy: 4.31357
Value Function Loss: 0.00290
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03444
Policy Update Magnitude: 1.09604
Value Function Update Magnitude: 0.81465
Collected Steps per Second: 12,961.34118
Overall Steps per Second: 7,174.08876
Timestep Collection Time: 3.86133
Timestep Consumption Time: 3.11489
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.97622
Cumulative Model Updates: 143,057
Cumulative Timesteps: 1,160,954,082
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1160954082...
Checkpoint 1160954082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.21537
Policy Entropy: 4.31601
Value Function Loss: 0.00282
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 1.11281
Value Function Update Magnitude: 0.82807
Collected Steps per Second: 12,924.95521
Overall Steps per Second: 7,287.03090
Timestep Collection Time: 3.86864
Timestep Consumption Time: 2.99314
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.86178
Cumulative Model Updates: 143,066
Cumulative Timesteps: 1,161,004,084
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.97250
Policy Entropy: 4.31152
Value Function Loss: 0.00285
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03496
Policy Update Magnitude: 1.11557
Value Function Update Magnitude: 0.81219
Collected Steps per Second: 12,957.82751
Overall Steps per Second: 7,179.03265
Timestep Collection Time: 3.86222
Timestep Consumption Time: 3.10891
PPO Batch Consumption Time: 0.22926
Total Iteration Time: 6.97113
Cumulative Model Updates: 143,075
Cumulative Timesteps: 1,161,054,130
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1161054130...
Checkpoint 1161054130 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.24797
Policy Entropy: 4.31768
Value Function Loss: 0.00274
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03342
Policy Update Magnitude: 1.09034
Value Function Update Magnitude: 0.79737
Collected Steps per Second: 13,076.40443
Overall Steps per Second: 7,253.72599
Timestep Collection Time: 3.82445
Timestep Consumption Time: 3.06994
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.89439
Cumulative Model Updates: 143,084
Cumulative Timesteps: 1,161,104,140
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.30977
Policy Entropy: 4.31836
Value Function Loss: 0.00273
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03390
Policy Update Magnitude: 1.07031
Value Function Update Magnitude: 0.77603
Collected Steps per Second: 12,829.82901
Overall Steps per Second: 7,245.31188
Timestep Collection Time: 3.89919
Timestep Consumption Time: 3.00541
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 6.90460
Cumulative Model Updates: 143,093
Cumulative Timesteps: 1,161,154,166
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1161154166...
Checkpoint 1161154166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46033
Policy Entropy: 4.32027
Value Function Loss: 0.00277
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03217
Policy Update Magnitude: 1.07893
Value Function Update Magnitude: 0.80239
Collected Steps per Second: 12,910.22601
Overall Steps per Second: 7,170.46218
Timestep Collection Time: 3.87491
Timestep Consumption Time: 3.10176
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.97668
Cumulative Model Updates: 143,102
Cumulative Timesteps: 1,161,204,192
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18001
Policy Entropy: 4.31952
Value Function Loss: 0.00284
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 1.08954
Value Function Update Magnitude: 0.80847
Collected Steps per Second: 12,867.68248
Overall Steps per Second: 7,074.60100
Timestep Collection Time: 3.88741
Timestep Consumption Time: 3.18323
PPO Batch Consumption Time: 0.23726
Total Iteration Time: 7.07065
Cumulative Model Updates: 143,111
Cumulative Timesteps: 1,161,254,214
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1161254214...
Checkpoint 1161254214 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11609
Policy Entropy: 4.31688
Value Function Loss: 0.00291
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03421
Policy Update Magnitude: 1.10660
Value Function Update Magnitude: 0.79096
Collected Steps per Second: 12,952.80666
Overall Steps per Second: 7,287.01670
Timestep Collection Time: 3.86140
Timestep Consumption Time: 3.00231
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.86371
Cumulative Model Updates: 143,120
Cumulative Timesteps: 1,161,304,230
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.04261
Policy Entropy: 4.31820
Value Function Loss: 0.00281
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03227
Policy Update Magnitude: 1.09849
Value Function Update Magnitude: 0.78741
Collected Steps per Second: 13,102.72042
Overall Steps per Second: 7,217.15409
Timestep Collection Time: 3.81738
Timestep Consumption Time: 3.11306
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.93043
Cumulative Model Updates: 143,129
Cumulative Timesteps: 1,161,354,248
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1161354248...
Checkpoint 1161354248 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61989
Policy Entropy: 4.31959
Value Function Loss: 0.00279
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 1.08303
Value Function Update Magnitude: 0.80773
Collected Steps per Second: 12,842.05844
Overall Steps per Second: 7,176.97009
Timestep Collection Time: 3.89501
Timestep Consumption Time: 3.07450
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.96951
Cumulative Model Updates: 143,138
Cumulative Timesteps: 1,161,404,268
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.92456
Policy Entropy: 4.31709
Value Function Loss: 0.00278
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03179
Policy Update Magnitude: 1.09168
Value Function Update Magnitude: 0.83046
Collected Steps per Second: 13,221.05316
Overall Steps per Second: 7,241.81365
Timestep Collection Time: 3.78291
Timestep Consumption Time: 3.12338
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.90628
Cumulative Model Updates: 143,147
Cumulative Timesteps: 1,161,454,282
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1161454282...
Checkpoint 1161454282 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60004
Policy Entropy: 4.31715
Value Function Loss: 0.00271
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03163
Policy Update Magnitude: 1.07279
Value Function Update Magnitude: 0.79448
Collected Steps per Second: 12,930.01011
Overall Steps per Second: 7,187.49545
Timestep Collection Time: 3.86991
Timestep Consumption Time: 3.09190
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.96181
Cumulative Model Updates: 143,156
Cumulative Timesteps: 1,161,504,320
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85369
Policy Entropy: 4.31417
Value Function Loss: 0.00289
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03341
Policy Update Magnitude: 1.06693
Value Function Update Magnitude: 0.79597
Collected Steps per Second: 12,915.45339
Overall Steps per Second: 7,206.38831
Timestep Collection Time: 3.87458
Timestep Consumption Time: 3.06953
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.94412
Cumulative Model Updates: 143,165
Cumulative Timesteps: 1,161,554,362
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1161554362...
Checkpoint 1161554362 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.35598
Policy Entropy: 4.31472
Value Function Loss: 0.00290
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03374
Policy Update Magnitude: 1.07203
Value Function Update Magnitude: 0.82583
Collected Steps per Second: 13,288.96205
Overall Steps per Second: 7,218.04006
Timestep Collection Time: 3.76418
Timestep Consumption Time: 3.16596
PPO Batch Consumption Time: 0.23068
Total Iteration Time: 6.93014
Cumulative Model Updates: 143,174
Cumulative Timesteps: 1,161,604,384
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.59119
Policy Entropy: 4.30896
Value Function Loss: 0.00307
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03539
Policy Update Magnitude: 1.08280
Value Function Update Magnitude: 0.85215
Collected Steps per Second: 13,138.58376
Overall Steps per Second: 7,234.39228
Timestep Collection Time: 3.80619
Timestep Consumption Time: 3.10634
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.91254
Cumulative Model Updates: 143,183
Cumulative Timesteps: 1,161,654,392
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1161654392...
Checkpoint 1161654392 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.95353
Policy Entropy: 4.30828
Value Function Loss: 0.00294
Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03752
Policy Update Magnitude: 1.09202
Value Function Update Magnitude: 0.83687
Collected Steps per Second: 12,774.40640
Overall Steps per Second: 7,232.69002
Timestep Collection Time: 3.91533
Timestep Consumption Time: 2.99994
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.91527
Cumulative Model Updates: 143,192
Cumulative Timesteps: 1,161,704,408
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.59253
Policy Entropy: 4.31169
Value Function Loss: 0.00293
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03533
Policy Update Magnitude: 1.08403
Value Function Update Magnitude: 0.80264
Collected Steps per Second: 12,889.37413
Overall Steps per Second: 7,155.02030
Timestep Collection Time: 3.88196
Timestep Consumption Time: 3.11117
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.99313
Cumulative Model Updates: 143,201
Cumulative Timesteps: 1,161,754,444
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1161754444...
Checkpoint 1161754444 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.48173
Policy Entropy: 4.31520
Value Function Loss: 0.00295
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03486
Policy Update Magnitude: 1.09216
Value Function Update Magnitude: 0.77038
Collected Steps per Second: 12,891.40822
Overall Steps per Second: 7,189.32019
Timestep Collection Time: 3.87995
Timestep Consumption Time: 3.07732
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.95726
Cumulative Model Updates: 143,210
Cumulative Timesteps: 1,161,804,462
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00633
Policy Entropy: 4.31922
Value Function Loss: 0.00302
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03418
Policy Update Magnitude: 1.11460
Value Function Update Magnitude: 0.78205
Collected Steps per Second: 12,923.11981
Overall Steps per Second: 7,282.42588
Timestep Collection Time: 3.87136
Timestep Consumption Time: 2.99861
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.86996
Cumulative Model Updates: 143,219
Cumulative Timesteps: 1,161,854,492
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1161854492...
Checkpoint 1161854492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36347
Policy Entropy: 4.31357
Value Function Loss: 0.00306
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03604
Policy Update Magnitude: 1.11857
Value Function Update Magnitude: 0.82095
Collected Steps per Second: 13,048.24939
Overall Steps per Second: 7,188.34019
Timestep Collection Time: 3.83438
Timestep Consumption Time: 3.12578
PPO Batch Consumption Time: 0.22948
Total Iteration Time: 6.96016
Cumulative Model Updates: 143,228
Cumulative Timesteps: 1,161,904,524
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64450
Policy Entropy: 4.32027
Value Function Loss: 0.00302
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03449
Policy Update Magnitude: 1.09290
Value Function Update Magnitude: 0.84953
Collected Steps per Second: 12,925.24101
Overall Steps per Second: 7,142.19458
Timestep Collection Time: 3.86917
Timestep Consumption Time: 3.13288
PPO Batch Consumption Time: 0.23003
Total Iteration Time: 7.00205
Cumulative Model Updates: 143,237
Cumulative Timesteps: 1,161,954,534
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1161954534...
Checkpoint 1161954534 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.55110
Policy Entropy: 4.31570
Value Function Loss: 0.00296
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03354
Policy Update Magnitude: 1.09232
Value Function Update Magnitude: 0.82125
Collected Steps per Second: 12,895.61287
Overall Steps per Second: 7,256.00010
Timestep Collection Time: 3.87930
Timestep Consumption Time: 3.01513
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.89443
Cumulative Model Updates: 143,246
Cumulative Timesteps: 1,162,004,560
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.33458
Policy Entropy: 4.31920
Value Function Loss: 0.00284
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03286
Policy Update Magnitude: 1.07250
Value Function Update Magnitude: 0.80606
Collected Steps per Second: 13,018.71059
Overall Steps per Second: 7,221.86997
Timestep Collection Time: 3.84232
Timestep Consumption Time: 3.08414
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.92646
Cumulative Model Updates: 143,255
Cumulative Timesteps: 1,162,054,582
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1162054582...
Checkpoint 1162054582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.98928
Policy Entropy: 4.31674
Value Function Loss: 0.00275
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 1.06571
Value Function Update Magnitude: 0.78425
Collected Steps per Second: 12,938.05639
Overall Steps per Second: 7,203.05233
Timestep Collection Time: 3.86457
Timestep Consumption Time: 3.07693
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.94150
Cumulative Model Updates: 143,264
Cumulative Timesteps: 1,162,104,582
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.37308
Policy Entropy: 4.31754
Value Function Loss: 0.00271
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 1.05889
Value Function Update Magnitude: 0.77655
Collected Steps per Second: 13,054.44660
Overall Steps per Second: 7,310.49681
Timestep Collection Time: 3.83118
Timestep Consumption Time: 3.01021
PPO Batch Consumption Time: 0.22933
Total Iteration Time: 6.84140
Cumulative Model Updates: 143,273
Cumulative Timesteps: 1,162,154,596
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1162154596...
Checkpoint 1162154596 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.66866
Policy Entropy: 4.31590
Value Function Loss: 0.00283
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 1.07215
Value Function Update Magnitude: 0.78634
Collected Steps per Second: 13,031.61690
Overall Steps per Second: 7,205.15536
Timestep Collection Time: 3.83698
Timestep Consumption Time: 3.10278
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.93975
Cumulative Model Updates: 143,282
Cumulative Timesteps: 1,162,204,598
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51521
Policy Entropy: 4.31320
Value Function Loss: 0.00280
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 1.08342
Value Function Update Magnitude: 0.79628
Collected Steps per Second: 12,789.29639
Overall Steps per Second: 7,166.59838
Timestep Collection Time: 3.91046
Timestep Consumption Time: 3.06803
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.97849
Cumulative Model Updates: 143,291
Cumulative Timesteps: 1,162,254,610
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1162254610...
Checkpoint 1162254610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.66799
Policy Entropy: 4.31807
Value Function Loss: 0.00285
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03211
Policy Update Magnitude: 1.09584
Value Function Update Magnitude: 0.80515
Collected Steps per Second: 12,994.45328
Overall Steps per Second: 7,248.93889
Timestep Collection Time: 3.85057
Timestep Consumption Time: 3.05196
PPO Batch Consumption Time: 0.22993
Total Iteration Time: 6.90253
Cumulative Model Updates: 143,300
Cumulative Timesteps: 1,162,304,646
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.18632
Policy Entropy: 4.32005
Value Function Loss: 0.00284
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03359
Policy Update Magnitude: 1.09618
Value Function Update Magnitude: 0.80962
Collected Steps per Second: 13,010.71023
Overall Steps per Second: 7,174.07838
Timestep Collection Time: 3.84499
Timestep Consumption Time: 3.12817
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.97316
Cumulative Model Updates: 143,309
Cumulative Timesteps: 1,162,354,672
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1162354672...
Checkpoint 1162354672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16560
Policy Entropy: 4.32326
Value Function Loss: 0.00286
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03397
Policy Update Magnitude: 1.09147
Value Function Update Magnitude: 0.81341
Collected Steps per Second: 13,138.95945
Overall Steps per Second: 7,250.43811
Timestep Collection Time: 3.80715
Timestep Consumption Time: 3.09202
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.89917
Cumulative Model Updates: 143,318
Cumulative Timesteps: 1,162,404,694
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16860
Policy Entropy: 4.32240
Value Function Loss: 0.00304
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03573
Policy Update Magnitude: 1.10249
Value Function Update Magnitude: 0.80001
Collected Steps per Second: 13,479.28590
Overall Steps per Second: 7,338.43012
Timestep Collection Time: 3.71073
Timestep Consumption Time: 3.10517
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.81590
Cumulative Model Updates: 143,327
Cumulative Timesteps: 1,162,454,712
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1162454712...
Checkpoint 1162454712 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.98478
Policy Entropy: 4.31952
Value Function Loss: 0.00297
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03435
Policy Update Magnitude: 1.12017
Value Function Update Magnitude: 0.79690
Collected Steps per Second: 12,997.28536
Overall Steps per Second: 7,206.69968
Timestep Collection Time: 3.84880
Timestep Consumption Time: 3.09252
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.94132
Cumulative Model Updates: 143,336
Cumulative Timesteps: 1,162,504,736
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16855
Policy Entropy: 4.31828
Value Function Loss: 0.00296
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03703
Policy Update Magnitude: 1.11101
Value Function Update Magnitude: 0.80088
Collected Steps per Second: 13,038.30344
Overall Steps per Second: 7,229.05893
Timestep Collection Time: 3.83639
Timestep Consumption Time: 3.08291
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.91930
Cumulative Model Updates: 143,345
Cumulative Timesteps: 1,162,554,756
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1162554756...
Checkpoint 1162554756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19003
Policy Entropy: 4.31405
Value Function Loss: 0.00284
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03733
Policy Update Magnitude: 1.09894
Value Function Update Magnitude: 0.79338
Collected Steps per Second: 13,137.32135
Overall Steps per Second: 7,230.77594
Timestep Collection Time: 3.80595
Timestep Consumption Time: 3.10894
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.91489
Cumulative Model Updates: 143,354
Cumulative Timesteps: 1,162,604,756
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.49072
Policy Entropy: 4.31500
Value Function Loss: 0.00285
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03637
Policy Update Magnitude: 1.08357
Value Function Update Magnitude: 0.79180
Collected Steps per Second: 12,916.65496
Overall Steps per Second: 7,103.80232
Timestep Collection Time: 3.87236
Timestep Consumption Time: 3.16865
PPO Batch Consumption Time: 0.23013
Total Iteration Time: 7.04102
Cumulative Model Updates: 143,363
Cumulative Timesteps: 1,162,654,774
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1162654774...
Checkpoint 1162654774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89922
Policy Entropy: 4.31384
Value Function Loss: 0.00296
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03522
Policy Update Magnitude: 1.08287
Value Function Update Magnitude: 0.78955
Collected Steps per Second: 12,898.93047
Overall Steps per Second: 7,266.09216
Timestep Collection Time: 3.87877
Timestep Consumption Time: 3.00691
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.88568
Cumulative Model Updates: 143,372
Cumulative Timesteps: 1,162,704,806
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87305
Policy Entropy: 4.31104
Value Function Loss: 0.00298
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03392
Policy Update Magnitude: 1.08409
Value Function Update Magnitude: 0.74751
Collected Steps per Second: 13,047.21340
Overall Steps per Second: 7,194.19089
Timestep Collection Time: 3.83270
Timestep Consumption Time: 3.11819
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.95089
Cumulative Model Updates: 143,381
Cumulative Timesteps: 1,162,754,812
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1162754812...
Checkpoint 1162754812 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81728
Policy Entropy: 4.31145
Value Function Loss: 0.00307
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 1.08390
Value Function Update Magnitude: 0.74595
Collected Steps per Second: 12,948.19061
Overall Steps per Second: 7,209.42298
Timestep Collection Time: 3.86154
Timestep Consumption Time: 3.07382
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.93537
Cumulative Model Updates: 143,390
Cumulative Timesteps: 1,162,804,812
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.54520
Policy Entropy: 4.30852
Value Function Loss: 0.00305
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03480
Policy Update Magnitude: 1.09074
Value Function Update Magnitude: 0.79802
Collected Steps per Second: 13,012.69384
Overall Steps per Second: 7,302.85646
Timestep Collection Time: 3.84379
Timestep Consumption Time: 3.00532
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.84910
Cumulative Model Updates: 143,399
Cumulative Timesteps: 1,162,854,830
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1162854830...
Checkpoint 1162854830 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40854
Policy Entropy: 4.31017
Value Function Loss: 0.00296
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03509
Policy Update Magnitude: 1.08484
Value Function Update Magnitude: 0.82154
Collected Steps per Second: 13,067.21064
Overall Steps per Second: 7,210.46516
Timestep Collection Time: 3.83050
Timestep Consumption Time: 3.11135
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.94185
Cumulative Model Updates: 143,408
Cumulative Timesteps: 1,162,904,884
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.73017
Policy Entropy: 4.30912
Value Function Loss: 0.00293
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03454
Policy Update Magnitude: 1.07821
Value Function Update Magnitude: 0.79251
Collected Steps per Second: 12,918.91664
Overall Steps per Second: 7,219.19344
Timestep Collection Time: 3.87200
Timestep Consumption Time: 3.05703
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.92903
Cumulative Model Updates: 143,417
Cumulative Timesteps: 1,162,954,906
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1162954906...
Checkpoint 1162954906 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83833
Policy Entropy: 4.31010
Value Function Loss: 0.00282
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03786
Policy Update Magnitude: 1.06848
Value Function Update Magnitude: 0.78952
Collected Steps per Second: 12,866.81624
Overall Steps per Second: 7,110.19141
Timestep Collection Time: 3.88923
Timestep Consumption Time: 3.14884
PPO Batch Consumption Time: 0.23995
Total Iteration Time: 7.03807
Cumulative Model Updates: 143,426
Cumulative Timesteps: 1,163,004,948
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.74648
Policy Entropy: 4.31322
Value Function Loss: 0.00286
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03686
Policy Update Magnitude: 1.07380
Value Function Update Magnitude: 0.79360
Collected Steps per Second: 13,031.00981
Overall Steps per Second: 7,218.35495
Timestep Collection Time: 3.83915
Timestep Consumption Time: 3.09152
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.93066
Cumulative Model Updates: 143,435
Cumulative Timesteps: 1,163,054,976
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1163054976...
Checkpoint 1163054976 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.11263
Policy Entropy: 4.31384
Value Function Loss: 0.00283
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03342
Policy Update Magnitude: 1.09358
Value Function Update Magnitude: 0.79006
Collected Steps per Second: 12,914.81939
Overall Steps per Second: 7,198.34089
Timestep Collection Time: 3.87400
Timestep Consumption Time: 3.07649
PPO Batch Consumption Time: 0.22925
Total Iteration Time: 6.95049
Cumulative Model Updates: 143,444
Cumulative Timesteps: 1,163,105,008
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.91606
Policy Entropy: 4.31379
Value Function Loss: 0.00291
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03435
Policy Update Magnitude: 1.09561
Value Function Update Magnitude: 0.77437
Collected Steps per Second: 12,694.61216
Overall Steps per Second: 7,219.88704
Timestep Collection Time: 3.94230
Timestep Consumption Time: 2.98938
PPO Batch Consumption Time: 0.22797
Total Iteration Time: 6.93169
Cumulative Model Updates: 143,453
Cumulative Timesteps: 1,163,155,054
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1163155054...
Checkpoint 1163155054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76408
Policy Entropy: 4.31281
Value Function Loss: 0.00293
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03664
Policy Update Magnitude: 1.09753
Value Function Update Magnitude: 0.76314
Collected Steps per Second: 12,979.32837
Overall Steps per Second: 7,175.80772
Timestep Collection Time: 3.85320
Timestep Consumption Time: 3.11632
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.96953
Cumulative Model Updates: 143,462
Cumulative Timesteps: 1,163,205,066
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28094
Policy Entropy: 4.31138
Value Function Loss: 0.00304
Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03900
Policy Update Magnitude: 1.09664
Value Function Update Magnitude: 0.79108
Collected Steps per Second: 12,707.84796
Overall Steps per Second: 7,151.77685
Timestep Collection Time: 3.93741
Timestep Consumption Time: 3.05889
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.99630
Cumulative Model Updates: 143,471
Cumulative Timesteps: 1,163,255,102
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1163255102...
Checkpoint 1163255102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.93927
Policy Entropy: 4.30847
Value Function Loss: 0.00292
Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03899
Policy Update Magnitude: 1.09593
Value Function Update Magnitude: 0.78389
Collected Steps per Second: 13,312.95272
Overall Steps per Second: 7,283.16072
Timestep Collection Time: 3.75664
Timestep Consumption Time: 3.11016
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.86680
Cumulative Model Updates: 143,480
Cumulative Timesteps: 1,163,305,114
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.41840
Policy Entropy: 4.30662
Value Function Loss: 0.00308
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03575
Policy Update Magnitude: 1.09373
Value Function Update Magnitude: 0.78508
Collected Steps per Second: 12,988.51407
Overall Steps per Second: 7,105.23831
Timestep Collection Time: 3.85263
Timestep Consumption Time: 3.19006
PPO Batch Consumption Time: 0.23075
Total Iteration Time: 7.04269
Cumulative Model Updates: 143,489
Cumulative Timesteps: 1,163,355,154
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1163355154...
Checkpoint 1163355154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74751
Policy Entropy: 4.31133
Value Function Loss: 0.00296
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 1.09303
Value Function Update Magnitude: 0.80527
Collected Steps per Second: 12,771.66538
Overall Steps per Second: 7,234.19553
Timestep Collection Time: 3.91601
Timestep Consumption Time: 2.99754
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.91355
Cumulative Model Updates: 143,498
Cumulative Timesteps: 1,163,405,168
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58425
Policy Entropy: 4.31430
Value Function Loss: 0.00293
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 1.07574
Value Function Update Magnitude: 0.83188
Collected Steps per Second: 12,837.86040
Overall Steps per Second: 7,136.42699
Timestep Collection Time: 3.89613
Timestep Consumption Time: 3.11270
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 7.00883
Cumulative Model Updates: 143,507
Cumulative Timesteps: 1,163,455,186
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1163455186...
Checkpoint 1163455186 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16460
Policy Entropy: 4.31789
Value Function Loss: 0.00282
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 1.05909
Value Function Update Magnitude: 0.82803
Collected Steps per Second: 12,843.21282
Overall Steps per Second: 7,177.74134
Timestep Collection Time: 3.89653
Timestep Consumption Time: 3.07558
PPO Batch Consumption Time: 0.22930
Total Iteration Time: 6.97211
Cumulative Model Updates: 143,516
Cumulative Timesteps: 1,163,505,230
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.62221
Policy Entropy: 4.31180
Value Function Loss: 0.00282
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03285
Policy Update Magnitude: 1.08183
Value Function Update Magnitude: 0.80409
Collected Steps per Second: 12,916.42625
Overall Steps per Second: 7,292.63403
Timestep Collection Time: 3.87367
Timestep Consumption Time: 2.98722
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.86090
Cumulative Model Updates: 143,525
Cumulative Timesteps: 1,163,555,264
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1163555264...
Checkpoint 1163555264 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12671
Policy Entropy: 4.31300
Value Function Loss: 0.00288
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03476
Policy Update Magnitude: 1.07603
Value Function Update Magnitude: 0.79572
Collected Steps per Second: 12,983.74937
Overall Steps per Second: 7,209.87307
Timestep Collection Time: 3.85359
Timestep Consumption Time: 3.08606
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.93965
Cumulative Model Updates: 143,534
Cumulative Timesteps: 1,163,605,298
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.16283
Policy Entropy: 4.31184
Value Function Loss: 0.00299
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03483
Policy Update Magnitude: 1.06033
Value Function Update Magnitude: 0.78982
Collected Steps per Second: 12,936.83481
Overall Steps per Second: 7,218.73241
Timestep Collection Time: 3.86602
Timestep Consumption Time: 3.06235
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.92836
Cumulative Model Updates: 143,543
Cumulative Timesteps: 1,163,655,312
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1163655312...
Checkpoint 1163655312 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83867
Policy Entropy: 4.31192
Value Function Loss: 0.00311
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03626
Policy Update Magnitude: 1.08403
Value Function Update Magnitude: 0.77872
Collected Steps per Second: 12,856.20715
Overall Steps per Second: 7,097.89096
Timestep Collection Time: 3.88933
Timestep Consumption Time: 3.15530
PPO Batch Consumption Time: 0.24126
Total Iteration Time: 7.04463
Cumulative Model Updates: 143,552
Cumulative Timesteps: 1,163,705,314
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24480
Policy Entropy: 4.30848
Value Function Loss: 0.00321
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03677
Policy Update Magnitude: 1.07927
Value Function Update Magnitude: 0.79972
Collected Steps per Second: 13,058.66338
Overall Steps per Second: 7,210.71943
Timestep Collection Time: 3.83087
Timestep Consumption Time: 3.10686
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.93773
Cumulative Model Updates: 143,561
Cumulative Timesteps: 1,163,755,340
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1163755340...
Checkpoint 1163755340 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.74966
Policy Entropy: 4.30945
Value Function Loss: 0.00315
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03808
Policy Update Magnitude: 1.08440
Value Function Update Magnitude: 0.81085
Collected Steps per Second: 13,012.98633
Overall Steps per Second: 7,209.51140
Timestep Collection Time: 3.84585
Timestep Consumption Time: 3.09581
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.94166
Cumulative Model Updates: 143,570
Cumulative Timesteps: 1,163,805,386
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33797
Policy Entropy: 4.31544
Value Function Loss: 0.00283
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03574
Policy Update Magnitude: 1.06931
Value Function Update Magnitude: 0.78278
Collected Steps per Second: 12,910.26035
Overall Steps per Second: 7,276.08868
Timestep Collection Time: 3.87397
Timestep Consumption Time: 2.99977
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.87375
Cumulative Model Updates: 143,579
Cumulative Timesteps: 1,163,855,400
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1163855400...
Checkpoint 1163855400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.99954
Policy Entropy: 4.31352
Value Function Loss: 0.00285
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 1.04953
Value Function Update Magnitude: 0.76955
Collected Steps per Second: 12,797.32027
Overall Steps per Second: 7,147.79770
Timestep Collection Time: 3.90941
Timestep Consumption Time: 3.08995
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.99936
Cumulative Model Updates: 143,588
Cumulative Timesteps: 1,163,905,430
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.21882
Policy Entropy: 4.31813
Value Function Loss: 0.00277
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03524
Policy Update Magnitude: 1.05015
Value Function Update Magnitude: 0.76947
Collected Steps per Second: 12,811.72379
Overall Steps per Second: 7,167.15678
Timestep Collection Time: 3.90361
Timestep Consumption Time: 3.07433
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.97794
Cumulative Model Updates: 143,597
Cumulative Timesteps: 1,163,955,442
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1163955442...
Checkpoint 1163955442 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.55712
Policy Entropy: 4.31731
Value Function Loss: 0.00295
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03880
Policy Update Magnitude: 1.06064
Value Function Update Magnitude: 0.77320
Collected Steps per Second: 12,692.84851
Overall Steps per Second: 7,214.55688
Timestep Collection Time: 3.94222
Timestep Consumption Time: 2.99348
PPO Batch Consumption Time: 0.22952
Total Iteration Time: 6.93570
Cumulative Model Updates: 143,606
Cumulative Timesteps: 1,164,005,480
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.55569
Policy Entropy: 4.31983
Value Function Loss: 0.00288
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03824
Policy Update Magnitude: 1.06889
Value Function Update Magnitude: 0.76768
Collected Steps per Second: 13,072.92440
Overall Steps per Second: 7,156.69967
Timestep Collection Time: 3.82638
Timestep Consumption Time: 3.16315
PPO Batch Consumption Time: 0.22974
Total Iteration Time: 6.98953
Cumulative Model Updates: 143,615
Cumulative Timesteps: 1,164,055,502
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1164055502...
Checkpoint 1164055502 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.92936
Policy Entropy: 4.32092
Value Function Loss: 0.00279
Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03761
Policy Update Magnitude: 1.06703
Value Function Update Magnitude: 0.76010
Collected Steps per Second: 12,814.78004
Overall Steps per Second: 7,164.12333
Timestep Collection Time: 3.90377
Timestep Consumption Time: 3.07908
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.98285
Cumulative Model Updates: 143,624
Cumulative Timesteps: 1,164,105,528
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.51098
Policy Entropy: 4.31961
Value Function Loss: 0.00271
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03527
Policy Update Magnitude: 1.04353
Value Function Update Magnitude: 0.75897
Collected Steps per Second: 12,955.35366
Overall Steps per Second: 7,286.76919
Timestep Collection Time: 3.86033
Timestep Consumption Time: 3.00306
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.86340
Cumulative Model Updates: 143,633
Cumulative Timesteps: 1,164,155,540
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1164155540...
Checkpoint 1164155540 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76386
Policy Entropy: 4.32302
Value Function Loss: 0.00276
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03483
Policy Update Magnitude: 1.04574
Value Function Update Magnitude: 0.73474
Collected Steps per Second: 12,827.17811
Overall Steps per Second: 7,135.84658
Timestep Collection Time: 3.89984
Timestep Consumption Time: 3.11040
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 7.01024
Cumulative Model Updates: 143,642
Cumulative Timesteps: 1,164,205,564
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57865
Policy Entropy: 4.32358
Value Function Loss: 0.00275
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03549
Policy Update Magnitude: 1.04592
Value Function Update Magnitude: 0.73240
Collected Steps per Second: 13,009.16312
Overall Steps per Second: 7,221.50949
Timestep Collection Time: 3.84437
Timestep Consumption Time: 3.08105
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.92542
Cumulative Model Updates: 143,651
Cumulative Timesteps: 1,164,255,576
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1164255576...
Checkpoint 1164255576 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.20463
Policy Entropy: 4.32039
Value Function Loss: 0.00295
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03437
Policy Update Magnitude: 1.05254
Value Function Update Magnitude: 0.76140
Collected Steps per Second: 13,436.47084
Overall Steps per Second: 7,322.84918
Timestep Collection Time: 3.72509
Timestep Consumption Time: 3.10996
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.83504
Cumulative Model Updates: 143,660
Cumulative Timesteps: 1,164,305,628
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22331
Policy Entropy: 4.32155
Value Function Loss: 0.00290
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 1.06601
Value Function Update Magnitude: 0.80369
Collected Steps per Second: 13,147.95761
Overall Steps per Second: 7,238.56942
Timestep Collection Time: 3.80378
Timestep Consumption Time: 3.10532
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.90910
Cumulative Model Updates: 143,669
Cumulative Timesteps: 1,164,355,640
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1164355640...
Checkpoint 1164355640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47633
Policy Entropy: 4.31805
Value Function Loss: 0.00290
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03544
Policy Update Magnitude: 1.06582
Value Function Update Magnitude: 0.81786
Collected Steps per Second: 12,968.28693
Overall Steps per Second: 7,183.79132
Timestep Collection Time: 3.85587
Timestep Consumption Time: 3.10480
PPO Batch Consumption Time: 0.23012
Total Iteration Time: 6.96067
Cumulative Model Updates: 143,678
Cumulative Timesteps: 1,164,405,644
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.00761
Policy Entropy: 4.32050
Value Function Loss: 0.00281
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 1.07608
Value Function Update Magnitude: 0.79698
Collected Steps per Second: 13,177.40961
Overall Steps per Second: 7,215.99633
Timestep Collection Time: 3.79710
Timestep Consumption Time: 3.13693
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.93404
Cumulative Model Updates: 143,687
Cumulative Timesteps: 1,164,455,680
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1164455680...
Checkpoint 1164455680 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79559
Policy Entropy: 4.32004
Value Function Loss: 0.00281
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03542
Policy Update Magnitude: 1.06827
Value Function Update Magnitude: 0.80682
Collected Steps per Second: 12,962.34145
Overall Steps per Second: 7,182.56351
Timestep Collection Time: 3.85949
Timestep Consumption Time: 3.10571
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.96520
Cumulative Model Updates: 143,696
Cumulative Timesteps: 1,164,505,708
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23940
Policy Entropy: 4.32219
Value Function Loss: 0.00276
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03492
Policy Update Magnitude: 1.04414
Value Function Update Magnitude: 0.81757
Collected Steps per Second: 12,769.10573
Overall Steps per Second: 7,144.96288
Timestep Collection Time: 3.91852
Timestep Consumption Time: 3.08446
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 7.00298
Cumulative Model Updates: 143,705
Cumulative Timesteps: 1,164,555,744
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1164555744...
Checkpoint 1164555744 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.77329
Policy Entropy: 4.32603
Value Function Loss: 0.00278
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03372
Policy Update Magnitude: 1.05577
Value Function Update Magnitude: 0.81318
Collected Steps per Second: 13,200.76823
Overall Steps per Second: 7,244.36667
Timestep Collection Time: 3.78887
Timestep Consumption Time: 3.11525
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.90412
Cumulative Model Updates: 143,714
Cumulative Timesteps: 1,164,605,760
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.77430
Policy Entropy: 4.32705
Value Function Loss: 0.00276
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03543
Policy Update Magnitude: 1.07295
Value Function Update Magnitude: 0.78584
Collected Steps per Second: 12,900.64760
Overall Steps per Second: 7,162.12461
Timestep Collection Time: 3.87717
Timestep Consumption Time: 3.10651
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.98368
Cumulative Model Updates: 143,723
Cumulative Timesteps: 1,164,655,778
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1164655778...
Checkpoint 1164655778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.06888
Policy Entropy: 4.32257
Value Function Loss: 0.00284
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 1.07500
Value Function Update Magnitude: 0.76639
Collected Steps per Second: 12,981.15083
Overall Steps per Second: 7,205.31019
Timestep Collection Time: 3.85235
Timestep Consumption Time: 3.08808
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.94044
Cumulative Model Updates: 143,732
Cumulative Timesteps: 1,164,705,786
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.80657
Policy Entropy: 4.31862
Value Function Loss: 0.00283
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03327
Policy Update Magnitude: 1.08427
Value Function Update Magnitude: 0.76475
Collected Steps per Second: 13,240.50161
Overall Steps per Second: 7,174.64444
Timestep Collection Time: 3.77841
Timestep Consumption Time: 3.19448
PPO Batch Consumption Time: 0.23335
Total Iteration Time: 6.97289
Cumulative Model Updates: 143,741
Cumulative Timesteps: 1,164,755,814
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1164755814...
Checkpoint 1164755814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.82587
Policy Entropy: 4.31511
Value Function Loss: 0.00295
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03620
Policy Update Magnitude: 1.09597
Value Function Update Magnitude: 0.78036
Collected Steps per Second: 12,891.95257
Overall Steps per Second: 7,160.21949
Timestep Collection Time: 3.88165
Timestep Consumption Time: 3.10725
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.98889
Cumulative Model Updates: 143,750
Cumulative Timesteps: 1,164,805,856
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.94852
Policy Entropy: 4.31636
Value Function Loss: 0.00284
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03452
Policy Update Magnitude: 1.09210
Value Function Update Magnitude: 0.79216
Collected Steps per Second: 12,899.52284
Overall Steps per Second: 7,270.61164
Timestep Collection Time: 3.87937
Timestep Consumption Time: 3.00341
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.88278
Cumulative Model Updates: 143,759
Cumulative Timesteps: 1,164,855,898
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1164855898...
Checkpoint 1164855898 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.22430
Policy Entropy: 4.31936
Value Function Loss: 0.00293
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 1.08312
Value Function Update Magnitude: 0.78766
Collected Steps per Second: 13,002.12558
Overall Steps per Second: 7,184.73942
Timestep Collection Time: 3.84568
Timestep Consumption Time: 3.11379
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.95947
Cumulative Model Updates: 143,768
Cumulative Timesteps: 1,164,905,900
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.47869
Policy Entropy: 4.31947
Value Function Loss: 0.00281
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03235
Policy Update Magnitude: 1.07444
Value Function Update Magnitude: 0.79548
Collected Steps per Second: 12,992.99191
Overall Steps per Second: 7,211.12989
Timestep Collection Time: 3.85054
Timestep Consumption Time: 3.08735
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.93789
Cumulative Model Updates: 143,777
Cumulative Timesteps: 1,164,955,930
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1164955930...
Checkpoint 1164955930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89591
Policy Entropy: 4.31907
Value Function Loss: 0.00290
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03164
Policy Update Magnitude: 1.06471
Value Function Update Magnitude: 0.79692
Collected Steps per Second: 12,855.34450
Overall Steps per Second: 7,258.19057
Timestep Collection Time: 3.89021
Timestep Consumption Time: 2.99994
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.89015
Cumulative Model Updates: 143,786
Cumulative Timesteps: 1,165,005,940
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.29007
Policy Entropy: 4.31757
Value Function Loss: 0.00273
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 1.05788
Value Function Update Magnitude: 0.77796
Collected Steps per Second: 13,096.31813
Overall Steps per Second: 7,229.03601
Timestep Collection Time: 3.81955
Timestep Consumption Time: 3.10005
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.91959
Cumulative Model Updates: 143,795
Cumulative Timesteps: 1,165,055,962
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1165055962...
Checkpoint 1165055962 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.32229
Policy Entropy: 4.31392
Value Function Loss: 0.00274
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03292
Policy Update Magnitude: 1.06235
Value Function Update Magnitude: 0.79074
Collected Steps per Second: 12,968.00295
Overall Steps per Second: 7,042.29327
Timestep Collection Time: 3.85811
Timestep Consumption Time: 3.24639
PPO Batch Consumption Time: 0.24145
Total Iteration Time: 7.10450
Cumulative Model Updates: 143,804
Cumulative Timesteps: 1,165,105,994
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.19582
Policy Entropy: 4.32049
Value Function Loss: 0.00265
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03416
Policy Update Magnitude: 1.05730
Value Function Update Magnitude: 0.77192
Collected Steps per Second: 12,984.18940
Overall Steps per Second: 7,311.22655
Timestep Collection Time: 3.85115
Timestep Consumption Time: 2.98820
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.83934
Cumulative Model Updates: 143,813
Cumulative Timesteps: 1,165,155,998
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1165155998...
Checkpoint 1165155998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.45294
Policy Entropy: 4.31958
Value Function Loss: 0.00279
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03431
Policy Update Magnitude: 1.05283
Value Function Update Magnitude: 0.75489
Collected Steps per Second: 12,900.56213
Overall Steps per Second: 7,170.99123
Timestep Collection Time: 3.87968
Timestep Consumption Time: 3.09983
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.97951
Cumulative Model Updates: 143,822
Cumulative Timesteps: 1,165,206,048
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.07272
Policy Entropy: 4.32018
Value Function Loss: 0.00285
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03330
Policy Update Magnitude: 1.06304
Value Function Update Magnitude: 0.78715
Collected Steps per Second: 13,016.97776
Overall Steps per Second: 7,232.31251
Timestep Collection Time: 3.84252
Timestep Consumption Time: 3.07339
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.91591
Cumulative Model Updates: 143,831
Cumulative Timesteps: 1,165,256,066
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1165256066...
Checkpoint 1165256066 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.00254
Policy Entropy: 4.31693
Value Function Loss: 0.00291
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03458
Policy Update Magnitude: 1.06303
Value Function Update Magnitude: 0.78686
Collected Steps per Second: 13,190.38165
Overall Steps per Second: 7,240.93022
Timestep Collection Time: 3.79367
Timestep Consumption Time: 3.11704
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.91071
Cumulative Model Updates: 143,840
Cumulative Timesteps: 1,165,306,106
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.55932
Policy Entropy: 4.31945
Value Function Loss: 0.00288
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03378
Policy Update Magnitude: 1.08030
Value Function Update Magnitude: 0.80783
Collected Steps per Second: 12,920.19592
Overall Steps per Second: 7,167.07835
Timestep Collection Time: 3.87239
Timestep Consumption Time: 3.10842
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.98081
Cumulative Model Updates: 143,849
Cumulative Timesteps: 1,165,356,138
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1165356138...
Checkpoint 1165356138 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.44559
Policy Entropy: 4.32131
Value Function Loss: 0.00282
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03320
Policy Update Magnitude: 1.07925
Value Function Update Magnitude: 0.81773
Collected Steps per Second: 12,701.50096
Overall Steps per Second: 7,203.67376
Timestep Collection Time: 3.93749
Timestep Consumption Time: 3.00508
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.94257
Cumulative Model Updates: 143,858
Cumulative Timesteps: 1,165,406,150
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.70296
Policy Entropy: 4.32000
Value Function Loss: 0.00281
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 1.07967
Value Function Update Magnitude: 0.84821
Collected Steps per Second: 12,998.50134
Overall Steps per Second: 7,127.41484
Timestep Collection Time: 3.84783
Timestep Consumption Time: 3.16958
PPO Batch Consumption Time: 0.23083
Total Iteration Time: 7.01741
Cumulative Model Updates: 143,867
Cumulative Timesteps: 1,165,456,166
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1165456166...
Checkpoint 1165456166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.10248
Policy Entropy: 4.31597
Value Function Loss: 0.00283
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03441
Policy Update Magnitude: 1.08102
Value Function Update Magnitude: 0.80832
Collected Steps per Second: 12,892.60642
Overall Steps per Second: 7,212.04889
Timestep Collection Time: 3.87897
Timestep Consumption Time: 3.05526
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.93423
Cumulative Model Updates: 143,876
Cumulative Timesteps: 1,165,506,176
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05864
Policy Entropy: 4.30852
Value Function Loss: 0.00306
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03496
Policy Update Magnitude: 1.09251
Value Function Update Magnitude: 0.78555
Collected Steps per Second: 12,892.84706
Overall Steps per Second: 7,264.32012
Timestep Collection Time: 3.87827
Timestep Consumption Time: 3.00496
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.88323
Cumulative Model Updates: 143,885
Cumulative Timesteps: 1,165,556,178
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1165556178...
Checkpoint 1165556178 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.25381
Policy Entropy: 4.30978
Value Function Loss: 0.00306
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03528
Policy Update Magnitude: 1.08277
Value Function Update Magnitude: 0.82386
Collected Steps per Second: 13,021.71016
Overall Steps per Second: 7,201.21911
Timestep Collection Time: 3.84020
Timestep Consumption Time: 3.10390
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.94410
Cumulative Model Updates: 143,894
Cumulative Timesteps: 1,165,606,184
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.23620
Policy Entropy: 4.30782
Value Function Loss: 0.00302
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03454
Policy Update Magnitude: 1.07269
Value Function Update Magnitude: 0.84514
Collected Steps per Second: 13,034.96247
Overall Steps per Second: 7,211.72496
Timestep Collection Time: 3.83737
Timestep Consumption Time: 3.09856
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 6.93593
Cumulative Model Updates: 143,903
Cumulative Timesteps: 1,165,656,204
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1165656204...
Checkpoint 1165656204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.25531
Policy Entropy: 4.31517
Value Function Loss: 0.00275
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03273
Policy Update Magnitude: 1.05711
Value Function Update Magnitude: 0.80631
Collected Steps per Second: 12,736.99818
Overall Steps per Second: 7,223.89456
Timestep Collection Time: 3.92604
Timestep Consumption Time: 2.99626
PPO Batch Consumption Time: 0.22921
Total Iteration Time: 6.92230
Cumulative Model Updates: 143,912
Cumulative Timesteps: 1,165,706,210
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82782
Policy Entropy: 4.31506
Value Function Loss: 0.00280
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03292
Policy Update Magnitude: 1.03809
Value Function Update Magnitude: 0.77400
Collected Steps per Second: 13,102.89080
Overall Steps per Second: 7,222.23187
Timestep Collection Time: 3.81748
Timestep Consumption Time: 3.10836
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.92584
Cumulative Model Updates: 143,921
Cumulative Timesteps: 1,165,756,230
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1165756230...
Checkpoint 1165756230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.56317
Policy Entropy: 4.31510
Value Function Loss: 0.00271
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03342
Policy Update Magnitude: 1.03636
Value Function Update Magnitude: 0.75976
Collected Steps per Second: 12,999.09794
Overall Steps per Second: 7,102.87540
Timestep Collection Time: 3.84873
Timestep Consumption Time: 3.19490
PPO Batch Consumption Time: 0.23610
Total Iteration Time: 7.04363
Cumulative Model Updates: 143,930
Cumulative Timesteps: 1,165,806,260
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.60789
Policy Entropy: 4.31299
Value Function Loss: 0.00273
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03459
Policy Update Magnitude: 1.05135
Value Function Update Magnitude: 0.79471
Collected Steps per Second: 12,937.09516
Overall Steps per Second: 7,272.61145
Timestep Collection Time: 3.86857
Timestep Consumption Time: 3.01314
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.88171
Cumulative Model Updates: 143,939
Cumulative Timesteps: 1,165,856,308
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1165856308...
Checkpoint 1165856308 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.91322
Policy Entropy: 4.31169
Value Function Loss: 0.00270
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03710
Policy Update Magnitude: 1.05060
Value Function Update Magnitude: 0.80951
Collected Steps per Second: 12,908.72832
Overall Steps per Second: 7,157.70584
Timestep Collection Time: 3.87366
Timestep Consumption Time: 3.11238
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.98604
Cumulative Model Updates: 143,948
Cumulative Timesteps: 1,165,906,312
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.47988
Policy Entropy: 4.31188
Value Function Loss: 0.00276
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 1.03661
Value Function Update Magnitude: 0.80351
Collected Steps per Second: 13,006.39997
Overall Steps per Second: 7,225.16749
Timestep Collection Time: 3.84580
Timestep Consumption Time: 3.07722
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.92302
Cumulative Model Updates: 143,957
Cumulative Timesteps: 1,165,956,332
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1165956332...
Checkpoint 1165956332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.41455
Policy Entropy: 4.31262
Value Function Loss: 0.00285
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 1.05128
Value Function Update Magnitude: 0.80423
Collected Steps per Second: 13,153.22481
Overall Steps per Second: 7,264.89235
Timestep Collection Time: 3.80317
Timestep Consumption Time: 3.08254
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.88572
Cumulative Model Updates: 143,966
Cumulative Timesteps: 1,166,006,356
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64021
Policy Entropy: 4.31667
Value Function Loss: 0.00283
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03448
Policy Update Magnitude: 1.05360
Value Function Update Magnitude: 0.81570
Collected Steps per Second: 12,870.48480
Overall Steps per Second: 7,152.14460
Timestep Collection Time: 3.88610
Timestep Consumption Time: 3.10705
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.99315
Cumulative Model Updates: 143,975
Cumulative Timesteps: 1,166,056,372
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1166056372...
Checkpoint 1166056372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50601
Policy Entropy: 4.31563
Value Function Loss: 0.00282
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 1.05248
Value Function Update Magnitude: 0.79895
Collected Steps per Second: 12,905.94368
Overall Steps per Second: 7,142.39809
Timestep Collection Time: 3.87589
Timestep Consumption Time: 3.12764
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 7.00353
Cumulative Model Updates: 143,984
Cumulative Timesteps: 1,166,106,394
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80669
Policy Entropy: 4.31544
Value Function Loss: 0.00282
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03156
Policy Update Magnitude: 1.06289
Value Function Update Magnitude: 0.79677
Collected Steps per Second: 13,300.37927
Overall Steps per Second: 7,192.78120
Timestep Collection Time: 3.76245
Timestep Consumption Time: 3.19480
PPO Batch Consumption Time: 0.23500
Total Iteration Time: 6.95725
Cumulative Model Updates: 143,993
Cumulative Timesteps: 1,166,156,436
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1166156436...
Checkpoint 1166156436 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90356
Policy Entropy: 4.31248
Value Function Loss: 0.00281
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03224
Policy Update Magnitude: 1.06253
Value Function Update Magnitude: 0.78330
Collected Steps per Second: 13,068.31235
Overall Steps per Second: 7,223.17456
Timestep Collection Time: 3.82773
Timestep Consumption Time: 3.09748
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.92521
Cumulative Model Updates: 144,002
Cumulative Timesteps: 1,166,206,458
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.53581
Policy Entropy: 4.31251
Value Function Loss: 0.00285
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03381
Policy Update Magnitude: 1.07014
Value Function Update Magnitude: 0.81966
Collected Steps per Second: 13,029.05783
Overall Steps per Second: 7,238.92891
Timestep Collection Time: 3.84126
Timestep Consumption Time: 3.07247
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.91373
Cumulative Model Updates: 144,011
Cumulative Timesteps: 1,166,256,506
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1166256506...
Checkpoint 1166256506 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97900
Policy Entropy: 4.30945
Value Function Loss: 0.00290
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03344
Policy Update Magnitude: 1.08451
Value Function Update Magnitude: 0.82709
Collected Steps per Second: 13,193.61834
Overall Steps per Second: 7,267.15556
Timestep Collection Time: 3.79047
Timestep Consumption Time: 3.09118
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.88165
Cumulative Model Updates: 144,020
Cumulative Timesteps: 1,166,306,516
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.58012
Policy Entropy: 4.30981
Value Function Loss: 0.00289
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03538
Policy Update Magnitude: 1.08258
Value Function Update Magnitude: 0.82274
Collected Steps per Second: 13,076.41374
Overall Steps per Second: 7,216.62812
Timestep Collection Time: 3.82582
Timestep Consumption Time: 3.10650
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.93232
Cumulative Model Updates: 144,029
Cumulative Timesteps: 1,166,356,544
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1166356544...
Checkpoint 1166356544 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85657
Policy Entropy: 4.31014
Value Function Loss: 0.00278
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03482
Policy Update Magnitude: 1.05416
Value Function Update Magnitude: 0.79525
Collected Steps per Second: 12,749.88522
Overall Steps per Second: 7,163.47560
Timestep Collection Time: 3.92349
Timestep Consumption Time: 3.05972
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.98320
Cumulative Model Updates: 144,038
Cumulative Timesteps: 1,166,406,568
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.42989
Policy Entropy: 4.31542
Value Function Loss: 0.00273
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03448
Policy Update Magnitude: 1.04207
Value Function Update Magnitude: 0.76249
Collected Steps per Second: 13,267.15067
Overall Steps per Second: 7,271.14904
Timestep Collection Time: 3.77112
Timestep Consumption Time: 3.10977
PPO Batch Consumption Time: 0.22937
Total Iteration Time: 6.88089
Cumulative Model Updates: 144,047
Cumulative Timesteps: 1,166,456,600
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1166456600...
Checkpoint 1166456600 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.43764
Policy Entropy: 4.31200
Value Function Loss: 0.00286
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 1.05151
Value Function Update Magnitude: 0.79485
Collected Steps per Second: 12,837.99270
Overall Steps per Second: 7,054.75742
Timestep Collection Time: 3.89547
Timestep Consumption Time: 3.19336
PPO Batch Consumption Time: 0.23344
Total Iteration Time: 7.08883
Cumulative Model Updates: 144,056
Cumulative Timesteps: 1,166,506,610
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95606
Policy Entropy: 4.31005
Value Function Loss: 0.00291
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 1.06644
Value Function Update Magnitude: 0.78624
Collected Steps per Second: 12,981.82417
Overall Steps per Second: 7,212.45192
Timestep Collection Time: 3.85370
Timestep Consumption Time: 3.08264
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.93634
Cumulative Model Updates: 144,065
Cumulative Timesteps: 1,166,556,638
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1166556638...
Checkpoint 1166556638 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.38966
Policy Entropy: 4.31058
Value Function Loss: 0.00283
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03528
Policy Update Magnitude: 1.04964
Value Function Update Magnitude: 0.79443
Collected Steps per Second: 13,041.60979
Overall Steps per Second: 7,222.72637
Timestep Collection Time: 3.83434
Timestep Consumption Time: 3.08908
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.92342
Cumulative Model Updates: 144,074
Cumulative Timesteps: 1,166,606,644
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04219
Policy Entropy: 4.31173
Value Function Loss: 0.00274
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 1.04597
Value Function Update Magnitude: 0.78006
Collected Steps per Second: 12,990.68698
Overall Steps per Second: 7,191.30518
Timestep Collection Time: 3.85122
Timestep Consumption Time: 3.10579
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.95701
Cumulative Model Updates: 144,083
Cumulative Timesteps: 1,166,656,674
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1166656674...
Checkpoint 1166656674 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27473
Policy Entropy: 4.31774
Value Function Loss: 0.00259
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03358
Policy Update Magnitude: 1.02351
Value Function Update Magnitude: 0.73624
Collected Steps per Second: 12,920.94901
Overall Steps per Second: 7,201.24906
Timestep Collection Time: 3.87216
Timestep Consumption Time: 3.07552
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.94768
Cumulative Model Updates: 144,092
Cumulative Timesteps: 1,166,706,706
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.73271
Policy Entropy: 4.31907
Value Function Loss: 0.00263
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03360
Policy Update Magnitude: 1.00958
Value Function Update Magnitude: 0.70876
Collected Steps per Second: 13,337.96428
Overall Steps per Second: 7,303.83701
Timestep Collection Time: 3.75215
Timestep Consumption Time: 3.09987
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.85201
Cumulative Model Updates: 144,101
Cumulative Timesteps: 1,166,756,752
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1166756752...
Checkpoint 1166756752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18141
Policy Entropy: 4.32148
Value Function Loss: 0.00281
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03388
Policy Update Magnitude: 1.03217
Value Function Update Magnitude: 0.75420
Collected Steps per Second: 12,972.92475
Overall Steps per Second: 7,193.88701
Timestep Collection Time: 3.85557
Timestep Consumption Time: 3.09728
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.95285
Cumulative Model Updates: 144,110
Cumulative Timesteps: 1,166,806,770
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68991
Policy Entropy: 4.32022
Value Function Loss: 0.00281
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03479
Policy Update Magnitude: 1.05472
Value Function Update Magnitude: 0.79065
Collected Steps per Second: 12,983.21039
Overall Steps per Second: 7,158.09080
Timestep Collection Time: 3.85144
Timestep Consumption Time: 3.13423
PPO Batch Consumption Time: 0.22937
Total Iteration Time: 6.98566
Cumulative Model Updates: 144,119
Cumulative Timesteps: 1,166,856,774
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1166856774...
Checkpoint 1166856774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.94378
Policy Entropy: 4.31795
Value Function Loss: 0.00290
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03743
Policy Update Magnitude: 1.05941
Value Function Update Magnitude: 0.76506
Collected Steps per Second: 13,139.54914
Overall Steps per Second: 7,234.48004
Timestep Collection Time: 3.80774
Timestep Consumption Time: 3.10803
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.91577
Cumulative Model Updates: 144,128
Cumulative Timesteps: 1,166,906,806
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.65373
Policy Entropy: 4.31576
Value Function Loss: 0.00285
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 1.08114
Value Function Update Magnitude: 0.76816
Collected Steps per Second: 12,598.92685
Overall Steps per Second: 7,078.70371
Timestep Collection Time: 3.97304
Timestep Consumption Time: 3.09831
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 7.07135
Cumulative Model Updates: 144,137
Cumulative Timesteps: 1,166,956,862
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1166956862...
Checkpoint 1166956862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19337
Policy Entropy: 4.31624
Value Function Loss: 0.00299
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 1.08107
Value Function Update Magnitude: 0.79750
Collected Steps per Second: 12,971.48374
Overall Steps per Second: 7,209.36723
Timestep Collection Time: 3.85615
Timestep Consumption Time: 3.08204
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.93820
Cumulative Model Updates: 144,146
Cumulative Timesteps: 1,167,006,882
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.79311
Policy Entropy: 4.31956
Value Function Loss: 0.00294
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03411
Policy Update Magnitude: 1.07893
Value Function Update Magnitude: 0.82547
Collected Steps per Second: 13,186.95631
Overall Steps per Second: 7,252.26534
Timestep Collection Time: 3.79602
Timestep Consumption Time: 3.10637
PPO Batch Consumption Time: 0.22947
Total Iteration Time: 6.90240
Cumulative Model Updates: 144,155
Cumulative Timesteps: 1,167,056,940
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 1167056940...
Checkpoint 1167056940 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.65245
Policy Entropy: 4.32112
Value Function Loss: 0.00273
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03443
Policy Update Magnitude: 1.05391
Value Function Update Magnitude: 0.79845
Collected Steps per Second: 12,908.40804
Overall Steps per Second: 7,157.71239
Timestep Collection Time: 3.87453
Timestep Consumption Time: 3.11290
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.98743
Cumulative Model Updates: 144,164
Cumulative Timesteps: 1,167,106,954
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.72414
Policy Entropy: 4.32234
Value Function Loss: 0.00268
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 1.04668
Value Function Update Magnitude: 0.79181
Collected Steps per Second: 12,995.47895
Overall Steps per Second: 7,298.58521
Timestep Collection Time: 3.84765
Timestep Consumption Time: 3.00327
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.85092
Cumulative Model Updates: 144,173
Cumulative Timesteps: 1,167,156,956
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1167156956...
Checkpoint 1167156956 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.92797
Policy Entropy: 4.32183
Value Function Loss: 0.00273
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03190
Policy Update Magnitude: 1.04080
Value Function Update Magnitude: 0.79975
Collected Steps per Second: 13,014.85129
Overall Steps per Second: 7,071.94988
Timestep Collection Time: 3.84484
Timestep Consumption Time: 3.23100
PPO Batch Consumption Time: 0.23707
Total Iteration Time: 7.07584
Cumulative Model Updates: 144,182
Cumulative Timesteps: 1,167,206,996
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.19868
Policy Entropy: 4.32235
Value Function Loss: 0.00281
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03117
Policy Update Magnitude: 1.05015
Value Function Update Magnitude: 0.82925
Collected Steps per Second: 13,008.54641
Overall Steps per Second: 7,194.51326
Timestep Collection Time: 3.84470
Timestep Consumption Time: 3.10698
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.95169
Cumulative Model Updates: 144,191
Cumulative Timesteps: 1,167,257,010
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1167257010...
Checkpoint 1167257010 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31942
Policy Entropy: 4.32332
Value Function Loss: 0.00277
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 1.05641
Value Function Update Magnitude: 0.82750
Collected Steps per Second: 12,873.32461
Overall Steps per Second: 7,261.49891
Timestep Collection Time: 3.88695
Timestep Consumption Time: 3.00391
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.89086
Cumulative Model Updates: 144,200
Cumulative Timesteps: 1,167,307,048
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.62933
Policy Entropy: 4.32203
Value Function Loss: 0.00269
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03318
Policy Update Magnitude: 1.05189
Value Function Update Magnitude: 0.81071
Collected Steps per Second: 13,040.28502
Overall Steps per Second: 7,189.57044
Timestep Collection Time: 3.83596
Timestep Consumption Time: 3.12162
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.95758
Cumulative Model Updates: 144,209
Cumulative Timesteps: 1,167,357,070
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1167357070...
Checkpoint 1167357070 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.49361
Policy Entropy: 4.31972
Value Function Loss: 0.00273
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03506
Policy Update Magnitude: 1.04109
Value Function Update Magnitude: 0.80722
Collected Steps per Second: 12,907.44579
Overall Steps per Second: 7,198.94837
Timestep Collection Time: 3.87373
Timestep Consumption Time: 3.07173
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.94546
Cumulative Model Updates: 144,218
Cumulative Timesteps: 1,167,407,070
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.56657
Policy Entropy: 4.31367
Value Function Loss: 0.00290
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03478
Policy Update Magnitude: 1.06047
Value Function Update Magnitude: 0.81964
Collected Steps per Second: 13,090.95347
Overall Steps per Second: 7,325.93491
Timestep Collection Time: 3.82142
Timestep Consumption Time: 3.00720
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.82862
Cumulative Model Updates: 144,227
Cumulative Timesteps: 1,167,457,096
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1167457096...
Checkpoint 1167457096 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.02897
Policy Entropy: 4.31076
Value Function Loss: 0.00298
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03628
Policy Update Magnitude: 1.09500
Value Function Update Magnitude: 0.81535
Collected Steps per Second: 12,926.26809
Overall Steps per Second: 7,170.60350
Timestep Collection Time: 3.87103
Timestep Consumption Time: 3.10718
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.97821
Cumulative Model Updates: 144,236
Cumulative Timesteps: 1,167,507,134
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19520
Policy Entropy: 4.30899
Value Function Loss: 0.00308
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03701
Policy Update Magnitude: 1.10002
Value Function Update Magnitude: 0.81966
Collected Steps per Second: 12,954.37942
Overall Steps per Second: 7,070.34844
Timestep Collection Time: 3.86217
Timestep Consumption Time: 3.21414
PPO Batch Consumption Time: 0.23984
Total Iteration Time: 7.07631
Cumulative Model Updates: 144,245
Cumulative Timesteps: 1,167,557,166
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1167557166...
Checkpoint 1167557166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.91487
Policy Entropy: 4.31501
Value Function Loss: 0.00297
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03454
Policy Update Magnitude: 1.08825
Value Function Update Magnitude: 0.84137
Collected Steps per Second: 12,913.50394
Overall Steps per Second: 7,253.85701
Timestep Collection Time: 3.87393
Timestep Consumption Time: 3.02254
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.89647
Cumulative Model Updates: 144,254
Cumulative Timesteps: 1,167,607,192
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84589
Policy Entropy: 4.31697
Value Function Loss: 0.00297
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 1.07613
Value Function Update Magnitude: 0.84287
Collected Steps per Second: 13,024.20505
Overall Steps per Second: 7,165.95556
Timestep Collection Time: 3.83977
Timestep Consumption Time: 3.13906
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.97883
Cumulative Model Updates: 144,263
Cumulative Timesteps: 1,167,657,202
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1167657202...
Checkpoint 1167657202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12068
Policy Entropy: 4.31866
Value Function Loss: 0.00297
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03341
Policy Update Magnitude: 1.06783
Value Function Update Magnitude: 0.83274
Collected Steps per Second: 12,914.05161
Overall Steps per Second: 7,214.97098
Timestep Collection Time: 3.87175
Timestep Consumption Time: 3.05828
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.93003
Cumulative Model Updates: 144,272
Cumulative Timesteps: 1,167,707,202
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80004
Policy Entropy: 4.31790
Value Function Loss: 0.00294
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 1.06039
Value Function Update Magnitude: 0.82911
Collected Steps per Second: 12,851.28730
Overall Steps per Second: 7,265.34509
Timestep Collection Time: 3.89113
Timestep Consumption Time: 2.99168
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.88281
Cumulative Model Updates: 144,281
Cumulative Timesteps: 1,167,757,208
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1167757208...
Checkpoint 1167757208 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.65198
Policy Entropy: 4.31926
Value Function Loss: 0.00289
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03450
Policy Update Magnitude: 1.05703
Value Function Update Magnitude: 0.80524
Collected Steps per Second: 12,998.28300
Overall Steps per Second: 7,187.81125
Timestep Collection Time: 3.84666
Timestep Consumption Time: 3.10956
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.95622
Cumulative Model Updates: 144,290
Cumulative Timesteps: 1,167,807,208
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27839
Policy Entropy: 4.32241
Value Function Loss: 0.00280
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 1.04018
Value Function Update Magnitude: 0.79023
Collected Steps per Second: 12,982.93590
Overall Steps per Second: 7,219.91960
Timestep Collection Time: 3.85429
Timestep Consumption Time: 3.07654
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.93083
Cumulative Model Updates: 144,299
Cumulative Timesteps: 1,167,857,248
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1167857248...
Checkpoint 1167857248 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.42070
Policy Entropy: 4.32204
Value Function Loss: 0.00276
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02975
Policy Update Magnitude: 1.03545
Value Function Update Magnitude: 0.78827
Collected Steps per Second: 13,355.58018
Overall Steps per Second: 7,159.41231
Timestep Collection Time: 3.74645
Timestep Consumption Time: 3.24239
PPO Batch Consumption Time: 0.24013
Total Iteration Time: 6.98884
Cumulative Model Updates: 144,308
Cumulative Timesteps: 1,167,907,284
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04670
Policy Entropy: 4.32567
Value Function Loss: 0.00272
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02996
Policy Update Magnitude: 1.02862
Value Function Update Magnitude: 0.78113
Collected Steps per Second: 13,094.06046
Overall Steps per Second: 7,232.46408
Timestep Collection Time: 3.81959
Timestep Consumption Time: 3.09561
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.91521
Cumulative Model Updates: 144,317
Cumulative Timesteps: 1,167,957,298
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1167957298...
Checkpoint 1167957298 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47673
Policy Entropy: 4.32003
Value Function Loss: 0.00277
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03027
Policy Update Magnitude: 1.03590
Value Function Update Magnitude: 0.80269
Collected Steps per Second: 13,015.60890
Overall Steps per Second: 7,252.88564
Timestep Collection Time: 3.84461
Timestep Consumption Time: 3.05471
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.89932
Cumulative Model Updates: 144,326
Cumulative Timesteps: 1,168,007,338
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01230
Policy Entropy: 4.31654
Value Function Loss: 0.00283
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03157
Policy Update Magnitude: 1.06325
Value Function Update Magnitude: 0.83329
Collected Steps per Second: 13,217.56245
Overall Steps per Second: 7,269.87156
Timestep Collection Time: 3.78663
Timestep Consumption Time: 3.09795
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.88458
Cumulative Model Updates: 144,335
Cumulative Timesteps: 1,168,057,388
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1168057388...
Checkpoint 1168057388 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.00373
Policy Entropy: 4.31836
Value Function Loss: 0.00273
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03422
Policy Update Magnitude: 1.03116
Value Function Update Magnitude: 0.83430
Collected Steps per Second: 13,150.53382
Overall Steps per Second: 7,237.94704
Timestep Collection Time: 3.80441
Timestep Consumption Time: 3.10777
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.91218
Cumulative Model Updates: 144,344
Cumulative Timesteps: 1,168,107,418
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.17960
Policy Entropy: 4.31998
Value Function Loss: 0.00267
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 1.02796
Value Function Update Magnitude: 0.82020
Collected Steps per Second: 12,954.47807
Overall Steps per Second: 7,192.45026
Timestep Collection Time: 3.86198
Timestep Consumption Time: 3.09392
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.95590
Cumulative Model Updates: 144,353
Cumulative Timesteps: 1,168,157,448
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1168157448...
Checkpoint 1168157448 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22314
Policy Entropy: 4.32250
Value Function Loss: 0.00276
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 1.05402
Value Function Update Magnitude: 0.81143
Collected Steps per Second: 13,229.94574
Overall Steps per Second: 7,272.28027
Timestep Collection Time: 3.78036
Timestep Consumption Time: 3.09698
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.87735
Cumulative Model Updates: 144,362
Cumulative Timesteps: 1,168,207,462
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03095
Policy Entropy: 4.31809
Value Function Loss: 0.00285
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03578
Policy Update Magnitude: 1.05141
Value Function Update Magnitude: 0.81621
Collected Steps per Second: 13,075.89841
Overall Steps per Second: 7,142.58547
Timestep Collection Time: 3.82459
Timestep Consumption Time: 3.17707
PPO Batch Consumption Time: 0.22981
Total Iteration Time: 7.00167
Cumulative Model Updates: 144,371
Cumulative Timesteps: 1,168,257,472
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1168257472...
Checkpoint 1168257472 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.61595
Policy Entropy: 4.31876
Value Function Loss: 0.00289
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03402
Policy Update Magnitude: 1.05517
Value Function Update Magnitude: 0.83581
Collected Steps per Second: 12,945.82807
Overall Steps per Second: 7,208.84278
Timestep Collection Time: 3.86395
Timestep Consumption Time: 3.07503
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.93898
Cumulative Model Updates: 144,380
Cumulative Timesteps: 1,168,307,494
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19225
Policy Entropy: 4.32031
Value Function Loss: 0.00283
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03502
Policy Update Magnitude: 1.05343
Value Function Update Magnitude: 0.86006
Collected Steps per Second: 13,051.25739
Overall Steps per Second: 7,213.77054
Timestep Collection Time: 3.83289
Timestep Consumption Time: 3.10163
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.93452
Cumulative Model Updates: 144,389
Cumulative Timesteps: 1,168,357,518
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1168357518...
Checkpoint 1168357518 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.11070
Policy Entropy: 4.32388
Value Function Loss: 0.00276
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03451
Policy Update Magnitude: 1.04860
Value Function Update Magnitude: 0.89131
Collected Steps per Second: 12,981.68516
Overall Steps per Second: 7,177.21756
Timestep Collection Time: 3.85235
Timestep Consumption Time: 3.11553
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.96788
Cumulative Model Updates: 144,398
Cumulative Timesteps: 1,168,407,528
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.32905
Policy Entropy: 4.32226
Value Function Loss: 0.00270
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03316
Policy Update Magnitude: 1.05472
Value Function Update Magnitude: 0.84584
Collected Steps per Second: 12,855.40161
Overall Steps per Second: 7,180.07041
Timestep Collection Time: 3.89097
Timestep Consumption Time: 3.07553
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.96651
Cumulative Model Updates: 144,407
Cumulative Timesteps: 1,168,457,548
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1168457548...
Checkpoint 1168457548 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79754
Policy Entropy: 4.32063
Value Function Loss: 0.00274
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03356
Policy Update Magnitude: 1.05589
Value Function Update Magnitude: 0.81671
Collected Steps per Second: 13,170.20180
Overall Steps per Second: 7,245.34827
Timestep Collection Time: 3.79949
Timestep Consumption Time: 3.10701
PPO Batch Consumption Time: 0.22959
Total Iteration Time: 6.90650
Cumulative Model Updates: 144,416
Cumulative Timesteps: 1,168,507,588
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02490
Policy Entropy: 4.31606
Value Function Loss: 0.00290
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03339
Policy Update Magnitude: 1.05913
Value Function Update Magnitude: 0.79083
Collected Steps per Second: 13,120.50911
Overall Steps per Second: 7,217.03122
Timestep Collection Time: 3.81159
Timestep Consumption Time: 3.11785
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.92944
Cumulative Model Updates: 144,425
Cumulative Timesteps: 1,168,557,598
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1168557598...
Checkpoint 1168557598 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85763
Policy Entropy: 4.31198
Value Function Loss: 0.00299
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03421
Policy Update Magnitude: 1.06605
Value Function Update Magnitude: 0.79019
Collected Steps per Second: 12,973.72896
Overall Steps per Second: 7,058.37720
Timestep Collection Time: 3.85533
Timestep Consumption Time: 3.23100
PPO Batch Consumption Time: 0.24049
Total Iteration Time: 7.08633
Cumulative Model Updates: 144,434
Cumulative Timesteps: 1,168,607,616
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68515
Policy Entropy: 4.31432
Value Function Loss: 0.00290
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03671
Policy Update Magnitude: 1.06524
Value Function Update Magnitude: 0.77920
Collected Steps per Second: 13,171.08018
Overall Steps per Second: 7,238.02985
Timestep Collection Time: 3.79665
Timestep Consumption Time: 3.11213
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.90879
Cumulative Model Updates: 144,443
Cumulative Timesteps: 1,168,657,622
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1168657622...
Checkpoint 1168657622 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46218
Policy Entropy: 4.31183
Value Function Loss: 0.00282
Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03802
Policy Update Magnitude: 1.04980
Value Function Update Magnitude: 0.73984
Collected Steps per Second: 12,724.04428
Overall Steps per Second: 7,108.00535
Timestep Collection Time: 3.92973
Timestep Consumption Time: 3.10488
PPO Batch Consumption Time: 0.22819
Total Iteration Time: 7.03460
Cumulative Model Updates: 144,452
Cumulative Timesteps: 1,168,707,624
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.78155
Policy Entropy: 4.31443
Value Function Loss: 0.00289
Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03744
Policy Update Magnitude: 1.04848
Value Function Update Magnitude: 0.74048
Collected Steps per Second: 12,778.43444
Overall Steps per Second: 7,221.06844
Timestep Collection Time: 3.91519
Timestep Consumption Time: 3.01315
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.92834
Cumulative Model Updates: 144,461
Cumulative Timesteps: 1,168,757,654
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1168757654...
Checkpoint 1168757654 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28636
Policy Entropy: 4.31255
Value Function Loss: 0.00304
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03702
Policy Update Magnitude: 1.05302
Value Function Update Magnitude: 0.77932
Collected Steps per Second: 12,993.07904
Overall Steps per Second: 7,193.85197
Timestep Collection Time: 3.84897
Timestep Consumption Time: 3.10280
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 6.95177
Cumulative Model Updates: 144,470
Cumulative Timesteps: 1,168,807,664
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35225
Policy Entropy: 4.31261
Value Function Loss: 0.00296
Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03938
Policy Update Magnitude: 1.05228
Value Function Update Magnitude: 0.79534
Collected Steps per Second: 13,030.53667
Overall Steps per Second: 7,249.27883
Timestep Collection Time: 3.83714
Timestep Consumption Time: 3.06010
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.89724
Cumulative Model Updates: 144,479
Cumulative Timesteps: 1,168,857,664
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1168857664...
Checkpoint 1168857664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28546
Policy Entropy: 4.31325
Value Function Loss: 0.00292
Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03962
Policy Update Magnitude: 1.05099
Value Function Update Magnitude: 0.80135
Collected Steps per Second: 12,803.08539
Overall Steps per Second: 7,238.77575
Timestep Collection Time: 3.90734
Timestep Consumption Time: 3.00350
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.91084
Cumulative Model Updates: 144,488
Cumulative Timesteps: 1,168,907,690
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58236
Policy Entropy: 4.31076
Value Function Loss: 0.00292
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03667
Policy Update Magnitude: 1.05124
Value Function Update Magnitude: 0.82458
Collected Steps per Second: 12,870.99151
Overall Steps per Second: 6,992.19717
Timestep Collection Time: 3.88610
Timestep Consumption Time: 3.26730
PPO Batch Consumption Time: 0.24005
Total Iteration Time: 7.15340
Cumulative Model Updates: 144,497
Cumulative Timesteps: 1,168,957,708
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1168957708...
Checkpoint 1168957708 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66072
Policy Entropy: 4.31057
Value Function Loss: 0.00297
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03642
Policy Update Magnitude: 1.07692
Value Function Update Magnitude: 0.83504
Collected Steps per Second: 12,941.07446
Overall Steps per Second: 7,291.14245
Timestep Collection Time: 3.86459
Timestep Consumption Time: 2.99469
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.85928
Cumulative Model Updates: 144,506
Cumulative Timesteps: 1,169,007,720
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.63570
Policy Entropy: 4.31299
Value Function Loss: 0.00293
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03627
Policy Update Magnitude: 1.06102
Value Function Update Magnitude: 0.81445
Collected Steps per Second: 13,006.95704
Overall Steps per Second: 7,175.45051
Timestep Collection Time: 3.84686
Timestep Consumption Time: 3.12636
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.97322
Cumulative Model Updates: 144,515
Cumulative Timesteps: 1,169,057,756
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1169057756...
Checkpoint 1169057756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.78170
Policy Entropy: 4.31800
Value Function Loss: 0.00293
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 1.05505
Value Function Update Magnitude: 0.80542
Collected Steps per Second: 12,890.73144
Overall Steps per Second: 7,179.08618
Timestep Collection Time: 3.87891
Timestep Consumption Time: 3.08604
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 6.96495
Cumulative Model Updates: 144,524
Cumulative Timesteps: 1,169,107,758
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85321
Policy Entropy: 4.32093
Value Function Loss: 0.00290
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03432
Policy Update Magnitude: 1.05077
Value Function Update Magnitude: 0.80122
Collected Steps per Second: 12,903.94862
Overall Steps per Second: 7,281.46233
Timestep Collection Time: 3.87556
Timestep Consumption Time: 2.99257
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.86813
Cumulative Model Updates: 144,533
Cumulative Timesteps: 1,169,157,768
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1169157768...
Checkpoint 1169157768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.18327
Policy Entropy: 4.32114
Value Function Loss: 0.00294
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03195
Policy Update Magnitude: 1.04218
Value Function Update Magnitude: 0.78537
Collected Steps per Second: 12,965.57983
Overall Steps per Second: 7,198.08063
Timestep Collection Time: 3.85760
Timestep Consumption Time: 3.09092
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.94852
Cumulative Model Updates: 144,542
Cumulative Timesteps: 1,169,207,784
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.84129
Policy Entropy: 4.32143
Value Function Loss: 0.00285
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03493
Policy Update Magnitude: 1.00860
Value Function Update Magnitude: 0.78069
Collected Steps per Second: 12,925.61653
Overall Steps per Second: 7,209.52859
Timestep Collection Time: 3.87107
Timestep Consumption Time: 3.06919
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.94026
Cumulative Model Updates: 144,551
Cumulative Timesteps: 1,169,257,820
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1169257820...
Checkpoint 1169257820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.74287
Policy Entropy: 4.32409
Value Function Loss: 0.00269
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03215
Policy Update Magnitude: 0.98570
Value Function Update Magnitude: 0.76222
Collected Steps per Second: 12,976.48131
Overall Steps per Second: 7,124.92517
Timestep Collection Time: 3.85775
Timestep Consumption Time: 3.16829
PPO Batch Consumption Time: 0.23897
Total Iteration Time: 7.02604
Cumulative Model Updates: 144,560
Cumulative Timesteps: 1,169,307,880
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.44018
Policy Entropy: 4.32740
Value Function Loss: 0.00271
Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.99360
Value Function Update Magnitude: 0.77078
Collected Steps per Second: 12,889.81009
Overall Steps per Second: 7,152.62016
Timestep Collection Time: 3.87903
Timestep Consumption Time: 3.11141
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.99045
Cumulative Model Updates: 144,569
Cumulative Timesteps: 1,169,357,880
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1169357880...
Checkpoint 1169357880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81719
Policy Entropy: 4.32603
Value Function Loss: 0.00269
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02907
Policy Update Magnitude: 1.00995
Value Function Update Magnitude: 0.81489
Collected Steps per Second: 13,018.97409
Overall Steps per Second: 7,219.62706
Timestep Collection Time: 3.84132
Timestep Consumption Time: 3.08563
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.92695
Cumulative Model Updates: 144,578
Cumulative Timesteps: 1,169,407,890
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.25870
Policy Entropy: 4.31889
Value Function Loss: 0.00291
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03397
Policy Update Magnitude: 1.04008
Value Function Update Magnitude: 0.79010
Collected Steps per Second: 13,096.28305
Overall Steps per Second: 7,335.53224
Timestep Collection Time: 3.81925
Timestep Consumption Time: 2.99934
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.81859
Cumulative Model Updates: 144,587
Cumulative Timesteps: 1,169,457,908
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1169457908...
Checkpoint 1169457908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.29893
Policy Entropy: 4.31699
Value Function Loss: 0.00288
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03528
Policy Update Magnitude: 1.04636
Value Function Update Magnitude: 0.80568
Collected Steps per Second: 12,939.26623
Overall Steps per Second: 7,163.16403
Timestep Collection Time: 3.86498
Timestep Consumption Time: 3.11657
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.98155
Cumulative Model Updates: 144,596
Cumulative Timesteps: 1,169,507,918
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.89406
Policy Entropy: 4.31366
Value Function Loss: 0.00295
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03662
Policy Update Magnitude: 1.04064
Value Function Update Magnitude: 0.80553
Collected Steps per Second: 13,179.67519
Overall Steps per Second: 7,275.13870
Timestep Collection Time: 3.79372
Timestep Consumption Time: 3.07900
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.87272
Cumulative Model Updates: 144,605
Cumulative Timesteps: 1,169,557,918
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1169557918...
Checkpoint 1169557918 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85856
Policy Entropy: 4.31615
Value Function Loss: 0.00280
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03420
Policy Update Magnitude: 1.01675
Value Function Update Magnitude: 0.79672
Collected Steps per Second: 13,129.97738
Overall Steps per Second: 7,223.88640
Timestep Collection Time: 3.80823
Timestep Consumption Time: 3.11353
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.92176
Cumulative Model Updates: 144,614
Cumulative Timesteps: 1,169,607,920
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.18095
Policy Entropy: 4.31322
Value Function Loss: 0.00287
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03403
Policy Update Magnitude: 1.02738
Value Function Update Magnitude: 0.74767
Collected Steps per Second: 13,051.28908
Overall Steps per Second: 7,154.51342
Timestep Collection Time: 3.83364
Timestep Consumption Time: 3.15970
PPO Batch Consumption Time: 0.23372
Total Iteration Time: 6.99335
Cumulative Model Updates: 144,623
Cumulative Timesteps: 1,169,657,954
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1169657954...
Checkpoint 1169657954 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.04546
Policy Entropy: 4.31179
Value Function Loss: 0.00282
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 1.02930
Value Function Update Magnitude: 0.71312
Collected Steps per Second: 12,782.41027
Overall Steps per Second: 7,154.41821
Timestep Collection Time: 3.91272
Timestep Consumption Time: 3.07792
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.99065
Cumulative Model Updates: 144,632
Cumulative Timesteps: 1,169,707,968
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.73823
Policy Entropy: 4.31265
Value Function Loss: 0.00292
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03584
Policy Update Magnitude: 1.02281
Value Function Update Magnitude: 0.70995
Collected Steps per Second: 13,398.90567
Overall Steps per Second: 7,299.87620
Timestep Collection Time: 3.73180
Timestep Consumption Time: 3.11791
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.84971
Cumulative Model Updates: 144,641
Cumulative Timesteps: 1,169,757,970
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1169757970...
Checkpoint 1169757970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.73242
Policy Entropy: 4.31568
Value Function Loss: 0.00287
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03555
Policy Update Magnitude: 1.01833
Value Function Update Magnitude: 0.72950
Collected Steps per Second: 12,976.24284
Overall Steps per Second: 7,181.14004
Timestep Collection Time: 3.85397
Timestep Consumption Time: 3.11011
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.96408
Cumulative Model Updates: 144,650
Cumulative Timesteps: 1,169,807,980
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32398
Policy Entropy: 4.31578
Value Function Loss: 0.00296
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03382
Policy Update Magnitude: 1.02067
Value Function Update Magnitude: 0.74927
Collected Steps per Second: 13,007.16283
Overall Steps per Second: 7,213.58295
Timestep Collection Time: 3.84496
Timestep Consumption Time: 3.08807
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.93303
Cumulative Model Updates: 144,659
Cumulative Timesteps: 1,169,857,992
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1169857992...
Checkpoint 1169857992 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03194
Policy Entropy: 4.31570
Value Function Loss: 0.00290
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03482
Policy Update Magnitude: 1.03679
Value Function Update Magnitude: 0.77371
Collected Steps per Second: 13,302.65996
Overall Steps per Second: 7,264.72553
Timestep Collection Time: 3.75970
Timestep Consumption Time: 3.12480
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.88450
Cumulative Model Updates: 144,668
Cumulative Timesteps: 1,169,908,006
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06842
Policy Entropy: 4.31652
Value Function Loss: 0.00286
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03506
Policy Update Magnitude: 1.03546
Value Function Update Magnitude: 0.79826
Collected Steps per Second: 12,897.51060
Overall Steps per Second: 7,163.71450
Timestep Collection Time: 3.87873
Timestep Consumption Time: 3.10452
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.98325
Cumulative Model Updates: 144,677
Cumulative Timesteps: 1,169,958,032
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1169958032...
Checkpoint 1169958032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.87479
Policy Entropy: 4.32272
Value Function Loss: 0.00281
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03303
Policy Update Magnitude: 1.02378
Value Function Update Magnitude: 0.76667
Collected Steps per Second: 12,875.29811
Overall Steps per Second: 7,144.25812
Timestep Collection Time: 3.88542
Timestep Consumption Time: 3.11684
PPO Batch Consumption Time: 0.23788
Total Iteration Time: 7.00227
Cumulative Model Updates: 144,686
Cumulative Timesteps: 1,170,008,058
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.91365
Policy Entropy: 4.32437
Value Function Loss: 0.00279
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 1.01692
Value Function Update Magnitude: 0.75347
Collected Steps per Second: 13,023.30903
Overall Steps per Second: 7,174.83943
Timestep Collection Time: 3.84203
Timestep Consumption Time: 3.13178
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.97381
Cumulative Model Updates: 144,695
Cumulative Timesteps: 1,170,058,094
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1170058094...
Checkpoint 1170058094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60850
Policy Entropy: 4.32844
Value Function Loss: 0.00270
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03096
Policy Update Magnitude: 0.98656
Value Function Update Magnitude: 0.75364
Collected Steps per Second: 12,917.09183
Overall Steps per Second: 7,225.52691
Timestep Collection Time: 3.87347
Timestep Consumption Time: 3.05114
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.92462
Cumulative Model Updates: 144,704
Cumulative Timesteps: 1,170,108,128
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76798
Policy Entropy: 4.33074
Value Function Loss: 0.00263
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03004
Policy Update Magnitude: 0.97637
Value Function Update Magnitude: 0.74312
Collected Steps per Second: 12,821.43651
Overall Steps per Second: 7,245.17846
Timestep Collection Time: 3.90019
Timestep Consumption Time: 3.00178
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.90197
Cumulative Model Updates: 144,713
Cumulative Timesteps: 1,170,158,134
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1170158134...
Checkpoint 1170158134 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.77971
Policy Entropy: 4.33437
Value Function Loss: 0.00259
Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.97921
Value Function Update Magnitude: 0.72565
Collected Steps per Second: 12,973.26321
Overall Steps per Second: 7,179.90171
Timestep Collection Time: 3.85593
Timestep Consumption Time: 3.11130
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.96723
Cumulative Model Updates: 144,722
Cumulative Timesteps: 1,170,208,158
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.35721
Policy Entropy: 4.33148
Value Function Loss: 0.00269
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.97606
Value Function Update Magnitude: 0.74883
Collected Steps per Second: 12,923.53178
Overall Steps per Second: 7,215.77052
Timestep Collection Time: 3.86907
Timestep Consumption Time: 3.06048
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.92954
Cumulative Model Updates: 144,731
Cumulative Timesteps: 1,170,258,160
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1170258160...
Checkpoint 1170258160 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76467
Policy Entropy: 4.33034
Value Function Loss: 0.00265
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02937
Policy Update Magnitude: 0.99007
Value Function Update Magnitude: 0.75421
Collected Steps per Second: 12,956.86231
Overall Steps per Second: 7,301.83181
Timestep Collection Time: 3.85958
Timestep Consumption Time: 2.98912
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.84869
Cumulative Model Updates: 144,740
Cumulative Timesteps: 1,170,308,168
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.69746
Policy Entropy: 4.32804
Value Function Loss: 0.00268
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03097
Policy Update Magnitude: 0.99952
Value Function Update Magnitude: 0.76389
Collected Steps per Second: 12,863.03811
Overall Steps per Second: 7,026.29867
Timestep Collection Time: 3.88882
Timestep Consumption Time: 3.23044
PPO Batch Consumption Time: 0.23942
Total Iteration Time: 7.11925
Cumulative Model Updates: 144,749
Cumulative Timesteps: 1,170,358,190
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1170358190...
Checkpoint 1170358190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.31905
Policy Entropy: 4.32820
Value Function Loss: 0.00268
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 1.01729
Value Function Update Magnitude: 0.79545
Collected Steps per Second: 12,901.47401
Overall Steps per Second: 7,203.94677
Timestep Collection Time: 3.87584
Timestep Consumption Time: 3.06536
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.94120
Cumulative Model Updates: 144,758
Cumulative Timesteps: 1,170,408,194
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.18937
Policy Entropy: 4.32626
Value Function Loss: 0.00272
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03236
Policy Update Magnitude: 1.03148
Value Function Update Magnitude: 0.81820
Collected Steps per Second: 13,022.88550
Overall Steps per Second: 7,290.91407
Timestep Collection Time: 3.84185
Timestep Consumption Time: 3.02039
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.86224
Cumulative Model Updates: 144,767
Cumulative Timesteps: 1,170,458,226
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1170458226...
Checkpoint 1170458226 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.62276
Policy Entropy: 4.32565
Value Function Loss: 0.00270
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03379
Policy Update Magnitude: 1.03823
Value Function Update Magnitude: 0.81813
Collected Steps per Second: 13,113.68595
Overall Steps per Second: 7,221.93146
Timestep Collection Time: 3.81479
Timestep Consumption Time: 3.11216
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.92696
Cumulative Model Updates: 144,776
Cumulative Timesteps: 1,170,508,252
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79855
Policy Entropy: 4.32511
Value Function Loss: 0.00272
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03355
Policy Update Magnitude: 1.03309
Value Function Update Magnitude: 0.79557
Collected Steps per Second: 12,970.15179
Overall Steps per Second: 7,205.92483
Timestep Collection Time: 3.85593
Timestep Consumption Time: 3.08447
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.94040
Cumulative Model Updates: 144,785
Cumulative Timesteps: 1,170,558,264
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1170558264...
Checkpoint 1170558264 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.30557
Policy Entropy: 4.32957
Value Function Loss: 0.00279
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03210
Policy Update Magnitude: 1.02863
Value Function Update Magnitude: 0.79860
Collected Steps per Second: 12,804.67290
Overall Steps per Second: 7,234.43255
Timestep Collection Time: 3.90623
Timestep Consumption Time: 3.00765
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.91388
Cumulative Model Updates: 144,794
Cumulative Timesteps: 1,170,608,282
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.53028
Policy Entropy: 4.33072
Value Function Loss: 0.00278
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 1.02943
Value Function Update Magnitude: 0.81824
Collected Steps per Second: 13,101.67627
Overall Steps per Second: 7,205.99280
Timestep Collection Time: 3.81905
Timestep Consumption Time: 3.12461
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.94366
Cumulative Model Updates: 144,803
Cumulative Timesteps: 1,170,658,318
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1170658318...
Checkpoint 1170658318 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75349
Policy Entropy: 4.33435
Value Function Loss: 0.00264
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 1.01869
Value Function Update Magnitude: 0.80582
Collected Steps per Second: 12,858.33453
Overall Steps per Second: 7,099.64920
Timestep Collection Time: 3.88900
Timestep Consumption Time: 3.15445
PPO Batch Consumption Time: 0.23527
Total Iteration Time: 7.04345
Cumulative Model Updates: 144,812
Cumulative Timesteps: 1,170,708,324
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.30424
Policy Entropy: 4.33086
Value Function Loss: 0.00254
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03066
Policy Update Magnitude: 0.99941
Value Function Update Magnitude: 0.75592
Collected Steps per Second: 12,869.47163
Overall Steps per Second: 7,268.01246
Timestep Collection Time: 3.88781
Timestep Consumption Time: 2.99633
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.88414
Cumulative Model Updates: 144,821
Cumulative Timesteps: 1,170,758,358
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1170758358...
Checkpoint 1170758358 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.97133
Policy Entropy: 4.32744
Value Function Loss: 0.00262
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03134
Policy Update Magnitude: 1.00187
Value Function Update Magnitude: 0.77545
Collected Steps per Second: 12,956.28606
Overall Steps per Second: 7,165.47733
Timestep Collection Time: 3.85913
Timestep Consumption Time: 3.11877
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.97790
Cumulative Model Updates: 144,830
Cumulative Timesteps: 1,170,808,358
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64232
Policy Entropy: 4.32092
Value Function Loss: 0.00279
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 1.00925
Value Function Update Magnitude: 0.79566
Collected Steps per Second: 12,985.99611
Overall Steps per Second: 7,211.19828
Timestep Collection Time: 3.85061
Timestep Consumption Time: 3.08361
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.93422
Cumulative Model Updates: 144,839
Cumulative Timesteps: 1,170,858,362
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1170858362...
Checkpoint 1170858362 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38463
Policy Entropy: 4.31958
Value Function Loss: 0.00288
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03169
Policy Update Magnitude: 1.03407
Value Function Update Magnitude: 0.83429
Collected Steps per Second: 12,758.09430
Overall Steps per Second: 7,121.27667
Timestep Collection Time: 3.91955
Timestep Consumption Time: 3.10250
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 7.02206
Cumulative Model Updates: 144,848
Cumulative Timesteps: 1,170,908,368
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89241
Policy Entropy: 4.31815
Value Function Loss: 0.00288
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 1.03075
Value Function Update Magnitude: 0.79232
Collected Steps per Second: 12,998.43022
Overall Steps per Second: 7,193.21832
Timestep Collection Time: 3.84939
Timestep Consumption Time: 3.10661
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.95600
Cumulative Model Updates: 144,857
Cumulative Timesteps: 1,170,958,404
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1170958404...
Checkpoint 1170958404 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.89301
Policy Entropy: 4.32025
Value Function Loss: 0.00283
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03518
Policy Update Magnitude: 1.02194
Value Function Update Magnitude: 0.76718
Collected Steps per Second: 12,944.60891
Overall Steps per Second: 7,199.44332
Timestep Collection Time: 3.86369
Timestep Consumption Time: 3.08323
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.94693
Cumulative Model Updates: 144,866
Cumulative Timesteps: 1,171,008,418
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23951
Policy Entropy: 4.32087
Value Function Loss: 0.00280
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03465
Policy Update Magnitude: 1.02120
Value Function Update Magnitude: 0.77307
Collected Steps per Second: 12,901.97719
Overall Steps per Second: 7,109.84653
Timestep Collection Time: 3.87941
Timestep Consumption Time: 3.16041
PPO Batch Consumption Time: 0.24128
Total Iteration Time: 7.03981
Cumulative Model Updates: 144,875
Cumulative Timesteps: 1,171,058,470
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1171058470...
Checkpoint 1171058470 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.76953
Policy Entropy: 4.32385
Value Function Loss: 0.00270
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 1.02825
Value Function Update Magnitude: 0.76917
Collected Steps per Second: 12,913.11596
Overall Steps per Second: 7,175.01246
Timestep Collection Time: 3.87234
Timestep Consumption Time: 3.09684
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.96919
Cumulative Model Updates: 144,884
Cumulative Timesteps: 1,171,108,474
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57188
Policy Entropy: 4.32530
Value Function Loss: 0.00273
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 1.01773
Value Function Update Magnitude: 0.76948
Collected Steps per Second: 12,890.12897
Overall Steps per Second: 7,178.85229
Timestep Collection Time: 3.88018
Timestep Consumption Time: 3.08695
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.96713
Cumulative Model Updates: 144,893
Cumulative Timesteps: 1,171,158,490
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1171158490...
Checkpoint 1171158490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83158
Policy Entropy: 4.32525
Value Function Loss: 0.00279
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03234
Policy Update Magnitude: 1.02659
Value Function Update Magnitude: 0.77670
Collected Steps per Second: 13,242.14053
Overall Steps per Second: 7,253.86647
Timestep Collection Time: 3.77673
Timestep Consumption Time: 3.11780
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 6.89453
Cumulative Model Updates: 144,902
Cumulative Timesteps: 1,171,208,502
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61243
Policy Entropy: 4.32037
Value Function Loss: 0.00301
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03368
Policy Update Magnitude: 1.06501
Value Function Update Magnitude: 0.79734
Collected Steps per Second: 12,979.27182
Overall Steps per Second: 7,182.02907
Timestep Collection Time: 3.85676
Timestep Consumption Time: 3.11313
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.96990
Cumulative Model Updates: 144,911
Cumulative Timesteps: 1,171,258,560
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
Saving checkpoint 1171258560...
Checkpoint 1171258560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.32370
Policy Entropy: 4.32205
Value Function Loss: 0.00303
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03442
Policy Update Magnitude: 1.06856
Value Function Update Magnitude: 0.79912
Collected Steps per Second: 12,816.17826
Overall Steps per Second: 7,161.06709
Timestep Collection Time: 3.90304
Timestep Consumption Time: 3.08224
PPO Batch Consumption Time: 0.22957
Total Iteration Time: 6.98527
Cumulative Model Updates: 144,920
Cumulative Timesteps: 1,171,308,582
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.69548
Policy Entropy: 4.32234
Value Function Loss: 0.00297
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03502
Policy Update Magnitude: 1.06875
Value Function Update Magnitude: 0.78667
Collected Steps per Second: 13,144.26865
Overall Steps per Second: 7,200.88352
Timestep Collection Time: 3.80607
Timestep Consumption Time: 3.14141
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 6.94748
Cumulative Model Updates: 144,929
Cumulative Timesteps: 1,171,358,610
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1171358610...
Checkpoint 1171358610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.33888
Policy Entropy: 4.32386
Value Function Loss: 0.00283
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03271
Policy Update Magnitude: 1.05942
Value Function Update Magnitude: 0.80052
Collected Steps per Second: 12,937.42834
Overall Steps per Second: 7,151.95523
Timestep Collection Time: 3.86646
Timestep Consumption Time: 3.12772
PPO Batch Consumption Time: 0.23289
Total Iteration Time: 6.99417
Cumulative Model Updates: 144,938
Cumulative Timesteps: 1,171,408,632
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36075
Policy Entropy: 4.32430
Value Function Loss: 0.00278
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03264
Policy Update Magnitude: 1.05775
Value Function Update Magnitude: 0.81612
Collected Steps per Second: 12,980.12117
Overall Steps per Second: 7,209.30010
Timestep Collection Time: 3.85513
Timestep Consumption Time: 3.08591
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.94103
Cumulative Model Updates: 144,947
Cumulative Timesteps: 1,171,458,672
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1171458672...
Checkpoint 1171458672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.34861
Policy Entropy: 4.32730
Value Function Loss: 0.00276
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03786
Policy Update Magnitude: 1.04863
Value Function Update Magnitude: 0.77672
Collected Steps per Second: 13,393.14900
Overall Steps per Second: 7,305.49663
Timestep Collection Time: 3.73534
Timestep Consumption Time: 3.11265
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.84799
Cumulative Model Updates: 144,956
Cumulative Timesteps: 1,171,508,700
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90191
Policy Entropy: 4.32875
Value Function Loss: 0.00273
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03709
Policy Update Magnitude: 1.01117
Value Function Update Magnitude: 0.76386
Collected Steps per Second: 13,167.73926
Overall Steps per Second: 7,219.19881
Timestep Collection Time: 3.79746
Timestep Consumption Time: 3.12907
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.92653
Cumulative Model Updates: 144,965
Cumulative Timesteps: 1,171,558,704
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1171558704...
Checkpoint 1171558704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61248
Policy Entropy: 4.32439
Value Function Loss: 0.00288
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03436
Policy Update Magnitude: 1.02202
Value Function Update Magnitude: 0.74227
Collected Steps per Second: 12,950.91868
Overall Steps per Second: 7,220.58097
Timestep Collection Time: 3.86243
Timestep Consumption Time: 3.06527
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.92770
Cumulative Model Updates: 144,974
Cumulative Timesteps: 1,171,608,726
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85673
Policy Entropy: 4.32194
Value Function Loss: 0.00293
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03424
Policy Update Magnitude: 1.03573
Value Function Update Magnitude: 0.76295
Collected Steps per Second: 13,265.50265
Overall Steps per Second: 7,260.73051
Timestep Collection Time: 3.77159
Timestep Consumption Time: 3.11918
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.89077
Cumulative Model Updates: 144,983
Cumulative Timesteps: 1,171,658,758
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1171658758...
Checkpoint 1171658758 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.35842
Policy Entropy: 4.31749
Value Function Loss: 0.00303
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03670
Policy Update Magnitude: 1.04411
Value Function Update Magnitude: 0.80508
Collected Steps per Second: 13,044.78784
Overall Steps per Second: 7,186.96003
Timestep Collection Time: 3.83464
Timestep Consumption Time: 3.12547
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.96011
Cumulative Model Updates: 144,992
Cumulative Timesteps: 1,171,708,780
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01551
Policy Entropy: 4.31844
Value Function Loss: 0.00284
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03510
Policy Update Magnitude: 1.04337
Value Function Update Magnitude: 0.80640
Collected Steps per Second: 12,907.33051
Overall Steps per Second: 7,143.28730
Timestep Collection Time: 3.87439
Timestep Consumption Time: 3.12631
PPO Batch Consumption Time: 0.23657
Total Iteration Time: 7.00070
Cumulative Model Updates: 145,001
Cumulative Timesteps: 1,171,758,788
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1171758788...
Checkpoint 1171758788 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19140
Policy Entropy: 4.31724
Value Function Loss: 0.00285
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03335
Policy Update Magnitude: 1.04441
Value Function Update Magnitude: 0.80374
Collected Steps per Second: 12,881.17829
Overall Steps per Second: 7,151.76795
Timestep Collection Time: 3.88287
Timestep Consumption Time: 3.11064
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.99352
Cumulative Model Updates: 145,010
Cumulative Timesteps: 1,171,808,804
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.58971
Policy Entropy: 4.32322
Value Function Loss: 0.00269
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 1.03149
Value Function Update Magnitude: 0.81267
Collected Steps per Second: 12,939.62147
Overall Steps per Second: 7,153.92256
Timestep Collection Time: 3.86441
Timestep Consumption Time: 3.12532
PPO Batch Consumption Time: 0.22923
Total Iteration Time: 6.98973
Cumulative Model Updates: 145,019
Cumulative Timesteps: 1,171,858,808
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1171858808...
Checkpoint 1171858808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.77584
Policy Entropy: 4.31797
Value Function Loss: 0.00277
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03546
Policy Update Magnitude: 1.02760
Value Function Update Magnitude: 0.77136
Collected Steps per Second: 13,043.77546
Overall Steps per Second: 7,322.43498
Timestep Collection Time: 3.83432
Timestep Consumption Time: 2.99592
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.83024
Cumulative Model Updates: 145,028
Cumulative Timesteps: 1,171,908,822
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.49031
Policy Entropy: 4.31991
Value Function Loss: 0.00277
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03437
Policy Update Magnitude: 1.02211
Value Function Update Magnitude: 0.77855
Collected Steps per Second: 12,931.61741
Overall Steps per Second: 7,159.16796
Timestep Collection Time: 3.86943
Timestep Consumption Time: 3.11993
PPO Batch Consumption Time: 0.22941
Total Iteration Time: 6.98936
Cumulative Model Updates: 145,037
Cumulative Timesteps: 1,171,958,860
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1171958860...
Checkpoint 1171958860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12051
Policy Entropy: 4.32311
Value Function Loss: 0.00278
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03311
Policy Update Magnitude: 1.02651
Value Function Update Magnitude: 0.77226
Collected Steps per Second: 12,802.92877
Overall Steps per Second: 7,132.72252
Timestep Collection Time: 3.90848
Timestep Consumption Time: 3.10707
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 7.01555
Cumulative Model Updates: 145,046
Cumulative Timesteps: 1,172,008,900
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06939
Policy Entropy: 4.32617
Value Function Loss: 0.00281
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03362
Policy Update Magnitude: 1.04034
Value Function Update Magnitude: 0.76344
Collected Steps per Second: 13,026.78558
Overall Steps per Second: 7,306.57306
Timestep Collection Time: 3.84024
Timestep Consumption Time: 3.00647
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.84671
Cumulative Model Updates: 145,055
Cumulative Timesteps: 1,172,058,926
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1172058926...
Checkpoint 1172058926 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.71175
Policy Entropy: 4.33078
Value Function Loss: 0.00279
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03344
Policy Update Magnitude: 1.04439
Value Function Update Magnitude: 0.77934
Collected Steps per Second: 13,018.72415
Overall Steps per Second: 7,163.60855
Timestep Collection Time: 3.84108
Timestep Consumption Time: 3.13948
PPO Batch Consumption Time: 0.23219
Total Iteration Time: 6.98056
Cumulative Model Updates: 145,064
Cumulative Timesteps: 1,172,108,932
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.21070
Policy Entropy: 4.33158
Value Function Loss: 0.00281
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03178
Policy Update Magnitude: 1.05252
Value Function Update Magnitude: 0.79961
Collected Steps per Second: 13,062.74962
Overall Steps per Second: 7,215.17125
Timestep Collection Time: 3.82875
Timestep Consumption Time: 3.10303
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.93178
Cumulative Model Updates: 145,073
Cumulative Timesteps: 1,172,158,946
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1172158946...
Checkpoint 1172158946 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.14763
Policy Entropy: 4.33088
Value Function Loss: 0.00283
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 1.06130
Value Function Update Magnitude: 0.80324
Collected Steps per Second: 12,887.44023
Overall Steps per Second: 7,241.24104
Timestep Collection Time: 3.88145
Timestep Consumption Time: 3.02648
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.90793
Cumulative Model Updates: 145,082
Cumulative Timesteps: 1,172,208,968
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90281
Policy Entropy: 4.32865
Value Function Loss: 0.00290
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03402
Policy Update Magnitude: 1.08184
Value Function Update Magnitude: 0.80904
Collected Steps per Second: 13,028.28031
Overall Steps per Second: 7,192.88149
Timestep Collection Time: 3.83842
Timestep Consumption Time: 3.11401
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.95243
Cumulative Model Updates: 145,091
Cumulative Timesteps: 1,172,258,976
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1172258976...
Checkpoint 1172258976 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27788
Policy Entropy: 4.32521
Value Function Loss: 0.00289
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03394
Policy Update Magnitude: 1.06920
Value Function Update Magnitude: 0.79520
Collected Steps per Second: 12,942.74803
Overall Steps per Second: 7,201.14690
Timestep Collection Time: 3.86533
Timestep Consumption Time: 3.08190
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.94723
Cumulative Model Updates: 145,100
Cumulative Timesteps: 1,172,309,004
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90928
Policy Entropy: 4.32635
Value Function Loss: 0.00281
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 1.05220
Value Function Update Magnitude: 0.77372
Collected Steps per Second: 12,840.03195
Overall Steps per Second: 7,242.11581
Timestep Collection Time: 3.89703
Timestep Consumption Time: 3.01228
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.90931
Cumulative Model Updates: 145,109
Cumulative Timesteps: 1,172,359,042
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1172359042...
Checkpoint 1172359042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61893
Policy Entropy: 4.32704
Value Function Loss: 0.00269
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03380
Policy Update Magnitude: 1.04340
Value Function Update Magnitude: 0.77741
Collected Steps per Second: 13,150.18912
Overall Steps per Second: 7,214.21065
Timestep Collection Time: 3.80481
Timestep Consumption Time: 3.13067
PPO Batch Consumption Time: 0.22916
Total Iteration Time: 6.93548
Cumulative Model Updates: 145,118
Cumulative Timesteps: 1,172,409,076
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.11508
Policy Entropy: 4.32635
Value Function Loss: 0.00258
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 1.03503
Value Function Update Magnitude: 0.76480
Collected Steps per Second: 12,949.38018
Overall Steps per Second: 7,140.46198
Timestep Collection Time: 3.86227
Timestep Consumption Time: 3.14204
PPO Batch Consumption Time: 0.23439
Total Iteration Time: 7.00431
Cumulative Model Updates: 145,127
Cumulative Timesteps: 1,172,459,090
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1172459090...
Checkpoint 1172459090 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.48401
Policy Entropy: 4.32627
Value Function Loss: 0.00270
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 1.03429
Value Function Update Magnitude: 0.77714
Collected Steps per Second: 12,752.74743
Overall Steps per Second: 7,230.76370
Timestep Collection Time: 3.92088
Timestep Consumption Time: 2.99429
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.91518
Cumulative Model Updates: 145,136
Cumulative Timesteps: 1,172,509,092
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24016
Policy Entropy: 4.32327
Value Function Loss: 0.00272
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03556
Policy Update Magnitude: 1.03463
Value Function Update Magnitude: 0.78155
Collected Steps per Second: 13,079.04775
Overall Steps per Second: 7,228.04878
Timestep Collection Time: 3.82398
Timestep Consumption Time: 3.09545
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.91943
Cumulative Model Updates: 145,145
Cumulative Timesteps: 1,172,559,106
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1172559106...
Checkpoint 1172559106 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27379
Policy Entropy: 4.32197
Value Function Loss: 0.00280
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03359
Policy Update Magnitude: 1.04646
Value Function Update Magnitude: 0.77885
Collected Steps per Second: 12,902.50996
Overall Steps per Second: 7,166.24533
Timestep Collection Time: 3.87723
Timestep Consumption Time: 3.10355
PPO Batch Consumption Time: 0.22972
Total Iteration Time: 6.98078
Cumulative Model Updates: 145,154
Cumulative Timesteps: 1,172,609,132
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61133
Policy Entropy: 4.32136
Value Function Loss: 0.00278
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03358
Policy Update Magnitude: 1.07005
Value Function Update Magnitude: 0.77312
Collected Steps per Second: 12,584.51764
Overall Steps per Second: 7,152.09214
Timestep Collection Time: 3.97568
Timestep Consumption Time: 3.01976
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.99544
Cumulative Model Updates: 145,163
Cumulative Timesteps: 1,172,659,164
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1172659164...
Checkpoint 1172659164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05449
Policy Entropy: 4.32447
Value Function Loss: 0.00293
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03445
Policy Update Magnitude: 1.08433
Value Function Update Magnitude: 0.78037
Collected Steps per Second: 13,117.41447
Overall Steps per Second: 7,211.98385
Timestep Collection Time: 3.81310
Timestep Consumption Time: 3.12230
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.93540
Cumulative Model Updates: 145,172
Cumulative Timesteps: 1,172,709,182
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.50910
Policy Entropy: 4.32836
Value Function Loss: 0.00290
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 1.07922
Value Function Update Magnitude: 0.76260
Collected Steps per Second: 12,977.85613
Overall Steps per Second: 7,228.52949
Timestep Collection Time: 3.85333
Timestep Consumption Time: 3.06481
PPO Batch Consumption Time: 0.22929
Total Iteration Time: 6.91814
Cumulative Model Updates: 145,181
Cumulative Timesteps: 1,172,759,190
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1172759190...
Checkpoint 1172759190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.99867
Policy Entropy: 4.32799
Value Function Loss: 0.00298
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03306
Policy Update Magnitude: 1.07193
Value Function Update Magnitude: 0.73308
Collected Steps per Second: 12,844.96090
Overall Steps per Second: 7,199.30439
Timestep Collection Time: 3.89507
Timestep Consumption Time: 3.05449
PPO Batch Consumption Time: 0.23041
Total Iteration Time: 6.94956
Cumulative Model Updates: 145,190
Cumulative Timesteps: 1,172,809,222
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.07314
Policy Entropy: 4.32958
Value Function Loss: 0.00282
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03300
Policy Update Magnitude: 1.07299
Value Function Update Magnitude: 0.72325
Collected Steps per Second: 13,153.35597
Overall Steps per Second: 7,186.51594
Timestep Collection Time: 3.80146
Timestep Consumption Time: 3.15629
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.95775
Cumulative Model Updates: 145,199
Cumulative Timesteps: 1,172,859,224
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1172859224...
Checkpoint 1172859224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.00897
Policy Entropy: 4.32811
Value Function Loss: 0.00285
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03538
Policy Update Magnitude: 1.05884
Value Function Update Magnitude: 0.73455
Collected Steps per Second: 13,062.99407
Overall Steps per Second: 7,225.33180
Timestep Collection Time: 3.83036
Timestep Consumption Time: 3.09472
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.92508
Cumulative Model Updates: 145,208
Cumulative Timesteps: 1,172,909,260
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.98519
Policy Entropy: 4.33352
Value Function Loss: 0.00265
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 1.02910
Value Function Update Magnitude: 0.73156
Collected Steps per Second: 12,987.65168
Overall Steps per Second: 7,290.99166
Timestep Collection Time: 3.85120
Timestep Consumption Time: 3.00905
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.86025
Cumulative Model Updates: 145,217
Cumulative Timesteps: 1,172,959,278
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1172959278...
Checkpoint 1172959278 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.21895
Policy Entropy: 4.32525
Value Function Loss: 0.00283
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03258
Policy Update Magnitude: 1.05109
Value Function Update Magnitude: 0.75754
Collected Steps per Second: 13,042.90016
Overall Steps per Second: 7,182.26384
Timestep Collection Time: 3.83488
Timestep Consumption Time: 3.12922
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.96410
Cumulative Model Updates: 145,226
Cumulative Timesteps: 1,173,009,296
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.80089
Policy Entropy: 4.32760
Value Function Loss: 0.00278
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03328
Policy Update Magnitude: 1.09263
Value Function Update Magnitude: 0.75139
Collected Steps per Second: 12,905.30315
Overall Steps per Second: 7,185.21737
Timestep Collection Time: 3.87717
Timestep Consumption Time: 3.08658
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.96374
Cumulative Model Updates: 145,235
Cumulative Timesteps: 1,173,059,332
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1173059332...
Checkpoint 1173059332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.58877
Policy Entropy: 4.32400
Value Function Loss: 0.00287
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03555
Policy Update Magnitude: 1.07206
Value Function Update Magnitude: 0.73671
Collected Steps per Second: 13,207.40652
Overall Steps per Second: 7,253.51953
Timestep Collection Time: 3.78575
Timestep Consumption Time: 3.10745
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.89321
Cumulative Model Updates: 145,244
Cumulative Timesteps: 1,173,109,332
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.63229
Policy Entropy: 4.32345
Value Function Loss: 0.00278
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03245
Policy Update Magnitude: 1.05807
Value Function Update Magnitude: 0.75805
Collected Steps per Second: 13,062.55395
Overall Steps per Second: 7,069.17545
Timestep Collection Time: 3.82957
Timestep Consumption Time: 3.24678
PPO Batch Consumption Time: 0.24026
Total Iteration Time: 7.07636
Cumulative Model Updates: 145,253
Cumulative Timesteps: 1,173,159,356
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1173159356...
Checkpoint 1173159356 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.45175
Policy Entropy: 4.32264
Value Function Loss: 0.00286
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03343
Policy Update Magnitude: 1.06088
Value Function Update Magnitude: 0.81231
Collected Steps per Second: 12,929.34328
Overall Steps per Second: 7,141.28482
Timestep Collection Time: 3.86764
Timestep Consumption Time: 3.13474
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 7.00238
Cumulative Model Updates: 145,262
Cumulative Timesteps: 1,173,209,362
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.23020
Policy Entropy: 4.32587
Value Function Loss: 0.00279
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03287
Policy Update Magnitude: 1.04303
Value Function Update Magnitude: 0.81868
Collected Steps per Second: 13,390.38133
Overall Steps per Second: 7,318.51235
Timestep Collection Time: 3.73597
Timestep Consumption Time: 3.09958
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.83554
Cumulative Model Updates: 145,271
Cumulative Timesteps: 1,173,259,388
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1173259388...
Checkpoint 1173259388 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.45772
Policy Entropy: 4.32550
Value Function Loss: 0.00291
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03308
Policy Update Magnitude: 1.05105
Value Function Update Magnitude: 0.78978
Collected Steps per Second: 12,980.41142
Overall Steps per Second: 7,199.44177
Timestep Collection Time: 3.85288
Timestep Consumption Time: 3.09377
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.94665
Cumulative Model Updates: 145,280
Cumulative Timesteps: 1,173,309,400
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01564
Policy Entropy: 4.32234
Value Function Loss: 0.00293
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03362
Policy Update Magnitude: 1.07547
Value Function Update Magnitude: 0.77725
Collected Steps per Second: 13,064.49811
Overall Steps per Second: 7,226.61653
Timestep Collection Time: 3.82916
Timestep Consumption Time: 3.09331
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 6.92246
Cumulative Model Updates: 145,289
Cumulative Timesteps: 1,173,359,426
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1173359426...
Checkpoint 1173359426 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.23124
Policy Entropy: 4.32177
Value Function Loss: 0.00289
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03594
Policy Update Magnitude: 1.08199
Value Function Update Magnitude: 0.78717
Collected Steps per Second: 13,091.12193
Overall Steps per Second: 7,218.48080
Timestep Collection Time: 3.82091
Timestep Consumption Time: 3.10853
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.92944
Cumulative Model Updates: 145,298
Cumulative Timesteps: 1,173,409,446
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.29501
Policy Entropy: 4.32112
Value Function Loss: 0.00286
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03506
Policy Update Magnitude: 1.07331
Value Function Update Magnitude: 0.79880
Collected Steps per Second: 13,014.76734
Overall Steps per Second: 7,206.76791
Timestep Collection Time: 3.84379
Timestep Consumption Time: 3.09774
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.94153
Cumulative Model Updates: 145,307
Cumulative Timesteps: 1,173,459,472
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1173459472...
Checkpoint 1173459472 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52014
Policy Entropy: 4.32702
Value Function Loss: 0.00265
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 1.06213
Value Function Update Magnitude: 0.78955
Collected Steps per Second: 12,923.79424
Overall Steps per Second: 7,217.22114
Timestep Collection Time: 3.87007
Timestep Consumption Time: 3.06002
PPO Batch Consumption Time: 0.23006
Total Iteration Time: 6.93009
Cumulative Model Updates: 145,316
Cumulative Timesteps: 1,173,509,488
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.95683
Policy Entropy: 4.32694
Value Function Loss: 0.00271
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03359
Policy Update Magnitude: 1.05845
Value Function Update Magnitude: 0.79311
Collected Steps per Second: 13,064.69508
Overall Steps per Second: 7,194.23426
Timestep Collection Time: 3.82879
Timestep Consumption Time: 3.12428
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.95307
Cumulative Model Updates: 145,325
Cumulative Timesteps: 1,173,559,510
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1173559510...
Checkpoint 1173559510 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21732
Policy Entropy: 4.32604
Value Function Loss: 0.00268
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03335
Policy Update Magnitude: 1.04850
Value Function Update Magnitude: 0.78782
Collected Steps per Second: 12,921.84854
Overall Steps per Second: 7,173.37551
Timestep Collection Time: 3.87220
Timestep Consumption Time: 3.10304
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.97524
Cumulative Model Updates: 145,334
Cumulative Timesteps: 1,173,609,546
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10517
Policy Entropy: 4.32665
Value Function Loss: 0.00271
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03440
Policy Update Magnitude: 1.05784
Value Function Update Magnitude: 0.78144
Collected Steps per Second: 13,048.53970
Overall Steps per Second: 7,311.53287
Timestep Collection Time: 3.83307
Timestep Consumption Time: 3.00763
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.84070
Cumulative Model Updates: 145,343
Cumulative Timesteps: 1,173,659,562
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1173659562...
Checkpoint 1173659562 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71423
Policy Entropy: 4.32503
Value Function Loss: 0.00278
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 1.06909
Value Function Update Magnitude: 0.76922
Collected Steps per Second: 12,893.74338
Overall Steps per Second: 7,151.51984
Timestep Collection Time: 3.87800
Timestep Consumption Time: 3.11380
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.99180
Cumulative Model Updates: 145,352
Cumulative Timesteps: 1,173,709,564
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.49915
Policy Entropy: 4.32629
Value Function Loss: 0.00269
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03350
Policy Update Magnitude: 1.05427
Value Function Update Magnitude: 0.76340
Collected Steps per Second: 13,051.09224
Overall Steps per Second: 7,206.48737
Timestep Collection Time: 3.83294
Timestep Consumption Time: 3.10859
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.94152
Cumulative Model Updates: 145,361
Cumulative Timesteps: 1,173,759,588
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1173759588...
Checkpoint 1173759588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.39761
Policy Entropy: 4.32197
Value Function Loss: 0.00285
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 1.07771
Value Function Update Magnitude: 0.77146
Collected Steps per Second: 12,914.39658
Overall Steps per Second: 7,269.89801
Timestep Collection Time: 3.87428
Timestep Consumption Time: 3.00807
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.88235
Cumulative Model Updates: 145,370
Cumulative Timesteps: 1,173,809,622
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11283
Policy Entropy: 4.32241
Value Function Loss: 0.00288
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03500
Policy Update Magnitude: 1.10991
Value Function Update Magnitude: 0.78818
Collected Steps per Second: 12,928.60245
Overall Steps per Second: 7,039.47045
Timestep Collection Time: 3.86863
Timestep Consumption Time: 3.23645
PPO Batch Consumption Time: 0.23936
Total Iteration Time: 7.10508
Cumulative Model Updates: 145,379
Cumulative Timesteps: 1,173,859,638
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1173859638...
Checkpoint 1173859638 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.39667
Policy Entropy: 4.32332
Value Function Loss: 0.00287
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03564
Policy Update Magnitude: 1.11233
Value Function Update Magnitude: 0.81618
Collected Steps per Second: 12,977.00771
Overall Steps per Second: 7,174.52808
Timestep Collection Time: 3.85420
Timestep Consumption Time: 3.11713
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.97133
Cumulative Model Updates: 145,388
Cumulative Timesteps: 1,173,909,654
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75992
Policy Entropy: 4.32365
Value Function Loss: 0.00282
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03427
Policy Update Magnitude: 1.09483
Value Function Update Magnitude: 0.82411
Collected Steps per Second: 12,994.39081
Overall Steps per Second: 7,288.86107
Timestep Collection Time: 3.84920
Timestep Consumption Time: 3.01305
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.86225
Cumulative Model Updates: 145,397
Cumulative Timesteps: 1,173,959,672
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1173959672...
Checkpoint 1173959672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.14027
Policy Entropy: 4.32401
Value Function Loss: 0.00285
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 1.08849
Value Function Update Magnitude: 0.84180
Collected Steps per Second: 12,894.30568
Overall Steps per Second: 7,163.96692
Timestep Collection Time: 3.87815
Timestep Consumption Time: 3.10206
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.98021
Cumulative Model Updates: 145,406
Cumulative Timesteps: 1,174,009,678
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22999
Policy Entropy: 4.32028
Value Function Loss: 0.00287
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03528
Policy Update Magnitude: 1.10702
Value Function Update Magnitude: 0.82795
Collected Steps per Second: 13,056.18063
Overall Steps per Second: 7,195.70105
Timestep Collection Time: 3.83037
Timestep Consumption Time: 3.11961
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.94998
Cumulative Model Updates: 145,415
Cumulative Timesteps: 1,174,059,688
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1174059688...
Checkpoint 1174059688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53196
Policy Entropy: 4.32205
Value Function Loss: 0.00284
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03516
Policy Update Magnitude: 1.09279
Value Function Update Magnitude: 0.82522
Collected Steps per Second: 12,875.89843
Overall Steps per Second: 7,256.70121
Timestep Collection Time: 3.88338
Timestep Consumption Time: 3.00708
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.89046
Cumulative Model Updates: 145,424
Cumulative Timesteps: 1,174,109,690
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24658
Policy Entropy: 4.32115
Value Function Loss: 0.00279
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03323
Policy Update Magnitude: 1.08123
Value Function Update Magnitude: 0.80700
Collected Steps per Second: 12,966.03832
Overall Steps per Second: 7,183.44277
Timestep Collection Time: 3.85623
Timestep Consumption Time: 3.10422
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.96045
Cumulative Model Updates: 145,433
Cumulative Timesteps: 1,174,159,690
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1174159690...
Checkpoint 1174159690 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.99569
Policy Entropy: 4.31917
Value Function Loss: 0.00269
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03396
Policy Update Magnitude: 1.05517
Value Function Update Magnitude: 0.80267
Collected Steps per Second: 12,957.58328
Overall Steps per Second: 7,053.22101
Timestep Collection Time: 3.86013
Timestep Consumption Time: 3.23138
PPO Batch Consumption Time: 0.24134
Total Iteration Time: 7.09151
Cumulative Model Updates: 145,442
Cumulative Timesteps: 1,174,209,708
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60343
Policy Entropy: 4.32217
Value Function Loss: 0.00277
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03334
Policy Update Magnitude: 1.04846
Value Function Update Magnitude: 0.80188
Collected Steps per Second: 12,806.26068
Overall Steps per Second: 7,251.48754
Timestep Collection Time: 3.90450
Timestep Consumption Time: 2.99092
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.89541
Cumulative Model Updates: 145,451
Cumulative Timesteps: 1,174,259,710
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1174259710...
Checkpoint 1174259710 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.38386
Policy Entropy: 4.32507
Value Function Loss: 0.00276
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03344
Policy Update Magnitude: 1.05693
Value Function Update Magnitude: 0.81181
Collected Steps per Second: 12,833.98021
Overall Steps per Second: 7,154.84617
Timestep Collection Time: 3.89669
Timestep Consumption Time: 3.09298
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.98967
Cumulative Model Updates: 145,460
Cumulative Timesteps: 1,174,309,720
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05147
Policy Entropy: 4.32921
Value Function Loss: 0.00281
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03443
Policy Update Magnitude: 1.06317
Value Function Update Magnitude: 0.79224
Collected Steps per Second: 13,062.90332
Overall Steps per Second: 7,243.44195
Timestep Collection Time: 3.83008
Timestep Consumption Time: 3.07713
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.90721
Cumulative Model Updates: 145,469
Cumulative Timesteps: 1,174,359,752
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1174359752...
Checkpoint 1174359752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.79618
Policy Entropy: 4.32780
Value Function Loss: 0.00288
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03766
Policy Update Magnitude: 1.08926
Value Function Update Magnitude: 0.80821
Collected Steps per Second: 13,087.46778
Overall Steps per Second: 7,318.08231
Timestep Collection Time: 3.82167
Timestep Consumption Time: 3.01291
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.83458
Cumulative Model Updates: 145,478
Cumulative Timesteps: 1,174,409,768
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.93638
Policy Entropy: 4.32635
Value Function Loss: 0.00289
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03958
Policy Update Magnitude: 1.08935
Value Function Update Magnitude: 0.80083
Collected Steps per Second: 12,979.08093
Overall Steps per Second: 7,152.33456
Timestep Collection Time: 3.85482
Timestep Consumption Time: 3.14038
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.99520
Cumulative Model Updates: 145,487
Cumulative Timesteps: 1,174,459,800
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1174459800...
Checkpoint 1174459800 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.38955
Policy Entropy: 4.32440
Value Function Loss: 0.00286
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03632
Policy Update Magnitude: 1.08002
Value Function Update Magnitude: 0.78643
Collected Steps per Second: 12,944.03852
Overall Steps per Second: 7,218.26913
Timestep Collection Time: 3.86309
Timestep Consumption Time: 3.06433
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.92742
Cumulative Model Updates: 145,496
Cumulative Timesteps: 1,174,509,804
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.73468
Policy Entropy: 4.32566
Value Function Loss: 0.00281
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 1.05023
Value Function Update Magnitude: 0.75603
Collected Steps per Second: 13,039.24180
Overall Steps per Second: 7,249.18580
Timestep Collection Time: 3.83719
Timestep Consumption Time: 3.06483
PPO Batch Consumption Time: 0.23012
Total Iteration Time: 6.90202
Cumulative Model Updates: 145,505
Cumulative Timesteps: 1,174,559,838
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1174559838...
Checkpoint 1174559838 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.82856
Policy Entropy: 4.32336
Value Function Loss: 0.00274
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03394
Policy Update Magnitude: 1.05179
Value Function Update Magnitude: 0.76911
Collected Steps per Second: 12,923.88235
Overall Steps per Second: 7,157.89191
Timestep Collection Time: 3.86912
Timestep Consumption Time: 3.11674
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.98586
Cumulative Model Updates: 145,514
Cumulative Timesteps: 1,174,609,842
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.44614
Policy Entropy: 4.32496
Value Function Loss: 0.00277
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03462
Policy Update Magnitude: 1.05311
Value Function Update Magnitude: 0.80287
Collected Steps per Second: 12,868.36419
Overall Steps per Second: 7,178.79964
Timestep Collection Time: 3.88596
Timestep Consumption Time: 3.07982
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.96579
Cumulative Model Updates: 145,523
Cumulative Timesteps: 1,174,659,848
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1174659848...
Checkpoint 1174659848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.23275
Policy Entropy: 4.32852
Value Function Loss: 0.00280
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03501
Policy Update Magnitude: 1.06462
Value Function Update Magnitude: 0.79860
Collected Steps per Second: 12,806.73576
Overall Steps per Second: 7,244.01496
Timestep Collection Time: 3.90560
Timestep Consumption Time: 2.99913
PPO Batch Consumption Time: 0.22936
Total Iteration Time: 6.90473
Cumulative Model Updates: 145,532
Cumulative Timesteps: 1,174,709,866
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58210
Policy Entropy: 4.32952
Value Function Loss: 0.00286
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03506
Policy Update Magnitude: 1.07852
Value Function Update Magnitude: 0.81527
Collected Steps per Second: 12,959.98518
Overall Steps per Second: 7,180.00394
Timestep Collection Time: 3.86019
Timestep Consumption Time: 3.10749
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.96768
Cumulative Model Updates: 145,541
Cumulative Timesteps: 1,174,759,894
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1174759894...
Checkpoint 1174759894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.76830
Policy Entropy: 4.32959
Value Function Loss: 0.00273
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 1.06238
Value Function Update Magnitude: 0.80451
Collected Steps per Second: 12,869.59285
Overall Steps per Second: 7,161.18451
Timestep Collection Time: 3.88839
Timestep Consumption Time: 3.09956
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.98795
Cumulative Model Updates: 145,550
Cumulative Timesteps: 1,174,809,936
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.29351
Policy Entropy: 4.32726
Value Function Loss: 0.00278
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03475
Policy Update Magnitude: 1.05679
Value Function Update Magnitude: 0.77684
Collected Steps per Second: 12,924.09612
Overall Steps per Second: 7,254.59101
Timestep Collection Time: 3.87122
Timestep Consumption Time: 3.02538
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 6.89660
Cumulative Model Updates: 145,559
Cumulative Timesteps: 1,174,859,968
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1174859968...
Checkpoint 1174859968 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.33720
Policy Entropy: 4.32676
Value Function Loss: 0.00274
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03411
Policy Update Magnitude: 1.06438
Value Function Update Magnitude: 0.78007
Collected Steps per Second: 13,036.95289
Overall Steps per Second: 7,164.34355
Timestep Collection Time: 3.83786
Timestep Consumption Time: 3.14589
PPO Batch Consumption Time: 0.23215
Total Iteration Time: 6.98375
Cumulative Model Updates: 145,568
Cumulative Timesteps: 1,174,910,002
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28040
Policy Entropy: 4.32143
Value Function Loss: 0.00281
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03506
Policy Update Magnitude: 1.06742
Value Function Update Magnitude: 0.80085
Collected Steps per Second: 12,905.88548
Overall Steps per Second: 7,265.58467
Timestep Collection Time: 3.87436
Timestep Consumption Time: 3.00768
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.88203
Cumulative Model Updates: 145,577
Cumulative Timesteps: 1,174,960,004
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1174960004...
Checkpoint 1174960004 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.67034
Policy Entropy: 4.31897
Value Function Loss: 0.00276
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03451
Policy Update Magnitude: 1.06075
Value Function Update Magnitude: 0.80030
Collected Steps per Second: 12,995.79856
Overall Steps per Second: 7,183.80666
Timestep Collection Time: 3.85032
Timestep Consumption Time: 3.11507
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.96539
Cumulative Model Updates: 145,586
Cumulative Timesteps: 1,175,010,042
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.15043
Policy Entropy: 4.32102
Value Function Loss: 0.00279
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03451
Policy Update Magnitude: 1.05401
Value Function Update Magnitude: 0.81219
Collected Steps per Second: 13,111.64687
Overall Steps per Second: 7,217.42792
Timestep Collection Time: 3.81554
Timestep Consumption Time: 3.11602
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.93156
Cumulative Model Updates: 145,595
Cumulative Timesteps: 1,175,060,070
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1175060070...
Checkpoint 1175060070 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25227
Policy Entropy: 4.32129
Value Function Loss: 0.00282
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 1.04326
Value Function Update Magnitude: 0.79146
Collected Steps per Second: 12,867.67676
Overall Steps per Second: 7,237.11879
Timestep Collection Time: 3.88726
Timestep Consumption Time: 3.02433
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.91159
Cumulative Model Updates: 145,604
Cumulative Timesteps: 1,175,110,090
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12719
Policy Entropy: 4.32310
Value Function Loss: 0.00283
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 1.06013
Value Function Update Magnitude: 0.79107
Collected Steps per Second: 12,985.00040
Overall Steps per Second: 7,187.34975
Timestep Collection Time: 3.85368
Timestep Consumption Time: 3.10856
PPO Batch Consumption Time: 0.23014
Total Iteration Time: 6.96223
Cumulative Model Updates: 145,613
Cumulative Timesteps: 1,175,160,130
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1175160130...
Checkpoint 1175160130 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.98265
Policy Entropy: 4.31966
Value Function Loss: 0.00290
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03509
Policy Update Magnitude: 1.07798
Value Function Update Magnitude: 0.79898
Collected Steps per Second: 12,977.76058
Overall Steps per Second: 7,119.37791
Timestep Collection Time: 3.85382
Timestep Consumption Time: 3.17123
PPO Batch Consumption Time: 0.22954
Total Iteration Time: 7.02505
Cumulative Model Updates: 145,622
Cumulative Timesteps: 1,175,210,144
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.06811
Policy Entropy: 4.31894
Value Function Loss: 0.00280
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03568
Policy Update Magnitude: 1.06711
Value Function Update Magnitude: 0.77850
Collected Steps per Second: 12,811.26433
Overall Steps per Second: 7,166.05854
Timestep Collection Time: 3.90625
Timestep Consumption Time: 3.07723
PPO Batch Consumption Time: 0.22942
Total Iteration Time: 6.98348
Cumulative Model Updates: 145,631
Cumulative Timesteps: 1,175,260,188
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1175260188...
Checkpoint 1175260188 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27231
Policy Entropy: 4.32124
Value Function Loss: 0.00280
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03494
Policy Update Magnitude: 1.05840
Value Function Update Magnitude: 0.78236
Collected Steps per Second: 13,011.74332
Overall Steps per Second: 7,173.10664
Timestep Collection Time: 3.84422
Timestep Consumption Time: 3.12905
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.97327
Cumulative Model Updates: 145,640
Cumulative Timesteps: 1,175,310,208
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74241
Policy Entropy: 4.32308
Value Function Loss: 0.00267
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03344
Policy Update Magnitude: 1.04782
Value Function Update Magnitude: 0.78718
Collected Steps per Second: 13,282.53811
Overall Steps per Second: 7,261.18406
Timestep Collection Time: 3.76600
Timestep Consumption Time: 3.12296
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.88896
Cumulative Model Updates: 145,649
Cumulative Timesteps: 1,175,360,230
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1175360230...
Checkpoint 1175360230 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81378
Policy Entropy: 4.32706
Value Function Loss: 0.00262
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03205
Policy Update Magnitude: 1.04440
Value Function Update Magnitude: 0.79340
Collected Steps per Second: 12,805.24097
Overall Steps per Second: 7,224.61129
Timestep Collection Time: 3.90731
Timestep Consumption Time: 3.01819
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.92549
Cumulative Model Updates: 145,658
Cumulative Timesteps: 1,175,410,264
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.88390
Policy Entropy: 4.32307
Value Function Loss: 0.00274
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03330
Policy Update Magnitude: 1.05910
Value Function Update Magnitude: 0.79078
Collected Steps per Second: 13,044.85435
Overall Steps per Second: 7,190.23821
Timestep Collection Time: 3.83508
Timestep Consumption Time: 3.12269
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.95777
Cumulative Model Updates: 145,667
Cumulative Timesteps: 1,175,460,292
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1175460292...
Checkpoint 1175460292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.62343
Policy Entropy: 4.32364
Value Function Loss: 0.00281
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03566
Policy Update Magnitude: 1.08312
Value Function Update Magnitude: 0.79648
Collected Steps per Second: 12,925.72692
Overall Steps per Second: 7,192.35499
Timestep Collection Time: 3.87135
Timestep Consumption Time: 3.08604
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.95739
Cumulative Model Updates: 145,676
Cumulative Timesteps: 1,175,510,332
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65919
Policy Entropy: 4.31856
Value Function Loss: 0.00286
Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03836
Policy Update Magnitude: 1.07737
Value Function Update Magnitude: 0.81450
Collected Steps per Second: 12,974.06218
Overall Steps per Second: 7,284.21917
Timestep Collection Time: 3.85384
Timestep Consumption Time: 3.01031
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.86415
Cumulative Model Updates: 145,685
Cumulative Timesteps: 1,175,560,332
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1175560332...
Checkpoint 1175560332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64123
Policy Entropy: 4.32700
Value Function Loss: 0.00264
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03743
Policy Update Magnitude: 1.04249
Value Function Update Magnitude: 0.77694
Collected Steps per Second: 12,949.82591
Overall Steps per Second: 7,013.83264
Timestep Collection Time: 3.86337
Timestep Consumption Time: 3.26967
PPO Batch Consumption Time: 0.24176
Total Iteration Time: 7.13305
Cumulative Model Updates: 145,694
Cumulative Timesteps: 1,175,610,362
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.96533
Policy Entropy: 4.32743
Value Function Loss: 0.00263
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03304
Policy Update Magnitude: 1.02326
Value Function Update Magnitude: 0.72097
Collected Steps per Second: 12,974.03880
Overall Steps per Second: 7,211.40260
Timestep Collection Time: 3.85601
Timestep Consumption Time: 3.08134
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.93735
Cumulative Model Updates: 145,703
Cumulative Timesteps: 1,175,660,390
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1175660390...
Checkpoint 1175660390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.07959
Policy Entropy: 4.32828
Value Function Loss: 0.00258
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03088
Policy Update Magnitude: 1.02026
Value Function Update Magnitude: 0.71491
Collected Steps per Second: 13,023.45130
Overall Steps per Second: 7,321.28657
Timestep Collection Time: 3.84215
Timestep Consumption Time: 2.99245
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.83459
Cumulative Model Updates: 145,712
Cumulative Timesteps: 1,175,710,428
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.64797
Policy Entropy: 4.32498
Value Function Loss: 0.00262
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03264
Policy Update Magnitude: 1.02856
Value Function Update Magnitude: 0.73552
Collected Steps per Second: 12,873.81173
Overall Steps per Second: 7,155.21196
Timestep Collection Time: 3.88587
Timestep Consumption Time: 3.10567
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.99155
Cumulative Model Updates: 145,721
Cumulative Timesteps: 1,175,760,454
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1175760454...
Checkpoint 1175760454 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.73635
Policy Entropy: 4.32521
Value Function Loss: 0.00259
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03349
Policy Update Magnitude: 1.02963
Value Function Update Magnitude: 0.76662
Collected Steps per Second: 12,894.63361
Overall Steps per Second: 7,188.99202
Timestep Collection Time: 3.87929
Timestep Consumption Time: 3.07885
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.95814
Cumulative Model Updates: 145,730
Cumulative Timesteps: 1,175,810,476
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54074
Policy Entropy: 4.32433
Value Function Loss: 0.00269
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 1.04977
Value Function Update Magnitude: 0.78529
Collected Steps per Second: 12,829.43467
Overall Steps per Second: 7,252.86782
Timestep Collection Time: 3.90025
Timestep Consumption Time: 2.99881
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.89906
Cumulative Model Updates: 145,739
Cumulative Timesteps: 1,175,860,514
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1175860514...
Checkpoint 1175860514 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64525
Policy Entropy: 4.32332
Value Function Loss: 0.00289
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03324
Policy Update Magnitude: 1.08959
Value Function Update Magnitude: 0.80170
Collected Steps per Second: 12,986.48581
Overall Steps per Second: 7,189.48766
Timestep Collection Time: 3.85293
Timestep Consumption Time: 3.10668
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.95961
Cumulative Model Updates: 145,748
Cumulative Timesteps: 1,175,910,550
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.08220
Policy Entropy: 4.32637
Value Function Loss: 0.00295
Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03873
Policy Update Magnitude: 1.10857
Value Function Update Magnitude: 0.80274
Collected Steps per Second: 12,799.23003
Overall Steps per Second: 7,093.97017
Timestep Collection Time: 3.90914
Timestep Consumption Time: 3.14389
PPO Batch Consumption Time: 0.22963
Total Iteration Time: 7.05303
Cumulative Model Updates: 145,757
Cumulative Timesteps: 1,175,960,584
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1175960584...
Checkpoint 1175960584 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.17754
Policy Entropy: 4.32730
Value Function Loss: 0.00292
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03738
Policy Update Magnitude: 1.10836
Value Function Update Magnitude: 0.80590
Collected Steps per Second: 12,808.98907
Overall Steps per Second: 7,211.52321
Timestep Collection Time: 3.90398
Timestep Consumption Time: 3.03020
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.93418
Cumulative Model Updates: 145,766
Cumulative Timesteps: 1,176,010,590
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.33879
Policy Entropy: 4.32838
Value Function Loss: 0.00286
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03640
Policy Update Magnitude: 1.09755
Value Function Update Magnitude: 0.82842
Collected Steps per Second: 12,999.24156
Overall Steps per Second: 7,176.01995
Timestep Collection Time: 3.84792
Timestep Consumption Time: 3.12252
PPO Batch Consumption Time: 0.22966
Total Iteration Time: 6.97044
Cumulative Model Updates: 145,775
Cumulative Timesteps: 1,176,060,610
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1176060610...
Checkpoint 1176060610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89797
Policy Entropy: 4.32760
Value Function Loss: 0.00282
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03530
Policy Update Magnitude: 1.07663
Value Function Update Magnitude: 0.83588
Collected Steps per Second: 12,876.25353
Overall Steps per Second: 7,173.12099
Timestep Collection Time: 3.88514
Timestep Consumption Time: 3.08895
PPO Batch Consumption Time: 0.22984
Total Iteration Time: 6.97409
Cumulative Model Updates: 145,784
Cumulative Timesteps: 1,176,110,636
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07017
Policy Entropy: 4.32919
Value Function Loss: 0.00277
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03734
Policy Update Magnitude: 1.06359
Value Function Update Magnitude: 0.81444
Collected Steps per Second: 13,216.34540
Overall Steps per Second: 7,269.68300
Timestep Collection Time: 3.78425
Timestep Consumption Time: 3.09555
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.87980
Cumulative Model Updates: 145,793
Cumulative Timesteps: 1,176,160,650
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1176160650...
Checkpoint 1176160650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.43734
Policy Entropy: 4.32783
Value Function Loss: 0.00273
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03450
Policy Update Magnitude: 1.05101
Value Function Update Magnitude: 0.82166
Collected Steps per Second: 13,041.64083
Overall Steps per Second: 7,190.31542
Timestep Collection Time: 3.83663
Timestep Consumption Time: 3.12217
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.95880
Cumulative Model Updates: 145,802
Cumulative Timesteps: 1,176,210,686
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07851
Policy Entropy: 4.32847
Value Function Loss: 0.00265
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03351
Policy Update Magnitude: 1.03147
Value Function Update Magnitude: 0.79125
Collected Steps per Second: 12,911.83734
Overall Steps per Second: 7,205.79170
Timestep Collection Time: 3.87582
Timestep Consumption Time: 3.06915
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.94497
Cumulative Model Updates: 145,811
Cumulative Timesteps: 1,176,260,730
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1176260730...
Checkpoint 1176260730 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43324
Policy Entropy: 4.32553
Value Function Loss: 0.00272
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 1.02714
Value Function Update Magnitude: 0.79106
Collected Steps per Second: 13,218.65012
Overall Steps per Second: 7,203.28043
Timestep Collection Time: 3.78344
Timestep Consumption Time: 3.15951
PPO Batch Consumption Time: 0.23393
Total Iteration Time: 6.94295
Cumulative Model Updates: 145,820
Cumulative Timesteps: 1,176,310,742
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42056
Policy Entropy: 4.32394
Value Function Loss: 0.00280
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 1.04214
Value Function Update Magnitude: 0.77317
Collected Steps per Second: 13,010.93684
Overall Steps per Second: 7,171.25388
Timestep Collection Time: 3.84461
Timestep Consumption Time: 3.13074
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.97535
Cumulative Model Updates: 145,829
Cumulative Timesteps: 1,176,360,764
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1176360764...
Checkpoint 1176360764 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.21972
Policy Entropy: 4.32064
Value Function Loss: 0.00292
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03723
Policy Update Magnitude: 1.06162
Value Function Update Magnitude: 0.79769
Collected Steps per Second: 12,720.16671
Overall Steps per Second: 7,076.23266
Timestep Collection Time: 3.93234
Timestep Consumption Time: 3.13639
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 7.06873
Cumulative Model Updates: 145,838
Cumulative Timesteps: 1,176,410,784
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89660
Policy Entropy: 4.32352
Value Function Loss: 0.00281
Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03755
Policy Update Magnitude: 1.05192
Value Function Update Magnitude: 0.78952
Collected Steps per Second: 13,283.81123
Overall Steps per Second: 7,233.48092
Timestep Collection Time: 3.76699
Timestep Consumption Time: 3.15084
PPO Batch Consumption Time: 0.23063
Total Iteration Time: 6.91783
Cumulative Model Updates: 145,847
Cumulative Timesteps: 1,176,460,824
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1176460824...
Checkpoint 1176460824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.59759
Policy Entropy: 4.32133
Value Function Loss: 0.00286
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03584
Policy Update Magnitude: 1.05042
Value Function Update Magnitude: 0.78584
Collected Steps per Second: 13,050.96242
Overall Steps per Second: 7,185.83682
Timestep Collection Time: 3.83389
Timestep Consumption Time: 3.12925
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.96314
Cumulative Model Updates: 145,856
Cumulative Timesteps: 1,176,510,860
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.24490
Policy Entropy: 4.32339
Value Function Loss: 0.00277
Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03777
Policy Update Magnitude: 1.03787
Value Function Update Magnitude: 0.80069
Collected Steps per Second: 12,933.37200
Overall Steps per Second: 7,268.12224
Timestep Collection Time: 3.86628
Timestep Consumption Time: 3.01363
PPO Batch Consumption Time: 0.23019
Total Iteration Time: 6.87991
Cumulative Model Updates: 145,865
Cumulative Timesteps: 1,176,560,864
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1176560864...
Checkpoint 1176560864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.62564
Policy Entropy: 4.32257
Value Function Loss: 0.00287
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03629
Policy Update Magnitude: 1.03819
Value Function Update Magnitude: 0.80629
Collected Steps per Second: 12,965.88821
Overall Steps per Second: 7,152.97096
Timestep Collection Time: 3.85735
Timestep Consumption Time: 3.13471
PPO Batch Consumption Time: 0.22959
Total Iteration Time: 6.99206
Cumulative Model Updates: 145,874
Cumulative Timesteps: 1,176,610,878
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22669
Policy Entropy: 4.32414
Value Function Loss: 0.00281
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03408
Policy Update Magnitude: 1.04743
Value Function Update Magnitude: 0.78147
Collected Steps per Second: 12,837.89210
Overall Steps per Second: 7,072.01197
Timestep Collection Time: 3.89862
Timestep Consumption Time: 3.17858
PPO Batch Consumption Time: 0.23641
Total Iteration Time: 7.07719
Cumulative Model Updates: 145,883
Cumulative Timesteps: 1,176,660,928
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1176660928...
Checkpoint 1176660928 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.07294
Policy Entropy: 4.32065
Value Function Loss: 0.00285
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03422
Policy Update Magnitude: 1.04553
Value Function Update Magnitude: 0.79115
Collected Steps per Second: 12,976.29019
Overall Steps per Second: 7,303.20866
Timestep Collection Time: 3.85488
Timestep Consumption Time: 2.99444
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.84932
Cumulative Model Updates: 145,892
Cumulative Timesteps: 1,176,710,950
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.76749
Policy Entropy: 4.32136
Value Function Loss: 0.00281
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03588
Policy Update Magnitude: 1.05687
Value Function Update Magnitude: 0.80035
Collected Steps per Second: 12,938.86809
Overall Steps per Second: 7,170.23740
Timestep Collection Time: 3.86525
Timestep Consumption Time: 3.10969
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.97494
Cumulative Model Updates: 145,901
Cumulative Timesteps: 1,176,760,962
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1176760962...
Checkpoint 1176760962 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52462
Policy Entropy: 4.32082
Value Function Loss: 0.00266
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03436
Policy Update Magnitude: 1.04984
Value Function Update Magnitude: 0.81728
Collected Steps per Second: 12,987.00725
Overall Steps per Second: 7,209.23929
Timestep Collection Time: 3.85062
Timestep Consumption Time: 3.08604
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.93665
Cumulative Model Updates: 145,910
Cumulative Timesteps: 1,176,810,970
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.79634
Policy Entropy: 4.32140
Value Function Loss: 0.00272
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03347
Policy Update Magnitude: 1.06496
Value Function Update Magnitude: 0.81195
Collected Steps per Second: 12,876.97276
Overall Steps per Second: 7,241.01495
Timestep Collection Time: 3.88492
Timestep Consumption Time: 3.02378
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.90870
Cumulative Model Updates: 145,919
Cumulative Timesteps: 1,176,860,996
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1176860996...
Checkpoint 1176860996 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.69728
Policy Entropy: 4.31916
Value Function Loss: 0.00275
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03448
Policy Update Magnitude: 1.07365
Value Function Update Magnitude: 0.82525
Collected Steps per Second: 12,925.20660
Overall Steps per Second: 7,159.35196
Timestep Collection Time: 3.87089
Timestep Consumption Time: 3.11746
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.98834
Cumulative Model Updates: 145,928
Cumulative Timesteps: 1,176,911,028
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.64478
Policy Entropy: 4.32257
Value Function Loss: 0.00275
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03443
Policy Update Magnitude: 1.06906
Value Function Update Magnitude: 0.80390
Collected Steps per Second: 12,949.67091
Overall Steps per Second: 7,191.44019
Timestep Collection Time: 3.86187
Timestep Consumption Time: 3.09223
PPO Batch Consumption Time: 0.23109
Total Iteration Time: 6.95410
Cumulative Model Updates: 145,937
Cumulative Timesteps: 1,176,961,038
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1176961038...
Checkpoint 1176961038 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50864
Policy Entropy: 4.32577
Value Function Loss: 0.00272
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03390
Policy Update Magnitude: 1.05041
Value Function Update Magnitude: 0.78488
Collected Steps per Second: 12,772.04620
Overall Steps per Second: 7,147.87156
Timestep Collection Time: 3.91856
Timestep Consumption Time: 3.08325
PPO Batch Consumption Time: 0.23207
Total Iteration Time: 7.00180
Cumulative Model Updates: 145,946
Cumulative Timesteps: 1,177,011,086
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.16274
Policy Entropy: 4.32595
Value Function Loss: 0.00279
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03324
Policy Update Magnitude: 1.05032
Value Function Update Magnitude: 0.76945
Collected Steps per Second: 13,005.86190
Overall Steps per Second: 7,168.26428
Timestep Collection Time: 3.84534
Timestep Consumption Time: 3.13152
PPO Batch Consumption Time: 0.23033
Total Iteration Time: 6.97686
Cumulative Model Updates: 145,955
Cumulative Timesteps: 1,177,061,098
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1177061098...
Checkpoint 1177061098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80141
Policy Entropy: 4.32412
Value Function Loss: 0.00296
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03620
Policy Update Magnitude: 1.06878
Value Function Update Magnitude: 0.80077
Collected Steps per Second: 12,860.59621
Overall Steps per Second: 7,139.00847
Timestep Collection Time: 3.89080
Timestep Consumption Time: 3.11830
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 7.00910
Cumulative Model Updates: 145,964
Cumulative Timesteps: 1,177,111,136
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53257
Policy Entropy: 4.32902
Value Function Loss: 0.00281
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03335
Policy Update Magnitude: 1.06103
Value Function Update Magnitude: 0.77959
Collected Steps per Second: 12,731.33886
Overall Steps per Second: 7,163.97072
Timestep Collection Time: 3.92779
Timestep Consumption Time: 3.05242
PPO Batch Consumption Time: 0.23124
Total Iteration Time: 6.98021
Cumulative Model Updates: 145,973
Cumulative Timesteps: 1,177,161,142
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1177161142...
Checkpoint 1177161142 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79373
Policy Entropy: 4.32479
Value Function Loss: 0.00293
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03360
Policy Update Magnitude: 1.05381
Value Function Update Magnitude: 0.79594
Collected Steps per Second: 12,857.99833
Overall Steps per Second: 7,095.77366
Timestep Collection Time: 3.89190
Timestep Consumption Time: 3.16047
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 7.05237
Cumulative Model Updates: 145,982
Cumulative Timesteps: 1,177,211,184
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.33842
Policy Entropy: 4.32876
Value Function Loss: 0.00278
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03311
Policy Update Magnitude: 1.04073
Value Function Update Magnitude: 0.81802
Collected Steps per Second: 12,902.03520
Overall Steps per Second: 7,181.97469
Timestep Collection Time: 3.87660
Timestep Consumption Time: 3.08750
PPO Batch Consumption Time: 0.23045
Total Iteration Time: 6.96410
Cumulative Model Updates: 145,991
Cumulative Timesteps: 1,177,261,200
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1177261200...
Checkpoint 1177261200 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.81828
Policy Entropy: 4.32031
Value Function Loss: 0.00286
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03513
Policy Update Magnitude: 1.03650
Value Function Update Magnitude: 0.80941
Collected Steps per Second: 12,989.16927
Overall Steps per Second: 7,263.30882
Timestep Collection Time: 3.84982
Timestep Consumption Time: 3.03492
PPO Batch Consumption Time: 0.23027
Total Iteration Time: 6.88474
Cumulative Model Updates: 146,000
Cumulative Timesteps: 1,177,311,206
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31577
Policy Entropy: 4.31939
Value Function Loss: 0.00287
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03518
Policy Update Magnitude: 1.05549
Value Function Update Magnitude: 0.80844
Collected Steps per Second: 12,895.40908
Overall Steps per Second: 7,102.06341
Timestep Collection Time: 3.87952
Timestep Consumption Time: 3.16463
PPO Batch Consumption Time: 0.23072
Total Iteration Time: 7.04415
Cumulative Model Updates: 146,009
Cumulative Timesteps: 1,177,361,234
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1177361234...
Checkpoint 1177361234 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28986
Policy Entropy: 4.31559
Value Function Loss: 0.00291
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03762
Policy Update Magnitude: 1.08246
Value Function Update Magnitude: 0.80914
Collected Steps per Second: 12,849.67448
Overall Steps per Second: 7,171.30704
Timestep Collection Time: 3.89130
Timestep Consumption Time: 3.08120
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.97251
Cumulative Model Updates: 146,018
Cumulative Timesteps: 1,177,411,236
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61786
Policy Entropy: 4.31905
Value Function Loss: 0.00287
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03643
Policy Update Magnitude: 1.08900
Value Function Update Magnitude: 0.79780
Collected Steps per Second: 12,800.09384
Overall Steps per Second: 7,243.62995
Timestep Collection Time: 3.90794
Timestep Consumption Time: 2.99771
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.90565
Cumulative Model Updates: 146,027
Cumulative Timesteps: 1,177,461,258
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1177461258...
Checkpoint 1177461258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22607
Policy Entropy: 4.32064
Value Function Loss: 0.00279
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03762
Policy Update Magnitude: 1.07378
Value Function Update Magnitude: 0.77871
Collected Steps per Second: 12,871.84408
Overall Steps per Second: 7,167.79153
Timestep Collection Time: 3.88445
Timestep Consumption Time: 3.09120
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.97565
Cumulative Model Updates: 146,036
Cumulative Timesteps: 1,177,511,258
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.16789
Policy Entropy: 4.32220
Value Function Loss: 0.00273
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03680
Policy Update Magnitude: 1.05905
Value Function Update Magnitude: 0.77466
Collected Steps per Second: 13,010.56370
Overall Steps per Second: 7,219.25490
Timestep Collection Time: 3.84426
Timestep Consumption Time: 3.08388
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.92814
Cumulative Model Updates: 146,045
Cumulative Timesteps: 1,177,561,274
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1177561274...
Checkpoint 1177561274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.08013
Policy Entropy: 4.32185
Value Function Loss: 0.00273
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03318
Policy Update Magnitude: 1.05287
Value Function Update Magnitude: 0.76302
Collected Steps per Second: 13,204.00982
Overall Steps per Second: 7,252.17731
Timestep Collection Time: 3.78809
Timestep Consumption Time: 3.10887
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.89696
Cumulative Model Updates: 146,054
Cumulative Timesteps: 1,177,611,292
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01605
Policy Entropy: 4.32378
Value Function Loss: 0.00278
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03381
Policy Update Magnitude: 1.05979
Value Function Update Magnitude: 0.76034
Collected Steps per Second: 13,078.21247
Overall Steps per Second: 7,197.74014
Timestep Collection Time: 3.82698
Timestep Consumption Time: 3.12660
PPO Batch Consumption Time: 0.22937
Total Iteration Time: 6.95357
Cumulative Model Updates: 146,063
Cumulative Timesteps: 1,177,661,342
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1177661342...
Checkpoint 1177661342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99168
Policy Entropy: 4.32285
Value Function Loss: 0.00279
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03606
Policy Update Magnitude: 1.05032
Value Function Update Magnitude: 0.76144
Collected Steps per Second: 12,904.74174
Overall Steps per Second: 7,221.31383
Timestep Collection Time: 3.87454
Timestep Consumption Time: 3.04940
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 6.92395
Cumulative Model Updates: 146,072
Cumulative Timesteps: 1,177,711,342
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.09740
Policy Entropy: 4.32236
Value Function Loss: 0.00287
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03536
Policy Update Magnitude: 1.06092
Value Function Update Magnitude: 0.78679
Collected Steps per Second: 13,040.80005
Overall Steps per Second: 7,213.13784
Timestep Collection Time: 3.83627
Timestep Consumption Time: 3.09941
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.93568
Cumulative Model Updates: 146,081
Cumulative Timesteps: 1,177,761,370
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1177761370...
Checkpoint 1177761370 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.63298
Policy Entropy: 4.32226
Value Function Loss: 0.00282
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03356
Policy Update Magnitude: 1.07694
Value Function Update Magnitude: 0.82448
Collected Steps per Second: 12,923.02939
Overall Steps per Second: 7,156.53901
Timestep Collection Time: 3.87216
Timestep Consumption Time: 3.12005
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.99221
Cumulative Model Updates: 146,090
Cumulative Timesteps: 1,177,811,410
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.77817
Policy Entropy: 4.32124
Value Function Loss: 0.00290
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03349
Policy Update Magnitude: 1.08203
Value Function Update Magnitude: 0.82049
Collected Steps per Second: 12,973.31805
Overall Steps per Second: 7,279.80910
Timestep Collection Time: 3.85468
Timestep Consumption Time: 3.01473
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.86941
Cumulative Model Updates: 146,099
Cumulative Timesteps: 1,177,861,418
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1177861418...
Checkpoint 1177861418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.54778
Policy Entropy: 4.32100
Value Function Loss: 0.00284
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03486
Policy Update Magnitude: 1.07382
Value Function Update Magnitude: 0.81379
Collected Steps per Second: 12,870.10360
Overall Steps per Second: 7,147.50823
Timestep Collection Time: 3.88668
Timestep Consumption Time: 3.11184
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 6.99852
Cumulative Model Updates: 146,108
Cumulative Timesteps: 1,177,911,440
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.94340
Policy Entropy: 4.32225
Value Function Loss: 0.00287
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03516
Policy Update Magnitude: 1.06403
Value Function Update Magnitude: 0.79779
Collected Steps per Second: 12,934.32518
Overall Steps per Second: 7,179.40358
Timestep Collection Time: 3.87063
Timestep Consumption Time: 3.10265
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.97328
Cumulative Model Updates: 146,117
Cumulative Timesteps: 1,177,961,504
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
Saving checkpoint 1177961504...
Checkpoint 1177961504 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.66041
Policy Entropy: 4.32100
Value Function Loss: 0.00288
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03181
Policy Update Magnitude: 1.06382
Value Function Update Magnitude: 0.77162
Collected Steps per Second: 12,914.12150
Overall Steps per Second: 7,260.42235
Timestep Collection Time: 3.87498
Timestep Consumption Time: 3.01745
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.89244
Cumulative Model Updates: 146,126
Cumulative Timesteps: 1,178,011,546
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.36328
Policy Entropy: 4.32024
Value Function Loss: 0.00284
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03289
Policy Update Magnitude: 1.06697
Value Function Update Magnitude: 0.76637
Collected Steps per Second: 13,060.45971
Overall Steps per Second: 7,031.41301
Timestep Collection Time: 3.82896
Timestep Consumption Time: 3.28312
PPO Batch Consumption Time: 0.23548
Total Iteration Time: 7.11208
Cumulative Model Updates: 146,135
Cumulative Timesteps: 1,178,061,554
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1178061554...
Checkpoint 1178061554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69991
Policy Entropy: 4.31570
Value Function Loss: 0.00283
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 1.06269
Value Function Update Magnitude: 0.78018
Collected Steps per Second: 12,852.47477
Overall Steps per Second: 7,170.71316
Timestep Collection Time: 3.89217
Timestep Consumption Time: 3.08399
PPO Batch Consumption Time: 0.22969
Total Iteration Time: 6.97615
Cumulative Model Updates: 146,144
Cumulative Timesteps: 1,178,111,578
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.62391
Policy Entropy: 4.32104
Value Function Loss: 0.00279
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03250
Policy Update Magnitude: 1.04460
Value Function Update Magnitude: 0.79917
Collected Steps per Second: 12,849.72219
Overall Steps per Second: 7,241.63497
Timestep Collection Time: 3.89145
Timestep Consumption Time: 3.01362
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.90507
Cumulative Model Updates: 146,153
Cumulative Timesteps: 1,178,161,582
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1178161582...
Checkpoint 1178161582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.38960
Policy Entropy: 4.31772
Value Function Loss: 0.00282
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03388
Policy Update Magnitude: 1.05184
Value Function Update Magnitude: 0.80684
Collected Steps per Second: 13,010.51674
Overall Steps per Second: 7,185.21832
Timestep Collection Time: 3.84304
Timestep Consumption Time: 3.11569
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.95873
Cumulative Model Updates: 146,162
Cumulative Timesteps: 1,178,211,582
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.80508
Policy Entropy: 4.32293
Value Function Loss: 0.00280
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 1.05912
Value Function Update Magnitude: 0.80492
Collected Steps per Second: 12,879.32515
Overall Steps per Second: 7,183.64874
Timestep Collection Time: 3.88328
Timestep Consumption Time: 3.07892
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.96220
Cumulative Model Updates: 146,171
Cumulative Timesteps: 1,178,261,596
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1178261596...
Checkpoint 1178261596 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.41128
Policy Entropy: 4.31789
Value Function Loss: 0.00284
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 1.06289
Value Function Update Magnitude: 0.81508
Collected Steps per Second: 12,806.70197
Overall Steps per Second: 7,231.04000
Timestep Collection Time: 3.90514
Timestep Consumption Time: 3.01115
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.91629
Cumulative Model Updates: 146,180
Cumulative Timesteps: 1,178,311,608
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.58667
Policy Entropy: 4.32091
Value Function Loss: 0.00284
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03547
Policy Update Magnitude: 1.07197
Value Function Update Magnitude: 0.83878
Collected Steps per Second: 12,964.80515
Overall Steps per Second: 7,183.92579
Timestep Collection Time: 3.85783
Timestep Consumption Time: 3.10438
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.96221
Cumulative Model Updates: 146,189
Cumulative Timesteps: 1,178,361,624
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1178361624...
Checkpoint 1178361624 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53863
Policy Entropy: 4.31617
Value Function Loss: 0.00281
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03628
Policy Update Magnitude: 1.06241
Value Function Update Magnitude: 0.80598
Collected Steps per Second: 12,689.62007
Overall Steps per Second: 7,079.05923
Timestep Collection Time: 3.94212
Timestep Consumption Time: 3.12436
PPO Batch Consumption Time: 0.23010
Total Iteration Time: 7.06648
Cumulative Model Updates: 146,198
Cumulative Timesteps: 1,178,411,648
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.72802
Policy Entropy: 4.32104
Value Function Loss: 0.00277
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03418
Policy Update Magnitude: 1.05823
Value Function Update Magnitude: 0.80217
Collected Steps per Second: 12,974.01241
Overall Steps per Second: 7,288.57779
Timestep Collection Time: 3.85447
Timestep Consumption Time: 3.00667
PPO Batch Consumption Time: 0.23023
Total Iteration Time: 6.86115
Cumulative Model Updates: 146,207
Cumulative Timesteps: 1,178,461,656
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1178461656...
Checkpoint 1178461656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25227
Policy Entropy: 4.31828
Value Function Loss: 0.00278
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 1.06362
Value Function Update Magnitude: 0.82463
Collected Steps per Second: 12,950.25691
Overall Steps per Second: 7,170.22033
Timestep Collection Time: 3.86232
Timestep Consumption Time: 3.11348
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.97580
Cumulative Model Updates: 146,216
Cumulative Timesteps: 1,178,511,674
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00729
Policy Entropy: 4.32151
Value Function Loss: 0.00280
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03280
Policy Update Magnitude: 1.06434
Value Function Update Magnitude: 0.84310
Collected Steps per Second: 12,970.79646
Overall Steps per Second: 7,128.24729
Timestep Collection Time: 3.85481
Timestep Consumption Time: 3.15953
PPO Batch Consumption Time: 0.23205
Total Iteration Time: 7.01435
Cumulative Model Updates: 146,225
Cumulative Timesteps: 1,178,561,674
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1178561674...
Checkpoint 1178561674 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.87119
Policy Entropy: 4.31783
Value Function Loss: 0.00281
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03395
Policy Update Magnitude: 1.05480
Value Function Update Magnitude: 0.82039
Collected Steps per Second: 13,195.37741
Overall Steps per Second: 7,237.91682
Timestep Collection Time: 3.79042
Timestep Consumption Time: 3.11986
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.91028
Cumulative Model Updates: 146,234
Cumulative Timesteps: 1,178,611,690
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05425
Policy Entropy: 4.31844
Value Function Loss: 0.00268
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 1.03869
Value Function Update Magnitude: 0.79250
Collected Steps per Second: 13,022.74117
Overall Steps per Second: 7,173.67325
Timestep Collection Time: 3.84174
Timestep Consumption Time: 3.13237
PPO Batch Consumption Time: 0.23065
Total Iteration Time: 6.97411
Cumulative Model Updates: 146,243
Cumulative Timesteps: 1,178,661,720
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1178661720...
Checkpoint 1178661720 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.78631
Policy Entropy: 4.32276
Value Function Loss: 0.00259
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 1.01231
Value Function Update Magnitude: 0.78241
Collected Steps per Second: 12,847.91072
Overall Steps per Second: 7,150.07751
Timestep Collection Time: 3.89184
Timestep Consumption Time: 3.10137
PPO Batch Consumption Time: 0.22933
Total Iteration Time: 6.99321
Cumulative Model Updates: 146,252
Cumulative Timesteps: 1,178,711,722
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27766
Policy Entropy: 4.32605
Value Function Loss: 0.00259
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03173
Policy Update Magnitude: 1.00672
Value Function Update Magnitude: 0.78272
Collected Steps per Second: 13,132.71959
Overall Steps per Second: 7,071.05983
Timestep Collection Time: 3.80942
Timestep Consumption Time: 3.26562
PPO Batch Consumption Time: 0.24216
Total Iteration Time: 7.07504
Cumulative Model Updates: 146,261
Cumulative Timesteps: 1,178,761,750
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1178761750...
Checkpoint 1178761750 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.70313
Policy Entropy: 4.32415
Value Function Loss: 0.00265
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03250
Policy Update Magnitude: 1.02823
Value Function Update Magnitude: 0.76578
Collected Steps per Second: 12,726.14155
Overall Steps per Second: 7,063.65683
Timestep Collection Time: 3.93301
Timestep Consumption Time: 3.15284
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 7.08585
Cumulative Model Updates: 146,270
Cumulative Timesteps: 1,178,811,802
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.17320
Policy Entropy: 4.32395
Value Function Loss: 0.00260
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03398
Policy Update Magnitude: 1.03650
Value Function Update Magnitude: 0.76582
Collected Steps per Second: 12,927.77271
Overall Steps per Second: 7,164.95088
Timestep Collection Time: 3.86888
Timestep Consumption Time: 3.11177
PPO Batch Consumption Time: 0.23090
Total Iteration Time: 6.98065
Cumulative Model Updates: 146,279
Cumulative Timesteps: 1,178,861,818
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1178861818...
Checkpoint 1178861818 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.93770
Policy Entropy: 4.32266
Value Function Loss: 0.00259
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 1.02381
Value Function Update Magnitude: 0.76814
Collected Steps per Second: 13,205.74907
Overall Steps per Second: 7,234.65211
Timestep Collection Time: 3.78638
Timestep Consumption Time: 3.12508
PPO Batch Consumption Time: 0.22994
Total Iteration Time: 6.91146
Cumulative Model Updates: 146,288
Cumulative Timesteps: 1,178,911,820
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.68560
Policy Entropy: 4.32337
Value Function Loss: 0.00262
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03164
Policy Update Magnitude: 1.02560
Value Function Update Magnitude: 0.74392
Collected Steps per Second: 12,927.04293
Overall Steps per Second: 7,155.80599
Timestep Collection Time: 3.87003
Timestep Consumption Time: 3.12122
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.99125
Cumulative Model Updates: 146,297
Cumulative Timesteps: 1,178,961,848
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1178961848...
Checkpoint 1178961848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03780
Policy Entropy: 4.32714
Value Function Loss: 0.00270
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 1.02787
Value Function Update Magnitude: 0.75385
Collected Steps per Second: 12,743.38393
Overall Steps per Second: 7,137.86494
Timestep Collection Time: 3.92674
Timestep Consumption Time: 3.08376
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 7.01050
Cumulative Model Updates: 146,306
Cumulative Timesteps: 1,179,011,888
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.26493
Policy Entropy: 4.32714
Value Function Loss: 0.00277
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03460
Policy Update Magnitude: 1.03292
Value Function Update Magnitude: 0.77461
Collected Steps per Second: 12,909.07585
Overall Steps per Second: 7,272.70676
Timestep Collection Time: 3.87557
Timestep Consumption Time: 3.00358
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.87914
Cumulative Model Updates: 146,315
Cumulative Timesteps: 1,179,061,918
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1179061918...
Checkpoint 1179061918 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.79735
Policy Entropy: 4.32254
Value Function Loss: 0.00288
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03359
Policy Update Magnitude: 1.05443
Value Function Update Magnitude: 0.78195
Collected Steps per Second: 12,876.44623
Overall Steps per Second: 7,112.34863
Timestep Collection Time: 3.88399
Timestep Consumption Time: 3.14772
PPO Batch Consumption Time: 0.23210
Total Iteration Time: 7.03171
Cumulative Model Updates: 146,324
Cumulative Timesteps: 1,179,111,930
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65257
Policy Entropy: 4.32122
Value Function Loss: 0.00279
Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03722
Policy Update Magnitude: 1.04969
Value Function Update Magnitude: 0.78306
Collected Steps per Second: 13,081.23830
Overall Steps per Second: 7,234.27779
Timestep Collection Time: 3.82410
Timestep Consumption Time: 3.09075
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.91486
Cumulative Model Updates: 146,333
Cumulative Timesteps: 1,179,161,954
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1179161954...
Checkpoint 1179161954 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.06234
Policy Entropy: 4.31985
Value Function Loss: 0.00277
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03671
Policy Update Magnitude: 1.05000
Value Function Update Magnitude: 0.79681
Collected Steps per Second: 13,156.40705
Overall Steps per Second: 7,203.11801
Timestep Collection Time: 3.80225
Timestep Consumption Time: 3.14252
PPO Batch Consumption Time: 0.22936
Total Iteration Time: 6.94477
Cumulative Model Updates: 146,342
Cumulative Timesteps: 1,179,211,978
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50106
Policy Entropy: 4.32164
Value Function Loss: 0.00265
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03458
Policy Update Magnitude: 1.06379
Value Function Update Magnitude: 0.80852
Collected Steps per Second: 12,864.88806
Overall Steps per Second: 7,146.79931
Timestep Collection Time: 3.89028
Timestep Consumption Time: 3.11258
PPO Batch Consumption Time: 0.23090
Total Iteration Time: 7.00286
Cumulative Model Updates: 146,351
Cumulative Timesteps: 1,179,262,026
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1179262026...
Checkpoint 1179262026 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.14044
Policy Entropy: 4.31764
Value Function Loss: 0.00284
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03777
Policy Update Magnitude: 1.07552
Value Function Update Magnitude: 0.81691
Collected Steps per Second: 12,768.01890
Overall Steps per Second: 7,151.16628
Timestep Collection Time: 3.91791
Timestep Consumption Time: 3.07731
PPO Batch Consumption Time: 0.22936
Total Iteration Time: 6.99522
Cumulative Model Updates: 146,360
Cumulative Timesteps: 1,179,312,050
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.37821
Policy Entropy: 4.31993
Value Function Loss: 0.00284
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03663
Policy Update Magnitude: 1.07729
Value Function Update Magnitude: 0.80663
Collected Steps per Second: 13,385.09804
Overall Steps per Second: 7,302.53849
Timestep Collection Time: 3.73565
Timestep Consumption Time: 3.11156
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.84721
Cumulative Model Updates: 146,369
Cumulative Timesteps: 1,179,362,052
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1179362052...
Checkpoint 1179362052 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.47490
Policy Entropy: 4.31851
Value Function Loss: 0.00291
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03692
Policy Update Magnitude: 1.05242
Value Function Update Magnitude: 0.77290
Collected Steps per Second: 12,816.12701
Overall Steps per Second: 7,129.91510
Timestep Collection Time: 3.90274
Timestep Consumption Time: 3.11249
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 7.01523
Cumulative Model Updates: 146,378
Cumulative Timesteps: 1,179,412,070
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.01287
Policy Entropy: 4.31849
Value Function Loss: 0.00290
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03458
Policy Update Magnitude: 1.04617
Value Function Update Magnitude: 0.77700
Collected Steps per Second: 12,779.34836
Overall Steps per Second: 7,079.10415
Timestep Collection Time: 3.91475
Timestep Consumption Time: 3.15224
PPO Batch Consumption Time: 0.23399
Total Iteration Time: 7.06700
Cumulative Model Updates: 146,387
Cumulative Timesteps: 1,179,462,098
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1179462098...
Checkpoint 1179462098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.17230
Policy Entropy: 4.31658
Value Function Loss: 0.00282
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03557
Policy Update Magnitude: 1.03572
Value Function Update Magnitude: 0.74521
Collected Steps per Second: 13,231.21479
Overall Steps per Second: 7,250.45245
Timestep Collection Time: 3.78076
Timestep Consumption Time: 3.11868
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.89943
Cumulative Model Updates: 146,396
Cumulative Timesteps: 1,179,512,122
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.59567
Policy Entropy: 4.32423
Value Function Loss: 0.00266
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03414
Policy Update Magnitude: 1.02739
Value Function Update Magnitude: 0.75697
Collected Steps per Second: 13,028.21517
Overall Steps per Second: 7,215.64487
Timestep Collection Time: 3.84089
Timestep Consumption Time: 3.09404
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.93493
Cumulative Model Updates: 146,405
Cumulative Timesteps: 1,179,562,162
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1179562162...
Checkpoint 1179562162 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.88368
Policy Entropy: 4.32553
Value Function Loss: 0.00256
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03448
Policy Update Magnitude: 1.00956
Value Function Update Magnitude: 0.76818
Collected Steps per Second: 12,604.69942
Overall Steps per Second: 7,066.36797
Timestep Collection Time: 3.96995
Timestep Consumption Time: 3.11148
PPO Batch Consumption Time: 0.22970
Total Iteration Time: 7.08143
Cumulative Model Updates: 146,414
Cumulative Timesteps: 1,179,612,202
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.74274
Policy Entropy: 4.32664
Value Function Loss: 0.00268
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03228
Policy Update Magnitude: 1.00265
Value Function Update Magnitude: 0.73252
Collected Steps per Second: 13,069.03698
Overall Steps per Second: 7,202.98112
Timestep Collection Time: 3.82675
Timestep Consumption Time: 3.11648
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.94324
Cumulative Model Updates: 146,423
Cumulative Timesteps: 1,179,662,214
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1179662214...
Checkpoint 1179662214 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31772
Policy Entropy: 4.32415
Value Function Loss: 0.00297
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03242
Policy Update Magnitude: 1.03859
Value Function Update Magnitude: 0.76233
Collected Steps per Second: 12,934.41557
Overall Steps per Second: 7,171.95757
Timestep Collection Time: 3.86736
Timestep Consumption Time: 3.10731
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.97466
Cumulative Model Updates: 146,432
Cumulative Timesteps: 1,179,712,236
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.26004
Policy Entropy: 4.32272
Value Function Loss: 0.00305
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03667
Policy Update Magnitude: 1.06432
Value Function Update Magnitude: 0.79932
Collected Steps per Second: 12,673.01316
Overall Steps per Second: 7,185.60005
Timestep Collection Time: 3.94713
Timestep Consumption Time: 3.01430
PPO Batch Consumption Time: 0.22937
Total Iteration Time: 6.96142
Cumulative Model Updates: 146,441
Cumulative Timesteps: 1,179,762,258
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1179762258...
Checkpoint 1179762258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.91943
Policy Entropy: 4.32941
Value Function Loss: 0.00287
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03372
Policy Update Magnitude: 1.03962
Value Function Update Magnitude: 0.77420
Collected Steps per Second: 12,758.70967
Overall Steps per Second: 7,035.10761
Timestep Collection Time: 3.92062
Timestep Consumption Time: 3.18972
PPO Batch Consumption Time: 0.23392
Total Iteration Time: 7.11034
Cumulative Model Updates: 146,450
Cumulative Timesteps: 1,179,812,280
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36216
Policy Entropy: 4.33301
Value Function Loss: 0.00267
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03080
Policy Update Magnitude: 1.01107
Value Function Update Magnitude: 0.76600
Collected Steps per Second: 12,930.38568
Overall Steps per Second: 7,204.05396
Timestep Collection Time: 3.86918
Timestep Consumption Time: 3.07552
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.94470
Cumulative Model Updates: 146,459
Cumulative Timesteps: 1,179,862,310
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1179862310...
Checkpoint 1179862310 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06541
Policy Entropy: 4.33438
Value Function Loss: 0.00255
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02975
Policy Update Magnitude: 0.99681
Value Function Update Magnitude: 0.75885
Collected Steps per Second: 12,838.15023
Overall Steps per Second: 7,245.86771
Timestep Collection Time: 3.89542
Timestep Consumption Time: 3.00644
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.90186
Cumulative Model Updates: 146,468
Cumulative Timesteps: 1,179,912,320
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.58870
Policy Entropy: 4.32949
Value Function Loss: 0.00263
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 1.00202
Value Function Update Magnitude: 0.78604
Collected Steps per Second: 13,091.23587
Overall Steps per Second: 7,212.48512
Timestep Collection Time: 3.81996
Timestep Consumption Time: 3.11357
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.93353
Cumulative Model Updates: 146,477
Cumulative Timesteps: 1,179,962,328
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1179962328...
Checkpoint 1179962328 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.89755
Policy Entropy: 4.32439
Value Function Loss: 0.00263
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03235
Policy Update Magnitude: 1.01830
Value Function Update Magnitude: 0.77678
Collected Steps per Second: 12,989.01950
Overall Steps per Second: 7,206.97170
Timestep Collection Time: 3.85110
Timestep Consumption Time: 3.08968
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.94078
Cumulative Model Updates: 146,486
Cumulative Timesteps: 1,180,012,350
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50011
Policy Entropy: 4.32771
Value Function Loss: 0.00260
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 1.00862
Value Function Update Magnitude: 0.75043
Collected Steps per Second: 12,915.69522
Overall Steps per Second: 7,261.69852
Timestep Collection Time: 3.87343
Timestep Consumption Time: 3.01587
PPO Batch Consumption Time: 0.22985
Total Iteration Time: 6.88930
Cumulative Model Updates: 146,495
Cumulative Timesteps: 1,180,062,378
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1180062378...
Checkpoint 1180062378 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.45159
Policy Entropy: 4.33222
Value Function Loss: 0.00251
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 0.98782
Value Function Update Magnitude: 0.76056
Collected Steps per Second: 12,915.62203
Overall Steps per Second: 7,128.18839
Timestep Collection Time: 3.87360
Timestep Consumption Time: 3.14501
PPO Batch Consumption Time: 0.22959
Total Iteration Time: 7.01861
Cumulative Model Updates: 146,504
Cumulative Timesteps: 1,180,112,408
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.40589
Policy Entropy: 4.33366
Value Function Loss: 0.00261
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 1.00071
Value Function Update Magnitude: 0.72718
Collected Steps per Second: 12,874.52647
Overall Steps per Second: 7,107.96114
Timestep Collection Time: 3.88473
Timestep Consumption Time: 3.15161
PPO Batch Consumption Time: 0.22938
Total Iteration Time: 7.03634
Cumulative Model Updates: 146,513
Cumulative Timesteps: 1,180,162,422
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1180162422...
Checkpoint 1180162422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.59328
Policy Entropy: 4.32668
Value Function Loss: 0.00267
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03248
Policy Update Magnitude: 1.00672
Value Function Update Magnitude: 0.74283
Collected Steps per Second: 12,835.25521
Overall Steps per Second: 7,229.18939
Timestep Collection Time: 3.89614
Timestep Consumption Time: 3.02137
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.91751
Cumulative Model Updates: 146,522
Cumulative Timesteps: 1,180,212,430
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27120
Policy Entropy: 4.32567
Value Function Loss: 0.00283
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03411
Policy Update Magnitude: 1.00956
Value Function Update Magnitude: 0.76592
Collected Steps per Second: 12,915.73190
Overall Steps per Second: 7,168.04065
Timestep Collection Time: 3.87342
Timestep Consumption Time: 3.10590
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.97931
Cumulative Model Updates: 146,531
Cumulative Timesteps: 1,180,262,458
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1180262458...
Checkpoint 1180262458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.82130
Policy Entropy: 4.32586
Value Function Loss: 0.00284
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03314
Policy Update Magnitude: 1.02250
Value Function Update Magnitude: 0.79272
Collected Steps per Second: 12,853.06969
Overall Steps per Second: 7,189.64089
Timestep Collection Time: 3.89059
Timestep Consumption Time: 3.06470
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.95528
Cumulative Model Updates: 146,540
Cumulative Timesteps: 1,180,312,464
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36570
Policy Entropy: 4.32390
Value Function Loss: 0.00284
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03441
Policy Update Magnitude: 1.03382
Value Function Update Magnitude: 0.79752
Collected Steps per Second: 12,840.55683
Overall Steps per Second: 7,260.00029
Timestep Collection Time: 3.89796
Timestep Consumption Time: 2.99625
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.89421
Cumulative Model Updates: 146,549
Cumulative Timesteps: 1,180,362,516
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1180362516...
Checkpoint 1180362516 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.63989
Policy Entropy: 4.32175
Value Function Loss: 0.00292
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03626
Policy Update Magnitude: 1.04808
Value Function Update Magnitude: 0.78705
Collected Steps per Second: 12,812.91909
Overall Steps per Second: 7,079.56967
Timestep Collection Time: 3.90403
Timestep Consumption Time: 3.16166
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 7.06568
Cumulative Model Updates: 146,558
Cumulative Timesteps: 1,180,412,538
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46783
Policy Entropy: 4.32395
Value Function Loss: 0.00283
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03697
Policy Update Magnitude: 1.04356
Value Function Update Magnitude: 0.78970
Collected Steps per Second: 12,933.84212
Overall Steps per Second: 7,188.69665
Timestep Collection Time: 3.86861
Timestep Consumption Time: 3.09176
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.96037
Cumulative Model Updates: 146,567
Cumulative Timesteps: 1,180,462,574
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1180462574...
Checkpoint 1180462574 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.90529
Policy Entropy: 4.32553
Value Function Loss: 0.00289
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03371
Policy Update Magnitude: 1.04907
Value Function Update Magnitude: 0.81338
Collected Steps per Second: 12,817.58440
Overall Steps per Second: 7,046.16362
Timestep Collection Time: 3.90339
Timestep Consumption Time: 3.19721
PPO Batch Consumption Time: 0.23956
Total Iteration Time: 7.10060
Cumulative Model Updates: 146,576
Cumulative Timesteps: 1,180,512,606
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.77739
Policy Entropy: 4.33024
Value Function Loss: 0.00286
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 1.05867
Value Function Update Magnitude: 0.87555
Collected Steps per Second: 13,005.38731
Overall Steps per Second: 7,168.71528
Timestep Collection Time: 3.84656
Timestep Consumption Time: 3.13182
PPO Batch Consumption Time: 0.23026
Total Iteration Time: 6.97838
Cumulative Model Updates: 146,585
Cumulative Timesteps: 1,180,562,632
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1180562632...
Checkpoint 1180562632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76038
Policy Entropy: 4.32667
Value Function Loss: 0.00293
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03545
Policy Update Magnitude: 1.05536
Value Function Update Magnitude: 0.88254
Collected Steps per Second: 12,772.29729
Overall Steps per Second: 7,168.62602
Timestep Collection Time: 3.91660
Timestep Consumption Time: 3.06158
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.97819
Cumulative Model Updates: 146,594
Cumulative Timesteps: 1,180,612,656
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.70427
Policy Entropy: 4.32646
Value Function Loss: 0.00282
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 1.04260
Value Function Update Magnitude: 0.84964
Collected Steps per Second: 12,956.12279
Overall Steps per Second: 7,252.69363
Timestep Collection Time: 3.85980
Timestep Consumption Time: 3.03530
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.89509
Cumulative Model Updates: 146,603
Cumulative Timesteps: 1,180,662,664
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1180662664...
Checkpoint 1180662664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.55117
Policy Entropy: 4.32495
Value Function Loss: 0.00280
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03388
Policy Update Magnitude: 1.02991
Value Function Update Magnitude: 0.81838
Collected Steps per Second: 12,716.58983
Overall Steps per Second: 7,091.38429
Timestep Collection Time: 3.93266
Timestep Consumption Time: 3.11956
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 7.05222
Cumulative Model Updates: 146,612
Cumulative Timesteps: 1,180,712,674
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.71502
Policy Entropy: 4.32456
Value Function Loss: 0.00266
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03311
Policy Update Magnitude: 1.02087
Value Function Update Magnitude: 0.78881
Collected Steps per Second: 12,970.37237
Overall Steps per Second: 7,194.75919
Timestep Collection Time: 3.85741
Timestep Consumption Time: 3.09654
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.95395
Cumulative Model Updates: 146,621
Cumulative Timesteps: 1,180,762,706
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1180762706...
Checkpoint 1180762706 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.35220
Policy Entropy: 4.32677
Value Function Loss: 0.00261
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03246
Policy Update Magnitude: 1.00900
Value Function Update Magnitude: 0.78273
Collected Steps per Second: 13,197.16345
Overall Steps per Second: 7,255.22571
Timestep Collection Time: 3.79142
Timestep Consumption Time: 3.10513
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.89655
Cumulative Model Updates: 146,630
Cumulative Timesteps: 1,180,812,742
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87149
Policy Entropy: 4.32995
Value Function Loss: 0.00241
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03297
Policy Update Magnitude: 0.99675
Value Function Update Magnitude: 0.74283
Collected Steps per Second: 12,967.90667
Overall Steps per Second: 7,132.23279
Timestep Collection Time: 3.85675
Timestep Consumption Time: 3.15564
PPO Batch Consumption Time: 0.22963
Total Iteration Time: 7.01239
Cumulative Model Updates: 146,639
Cumulative Timesteps: 1,180,862,756
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1180862756...
Checkpoint 1180862756 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.11877
Policy Entropy: 4.33411
Value Function Loss: 0.00243
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03060
Policy Update Magnitude: 0.98456
Value Function Update Magnitude: 0.71361
Collected Steps per Second: 12,886.17348
Overall Steps per Second: 7,171.74069
Timestep Collection Time: 3.88308
Timestep Consumption Time: 3.09403
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.97711
Cumulative Model Updates: 146,648
Cumulative Timesteps: 1,180,912,794
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.26287
Policy Entropy: 4.33318
Value Function Loss: 0.00249
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03175
Policy Update Magnitude: 0.98909
Value Function Update Magnitude: 0.74188
Collected Steps per Second: 12,772.96192
Overall Steps per Second: 7,243.46733
Timestep Collection Time: 3.91561
Timestep Consumption Time: 2.98909
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.90470
Cumulative Model Updates: 146,657
Cumulative Timesteps: 1,180,962,808
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1180962808...
Checkpoint 1180962808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.41265
Policy Entropy: 4.33783
Value Function Loss: 0.00251
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03026
Policy Update Magnitude: 0.98505
Value Function Update Magnitude: 0.74833
Collected Steps per Second: 12,907.88370
Overall Steps per Second: 7,165.87486
Timestep Collection Time: 3.87438
Timestep Consumption Time: 3.10453
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.97891
Cumulative Model Updates: 146,666
Cumulative Timesteps: 1,181,012,818
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61729
Policy Entropy: 4.33813
Value Function Loss: 0.00250
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 0.97786
Value Function Update Magnitude: 0.75056
Collected Steps per Second: 13,053.74249
Overall Steps per Second: 7,228.52784
Timestep Collection Time: 3.83078
Timestep Consumption Time: 3.08709
PPO Batch Consumption Time: 0.22987
Total Iteration Time: 6.91787
Cumulative Model Updates: 146,675
Cumulative Timesteps: 1,181,062,824
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1181062824...
Checkpoint 1181062824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41417
Policy Entropy: 4.34117
Value Function Loss: 0.00241
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03047
Policy Update Magnitude: 0.98282
Value Function Update Magnitude: 0.76499
Collected Steps per Second: 13,045.10300
Overall Steps per Second: 7,214.81316
Timestep Collection Time: 3.83500
Timestep Consumption Time: 3.09906
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.93407
Cumulative Model Updates: 146,684
Cumulative Timesteps: 1,181,112,852
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.24712
Policy Entropy: 4.34007
Value Function Loss: 0.00245
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03112
Policy Update Magnitude: 0.99549
Value Function Update Magnitude: 0.75381
Collected Steps per Second: 12,897.45952
Overall Steps per Second: 7,145.43766
Timestep Collection Time: 3.87704
Timestep Consumption Time: 3.12099
PPO Batch Consumption Time: 0.23043
Total Iteration Time: 6.99803
Cumulative Model Updates: 146,693
Cumulative Timesteps: 1,181,162,856
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1181162856...
Checkpoint 1181162856 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19811
Policy Entropy: 4.33363
Value Function Loss: 0.00254
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03244
Policy Update Magnitude: 1.00838
Value Function Update Magnitude: 0.75023
Collected Steps per Second: 12,832.16862
Overall Steps per Second: 7,078.41008
Timestep Collection Time: 3.89880
Timestep Consumption Time: 3.16918
PPO Batch Consumption Time: 0.23116
Total Iteration Time: 7.06797
Cumulative Model Updates: 146,702
Cumulative Timesteps: 1,181,212,886
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83139
Policy Entropy: 4.33104
Value Function Loss: 0.00256
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03308
Policy Update Magnitude: 1.01231
Value Function Update Magnitude: 0.76673
Collected Steps per Second: 13,227.65249
Overall Steps per Second: 7,239.75533
Timestep Collection Time: 3.78041
Timestep Consumption Time: 3.12673
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 6.90714
Cumulative Model Updates: 146,711
Cumulative Timesteps: 1,181,262,892
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1181262892...
Checkpoint 1181262892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77112
Policy Entropy: 4.32982
Value Function Loss: 0.00257
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03356
Policy Update Magnitude: 1.00501
Value Function Update Magnitude: 0.74205
Collected Steps per Second: 12,969.29882
Overall Steps per Second: 7,082.26410
Timestep Collection Time: 3.85618
Timestep Consumption Time: 3.20540
PPO Batch Consumption Time: 0.22980
Total Iteration Time: 7.06158
Cumulative Model Updates: 146,720
Cumulative Timesteps: 1,181,312,904
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67732
Policy Entropy: 4.33077
Value Function Loss: 0.00267
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03225
Policy Update Magnitude: 1.03002
Value Function Update Magnitude: 0.74681
Collected Steps per Second: 13,055.22135
Overall Steps per Second: 7,211.75838
Timestep Collection Time: 3.83234
Timestep Consumption Time: 3.10522
PPO Batch Consumption Time: 0.23006
Total Iteration Time: 6.93756
Cumulative Model Updates: 146,729
Cumulative Timesteps: 1,181,362,936
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1181362936...
Checkpoint 1181362936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22060
Policy Entropy: 4.32952
Value Function Loss: 0.00288
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03362
Policy Update Magnitude: 1.05073
Value Function Update Magnitude: 0.77445
Collected Steps per Second: 13,272.31850
Overall Steps per Second: 7,247.83493
Timestep Collection Time: 3.76739
Timestep Consumption Time: 3.13150
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.89889
Cumulative Model Updates: 146,738
Cumulative Timesteps: 1,181,412,938
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.40236
Policy Entropy: 4.32597
Value Function Loss: 0.00292
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03741
Policy Update Magnitude: 1.04992
Value Function Update Magnitude: 0.78051
Collected Steps per Second: 12,870.77445
Overall Steps per Second: 7,123.09016
Timestep Collection Time: 3.88679
Timestep Consumption Time: 3.13629
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 7.02308
Cumulative Model Updates: 146,747
Cumulative Timesteps: 1,181,462,964
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1181462964...
Checkpoint 1181462964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35102
Policy Entropy: 4.32260
Value Function Loss: 0.00304
Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03914
Policy Update Magnitude: 1.04094
Value Function Update Magnitude: 0.79332
Collected Steps per Second: 12,865.69256
Overall Steps per Second: 7,168.86744
Timestep Collection Time: 3.88724
Timestep Consumption Time: 3.08904
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.97628
Cumulative Model Updates: 146,756
Cumulative Timesteps: 1,181,512,976
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99680
Policy Entropy: 4.32249
Value Function Loss: 0.00291
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03698
Policy Update Magnitude: 1.04731
Value Function Update Magnitude: 0.79988
Collected Steps per Second: 13,248.59918
Overall Steps per Second: 7,199.55767
Timestep Collection Time: 3.77398
Timestep Consumption Time: 3.17089
PPO Batch Consumption Time: 0.23365
Total Iteration Time: 6.94487
Cumulative Model Updates: 146,765
Cumulative Timesteps: 1,181,562,976
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1181562976...
Checkpoint 1181562976 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.83108
Policy Entropy: 4.32107
Value Function Loss: 0.00284
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03576
Policy Update Magnitude: 1.04537
Value Function Update Magnitude: 0.79544
Collected Steps per Second: 13,011.26068
Overall Steps per Second: 7,195.45185
Timestep Collection Time: 3.84559
Timestep Consumption Time: 3.10825
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.95384
Cumulative Model Updates: 146,774
Cumulative Timesteps: 1,181,613,012
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36966
Policy Entropy: 4.32107
Value Function Loss: 0.00281
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03690
Policy Update Magnitude: 1.05430
Value Function Update Magnitude: 0.77721
Collected Steps per Second: 12,854.54963
Overall Steps per Second: 7,191.85053
Timestep Collection Time: 3.89107
Timestep Consumption Time: 3.06374
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.95482
Cumulative Model Updates: 146,783
Cumulative Timesteps: 1,181,663,030
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1181663030...
Checkpoint 1181663030 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01883
Policy Entropy: 4.32026
Value Function Loss: 0.00279
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 1.05176
Value Function Update Magnitude: 0.78066
Collected Steps per Second: 13,346.11810
Overall Steps per Second: 7,301.73778
Timestep Collection Time: 3.74925
Timestep Consumption Time: 3.10363
PPO Batch Consumption Time: 0.22933
Total Iteration Time: 6.85289
Cumulative Model Updates: 146,792
Cumulative Timesteps: 1,181,713,068
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.98669
Policy Entropy: 4.32203
Value Function Loss: 0.00272
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03673
Policy Update Magnitude: 1.03259
Value Function Update Magnitude: 0.80359
Collected Steps per Second: 12,944.43252
Overall Steps per Second: 7,160.26179
Timestep Collection Time: 3.86498
Timestep Consumption Time: 3.12219
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.98717
Cumulative Model Updates: 146,801
Cumulative Timesteps: 1,181,763,098
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1181763098...
Checkpoint 1181763098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.65567
Policy Entropy: 4.32578
Value Function Loss: 0.00268
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03546
Policy Update Magnitude: 1.02006
Value Function Update Magnitude: 0.77363
Collected Steps per Second: 12,984.80291
Overall Steps per Second: 7,201.75690
Timestep Collection Time: 3.85189
Timestep Consumption Time: 3.09308
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.94497
Cumulative Model Updates: 146,810
Cumulative Timesteps: 1,181,813,114
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.13408
Policy Entropy: 4.32920
Value Function Loss: 0.00274
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03682
Policy Update Magnitude: 1.01585
Value Function Update Magnitude: 0.77379
Collected Steps per Second: 13,250.04070
Overall Steps per Second: 7,251.68701
Timestep Collection Time: 3.77599
Timestep Consumption Time: 3.12337
PPO Batch Consumption Time: 0.23060
Total Iteration Time: 6.89936
Cumulative Model Updates: 146,819
Cumulative Timesteps: 1,181,863,146
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1181863146...
Checkpoint 1181863146 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.20621
Policy Entropy: 4.32810
Value Function Loss: 0.00278
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03568
Policy Update Magnitude: 1.02730
Value Function Update Magnitude: 0.76818
Collected Steps per Second: 12,828.80611
Overall Steps per Second: 6,986.62388
Timestep Collection Time: 3.89982
Timestep Consumption Time: 3.26101
PPO Batch Consumption Time: 0.24054
Total Iteration Time: 7.16083
Cumulative Model Updates: 146,828
Cumulative Timesteps: 1,181,913,176
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.91721
Policy Entropy: 4.32784
Value Function Loss: 0.00286
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03432
Policy Update Magnitude: 1.03830
Value Function Update Magnitude: 0.79495
Collected Steps per Second: 12,688.98907
Overall Steps per Second: 7,195.78358
Timestep Collection Time: 3.94200
Timestep Consumption Time: 3.00929
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.95129
Cumulative Model Updates: 146,837
Cumulative Timesteps: 1,181,963,196
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1181963196...
Checkpoint 1181963196 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28152
Policy Entropy: 4.32183
Value Function Loss: 0.00278
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03550
Policy Update Magnitude: 1.03873
Value Function Update Magnitude: 0.81272
Collected Steps per Second: 12,857.80521
Overall Steps per Second: 7,147.20570
Timestep Collection Time: 3.88916
Timestep Consumption Time: 3.10743
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.99658
Cumulative Model Updates: 146,846
Cumulative Timesteps: 1,182,013,202
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61741
Policy Entropy: 4.32494
Value Function Loss: 0.00274
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03464
Policy Update Magnitude: 1.03392
Value Function Update Magnitude: 0.80348
Collected Steps per Second: 12,965.30587
Overall Steps per Second: 7,166.54490
Timestep Collection Time: 3.85845
Timestep Consumption Time: 3.12204
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.98049
Cumulative Model Updates: 146,855
Cumulative Timesteps: 1,182,063,228
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1182063228...
Checkpoint 1182063228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04806
Policy Entropy: 4.32151
Value Function Loss: 0.00282
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03599
Policy Update Magnitude: 1.04295
Value Function Update Magnitude: 0.78743
Collected Steps per Second: 12,750.30692
Overall Steps per Second: 7,144.42096
Timestep Collection Time: 3.92273
Timestep Consumption Time: 3.07798
PPO Batch Consumption Time: 0.22965
Total Iteration Time: 7.00071
Cumulative Model Updates: 146,864
Cumulative Timesteps: 1,182,113,244
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46190
Policy Entropy: 4.32570
Value Function Loss: 0.00275
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03448
Policy Update Magnitude: 1.03322
Value Function Update Magnitude: 0.81013
Collected Steps per Second: 12,999.23796
Overall Steps per Second: 7,165.38905
Timestep Collection Time: 3.84746
Timestep Consumption Time: 3.13249
PPO Batch Consumption Time: 0.22959
Total Iteration Time: 6.97994
Cumulative Model Updates: 146,873
Cumulative Timesteps: 1,182,163,258
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1182163258...
Checkpoint 1182163258 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.55981
Policy Entropy: 4.32714
Value Function Loss: 0.00254
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03416
Policy Update Magnitude: 0.98869
Value Function Update Magnitude: 0.78932
Collected Steps per Second: 12,994.47948
Overall Steps per Second: 7,160.40216
Timestep Collection Time: 3.84871
Timestep Consumption Time: 3.13581
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 6.98452
Cumulative Model Updates: 146,882
Cumulative Timesteps: 1,182,213,270
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.69502
Policy Entropy: 4.33070
Value Function Loss: 0.00239
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03255
Policy Update Magnitude: 0.96889
Value Function Update Magnitude: 0.75854
Collected Steps per Second: 12,903.47147
Overall Steps per Second: 7,107.98331
Timestep Collection Time: 3.87632
Timestep Consumption Time: 3.16056
PPO Batch Consumption Time: 0.24067
Total Iteration Time: 7.03688
Cumulative Model Updates: 146,891
Cumulative Timesteps: 1,182,263,288
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1182263288...
Checkpoint 1182263288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.63220
Policy Entropy: 4.33501
Value Function Loss: 0.00241
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03263
Policy Update Magnitude: 0.98480
Value Function Update Magnitude: 0.78405
Collected Steps per Second: 13,012.42641
Overall Steps per Second: 7,203.96301
Timestep Collection Time: 3.84310
Timestep Consumption Time: 3.09864
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.94173
Cumulative Model Updates: 146,900
Cumulative Timesteps: 1,182,313,296
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93788
Policy Entropy: 4.33367
Value Function Loss: 0.00256
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03315
Policy Update Magnitude: 1.00093
Value Function Update Magnitude: 0.81081
Collected Steps per Second: 12,959.11940
Overall Steps per Second: 7,171.41447
Timestep Collection Time: 3.85998
Timestep Consumption Time: 3.11521
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.97519
Cumulative Model Updates: 146,909
Cumulative Timesteps: 1,182,363,318
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1182363318...
Checkpoint 1182363318 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.15034
Policy Entropy: 4.33339
Value Function Loss: 0.00257
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03092
Policy Update Magnitude: 1.00998
Value Function Update Magnitude: 0.81673
Collected Steps per Second: 12,965.07880
Overall Steps per Second: 7,278.88425
Timestep Collection Time: 3.85960
Timestep Consumption Time: 3.01508
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.87468
Cumulative Model Updates: 146,918
Cumulative Timesteps: 1,182,413,358
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.69320
Policy Entropy: 4.33152
Value Function Loss: 0.00268
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03192
Policy Update Magnitude: 1.01383
Value Function Update Magnitude: 0.80799
Collected Steps per Second: 12,981.71375
Overall Steps per Second: 7,168.83711
Timestep Collection Time: 3.85157
Timestep Consumption Time: 3.12306
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.97463
Cumulative Model Updates: 146,927
Cumulative Timesteps: 1,182,463,358
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1182463358...
Checkpoint 1182463358 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03282
Policy Entropy: 4.33166
Value Function Loss: 0.00263
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 1.00205
Value Function Update Magnitude: 0.79140
Collected Steps per Second: 12,883.02182
Overall Steps per Second: 7,059.53253
Timestep Collection Time: 3.88278
Timestep Consumption Time: 3.20295
PPO Batch Consumption Time: 0.22993
Total Iteration Time: 7.08574
Cumulative Model Updates: 146,936
Cumulative Timesteps: 1,182,513,380
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90538
Policy Entropy: 4.33071
Value Function Loss: 0.00272
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 1.01966
Value Function Update Magnitude: 0.79238
Collected Steps per Second: 13,089.57380
Overall Steps per Second: 7,314.24316
Timestep Collection Time: 3.82151
Timestep Consumption Time: 3.01747
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.83899
Cumulative Model Updates: 146,945
Cumulative Timesteps: 1,182,563,402
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1182563402...
Checkpoint 1182563402 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.39411
Policy Entropy: 4.33295
Value Function Loss: 0.00263
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 1.01467
Value Function Update Magnitude: 0.78813
Collected Steps per Second: 12,913.18521
Overall Steps per Second: 7,130.41563
Timestep Collection Time: 3.87418
Timestep Consumption Time: 3.14196
PPO Batch Consumption Time: 0.23279
Total Iteration Time: 7.01614
Cumulative Model Updates: 146,954
Cumulative Timesteps: 1,182,613,430
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.39128
Policy Entropy: 4.33257
Value Function Loss: 0.00263
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03242
Policy Update Magnitude: 1.01704
Value Function Update Magnitude: 0.76867
Collected Steps per Second: 12,885.51063
Overall Steps per Second: 7,145.24181
Timestep Collection Time: 3.88266
Timestep Consumption Time: 3.11921
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 7.00186
Cumulative Model Updates: 146,963
Cumulative Timesteps: 1,182,663,460
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1182663460...
Checkpoint 1182663460 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.96680
Policy Entropy: 4.33034
Value Function Loss: 0.00278
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03260
Policy Update Magnitude: 1.03642
Value Function Update Magnitude: 0.75517
Collected Steps per Second: 12,837.49089
Overall Steps per Second: 7,236.92190
Timestep Collection Time: 3.89733
Timestep Consumption Time: 3.01610
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.91344
Cumulative Model Updates: 146,972
Cumulative Timesteps: 1,182,713,492
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44534
Policy Entropy: 4.32701
Value Function Loss: 0.00279
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03384
Policy Update Magnitude: 1.03522
Value Function Update Magnitude: 0.73976
Collected Steps per Second: 12,977.46476
Overall Steps per Second: 7,171.96379
Timestep Collection Time: 3.85684
Timestep Consumption Time: 3.12200
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.97884
Cumulative Model Updates: 146,981
Cumulative Timesteps: 1,182,763,544
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1182763544...
Checkpoint 1182763544 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79790
Policy Entropy: 4.32761
Value Function Loss: 0.00271
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03508
Policy Update Magnitude: 1.00634
Value Function Update Magnitude: 0.73135
Collected Steps per Second: 11,966.41282
Overall Steps per Second: 6,868.52258
Timestep Collection Time: 4.18120
Timestep Consumption Time: 3.10333
PPO Batch Consumption Time: 0.22990
Total Iteration Time: 7.28454
Cumulative Model Updates: 146,990
Cumulative Timesteps: 1,182,813,578
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.14805
Policy Entropy: 4.32668
Value Function Loss: 0.00260
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.99509
Value Function Update Magnitude: 0.73999
Collected Steps per Second: 12,868.12764
Overall Steps per Second: 7,246.42603
Timestep Collection Time: 3.88852
Timestep Consumption Time: 3.01667
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.90520
Cumulative Model Updates: 146,999
Cumulative Timesteps: 1,182,863,616
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1182863616...
Checkpoint 1182863616 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65312
Policy Entropy: 4.32634
Value Function Loss: 0.00258
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03301
Policy Update Magnitude: 0.99035
Value Function Update Magnitude: 0.73174
Collected Steps per Second: 12,810.39575
Overall Steps per Second: 7,081.29758
Timestep Collection Time: 3.90480
Timestep Consumption Time: 3.15916
PPO Batch Consumption Time: 0.22975
Total Iteration Time: 7.06396
Cumulative Model Updates: 147,008
Cumulative Timesteps: 1,182,913,638
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69395
Policy Entropy: 4.32913
Value Function Loss: 0.00255
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 0.99552
Value Function Update Magnitude: 0.72455
Collected Steps per Second: 12,958.90287
Overall Steps per Second: 7,140.82319
Timestep Collection Time: 3.86098
Timestep Consumption Time: 3.14578
PPO Batch Consumption Time: 0.23020
Total Iteration Time: 7.00676
Cumulative Model Updates: 147,017
Cumulative Timesteps: 1,182,963,672
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1182963672...
Checkpoint 1182963672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02512
Policy Entropy: 4.33394
Value Function Loss: 0.00250
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 0.98047
Value Function Update Magnitude: 0.69913
Collected Steps per Second: 12,898.72390
Overall Steps per Second: 7,235.52590
Timestep Collection Time: 3.87821
Timestep Consumption Time: 3.03545
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 6.91366
Cumulative Model Updates: 147,026
Cumulative Timesteps: 1,183,013,696
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.90066
Policy Entropy: 4.33671
Value Function Loss: 0.00257
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 0.98965
Value Function Update Magnitude: 0.71290
Collected Steps per Second: 13,121.15269
Overall Steps per Second: 7,229.62200
Timestep Collection Time: 3.81293
Timestep Consumption Time: 3.10721
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.92014
Cumulative Model Updates: 147,035
Cumulative Timesteps: 1,183,063,726
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1183063726...
Checkpoint 1183063726 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.92426
Policy Entropy: 4.33093
Value Function Loss: 0.00267
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03390
Policy Update Magnitude: 1.00530
Value Function Update Magnitude: 0.75011
Collected Steps per Second: 12,958.54019
Overall Steps per Second: 7,201.41599
Timestep Collection Time: 3.85923
Timestep Consumption Time: 3.08524
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.94447
Cumulative Model Updates: 147,044
Cumulative Timesteps: 1,183,113,736
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.33810
Policy Entropy: 4.33232
Value Function Loss: 0.00257
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03437
Policy Update Magnitude: 1.00282
Value Function Update Magnitude: 0.75419
Collected Steps per Second: 12,885.79609
Overall Steps per Second: 7,238.89066
Timestep Collection Time: 3.88117
Timestep Consumption Time: 3.02762
PPO Batch Consumption Time: 0.23085
Total Iteration Time: 6.90879
Cumulative Model Updates: 147,053
Cumulative Timesteps: 1,183,163,748
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1183163748...
Checkpoint 1183163748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61377
Policy Entropy: 4.33018
Value Function Loss: 0.00259
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03288
Policy Update Magnitude: 1.00225
Value Function Update Magnitude: 0.74170
Collected Steps per Second: 12,956.26188
Overall Steps per Second: 7,180.93420
Timestep Collection Time: 3.85960
Timestep Consumption Time: 3.10412
PPO Batch Consumption Time: 0.22949
Total Iteration Time: 6.96372
Cumulative Model Updates: 147,062
Cumulative Timesteps: 1,183,213,754
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28686
Policy Entropy: 4.33043
Value Function Loss: 0.00255
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03289
Policy Update Magnitude: 1.00252
Value Function Update Magnitude: 0.73945
Collected Steps per Second: 12,692.54935
Overall Steps per Second: 7,129.31863
Timestep Collection Time: 3.94011
Timestep Consumption Time: 3.07459
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 7.01470
Cumulative Model Updates: 147,071
Cumulative Timesteps: 1,183,263,764
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1183263764...
Checkpoint 1183263764 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.72140
Policy Entropy: 4.32641
Value Function Loss: 0.00271
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03469
Policy Update Magnitude: 0.99594
Value Function Update Magnitude: 0.74374
Collected Steps per Second: 12,862.86228
Overall Steps per Second: 7,235.94623
Timestep Collection Time: 3.88840
Timestep Consumption Time: 3.02375
PPO Batch Consumption Time: 0.23054
Total Iteration Time: 6.91216
Cumulative Model Updates: 147,080
Cumulative Timesteps: 1,183,313,780
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25403
Policy Entropy: 4.32761
Value Function Loss: 0.00274
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 1.00280
Value Function Update Magnitude: 0.75484
Collected Steps per Second: 12,857.59677
Overall Steps per Second: 7,128.05953
Timestep Collection Time: 3.89093
Timestep Consumption Time: 3.12753
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 7.01846
Cumulative Model Updates: 147,089
Cumulative Timesteps: 1,183,363,808
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1183363808...
Checkpoint 1183363808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.67456
Policy Entropy: 4.33018
Value Function Loss: 0.00268
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03160
Policy Update Magnitude: 0.98968
Value Function Update Magnitude: 0.75040
Collected Steps per Second: 12,900.68303
Overall Steps per Second: 7,200.99599
Timestep Collection Time: 3.87638
Timestep Consumption Time: 3.06821
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.94459
Cumulative Model Updates: 147,098
Cumulative Timesteps: 1,183,413,816
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.49685
Policy Entropy: 4.32801
Value Function Loss: 0.00272
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03267
Policy Update Magnitude: 1.00375
Value Function Update Magnitude: 0.77202
Collected Steps per Second: 12,770.36014
Overall Steps per Second: 7,215.14328
Timestep Collection Time: 3.91579
Timestep Consumption Time: 3.01491
PPO Batch Consumption Time: 0.22954
Total Iteration Time: 6.93070
Cumulative Model Updates: 147,107
Cumulative Timesteps: 1,183,463,822
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1183463822...
Checkpoint 1183463822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57373
Policy Entropy: 4.32755
Value Function Loss: 0.00266
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03425
Policy Update Magnitude: 1.01198
Value Function Update Magnitude: 0.77840
Collected Steps per Second: 13,067.20136
Overall Steps per Second: 7,198.77411
Timestep Collection Time: 3.82683
Timestep Consumption Time: 3.11963
PPO Batch Consumption Time: 0.22947
Total Iteration Time: 6.94646
Cumulative Model Updates: 147,116
Cumulative Timesteps: 1,183,513,828
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47793
Policy Entropy: 4.32978
Value Function Loss: 0.00263
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03545
Policy Update Magnitude: 0.99564
Value Function Update Magnitude: 0.77330
Collected Steps per Second: 13,053.79534
Overall Steps per Second: 7,220.27945
Timestep Collection Time: 3.83214
Timestep Consumption Time: 3.09612
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.92826
Cumulative Model Updates: 147,125
Cumulative Timesteps: 1,183,563,852
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1183563852...
Checkpoint 1183563852 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54587
Policy Entropy: 4.32963
Value Function Loss: 0.00262
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03226
Policy Update Magnitude: 0.98295
Value Function Update Magnitude: 0.77138
Collected Steps per Second: 12,912.90973
Overall Steps per Second: 7,274.62535
Timestep Collection Time: 3.87380
Timestep Consumption Time: 3.00243
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.87623
Cumulative Model Updates: 147,134
Cumulative Timesteps: 1,183,613,874
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32988
Policy Entropy: 4.33332
Value Function Loss: 0.00255
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03174
Policy Update Magnitude: 0.97496
Value Function Update Magnitude: 0.75209
Collected Steps per Second: 12,815.06498
Overall Steps per Second: 7,065.03357
Timestep Collection Time: 3.90369
Timestep Consumption Time: 3.17710
PPO Batch Consumption Time: 0.23050
Total Iteration Time: 7.08079
Cumulative Model Updates: 147,143
Cumulative Timesteps: 1,183,663,900
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1183663900...
Checkpoint 1183663900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77328
Policy Entropy: 4.32659
Value Function Loss: 0.00277
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03212
Policy Update Magnitude: 0.98852
Value Function Update Magnitude: 0.76198
Collected Steps per Second: 12,971.81207
Overall Steps per Second: 7,191.06671
Timestep Collection Time: 3.85682
Timestep Consumption Time: 3.10042
PPO Batch Consumption Time: 0.22920
Total Iteration Time: 6.95724
Cumulative Model Updates: 147,152
Cumulative Timesteps: 1,183,713,930
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.68127
Policy Entropy: 4.32505
Value Function Loss: 0.00268
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03444
Policy Update Magnitude: 0.98499
Value Function Update Magnitude: 0.75948
Collected Steps per Second: 13,153.77625
Overall Steps per Second: 7,250.18908
Timestep Collection Time: 3.80377
Timestep Consumption Time: 3.09729
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.90106
Cumulative Model Updates: 147,161
Cumulative Timesteps: 1,183,763,964
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1183763964...
Checkpoint 1183763964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.66864
Policy Entropy: 4.31979
Value Function Loss: 0.00264
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 0.97707
Value Function Update Magnitude: 0.74143
Collected Steps per Second: 12,838.84611
Overall Steps per Second: 7,162.50991
Timestep Collection Time: 3.89770
Timestep Consumption Time: 3.08895
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.98666
Cumulative Model Updates: 147,170
Cumulative Timesteps: 1,183,814,006
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.17888
Policy Entropy: 4.32679
Value Function Loss: 0.00260
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03228
Policy Update Magnitude: 0.96976
Value Function Update Magnitude: 0.74978
Collected Steps per Second: 12,812.05569
Overall Steps per Second: 7,173.28681
Timestep Collection Time: 3.90476
Timestep Consumption Time: 3.06945
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.97421
Cumulative Model Updates: 147,179
Cumulative Timesteps: 1,183,864,034
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1183864034...
Checkpoint 1183864034 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.60383
Policy Entropy: 4.32853
Value Function Loss: 0.00253
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03262
Policy Update Magnitude: 0.97124
Value Function Update Magnitude: 0.76459
Collected Steps per Second: 13,236.96582
Overall Steps per Second: 7,245.38984
Timestep Collection Time: 3.77881
Timestep Consumption Time: 3.12489
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.90370
Cumulative Model Updates: 147,188
Cumulative Timesteps: 1,183,914,054
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10548
Policy Entropy: 4.32760
Value Function Loss: 0.00267
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03048
Policy Update Magnitude: 0.98312
Value Function Update Magnitude: 0.76983
Collected Steps per Second: 13,043.70371
Overall Steps per Second: 7,197.13656
Timestep Collection Time: 3.83388
Timestep Consumption Time: 3.11444
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.94832
Cumulative Model Updates: 147,197
Cumulative Timesteps: 1,183,964,062
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1183964062...
Checkpoint 1183964062 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.37339
Policy Entropy: 4.32293
Value Function Loss: 0.00271
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03400
Policy Update Magnitude: 1.00973
Value Function Update Magnitude: 0.75983
Collected Steps per Second: 12,898.15140
Overall Steps per Second: 7,205.98384
Timestep Collection Time: 3.87854
Timestep Consumption Time: 3.06375
PPO Batch Consumption Time: 0.23089
Total Iteration Time: 6.94229
Cumulative Model Updates: 147,206
Cumulative Timesteps: 1,184,014,088
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.47441
Policy Entropy: 4.32143
Value Function Loss: 0.00275
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03570
Policy Update Magnitude: 0.99924
Value Function Update Magnitude: 0.77648
Collected Steps per Second: 13,051.37757
Overall Steps per Second: 7,200.83382
Timestep Collection Time: 3.83132
Timestep Consumption Time: 3.11288
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.94420
Cumulative Model Updates: 147,215
Cumulative Timesteps: 1,184,064,092
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1184064092...
Checkpoint 1184064092 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56707
Policy Entropy: 4.32442
Value Function Loss: 0.00266
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03184
Policy Update Magnitude: 0.98777
Value Function Update Magnitude: 0.77363
Collected Steps per Second: 12,861.28408
Overall Steps per Second: 7,148.53798
Timestep Collection Time: 3.89044
Timestep Consumption Time: 3.10904
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.99947
Cumulative Model Updates: 147,224
Cumulative Timesteps: 1,184,114,128
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.23925
Policy Entropy: 4.32496
Value Function Loss: 0.00258
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 0.98379
Value Function Update Magnitude: 0.77429
Collected Steps per Second: 12,938.41385
Overall Steps per Second: 7,220.99512
Timestep Collection Time: 3.86755
Timestep Consumption Time: 3.06224
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.92979
Cumulative Model Updates: 147,233
Cumulative Timesteps: 1,184,164,168
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1184164168...
Checkpoint 1184164168 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.52187
Policy Entropy: 4.31980
Value Function Loss: 0.00265
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 0.98635
Value Function Update Magnitude: 0.75345
Collected Steps per Second: 12,974.31118
Overall Steps per Second: 7,168.75306
Timestep Collection Time: 3.85608
Timestep Consumption Time: 3.12282
PPO Batch Consumption Time: 0.22944
Total Iteration Time: 6.97890
Cumulative Model Updates: 147,242
Cumulative Timesteps: 1,184,214,198
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.26130
Policy Entropy: 4.32225
Value Function Loss: 0.00264
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03208
Policy Update Magnitude: 0.98986
Value Function Update Magnitude: 0.75603
Collected Steps per Second: 12,966.08134
Overall Steps per Second: 7,226.29414
Timestep Collection Time: 3.85652
Timestep Consumption Time: 3.06321
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.91973
Cumulative Model Updates: 147,251
Cumulative Timesteps: 1,184,264,202
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1184264202...
Checkpoint 1184264202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93425
Policy Entropy: 4.32081
Value Function Loss: 0.00267
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03174
Policy Update Magnitude: 0.98287
Value Function Update Magnitude: 0.79137
Collected Steps per Second: 12,955.22591
Overall Steps per Second: 7,290.07596
Timestep Collection Time: 3.85945
Timestep Consumption Time: 2.99919
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.85864
Cumulative Model Updates: 147,260
Cumulative Timesteps: 1,184,314,202
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.30497
Policy Entropy: 4.32727
Value Function Loss: 0.00261
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03086
Policy Update Magnitude: 0.98142
Value Function Update Magnitude: 0.76384
Collected Steps per Second: 12,996.24478
Overall Steps per Second: 7,031.73975
Timestep Collection Time: 3.85019
Timestep Consumption Time: 3.26583
PPO Batch Consumption Time: 0.24110
Total Iteration Time: 7.11602
Cumulative Model Updates: 147,269
Cumulative Timesteps: 1,184,364,240
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1184364240...
Checkpoint 1184364240 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.12072
Policy Entropy: 4.32611
Value Function Loss: 0.00253
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03184
Policy Update Magnitude: 0.96922
Value Function Update Magnitude: 0.77669
Collected Steps per Second: 12,883.72663
Overall Steps per Second: 7,187.56778
Timestep Collection Time: 3.88397
Timestep Consumption Time: 3.07805
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.96202
Cumulative Model Updates: 147,278
Cumulative Timesteps: 1,184,414,280
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.39403
Policy Entropy: 4.32630
Value Function Loss: 0.00263
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03150
Policy Update Magnitude: 0.97550
Value Function Update Magnitude: 0.82111
Collected Steps per Second: 12,990.48221
Overall Steps per Second: 7,279.91643
Timestep Collection Time: 3.84943
Timestep Consumption Time: 3.01960
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.86903
Cumulative Model Updates: 147,287
Cumulative Timesteps: 1,184,464,286
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1184464286...
Checkpoint 1184464286 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.95428
Policy Entropy: 4.32352
Value Function Loss: 0.00261
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 0.99205
Value Function Update Magnitude: 0.80252
Collected Steps per Second: 12,869.61316
Overall Steps per Second: 7,137.33604
Timestep Collection Time: 3.88636
Timestep Consumption Time: 3.12129
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 7.00766
Cumulative Model Updates: 147,296
Cumulative Timesteps: 1,184,514,302
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01566
Policy Entropy: 4.31867
Value Function Loss: 0.00267
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03584
Policy Update Magnitude: 0.99575
Value Function Update Magnitude: 0.80013
Collected Steps per Second: 13,013.86380
Overall Steps per Second: 7,216.35791
Timestep Collection Time: 3.84206
Timestep Consumption Time: 3.08665
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.92870
Cumulative Model Updates: 147,305
Cumulative Timesteps: 1,184,564,302
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1184564302...
Checkpoint 1184564302 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76478
Policy Entropy: 4.32305
Value Function Loss: 0.00265
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03444
Policy Update Magnitude: 0.99350
Value Function Update Magnitude: 0.77701
Collected Steps per Second: 12,995.16495
Overall Steps per Second: 7,287.01333
Timestep Collection Time: 3.84912
Timestep Consumption Time: 3.01514
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.86427
Cumulative Model Updates: 147,314
Cumulative Timesteps: 1,184,614,322
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.02495
Policy Entropy: 4.31823
Value Function Loss: 0.00282
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03596
Policy Update Magnitude: 1.01012
Value Function Update Magnitude: 0.75576
Collected Steps per Second: 12,919.96906
Overall Steps per Second: 7,172.35713
Timestep Collection Time: 3.87153
Timestep Consumption Time: 3.10247
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.97400
Cumulative Model Updates: 147,323
Cumulative Timesteps: 1,184,664,342
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1184664342...
Checkpoint 1184664342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.67105
Policy Entropy: 4.31905
Value Function Loss: 0.00283
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03418
Policy Update Magnitude: 1.00734
Value Function Update Magnitude: 0.75006
Collected Steps per Second: 12,808.96108
Overall Steps per Second: 7,016.91508
Timestep Collection Time: 3.90617
Timestep Consumption Time: 3.22431
PPO Batch Consumption Time: 0.24114
Total Iteration Time: 7.13048
Cumulative Model Updates: 147,332
Cumulative Timesteps: 1,184,714,376
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.54231
Policy Entropy: 4.32119
Value Function Loss: 0.00285
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03391
Policy Update Magnitude: 1.00259
Value Function Update Magnitude: 0.75408
Collected Steps per Second: 12,945.19112
Overall Steps per Second: 7,291.39592
Timestep Collection Time: 3.86537
Timestep Consumption Time: 2.99724
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.86261
Cumulative Model Updates: 147,341
Cumulative Timesteps: 1,184,764,414
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1184764414...
Checkpoint 1184764414 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00856
Policy Entropy: 4.32325
Value Function Loss: 0.00276
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03294
Policy Update Magnitude: 1.00720
Value Function Update Magnitude: 0.75409
Collected Steps per Second: 12,885.12707
Overall Steps per Second: 7,157.02839
Timestep Collection Time: 3.88122
Timestep Consumption Time: 3.10632
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.98754
Cumulative Model Updates: 147,350
Cumulative Timesteps: 1,184,814,424
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25865
Policy Entropy: 4.32331
Value Function Loss: 0.00279
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 1.00243
Value Function Update Magnitude: 0.76064
Collected Steps per Second: 13,039.44144
Overall Steps per Second: 7,257.01853
Timestep Collection Time: 3.83513
Timestep Consumption Time: 3.05585
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.89098
Cumulative Model Updates: 147,359
Cumulative Timesteps: 1,184,864,432
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1184864432...
Checkpoint 1184864432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53239
Policy Entropy: 4.32060
Value Function Loss: 0.00269
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 1.00383
Value Function Update Magnitude: 0.75474
Collected Steps per Second: 13,004.13752
Overall Steps per Second: 7,295.93966
Timestep Collection Time: 3.84585
Timestep Consumption Time: 3.00892
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.85477
Cumulative Model Updates: 147,368
Cumulative Timesteps: 1,184,914,444
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79787
Policy Entropy: 4.32270
Value Function Loss: 0.00263
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 1.00586
Value Function Update Magnitude: 0.77786
Collected Steps per Second: 12,993.97553
Overall Steps per Second: 7,165.49409
Timestep Collection Time: 3.84917
Timestep Consumption Time: 3.13095
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.98012
Cumulative Model Updates: 147,377
Cumulative Timesteps: 1,184,964,460
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1184964460...
Checkpoint 1184964460 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36905
Policy Entropy: 4.31681
Value Function Loss: 0.00268
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03462
Policy Update Magnitude: 1.00433
Value Function Update Magnitude: 0.79651
Collected Steps per Second: 12,994.07772
Overall Steps per Second: 7,218.73835
Timestep Collection Time: 3.84791
Timestep Consumption Time: 3.07851
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.92642
Cumulative Model Updates: 147,386
Cumulative Timesteps: 1,185,014,460
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.45679
Policy Entropy: 4.31510
Value Function Loss: 0.00277
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03662
Policy Update Magnitude: 1.01249
Value Function Update Magnitude: 0.77673
Collected Steps per Second: 13,172.28153
Overall Steps per Second: 7,186.34594
Timestep Collection Time: 3.79615
Timestep Consumption Time: 3.16204
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.95820
Cumulative Model Updates: 147,395
Cumulative Timesteps: 1,185,064,464
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1185064464...
Checkpoint 1185064464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.99625
Policy Entropy: 4.31435
Value Function Loss: 0.00275
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03836
Policy Update Magnitude: 1.02086
Value Function Update Magnitude: 0.78540
Collected Steps per Second: 12,902.28971
Overall Steps per Second: 7,158.88509
Timestep Collection Time: 3.87745
Timestep Consumption Time: 3.11079
PPO Batch Consumption Time: 0.22958
Total Iteration Time: 6.98824
Cumulative Model Updates: 147,404
Cumulative Timesteps: 1,185,114,492
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.26491
Policy Entropy: 4.31696
Value Function Loss: 0.00262
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03587
Policy Update Magnitude: 1.01041
Value Function Update Magnitude: 0.78918
Collected Steps per Second: 12,869.50479
Overall Steps per Second: 7,173.02252
Timestep Collection Time: 3.88826
Timestep Consumption Time: 3.08788
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.97614
Cumulative Model Updates: 147,413
Cumulative Timesteps: 1,185,164,532
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1185164532...
Checkpoint 1185164532 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.67768
Policy Entropy: 4.31993
Value Function Loss: 0.00260
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 0.99713
Value Function Update Magnitude: 0.78144
Collected Steps per Second: 13,219.29120
Overall Steps per Second: 7,265.31330
Timestep Collection Time: 3.78371
Timestep Consumption Time: 3.10078
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.88449
Cumulative Model Updates: 147,422
Cumulative Timesteps: 1,185,214,550
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.93856
Policy Entropy: 4.31973
Value Function Loss: 0.00275
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03477
Policy Update Magnitude: 1.01914
Value Function Update Magnitude: 0.78272
Collected Steps per Second: 13,089.30089
Overall Steps per Second: 7,199.81490
Timestep Collection Time: 3.82068
Timestep Consumption Time: 3.12533
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.94601
Cumulative Model Updates: 147,431
Cumulative Timesteps: 1,185,264,560
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1185264560...
Checkpoint 1185264560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.14068
Policy Entropy: 4.32161
Value Function Loss: 0.00271
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03558
Policy Update Magnitude: 1.02161
Value Function Update Magnitude: 0.77691
Collected Steps per Second: 12,772.80992
Overall Steps per Second: 7,154.79644
Timestep Collection Time: 3.91832
Timestep Consumption Time: 3.07670
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.99503
Cumulative Model Updates: 147,440
Cumulative Timesteps: 1,185,314,608
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.87309
Policy Entropy: 4.32470
Value Function Loss: 0.00263
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03507
Policy Update Magnitude: 1.00869
Value Function Update Magnitude: 0.77167
Collected Steps per Second: 13,164.30103
Overall Steps per Second: 7,228.75744
Timestep Collection Time: 3.80013
Timestep Consumption Time: 3.12029
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.92041
Cumulative Model Updates: 147,449
Cumulative Timesteps: 1,185,364,634
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1185364634...
Checkpoint 1185364634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.68925
Policy Entropy: 4.33129
Value Function Loss: 0.00251
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03364
Policy Update Magnitude: 0.98096
Value Function Update Magnitude: 0.77032
Collected Steps per Second: 12,950.22732
Overall Steps per Second: 7,119.84576
Timestep Collection Time: 3.86263
Timestep Consumption Time: 3.16308
PPO Batch Consumption Time: 0.23309
Total Iteration Time: 7.02571
Cumulative Model Updates: 147,458
Cumulative Timesteps: 1,185,414,656
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60347
Policy Entropy: 4.33294
Value Function Loss: 0.00263
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03400
Policy Update Magnitude: 0.99919
Value Function Update Magnitude: 0.76053
Collected Steps per Second: 13,033.31655
Overall Steps per Second: 7,208.04261
Timestep Collection Time: 3.83755
Timestep Consumption Time: 3.10137
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.93892
Cumulative Model Updates: 147,467
Cumulative Timesteps: 1,185,464,672
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1185464672...
Checkpoint 1185464672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.04496
Policy Entropy: 4.33271
Value Function Loss: 0.00266
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03326
Policy Update Magnitude: 1.02385
Value Function Update Magnitude: 0.78014
Collected Steps per Second: 12,914.57743
Overall Steps per Second: 7,276.39766
Timestep Collection Time: 3.87314
Timestep Consumption Time: 3.00114
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.87428
Cumulative Model Updates: 147,476
Cumulative Timesteps: 1,185,514,692
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.53333
Policy Entropy: 4.33317
Value Function Loss: 0.00270
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 1.03491
Value Function Update Magnitude: 0.80090
Collected Steps per Second: 12,980.30234
Overall Steps per Second: 7,176.49193
Timestep Collection Time: 3.85199
Timestep Consumption Time: 3.11520
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.96719
Cumulative Model Updates: 147,485
Cumulative Timesteps: 1,185,564,692
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1185564692...
Checkpoint 1185564692 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.05179
Policy Entropy: 4.33118
Value Function Loss: 0.00275
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 1.04429
Value Function Update Magnitude: 0.80569
Collected Steps per Second: 12,788.27284
Overall Steps per Second: 7,166.52213
Timestep Collection Time: 3.91046
Timestep Consumption Time: 3.06754
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.97800
Cumulative Model Updates: 147,494
Cumulative Timesteps: 1,185,614,700
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.85239
Policy Entropy: 4.33031
Value Function Loss: 0.00277
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03582
Policy Update Magnitude: 1.04465
Value Function Update Magnitude: 0.79022
Collected Steps per Second: 12,989.60178
Overall Steps per Second: 7,263.43408
Timestep Collection Time: 3.85277
Timestep Consumption Time: 3.03736
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.89013
Cumulative Model Updates: 147,503
Cumulative Timesteps: 1,185,664,746
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1185664746...
Checkpoint 1185664746 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.16396
Policy Entropy: 4.33117
Value Function Loss: 0.00276
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03532
Policy Update Magnitude: 1.03236
Value Function Update Magnitude: 0.81438
Collected Steps per Second: 12,949.75935
Overall Steps per Second: 7,179.33730
Timestep Collection Time: 3.86247
Timestep Consumption Time: 3.10447
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.96694
Cumulative Model Updates: 147,512
Cumulative Timesteps: 1,185,714,764
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.64876
Policy Entropy: 4.33217
Value Function Loss: 0.00257
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 1.00495
Value Function Update Magnitude: 0.78707
Collected Steps per Second: 12,767.91220
Overall Steps per Second: 7,076.60159
Timestep Collection Time: 3.91779
Timestep Consumption Time: 3.15086
PPO Batch Consumption Time: 0.23101
Total Iteration Time: 7.06865
Cumulative Model Updates: 147,521
Cumulative Timesteps: 1,185,764,786
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1185764786...
Checkpoint 1185764786 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.17848
Policy Entropy: 4.33039
Value Function Loss: 0.00265
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03456
Policy Update Magnitude: 0.99689
Value Function Update Magnitude: 0.77887
Collected Steps per Second: 12,942.84471
Overall Steps per Second: 7,263.49207
Timestep Collection Time: 3.86515
Timestep Consumption Time: 3.02217
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.88732
Cumulative Model Updates: 147,530
Cumulative Timesteps: 1,185,814,812
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.79317
Policy Entropy: 4.33017
Value Function Loss: 0.00260
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 1.00708
Value Function Update Magnitude: 0.77442
Collected Steps per Second: 12,952.53066
Overall Steps per Second: 7,173.29480
Timestep Collection Time: 3.86334
Timestep Consumption Time: 3.11254
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.97587
Cumulative Model Updates: 147,539
Cumulative Timesteps: 1,185,864,852
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1185864852...
Checkpoint 1185864852 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.48402
Policy Entropy: 4.32736
Value Function Loss: 0.00280
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03394
Policy Update Magnitude: 1.01801
Value Function Update Magnitude: 0.79278
Collected Steps per Second: 12,851.31410
Overall Steps per Second: 7,178.27143
Timestep Collection Time: 3.89299
Timestep Consumption Time: 3.07666
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.96964
Cumulative Model Updates: 147,548
Cumulative Timesteps: 1,185,914,882
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03751
Policy Entropy: 4.33054
Value Function Loss: 0.00265
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 1.01838
Value Function Update Magnitude: 0.79102
Collected Steps per Second: 12,888.34771
Overall Steps per Second: 7,275.59049
Timestep Collection Time: 3.88196
Timestep Consumption Time: 2.99474
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.87669
Cumulative Model Updates: 147,557
Cumulative Timesteps: 1,185,964,914
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1185964914...
Checkpoint 1185964914 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25253
Policy Entropy: 4.32416
Value Function Loss: 0.00283
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03475
Policy Update Magnitude: 1.03196
Value Function Update Magnitude: 0.78427
Collected Steps per Second: 13,032.64816
Overall Steps per Second: 7,205.70573
Timestep Collection Time: 3.83974
Timestep Consumption Time: 3.10503
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.94477
Cumulative Model Updates: 147,566
Cumulative Timesteps: 1,186,014,956
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19037
Policy Entropy: 4.32771
Value Function Loss: 0.00259
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03336
Policy Update Magnitude: 1.01685
Value Function Update Magnitude: 0.78137
Collected Steps per Second: 12,857.01553
Overall Steps per Second: 7,181.79063
Timestep Collection Time: 3.89002
Timestep Consumption Time: 3.07399
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.96400
Cumulative Model Updates: 147,575
Cumulative Timesteps: 1,186,064,970
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1186064970...
Checkpoint 1186064970 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.63544
Policy Entropy: 4.32768
Value Function Loss: 0.00257
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 0.99245
Value Function Update Magnitude: 0.75322
Collected Steps per Second: 12,761.66658
Overall Steps per Second: 7,122.16484
Timestep Collection Time: 3.92065
Timestep Consumption Time: 3.10446
PPO Batch Consumption Time: 0.23732
Total Iteration Time: 7.02511
Cumulative Model Updates: 147,584
Cumulative Timesteps: 1,186,115,004
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52894
Policy Entropy: 4.32966
Value Function Loss: 0.00258
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03155
Policy Update Magnitude: 0.99441
Value Function Update Magnitude: 0.76337
Collected Steps per Second: 13,024.96642
Overall Steps per Second: 7,212.53441
Timestep Collection Time: 3.84001
Timestep Consumption Time: 3.09458
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.93459
Cumulative Model Updates: 147,593
Cumulative Timesteps: 1,186,165,020
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1186165020...
Checkpoint 1186165020 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79892
Policy Entropy: 4.33146
Value Function Loss: 0.00257
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03238
Policy Update Magnitude: 0.99495
Value Function Update Magnitude: 0.78300
Collected Steps per Second: 12,834.55612
Overall Steps per Second: 7,189.26010
Timestep Collection Time: 3.89838
Timestep Consumption Time: 3.06117
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.95955
Cumulative Model Updates: 147,602
Cumulative Timesteps: 1,186,215,054
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.68126
Policy Entropy: 4.33529
Value Function Loss: 0.00253
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03338
Policy Update Magnitude: 0.98724
Value Function Update Magnitude: 0.78684
Collected Steps per Second: 12,883.05344
Overall Steps per Second: 7,274.61455
Timestep Collection Time: 3.88107
Timestep Consumption Time: 2.99215
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.87322
Cumulative Model Updates: 147,611
Cumulative Timesteps: 1,186,265,054
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1186265054...
Checkpoint 1186265054 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.15769
Policy Entropy: 4.33889
Value Function Loss: 0.00258
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03112
Policy Update Magnitude: 0.98931
Value Function Update Magnitude: 0.78870
Collected Steps per Second: 12,959.56624
Overall Steps per Second: 7,188.58544
Timestep Collection Time: 3.85862
Timestep Consumption Time: 3.09769
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.95631
Cumulative Model Updates: 147,620
Cumulative Timesteps: 1,186,315,060
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44577
Policy Entropy: 4.33679
Value Function Loss: 0.00263
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 1.01461
Value Function Update Magnitude: 0.79979
Collected Steps per Second: 12,993.97480
Overall Steps per Second: 7,215.36434
Timestep Collection Time: 3.84901
Timestep Consumption Time: 3.08258
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.93160
Cumulative Model Updates: 147,629
Cumulative Timesteps: 1,186,365,074
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1186365074...
Checkpoint 1186365074 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.15553
Policy Entropy: 4.33282
Value Function Loss: 0.00272
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03271
Policy Update Magnitude: 1.01837
Value Function Update Magnitude: 0.78095
Collected Steps per Second: 12,960.53135
Overall Steps per Second: 7,283.03243
Timestep Collection Time: 3.86080
Timestep Consumption Time: 3.00969
PPO Batch Consumption Time: 0.22940
Total Iteration Time: 6.87049
Cumulative Model Updates: 147,638
Cumulative Timesteps: 1,186,415,112
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.04886
Policy Entropy: 4.33272
Value Function Loss: 0.00271
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02992
Policy Update Magnitude: 1.00911
Value Function Update Magnitude: 0.77003
Collected Steps per Second: 12,916.51412
Overall Steps per Second: 7,010.87027
Timestep Collection Time: 3.87117
Timestep Consumption Time: 3.26090
PPO Batch Consumption Time: 0.24143
Total Iteration Time: 7.13207
Cumulative Model Updates: 147,647
Cumulative Timesteps: 1,186,465,114
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1186465114...
Checkpoint 1186465114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.55332
Policy Entropy: 4.33078
Value Function Loss: 0.00271
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03044
Policy Update Magnitude: 1.00343
Value Function Update Magnitude: 0.79943
Collected Steps per Second: 12,889.50105
Overall Steps per Second: 7,189.16501
Timestep Collection Time: 3.87959
Timestep Consumption Time: 3.07615
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.95575
Cumulative Model Updates: 147,656
Cumulative Timesteps: 1,186,515,120
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50508
Policy Entropy: 4.32861
Value Function Loss: 0.00276
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03088
Policy Update Magnitude: 1.01290
Value Function Update Magnitude: 0.81364
Collected Steps per Second: 12,994.49966
Overall Steps per Second: 7,289.02469
Timestep Collection Time: 3.84978
Timestep Consumption Time: 3.01341
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.86320
Cumulative Model Updates: 147,665
Cumulative Timesteps: 1,186,565,146
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1186565146...
Checkpoint 1186565146 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89145
Policy Entropy: 4.32560
Value Function Loss: 0.00277
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 1.02564
Value Function Update Magnitude: 0.80974
Collected Steps per Second: 12,799.14672
Overall Steps per Second: 7,146.94726
Timestep Collection Time: 3.90776
Timestep Consumption Time: 3.09047
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.99823
Cumulative Model Updates: 147,674
Cumulative Timesteps: 1,186,615,162
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04822
Policy Entropy: 4.32561
Value Function Loss: 0.00282
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 1.03782
Value Function Update Magnitude: 0.79932
Collected Steps per Second: 12,938.31605
Overall Steps per Second: 7,211.75503
Timestep Collection Time: 3.86557
Timestep Consumption Time: 3.06949
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.93507
Cumulative Model Updates: 147,683
Cumulative Timesteps: 1,186,665,176
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1186665176...
Checkpoint 1186665176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.51806
Policy Entropy: 4.32827
Value Function Loss: 0.00285
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03236
Policy Update Magnitude: 1.03217
Value Function Update Magnitude: 0.81872
Collected Steps per Second: 12,851.60826
Overall Steps per Second: 7,242.59564
Timestep Collection Time: 3.89087
Timestep Consumption Time: 3.01328
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.90415
Cumulative Model Updates: 147,692
Cumulative Timesteps: 1,186,715,180
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03566
Policy Entropy: 4.32763
Value Function Loss: 0.00278
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03318
Policy Update Magnitude: 1.02214
Value Function Update Magnitude: 0.82495
Collected Steps per Second: 13,081.87772
Overall Steps per Second: 7,205.22817
Timestep Collection Time: 3.82468
Timestep Consumption Time: 3.11944
PPO Batch Consumption Time: 0.22986
Total Iteration Time: 6.94412
Cumulative Model Updates: 147,701
Cumulative Timesteps: 1,186,765,214
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1186765214...
Checkpoint 1186765214 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.10838
Policy Entropy: 4.32823
Value Function Loss: 0.00273
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03305
Policy Update Magnitude: 0.99297
Value Function Update Magnitude: 0.82321
Collected Steps per Second: 12,965.59715
Overall Steps per Second: 7,157.92878
Timestep Collection Time: 3.85944
Timestep Consumption Time: 3.13140
PPO Batch Consumption Time: 0.22983
Total Iteration Time: 6.99085
Cumulative Model Updates: 147,710
Cumulative Timesteps: 1,186,815,254
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.55384
Policy Entropy: 4.33029
Value Function Loss: 0.00261
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03103
Policy Update Magnitude: 0.98540
Value Function Update Magnitude: 0.81363
Collected Steps per Second: 12,879.49259
Overall Steps per Second: 7,227.17498
Timestep Collection Time: 3.88230
Timestep Consumption Time: 3.03631
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.91861
Cumulative Model Updates: 147,719
Cumulative Timesteps: 1,186,865,256
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1186865256...
Checkpoint 1186865256 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.62313
Policy Entropy: 4.33008
Value Function Loss: 0.00265
Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03221
Policy Update Magnitude: 0.98415
Value Function Update Magnitude: 0.78328
Collected Steps per Second: 13,062.20547
Overall Steps per Second: 7,222.30971
Timestep Collection Time: 3.82891
Timestep Consumption Time: 3.09602
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.92493
Cumulative Model Updates: 147,728
Cumulative Timesteps: 1,186,915,270
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.19590
Policy Entropy: 4.33393
Value Function Loss: 0.00257
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02994
Policy Update Magnitude: 0.98186
Value Function Update Magnitude: 0.78965
Collected Steps per Second: 12,970.99933
Overall Steps per Second: 7,218.23171
Timestep Collection Time: 3.85645
Timestep Consumption Time: 3.07350
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.92995
Cumulative Model Updates: 147,737
Cumulative Timesteps: 1,186,965,292
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1186965292...
Checkpoint 1186965292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.49072
Policy Entropy: 4.33243
Value Function Loss: 0.00267
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03017
Policy Update Magnitude: 0.99632
Value Function Update Magnitude: 0.78318
Collected Steps per Second: 13,006.80935
Overall Steps per Second: 7,278.26733
Timestep Collection Time: 3.84414
Timestep Consumption Time: 3.02563
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.86977
Cumulative Model Updates: 147,746
Cumulative Timesteps: 1,187,015,292
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12834
Policy Entropy: 4.33176
Value Function Loss: 0.00260
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03078
Policy Update Magnitude: 1.01280
Value Function Update Magnitude: 0.80254
Collected Steps per Second: 13,130.45163
Overall Steps per Second: 7,221.42814
Timestep Collection Time: 3.81023
Timestep Consumption Time: 3.11777
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.92799
Cumulative Model Updates: 147,755
Cumulative Timesteps: 1,187,065,322
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1187065322...
Checkpoint 1187065322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.69851
Policy Entropy: 4.33248
Value Function Loss: 0.00254
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 1.00798
Value Function Update Magnitude: 0.81201
Collected Steps per Second: 12,727.85582
Overall Steps per Second: 7,143.31878
Timestep Collection Time: 3.92949
Timestep Consumption Time: 3.07202
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 7.00151
Cumulative Model Updates: 147,764
Cumulative Timesteps: 1,187,115,336
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.28959
Policy Entropy: 4.32997
Value Function Loss: 0.00252
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03183
Policy Update Magnitude: 0.99198
Value Function Update Magnitude: 0.79153
Collected Steps per Second: 12,880.89258
Overall Steps per Second: 7,114.11902
Timestep Collection Time: 3.88358
Timestep Consumption Time: 3.14807
PPO Batch Consumption Time: 0.23879
Total Iteration Time: 7.03165
Cumulative Model Updates: 147,773
Cumulative Timesteps: 1,187,165,360
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1187165360...
Checkpoint 1187165360 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.10410
Policy Entropy: 4.32940
Value Function Loss: 0.00252
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 0.99180
Value Function Update Magnitude: 0.79375
Collected Steps per Second: 13,058.69502
Overall Steps per Second: 7,200.39339
Timestep Collection Time: 3.83024
Timestep Consumption Time: 3.11632
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.94656
Cumulative Model Updates: 147,782
Cumulative Timesteps: 1,187,215,378
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.14593
Policy Entropy: 4.32784
Value Function Loss: 0.00263
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03080
Policy Update Magnitude: 1.00005
Value Function Update Magnitude: 0.77223
Collected Steps per Second: 12,835.12589
Overall Steps per Second: 7,190.59638
Timestep Collection Time: 3.89649
Timestep Consumption Time: 3.05870
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.95519
Cumulative Model Updates: 147,791
Cumulative Timesteps: 1,187,265,390
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1187265390...
Checkpoint 1187265390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.83849
Policy Entropy: 4.32709
Value Function Loss: 0.00274
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03239
Policy Update Magnitude: 1.02132
Value Function Update Magnitude: 0.78548
Collected Steps per Second: 12,793.90312
Overall Steps per Second: 7,242.44584
Timestep Collection Time: 3.90999
Timestep Consumption Time: 2.99707
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.90706
Cumulative Model Updates: 147,800
Cumulative Timesteps: 1,187,315,414
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43396
Policy Entropy: 4.32836
Value Function Loss: 0.00275
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03264
Policy Update Magnitude: 1.01938
Value Function Update Magnitude: 0.82773
Collected Steps per Second: 12,942.77346
Overall Steps per Second: 7,168.56532
Timestep Collection Time: 3.86470
Timestep Consumption Time: 3.11298
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.97769
Cumulative Model Updates: 147,809
Cumulative Timesteps: 1,187,365,434
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1187365434...
Checkpoint 1187365434 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95258
Policy Entropy: 4.32369
Value Function Loss: 0.00276
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03247
Policy Update Magnitude: 1.01336
Value Function Update Magnitude: 0.82547
Collected Steps per Second: 13,004.88094
Overall Steps per Second: 7,229.36266
Timestep Collection Time: 3.84502
Timestep Consumption Time: 3.07177
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.91679
Cumulative Model Updates: 147,818
Cumulative Timesteps: 1,187,415,438
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.70232
Policy Entropy: 4.32304
Value Function Loss: 0.00275
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03300
Policy Update Magnitude: 1.02372
Value Function Update Magnitude: 0.84169
Collected Steps per Second: 12,959.94035
Overall Steps per Second: 7,284.91674
Timestep Collection Time: 3.85912
Timestep Consumption Time: 3.00630
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.86542
Cumulative Model Updates: 147,827
Cumulative Timesteps: 1,187,465,452
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1187465452...
Checkpoint 1187465452 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.49857
Policy Entropy: 4.32487
Value Function Loss: 0.00259
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03258
Policy Update Magnitude: 1.01365
Value Function Update Magnitude: 0.81228
Collected Steps per Second: 13,073.62756
Overall Steps per Second: 7,143.81949
Timestep Collection Time: 3.82541
Timestep Consumption Time: 3.17533
PPO Batch Consumption Time: 0.23027
Total Iteration Time: 7.00074
Cumulative Model Updates: 147,836
Cumulative Timesteps: 1,187,515,464
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69712
Policy Entropy: 4.33311
Value Function Loss: 0.00255
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03018
Policy Update Magnitude: 0.98562
Value Function Update Magnitude: 0.78432
Collected Steps per Second: 12,986.56859
Overall Steps per Second: 7,221.32528
Timestep Collection Time: 3.85167
Timestep Consumption Time: 3.07503
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.92671
Cumulative Model Updates: 147,845
Cumulative Timesteps: 1,187,565,484
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1187565484...
Checkpoint 1187565484 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52324
Policy Entropy: 4.33340
Value Function Loss: 0.00258
Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.99759
Value Function Update Magnitude: 0.78173
Collected Steps per Second: 12,852.62175
Overall Steps per Second: 7,268.37200
Timestep Collection Time: 3.89228
Timestep Consumption Time: 2.99042
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.88270
Cumulative Model Updates: 147,854
Cumulative Timesteps: 1,187,615,510
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.53599
Policy Entropy: 4.33217
Value Function Loss: 0.00261
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02960
Policy Update Magnitude: 1.01306
Value Function Update Magnitude: 0.80363
Collected Steps per Second: 12,993.99524
Overall Steps per Second: 7,184.97871
Timestep Collection Time: 3.85039
Timestep Consumption Time: 3.11302
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.96342
Cumulative Model Updates: 147,863
Cumulative Timesteps: 1,187,665,542
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1187665542...
Checkpoint 1187665542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.17536
Policy Entropy: 4.32476
Value Function Loss: 0.00281
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03331
Policy Update Magnitude: 1.03742
Value Function Update Magnitude: 0.85930
Collected Steps per Second: 12,851.96650
Overall Steps per Second: 7,181.26505
Timestep Collection Time: 3.89295
Timestep Consumption Time: 3.07407
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.96702
Cumulative Model Updates: 147,872
Cumulative Timesteps: 1,187,715,574
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.70707
Policy Entropy: 4.32492
Value Function Loss: 0.00274
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03293
Policy Update Magnitude: 1.04075
Value Function Update Magnitude: 0.90136
Collected Steps per Second: 12,773.27313
Overall Steps per Second: 7,231.16711
Timestep Collection Time: 3.91552
Timestep Consumption Time: 3.00093
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.91645
Cumulative Model Updates: 147,881
Cumulative Timesteps: 1,187,765,588
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1187765588...
Checkpoint 1187765588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75789
Policy Entropy: 4.32404
Value Function Loss: 0.00280
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03323
Policy Update Magnitude: 1.03761
Value Function Update Magnitude: 0.87451
Collected Steps per Second: 12,892.83252
Overall Steps per Second: 7,158.68677
Timestep Collection Time: 3.88030
Timestep Consumption Time: 3.10814
PPO Batch Consumption Time: 0.22962
Total Iteration Time: 6.98843
Cumulative Model Updates: 147,890
Cumulative Timesteps: 1,187,815,616
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86764
Policy Entropy: 4.32508
Value Function Loss: 0.00272
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 1.03676
Value Function Update Magnitude: 0.87363
Collected Steps per Second: 12,969.80446
Overall Steps per Second: 7,151.15292
Timestep Collection Time: 3.85742
Timestep Consumption Time: 3.13865
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 6.99607
Cumulative Model Updates: 147,899
Cumulative Timesteps: 1,187,865,646
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1187865646...
Checkpoint 1187865646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.72587
Policy Entropy: 4.32728
Value Function Loss: 0.00275
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03195
Policy Update Magnitude: 1.04317
Value Function Update Magnitude: 0.84319
Collected Steps per Second: 13,056.66990
Overall Steps per Second: 7,285.91729
Timestep Collection Time: 3.83069
Timestep Consumption Time: 3.03406
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.86475
Cumulative Model Updates: 147,908
Cumulative Timesteps: 1,187,915,662
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.70933
Policy Entropy: 4.33094
Value Function Loss: 0.00269
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03294
Policy Update Magnitude: 1.03191
Value Function Update Magnitude: 0.81661
Collected Steps per Second: 12,923.66588
Overall Steps per Second: 7,163.98835
Timestep Collection Time: 3.86887
Timestep Consumption Time: 3.11048
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.97935
Cumulative Model Updates: 147,917
Cumulative Timesteps: 1,187,965,662
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1187965662...
Checkpoint 1187965662 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.63053
Policy Entropy: 4.33061
Value Function Loss: 0.00268
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03174
Policy Update Magnitude: 1.02589
Value Function Update Magnitude: 0.80921
Collected Steps per Second: 12,788.80638
Overall Steps per Second: 7,147.68946
Timestep Collection Time: 3.91217
Timestep Consumption Time: 3.08757
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.99974
Cumulative Model Updates: 147,926
Cumulative Timesteps: 1,188,015,694
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68161
Policy Entropy: 4.32783
Value Function Loss: 0.00260
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03102
Policy Update Magnitude: 1.02403
Value Function Update Magnitude: 0.80206
Collected Steps per Second: 12,866.96935
Overall Steps per Second: 7,239.49806
Timestep Collection Time: 3.88825
Timestep Consumption Time: 3.02245
PPO Batch Consumption Time: 0.23032
Total Iteration Time: 6.91070
Cumulative Model Updates: 147,935
Cumulative Timesteps: 1,188,065,724
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1188065724...
Checkpoint 1188065724 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.10339
Policy Entropy: 4.32283
Value Function Loss: 0.00266
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03217
Policy Update Magnitude: 1.02258
Value Function Update Magnitude: 0.82812
Collected Steps per Second: 12,940.60285
Overall Steps per Second: 7,104.90372
Timestep Collection Time: 3.86520
Timestep Consumption Time: 3.17473
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 7.03993
Cumulative Model Updates: 147,944
Cumulative Timesteps: 1,188,115,742
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.57445
Policy Entropy: 4.32330
Value Function Loss: 0.00267
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 1.03032
Value Function Update Magnitude: 0.84896
Collected Steps per Second: 12,966.82266
Overall Steps per Second: 7,206.67263
Timestep Collection Time: 3.85738
Timestep Consumption Time: 3.08313
PPO Batch Consumption Time: 0.22982
Total Iteration Time: 6.94051
Cumulative Model Updates: 147,953
Cumulative Timesteps: 1,188,165,760
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1188165760...
Checkpoint 1188165760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74581
Policy Entropy: 4.32581
Value Function Loss: 0.00267
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03445
Policy Update Magnitude: 1.03005
Value Function Update Magnitude: 0.86838
Collected Steps per Second: 12,817.34409
Overall Steps per Second: 7,185.04750
Timestep Collection Time: 3.90393
Timestep Consumption Time: 3.06026
PPO Batch Consumption Time: 0.23031
Total Iteration Time: 6.96419
Cumulative Model Updates: 147,962
Cumulative Timesteps: 1,188,215,798
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42618
Policy Entropy: 4.32972
Value Function Loss: 0.00269
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03477
Policy Update Magnitude: 1.02991
Value Function Update Magnitude: 0.86502
Collected Steps per Second: 13,066.07099
Overall Steps per Second: 7,193.07528
Timestep Collection Time: 3.82701
Timestep Consumption Time: 3.12467
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.95169
Cumulative Model Updates: 147,971
Cumulative Timesteps: 1,188,265,802
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1188265802...
Checkpoint 1188265802 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.26636
Policy Entropy: 4.33141
Value Function Loss: 0.00264
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03395
Policy Update Magnitude: 1.02753
Value Function Update Magnitude: 0.82214
Collected Steps per Second: 12,856.22434
Overall Steps per Second: 7,192.75340
Timestep Collection Time: 3.89166
Timestep Consumption Time: 3.06423
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.95589
Cumulative Model Updates: 147,980
Cumulative Timesteps: 1,188,315,834
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.37380
Policy Entropy: 4.33315
Value Function Loss: 0.00266
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03306
Policy Update Magnitude: 1.02598
Value Function Update Magnitude: 0.83173
Collected Steps per Second: 12,721.18144
Overall Steps per Second: 7,204.51560
Timestep Collection Time: 3.93265
Timestep Consumption Time: 3.01132
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.94398
Cumulative Model Updates: 147,989
Cumulative Timesteps: 1,188,365,862
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1188365862...
Checkpoint 1188365862 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79845
Policy Entropy: 4.33355
Value Function Loss: 0.00264
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 1.02713
Value Function Update Magnitude: 0.84924
Collected Steps per Second: 13,072.30511
Overall Steps per Second: 7,196.31683
Timestep Collection Time: 3.82565
Timestep Consumption Time: 3.12374
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.94939
Cumulative Model Updates: 147,998
Cumulative Timesteps: 1,188,415,872
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.89865
Policy Entropy: 4.33311
Value Function Loss: 0.00261
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03092
Policy Update Magnitude: 1.02129
Value Function Update Magnitude: 0.84081
Collected Steps per Second: 12,954.02520
Overall Steps per Second: 7,194.64092
Timestep Collection Time: 3.86042
Timestep Consumption Time: 3.09031
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.95073
Cumulative Model Updates: 148,007
Cumulative Timesteps: 1,188,465,880
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1188465880...
Checkpoint 1188465880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02960
Policy Entropy: 4.33789
Value Function Loss: 0.00278
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03126
Policy Update Magnitude: 1.02506
Value Function Update Magnitude: 0.82037
Collected Steps per Second: 12,933.15693
Overall Steps per Second: 7,292.69327
Timestep Collection Time: 3.86711
Timestep Consumption Time: 2.99098
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.85810
Cumulative Model Updates: 148,016
Cumulative Timesteps: 1,188,515,894
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.40478
Policy Entropy: 4.33513
Value Function Loss: 0.00288
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03345
Policy Update Magnitude: 1.04626
Value Function Update Magnitude: 0.82818
Collected Steps per Second: 12,784.23826
Overall Steps per Second: 6,968.03778
Timestep Collection Time: 3.91388
Timestep Consumption Time: 3.26691
PPO Batch Consumption Time: 0.24196
Total Iteration Time: 7.18079
Cumulative Model Updates: 148,025
Cumulative Timesteps: 1,188,565,930
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1188565930...
Checkpoint 1188565930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.59822
Policy Entropy: 4.33509
Value Function Loss: 0.00293
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03630
Policy Update Magnitude: 1.05651
Value Function Update Magnitude: 0.84544
Collected Steps per Second: 12,983.51914
Overall Steps per Second: 7,217.02452
Timestep Collection Time: 3.85427
Timestep Consumption Time: 3.07961
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.93388
Cumulative Model Updates: 148,034
Cumulative Timesteps: 1,188,615,972
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.89841
Policy Entropy: 4.33284
Value Function Loss: 0.00281
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03656
Policy Update Magnitude: 1.04652
Value Function Update Magnitude: 0.84928
Collected Steps per Second: 12,795.16387
Overall Steps per Second: 7,245.99080
Timestep Collection Time: 3.90898
Timestep Consumption Time: 2.99360
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.90258
Cumulative Model Updates: 148,043
Cumulative Timesteps: 1,188,665,988
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1188665988...
Checkpoint 1188665988 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95498
Policy Entropy: 4.33497
Value Function Loss: 0.00271
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03425
Policy Update Magnitude: 1.04105
Value Function Update Magnitude: 0.83366
Collected Steps per Second: 12,837.08276
Overall Steps per Second: 7,126.65429
Timestep Collection Time: 3.89839
Timestep Consumption Time: 3.12370
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 7.02209
Cumulative Model Updates: 148,052
Cumulative Timesteps: 1,188,716,032
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.76204
Policy Entropy: 4.33393
Value Function Loss: 0.00272
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 1.03218
Value Function Update Magnitude: 0.80002
Collected Steps per Second: 12,913.98099
Overall Steps per Second: 7,187.55454
Timestep Collection Time: 3.87270
Timestep Consumption Time: 3.08544
PPO Batch Consumption Time: 0.23072
Total Iteration Time: 6.95814
Cumulative Model Updates: 148,061
Cumulative Timesteps: 1,188,766,044
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1188766044...
Checkpoint 1188766044 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.12340
Policy Entropy: 4.33043
Value Function Loss: 0.00272
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03414
Policy Update Magnitude: 1.04230
Value Function Update Magnitude: 0.82409
Collected Steps per Second: 12,841.94438
Overall Steps per Second: 7,235.25758
Timestep Collection Time: 3.89349
Timestep Consumption Time: 3.01711
PPO Batch Consumption Time: 0.22960
Total Iteration Time: 6.91060
Cumulative Model Updates: 148,070
Cumulative Timesteps: 1,188,816,044
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.74068
Policy Entropy: 4.32857
Value Function Loss: 0.00268
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 1.03714
Value Function Update Magnitude: 0.87504
Collected Steps per Second: 12,805.74445
Overall Steps per Second: 7,101.75878
Timestep Collection Time: 3.90465
Timestep Consumption Time: 3.13614
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 7.04079
Cumulative Model Updates: 148,079
Cumulative Timesteps: 1,188,866,046
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1188866046...
Checkpoint 1188866046 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.71224
Policy Entropy: 4.32925
Value Function Loss: 0.00272
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03371
Policy Update Magnitude: 1.04209
Value Function Update Magnitude: 0.85687
Collected Steps per Second: 12,893.15821
Overall Steps per Second: 6,982.37048
Timestep Collection Time: 3.88035
Timestep Consumption Time: 3.28484
PPO Batch Consumption Time: 0.24260
Total Iteration Time: 7.16519
Cumulative Model Updates: 148,088
Cumulative Timesteps: 1,188,916,076
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31067
Policy Entropy: 4.33208
Value Function Loss: 0.00277
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 1.05388
Value Function Update Magnitude: 0.86007
Collected Steps per Second: 12,720.39701
Overall Steps per Second: 7,196.60111
Timestep Collection Time: 3.93337
Timestep Consumption Time: 3.01908
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.95245
Cumulative Model Updates: 148,097
Cumulative Timesteps: 1,188,966,110
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1188966110...
Checkpoint 1188966110 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.89281
Policy Entropy: 4.33120
Value Function Loss: 0.00281
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03397
Policy Update Magnitude: 1.06770
Value Function Update Magnitude: 0.84935
Collected Steps per Second: 12,995.40602
Overall Steps per Second: 7,199.95511
Timestep Collection Time: 3.84936
Timestep Consumption Time: 3.09846
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.94782
Cumulative Model Updates: 148,106
Cumulative Timesteps: 1,189,016,134
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.81658
Policy Entropy: 4.32955
Value Function Loss: 0.00281
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03479
Policy Update Magnitude: 1.07252
Value Function Update Magnitude: 0.85364
Collected Steps per Second: 13,019.74327
Overall Steps per Second: 7,210.66999
Timestep Collection Time: 3.84032
Timestep Consumption Time: 3.09385
PPO Batch Consumption Time: 0.22941
Total Iteration Time: 6.93417
Cumulative Model Updates: 148,115
Cumulative Timesteps: 1,189,066,134
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1189066134...
Checkpoint 1189066134 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.07499
Policy Entropy: 4.33228
Value Function Loss: 0.00277
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03644
Policy Update Magnitude: 1.06238
Value Function Update Magnitude: 0.87616
Collected Steps per Second: 12,678.23671
Overall Steps per Second: 7,205.46572
Timestep Collection Time: 3.94629
Timestep Consumption Time: 2.99733
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.94362
Cumulative Model Updates: 148,124
Cumulative Timesteps: 1,189,116,166
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.55443
Policy Entropy: 4.32905
Value Function Loss: 0.00281
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03588
Policy Update Magnitude: 1.06967
Value Function Update Magnitude: 0.87272
Collected Steps per Second: 12,990.12460
Overall Steps per Second: 7,147.76995
Timestep Collection Time: 3.84985
Timestep Consumption Time: 3.14674
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.99659
Cumulative Model Updates: 148,133
Cumulative Timesteps: 1,189,166,176
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1189166176...
Checkpoint 1189166176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.29990
Policy Entropy: 4.32916
Value Function Loss: 0.00285
Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03750
Policy Update Magnitude: 1.07461
Value Function Update Magnitude: 0.86087
Collected Steps per Second: 12,782.82877
Overall Steps per Second: 7,145.98671
Timestep Collection Time: 3.91337
Timestep Consumption Time: 3.08692
PPO Batch Consumption Time: 0.22944
Total Iteration Time: 7.00029
Cumulative Model Updates: 148,142
Cumulative Timesteps: 1,189,216,200
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.13578
Policy Entropy: 4.32556
Value Function Loss: 0.00280
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03747
Policy Update Magnitude: 1.05999
Value Function Update Magnitude: 0.85430
Collected Steps per Second: 12,869.67911
Overall Steps per Second: 7,202.52032
Timestep Collection Time: 3.88697
Timestep Consumption Time: 3.05838
PPO Batch Consumption Time: 0.22984
Total Iteration Time: 6.94535
Cumulative Model Updates: 148,151
Cumulative Timesteps: 1,189,266,224
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1189266224...
Checkpoint 1189266224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.88858
Policy Entropy: 4.32620
Value Function Loss: 0.00287
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03553
Policy Update Magnitude: 1.06044
Value Function Update Magnitude: 0.84861
Collected Steps per Second: 12,844.22730
Overall Steps per Second: 7,092.07868
Timestep Collection Time: 3.89311
Timestep Consumption Time: 3.15757
PPO Batch Consumption Time: 0.22995
Total Iteration Time: 7.05068
Cumulative Model Updates: 148,160
Cumulative Timesteps: 1,189,316,228
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.69610
Policy Entropy: 4.32838
Value Function Loss: 0.00294
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 1.08313
Value Function Update Magnitude: 0.85899
Collected Steps per Second: 12,939.26802
Overall Steps per Second: 7,196.82822
Timestep Collection Time: 3.86529
Timestep Consumption Time: 3.08416
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.94945
Cumulative Model Updates: 148,169
Cumulative Timesteps: 1,189,366,242
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1189366242...
Checkpoint 1189366242 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61007
Policy Entropy: 4.33337
Value Function Loss: 0.00285
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03491
Policy Update Magnitude: 1.05781
Value Function Update Magnitude: 0.85965
Collected Steps per Second: 12,825.36328
Overall Steps per Second: 7,243.99595
Timestep Collection Time: 3.90024
Timestep Consumption Time: 3.00506
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.90530
Cumulative Model Updates: 148,178
Cumulative Timesteps: 1,189,416,264
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.87980
Policy Entropy: 4.33693
Value Function Loss: 0.00274
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03330
Policy Update Magnitude: 1.04001
Value Function Update Magnitude: 0.85420
Collected Steps per Second: 12,942.23707
Overall Steps per Second: 7,164.70426
Timestep Collection Time: 3.86595
Timestep Consumption Time: 3.11745
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.98340
Cumulative Model Updates: 148,187
Cumulative Timesteps: 1,189,466,298
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1189466298...
Checkpoint 1189466298 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.40356
Policy Entropy: 4.33799
Value Function Loss: 0.00273
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03235
Policy Update Magnitude: 1.06020
Value Function Update Magnitude: 0.89026
Collected Steps per Second: 12,934.33816
Overall Steps per Second: 7,213.68481
Timestep Collection Time: 3.86599
Timestep Consumption Time: 3.06584
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.93182
Cumulative Model Updates: 148,196
Cumulative Timesteps: 1,189,516,302
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.21520
Policy Entropy: 4.32796
Value Function Loss: 0.00285
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03704
Policy Update Magnitude: 1.07829
Value Function Update Magnitude: 0.89488
Collected Steps per Second: 12,842.82327
Overall Steps per Second: 7,267.34705
Timestep Collection Time: 3.89509
Timestep Consumption Time: 2.98830
PPO Batch Consumption Time: 0.22792
Total Iteration Time: 6.88339
Cumulative Model Updates: 148,205
Cumulative Timesteps: 1,189,566,326
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1189566326...
Checkpoint 1189566326 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68818
Policy Entropy: 4.33097
Value Function Loss: 0.00280
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03565
Policy Update Magnitude: 1.08743
Value Function Update Magnitude: 0.89919
Collected Steps per Second: 12,901.60602
Overall Steps per Second: 7,077.10118
Timestep Collection Time: 3.87626
Timestep Consumption Time: 3.19019
PPO Batch Consumption Time: 0.23470
Total Iteration Time: 7.06645
Cumulative Model Updates: 148,214
Cumulative Timesteps: 1,189,616,336
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.78650
Policy Entropy: 4.32803
Value Function Loss: 0.00277
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03424
Policy Update Magnitude: 1.06218
Value Function Update Magnitude: 0.90073
Collected Steps per Second: 12,931.20937
Overall Steps per Second: 7,199.48672
Timestep Collection Time: 3.86955
Timestep Consumption Time: 3.08066
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.95022
Cumulative Model Updates: 148,223
Cumulative Timesteps: 1,189,666,374
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1189666374...
Checkpoint 1189666374 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.73109
Policy Entropy: 4.32751
Value Function Loss: 0.00283
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03225
Policy Update Magnitude: 1.06782
Value Function Update Magnitude: 0.88805
Collected Steps per Second: 12,853.07982
Overall Steps per Second: 7,189.38437
Timestep Collection Time: 3.89276
Timestep Consumption Time: 3.06666
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.95943
Cumulative Model Updates: 148,232
Cumulative Timesteps: 1,189,716,408
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36560
Policy Entropy: 4.32683
Value Function Loss: 0.00277
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03701
Policy Update Magnitude: 1.09436
Value Function Update Magnitude: 0.86639
Collected Steps per Second: 12,976.77177
Overall Steps per Second: 7,178.34889
Timestep Collection Time: 3.85443
Timestep Consumption Time: 3.11347
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.96790
Cumulative Model Updates: 148,241
Cumulative Timesteps: 1,189,766,426
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1189766426...
Checkpoint 1189766426 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.17832
Policy Entropy: 4.32802
Value Function Loss: 0.00273
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03704
Policy Update Magnitude: 1.07154
Value Function Update Magnitude: 0.82803
Collected Steps per Second: 13,022.19563
Overall Steps per Second: 7,216.11273
Timestep Collection Time: 3.84328
Timestep Consumption Time: 3.09231
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.93559
Cumulative Model Updates: 148,250
Cumulative Timesteps: 1,189,816,474
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.58383
Policy Entropy: 4.32903
Value Function Loss: 0.00280
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03267
Policy Update Magnitude: 1.06940
Value Function Update Magnitude: 0.80885
Collected Steps per Second: 12,925.69598
Overall Steps per Second: 7,241.48796
Timestep Collection Time: 3.86950
Timestep Consumption Time: 3.03737
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 6.90687
Cumulative Model Updates: 148,259
Cumulative Timesteps: 1,189,866,490
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1189866490...
Checkpoint 1189866490 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.39685
Policy Entropy: 4.32364
Value Function Loss: 0.00288
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03609
Policy Update Magnitude: 1.07388
Value Function Update Magnitude: 0.86302
Collected Steps per Second: 12,910.97445
Overall Steps per Second: 7,141.07421
Timestep Collection Time: 3.87531
Timestep Consumption Time: 3.13120
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 7.00651
Cumulative Model Updates: 148,268
Cumulative Timesteps: 1,189,916,524
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36803
Policy Entropy: 4.32035
Value Function Loss: 0.00291
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03652
Policy Update Magnitude: 1.07694
Value Function Update Magnitude: 0.86862
Collected Steps per Second: 12,759.67071
Overall Steps per Second: 7,097.61813
Timestep Collection Time: 3.92173
Timestep Consumption Time: 3.12852
PPO Batch Consumption Time: 0.23035
Total Iteration Time: 7.05025
Cumulative Model Updates: 148,277
Cumulative Timesteps: 1,189,966,564
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1189966564...
Checkpoint 1189966564 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.43682
Policy Entropy: 4.32365
Value Function Loss: 0.00276
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03595
Policy Update Magnitude: 1.06335
Value Function Update Magnitude: 0.84401
Collected Steps per Second: 12,869.26504
Overall Steps per Second: 7,268.80572
Timestep Collection Time: 3.88942
Timestep Consumption Time: 2.99672
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.88614
Cumulative Model Updates: 148,286
Cumulative Timesteps: 1,190,016,618
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03018
Policy Entropy: 4.32596
Value Function Loss: 0.00273
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 1.03681
Value Function Update Magnitude: 0.83565
Collected Steps per Second: 12,982.03500
Overall Steps per Second: 7,195.53597
Timestep Collection Time: 3.85333
Timestep Consumption Time: 3.09876
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.95209
Cumulative Model Updates: 148,295
Cumulative Timesteps: 1,190,066,642
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1190066642...
Checkpoint 1190066642 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79260
Policy Entropy: 4.32678
Value Function Loss: 0.00273
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03169
Policy Update Magnitude: 1.03724
Value Function Update Magnitude: 0.84460
Collected Steps per Second: 12,789.13532
Overall Steps per Second: 7,107.86382
Timestep Collection Time: 3.91098
Timestep Consumption Time: 3.12602
PPO Batch Consumption Time: 0.23155
Total Iteration Time: 7.03699
Cumulative Model Updates: 148,304
Cumulative Timesteps: 1,190,116,660
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.39661
Policy Entropy: 4.32153
Value Function Loss: 0.00289
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03298
Policy Update Magnitude: 1.04241
Value Function Update Magnitude: 0.84705
Collected Steps per Second: 13,163.51856
Overall Steps per Second: 7,245.10799
Timestep Collection Time: 3.80126
Timestep Consumption Time: 3.10519
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.90645
Cumulative Model Updates: 148,313
Cumulative Timesteps: 1,190,166,698
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1190166698...
Checkpoint 1190166698 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86631
Policy Entropy: 4.32134
Value Function Loss: 0.00283
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03680
Policy Update Magnitude: 1.04501
Value Function Update Magnitude: 0.81239
Collected Steps per Second: 12,796.61882
Overall Steps per Second: 7,136.64004
Timestep Collection Time: 3.90775
Timestep Consumption Time: 3.09919
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 7.00694
Cumulative Model Updates: 148,322
Cumulative Timesteps: 1,190,216,704
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.68406
Policy Entropy: 4.32538
Value Function Loss: 0.00281
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03739
Policy Update Magnitude: 1.04293
Value Function Update Magnitude: 0.81614
Collected Steps per Second: 12,979.89367
Overall Steps per Second: 7,207.73676
Timestep Collection Time: 3.85288
Timestep Consumption Time: 3.08550
PPO Batch Consumption Time: 0.22975
Total Iteration Time: 6.93838
Cumulative Model Updates: 148,331
Cumulative Timesteps: 1,190,266,714
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1190266714...
Checkpoint 1190266714 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.45855
Policy Entropy: 4.32937
Value Function Loss: 0.00263
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03224
Policy Update Magnitude: 1.03431
Value Function Update Magnitude: 0.84013
Collected Steps per Second: 13,169.02568
Overall Steps per Second: 7,161.55514
Timestep Collection Time: 3.79679
Timestep Consumption Time: 3.18494
PPO Batch Consumption Time: 0.23091
Total Iteration Time: 6.98172
Cumulative Model Updates: 148,340
Cumulative Timesteps: 1,190,316,714
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.93763
Policy Entropy: 4.33056
Value Function Loss: 0.00270
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 1.03975
Value Function Update Magnitude: 0.84381
Collected Steps per Second: 13,057.08300
Overall Steps per Second: 7,182.03893
Timestep Collection Time: 3.83118
Timestep Consumption Time: 3.13398
PPO Batch Consumption Time: 0.23107
Total Iteration Time: 6.96515
Cumulative Model Updates: 148,349
Cumulative Timesteps: 1,190,366,738
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1190366738...
Checkpoint 1190366738 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.08062
Policy Entropy: 4.32857
Value Function Loss: 0.00279
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03292
Policy Update Magnitude: 1.05550
Value Function Update Magnitude: 0.87255
Collected Steps per Second: 12,769.77535
Overall Steps per Second: 7,191.73808
Timestep Collection Time: 3.91894
Timestep Consumption Time: 3.03960
PPO Batch Consumption Time: 0.22936
Total Iteration Time: 6.95854
Cumulative Model Updates: 148,358
Cumulative Timesteps: 1,190,416,782
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.30889
Policy Entropy: 4.32668
Value Function Loss: 0.00269
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03408
Policy Update Magnitude: 1.03378
Value Function Update Magnitude: 0.87431
Collected Steps per Second: 13,011.97335
Overall Steps per Second: 7,187.87940
Timestep Collection Time: 3.84277
Timestep Consumption Time: 3.11366
PPO Batch Consumption Time: 0.23065
Total Iteration Time: 6.95643
Cumulative Model Updates: 148,367
Cumulative Timesteps: 1,190,466,784
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1190466784...
Checkpoint 1190466784 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.91089
Policy Entropy: 4.32752
Value Function Loss: 0.00272
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03445
Policy Update Magnitude: 1.02854
Value Function Update Magnitude: 0.87644
Collected Steps per Second: 12,807.84853
Overall Steps per Second: 7,053.28858
Timestep Collection Time: 3.90620
Timestep Consumption Time: 3.18695
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 7.09315
Cumulative Model Updates: 148,376
Cumulative Timesteps: 1,190,516,814
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32008
Policy Entropy: 4.32615
Value Function Loss: 0.00278
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03184
Policy Update Magnitude: 1.03601
Value Function Update Magnitude: 0.88127
Collected Steps per Second: 12,909.83761
Overall Steps per Second: 7,267.20427
Timestep Collection Time: 3.87596
Timestep Consumption Time: 3.00950
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.88545
Cumulative Model Updates: 148,385
Cumulative Timesteps: 1,190,566,852
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1190566852...
Checkpoint 1190566852 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.87236
Policy Entropy: 4.32449
Value Function Loss: 0.00291
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03345
Policy Update Magnitude: 1.06608
Value Function Update Magnitude: 0.83729
Collected Steps per Second: 12,885.97793
Overall Steps per Second: 7,141.00950
Timestep Collection Time: 3.88050
Timestep Consumption Time: 3.12187
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 7.00237
Cumulative Model Updates: 148,394
Cumulative Timesteps: 1,190,616,856
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.67248
Policy Entropy: 4.32457
Value Function Loss: 0.00286
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03545
Policy Update Magnitude: 1.06657
Value Function Update Magnitude: 0.82713
Collected Steps per Second: 12,922.52363
Overall Steps per Second: 7,106.07144
Timestep Collection Time: 3.87107
Timestep Consumption Time: 3.16854
PPO Batch Consumption Time: 0.23758
Total Iteration Time: 7.03961
Cumulative Model Updates: 148,403
Cumulative Timesteps: 1,190,666,880
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1190666880...
Checkpoint 1190666880 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.90764
Policy Entropy: 4.32678
Value Function Loss: 0.00266
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03544
Policy Update Magnitude: 1.02634
Value Function Update Magnitude: 0.82800
Collected Steps per Second: 12,911.37364
Overall Steps per Second: 7,264.92415
Timestep Collection Time: 3.87627
Timestep Consumption Time: 3.01272
PPO Batch Consumption Time: 0.22979
Total Iteration Time: 6.88899
Cumulative Model Updates: 148,412
Cumulative Timesteps: 1,190,716,928
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.98300
Policy Entropy: 4.32717
Value Function Loss: 0.00268
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 1.02876
Value Function Update Magnitude: 0.81876
Collected Steps per Second: 13,072.30588
Overall Steps per Second: 7,200.25811
Timestep Collection Time: 3.82488
Timestep Consumption Time: 3.11932
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.94420
Cumulative Model Updates: 148,421
Cumulative Timesteps: 1,190,766,928
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1190766928...
Checkpoint 1190766928 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.45658
Policy Entropy: 4.32122
Value Function Loss: 0.00279
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 1.05509
Value Function Update Magnitude: 0.82293
Collected Steps per Second: 12,863.15320
Overall Steps per Second: 7,175.25601
Timestep Collection Time: 3.89065
Timestep Consumption Time: 3.08416
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.97480
Cumulative Model Updates: 148,430
Cumulative Timesteps: 1,190,816,974
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70359
Policy Entropy: 4.32052
Value Function Loss: 0.00283
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03609
Policy Update Magnitude: 1.05356
Value Function Update Magnitude: 0.84007
Collected Steps per Second: 12,925.24932
Overall Steps per Second: 7,265.09407
Timestep Collection Time: 3.87041
Timestep Consumption Time: 3.01539
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.88580
Cumulative Model Updates: 148,439
Cumulative Timesteps: 1,190,867,000
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1190867000...
Checkpoint 1190867000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.71102
Policy Entropy: 4.32181
Value Function Loss: 0.00285
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 1.05722
Value Function Update Magnitude: 0.83295
Collected Steps per Second: 12,763.31644
Overall Steps per Second: 7,088.62050
Timestep Collection Time: 3.91936
Timestep Consumption Time: 3.13759
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 7.05694
Cumulative Model Updates: 148,448
Cumulative Timesteps: 1,190,917,024
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31411
Policy Entropy: 4.32620
Value Function Loss: 0.00282
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 1.05789
Value Function Update Magnitude: 0.81363
Collected Steps per Second: 12,886.37093
Overall Steps per Second: 7,158.69652
Timestep Collection Time: 3.88286
Timestep Consumption Time: 3.10668
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.98954
Cumulative Model Updates: 148,457
Cumulative Timesteps: 1,190,967,060
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1190967060...
Checkpoint 1190967060 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04340
Policy Entropy: 4.32754
Value Function Loss: 0.00291
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03223
Policy Update Magnitude: 1.06340
Value Function Update Magnitude: 0.82497
Collected Steps per Second: 12,918.81859
Overall Steps per Second: 7,156.90359
Timestep Collection Time: 3.87218
Timestep Consumption Time: 3.11743
PPO Batch Consumption Time: 0.23699
Total Iteration Time: 6.98961
Cumulative Model Updates: 148,466
Cumulative Timesteps: 1,191,017,084
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.99364
Policy Entropy: 4.32693
Value Function Loss: 0.00290
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 1.05520
Value Function Update Magnitude: 0.82953
Collected Steps per Second: 13,032.52306
Overall Steps per Second: 7,178.91517
Timestep Collection Time: 3.83717
Timestep Consumption Time: 3.12879
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.96595
Cumulative Model Updates: 148,475
Cumulative Timesteps: 1,191,067,092
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1191067092...
Checkpoint 1191067092 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.39103
Policy Entropy: 4.32754
Value Function Loss: 0.00283
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03394
Policy Update Magnitude: 1.04016
Value Function Update Magnitude: 0.82690
Collected Steps per Second: 12,973.28978
Overall Steps per Second: 7,201.95060
Timestep Collection Time: 3.85469
Timestep Consumption Time: 3.08899
PPO Batch Consumption Time: 0.22945
Total Iteration Time: 6.94367
Cumulative Model Updates: 148,484
Cumulative Timesteps: 1,191,117,100
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04590
Policy Entropy: 4.32927
Value Function Loss: 0.00269
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 1.03867
Value Function Update Magnitude: 0.82406
Collected Steps per Second: 12,874.67310
Overall Steps per Second: 7,264.77008
Timestep Collection Time: 3.88732
Timestep Consumption Time: 3.00182
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.88914
Cumulative Model Updates: 148,493
Cumulative Timesteps: 1,191,167,148
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1191167148...
Checkpoint 1191167148 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.69036
Policy Entropy: 4.32834
Value Function Loss: 0.00258
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 1.04501
Value Function Update Magnitude: 0.81903
Collected Steps per Second: 12,950.95149
Overall Steps per Second: 7,179.17741
Timestep Collection Time: 3.86180
Timestep Consumption Time: 3.10474
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.96654
Cumulative Model Updates: 148,502
Cumulative Timesteps: 1,191,217,162
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04832
Policy Entropy: 4.33042
Value Function Loss: 0.00257
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03398
Policy Update Magnitude: 1.02099
Value Function Update Magnitude: 0.81674
Collected Steps per Second: 12,925.19041
Overall Steps per Second: 7,196.26269
Timestep Collection Time: 3.86857
Timestep Consumption Time: 3.07976
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.94833
Cumulative Model Updates: 148,511
Cumulative Timesteps: 1,191,267,164
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1191267164...
Checkpoint 1191267164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.10221
Policy Entropy: 4.32976
Value Function Loss: 0.00254
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03251
Policy Update Magnitude: 1.01260
Value Function Update Magnitude: 0.80176
Collected Steps per Second: 12,865.63567
Overall Steps per Second: 7,138.44235
Timestep Collection Time: 3.88788
Timestep Consumption Time: 3.11925
PPO Batch Consumption Time: 0.23016
Total Iteration Time: 7.00713
Cumulative Model Updates: 148,520
Cumulative Timesteps: 1,191,317,184
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.96953
Policy Entropy: 4.32614
Value Function Loss: 0.00262
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03162
Policy Update Magnitude: 1.02193
Value Function Update Magnitude: 0.78002
Collected Steps per Second: 13,016.83274
Overall Steps per Second: 7,126.34026
Timestep Collection Time: 3.84318
Timestep Consumption Time: 3.17669
PPO Batch Consumption Time: 0.23132
Total Iteration Time: 7.01987
Cumulative Model Updates: 148,529
Cumulative Timesteps: 1,191,367,210
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1191367210...
Checkpoint 1191367210 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.02128
Policy Entropy: 4.32706
Value Function Loss: 0.00266
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03243
Policy Update Magnitude: 1.03846
Value Function Update Magnitude: 0.79740
Collected Steps per Second: 12,783.31474
Overall Steps per Second: 7,150.68078
Timestep Collection Time: 3.91197
Timestep Consumption Time: 3.08149
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.99346
Cumulative Model Updates: 148,538
Cumulative Timesteps: 1,191,417,218
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.17479
Policy Entropy: 4.32418
Value Function Loss: 0.00274
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03406
Policy Update Magnitude: 1.03394
Value Function Update Magnitude: 0.81317
Collected Steps per Second: 12,757.95867
Overall Steps per Second: 7,219.62883
Timestep Collection Time: 3.91991
Timestep Consumption Time: 3.00704
PPO Batch Consumption Time: 0.23019
Total Iteration Time: 6.92695
Cumulative Model Updates: 148,547
Cumulative Timesteps: 1,191,467,228
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1191467228...
Checkpoint 1191467228 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.73994
Policy Entropy: 4.32240
Value Function Loss: 0.00277
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 1.04134
Value Function Update Magnitude: 0.82365
Collected Steps per Second: 12,893.61403
Overall Steps per Second: 7,133.74476
Timestep Collection Time: 3.88099
Timestep Consumption Time: 3.13356
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 7.01455
Cumulative Model Updates: 148,556
Cumulative Timesteps: 1,191,517,268
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.93069
Policy Entropy: 4.32549
Value Function Loss: 0.00272
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03244
Policy Update Magnitude: 1.02326
Value Function Update Magnitude: 0.80197
Collected Steps per Second: 12,790.31366
Overall Steps per Second: 7,138.46218
Timestep Collection Time: 3.91155
Timestep Consumption Time: 3.09696
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 7.00851
Cumulative Model Updates: 148,565
Cumulative Timesteps: 1,191,567,298
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1191567298...
Checkpoint 1191567298 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.92502
Policy Entropy: 4.33017
Value Function Loss: 0.00263
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03238
Policy Update Magnitude: 0.99403
Value Function Update Magnitude: 0.80754
Collected Steps per Second: 12,771.31743
Overall Steps per Second: 7,241.10949
Timestep Collection Time: 3.91753
Timestep Consumption Time: 2.99191
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.90944
Cumulative Model Updates: 148,574
Cumulative Timesteps: 1,191,617,330
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03900
Policy Entropy: 4.33262
Value Function Loss: 0.00254
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03165
Policy Update Magnitude: 0.98272
Value Function Update Magnitude: 0.80038
Collected Steps per Second: 12,930.01110
Overall Steps per Second: 7,168.21434
Timestep Collection Time: 3.86775
Timestep Consumption Time: 3.10889
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.97663
Cumulative Model Updates: 148,583
Cumulative Timesteps: 1,191,667,340
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1191667340...
Checkpoint 1191667340 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64804
Policy Entropy: 4.32858
Value Function Loss: 0.00252
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03222
Policy Update Magnitude: 0.99594
Value Function Update Magnitude: 0.81512
Collected Steps per Second: 12,876.38781
Overall Steps per Second: 7,118.28138
Timestep Collection Time: 3.88587
Timestep Consumption Time: 3.14335
PPO Batch Consumption Time: 0.23008
Total Iteration Time: 7.02922
Cumulative Model Updates: 148,592
Cumulative Timesteps: 1,191,717,376
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67395
Policy Entropy: 4.32821
Value Function Loss: 0.00258
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03239
Policy Update Magnitude: 1.00660
Value Function Update Magnitude: 0.78236
Collected Steps per Second: 12,940.78866
Overall Steps per Second: 7,275.51079
Timestep Collection Time: 3.86422
Timestep Consumption Time: 3.00898
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.87319
Cumulative Model Updates: 148,601
Cumulative Timesteps: 1,191,767,382
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1191767382...
Checkpoint 1191767382 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.84531
Policy Entropy: 4.33013
Value Function Loss: 0.00260
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03446
Policy Update Magnitude: 1.00859
Value Function Update Magnitude: 0.76218
Collected Steps per Second: 12,843.83981
Overall Steps per Second: 7,142.44041
Timestep Collection Time: 3.89556
Timestep Consumption Time: 3.10960
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 7.00517
Cumulative Model Updates: 148,610
Cumulative Timesteps: 1,191,817,416
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53604
Policy Entropy: 4.33333
Value Function Loss: 0.00264
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03428
Policy Update Magnitude: 1.00359
Value Function Update Magnitude: 0.76190
Collected Steps per Second: 12,821.75773
Overall Steps per Second: 7,186.11636
Timestep Collection Time: 3.90103
Timestep Consumption Time: 3.05934
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.96037
Cumulative Model Updates: 148,619
Cumulative Timesteps: 1,191,867,434
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1191867434...
Checkpoint 1191867434 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.65726
Policy Entropy: 4.33112
Value Function Loss: 0.00265
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03179
Policy Update Magnitude: 1.02386
Value Function Update Magnitude: 0.80877
Collected Steps per Second: 12,861.12764
Overall Steps per Second: 7,263.09790
Timestep Collection Time: 3.89002
Timestep Consumption Time: 2.99823
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.88825
Cumulative Model Updates: 148,628
Cumulative Timesteps: 1,191,917,464
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.41235
Policy Entropy: 4.32935
Value Function Loss: 0.00263
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03494
Policy Update Magnitude: 1.02911
Value Function Update Magnitude: 0.80879
Collected Steps per Second: 12,807.98863
Overall Steps per Second: 7,133.25717
Timestep Collection Time: 3.90475
Timestep Consumption Time: 3.10635
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 7.01110
Cumulative Model Updates: 148,637
Cumulative Timesteps: 1,191,967,476
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1191967476...
Checkpoint 1191967476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.00384
Policy Entropy: 4.32157
Value Function Loss: 0.00274
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03695
Policy Update Magnitude: 1.04830
Value Function Update Magnitude: 0.79928
Collected Steps per Second: 12,669.35563
Overall Steps per Second: 7,122.06417
Timestep Collection Time: 3.94827
Timestep Consumption Time: 3.07526
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 7.02353
Cumulative Model Updates: 148,646
Cumulative Timesteps: 1,192,017,498
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.93753
Policy Entropy: 4.32327
Value Function Loss: 0.00274
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03842
Policy Update Magnitude: 1.05985
Value Function Update Magnitude: 0.81482
Collected Steps per Second: 13,102.20493
Overall Steps per Second: 7,160.74981
Timestep Collection Time: 3.81722
Timestep Consumption Time: 3.16724
PPO Batch Consumption Time: 0.23032
Total Iteration Time: 6.98446
Cumulative Model Updates: 148,655
Cumulative Timesteps: 1,192,067,512
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1192067512...
Checkpoint 1192067512 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54802
Policy Entropy: 4.32914
Value Function Loss: 0.00274
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03744
Policy Update Magnitude: 1.04513
Value Function Update Magnitude: 0.82975
Collected Steps per Second: 12,788.10194
Overall Steps per Second: 7,098.97354
Timestep Collection Time: 3.91254
Timestep Consumption Time: 3.13552
PPO Batch Consumption Time: 0.22976
Total Iteration Time: 7.04806
Cumulative Model Updates: 148,664
Cumulative Timesteps: 1,192,117,546
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.75076
Policy Entropy: 4.33452
Value Function Loss: 0.00268
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03498
Policy Update Magnitude: 1.02820
Value Function Update Magnitude: 0.84285
Collected Steps per Second: 12,864.36331
Overall Steps per Second: 7,172.68567
Timestep Collection Time: 3.88842
Timestep Consumption Time: 3.08554
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.97396
Cumulative Model Updates: 148,673
Cumulative Timesteps: 1,192,167,568
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1192167568...
Checkpoint 1192167568 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.31583
Policy Entropy: 4.33246
Value Function Loss: 0.00283
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03580
Policy Update Magnitude: 1.05343
Value Function Update Magnitude: 0.85182
Collected Steps per Second: 12,716.46629
Overall Steps per Second: 7,212.61123
Timestep Collection Time: 3.93207
Timestep Consumption Time: 3.00051
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.93258
Cumulative Model Updates: 148,682
Cumulative Timesteps: 1,192,217,570
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.68719
Policy Entropy: 4.32732
Value Function Loss: 0.00289
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03457
Policy Update Magnitude: 1.07355
Value Function Update Magnitude: 0.86865
Collected Steps per Second: 13,037.89089
Overall Steps per Second: 7,190.96610
Timestep Collection Time: 3.83528
Timestep Consumption Time: 3.11844
PPO Batch Consumption Time: 0.23021
Total Iteration Time: 6.95372
Cumulative Model Updates: 148,691
Cumulative Timesteps: 1,192,267,574
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1192267574...
Checkpoint 1192267574 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.22185
Policy Entropy: 4.32973
Value Function Loss: 0.00285
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03530
Policy Update Magnitude: 1.06728
Value Function Update Magnitude: 0.83944
Collected Steps per Second: 12,904.28557
Overall Steps per Second: 7,183.64332
Timestep Collection Time: 3.87794
Timestep Consumption Time: 3.08817
PPO Batch Consumption Time: 0.22916
Total Iteration Time: 6.96610
Cumulative Model Updates: 148,700
Cumulative Timesteps: 1,192,317,616
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.07344
Policy Entropy: 4.33286
Value Function Loss: 0.00273
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 1.05305
Value Function Update Magnitude: 0.81959
Collected Steps per Second: 12,832.39350
Overall Steps per Second: 7,267.59988
Timestep Collection Time: 3.89655
Timestep Consumption Time: 2.98358
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.88013
Cumulative Model Updates: 148,709
Cumulative Timesteps: 1,192,367,618
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1192367618...
Checkpoint 1192367618 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.07440
Policy Entropy: 4.33483
Value Function Loss: 0.00257
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03296
Policy Update Magnitude: 1.03262
Value Function Update Magnitude: 0.79307
Collected Steps per Second: 12,718.53091
Overall Steps per Second: 6,960.88172
Timestep Collection Time: 3.93143
Timestep Consumption Time: 3.25186
PPO Batch Consumption Time: 0.23942
Total Iteration Time: 7.18329
Cumulative Model Updates: 148,718
Cumulative Timesteps: 1,192,417,620
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.16937
Policy Entropy: 4.33148
Value Function Loss: 0.00262
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03290
Policy Update Magnitude: 1.02409
Value Function Update Magnitude: 0.78703
Collected Steps per Second: 12,936.84277
Overall Steps per Second: 7,200.83356
Timestep Collection Time: 3.86710
Timestep Consumption Time: 3.08043
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.94753
Cumulative Model Updates: 148,727
Cumulative Timesteps: 1,192,467,648
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1192467648...
Checkpoint 1192467648 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10272
Policy Entropy: 4.33110
Value Function Loss: 0.00276
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03409
Policy Update Magnitude: 1.03238
Value Function Update Magnitude: 0.78995
Collected Steps per Second: 13,066.06607
Overall Steps per Second: 7,152.30715
Timestep Collection Time: 3.82961
Timestep Consumption Time: 3.16645
PPO Batch Consumption Time: 0.22964
Total Iteration Time: 6.99606
Cumulative Model Updates: 148,736
Cumulative Timesteps: 1,192,517,686
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.38400
Policy Entropy: 4.32639
Value Function Loss: 0.00288
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03680
Policy Update Magnitude: 1.04374
Value Function Update Magnitude: 0.78099
Collected Steps per Second: 12,943.19714
Overall Steps per Second: 7,179.09310
Timestep Collection Time: 3.86535
Timestep Consumption Time: 3.10350
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.96885
Cumulative Model Updates: 148,745
Cumulative Timesteps: 1,192,567,716
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1192567716...
Checkpoint 1192567716 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02279
Policy Entropy: 4.32519
Value Function Loss: 0.00295
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03711
Policy Update Magnitude: 1.05617
Value Function Update Magnitude: 0.81326
Collected Steps per Second: 12,805.40717
Overall Steps per Second: 7,164.10936
Timestep Collection Time: 3.90616
Timestep Consumption Time: 3.07586
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.98203
Cumulative Model Updates: 148,754
Cumulative Timesteps: 1,192,617,736
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23853
Policy Entropy: 4.32553
Value Function Loss: 0.00300
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03696
Policy Update Magnitude: 1.06878
Value Function Update Magnitude: 0.84204
Collected Steps per Second: 13,083.14077
Overall Steps per Second: 7,212.91224
Timestep Collection Time: 3.82171
Timestep Consumption Time: 3.11030
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.93201
Cumulative Model Updates: 148,763
Cumulative Timesteps: 1,192,667,736
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1192667736...
Checkpoint 1192667736 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95586
Policy Entropy: 4.32304
Value Function Loss: 0.00300
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03894
Policy Update Magnitude: 1.07327
Value Function Update Magnitude: 0.83634
Collected Steps per Second: 13,051.48533
Overall Steps per Second: 7,200.33986
Timestep Collection Time: 3.83297
Timestep Consumption Time: 3.11475
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.94773
Cumulative Model Updates: 148,772
Cumulative Timesteps: 1,192,717,762
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10742
Policy Entropy: 4.32339
Value Function Loss: 0.00297
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03543
Policy Update Magnitude: 1.06526
Value Function Update Magnitude: 0.83642
Collected Steps per Second: 12,879.82954
Overall Steps per Second: 7,138.94792
Timestep Collection Time: 3.88250
Timestep Consumption Time: 3.12217
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 7.00467
Cumulative Model Updates: 148,781
Cumulative Timesteps: 1,192,767,768
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1192767768...
Checkpoint 1192767768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.31844
Policy Entropy: 4.32148
Value Function Loss: 0.00293
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03572
Policy Update Magnitude: 1.07377
Value Function Update Magnitude: 0.83564
Collected Steps per Second: 13,284.27577
Overall Steps per Second: 7,281.26013
Timestep Collection Time: 3.76611
Timestep Consumption Time: 3.10496
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.87106
Cumulative Model Updates: 148,790
Cumulative Timesteps: 1,192,817,798
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.23761
Policy Entropy: 4.32604
Value Function Loss: 0.00280
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03618
Policy Update Magnitude: 1.06728
Value Function Update Magnitude: 0.82811
Collected Steps per Second: 12,972.00463
Overall Steps per Second: 7,183.93446
Timestep Collection Time: 3.85569
Timestep Consumption Time: 3.10651
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.96220
Cumulative Model Updates: 148,799
Cumulative Timesteps: 1,192,867,814
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1192867814...
Checkpoint 1192867814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19071
Policy Entropy: 4.32884
Value Function Loss: 0.00277
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03702
Policy Update Magnitude: 1.03573
Value Function Update Magnitude: 0.82144
Collected Steps per Second: 12,955.59145
Overall Steps per Second: 7,192.28955
Timestep Collection Time: 3.85995
Timestep Consumption Time: 3.09305
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 6.95300
Cumulative Model Updates: 148,808
Cumulative Timesteps: 1,192,917,822
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.44597
Policy Entropy: 4.33138
Value Function Loss: 0.00264
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03551
Policy Update Magnitude: 1.01781
Value Function Update Magnitude: 0.82498
Collected Steps per Second: 13,160.58451
Overall Steps per Second: 7,238.27245
Timestep Collection Time: 3.80241
Timestep Consumption Time: 3.11111
PPO Batch Consumption Time: 0.22966
Total Iteration Time: 6.91353
Cumulative Model Updates: 148,817
Cumulative Timesteps: 1,192,967,864
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1192967864...
Checkpoint 1192967864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.09543
Policy Entropy: 4.32842
Value Function Loss: 0.00264
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03442
Policy Update Magnitude: 1.00632
Value Function Update Magnitude: 0.78912
Collected Steps per Second: 13,052.17419
Overall Steps per Second: 7,172.80823
Timestep Collection Time: 3.83078
Timestep Consumption Time: 3.13999
PPO Batch Consumption Time: 0.22989
Total Iteration Time: 6.97077
Cumulative Model Updates: 148,826
Cumulative Timesteps: 1,193,017,864
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76987
Policy Entropy: 4.32583
Value Function Loss: 0.00266
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03346
Policy Update Magnitude: 1.02998
Value Function Update Magnitude: 0.76996
Collected Steps per Second: 12,952.00596
Overall Steps per Second: 7,198.78681
Timestep Collection Time: 3.86056
Timestep Consumption Time: 3.08533
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.94589
Cumulative Model Updates: 148,835
Cumulative Timesteps: 1,193,067,866
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1193067866...
Checkpoint 1193067866 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04215
Policy Entropy: 4.32412
Value Function Loss: 0.00276
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03576
Policy Update Magnitude: 1.04702
Value Function Update Magnitude: 0.75716
Collected Steps per Second: 13,057.82223
Overall Steps per Second: 7,063.13093
Timestep Collection Time: 3.83188
Timestep Consumption Time: 3.25223
PPO Batch Consumption Time: 0.24125
Total Iteration Time: 7.08411
Cumulative Model Updates: 148,844
Cumulative Timesteps: 1,193,117,902
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61913
Policy Entropy: 4.32540
Value Function Loss: 0.00276
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 1.03123
Value Function Update Magnitude: 0.75436
Collected Steps per Second: 12,886.70546
Overall Steps per Second: 7,152.97480
Timestep Collection Time: 3.88307
Timestep Consumption Time: 3.11262
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.99569
Cumulative Model Updates: 148,853
Cumulative Timesteps: 1,193,167,942
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1193167942...
Checkpoint 1193167942 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25256
Policy Entropy: 4.32287
Value Function Loss: 0.00273
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 1.03597
Value Function Update Magnitude: 0.75821
Collected Steps per Second: 12,884.92038
Overall Steps per Second: 7,185.50409
Timestep Collection Time: 3.88237
Timestep Consumption Time: 3.07943
PPO Batch Consumption Time: 0.22966
Total Iteration Time: 6.96179
Cumulative Model Updates: 148,862
Cumulative Timesteps: 1,193,217,966
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81479
Policy Entropy: 4.32006
Value Function Loss: 0.00281
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03524
Policy Update Magnitude: 1.04312
Value Function Update Magnitude: 0.78989
Collected Steps per Second: 13,093.20607
Overall Steps per Second: 7,207.76122
Timestep Collection Time: 3.82061
Timestep Consumption Time: 3.11969
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.94030
Cumulative Model Updates: 148,871
Cumulative Timesteps: 1,193,267,990
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1193267990...
Checkpoint 1193267990 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.49170
Policy Entropy: 4.32064
Value Function Loss: 0.00280
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03501
Policy Update Magnitude: 1.05292
Value Function Update Magnitude: 0.80656
Collected Steps per Second: 12,906.92194
Overall Steps per Second: 7,160.23842
Timestep Collection Time: 3.87467
Timestep Consumption Time: 3.10974
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.98440
Cumulative Model Updates: 148,880
Cumulative Timesteps: 1,193,318,000
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.05403
Policy Entropy: 4.32226
Value Function Loss: 0.00285
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03513
Policy Update Magnitude: 1.05079
Value Function Update Magnitude: 0.80095
Collected Steps per Second: 12,755.93537
Overall Steps per Second: 7,102.66396
Timestep Collection Time: 3.91990
Timestep Consumption Time: 3.11999
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 7.03989
Cumulative Model Updates: 148,889
Cumulative Timesteps: 1,193,368,002
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1193368002...
Checkpoint 1193368002 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.73081
Policy Entropy: 4.31895
Value Function Loss: 0.00276
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03436
Policy Update Magnitude: 1.04146
Value Function Update Magnitude: 0.76679
Collected Steps per Second: 12,862.74273
Overall Steps per Second: 7,242.62778
Timestep Collection Time: 3.88766
Timestep Consumption Time: 3.01674
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.90440
Cumulative Model Updates: 148,898
Cumulative Timesteps: 1,193,418,008
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.62881
Policy Entropy: 4.31996
Value Function Loss: 0.00280
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 1.04241
Value Function Update Magnitude: 0.75431
Collected Steps per Second: 12,956.79703
Overall Steps per Second: 7,011.50192
Timestep Collection Time: 3.86052
Timestep Consumption Time: 3.27347
PPO Batch Consumption Time: 0.24154
Total Iteration Time: 7.13399
Cumulative Model Updates: 148,907
Cumulative Timesteps: 1,193,468,028
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1193468028...
Checkpoint 1193468028 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10676
Policy Entropy: 4.31626
Value Function Loss: 0.00281
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03509
Policy Update Magnitude: 1.05007
Value Function Update Magnitude: 0.76869
Collected Steps per Second: 12,963.07654
Overall Steps per Second: 7,207.16317
Timestep Collection Time: 3.85773
Timestep Consumption Time: 3.08093
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.93865
Cumulative Model Updates: 148,916
Cumulative Timesteps: 1,193,518,036
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30372
Policy Entropy: 4.31712
Value Function Loss: 0.00287
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03388
Policy Update Magnitude: 1.06278
Value Function Update Magnitude: 0.78555
Collected Steps per Second: 13,274.94023
Overall Steps per Second: 7,278.17097
Timestep Collection Time: 3.76800
Timestep Consumption Time: 3.10460
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.87261
Cumulative Model Updates: 148,925
Cumulative Timesteps: 1,193,568,056
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1193568056...
Checkpoint 1193568056 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95295
Policy Entropy: 4.31944
Value Function Loss: 0.00286
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03652
Policy Update Magnitude: 1.06868
Value Function Update Magnitude: 0.77096
Collected Steps per Second: 13,037.22431
Overall Steps per Second: 7,199.11794
Timestep Collection Time: 3.83778
Timestep Consumption Time: 3.11224
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.95002
Cumulative Model Updates: 148,934
Cumulative Timesteps: 1,193,618,090
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.54086
Policy Entropy: 4.32403
Value Function Loss: 0.00279
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03537
Policy Update Magnitude: 1.05723
Value Function Update Magnitude: 0.77681
Collected Steps per Second: 13,040.99866
Overall Steps per Second: 7,229.88387
Timestep Collection Time: 3.83406
Timestep Consumption Time: 3.08168
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.91574
Cumulative Model Updates: 148,943
Cumulative Timesteps: 1,193,668,090
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1193668090...
Checkpoint 1193668090 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44538
Policy Entropy: 4.32737
Value Function Loss: 0.00275
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03511
Policy Update Magnitude: 1.03623
Value Function Update Magnitude: 0.77053
Collected Steps per Second: 12,777.00984
Overall Steps per Second: 7,256.47922
Timestep Collection Time: 3.91547
Timestep Consumption Time: 2.97878
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.89425
Cumulative Model Updates: 148,952
Cumulative Timesteps: 1,193,718,118
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.56750
Policy Entropy: 4.32694
Value Function Loss: 0.00270
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03519
Policy Update Magnitude: 1.02322
Value Function Update Magnitude: 0.79724
Collected Steps per Second: 13,064.35308
Overall Steps per Second: 7,203.12298
Timestep Collection Time: 3.82797
Timestep Consumption Time: 3.11485
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.94282
Cumulative Model Updates: 148,961
Cumulative Timesteps: 1,193,768,128
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1193768128...
Checkpoint 1193768128 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.78573
Policy Entropy: 4.32449
Value Function Loss: 0.00281
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03354
Policy Update Magnitude: 1.02725
Value Function Update Magnitude: 0.80496
Collected Steps per Second: 12,969.36088
Overall Steps per Second: 7,112.03654
Timestep Collection Time: 3.85539
Timestep Consumption Time: 3.17522
PPO Batch Consumption Time: 0.23648
Total Iteration Time: 7.03062
Cumulative Model Updates: 148,970
Cumulative Timesteps: 1,193,818,130
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36067
Policy Entropy: 4.32246
Value Function Loss: 0.00284
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03421
Policy Update Magnitude: 1.04218
Value Function Update Magnitude: 0.81994
Collected Steps per Second: 12,930.29552
Overall Steps per Second: 7,286.57110
Timestep Collection Time: 3.86843
Timestep Consumption Time: 2.99625
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.86468
Cumulative Model Updates: 148,979
Cumulative Timesteps: 1,193,868,150
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1193868150...
Checkpoint 1193868150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.51833
Policy Entropy: 4.32457
Value Function Loss: 0.00288
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03556
Policy Update Magnitude: 1.06535
Value Function Update Magnitude: 0.83022
Collected Steps per Second: 12,994.82713
Overall Steps per Second: 7,185.44817
Timestep Collection Time: 3.84999
Timestep Consumption Time: 3.11269
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.96268
Cumulative Model Updates: 148,988
Cumulative Timesteps: 1,193,918,180
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.09423
Policy Entropy: 4.32328
Value Function Loss: 0.00288
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03298
Policy Update Magnitude: 1.03961
Value Function Update Magnitude: 0.80060
Collected Steps per Second: 12,988.34840
Overall Steps per Second: 7,208.30856
Timestep Collection Time: 3.85114
Timestep Consumption Time: 3.08807
PPO Batch Consumption Time: 0.22784
Total Iteration Time: 6.93921
Cumulative Model Updates: 148,997
Cumulative Timesteps: 1,193,968,200
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1193968200...
Checkpoint 1193968200 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60266
Policy Entropy: 4.32462
Value Function Loss: 0.00284
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03271
Policy Update Magnitude: 1.02810
Value Function Update Magnitude: 0.78477
Collected Steps per Second: 12,851.72042
Overall Steps per Second: 7,275.43776
Timestep Collection Time: 3.89053
Timestep Consumption Time: 2.98191
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.87244
Cumulative Model Updates: 149,006
Cumulative Timesteps: 1,194,018,200
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.46174
Policy Entropy: 4.32382
Value Function Loss: 0.00277
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03570
Policy Update Magnitude: 1.01009
Value Function Update Magnitude: 0.78937
Collected Steps per Second: 12,991.08522
Overall Steps per Second: 7,199.01472
Timestep Collection Time: 3.85187
Timestep Consumption Time: 3.09908
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.95095
Cumulative Model Updates: 149,015
Cumulative Timesteps: 1,194,068,240
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1194068240...
Checkpoint 1194068240 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.84526
Policy Entropy: 4.32483
Value Function Loss: 0.00278
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03473
Policy Update Magnitude: 0.98703
Value Function Update Magnitude: 0.80618
Collected Steps per Second: 12,769.77398
Overall Steps per Second: 7,094.24202
Timestep Collection Time: 3.91879
Timestep Consumption Time: 3.13510
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 7.05389
Cumulative Model Updates: 149,024
Cumulative Timesteps: 1,194,118,282
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.18796
Policy Entropy: 4.32540
Value Function Loss: 0.00276
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03227
Policy Update Magnitude: 1.00733
Value Function Update Magnitude: 0.82271
Collected Steps per Second: 12,697.06614
Overall Steps per Second: 7,153.99980
Timestep Collection Time: 3.94186
Timestep Consumption Time: 3.05423
PPO Batch Consumption Time: 0.23055
Total Iteration Time: 6.99609
Cumulative Model Updates: 149,033
Cumulative Timesteps: 1,194,168,332
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1194168332...
Checkpoint 1194168332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61792
Policy Entropy: 4.32860
Value Function Loss: 0.00279
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03452
Policy Update Magnitude: 1.00517
Value Function Update Magnitude: 0.80818
Collected Steps per Second: 12,759.93891
Overall Steps per Second: 7,106.72568
Timestep Collection Time: 3.91945
Timestep Consumption Time: 3.11782
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 7.03728
Cumulative Model Updates: 149,042
Cumulative Timesteps: 1,194,218,344
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36273
Policy Entropy: 4.32950
Value Function Loss: 0.00272
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03146
Policy Update Magnitude: 0.98785
Value Function Update Magnitude: 0.79085
Collected Steps per Second: 12,856.70503
Overall Steps per Second: 7,143.12397
Timestep Collection Time: 3.89229
Timestep Consumption Time: 3.11333
PPO Batch Consumption Time: 0.23118
Total Iteration Time: 7.00562
Cumulative Model Updates: 149,051
Cumulative Timesteps: 1,194,268,386
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1194268386...
Checkpoint 1194268386 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52022
Policy Entropy: 4.32728
Value Function Loss: 0.00284
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 1.00109
Value Function Update Magnitude: 0.80359
Collected Steps per Second: 12,922.18220
Overall Steps per Second: 7,263.76225
Timestep Collection Time: 3.87164
Timestep Consumption Time: 3.01598
PPO Batch Consumption Time: 0.22982
Total Iteration Time: 6.88762
Cumulative Model Updates: 149,060
Cumulative Timesteps: 1,194,318,416
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83528
Policy Entropy: 4.32611
Value Function Loss: 0.00276
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03235
Policy Update Magnitude: 1.00455
Value Function Update Magnitude: 0.81691
Collected Steps per Second: 12,977.33026
Overall Steps per Second: 7,168.36454
Timestep Collection Time: 3.85303
Timestep Consumption Time: 3.12234
PPO Batch Consumption Time: 0.22953
Total Iteration Time: 6.97537
Cumulative Model Updates: 149,069
Cumulative Timesteps: 1,194,368,418
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1194368418...
Checkpoint 1194368418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.72070
Policy Entropy: 4.32350
Value Function Loss: 0.00280
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03309
Policy Update Magnitude: 1.01280
Value Function Update Magnitude: 0.79667
Collected Steps per Second: 13,151.18390
Overall Steps per Second: 7,260.60220
Timestep Collection Time: 3.80316
Timestep Consumption Time: 3.08553
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.88868
Cumulative Model Updates: 149,078
Cumulative Timesteps: 1,194,418,434
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.22734
Policy Entropy: 4.32709
Value Function Loss: 0.00268
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03220
Policy Update Magnitude: 1.02578
Value Function Update Magnitude: 0.81481
Collected Steps per Second: 13,265.07331
Overall Steps per Second: 7,272.82433
Timestep Collection Time: 3.77156
Timestep Consumption Time: 3.10747
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.87903
Cumulative Model Updates: 149,087
Cumulative Timesteps: 1,194,468,464
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1194468464...
Checkpoint 1194468464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.49463
Policy Entropy: 4.32519
Value Function Loss: 0.00269
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03192
Policy Update Magnitude: 1.01699
Value Function Update Magnitude: 0.82356
Collected Steps per Second: 12,980.53335
Overall Steps per Second: 7,055.14886
Timestep Collection Time: 3.85423
Timestep Consumption Time: 3.23704
PPO Batch Consumption Time: 0.24025
Total Iteration Time: 7.09127
Cumulative Model Updates: 149,096
Cumulative Timesteps: 1,194,518,494
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74374
Policy Entropy: 4.32898
Value Function Loss: 0.00258
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03126
Policy Update Magnitude: 1.00725
Value Function Update Magnitude: 0.81615
Collected Steps per Second: 12,986.09084
Overall Steps per Second: 7,237.41460
Timestep Collection Time: 3.85181
Timestep Consumption Time: 3.05949
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.91131
Cumulative Model Updates: 149,105
Cumulative Timesteps: 1,194,568,514
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1194568514...
Checkpoint 1194568514 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.59135
Policy Entropy: 4.32952
Value Function Loss: 0.00263
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 0.99731
Value Function Update Magnitude: 0.80969
Collected Steps per Second: 13,178.41670
Overall Steps per Second: 7,275.96240
Timestep Collection Time: 3.79651
Timestep Consumption Time: 3.07983
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.87634
Cumulative Model Updates: 149,114
Cumulative Timesteps: 1,194,618,546
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.43782
Policy Entropy: 4.32669
Value Function Loss: 0.00271
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 1.01241
Value Function Update Magnitude: 0.82902
Collected Steps per Second: 13,042.29301
Overall Steps per Second: 7,208.55241
Timestep Collection Time: 3.83629
Timestep Consumption Time: 3.10463
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.94092
Cumulative Model Updates: 149,123
Cumulative Timesteps: 1,194,668,580
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1194668580...
Checkpoint 1194668580 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.04284
Policy Entropy: 4.32143
Value Function Loss: 0.00287
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 1.04837
Value Function Update Magnitude: 0.85779
Collected Steps per Second: 12,879.98365
Overall Steps per Second: 7,183.22629
Timestep Collection Time: 3.88510
Timestep Consumption Time: 3.08113
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.96623
Cumulative Model Updates: 149,132
Cumulative Timesteps: 1,194,718,620
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.88428
Policy Entropy: 4.32260
Value Function Loss: 0.00283
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03438
Policy Update Magnitude: 1.05274
Value Function Update Magnitude: 0.85378
Collected Steps per Second: 13,213.62197
Overall Steps per Second: 7,273.80597
Timestep Collection Time: 3.78564
Timestep Consumption Time: 3.09137
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.87701
Cumulative Model Updates: 149,141
Cumulative Timesteps: 1,194,768,642
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1194768642...
Checkpoint 1194768642 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01499
Policy Entropy: 4.32806
Value Function Loss: 0.00280
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03300
Policy Update Magnitude: 1.03180
Value Function Update Magnitude: 0.83751
Collected Steps per Second: 12,772.11912
Overall Steps per Second: 7,124.54513
Timestep Collection Time: 3.91556
Timestep Consumption Time: 3.10384
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 7.01940
Cumulative Model Updates: 149,150
Cumulative Timesteps: 1,194,818,652
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.88665
Policy Entropy: 4.32788
Value Function Loss: 0.00279
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03426
Policy Update Magnitude: 1.03932
Value Function Update Magnitude: 0.81305
Collected Steps per Second: 12,786.29890
Overall Steps per Second: 7,076.18641
Timestep Collection Time: 3.91200
Timestep Consumption Time: 3.15678
PPO Batch Consumption Time: 0.23111
Total Iteration Time: 7.06878
Cumulative Model Updates: 149,159
Cumulative Timesteps: 1,194,868,672
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1194868672...
Checkpoint 1194868672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46083
Policy Entropy: 4.32950
Value Function Loss: 0.00266
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03524
Policy Update Magnitude: 1.02957
Value Function Update Magnitude: 0.82555
Collected Steps per Second: 13,182.14462
Overall Steps per Second: 7,243.83745
Timestep Collection Time: 3.79437
Timestep Consumption Time: 3.11053
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.90490
Cumulative Model Updates: 149,168
Cumulative Timesteps: 1,194,918,690
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.97564
Policy Entropy: 4.32822
Value Function Loss: 0.00271
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03338
Policy Update Magnitude: 1.02837
Value Function Update Magnitude: 0.84368
Collected Steps per Second: 12,940.88244
Overall Steps per Second: 7,193.21865
Timestep Collection Time: 3.86388
Timestep Consumption Time: 3.08739
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.95127
Cumulative Model Updates: 149,177
Cumulative Timesteps: 1,194,968,692
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1194968692...
Checkpoint 1194968692 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.29431
Policy Entropy: 4.32938
Value Function Loss: 0.00274
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 1.03902
Value Function Update Magnitude: 0.87464
Collected Steps per Second: 12,922.57740
Overall Steps per Second: 7,180.62476
Timestep Collection Time: 3.87198
Timestep Consumption Time: 3.09621
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.96820
Cumulative Model Updates: 149,186
Cumulative Timesteps: 1,195,018,728
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.32734
Policy Entropy: 4.32385
Value Function Loss: 0.00295
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03588
Policy Update Magnitude: 1.07128
Value Function Update Magnitude: 0.86980
Collected Steps per Second: 12,872.89279
Overall Steps per Second: 7,258.69062
Timestep Collection Time: 3.88568
Timestep Consumption Time: 3.00537
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 6.89105
Cumulative Model Updates: 149,195
Cumulative Timesteps: 1,195,068,748
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1195068748...
Checkpoint 1195068748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69834
Policy Entropy: 4.32492
Value Function Loss: 0.00284
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 1.06494
Value Function Update Magnitude: 0.87712
Collected Steps per Second: 12,956.52028
Overall Steps per Second: 7,179.39542
Timestep Collection Time: 3.86168
Timestep Consumption Time: 3.10743
PPO Batch Consumption Time: 0.22941
Total Iteration Time: 6.96911
Cumulative Model Updates: 149,204
Cumulative Timesteps: 1,195,118,782
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.90851
Policy Entropy: 4.32739
Value Function Loss: 0.00286
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03772
Policy Update Magnitude: 1.04675
Value Function Update Magnitude: 0.85852
Collected Steps per Second: 12,896.85100
Overall Steps per Second: 7,195.17084
Timestep Collection Time: 3.87878
Timestep Consumption Time: 3.07366
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.95244
Cumulative Model Updates: 149,213
Cumulative Timesteps: 1,195,168,806
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1195168806...
Checkpoint 1195168806 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29503
Policy Entropy: 4.32902
Value Function Loss: 0.00282
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03657
Policy Update Magnitude: 1.05368
Value Function Update Magnitude: 0.87334
Collected Steps per Second: 13,067.43156
Overall Steps per Second: 7,135.92719
Timestep Collection Time: 3.82768
Timestep Consumption Time: 3.18164
PPO Batch Consumption Time: 0.23647
Total Iteration Time: 7.00932
Cumulative Model Updates: 149,222
Cumulative Timesteps: 1,195,218,824
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87440
Policy Entropy: 4.32800
Value Function Loss: 0.00287
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03487
Policy Update Magnitude: 1.06952
Value Function Update Magnitude: 0.84678
Collected Steps per Second: 13,047.62281
Overall Steps per Second: 7,217.20902
Timestep Collection Time: 3.83396
Timestep Consumption Time: 3.09726
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.93121
Cumulative Model Updates: 149,231
Cumulative Timesteps: 1,195,268,848
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1195268848...
Checkpoint 1195268848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.86045
Policy Entropy: 4.32569
Value Function Loss: 0.00288
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03344
Policy Update Magnitude: 1.07263
Value Function Update Magnitude: 0.82099
Collected Steps per Second: 13,046.74593
Overall Steps per Second: 7,216.07354
Timestep Collection Time: 3.83667
Timestep Consumption Time: 3.10007
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.93674
Cumulative Model Updates: 149,240
Cumulative Timesteps: 1,195,318,904
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.93433
Policy Entropy: 4.32750
Value Function Loss: 0.00284
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03174
Policy Update Magnitude: 1.06584
Value Function Update Magnitude: 0.81731
Collected Steps per Second: 12,816.09541
Overall Steps per Second: 7,235.73074
Timestep Collection Time: 3.90384
Timestep Consumption Time: 3.01073
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.91457
Cumulative Model Updates: 149,249
Cumulative Timesteps: 1,195,368,936
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1195368936...
Checkpoint 1195368936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.94718
Policy Entropy: 4.32498
Value Function Loss: 0.00284
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 1.06645
Value Function Update Magnitude: 0.82798
Collected Steps per Second: 12,963.11497
Overall Steps per Second: 7,175.16086
Timestep Collection Time: 3.85833
Timestep Consumption Time: 3.11238
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.97071
Cumulative Model Updates: 149,258
Cumulative Timesteps: 1,195,418,952
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.93872
Policy Entropy: 4.32371
Value Function Loss: 0.00275
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03625
Policy Update Magnitude: 1.04575
Value Function Update Magnitude: 0.82861
Collected Steps per Second: 12,887.70037
Overall Steps per Second: 7,181.83430
Timestep Collection Time: 3.88200
Timestep Consumption Time: 3.08419
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.96619
Cumulative Model Updates: 149,267
Cumulative Timesteps: 1,195,468,982
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1195468982...
Checkpoint 1195468982 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.62283
Policy Entropy: 4.31951
Value Function Loss: 0.00275
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03674
Policy Update Magnitude: 1.02664
Value Function Update Magnitude: 0.82021
Collected Steps per Second: 13,131.98326
Overall Steps per Second: 7,228.93931
Timestep Collection Time: 3.80948
Timestep Consumption Time: 3.11076
PPO Batch Consumption Time: 0.22923
Total Iteration Time: 6.92024
Cumulative Model Updates: 149,276
Cumulative Timesteps: 1,195,519,008
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.00056
Policy Entropy: 4.32223
Value Function Loss: 0.00267
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 1.01431
Value Function Update Magnitude: 0.82338
Collected Steps per Second: 12,858.28692
Overall Steps per Second: 7,078.26451
Timestep Collection Time: 3.88901
Timestep Consumption Time: 3.17572
PPO Batch Consumption Time: 0.23094
Total Iteration Time: 7.06473
Cumulative Model Updates: 149,285
Cumulative Timesteps: 1,195,569,014
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1195569014...
Checkpoint 1195569014 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.11573
Policy Entropy: 4.32371
Value Function Loss: 0.00263
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 1.01681
Value Function Update Magnitude: 0.80878
Collected Steps per Second: 12,873.78406
Overall Steps per Second: 7,185.32358
Timestep Collection Time: 3.88573
Timestep Consumption Time: 3.07624
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.96197
Cumulative Model Updates: 149,294
Cumulative Timesteps: 1,195,619,038
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66150
Policy Entropy: 4.32683
Value Function Loss: 0.00259
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03126
Policy Update Magnitude: 0.99976
Value Function Update Magnitude: 0.79409
Collected Steps per Second: 13,096.78633
Overall Steps per Second: 7,211.47263
Timestep Collection Time: 3.82017
Timestep Consumption Time: 3.11766
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.93783
Cumulative Model Updates: 149,303
Cumulative Timesteps: 1,195,669,070
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1195669070...
Checkpoint 1195669070 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.13677
Policy Entropy: 4.32374
Value Function Loss: 0.00277
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 1.00974
Value Function Update Magnitude: 0.78069
Collected Steps per Second: 12,995.83902
Overall Steps per Second: 7,201.87372
Timestep Collection Time: 3.84739
Timestep Consumption Time: 3.09525
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.94264
Cumulative Model Updates: 149,312
Cumulative Timesteps: 1,195,719,070
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.26968
Policy Entropy: 4.32275
Value Function Loss: 0.00278
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 1.01209
Value Function Update Magnitude: 0.80442
Collected Steps per Second: 12,948.81462
Overall Steps per Second: 7,199.68778
Timestep Collection Time: 3.86275
Timestep Consumption Time: 3.08450
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.94725
Cumulative Model Updates: 149,321
Cumulative Timesteps: 1,195,769,088
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1195769088...
Checkpoint 1195769088 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.40348
Policy Entropy: 4.32279
Value Function Loss: 0.00288
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03290
Policy Update Magnitude: 1.03004
Value Function Update Magnitude: 0.84681
Collected Steps per Second: 13,233.62227
Overall Steps per Second: 7,276.14854
Timestep Collection Time: 3.78007
Timestep Consumption Time: 3.09500
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.87507
Cumulative Model Updates: 149,330
Cumulative Timesteps: 1,195,819,112
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66149
Policy Entropy: 4.32254
Value Function Loss: 0.00282
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03283
Policy Update Magnitude: 1.03275
Value Function Update Magnitude: 0.85871
Collected Steps per Second: 13,059.70924
Overall Steps per Second: 7,203.80054
Timestep Collection Time: 3.83087
Timestep Consumption Time: 3.11408
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.94495
Cumulative Model Updates: 149,339
Cumulative Timesteps: 1,195,869,142
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1195869142...
Checkpoint 1195869142 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.82126
Policy Entropy: 4.32174
Value Function Loss: 0.00285
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03467
Policy Update Magnitude: 1.02295
Value Function Update Magnitude: 0.85943
Collected Steps per Second: 12,892.38921
Overall Steps per Second: 7,046.92563
Timestep Collection Time: 3.87826
Timestep Consumption Time: 3.21704
PPO Batch Consumption Time: 0.24042
Total Iteration Time: 7.09529
Cumulative Model Updates: 149,348
Cumulative Timesteps: 1,195,919,142
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51210
Policy Entropy: 4.32565
Value Function Loss: 0.00279
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03241
Policy Update Magnitude: 1.02360
Value Function Update Magnitude: 0.82436
Collected Steps per Second: 13,247.12212
Overall Steps per Second: 7,267.71778
Timestep Collection Time: 3.77440
Timestep Consumption Time: 3.10533
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 6.87974
Cumulative Model Updates: 149,357
Cumulative Timesteps: 1,195,969,142
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1195969142...
Checkpoint 1195969142 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.55230
Policy Entropy: 4.32166
Value Function Loss: 0.00290
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 1.03258
Value Function Update Magnitude: 0.81876
Collected Steps per Second: 13,007.58570
Overall Steps per Second: 7,180.09962
Timestep Collection Time: 3.84591
Timestep Consumption Time: 3.12140
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.96731
Cumulative Model Updates: 149,366
Cumulative Timesteps: 1,196,019,168
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.48217
Policy Entropy: 4.32122
Value Function Loss: 0.00296
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03483
Policy Update Magnitude: 1.04204
Value Function Update Magnitude: 0.82479
Collected Steps per Second: 12,960.11357
Overall Steps per Second: 7,220.48445
Timestep Collection Time: 3.85969
Timestep Consumption Time: 3.06810
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.92779
Cumulative Model Updates: 149,375
Cumulative Timesteps: 1,196,069,190
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1196069190...
Checkpoint 1196069190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05544
Policy Entropy: 4.31655
Value Function Loss: 0.00290
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 1.02598
Value Function Update Magnitude: 0.79918
Collected Steps per Second: 13,150.27207
Overall Steps per Second: 7,237.02297
Timestep Collection Time: 3.80479
Timestep Consumption Time: 3.10883
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.91362
Cumulative Model Updates: 149,384
Cumulative Timesteps: 1,196,119,224
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.31028
Policy Entropy: 4.31632
Value Function Loss: 0.00288
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03328
Policy Update Magnitude: 1.03602
Value Function Update Magnitude: 0.81312
Collected Steps per Second: 12,902.24118
Overall Steps per Second: 7,168.09878
Timestep Collection Time: 3.87638
Timestep Consumption Time: 3.10092
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.97730
Cumulative Model Updates: 149,393
Cumulative Timesteps: 1,196,169,238
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1196169238...
Checkpoint 1196169238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.57942
Policy Entropy: 4.31982
Value Function Loss: 0.00274
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03306
Policy Update Magnitude: 1.03973
Value Function Update Magnitude: 0.79786
Collected Steps per Second: 12,917.19968
Overall Steps per Second: 7,183.86193
Timestep Collection Time: 3.87267
Timestep Consumption Time: 3.09072
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.96339
Cumulative Model Updates: 149,402
Cumulative Timesteps: 1,196,219,262
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33543
Policy Entropy: 4.31780
Value Function Loss: 0.00286
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 1.04346
Value Function Update Magnitude: 0.79748
Collected Steps per Second: 13,238.42935
Overall Steps per Second: 7,200.63654
Timestep Collection Time: 3.77930
Timestep Consumption Time: 3.16897
PPO Batch Consumption Time: 0.23036
Total Iteration Time: 6.94827
Cumulative Model Updates: 149,411
Cumulative Timesteps: 1,196,269,294
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1196269294...
Checkpoint 1196269294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.89199
Policy Entropy: 4.32362
Value Function Loss: 0.00281
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03692
Policy Update Magnitude: 1.05555
Value Function Update Magnitude: 0.79974
Collected Steps per Second: 13,041.54124
Overall Steps per Second: 7,208.46166
Timestep Collection Time: 3.83421
Timestep Consumption Time: 3.10264
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.93685
Cumulative Model Updates: 149,420
Cumulative Timesteps: 1,196,319,298
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.57911
Policy Entropy: 4.31757
Value Function Loss: 0.00290
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03828
Policy Update Magnitude: 1.06056
Value Function Update Magnitude: 0.80698
Collected Steps per Second: 12,943.73244
Overall Steps per Second: 7,198.13926
Timestep Collection Time: 3.86473
Timestep Consumption Time: 3.08485
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.94957
Cumulative Model Updates: 149,429
Cumulative Timesteps: 1,196,369,322
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1196369322...
Checkpoint 1196369322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51662
Policy Entropy: 4.31676
Value Function Loss: 0.00292
Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03901
Policy Update Magnitude: 1.05890
Value Function Update Magnitude: 0.80736
Collected Steps per Second: 13,286.38043
Overall Steps per Second: 7,279.69051
Timestep Collection Time: 3.76340
Timestep Consumption Time: 3.10530
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.86870
Cumulative Model Updates: 149,438
Cumulative Timesteps: 1,196,419,324
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.40016
Policy Entropy: 4.32089
Value Function Loss: 0.00283
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03680
Policy Update Magnitude: 1.04350
Value Function Update Magnitude: 0.80203
Collected Steps per Second: 13,039.15887
Overall Steps per Second: 7,222.01844
Timestep Collection Time: 3.83920
Timestep Consumption Time: 3.09238
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.93158
Cumulative Model Updates: 149,447
Cumulative Timesteps: 1,196,469,384
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 1196469384...
Checkpoint 1196469384 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53325
Policy Entropy: 4.32189
Value Function Loss: 0.00280
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03401
Policy Update Magnitude: 1.01791
Value Function Update Magnitude: 0.79976
Collected Steps per Second: 12,943.23894
Overall Steps per Second: 7,196.72119
Timestep Collection Time: 3.86596
Timestep Consumption Time: 3.08693
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.95289
Cumulative Model Updates: 149,456
Cumulative Timesteps: 1,196,519,422
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.36823
Policy Entropy: 4.32359
Value Function Loss: 0.00282
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 1.02648
Value Function Update Magnitude: 0.80400
Collected Steps per Second: 13,065.10326
Overall Steps per Second: 7,217.63357
Timestep Collection Time: 3.82928
Timestep Consumption Time: 3.10235
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.93163
Cumulative Model Updates: 149,465
Cumulative Timesteps: 1,196,569,452
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1196569452...
Checkpoint 1196569452 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.00181
Policy Entropy: 4.31997
Value Function Loss: 0.00285
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03159
Policy Update Magnitude: 1.04123
Value Function Update Magnitude: 0.81735
Collected Steps per Second: 12,944.32919
Overall Steps per Second: 7,106.09792
Timestep Collection Time: 3.86594
Timestep Consumption Time: 3.17618
PPO Batch Consumption Time: 0.23126
Total Iteration Time: 7.04212
Cumulative Model Updates: 149,474
Cumulative Timesteps: 1,196,619,494
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33476
Policy Entropy: 4.31420
Value Function Loss: 0.00301
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 1.05076
Value Function Update Magnitude: 0.83915
Collected Steps per Second: 12,945.75570
Overall Steps per Second: 7,184.75370
Timestep Collection Time: 3.86227
Timestep Consumption Time: 3.09691
PPO Batch Consumption Time: 0.23021
Total Iteration Time: 6.95918
Cumulative Model Updates: 149,483
Cumulative Timesteps: 1,196,669,494
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1196669494...
Checkpoint 1196669494 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 9.87342
Policy Entropy: 4.31491
Value Function Loss: 0.00282
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03354
Policy Update Magnitude: 1.05368
Value Function Update Magnitude: 0.82091
Collected Steps per Second: 13,167.16108
Overall Steps per Second: 7,234.32562
Timestep Collection Time: 3.79869
Timestep Consumption Time: 3.11529
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.91398
Cumulative Model Updates: 149,492
Cumulative Timesteps: 1,196,719,512
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21049
Policy Entropy: 4.31860
Value Function Loss: 0.00275
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03318
Policy Update Magnitude: 1.01388
Value Function Update Magnitude: 0.81753
Collected Steps per Second: 13,038.22346
Overall Steps per Second: 7,198.60389
Timestep Collection Time: 3.83749
Timestep Consumption Time: 3.11303
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.95051
Cumulative Model Updates: 149,501
Cumulative Timesteps: 1,196,769,546
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1196769546...
Checkpoint 1196769546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38190
Policy Entropy: 4.32097
Value Function Loss: 0.00268
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 0.99288
Value Function Update Magnitude: 0.80336
Collected Steps per Second: 13,116.07609
Overall Steps per Second: 7,129.86790
Timestep Collection Time: 3.81440
Timestep Consumption Time: 3.20256
PPO Batch Consumption Time: 0.22957
Total Iteration Time: 7.01696
Cumulative Model Updates: 149,510
Cumulative Timesteps: 1,196,819,576
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.84150
Policy Entropy: 4.32036
Value Function Loss: 0.00273
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03575
Policy Update Magnitude: 0.99699
Value Function Update Magnitude: 0.82403
Collected Steps per Second: 13,130.17563
Overall Steps per Second: 7,224.10704
Timestep Collection Time: 3.80817
Timestep Consumption Time: 3.11337
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.92155
Cumulative Model Updates: 149,519
Cumulative Timesteps: 1,196,869,578
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1196869578...
Checkpoint 1196869578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.87200
Policy Entropy: 4.31573
Value Function Loss: 0.00279
Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03882
Policy Update Magnitude: 1.01805
Value Function Update Magnitude: 0.83736
Collected Steps per Second: 13,107.12429
Overall Steps per Second: 7,204.49593
Timestep Collection Time: 3.81472
Timestep Consumption Time: 3.12539
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.94011
Cumulative Model Updates: 149,528
Cumulative Timesteps: 1,196,919,578
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01808
Policy Entropy: 4.31217
Value Function Loss: 0.00277
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03508
Policy Update Magnitude: 1.01314
Value Function Update Magnitude: 0.84115
Collected Steps per Second: 12,749.69512
Overall Steps per Second: 7,066.43299
Timestep Collection Time: 3.92402
Timestep Consumption Time: 3.15594
PPO Batch Consumption Time: 0.23144
Total Iteration Time: 7.07995
Cumulative Model Updates: 149,537
Cumulative Timesteps: 1,196,969,608
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1196969608...
Checkpoint 1196969608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.77030
Policy Entropy: 4.31073
Value Function Loss: 0.00275
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03355
Policy Update Magnitude: 1.01082
Value Function Update Magnitude: 0.84248
Collected Steps per Second: 13,157.95601
Overall Steps per Second: 7,248.04081
Timestep Collection Time: 3.80120
Timestep Consumption Time: 3.09943
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.90062
Cumulative Model Updates: 149,546
Cumulative Timesteps: 1,197,019,624
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12434
Policy Entropy: 4.30957
Value Function Loss: 0.00276
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03318
Policy Update Magnitude: 1.00963
Value Function Update Magnitude: 0.82808
Collected Steps per Second: 12,970.95387
Overall Steps per Second: 7,151.42550
Timestep Collection Time: 3.85507
Timestep Consumption Time: 3.13710
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.99217
Cumulative Model Updates: 149,555
Cumulative Timesteps: 1,197,069,628
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1197069628...
Checkpoint 1197069628 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.50989
Policy Entropy: 4.31337
Value Function Loss: 0.00276
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03392
Policy Update Magnitude: 1.00517
Value Function Update Magnitude: 0.82015
Collected Steps per Second: 12,855.14100
Overall Steps per Second: 7,257.88999
Timestep Collection Time: 3.89089
Timestep Consumption Time: 3.00064
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.89153
Cumulative Model Updates: 149,564
Cumulative Timesteps: 1,197,119,646
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.74200
Policy Entropy: 4.31464
Value Function Loss: 0.00277
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03388
Policy Update Magnitude: 1.00140
Value Function Update Magnitude: 0.80261
Collected Steps per Second: 12,971.47355
Overall Steps per Second: 7,175.23945
Timestep Collection Time: 3.85646
Timestep Consumption Time: 3.11529
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.97175
Cumulative Model Updates: 149,573
Cumulative Timesteps: 1,197,169,670
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1197169670...
Checkpoint 1197169670 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.18986
Policy Entropy: 4.31761
Value Function Loss: 0.00260
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 0.97787
Value Function Update Magnitude: 0.81038
Collected Steps per Second: 12,842.38091
Overall Steps per Second: 7,181.30597
Timestep Collection Time: 3.89538
Timestep Consumption Time: 3.07076
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.96614
Cumulative Model Updates: 149,582
Cumulative Timesteps: 1,197,219,696
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.98728
Policy Entropy: 4.32234
Value Function Loss: 0.00257
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 0.97414
Value Function Update Magnitude: 0.80385
Collected Steps per Second: 12,889.32377
Overall Steps per Second: 7,261.18238
Timestep Collection Time: 3.88135
Timestep Consumption Time: 3.00844
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.88979
Cumulative Model Updates: 149,591
Cumulative Timesteps: 1,197,269,724
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1197269724...
Checkpoint 1197269724 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01797
Policy Entropy: 4.32156
Value Function Loss: 0.00260
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03308
Policy Update Magnitude: 0.99022
Value Function Update Magnitude: 0.81526
Collected Steps per Second: 12,973.85148
Overall Steps per Second: 7,123.26383
Timestep Collection Time: 3.85421
Timestep Consumption Time: 3.16560
PPO Batch Consumption Time: 0.22999
Total Iteration Time: 7.01982
Cumulative Model Updates: 149,600
Cumulative Timesteps: 1,197,319,728
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.30853
Policy Entropy: 4.31933
Value Function Loss: 0.00266
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03226
Policy Update Magnitude: 1.00724
Value Function Update Magnitude: 0.80256
Collected Steps per Second: 13,092.10943
Overall Steps per Second: 7,230.75802
Timestep Collection Time: 3.82062
Timestep Consumption Time: 3.09705
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.91767
Cumulative Model Updates: 149,609
Cumulative Timesteps: 1,197,369,748
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1197369748...
Checkpoint 1197369748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54975
Policy Entropy: 4.31607
Value Function Loss: 0.00268
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03241
Policy Update Magnitude: 1.00268
Value Function Update Magnitude: 0.81798
Collected Steps per Second: 12,988.57749
Overall Steps per Second: 7,284.01928
Timestep Collection Time: 3.85169
Timestep Consumption Time: 3.01649
PPO Batch Consumption Time: 0.22937
Total Iteration Time: 6.86819
Cumulative Model Updates: 149,618
Cumulative Timesteps: 1,197,419,776
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40038
Policy Entropy: 4.31674
Value Function Loss: 0.00282
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 1.02411
Value Function Update Magnitude: 0.82083
Collected Steps per Second: 12,963.56358
Overall Steps per Second: 7,169.99706
Timestep Collection Time: 3.86020
Timestep Consumption Time: 3.11916
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.97936
Cumulative Model Updates: 149,627
Cumulative Timesteps: 1,197,469,818
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1197469818...
Checkpoint 1197469818 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.59954
Policy Entropy: 4.31891
Value Function Loss: 0.00273
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03497
Policy Update Magnitude: 1.02101
Value Function Update Magnitude: 0.83870
Collected Steps per Second: 12,954.87740
Overall Steps per Second: 7,229.21255
Timestep Collection Time: 3.86063
Timestep Consumption Time: 3.05769
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.91832
Cumulative Model Updates: 149,636
Cumulative Timesteps: 1,197,519,832
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.28510
Policy Entropy: 4.32050
Value Function Loss: 0.00272
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03256
Policy Update Magnitude: 1.02834
Value Function Update Magnitude: 0.81815
Collected Steps per Second: 12,972.62834
Overall Steps per Second: 7,306.23166
Timestep Collection Time: 3.85458
Timestep Consumption Time: 2.98944
PPO Batch Consumption Time: 0.22780
Total Iteration Time: 6.84402
Cumulative Model Updates: 149,645
Cumulative Timesteps: 1,197,569,836
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1197569836...
Checkpoint 1197569836 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.96226
Policy Entropy: 4.31791
Value Function Loss: 0.00271
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03359
Policy Update Magnitude: 1.04668
Value Function Update Magnitude: 0.81360
Collected Steps per Second: 12,880.63815
Overall Steps per Second: 7,139.67631
Timestep Collection Time: 3.88428
Timestep Consumption Time: 3.12332
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 7.00760
Cumulative Model Updates: 149,654
Cumulative Timesteps: 1,197,619,868
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.10348
Policy Entropy: 4.31664
Value Function Loss: 0.00279
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03653
Policy Update Magnitude: 1.03447
Value Function Update Magnitude: 0.81005
Collected Steps per Second: 12,748.35574
Overall Steps per Second: 6,998.80650
Timestep Collection Time: 3.92506
Timestep Consumption Time: 3.22445
PPO Batch Consumption Time: 0.23855
Total Iteration Time: 7.14950
Cumulative Model Updates: 149,663
Cumulative Timesteps: 1,197,669,906
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1197669906...
Checkpoint 1197669906 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.91534
Policy Entropy: 4.31439
Value Function Loss: 0.00280
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03643
Policy Update Magnitude: 1.04165
Value Function Update Magnitude: 0.82100
Collected Steps per Second: 13,173.74411
Overall Steps per Second: 7,233.16378
Timestep Collection Time: 3.79801
Timestep Consumption Time: 3.11930
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.91730
Cumulative Model Updates: 149,672
Cumulative Timesteps: 1,197,719,940
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85265
Policy Entropy: 4.31633
Value Function Loss: 0.00287
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03594
Policy Update Magnitude: 1.05268
Value Function Update Magnitude: 0.85088
Collected Steps per Second: 13,029.79672
Overall Steps per Second: 7,208.62458
Timestep Collection Time: 3.84027
Timestep Consumption Time: 3.10113
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.94141
Cumulative Model Updates: 149,681
Cumulative Timesteps: 1,197,769,978
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1197769978...
Checkpoint 1197769978 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.24067
Policy Entropy: 4.31517
Value Function Loss: 0.00285
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03546
Policy Update Magnitude: 1.03423
Value Function Update Magnitude: 0.86243
Collected Steps per Second: 12,980.02883
Overall Steps per Second: 7,210.19203
Timestep Collection Time: 3.85269
Timestep Consumption Time: 3.08305
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.93574
Cumulative Model Updates: 149,690
Cumulative Timesteps: 1,197,819,986
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.81233
Policy Entropy: 4.31221
Value Function Loss: 0.00283
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03657
Policy Update Magnitude: 1.03454
Value Function Update Magnitude: 0.88500
Collected Steps per Second: 13,264.33489
Overall Steps per Second: 7,257.05554
Timestep Collection Time: 3.77147
Timestep Consumption Time: 3.12196
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.89343
Cumulative Model Updates: 149,699
Cumulative Timesteps: 1,197,870,012
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1197870012...
Checkpoint 1197870012 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28684
Policy Entropy: 4.31430
Value Function Loss: 0.00270
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03630
Policy Update Magnitude: 1.03240
Value Function Update Magnitude: 0.88449
Collected Steps per Second: 12,971.43947
Overall Steps per Second: 7,175.01312
Timestep Collection Time: 3.85678
Timestep Consumption Time: 3.11575
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.97253
Cumulative Model Updates: 149,708
Cumulative Timesteps: 1,197,920,040
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42821
Policy Entropy: 4.32067
Value Function Loss: 0.00272
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03621
Policy Update Magnitude: 1.02906
Value Function Update Magnitude: 0.86256
Collected Steps per Second: 12,929.37799
Overall Steps per Second: 7,190.31981
Timestep Collection Time: 3.87010
Timestep Consumption Time: 3.08898
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.95908
Cumulative Model Updates: 149,717
Cumulative Timesteps: 1,197,970,078
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1197970078...
Checkpoint 1197970078 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.31249
Policy Entropy: 4.32390
Value Function Loss: 0.00282
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03424
Policy Update Magnitude: 1.02451
Value Function Update Magnitude: 0.87181
Collected Steps per Second: 13,193.70062
Overall Steps per Second: 7,213.35079
Timestep Collection Time: 3.79242
Timestep Consumption Time: 3.14417
PPO Batch Consumption Time: 0.22981
Total Iteration Time: 6.93658
Cumulative Model Updates: 149,726
Cumulative Timesteps: 1,198,020,114
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.96881
Policy Entropy: 4.31644
Value Function Loss: 0.00300
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03629
Policy Update Magnitude: 1.05475
Value Function Update Magnitude: 0.89010
Collected Steps per Second: 12,959.52575
Overall Steps per Second: 7,179.74718
Timestep Collection Time: 3.86064
Timestep Consumption Time: 3.10786
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.96849
Cumulative Model Updates: 149,735
Cumulative Timesteps: 1,198,070,146
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1198070146...
Checkpoint 1198070146 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.92102
Policy Entropy: 4.31357
Value Function Loss: 0.00294
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03635
Policy Update Magnitude: 1.06634
Value Function Update Magnitude: 0.86498
Collected Steps per Second: 12,796.27268
Overall Steps per Second: 7,164.56178
Timestep Collection Time: 3.90801
Timestep Consumption Time: 3.07190
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.97991
Cumulative Model Updates: 149,744
Cumulative Timesteps: 1,198,120,154
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.17696
Policy Entropy: 4.31104
Value Function Loss: 0.00285
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03574
Policy Update Magnitude: 1.06130
Value Function Update Magnitude: 0.81818
Collected Steps per Second: 13,285.44742
Overall Steps per Second: 7,283.78220
Timestep Collection Time: 3.76442
Timestep Consumption Time: 3.10179
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.86621
Cumulative Model Updates: 149,753
Cumulative Timesteps: 1,198,170,166
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1198170166...
Checkpoint 1198170166 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.92919
Policy Entropy: 4.31449
Value Function Loss: 0.00277
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03565
Policy Update Magnitude: 1.03697
Value Function Update Magnitude: 0.80891
Collected Steps per Second: 12,961.41221
Overall Steps per Second: 7,151.52055
Timestep Collection Time: 3.85976
Timestep Consumption Time: 3.13567
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.99544
Cumulative Model Updates: 149,762
Cumulative Timesteps: 1,198,220,194
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58256
Policy Entropy: 4.32027
Value Function Loss: 0.00269
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03370
Policy Update Magnitude: 1.02251
Value Function Update Magnitude: 0.80248
Collected Steps per Second: 12,751.12004
Overall Steps per Second: 7,123.91038
Timestep Collection Time: 3.92295
Timestep Consumption Time: 3.09876
PPO Batch Consumption Time: 0.22919
Total Iteration Time: 7.02171
Cumulative Model Updates: 149,771
Cumulative Timesteps: 1,198,270,216
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1198270216...
Checkpoint 1198270216 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01340
Policy Entropy: 4.31980
Value Function Loss: 0.00269
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03063
Policy Update Magnitude: 1.02666
Value Function Update Magnitude: 0.78302
Collected Steps per Second: 13,144.80682
Overall Steps per Second: 7,244.44601
Timestep Collection Time: 3.80896
Timestep Consumption Time: 3.10227
PPO Batch Consumption Time: 0.22944
Total Iteration Time: 6.91123
Cumulative Model Updates: 149,780
Cumulative Timesteps: 1,198,320,284
Timesteps Collected: 50,068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.52775
Policy Entropy: 4.31879
Value Function Loss: 0.00273
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03427
Policy Update Magnitude: 1.02813
Value Function Update Magnitude: 0.80942
Collected Steps per Second: 12,953.75148
Overall Steps per Second: 7,112.14536
Timestep Collection Time: 3.86297
Timestep Consumption Time: 3.17288
PPO Batch Consumption Time: 0.22987
Total Iteration Time: 7.03585
Cumulative Model Updates: 149,789
Cumulative Timesteps: 1,198,370,324
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1198370324...
Checkpoint 1198370324 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58537
Policy Entropy: 4.31496
Value Function Loss: 0.00290
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03449
Policy Update Magnitude: 1.05728
Value Function Update Magnitude: 0.81678
Collected Steps per Second: 13,046.83449
Overall Steps per Second: 7,231.44552
Timestep Collection Time: 3.83557
Timestep Consumption Time: 3.08449
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.92005
Cumulative Model Updates: 149,798
Cumulative Timesteps: 1,198,420,366
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.79101
Policy Entropy: 4.31294
Value Function Loss: 0.00304
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03480
Policy Update Magnitude: 1.08387
Value Function Update Magnitude: 0.83257
Collected Steps per Second: 13,352.39568
Overall Steps per Second: 7,294.68525
Timestep Collection Time: 3.74644
Timestep Consumption Time: 3.11115
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.85760
Cumulative Model Updates: 149,807
Cumulative Timesteps: 1,198,470,390
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1198470390...
Checkpoint 1198470390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00260
Policy Entropy: 4.31484
Value Function Loss: 0.00295
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03651
Policy Update Magnitude: 1.08225
Value Function Update Magnitude: 0.85047
Collected Steps per Second: 12,782.48065
Overall Steps per Second: 7,135.14135
Timestep Collection Time: 3.91426
Timestep Consumption Time: 3.09807
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 7.01233
Cumulative Model Updates: 149,816
Cumulative Timesteps: 1,198,520,424
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.45208
Policy Entropy: 4.31938
Value Function Loss: 0.00280
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03390
Policy Update Magnitude: 1.04051
Value Function Update Magnitude: 0.82435
Collected Steps per Second: 12,896.04610
Overall Steps per Second: 7,268.94602
Timestep Collection Time: 3.87778
Timestep Consumption Time: 3.00190
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.87968
Cumulative Model Updates: 149,825
Cumulative Timesteps: 1,198,570,432
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1198570432...
Checkpoint 1198570432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.33796
Policy Entropy: 4.32103
Value Function Loss: 0.00264
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 1.00262
Value Function Update Magnitude: 0.78959
Collected Steps per Second: 13,026.71096
Overall Steps per Second: 7,191.10008
Timestep Collection Time: 3.83827
Timestep Consumption Time: 3.11477
PPO Batch Consumption Time: 0.22943
Total Iteration Time: 6.95304
Cumulative Model Updates: 149,834
Cumulative Timesteps: 1,198,620,432
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19787
Policy Entropy: 4.32345
Value Function Loss: 0.00259
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03210
Policy Update Magnitude: 1.00226
Value Function Update Magnitude: 0.78282
Collected Steps per Second: 12,882.70478
Overall Steps per Second: 7,176.80384
Timestep Collection Time: 3.88304
Timestep Consumption Time: 3.08720
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.97023
Cumulative Model Updates: 149,843
Cumulative Timesteps: 1,198,670,456
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1198670456...
Checkpoint 1198670456 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61895
Policy Entropy: 4.32002
Value Function Loss: 0.00265
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 1.01550
Value Function Update Magnitude: 0.78934
Collected Steps per Second: 12,812.29587
Overall Steps per Second: 7,184.57801
Timestep Collection Time: 3.90297
Timestep Consumption Time: 3.05722
PPO Batch Consumption Time: 0.23063
Total Iteration Time: 6.96019
Cumulative Model Updates: 149,852
Cumulative Timesteps: 1,198,720,462
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00849
Policy Entropy: 4.31840
Value Function Loss: 0.00267
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 1.01849
Value Function Update Magnitude: 0.80806
Collected Steps per Second: 13,015.21849
Overall Steps per Second: 7,189.82085
Timestep Collection Time: 3.84166
Timestep Consumption Time: 3.11262
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.95428
Cumulative Model Updates: 149,861
Cumulative Timesteps: 1,198,770,462
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1198770462...
Checkpoint 1198770462 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.32742
Policy Entropy: 4.31719
Value Function Loss: 0.00269
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03101
Policy Update Magnitude: 1.03098
Value Function Update Magnitude: 0.81212
Collected Steps per Second: 12,798.50024
Overall Steps per Second: 7,154.09842
Timestep Collection Time: 3.90890
Timestep Consumption Time: 3.08402
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.99291
Cumulative Model Updates: 149,870
Cumulative Timesteps: 1,198,820,490
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06022
Policy Entropy: 4.32007
Value Function Loss: 0.00260
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03372
Policy Update Magnitude: 1.02093
Value Function Update Magnitude: 0.81172
Collected Steps per Second: 12,876.34142
Overall Steps per Second: 7,240.66133
Timestep Collection Time: 3.88589
Timestep Consumption Time: 3.02453
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.91042
Cumulative Model Updates: 149,879
Cumulative Timesteps: 1,198,870,526
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1198870526...
Checkpoint 1198870526 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.17482
Policy Entropy: 4.32186
Value Function Loss: 0.00265
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 1.01363
Value Function Update Magnitude: 0.80012
Collected Steps per Second: 12,919.00684
Overall Steps per Second: 7,144.78799
Timestep Collection Time: 3.87104
Timestep Consumption Time: 3.12847
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.99951
Cumulative Model Updates: 149,888
Cumulative Timesteps: 1,198,920,536
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67637
Policy Entropy: 4.32248
Value Function Loss: 0.00261
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 1.00808
Value Function Update Magnitude: 0.80757
Collected Steps per Second: 12,890.56099
Overall Steps per Second: 7,176.98683
Timestep Collection Time: 3.87958
Timestep Consumption Time: 3.08852
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.96811
Cumulative Model Updates: 149,897
Cumulative Timesteps: 1,198,970,546
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1198970546...
Checkpoint 1198970546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27017
Policy Entropy: 4.32277
Value Function Loss: 0.00257
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 1.00005
Value Function Update Magnitude: 0.83049
Collected Steps per Second: 12,714.22225
Overall Steps per Second: 7,225.40502
Timestep Collection Time: 3.93260
Timestep Consumption Time: 2.98742
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.92003
Cumulative Model Updates: 149,906
Cumulative Timesteps: 1,199,020,546
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.81220
Policy Entropy: 4.32044
Value Function Loss: 0.00260
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03287
Policy Update Magnitude: 1.01720
Value Function Update Magnitude: 0.81550
Collected Steps per Second: 12,953.57423
Overall Steps per Second: 7,114.09053
Timestep Collection Time: 3.86056
Timestep Consumption Time: 3.16887
PPO Batch Consumption Time: 0.23023
Total Iteration Time: 7.02943
Cumulative Model Updates: 149,915
Cumulative Timesteps: 1,199,070,554
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1199070554...
Checkpoint 1199070554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05253
Policy Entropy: 4.32528
Value Function Loss: 0.00257
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 1.01186
Value Function Update Magnitude: 0.82104
Collected Steps per Second: 12,898.64617
Overall Steps per Second: 7,188.10377
Timestep Collection Time: 3.87917
Timestep Consumption Time: 3.08178
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.96095
Cumulative Model Updates: 149,924
Cumulative Timesteps: 1,199,120,590
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06865
Policy Entropy: 4.33040
Value Function Loss: 0.00257
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 1.00992
Value Function Update Magnitude: 0.80703
Collected Steps per Second: 12,838.28466
Overall Steps per Second: 7,235.01176
Timestep Collection Time: 3.89647
Timestep Consumption Time: 3.01769
PPO Batch Consumption Time: 0.22980
Total Iteration Time: 6.91416
Cumulative Model Updates: 149,933
Cumulative Timesteps: 1,199,170,614
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1199170614...
Checkpoint 1199170614 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.88017
Policy Entropy: 4.33285
Value Function Loss: 0.00245
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02961
Policy Update Magnitude: 0.99575
Value Function Update Magnitude: 0.79496
Collected Steps per Second: 12,982.10600
Overall Steps per Second: 7,172.89732
Timestep Collection Time: 3.85192
Timestep Consumption Time: 3.11960
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.97152
Cumulative Model Updates: 149,942
Cumulative Timesteps: 1,199,220,620
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64683
Policy Entropy: 4.33068
Value Function Loss: 0.00263
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03020
Policy Update Magnitude: 1.00247
Value Function Update Magnitude: 0.79746
Collected Steps per Second: 12,967.14754
Overall Steps per Second: 7,208.06176
Timestep Collection Time: 3.85790
Timestep Consumption Time: 3.08238
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.94028
Cumulative Model Updates: 149,951
Cumulative Timesteps: 1,199,270,646
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1199270646...
Checkpoint 1199270646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04276
Policy Entropy: 4.32254
Value Function Loss: 0.00269
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 1.02303
Value Function Update Magnitude: 0.83598
Collected Steps per Second: 12,829.77003
Overall Steps per Second: 7,259.86333
Timestep Collection Time: 3.89828
Timestep Consumption Time: 2.99083
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.88911
Cumulative Model Updates: 149,960
Cumulative Timesteps: 1,199,320,660
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43708
Policy Entropy: 4.32124
Value Function Loss: 0.00275
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03380
Policy Update Magnitude: 1.04240
Value Function Update Magnitude: 0.82494
Collected Steps per Second: 12,961.02656
Overall Steps per Second: 7,185.23281
Timestep Collection Time: 3.85911
Timestep Consumption Time: 3.10211
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.96122
Cumulative Model Updates: 149,969
Cumulative Timesteps: 1,199,370,678
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1199370678...
Checkpoint 1199370678 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71223
Policy Entropy: 4.31713
Value Function Loss: 0.00266
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 1.03955
Value Function Update Magnitude: 0.82155
Collected Steps per Second: 12,951.14718
Overall Steps per Second: 7,225.60742
Timestep Collection Time: 3.86205
Timestep Consumption Time: 3.06027
PPO Batch Consumption Time: 0.23031
Total Iteration Time: 6.92232
Cumulative Model Updates: 149,978
Cumulative Timesteps: 1,199,420,696
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86468
Policy Entropy: 4.31939
Value Function Loss: 0.00267
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03316
Policy Update Magnitude: 1.03586
Value Function Update Magnitude: 0.83538
Collected Steps per Second: 13,118.00197
Overall Steps per Second: 7,222.31373
Timestep Collection Time: 3.81384
Timestep Consumption Time: 3.11330
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.92714
Cumulative Model Updates: 149,987
Cumulative Timesteps: 1,199,470,726
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1199470726...
Checkpoint 1199470726 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.94100
Policy Entropy: 4.32109
Value Function Loss: 0.00255
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03300
Policy Update Magnitude: 1.01445
Value Function Update Magnitude: 0.83379
Collected Steps per Second: 12,884.88042
Overall Steps per Second: 7,149.67224
Timestep Collection Time: 3.88207
Timestep Consumption Time: 3.11406
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.99612
Cumulative Model Updates: 149,996
Cumulative Timesteps: 1,199,520,746
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.09166
Policy Entropy: 4.32539
Value Function Loss: 0.00258
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03294
Policy Update Magnitude: 1.01791
Value Function Update Magnitude: 0.81982
Collected Steps per Second: 12,959.47894
Overall Steps per Second: 7,273.51809
Timestep Collection Time: 3.85926
Timestep Consumption Time: 3.01692
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.87618
Cumulative Model Updates: 150,005
Cumulative Timesteps: 1,199,570,760
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1199570760...
Checkpoint 1199570760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.65183
Policy Entropy: 4.32121
Value Function Loss: 0.00277
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03338
Policy Update Magnitude: 1.04267
Value Function Update Magnitude: 0.85231
Collected Steps per Second: 13,151.22640
Overall Steps per Second: 7,226.74050
Timestep Collection Time: 3.80254
Timestep Consumption Time: 3.11732
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.91986
Cumulative Model Updates: 150,014
Cumulative Timesteps: 1,199,620,768
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.59472
Policy Entropy: 4.32058
Value Function Loss: 0.00279
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03533
Policy Update Magnitude: 1.05283
Value Function Update Magnitude: 0.87627
Collected Steps per Second: 12,852.05641
Overall Steps per Second: 7,131.70944
Timestep Collection Time: 3.89323
Timestep Consumption Time: 3.12276
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 7.01599
Cumulative Model Updates: 150,023
Cumulative Timesteps: 1,199,670,804
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1199670804...
Checkpoint 1199670804 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06312
Policy Entropy: 4.31963
Value Function Loss: 0.00285
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03575
Policy Update Magnitude: 1.06580
Value Function Update Magnitude: 0.91246
Collected Steps per Second: 13,051.34009
Overall Steps per Second: 7,326.14998
Timestep Collection Time: 3.83394
Timestep Consumption Time: 2.99612
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.83005
Cumulative Model Updates: 150,032
Cumulative Timesteps: 1,199,720,842
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.23469
Policy Entropy: 4.31771
Value Function Loss: 0.00275
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03460
Policy Update Magnitude: 1.07825
Value Function Update Magnitude: 0.87996
Collected Steps per Second: 13,121.45702
Overall Steps per Second: 7,161.38018
Timestep Collection Time: 3.81101
Timestep Consumption Time: 3.17172
PPO Batch Consumption Time: 0.23372
Total Iteration Time: 6.98273
Cumulative Model Updates: 150,041
Cumulative Timesteps: 1,199,770,848
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1199770848...
Checkpoint 1199770848 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52733
Policy Entropy: 4.31759
Value Function Loss: 0.00269
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03559
Policy Update Magnitude: 1.05319
Value Function Update Magnitude: 0.81973
Collected Steps per Second: 12,979.30482
Overall Steps per Second: 7,169.07772
Timestep Collection Time: 3.85306
Timestep Consumption Time: 3.12274
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.97579
Cumulative Model Updates: 150,050
Cumulative Timesteps: 1,199,820,858
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.71977
Policy Entropy: 4.32114
Value Function Loss: 0.00258
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 1.02121
Value Function Update Magnitude: 0.78363
Collected Steps per Second: 12,912.66646
Overall Steps per Second: 7,271.98408
Timestep Collection Time: 3.87480
Timestep Consumption Time: 3.00558
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.88038
Cumulative Model Updates: 150,059
Cumulative Timesteps: 1,199,870,892
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1199870892...
Checkpoint 1199870892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79485
Policy Entropy: 4.32126
Value Function Loss: 0.00263
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 1.02544
Value Function Update Magnitude: 0.80151
Collected Steps per Second: 12,863.25149
Overall Steps per Second: 7,088.16573
Timestep Collection Time: 3.88953
Timestep Consumption Time: 3.16900
PPO Batch Consumption Time: 0.23021
Total Iteration Time: 7.05853
Cumulative Model Updates: 150,068
Cumulative Timesteps: 1,199,920,924
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36580
Policy Entropy: 4.32612
Value Function Loss: 0.00263
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03238
Policy Update Magnitude: 1.05078
Value Function Update Magnitude: 0.81727
Collected Steps per Second: 12,919.57639
Overall Steps per Second: 7,168.75806
Timestep Collection Time: 3.87288
Timestep Consumption Time: 3.10685
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.97973
Cumulative Model Updates: 150,077
Cumulative Timesteps: 1,199,970,960
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1199970960...
Checkpoint 1199970960 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02059
Policy Entropy: 4.32524
Value Function Loss: 0.00264
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 1.04236
Value Function Update Magnitude: 0.82154
Collected Steps per Second: 12,803.31522
Overall Steps per Second: 7,248.32833
Timestep Collection Time: 3.90789
Timestep Consumption Time: 2.99494
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.90283
Cumulative Model Updates: 150,086
Cumulative Timesteps: 1,200,020,994
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.73656
Policy Entropy: 4.33006
Value Function Loss: 0.00259
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03347
Policy Update Magnitude: 1.02827
Value Function Update Magnitude: 0.79936
Collected Steps per Second: 13,042.79491
Overall Steps per Second: 7,175.18223
Timestep Collection Time: 3.83660
Timestep Consumption Time: 3.13744
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.97404
Cumulative Model Updates: 150,095
Cumulative Timesteps: 1,200,071,034
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1200071034...
Checkpoint 1200071034 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99708
Policy Entropy: 4.32524
Value Function Loss: 0.00263
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03338
Policy Update Magnitude: 1.02798
Value Function Update Magnitude: 0.79090
Collected Steps per Second: 12,982.43602
Overall Steps per Second: 7,063.52948
Timestep Collection Time: 3.85244
Timestep Consumption Time: 3.22816
PPO Batch Consumption Time: 0.23601
Total Iteration Time: 7.08060
Cumulative Model Updates: 150,104
Cumulative Timesteps: 1,200,121,048
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.33910
Policy Entropy: 4.32620
Value Function Loss: 0.00261
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03119
Policy Update Magnitude: 1.02409
Value Function Update Magnitude: 0.80686
Collected Steps per Second: 12,805.41746
Overall Steps per Second: 7,232.60500
Timestep Collection Time: 3.90772
Timestep Consumption Time: 3.01095
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.91867
Cumulative Model Updates: 150,113
Cumulative Timesteps: 1,200,171,088
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1200171088...
Checkpoint 1200171088 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97890
Policy Entropy: 4.32268
Value Function Loss: 0.00256
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 1.01946
Value Function Update Magnitude: 0.78099
Collected Steps per Second: 12,899.14497
Overall Steps per Second: 7,164.13232
Timestep Collection Time: 3.87840
Timestep Consumption Time: 3.10472
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.98312
Cumulative Model Updates: 150,122
Cumulative Timesteps: 1,200,221,116
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31633
Policy Entropy: 4.32232
Value Function Loss: 0.00271
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03238
Policy Update Magnitude: 1.04047
Value Function Update Magnitude: 0.80470
Collected Steps per Second: 12,898.38064
Overall Steps per Second: 7,183.02037
Timestep Collection Time: 3.87909
Timestep Consumption Time: 3.08650
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.96559
Cumulative Model Updates: 150,131
Cumulative Timesteps: 1,200,271,150
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1200271150...
Checkpoint 1200271150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.53955
Policy Entropy: 4.32218
Value Function Loss: 0.00264
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 1.05193
Value Function Update Magnitude: 0.80756
Collected Steps per Second: 12,863.90491
Overall Steps per Second: 7,272.00954
Timestep Collection Time: 3.88716
Timestep Consumption Time: 2.98907
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.87623
Cumulative Model Updates: 150,140
Cumulative Timesteps: 1,200,321,154
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.14950
Policy Entropy: 4.32539
Value Function Loss: 0.00273
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03591
Policy Update Magnitude: 1.04464
Value Function Update Magnitude: 0.81689
Collected Steps per Second: 12,828.77782
Overall Steps per Second: 7,138.50862
Timestep Collection Time: 3.89936
Timestep Consumption Time: 3.10827
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 7.00763
Cumulative Model Updates: 150,149
Cumulative Timesteps: 1,200,371,178
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1200371178...
Checkpoint 1200371178 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.62543
Policy Entropy: 4.32526
Value Function Loss: 0.00270
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03361
Policy Update Magnitude: 1.03638
Value Function Update Magnitude: 0.80876
Collected Steps per Second: 12,872.09899
Overall Steps per Second: 7,121.28945
Timestep Collection Time: 3.88484
Timestep Consumption Time: 3.13721
PPO Batch Consumption Time: 0.22953
Total Iteration Time: 7.02204
Cumulative Model Updates: 150,158
Cumulative Timesteps: 1,200,421,184
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.96682
Policy Entropy: 4.32648
Value Function Loss: 0.00273
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03368
Policy Update Magnitude: 1.03127
Value Function Update Magnitude: 0.79378
Collected Steps per Second: 12,878.63772
Overall Steps per Second: 7,133.77199
Timestep Collection Time: 3.88271
Timestep Consumption Time: 3.12677
PPO Batch Consumption Time: 0.23725
Total Iteration Time: 7.00948
Cumulative Model Updates: 150,167
Cumulative Timesteps: 1,200,471,188
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1200471188...
Checkpoint 1200471188 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01638
Policy Entropy: 4.32636
Value Function Loss: 0.00268
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03333
Policy Update Magnitude: 1.03231
Value Function Update Magnitude: 0.77300
Collected Steps per Second: 13,031.22406
Overall Steps per Second: 7,199.15933
Timestep Collection Time: 3.83893
Timestep Consumption Time: 3.10993
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.94887
Cumulative Model Updates: 150,176
Cumulative Timesteps: 1,200,521,214
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27377
Policy Entropy: 4.32770
Value Function Loss: 0.00262
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 1.02651
Value Function Update Magnitude: 0.78181
Collected Steps per Second: 13,059.52967
Overall Steps per Second: 7,207.99185
Timestep Collection Time: 3.82862
Timestep Consumption Time: 3.10812
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.93674
Cumulative Model Updates: 150,185
Cumulative Timesteps: 1,200,571,214
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1200571214...
Checkpoint 1200571214 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.52040
Policy Entropy: 4.32818
Value Function Loss: 0.00257
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03217
Policy Update Magnitude: 1.01342
Value Function Update Magnitude: 0.77004
Collected Steps per Second: 12,793.51336
Overall Steps per Second: 7,228.67828
Timestep Collection Time: 3.91214
Timestep Consumption Time: 3.01167
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.92381
Cumulative Model Updates: 150,194
Cumulative Timesteps: 1,200,621,264
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.20313
Policy Entropy: 4.32620
Value Function Loss: 0.00264
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03170
Policy Update Magnitude: 1.02972
Value Function Update Magnitude: 0.75380
Collected Steps per Second: 12,952.87992
Overall Steps per Second: 7,174.51640
Timestep Collection Time: 3.86246
Timestep Consumption Time: 3.11083
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.97329
Cumulative Model Updates: 150,203
Cumulative Timesteps: 1,200,671,294
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1200671294...
Checkpoint 1200671294 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71705
Policy Entropy: 4.32527
Value Function Loss: 0.00275
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03256
Policy Update Magnitude: 1.05061
Value Function Update Magnitude: 0.76768
Collected Steps per Second: 12,915.28388
Overall Steps per Second: 7,189.11838
Timestep Collection Time: 3.87309
Timestep Consumption Time: 3.08493
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.95802
Cumulative Model Updates: 150,212
Cumulative Timesteps: 1,200,721,316
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70938
Policy Entropy: 4.32515
Value Function Loss: 0.00282
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03453
Policy Update Magnitude: 1.05750
Value Function Update Magnitude: 0.75570
Collected Steps per Second: 12,871.24823
Overall Steps per Second: 7,247.15200
Timestep Collection Time: 3.88696
Timestep Consumption Time: 3.01644
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.90340
Cumulative Model Updates: 150,221
Cumulative Timesteps: 1,200,771,346
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1200771346...
Checkpoint 1200771346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90816
Policy Entropy: 4.33004
Value Function Loss: 0.00280
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03380
Policy Update Magnitude: 1.05398
Value Function Update Magnitude: 0.75799
Collected Steps per Second: 12,848.76348
Overall Steps per Second: 7,018.39614
Timestep Collection Time: 3.89267
Timestep Consumption Time: 3.23374
PPO Batch Consumption Time: 0.23121
Total Iteration Time: 7.12641
Cumulative Model Updates: 150,230
Cumulative Timesteps: 1,200,821,362
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.06087
Policy Entropy: 4.32883
Value Function Loss: 0.00295
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03502
Policy Update Magnitude: 1.08538
Value Function Update Magnitude: 0.76981
Collected Steps per Second: 13,001.11271
Overall Steps per Second: 7,226.59614
Timestep Collection Time: 3.84690
Timestep Consumption Time: 3.07392
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.92082
Cumulative Model Updates: 150,239
Cumulative Timesteps: 1,200,871,376
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1200871376...
Checkpoint 1200871376 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01432
Policy Entropy: 4.33085
Value Function Loss: 0.00300
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03754
Policy Update Magnitude: 1.09330
Value Function Update Magnitude: 0.79788
Collected Steps per Second: 12,858.14843
Overall Steps per Second: 7,251.25987
Timestep Collection Time: 3.88874
Timestep Consumption Time: 3.00689
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.89563
Cumulative Model Updates: 150,248
Cumulative Timesteps: 1,200,921,378
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.30833
Policy Entropy: 4.32887
Value Function Loss: 0.00309
Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03753
Policy Update Magnitude: 1.10928
Value Function Update Magnitude: 0.84365
Collected Steps per Second: 12,887.54923
Overall Steps per Second: 7,147.07933
Timestep Collection Time: 3.87971
Timestep Consumption Time: 3.11615
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.99586
Cumulative Model Updates: 150,257
Cumulative Timesteps: 1,200,971,378
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1200971378...
Checkpoint 1200971378 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.22550
Policy Entropy: 4.32772
Value Function Loss: 0.00298
Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03782
Policy Update Magnitude: 1.09956
Value Function Update Magnitude: 0.85878
Collected Steps per Second: 13,089.30666
Overall Steps per Second: 7,244.72036
Timestep Collection Time: 3.82129
Timestep Consumption Time: 3.08278
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.90406
Cumulative Model Updates: 150,266
Cumulative Timesteps: 1,201,021,396
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66628
Policy Entropy: 4.32435
Value Function Loss: 0.00285
Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03870
Policy Update Magnitude: 1.07928
Value Function Update Magnitude: 0.86380
Collected Steps per Second: 12,974.53262
Overall Steps per Second: 7,281.38361
Timestep Collection Time: 3.85478
Timestep Consumption Time: 3.01397
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.86875
Cumulative Model Updates: 150,275
Cumulative Timesteps: 1,201,071,410
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1201071410...
Checkpoint 1201071410 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42233
Policy Entropy: 4.32217
Value Function Loss: 0.00286
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03734
Policy Update Magnitude: 1.06960
Value Function Update Magnitude: 0.83995
Collected Steps per Second: 12,931.43744
Overall Steps per Second: 7,174.97787
Timestep Collection Time: 3.86686
Timestep Consumption Time: 3.10236
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.96922
Cumulative Model Updates: 150,284
Cumulative Timesteps: 1,201,121,414
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56178
Policy Entropy: 4.32119
Value Function Loss: 0.00293
Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03904
Policy Update Magnitude: 1.08972
Value Function Update Magnitude: 0.80580
Collected Steps per Second: 12,792.44753
Overall Steps per Second: 7,093.58403
Timestep Collection Time: 3.91043
Timestep Consumption Time: 3.14157
PPO Batch Consumption Time: 0.23197
Total Iteration Time: 7.05201
Cumulative Model Updates: 150,293
Cumulative Timesteps: 1,201,171,438
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1201171438...
Checkpoint 1201171438 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42120
Policy Entropy: 4.32127
Value Function Loss: 0.00301
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03712
Policy Update Magnitude: 1.10402
Value Function Update Magnitude: 0.80757
Collected Steps per Second: 12,873.17762
Overall Steps per Second: 7,190.42218
Timestep Collection Time: 3.88855
Timestep Consumption Time: 3.07321
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 6.96176
Cumulative Model Updates: 150,302
Cumulative Timesteps: 1,201,221,496
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.93222
Policy Entropy: 4.32240
Value Function Loss: 0.00299
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03697
Policy Update Magnitude: 1.11299
Value Function Update Magnitude: 0.81820
Collected Steps per Second: 12,837.19213
Overall Steps per Second: 7,139.30174
Timestep Collection Time: 3.89758
Timestep Consumption Time: 3.11067
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 7.00825
Cumulative Model Updates: 150,311
Cumulative Timesteps: 1,201,271,530
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1201271530...
Checkpoint 1201271530 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.44996
Policy Entropy: 4.31879
Value Function Loss: 0.00292
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03801
Policy Update Magnitude: 1.09562
Value Function Update Magnitude: 0.78146
Collected Steps per Second: 12,965.98535
Overall Steps per Second: 7,208.48189
Timestep Collection Time: 3.85794
Timestep Consumption Time: 3.08138
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.93933
Cumulative Model Updates: 150,320
Cumulative Timesteps: 1,201,321,552
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.47713
Policy Entropy: 4.31886
Value Function Loss: 0.00289
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03829
Policy Update Magnitude: 1.08024
Value Function Update Magnitude: 0.78443
Collected Steps per Second: 12,897.07748
Overall Steps per Second: 7,252.51338
Timestep Collection Time: 3.87685
Timestep Consumption Time: 3.01731
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.89416
Cumulative Model Updates: 150,329
Cumulative Timesteps: 1,201,371,552
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1201371552...
Checkpoint 1201371552 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21133
Policy Entropy: 4.32011
Value Function Loss: 0.00288
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03788
Policy Update Magnitude: 1.07869
Value Function Update Magnitude: 0.81963
Collected Steps per Second: 12,948.04560
Overall Steps per Second: 7,184.59481
Timestep Collection Time: 3.86220
Timestep Consumption Time: 3.09824
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.96045
Cumulative Model Updates: 150,338
Cumulative Timesteps: 1,201,421,560
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.61365
Policy Entropy: 4.32231
Value Function Loss: 0.00287
Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03892
Policy Update Magnitude: 1.06836
Value Function Update Magnitude: 0.81499
Collected Steps per Second: 13,006.08621
Overall Steps per Second: 7,227.88263
Timestep Collection Time: 3.84635
Timestep Consumption Time: 3.07490
PPO Batch Consumption Time: 0.22794
Total Iteration Time: 6.92125
Cumulative Model Updates: 150,347
Cumulative Timesteps: 1,201,471,586
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1201471586...
Checkpoint 1201471586 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.32714
Policy Entropy: 4.32581
Value Function Loss: 0.00286
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03748
Policy Update Magnitude: 1.05069
Value Function Update Magnitude: 0.79845
Collected Steps per Second: 12,862.83441
Overall Steps per Second: 7,133.73440
Timestep Collection Time: 3.88872
Timestep Consumption Time: 3.12303
PPO Batch Consumption Time: 0.23762
Total Iteration Time: 7.01176
Cumulative Model Updates: 150,356
Cumulative Timesteps: 1,201,521,606
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.52418
Policy Entropy: 4.32252
Value Function Loss: 0.00293
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03662
Policy Update Magnitude: 1.05754
Value Function Update Magnitude: 0.79526
Collected Steps per Second: 13,008.53304
Overall Steps per Second: 7,185.41695
Timestep Collection Time: 3.84794
Timestep Consumption Time: 3.11840
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.96633
Cumulative Model Updates: 150,365
Cumulative Timesteps: 1,201,571,662
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1201571662...
Checkpoint 1201571662 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.36051
Policy Entropy: 4.32111
Value Function Loss: 0.00290
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03521
Policy Update Magnitude: 1.06851
Value Function Update Magnitude: 0.82127
Collected Steps per Second: 12,863.43870
Overall Steps per Second: 7,123.80340
Timestep Collection Time: 3.88792
Timestep Consumption Time: 3.13249
PPO Batch Consumption Time: 0.22932
Total Iteration Time: 7.02041
Cumulative Model Updates: 150,374
Cumulative Timesteps: 1,201,621,674
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85285
Policy Entropy: 4.32010
Value Function Loss: 0.00281
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03510
Policy Update Magnitude: 1.06746
Value Function Update Magnitude: 0.81519
Collected Steps per Second: 13,287.14116
Overall Steps per Second: 7,281.53264
Timestep Collection Time: 3.76785
Timestep Consumption Time: 3.10762
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.87548
Cumulative Model Updates: 150,383
Cumulative Timesteps: 1,201,671,738
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
Saving checkpoint 1201671738...
Checkpoint 1201671738 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.00089
Policy Entropy: 4.32240
Value Function Loss: 0.00277
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03419
Policy Update Magnitude: 1.07224
Value Function Update Magnitude: 0.79572
Collected Steps per Second: 12,931.39981
Overall Steps per Second: 7,172.26912
Timestep Collection Time: 3.86996
Timestep Consumption Time: 3.10747
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.97743
Cumulative Model Updates: 150,392
Cumulative Timesteps: 1,201,721,782
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.68428
Policy Entropy: 4.32110
Value Function Loss: 0.00271
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03500
Policy Update Magnitude: 1.05962
Value Function Update Magnitude: 0.78262
Collected Steps per Second: 12,996.11666
Overall Steps per Second: 7,216.28819
Timestep Collection Time: 3.84746
Timestep Consumption Time: 3.08159
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.92905
Cumulative Model Updates: 150,401
Cumulative Timesteps: 1,201,771,784
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1201771784...
Checkpoint 1201771784 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00338
Policy Entropy: 4.32251
Value Function Loss: 0.00279
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 1.05343
Value Function Update Magnitude: 0.77017
Collected Steps per Second: 13,263.83142
Overall Steps per Second: 7,249.04593
Timestep Collection Time: 3.77010
Timestep Consumption Time: 3.12818
PPO Batch Consumption Time: 0.22926
Total Iteration Time: 6.89829
Cumulative Model Updates: 150,410
Cumulative Timesteps: 1,201,821,790
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.77649
Policy Entropy: 4.32204
Value Function Loss: 0.00278
Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03778
Policy Update Magnitude: 1.04090
Value Function Update Magnitude: 0.79065
Collected Steps per Second: 12,898.16531
Overall Steps per Second: 7,013.19551
Timestep Collection Time: 3.87900
Timestep Consumption Time: 3.25498
PPO Batch Consumption Time: 0.24109
Total Iteration Time: 7.13398
Cumulative Model Updates: 150,419
Cumulative Timesteps: 1,201,871,822
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1201871822...
Checkpoint 1201871822 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90693
Policy Entropy: 4.32686
Value Function Loss: 0.00272
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03593
Policy Update Magnitude: 1.03266
Value Function Update Magnitude: 0.80984
Collected Steps per Second: 12,881.01551
Overall Steps per Second: 7,250.71352
Timestep Collection Time: 3.88277
Timestep Consumption Time: 3.01504
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.89780
Cumulative Model Updates: 150,428
Cumulative Timesteps: 1,201,921,836
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.52514
Policy Entropy: 4.32519
Value Function Loss: 0.00275
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03402
Policy Update Magnitude: 1.03691
Value Function Update Magnitude: 0.80186
Collected Steps per Second: 12,972.71314
Overall Steps per Second: 7,181.01835
Timestep Collection Time: 3.85609
Timestep Consumption Time: 3.11005
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.96614
Cumulative Model Updates: 150,437
Cumulative Timesteps: 1,201,971,860
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1201971860...
Checkpoint 1201971860 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.54731
Policy Entropy: 4.33156
Value Function Loss: 0.00268
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03460
Policy Update Magnitude: 1.04738
Value Function Update Magnitude: 0.78150
Collected Steps per Second: 12,924.34135
Overall Steps per Second: 7,165.85041
Timestep Collection Time: 3.86867
Timestep Consumption Time: 3.10887
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.97754
Cumulative Model Updates: 150,446
Cumulative Timesteps: 1,202,021,860
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28648
Policy Entropy: 4.32697
Value Function Loss: 0.00287
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03564
Policy Update Magnitude: 1.06031
Value Function Update Magnitude: 0.79162
Collected Steps per Second: 12,838.59221
Overall Steps per Second: 7,238.64269
Timestep Collection Time: 3.89762
Timestep Consumption Time: 3.01527
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.91290
Cumulative Model Updates: 150,455
Cumulative Timesteps: 1,202,071,900
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1202071900...
Checkpoint 1202071900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.49823
Policy Entropy: 4.32478
Value Function Loss: 0.00276
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03543
Policy Update Magnitude: 1.06478
Value Function Update Magnitude: 0.81404
Collected Steps per Second: 13,009.47753
Overall Steps per Second: 7,208.35971
Timestep Collection Time: 3.84612
Timestep Consumption Time: 3.09527
PPO Batch Consumption Time: 0.22920
Total Iteration Time: 6.94139
Cumulative Model Updates: 150,464
Cumulative Timesteps: 1,202,121,936
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.28736
Policy Entropy: 4.32332
Value Function Loss: 0.00276
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03422
Policy Update Magnitude: 1.05256
Value Function Update Magnitude: 0.84360
Collected Steps per Second: 12,940.58300
Overall Steps per Second: 7,197.72393
Timestep Collection Time: 3.86660
Timestep Consumption Time: 3.08505
PPO Batch Consumption Time: 0.22955
Total Iteration Time: 6.95164
Cumulative Model Updates: 150,473
Cumulative Timesteps: 1,202,171,972
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1202171972...
Checkpoint 1202171972 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.59735
Policy Entropy: 4.32670
Value Function Loss: 0.00263
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03322
Policy Update Magnitude: 1.05151
Value Function Update Magnitude: 0.81431
Collected Steps per Second: 12,872.46737
Overall Steps per Second: 7,209.47390
Timestep Collection Time: 3.88643
Timestep Consumption Time: 3.05277
PPO Batch Consumption Time: 0.22969
Total Iteration Time: 6.93920
Cumulative Model Updates: 150,482
Cumulative Timesteps: 1,202,222,000
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.57460
Policy Entropy: 4.33145
Value Function Loss: 0.00258
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03459
Policy Update Magnitude: 1.02394
Value Function Update Magnitude: 0.82087
Collected Steps per Second: 12,910.06591
Overall Steps per Second: 7,144.41023
Timestep Collection Time: 3.87450
Timestep Consumption Time: 3.12678
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 7.00128
Cumulative Model Updates: 150,491
Cumulative Timesteps: 1,202,272,020
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1202272020...
Checkpoint 1202272020 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.85223
Policy Entropy: 4.33547
Value Function Loss: 0.00257
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03390
Policy Update Magnitude: 1.01902
Value Function Update Magnitude: 0.82526
Collected Steps per Second: 13,008.11385
Overall Steps per Second: 7,190.44147
Timestep Collection Time: 3.84683
Timestep Consumption Time: 3.11241
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.95924
Cumulative Model Updates: 150,500
Cumulative Timesteps: 1,202,322,060
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.93162
Policy Entropy: 4.33551
Value Function Loss: 0.00255
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03431
Policy Update Magnitude: 1.02385
Value Function Update Magnitude: 0.80556
Collected Steps per Second: 13,034.02534
Overall Steps per Second: 7,273.35249
Timestep Collection Time: 3.83627
Timestep Consumption Time: 3.03842
PPO Batch Consumption Time: 0.23060
Total Iteration Time: 6.87468
Cumulative Model Updates: 150,509
Cumulative Timesteps: 1,202,372,062
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1202372062...
Checkpoint 1202372062 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.05559
Policy Entropy: 4.33467
Value Function Loss: 0.00265
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03420
Policy Update Magnitude: 1.03134
Value Function Update Magnitude: 0.80709
Collected Steps per Second: 12,868.24434
Overall Steps per Second: 7,120.05671
Timestep Collection Time: 3.88895
Timestep Consumption Time: 3.13964
PPO Batch Consumption Time: 0.22988
Total Iteration Time: 7.02860
Cumulative Model Updates: 150,518
Cumulative Timesteps: 1,202,422,106
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.83440
Policy Entropy: 4.33295
Value Function Loss: 0.00273
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03210
Policy Update Magnitude: 1.03756
Value Function Update Magnitude: 0.79784
Collected Steps per Second: 12,875.71754
Overall Steps per Second: 7,148.82161
Timestep Collection Time: 3.88514
Timestep Consumption Time: 3.11237
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.99752
Cumulative Model Updates: 150,527
Cumulative Timesteps: 1,202,472,130
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1202472130...
Checkpoint 1202472130 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56256
Policy Entropy: 4.32414
Value Function Loss: 0.00286
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03408
Policy Update Magnitude: 1.07604
Value Function Update Magnitude: 0.80668
Collected Steps per Second: 12,853.66659
Overall Steps per Second: 7,254.12735
Timestep Collection Time: 3.89243
Timestep Consumption Time: 3.00461
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.89704
Cumulative Model Updates: 150,536
Cumulative Timesteps: 1,202,522,162
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.95846
Policy Entropy: 4.32287
Value Function Loss: 0.00284
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03694
Policy Update Magnitude: 1.06628
Value Function Update Magnitude: 0.79088
Collected Steps per Second: 12,948.58002
Overall Steps per Second: 7,138.71908
Timestep Collection Time: 3.86205
Timestep Consumption Time: 3.14313
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 7.00518
Cumulative Model Updates: 150,545
Cumulative Timesteps: 1,202,572,170
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1202572170...
Checkpoint 1202572170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10582
Policy Entropy: 4.32167
Value Function Loss: 0.00288
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03569
Policy Update Magnitude: 1.04106
Value Function Update Magnitude: 0.78959
Collected Steps per Second: 12,952.42385
Overall Steps per Second: 7,208.36972
Timestep Collection Time: 3.86121
Timestep Consumption Time: 3.07684
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.93805
Cumulative Model Updates: 150,554
Cumulative Timesteps: 1,202,622,182
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.23616
Policy Entropy: 4.32936
Value Function Loss: 0.00280
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03355
Policy Update Magnitude: 1.04244
Value Function Update Magnitude: 0.79088
Collected Steps per Second: 12,950.30358
Overall Steps per Second: 7,290.64578
Timestep Collection Time: 3.86323
Timestep Consumption Time: 2.99899
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.86222
Cumulative Model Updates: 150,563
Cumulative Timesteps: 1,202,672,212
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1202672212...
Checkpoint 1202672212 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85198
Policy Entropy: 4.33108
Value Function Loss: 0.00282
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03287
Policy Update Magnitude: 1.05085
Value Function Update Magnitude: 0.81156
Collected Steps per Second: 12,665.58591
Overall Steps per Second: 7,079.88223
Timestep Collection Time: 3.95055
Timestep Consumption Time: 3.11680
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 7.06735
Cumulative Model Updates: 150,572
Cumulative Timesteps: 1,202,722,248
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07774
Policy Entropy: 4.32845
Value Function Loss: 0.00266
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03258
Policy Update Magnitude: 1.04681
Value Function Update Magnitude: 0.80982
Collected Steps per Second: 13,060.46292
Overall Steps per Second: 7,226.54432
Timestep Collection Time: 3.83095
Timestep Consumption Time: 3.09269
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.92364
Cumulative Model Updates: 150,581
Cumulative Timesteps: 1,202,772,282
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1202772282...
Checkpoint 1202772282 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.15694
Policy Entropy: 4.32653
Value Function Loss: 0.00263
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03392
Policy Update Magnitude: 1.03829
Value Function Update Magnitude: 0.80421
Collected Steps per Second: 12,849.30878
Overall Steps per Second: 7,240.13361
Timestep Collection Time: 3.89126
Timestep Consumption Time: 3.01469
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.90595
Cumulative Model Updates: 150,590
Cumulative Timesteps: 1,202,822,282
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.03936
Policy Entropy: 4.32295
Value Function Loss: 0.00267
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03405
Policy Update Magnitude: 1.03232
Value Function Update Magnitude: 0.78298
Collected Steps per Second: 12,967.13730
Overall Steps per Second: 7,169.05095
Timestep Collection Time: 3.85899
Timestep Consumption Time: 3.12102
PPO Batch Consumption Time: 0.23003
Total Iteration Time: 6.98000
Cumulative Model Updates: 150,599
Cumulative Timesteps: 1,202,872,322
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1202872322...
Checkpoint 1202872322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.45860
Policy Entropy: 4.32024
Value Function Loss: 0.00291
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03517
Policy Update Magnitude: 1.05785
Value Function Update Magnitude: 0.79236
Collected Steps per Second: 12,886.98258
Overall Steps per Second: 7,097.13233
Timestep Collection Time: 3.88299
Timestep Consumption Time: 3.16775
PPO Batch Consumption Time: 0.23569
Total Iteration Time: 7.05074
Cumulative Model Updates: 150,608
Cumulative Timesteps: 1,202,922,362
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.80113
Policy Entropy: 4.31867
Value Function Loss: 0.00293
Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03838
Policy Update Magnitude: 1.06782
Value Function Update Magnitude: 0.81369
Collected Steps per Second: 12,901.39914
Overall Steps per Second: 7,268.49142
Timestep Collection Time: 3.87803
Timestep Consumption Time: 3.00538
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.88341
Cumulative Model Updates: 150,617
Cumulative Timesteps: 1,202,972,394
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1202972394...
Checkpoint 1202972394 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.26248
Policy Entropy: 4.32243
Value Function Loss: 0.00286
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03578
Policy Update Magnitude: 1.06699
Value Function Update Magnitude: 0.81302
Collected Steps per Second: 12,963.36831
Overall Steps per Second: 7,179.87260
Timestep Collection Time: 3.85903
Timestep Consumption Time: 3.10851
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.96753
Cumulative Model Updates: 150,626
Cumulative Timesteps: 1,203,022,420
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.64654
Policy Entropy: 4.32273
Value Function Loss: 0.00281
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03633
Policy Update Magnitude: 1.07169
Value Function Update Magnitude: 0.81890
Collected Steps per Second: 13,039.52956
Overall Steps per Second: 7,227.28633
Timestep Collection Time: 3.83725
Timestep Consumption Time: 3.08595
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.92321
Cumulative Model Updates: 150,635
Cumulative Timesteps: 1,203,072,456
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1203072456...
Checkpoint 1203072456 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.86628
Policy Entropy: 4.32407
Value Function Loss: 0.00273
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03533
Policy Update Magnitude: 1.05873
Value Function Update Magnitude: 0.79865
Collected Steps per Second: 12,877.82327
Overall Steps per Second: 7,281.06917
Timestep Collection Time: 3.88404
Timestep Consumption Time: 2.98555
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.86960
Cumulative Model Updates: 150,644
Cumulative Timesteps: 1,203,122,474
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05693
Policy Entropy: 4.32430
Value Function Loss: 0.00287
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03459
Policy Update Magnitude: 1.06020
Value Function Update Magnitude: 0.80115
Collected Steps per Second: 12,943.59300
Overall Steps per Second: 7,174.85642
Timestep Collection Time: 3.86631
Timestep Consumption Time: 3.10860
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.97491
Cumulative Model Updates: 150,653
Cumulative Timesteps: 1,203,172,518
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1203172518...
Checkpoint 1203172518 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18226
Policy Entropy: 4.32591
Value Function Loss: 0.00286
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 1.06132
Value Function Update Magnitude: 0.81847
Collected Steps per Second: 12,942.90373
Overall Steps per Second: 7,203.94066
Timestep Collection Time: 3.86652
Timestep Consumption Time: 3.08023
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.94675
Cumulative Model Updates: 150,662
Cumulative Timesteps: 1,203,222,562
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79871
Policy Entropy: 4.32520
Value Function Loss: 0.00297
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 1.05525
Value Function Update Magnitude: 0.83042
Collected Steps per Second: 13,245.89945
Overall Steps per Second: 7,130.77653
Timestep Collection Time: 3.77626
Timestep Consumption Time: 3.23840
PPO Batch Consumption Time: 0.24075
Total Iteration Time: 7.01466
Cumulative Model Updates: 150,671
Cumulative Timesteps: 1,203,272,582
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1203272582...
Checkpoint 1203272582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.20282
Policy Entropy: 4.32490
Value Function Loss: 0.00290
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03341
Policy Update Magnitude: 1.07180
Value Function Update Magnitude: 0.83367
Collected Steps per Second: 13,009.36297
Overall Steps per Second: 7,181.93554
Timestep Collection Time: 3.84369
Timestep Consumption Time: 3.11878
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.96247
Cumulative Model Updates: 150,680
Cumulative Timesteps: 1,203,322,586
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.58200
Policy Entropy: 4.32296
Value Function Loss: 0.00281
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03388
Policy Update Magnitude: 1.04342
Value Function Update Magnitude: 0.83595
Collected Steps per Second: 12,814.43642
Overall Steps per Second: 7,170.77498
Timestep Collection Time: 3.90435
Timestep Consumption Time: 3.07286
PPO Batch Consumption Time: 0.22933
Total Iteration Time: 6.97721
Cumulative Model Updates: 150,689
Cumulative Timesteps: 1,203,372,618
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1203372618...
Checkpoint 1203372618 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.37624
Policy Entropy: 4.32606
Value Function Loss: 0.00271
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 1.03212
Value Function Update Magnitude: 0.81567
Collected Steps per Second: 12,907.59627
Overall Steps per Second: 7,261.02524
Timestep Collection Time: 3.87617
Timestep Consumption Time: 3.01432
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.89049
Cumulative Model Updates: 150,698
Cumulative Timesteps: 1,203,422,650
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.19983
Policy Entropy: 4.32626
Value Function Loss: 0.00270
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03225
Policy Update Magnitude: 1.03479
Value Function Update Magnitude: 0.80097
Collected Steps per Second: 12,972.43938
Overall Steps per Second: 7,167.58747
Timestep Collection Time: 3.85433
Timestep Consumption Time: 3.12152
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.97585
Cumulative Model Updates: 150,707
Cumulative Timesteps: 1,203,472,650
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1203472650...
Checkpoint 1203472650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.77694
Policy Entropy: 4.33194
Value Function Loss: 0.00265
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03216
Policy Update Magnitude: 1.05458
Value Function Update Magnitude: 0.79046
Collected Steps per Second: 12,860.06213
Overall Steps per Second: 7,186.51863
Timestep Collection Time: 3.88801
Timestep Consumption Time: 3.06947
PPO Batch Consumption Time: 0.22944
Total Iteration Time: 6.95747
Cumulative Model Updates: 150,716
Cumulative Timesteps: 1,203,522,650
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27952
Policy Entropy: 4.32833
Value Function Loss: 0.00263
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03326
Policy Update Magnitude: 1.03270
Value Function Update Magnitude: 0.77099
Collected Steps per Second: 13,122.66519
Overall Steps per Second: 7,301.93714
Timestep Collection Time: 3.81386
Timestep Consumption Time: 3.04021
PPO Batch Consumption Time: 0.22954
Total Iteration Time: 6.85407
Cumulative Model Updates: 150,725
Cumulative Timesteps: 1,203,572,698
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1203572698...
Checkpoint 1203572698 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.24605
Policy Entropy: 4.33144
Value Function Loss: 0.00254
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03341
Policy Update Magnitude: 1.02882
Value Function Update Magnitude: 0.78647
Collected Steps per Second: 13,177.85938
Overall Steps per Second: 7,186.94709
Timestep Collection Time: 3.79697
Timestep Consumption Time: 3.16509
PPO Batch Consumption Time: 0.23086
Total Iteration Time: 6.96207
Cumulative Model Updates: 150,734
Cumulative Timesteps: 1,203,622,734
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.63708
Policy Entropy: 4.33072
Value Function Loss: 0.00259
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03318
Policy Update Magnitude: 1.02720
Value Function Update Magnitude: 0.80617
Collected Steps per Second: 12,930.12030
Overall Steps per Second: 7,220.71566
Timestep Collection Time: 3.87003
Timestep Consumption Time: 3.06003
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.93006
Cumulative Model Updates: 150,743
Cumulative Timesteps: 1,203,672,774
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1203672774...
Checkpoint 1203672774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.45635
Policy Entropy: 4.33334
Value Function Loss: 0.00259
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03140
Policy Update Magnitude: 1.01761
Value Function Update Magnitude: 0.80098
Collected Steps per Second: 12,936.90544
Overall Steps per Second: 7,272.86678
Timestep Collection Time: 3.86568
Timestep Consumption Time: 3.01056
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.87624
Cumulative Model Updates: 150,752
Cumulative Timesteps: 1,203,722,784
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.10855
Policy Entropy: 4.32761
Value Function Loss: 0.00271
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03141
Policy Update Magnitude: 1.04205
Value Function Update Magnitude: 0.79750
Collected Steps per Second: 12,885.34922
Overall Steps per Second: 7,165.08435
Timestep Collection Time: 3.88131
Timestep Consumption Time: 3.09865
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.97996
Cumulative Model Updates: 150,761
Cumulative Timesteps: 1,203,772,796
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1203772796...
Checkpoint 1203772796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.09995
Policy Entropy: 4.32749
Value Function Loss: 0.00268
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03364
Policy Update Magnitude: 1.03689
Value Function Update Magnitude: 0.79424
Collected Steps per Second: 12,905.77788
Overall Steps per Second: 7,207.92667
Timestep Collection Time: 3.87439
Timestep Consumption Time: 3.06270
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.93708
Cumulative Model Updates: 150,770
Cumulative Timesteps: 1,203,822,798
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90770
Policy Entropy: 4.32561
Value Function Loss: 0.00286
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 1.03699
Value Function Update Magnitude: 0.79644
Collected Steps per Second: 12,863.47455
Overall Steps per Second: 7,256.43418
Timestep Collection Time: 3.88837
Timestep Consumption Time: 3.00454
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.89292
Cumulative Model Updates: 150,779
Cumulative Timesteps: 1,203,872,816
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1203872816...
Checkpoint 1203872816 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.13994
Policy Entropy: 4.33065
Value Function Loss: 0.00280
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03380
Policy Update Magnitude: 1.04266
Value Function Update Magnitude: 0.79809
Collected Steps per Second: 12,870.74095
Overall Steps per Second: 7,164.99670
Timestep Collection Time: 3.88711
Timestep Consumption Time: 3.09545
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.98256
Cumulative Model Updates: 150,788
Cumulative Timesteps: 1,203,922,846
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.96696
Policy Entropy: 4.33327
Value Function Loss: 0.00293
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03445
Policy Update Magnitude: 1.03892
Value Function Update Magnitude: 0.80963
Collected Steps per Second: 13,050.12447
Overall Steps per Second: 7,092.44201
Timestep Collection Time: 3.83337
Timestep Consumption Time: 3.22005
PPO Batch Consumption Time: 0.23982
Total Iteration Time: 7.05342
Cumulative Model Updates: 150,797
Cumulative Timesteps: 1,203,972,872
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1203972872...
Checkpoint 1203972872 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.34841
Policy Entropy: 4.33429
Value Function Loss: 0.00289
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 1.05278
Value Function Update Magnitude: 0.79476
Collected Steps per Second: 12,747.94140
Overall Steps per Second: 7,247.95968
Timestep Collection Time: 3.92487
Timestep Consumption Time: 2.97832
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.90318
Cumulative Model Updates: 150,806
Cumulative Timesteps: 1,204,022,906
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.82035
Policy Entropy: 4.33312
Value Function Loss: 0.00290
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03601
Policy Update Magnitude: 1.04747
Value Function Update Magnitude: 0.79496
Collected Steps per Second: 12,999.11567
Overall Steps per Second: 7,202.20797
Timestep Collection Time: 3.84642
Timestep Consumption Time: 3.09590
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.94232
Cumulative Model Updates: 150,815
Cumulative Timesteps: 1,204,072,906
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1204072906...
Checkpoint 1204072906 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.07783
Policy Entropy: 4.33394
Value Function Loss: 0.00272
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03412
Policy Update Magnitude: 1.02678
Value Function Update Magnitude: 0.77758
Collected Steps per Second: 12,743.39530
Overall Steps per Second: 7,131.30025
Timestep Collection Time: 3.92533
Timestep Consumption Time: 3.08910
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 7.01443
Cumulative Model Updates: 150,824
Cumulative Timesteps: 1,204,122,928
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.36254
Policy Entropy: 4.33577
Value Function Loss: 0.00266
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03384
Policy Update Magnitude: 1.01996
Value Function Update Magnitude: 0.78058
Collected Steps per Second: 12,868.80128
Overall Steps per Second: 7,256.26242
Timestep Collection Time: 3.88568
Timestep Consumption Time: 3.00547
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.89115
Cumulative Model Updates: 150,833
Cumulative Timesteps: 1,204,172,932
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1204172932...
Checkpoint 1204172932 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64677
Policy Entropy: 4.34005
Value Function Loss: 0.00259
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 1.01243
Value Function Update Magnitude: 0.79443
Collected Steps per Second: 12,990.62631
Overall Steps per Second: 7,188.95637
Timestep Collection Time: 3.85047
Timestep Consumption Time: 3.10743
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.95789
Cumulative Model Updates: 150,842
Cumulative Timesteps: 1,204,222,952
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.92540
Policy Entropy: 4.34091
Value Function Loss: 0.00277
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03518
Policy Update Magnitude: 1.02153
Value Function Update Magnitude: 0.83102
Collected Steps per Second: 12,935.59316
Overall Steps per Second: 7,174.76507
Timestep Collection Time: 3.86530
Timestep Consumption Time: 3.10357
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.96887
Cumulative Model Updates: 150,851
Cumulative Timesteps: 1,204,272,952
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1204272952...
Checkpoint 1204272952 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.63706
Policy Entropy: 4.34442
Value Function Loss: 0.00272
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03218
Policy Update Magnitude: 1.03048
Value Function Update Magnitude: 0.84000
Collected Steps per Second: 12,974.94371
Overall Steps per Second: 7,228.34158
Timestep Collection Time: 3.85620
Timestep Consumption Time: 3.06572
PPO Batch Consumption Time: 0.23364
Total Iteration Time: 6.92192
Cumulative Model Updates: 150,860
Cumulative Timesteps: 1,204,322,986
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52644
Policy Entropy: 4.34293
Value Function Loss: 0.00276
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 1.03194
Value Function Update Magnitude: 0.82062
Collected Steps per Second: 13,047.36481
Overall Steps per Second: 7,218.85537
Timestep Collection Time: 3.83418
Timestep Consumption Time: 3.09572
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.92991
Cumulative Model Updates: 150,869
Cumulative Timesteps: 1,204,373,012
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1204373012...
Checkpoint 1204373012 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.72755
Policy Entropy: 4.34271
Value Function Loss: 0.00258
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03100
Policy Update Magnitude: 1.02090
Value Function Update Magnitude: 0.81367
Collected Steps per Second: 12,904.30899
Overall Steps per Second: 7,151.96403
Timestep Collection Time: 3.87746
Timestep Consumption Time: 3.11866
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.99612
Cumulative Model Updates: 150,878
Cumulative Timesteps: 1,204,423,048
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.93478
Policy Entropy: 4.34022
Value Function Loss: 0.00258
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 1.02325
Value Function Update Magnitude: 0.77401
Collected Steps per Second: 12,874.71251
Overall Steps per Second: 7,263.16847
Timestep Collection Time: 3.88622
Timestep Consumption Time: 3.00251
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.88873
Cumulative Model Updates: 150,887
Cumulative Timesteps: 1,204,473,082
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1204473082...
Checkpoint 1204473082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75566
Policy Entropy: 4.33897
Value Function Loss: 0.00266
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03135
Policy Update Magnitude: 1.04476
Value Function Update Magnitude: 0.76808
Collected Steps per Second: 12,876.70556
Overall Steps per Second: 7,166.08842
Timestep Collection Time: 3.88407
Timestep Consumption Time: 3.09519
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.97926
Cumulative Model Updates: 150,896
Cumulative Timesteps: 1,204,523,096
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74971
Policy Entropy: 4.34061
Value Function Loss: 0.00268
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03319
Policy Update Magnitude: 1.03854
Value Function Update Magnitude: 0.77856
Collected Steps per Second: 12,936.35088
Overall Steps per Second: 7,166.22395
Timestep Collection Time: 3.86508
Timestep Consumption Time: 3.11210
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.97718
Cumulative Model Updates: 150,905
Cumulative Timesteps: 1,204,573,096
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1204573096...
Checkpoint 1204573096 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.56661
Policy Entropy: 4.34133
Value Function Loss: 0.00266
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03422
Policy Update Magnitude: 1.03307
Value Function Update Magnitude: 0.76680
Collected Steps per Second: 12,905.47169
Overall Steps per Second: 7,207.46607
Timestep Collection Time: 3.87634
Timestep Consumption Time: 3.06452
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.94086
Cumulative Model Updates: 150,914
Cumulative Timesteps: 1,204,623,122
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12400
Policy Entropy: 4.34120
Value Function Loss: 0.00262
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03294
Policy Update Magnitude: 1.04799
Value Function Update Magnitude: 0.75218
Collected Steps per Second: 13,124.04672
Overall Steps per Second: 7,162.98933
Timestep Collection Time: 3.81209
Timestep Consumption Time: 3.17243
PPO Batch Consumption Time: 0.23002
Total Iteration Time: 6.98451
Cumulative Model Updates: 150,923
Cumulative Timesteps: 1,204,673,152
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1204673152...
Checkpoint 1204673152 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.66089
Policy Entropy: 4.33740
Value Function Loss: 0.00268
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03427
Policy Update Magnitude: 1.03609
Value Function Update Magnitude: 0.74380
Collected Steps per Second: 12,965.45121
Overall Steps per Second: 7,136.47993
Timestep Collection Time: 3.85717
Timestep Consumption Time: 3.15048
PPO Batch Consumption Time: 0.22959
Total Iteration Time: 7.00766
Cumulative Model Updates: 150,932
Cumulative Timesteps: 1,204,723,162
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.67983
Policy Entropy: 4.33484
Value Function Loss: 0.00271
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03447
Policy Update Magnitude: 1.03114
Value Function Update Magnitude: 0.75273
Collected Steps per Second: 12,857.12978
Overall Steps per Second: 7,183.56343
Timestep Collection Time: 3.88905
Timestep Consumption Time: 3.07156
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.96061
Cumulative Model Updates: 150,941
Cumulative Timesteps: 1,204,773,164
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1204773164...
Checkpoint 1204773164 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.71758
Policy Entropy: 4.33310
Value Function Loss: 0.00270
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03090
Policy Update Magnitude: 1.04997
Value Function Update Magnitude: 0.76389
Collected Steps per Second: 13,256.21484
Overall Steps per Second: 7,286.13682
Timestep Collection Time: 3.77212
Timestep Consumption Time: 3.09078
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.86290
Cumulative Model Updates: 150,950
Cumulative Timesteps: 1,204,823,168
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.28955
Policy Entropy: 4.32904
Value Function Loss: 0.00272
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03537
Policy Update Magnitude: 1.06078
Value Function Update Magnitude: 0.77817
Collected Steps per Second: 13,003.62930
Overall Steps per Second: 7,184.21312
Timestep Collection Time: 3.84570
Timestep Consumption Time: 3.11512
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.96082
Cumulative Model Updates: 150,959
Cumulative Timesteps: 1,204,873,176
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1204873176...
Checkpoint 1204873176 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23013
Policy Entropy: 4.33302
Value Function Loss: 0.00273
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 1.05713
Value Function Update Magnitude: 0.79012
Collected Steps per Second: 12,776.45781
Overall Steps per Second: 7,161.40374
Timestep Collection Time: 3.91533
Timestep Consumption Time: 3.06990
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.98522
Cumulative Model Updates: 150,968
Cumulative Timesteps: 1,204,923,200
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.09831
Policy Entropy: 4.33327
Value Function Loss: 0.00275
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03322
Policy Update Magnitude: 1.05952
Value Function Update Magnitude: 0.80300
Collected Steps per Second: 13,178.79299
Overall Steps per Second: 7,243.73580
Timestep Collection Time: 3.79640
Timestep Consumption Time: 3.11053
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.90693
Cumulative Model Updates: 150,977
Cumulative Timesteps: 1,204,973,232
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1204973232...
Checkpoint 1204973232 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.71966
Policy Entropy: 4.33507
Value Function Loss: 0.00277
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03439
Policy Update Magnitude: 1.05153
Value Function Update Magnitude: 0.79840
Collected Steps per Second: 12,942.24301
Overall Steps per Second: 7,051.99713
Timestep Collection Time: 3.86394
Timestep Consumption Time: 3.22739
PPO Batch Consumption Time: 0.23670
Total Iteration Time: 7.09132
Cumulative Model Updates: 150,986
Cumulative Timesteps: 1,205,023,240
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64215
Policy Entropy: 4.33228
Value Function Loss: 0.00275
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03535
Policy Update Magnitude: 1.04967
Value Function Update Magnitude: 0.80137
Collected Steps per Second: 12,963.30412
Overall Steps per Second: 7,219.64089
Timestep Collection Time: 3.85828
Timestep Consumption Time: 3.06949
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.92777
Cumulative Model Updates: 150,995
Cumulative Timesteps: 1,205,073,256
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1205073256...
Checkpoint 1205073256 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.72915
Policy Entropy: 4.33014
Value Function Loss: 0.00284
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03732
Policy Update Magnitude: 1.04926
Value Function Update Magnitude: 0.81550
Collected Steps per Second: 13,137.55264
Overall Steps per Second: 7,218.62374
Timestep Collection Time: 3.80893
Timestep Consumption Time: 3.12314
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.93207
Cumulative Model Updates: 151,004
Cumulative Timesteps: 1,205,123,296
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.96325
Policy Entropy: 4.32997
Value Function Loss: 0.00276
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03518
Policy Update Magnitude: 1.04684
Value Function Update Magnitude: 0.81608
Collected Steps per Second: 13,064.99058
Overall Steps per Second: 7,207.95027
Timestep Collection Time: 3.82871
Timestep Consumption Time: 3.11113
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 6.93984
Cumulative Model Updates: 151,013
Cumulative Timesteps: 1,205,173,318
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1205173318...
Checkpoint 1205173318 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60750
Policy Entropy: 4.33280
Value Function Loss: 0.00270
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03347
Policy Update Magnitude: 1.02476
Value Function Update Magnitude: 0.78098
Collected Steps per Second: 12,983.94850
Overall Steps per Second: 7,209.63018
Timestep Collection Time: 3.85353
Timestep Consumption Time: 3.08636
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.93988
Cumulative Model Updates: 151,022
Cumulative Timesteps: 1,205,223,352
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.96171
Policy Entropy: 4.33020
Value Function Loss: 0.00265
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 1.01793
Value Function Update Magnitude: 0.74219
Collected Steps per Second: 13,019.98883
Overall Steps per Second: 7,307.27084
Timestep Collection Time: 3.84071
Timestep Consumption Time: 3.00261
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.84332
Cumulative Model Updates: 151,031
Cumulative Timesteps: 1,205,273,358
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1205273358...
Checkpoint 1205273358 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27393
Policy Entropy: 4.32912
Value Function Loss: 0.00271
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 1.04046
Value Function Update Magnitude: 0.74431
Collected Steps per Second: 12,814.60184
Overall Steps per Second: 7,131.17479
Timestep Collection Time: 3.90430
Timestep Consumption Time: 3.11166
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 7.01595
Cumulative Model Updates: 151,040
Cumulative Timesteps: 1,205,323,390
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.89679
Policy Entropy: 4.31842
Value Function Loss: 0.00291
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03676
Policy Update Magnitude: 1.07824
Value Function Update Magnitude: 0.78388
Collected Steps per Second: 12,812.55643
Overall Steps per Second: 7,006.15726
Timestep Collection Time: 3.90430
Timestep Consumption Time: 3.23571
PPO Batch Consumption Time: 0.24134
Total Iteration Time: 7.14001
Cumulative Model Updates: 151,049
Cumulative Timesteps: 1,205,373,414
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1205373414...
Checkpoint 1205373414 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.44194
Policy Entropy: 4.32323
Value Function Loss: 0.00283
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03703
Policy Update Magnitude: 1.06657
Value Function Update Magnitude: 0.78922
Collected Steps per Second: 12,954.30003
Overall Steps per Second: 7,146.15297
Timestep Collection Time: 3.86173
Timestep Consumption Time: 3.13868
PPO Batch Consumption Time: 0.23009
Total Iteration Time: 7.00041
Cumulative Model Updates: 151,058
Cumulative Timesteps: 1,205,423,440
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.64280
Policy Entropy: 4.32773
Value Function Loss: 0.00278
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03922
Policy Update Magnitude: 1.02976
Value Function Update Magnitude: 0.77598
Collected Steps per Second: 13,132.31538
Overall Steps per Second: 7,231.52811
Timestep Collection Time: 3.80771
Timestep Consumption Time: 3.10701
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.91472
Cumulative Model Updates: 151,067
Cumulative Timesteps: 1,205,473,444
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1205473444...
Checkpoint 1205473444 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.79652
Policy Entropy: 4.33369
Value Function Loss: 0.00267
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03155
Policy Update Magnitude: 1.03477
Value Function Update Magnitude: 0.81417
Collected Steps per Second: 13,071.73078
Overall Steps per Second: 7,224.22812
Timestep Collection Time: 3.82688
Timestep Consumption Time: 3.09759
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.92448
Cumulative Model Updates: 151,076
Cumulative Timesteps: 1,205,523,468
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84103
Policy Entropy: 4.33235
Value Function Loss: 0.00266
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03156
Policy Update Magnitude: 1.04889
Value Function Update Magnitude: 0.83263
Collected Steps per Second: 12,949.32035
Overall Steps per Second: 7,309.96695
Timestep Collection Time: 3.86182
Timestep Consumption Time: 2.97925
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.84107
Cumulative Model Updates: 151,085
Cumulative Timesteps: 1,205,573,476
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1205573476...
Checkpoint 1205573476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75344
Policy Entropy: 4.33227
Value Function Loss: 0.00262
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03223
Policy Update Magnitude: 1.04285
Value Function Update Magnitude: 0.80105
Collected Steps per Second: 12,926.32565
Overall Steps per Second: 7,178.74410
Timestep Collection Time: 3.86993
Timestep Consumption Time: 3.09842
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.96835
Cumulative Model Updates: 151,094
Cumulative Timesteps: 1,205,623,500
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.41831
Policy Entropy: 4.33408
Value Function Loss: 0.00259
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03403
Policy Update Magnitude: 1.02126
Value Function Update Magnitude: 0.79421
Collected Steps per Second: 12,907.60317
Overall Steps per Second: 7,203.92314
Timestep Collection Time: 3.87477
Timestep Consumption Time: 3.06784
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.94261
Cumulative Model Updates: 151,103
Cumulative Timesteps: 1,205,673,514
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1205673514...
Checkpoint 1205673514 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32299
Policy Entropy: 4.33865
Value Function Loss: 0.00258
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03586
Policy Update Magnitude: 1.02498
Value Function Update Magnitude: 0.78412
Collected Steps per Second: 12,819.42672
Overall Steps per Second: 7,179.40147
Timestep Collection Time: 3.90127
Timestep Consumption Time: 3.06477
PPO Batch Consumption Time: 0.23030
Total Iteration Time: 6.96604
Cumulative Model Updates: 151,112
Cumulative Timesteps: 1,205,723,526
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.32988
Policy Entropy: 4.33890
Value Function Loss: 0.00257
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03322
Policy Update Magnitude: 1.02031
Value Function Update Magnitude: 0.80146
Collected Steps per Second: 12,929.43641
Overall Steps per Second: 7,152.95749
Timestep Collection Time: 3.86916
Timestep Consumption Time: 3.12459
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.99375
Cumulative Model Updates: 151,121
Cumulative Timesteps: 1,205,773,552
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1205773552...
Checkpoint 1205773552 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.35332
Policy Entropy: 4.33702
Value Function Loss: 0.00268
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 1.02808
Value Function Update Magnitude: 0.82988
Collected Steps per Second: 12,986.29191
Overall Steps per Second: 7,209.40962
Timestep Collection Time: 3.85068
Timestep Consumption Time: 3.08554
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.93621
Cumulative Model Updates: 151,130
Cumulative Timesteps: 1,205,823,558
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23831
Policy Entropy: 4.33006
Value Function Loss: 0.00268
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 1.04816
Value Function Update Magnitude: 0.85341
Collected Steps per Second: 12,894.75797
Overall Steps per Second: 7,275.51081
Timestep Collection Time: 3.88034
Timestep Consumption Time: 2.99698
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.87732
Cumulative Model Updates: 151,139
Cumulative Timesteps: 1,205,873,594
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1205873594...
Checkpoint 1205873594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.73369
Policy Entropy: 4.33157
Value Function Loss: 0.00268
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03455
Policy Update Magnitude: 1.03975
Value Function Update Magnitude: 0.83891
Collected Steps per Second: 12,890.27370
Overall Steps per Second: 7,155.62380
Timestep Collection Time: 3.87920
Timestep Consumption Time: 3.10887
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.98807
Cumulative Model Updates: 151,148
Cumulative Timesteps: 1,205,923,598
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.92324
Policy Entropy: 4.33650
Value Function Loss: 0.00254
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 1.01757
Value Function Update Magnitude: 0.82267
Collected Steps per Second: 12,876.86861
Overall Steps per Second: 7,134.06906
Timestep Collection Time: 3.88386
Timestep Consumption Time: 3.12644
PPO Batch Consumption Time: 0.23076
Total Iteration Time: 7.01031
Cumulative Model Updates: 151,157
Cumulative Timesteps: 1,205,973,610
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1205973610...
Checkpoint 1205973610 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81437
Policy Entropy: 4.33951
Value Function Loss: 0.00255
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03018
Policy Update Magnitude: 1.00540
Value Function Update Magnitude: 0.82423
Collected Steps per Second: 12,836.95763
Overall Steps per Second: 7,227.96285
Timestep Collection Time: 3.89765
Timestep Consumption Time: 3.02463
PPO Batch Consumption Time: 0.22960
Total Iteration Time: 6.92228
Cumulative Model Updates: 151,166
Cumulative Timesteps: 1,206,023,644
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90810
Policy Entropy: 4.33824
Value Function Loss: 0.00249
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02936
Policy Update Magnitude: 1.00748
Value Function Update Magnitude: 0.80589
Collected Steps per Second: 12,948.36122
Overall Steps per Second: 7,126.67370
Timestep Collection Time: 3.86196
Timestep Consumption Time: 3.15478
PPO Batch Consumption Time: 0.23287
Total Iteration Time: 7.01674
Cumulative Model Updates: 151,175
Cumulative Timesteps: 1,206,073,650
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1206073650...
Checkpoint 1206073650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12318
Policy Entropy: 4.33912
Value Function Loss: 0.00248
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03300
Policy Update Magnitude: 1.00494
Value Function Update Magnitude: 0.79193
Collected Steps per Second: 12,931.53611
Overall Steps per Second: 7,173.23436
Timestep Collection Time: 3.86760
Timestep Consumption Time: 3.10471
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.97231
Cumulative Model Updates: 151,184
Cumulative Timesteps: 1,206,123,664
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.77185
Policy Entropy: 4.33776
Value Function Loss: 0.00250
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03147
Policy Update Magnitude: 1.01012
Value Function Update Magnitude: 0.78256
Collected Steps per Second: 12,918.00543
Overall Steps per Second: 7,210.68960
Timestep Collection Time: 3.87211
Timestep Consumption Time: 3.06481
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.93692
Cumulative Model Updates: 151,193
Cumulative Timesteps: 1,206,173,684
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1206173684...
Checkpoint 1206173684 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.81681
Policy Entropy: 4.34098
Value Function Loss: 0.00263
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 1.00097
Value Function Update Magnitude: 0.77718
Collected Steps per Second: 13,243.73302
Overall Steps per Second: 7,248.56194
Timestep Collection Time: 3.77764
Timestep Consumption Time: 3.12442
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.90206
Cumulative Model Updates: 151,202
Cumulative Timesteps: 1,206,223,714
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.86938
Policy Entropy: 4.33730
Value Function Loss: 0.00268
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03106
Policy Update Magnitude: 1.01580
Value Function Update Magnitude: 0.79853
Collected Steps per Second: 12,754.09184
Overall Steps per Second: 7,128.86851
Timestep Collection Time: 3.92298
Timestep Consumption Time: 3.09553
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 7.01851
Cumulative Model Updates: 151,211
Cumulative Timesteps: 1,206,273,748
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1206273748...
Checkpoint 1206273748 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.79295
Policy Entropy: 4.33492
Value Function Loss: 0.00264
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03112
Policy Update Magnitude: 1.03038
Value Function Update Magnitude: 0.79841
Collected Steps per Second: 12,966.50479
Overall Steps per Second: 7,217.69884
Timestep Collection Time: 3.85902
Timestep Consumption Time: 3.07366
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.93268
Cumulative Model Updates: 151,220
Cumulative Timesteps: 1,206,323,786
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.34579
Policy Entropy: 4.33693
Value Function Loss: 0.00244
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03159
Policy Update Magnitude: 0.99528
Value Function Update Magnitude: 0.77492
Collected Steps per Second: 13,166.96906
Overall Steps per Second: 7,200.45948
Timestep Collection Time: 3.80194
Timestep Consumption Time: 3.15040
PPO Batch Consumption Time: 0.22920
Total Iteration Time: 6.95233
Cumulative Model Updates: 151,229
Cumulative Timesteps: 1,206,373,846
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 1206373846...
Checkpoint 1206373846 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05741
Policy Entropy: 4.34048
Value Function Loss: 0.00254
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03250
Policy Update Magnitude: 1.00802
Value Function Update Magnitude: 0.75158
Collected Steps per Second: 12,750.99538
Overall Steps per Second: 7,079.72629
Timestep Collection Time: 3.92220
Timestep Consumption Time: 3.14191
PPO Batch Consumption Time: 0.23000
Total Iteration Time: 7.06411
Cumulative Model Updates: 151,238
Cumulative Timesteps: 1,206,423,858
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19587
Policy Entropy: 4.34369
Value Function Loss: 0.00251
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03236
Policy Update Magnitude: 1.01882
Value Function Update Magnitude: 0.76379
Collected Steps per Second: 12,983.82299
Overall Steps per Second: 7,229.39353
Timestep Collection Time: 3.85295
Timestep Consumption Time: 3.06686
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.91981
Cumulative Model Updates: 151,247
Cumulative Timesteps: 1,206,473,884
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1206473884...
Checkpoint 1206473884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.48511
Policy Entropy: 4.34070
Value Function Loss: 0.00264
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 1.01350
Value Function Update Magnitude: 0.77055
Collected Steps per Second: 12,835.65426
Overall Steps per Second: 7,250.74040
Timestep Collection Time: 3.89727
Timestep Consumption Time: 3.00189
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.89916
Cumulative Model Updates: 151,256
Cumulative Timesteps: 1,206,523,908
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.30832
Policy Entropy: 4.33858
Value Function Loss: 0.00257
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03193
Policy Update Magnitude: 1.03275
Value Function Update Magnitude: 0.76351
Collected Steps per Second: 13,040.82675
Overall Steps per Second: 7,215.35637
Timestep Collection Time: 3.83473
Timestep Consumption Time: 3.09605
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.93077
Cumulative Model Updates: 151,265
Cumulative Timesteps: 1,206,573,916
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1206573916...
Checkpoint 1206573916 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.20095
Policy Entropy: 4.34003
Value Function Loss: 0.00259
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03260
Policy Update Magnitude: 1.02375
Value Function Update Magnitude: 0.79320
Collected Steps per Second: 12,921.19161
Overall Steps per Second: 7,214.52620
Timestep Collection Time: 3.87008
Timestep Consumption Time: 3.06122
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.93129
Cumulative Model Updates: 151,274
Cumulative Timesteps: 1,206,623,922
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97275
Policy Entropy: 4.33706
Value Function Loss: 0.00256
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03340
Policy Update Magnitude: 1.00974
Value Function Update Magnitude: 0.81490
Collected Steps per Second: 13,258.73301
Overall Steps per Second: 7,256.52985
Timestep Collection Time: 3.77216
Timestep Consumption Time: 3.12012
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.89228
Cumulative Model Updates: 151,283
Cumulative Timesteps: 1,206,673,936
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1206673936...
Checkpoint 1206673936 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70557
Policy Entropy: 4.33694
Value Function Loss: 0.00269
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03286
Policy Update Magnitude: 1.03678
Value Function Update Magnitude: 0.80351
Collected Steps per Second: 13,089.39167
Overall Steps per Second: 7,211.52453
Timestep Collection Time: 3.82065
Timestep Consumption Time: 3.11408
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.93473
Cumulative Model Updates: 151,292
Cumulative Timesteps: 1,206,723,946
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31340
Policy Entropy: 4.33516
Value Function Loss: 0.00271
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03384
Policy Update Magnitude: 1.05063
Value Function Update Magnitude: 0.82822
Collected Steps per Second: 12,977.94916
Overall Steps per Second: 7,150.33103
Timestep Collection Time: 3.85377
Timestep Consumption Time: 3.14087
PPO Batch Consumption Time: 0.23370
Total Iteration Time: 6.99464
Cumulative Model Updates: 151,301
Cumulative Timesteps: 1,206,773,960
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1206773960...
Checkpoint 1206773960 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.19517
Policy Entropy: 4.33402
Value Function Loss: 0.00281
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 1.06361
Value Function Update Magnitude: 0.84114
Collected Steps per Second: 12,835.38641
Overall Steps per Second: 7,240.80471
Timestep Collection Time: 3.89875
Timestep Consumption Time: 3.01236
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.91111
Cumulative Model Updates: 151,310
Cumulative Timesteps: 1,206,824,002
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.89010
Policy Entropy: 4.33520
Value Function Loss: 0.00277
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03462
Policy Update Magnitude: 1.07646
Value Function Update Magnitude: 0.84279
Collected Steps per Second: 12,743.65335
Overall Steps per Second: 7,119.71297
Timestep Collection Time: 3.92635
Timestep Consumption Time: 3.10146
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 7.02781
Cumulative Model Updates: 151,319
Cumulative Timesteps: 1,206,874,038
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1206874038...
Checkpoint 1206874038 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.34821
Policy Entropy: 4.33536
Value Function Loss: 0.00281
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03539
Policy Update Magnitude: 1.05641
Value Function Update Magnitude: 0.85861
Collected Steps per Second: 12,860.39858
Overall Steps per Second: 7,195.78527
Timestep Collection Time: 3.88806
Timestep Consumption Time: 3.06073
PPO Batch Consumption Time: 0.22921
Total Iteration Time: 6.94879
Cumulative Model Updates: 151,328
Cumulative Timesteps: 1,206,924,040
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.08286
Policy Entropy: 4.33544
Value Function Loss: 0.00268
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 1.03880
Value Function Update Magnitude: 0.83290
Collected Steps per Second: 12,975.00136
Overall Steps per Second: 7,295.78502
Timestep Collection Time: 3.85449
Timestep Consumption Time: 3.00043
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.85492
Cumulative Model Updates: 151,337
Cumulative Timesteps: 1,206,974,052
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1206974052...
Checkpoint 1206974052 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61623
Policy Entropy: 4.33462
Value Function Loss: 0.00260
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03300
Policy Update Magnitude: 1.03665
Value Function Update Magnitude: 0.78652
Collected Steps per Second: 12,982.41798
Overall Steps per Second: 7,198.13988
Timestep Collection Time: 3.85229
Timestep Consumption Time: 3.09562
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.94791
Cumulative Model Updates: 151,346
Cumulative Timesteps: 1,207,024,064
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22127
Policy Entropy: 4.32868
Value Function Loss: 0.00279
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03262
Policy Update Magnitude: 1.06508
Value Function Update Magnitude: 0.77375
Collected Steps per Second: 13,004.60557
Overall Steps per Second: 7,228.22747
Timestep Collection Time: 3.84910
Timestep Consumption Time: 3.07597
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.92507
Cumulative Model Updates: 151,355
Cumulative Timesteps: 1,207,074,120
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1207074120...
Checkpoint 1207074120 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.79478
Policy Entropy: 4.32697
Value Function Loss: 0.00298
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03562
Policy Update Magnitude: 1.09453
Value Function Update Magnitude: 0.83329
Collected Steps per Second: 12,917.46118
Overall Steps per Second: 7,241.68551
Timestep Collection Time: 3.87259
Timestep Consumption Time: 3.03520
PPO Batch Consumption Time: 0.22970
Total Iteration Time: 6.90778
Cumulative Model Updates: 151,364
Cumulative Timesteps: 1,207,124,144
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.23351
Policy Entropy: 4.32780
Value Function Loss: 0.00301
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03694
Policy Update Magnitude: 1.10141
Value Function Update Magnitude: 0.86376
Collected Steps per Second: 13,010.29143
Overall Steps per Second: 7,207.11571
Timestep Collection Time: 3.84403
Timestep Consumption Time: 3.09522
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.93925
Cumulative Model Updates: 151,373
Cumulative Timesteps: 1,207,174,156
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1207174156...
Checkpoint 1207174156 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.36291
Policy Entropy: 4.32853
Value Function Loss: 0.00291
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03578
Policy Update Magnitude: 1.09902
Value Function Update Magnitude: 0.88063
Collected Steps per Second: 12,918.94630
Overall Steps per Second: 7,199.21585
Timestep Collection Time: 3.87323
Timestep Consumption Time: 3.07725
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.95048
Cumulative Model Updates: 151,382
Cumulative Timesteps: 1,207,224,194
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.26351
Policy Entropy: 4.33327
Value Function Loss: 0.00281
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03526
Policy Update Magnitude: 1.07813
Value Function Update Magnitude: 0.83316
Collected Steps per Second: 12,994.05491
Overall Steps per Second: 7,312.54414
Timestep Collection Time: 3.85022
Timestep Consumption Time: 2.99145
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.84167
Cumulative Model Updates: 151,391
Cumulative Timesteps: 1,207,274,224
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1207274224...
Checkpoint 1207274224 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.37295
Policy Entropy: 4.33348
Value Function Loss: 0.00279
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03462
Policy Update Magnitude: 1.06512
Value Function Update Magnitude: 0.81407
Collected Steps per Second: 12,853.01759
Overall Steps per Second: 7,167.90259
Timestep Collection Time: 3.89138
Timestep Consumption Time: 3.08639
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.97777
Cumulative Model Updates: 151,400
Cumulative Timesteps: 1,207,324,240
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82388
Policy Entropy: 4.33372
Value Function Loss: 0.00282
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03428
Policy Update Magnitude: 1.06420
Value Function Update Magnitude: 0.79683
Collected Steps per Second: 12,807.30059
Overall Steps per Second: 7,171.72245
Timestep Collection Time: 3.90605
Timestep Consumption Time: 3.06940
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.97545
Cumulative Model Updates: 151,409
Cumulative Timesteps: 1,207,374,266
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1207374266...
Checkpoint 1207374266 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99888
Policy Entropy: 4.33183
Value Function Loss: 0.00288
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03667
Policy Update Magnitude: 1.06899
Value Function Update Magnitude: 0.79983
Collected Steps per Second: 12,939.01839
Overall Steps per Second: 7,284.84369
Timestep Collection Time: 3.86629
Timestep Consumption Time: 3.00084
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.86713
Cumulative Model Updates: 151,418
Cumulative Timesteps: 1,207,424,292
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40858
Policy Entropy: 4.33275
Value Function Loss: 0.00287
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03579
Policy Update Magnitude: 1.07404
Value Function Update Magnitude: 0.84779
Collected Steps per Second: 12,909.72423
Overall Steps per Second: 7,114.77911
Timestep Collection Time: 3.87429
Timestep Consumption Time: 3.15559
PPO Batch Consumption Time: 0.22984
Total Iteration Time: 7.02987
Cumulative Model Updates: 151,427
Cumulative Timesteps: 1,207,474,308
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1207474308...
Checkpoint 1207474308 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.51954
Policy Entropy: 4.33360
Value Function Loss: 0.00279
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03566
Policy Update Magnitude: 1.05157
Value Function Update Magnitude: 0.83916
Collected Steps per Second: 12,960.32315
Overall Steps per Second: 7,191.05823
Timestep Collection Time: 3.85885
Timestep Consumption Time: 3.09589
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.95475
Cumulative Model Updates: 151,436
Cumulative Timesteps: 1,207,524,320
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.83010
Policy Entropy: 4.33471
Value Function Loss: 0.00270
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03537
Policy Update Magnitude: 1.04717
Value Function Update Magnitude: 0.85159
Collected Steps per Second: 12,988.27926
Overall Steps per Second: 7,280.97472
Timestep Collection Time: 3.85116
Timestep Consumption Time: 3.01879
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.86996
Cumulative Model Updates: 151,445
Cumulative Timesteps: 1,207,574,340
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1207574340...
Checkpoint 1207574340 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.01398
Policy Entropy: 4.33386
Value Function Loss: 0.00271
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03600
Policy Update Magnitude: 1.06249
Value Function Update Magnitude: 0.85183
Collected Steps per Second: 12,795.37699
Overall Steps per Second: 7,133.63443
Timestep Collection Time: 3.90907
Timestep Consumption Time: 3.10251
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 7.01157
Cumulative Model Updates: 151,454
Cumulative Timesteps: 1,207,624,358
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86590
Policy Entropy: 4.33056
Value Function Loss: 0.00275
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03592
Policy Update Magnitude: 1.06387
Value Function Update Magnitude: 0.82974
Collected Steps per Second: 12,862.71895
Overall Steps per Second: 7,163.67270
Timestep Collection Time: 3.88751
Timestep Consumption Time: 3.09270
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.98022
Cumulative Model Updates: 151,463
Cumulative Timesteps: 1,207,674,362
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1207674362...
Checkpoint 1207674362 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.20811
Policy Entropy: 4.32984
Value Function Loss: 0.00284
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03581
Policy Update Magnitude: 1.07036
Value Function Update Magnitude: 0.82333
Collected Steps per Second: 12,911.97599
Overall Steps per Second: 7,255.69072
Timestep Collection Time: 3.87516
Timestep Consumption Time: 3.02094
PPO Batch Consumption Time: 0.22923
Total Iteration Time: 6.89610
Cumulative Model Updates: 151,472
Cumulative Timesteps: 1,207,724,398
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.39671
Policy Entropy: 4.33387
Value Function Loss: 0.00274
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 1.04863
Value Function Update Magnitude: 0.80189
Collected Steps per Second: 12,903.83365
Overall Steps per Second: 7,163.41529
Timestep Collection Time: 3.87621
Timestep Consumption Time: 3.10621
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.98242
Cumulative Model Updates: 151,481
Cumulative Timesteps: 1,207,774,416
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1207774416...
Checkpoint 1207774416 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.99437
Policy Entropy: 4.33837
Value Function Loss: 0.00270
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03435
Policy Update Magnitude: 1.02220
Value Function Update Magnitude: 0.79324
Collected Steps per Second: 12,903.86535
Overall Steps per Second: 7,048.26906
Timestep Collection Time: 3.87775
Timestep Consumption Time: 3.22158
PPO Batch Consumption Time: 0.24039
Total Iteration Time: 7.09933
Cumulative Model Updates: 151,490
Cumulative Timesteps: 1,207,824,454
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.94200
Policy Entropy: 4.33720
Value Function Loss: 0.00257
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 1.02321
Value Function Update Magnitude: 0.78242
Collected Steps per Second: 12,870.13008
Overall Steps per Second: 7,271.94710
Timestep Collection Time: 3.88714
Timestep Consumption Time: 2.99245
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.87959
Cumulative Model Updates: 151,499
Cumulative Timesteps: 1,207,874,482
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1207874482...
Checkpoint 1207874482 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.55929
Policy Entropy: 4.33513
Value Function Loss: 0.00267
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03320
Policy Update Magnitude: 1.04494
Value Function Update Magnitude: 0.81537
Collected Steps per Second: 12,983.72372
Overall Steps per Second: 7,180.67378
Timestep Collection Time: 3.85236
Timestep Consumption Time: 3.11328
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.96564
Cumulative Model Updates: 151,508
Cumulative Timesteps: 1,207,924,500
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.13007
Policy Entropy: 4.33114
Value Function Loss: 0.00282
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03510
Policy Update Magnitude: 1.07967
Value Function Update Magnitude: 0.85312
Collected Steps per Second: 12,940.64759
Overall Steps per Second: 7,230.50983
Timestep Collection Time: 3.86658
Timestep Consumption Time: 3.05354
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.92012
Cumulative Model Updates: 151,517
Cumulative Timesteps: 1,207,974,536
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1207974536...
Checkpoint 1207974536 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.16138
Policy Entropy: 4.33126
Value Function Loss: 0.00282
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03547
Policy Update Magnitude: 1.08414
Value Function Update Magnitude: 0.87957
Collected Steps per Second: 12,868.17890
Overall Steps per Second: 7,262.54463
Timestep Collection Time: 3.88633
Timestep Consumption Time: 2.99969
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.88602
Cumulative Model Updates: 151,526
Cumulative Timesteps: 1,208,024,546
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61312
Policy Entropy: 4.33296
Value Function Loss: 0.00276
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03406
Policy Update Magnitude: 1.05754
Value Function Update Magnitude: 0.88002
Collected Steps per Second: 12,872.35971
Overall Steps per Second: 7,151.80558
Timestep Collection Time: 3.88429
Timestep Consumption Time: 3.10695
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.99124
Cumulative Model Updates: 151,535
Cumulative Timesteps: 1,208,074,546
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1208074546...
Checkpoint 1208074546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49868
Policy Entropy: 4.33602
Value Function Loss: 0.00265
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03248
Policy Update Magnitude: 1.04287
Value Function Update Magnitude: 0.85703
Collected Steps per Second: 13,009.58659
Overall Steps per Second: 7,213.87605
Timestep Collection Time: 3.84347
Timestep Consumption Time: 3.08789
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.93136
Cumulative Model Updates: 151,544
Cumulative Timesteps: 1,208,124,548
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.15968
Policy Entropy: 4.33359
Value Function Loss: 0.00266
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03195
Policy Update Magnitude: 1.03954
Value Function Update Magnitude: 0.85220
Collected Steps per Second: 12,857.66170
Overall Steps per Second: 7,102.27283
Timestep Collection Time: 3.89138
Timestep Consumption Time: 3.15341
PPO Batch Consumption Time: 0.23991
Total Iteration Time: 7.04479
Cumulative Model Updates: 151,553
Cumulative Timesteps: 1,208,174,582
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1208174582...
Checkpoint 1208174582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.07437
Policy Entropy: 4.33271
Value Function Loss: 0.00271
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03269
Policy Update Magnitude: 1.04551
Value Function Update Magnitude: 0.82650
Collected Steps per Second: 12,953.00488
Overall Steps per Second: 7,183.26202
Timestep Collection Time: 3.86103
Timestep Consumption Time: 3.10126
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.96230
Cumulative Model Updates: 151,562
Cumulative Timesteps: 1,208,224,594
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.83055
Policy Entropy: 4.32891
Value Function Loss: 0.00287
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03322
Policy Update Magnitude: 1.07707
Value Function Update Magnitude: 0.81222
Collected Steps per Second: 12,924.33641
Overall Steps per Second: 7,200.89723
Timestep Collection Time: 3.87238
Timestep Consumption Time: 3.07786
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.95024
Cumulative Model Updates: 151,571
Cumulative Timesteps: 1,208,274,642
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1208274642...
Checkpoint 1208274642 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30206
Policy Entropy: 4.32511
Value Function Loss: 0.00297
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03507
Policy Update Magnitude: 1.08052
Value Function Update Magnitude: 0.83545
Collected Steps per Second: 13,245.63931
Overall Steps per Second: 7,258.78664
Timestep Collection Time: 3.77558
Timestep Consumption Time: 3.11400
PPO Batch Consumption Time: 0.22925
Total Iteration Time: 6.88958
Cumulative Model Updates: 151,580
Cumulative Timesteps: 1,208,324,652
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.91044
Policy Entropy: 4.32047
Value Function Loss: 0.00298
Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03981
Policy Update Magnitude: 1.07448
Value Function Update Magnitude: 0.84374
Collected Steps per Second: 13,040.18814
Overall Steps per Second: 7,200.33507
Timestep Collection Time: 3.83599
Timestep Consumption Time: 3.11119
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.94718
Cumulative Model Updates: 151,589
Cumulative Timesteps: 1,208,374,674
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1208374674...
Checkpoint 1208374674 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.26050
Policy Entropy: 4.32354
Value Function Loss: 0.00285
Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04010
Policy Update Magnitude: 1.08507
Value Function Update Magnitude: 0.88650
Collected Steps per Second: 12,833.67023
Overall Steps per Second: 7,159.31878
Timestep Collection Time: 3.89631
Timestep Consumption Time: 3.08815
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.98446
Cumulative Model Updates: 151,598
Cumulative Timesteps: 1,208,424,678
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53070
Policy Entropy: 4.32507
Value Function Loss: 0.00289
Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03869
Policy Update Magnitude: 1.08110
Value Function Update Magnitude: 0.88633
Collected Steps per Second: 13,248.68425
Overall Steps per Second: 7,293.70603
Timestep Collection Time: 3.77638
Timestep Consumption Time: 3.08324
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.85961
Cumulative Model Updates: 151,607
Cumulative Timesteps: 1,208,474,710
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1208474710...
Checkpoint 1208474710 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.94779
Policy Entropy: 4.32791
Value Function Loss: 0.00286
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03676
Policy Update Magnitude: 1.08373
Value Function Update Magnitude: 0.87232
Collected Steps per Second: 12,832.62567
Overall Steps per Second: 6,965.12003
Timestep Collection Time: 3.89912
Timestep Consumption Time: 3.28467
PPO Batch Consumption Time: 0.24234
Total Iteration Time: 7.18380
Cumulative Model Updates: 151,616
Cumulative Timesteps: 1,208,524,746
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.78848
Policy Entropy: 4.32896
Value Function Loss: 0.00287
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03479
Policy Update Magnitude: 1.08333
Value Function Update Magnitude: 0.85243
Collected Steps per Second: 12,337.37771
Overall Steps per Second: 6,989.21598
Timestep Collection Time: 4.05499
Timestep Consumption Time: 3.10289
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 7.15788
Cumulative Model Updates: 151,625
Cumulative Timesteps: 1,208,574,774
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1208574774...
Checkpoint 1208574774 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.81455
Policy Entropy: 4.32862
Value Function Loss: 0.00280
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03482
Policy Update Magnitude: 1.07203
Value Function Update Magnitude: 0.83114
Collected Steps per Second: 12,813.63526
Overall Steps per Second: 7,222.43043
Timestep Collection Time: 3.90475
Timestep Consumption Time: 3.02284
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.92758
Cumulative Model Updates: 151,634
Cumulative Timesteps: 1,208,624,808
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.28267
Policy Entropy: 4.33214
Value Function Loss: 0.00284
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03538
Policy Update Magnitude: 1.08984
Value Function Update Magnitude: 0.84462
Collected Steps per Second: 12,860.06888
Overall Steps per Second: 7,121.23757
Timestep Collection Time: 3.88832
Timestep Consumption Time: 3.13350
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 7.02181
Cumulative Model Updates: 151,643
Cumulative Timesteps: 1,208,674,812
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1208674812...
Checkpoint 1208674812 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.78541
Policy Entropy: 4.33482
Value Function Loss: 0.00274
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03650
Policy Update Magnitude: 1.07635
Value Function Update Magnitude: 0.82203
Collected Steps per Second: 12,928.05912
Overall Steps per Second: 7,191.69831
Timestep Collection Time: 3.86957
Timestep Consumption Time: 3.08651
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.95608
Cumulative Model Updates: 151,652
Cumulative Timesteps: 1,208,724,838
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66857
Policy Entropy: 4.33501
Value Function Loss: 0.00266
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03476
Policy Update Magnitude: 1.06926
Value Function Update Magnitude: 0.84403
Collected Steps per Second: 12,862.23480
Overall Steps per Second: 7,247.92407
Timestep Collection Time: 3.88844
Timestep Consumption Time: 3.01202
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.90046
Cumulative Model Updates: 151,661
Cumulative Timesteps: 1,208,774,852
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1208774852...
Checkpoint 1208774852 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.33870
Policy Entropy: 4.33678
Value Function Loss: 0.00260
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 1.05524
Value Function Update Magnitude: 0.87697
Collected Steps per Second: 12,964.99619
Overall Steps per Second: 7,137.06035
Timestep Collection Time: 3.85839
Timestep Consumption Time: 3.15066
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 7.00905
Cumulative Model Updates: 151,670
Cumulative Timesteps: 1,208,824,876
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.43274
Policy Entropy: 4.33424
Value Function Loss: 0.00275
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03473
Policy Update Magnitude: 1.07766
Value Function Update Magnitude: 0.84996
Collected Steps per Second: 12,880.55151
Overall Steps per Second: 7,046.36104
Timestep Collection Time: 3.88446
Timestep Consumption Time: 3.21623
PPO Batch Consumption Time: 0.23887
Total Iteration Time: 7.10069
Cumulative Model Updates: 151,679
Cumulative Timesteps: 1,208,874,910
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1208874910...
Checkpoint 1208874910 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.57696
Policy Entropy: 4.33364
Value Function Loss: 0.00287
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03649
Policy Update Magnitude: 1.09552
Value Function Update Magnitude: 0.83971
Collected Steps per Second: 12,895.81491
Overall Steps per Second: 7,255.04307
Timestep Collection Time: 3.87955
Timestep Consumption Time: 3.01634
PPO Batch Consumption Time: 0.22916
Total Iteration Time: 6.89589
Cumulative Model Updates: 151,688
Cumulative Timesteps: 1,208,924,940
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27579
Policy Entropy: 4.32996
Value Function Loss: 0.00287
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03514
Policy Update Magnitude: 1.09368
Value Function Update Magnitude: 0.84464
Collected Steps per Second: 12,968.55251
Overall Steps per Second: 7,204.35423
Timestep Collection Time: 3.85548
Timestep Consumption Time: 3.08477
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.94025
Cumulative Model Updates: 151,697
Cumulative Timesteps: 1,208,974,940
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1208974940...
Checkpoint 1208974940 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.35702
Policy Entropy: 4.33131
Value Function Loss: 0.00280
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03576
Policy Update Magnitude: 1.08590
Value Function Update Magnitude: 0.82420
Collected Steps per Second: 12,950.61669
Overall Steps per Second: 7,216.10878
Timestep Collection Time: 3.86267
Timestep Consumption Time: 3.06959
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.93227
Cumulative Model Updates: 151,706
Cumulative Timesteps: 1,209,024,964
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.15785
Policy Entropy: 4.32921
Value Function Loss: 0.00290
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03572
Policy Update Magnitude: 1.08919
Value Function Update Magnitude: 0.84641
Collected Steps per Second: 12,942.78981
Overall Steps per Second: 7,263.25124
Timestep Collection Time: 3.86578
Timestep Consumption Time: 3.02287
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.88865
Cumulative Model Updates: 151,715
Cumulative Timesteps: 1,209,074,998
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1209074998...
Checkpoint 1209074998 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.29223
Policy Entropy: 4.33049
Value Function Loss: 0.00285
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 1.09226
Value Function Update Magnitude: 0.84790
Collected Steps per Second: 13,000.15128
Overall Steps per Second: 7,193.11948
Timestep Collection Time: 3.84719
Timestep Consumption Time: 3.10585
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.95303
Cumulative Model Updates: 151,724
Cumulative Timesteps: 1,209,125,012
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.98538
Policy Entropy: 4.32631
Value Function Loss: 0.00308
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03615
Policy Update Magnitude: 1.11705
Value Function Update Magnitude: 0.86243
Collected Steps per Second: 12,939.29706
Overall Steps per Second: 7,222.73528
Timestep Collection Time: 3.86636
Timestep Consumption Time: 3.06010
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.92646
Cumulative Model Updates: 151,733
Cumulative Timesteps: 1,209,175,040
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1209175040...
Checkpoint 1209175040 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.77577
Policy Entropy: 4.32564
Value Function Loss: 0.00307
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03585
Policy Update Magnitude: 1.12751
Value Function Update Magnitude: 0.88976
Collected Steps per Second: 12,981.36673
Overall Steps per Second: 7,132.10930
Timestep Collection Time: 3.85476
Timestep Consumption Time: 3.16140
PPO Batch Consumption Time: 0.24099
Total Iteration Time: 7.01616
Cumulative Model Updates: 151,742
Cumulative Timesteps: 1,209,225,080
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.14767
Policy Entropy: 4.32184
Value Function Loss: 0.00315
Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03863
Policy Update Magnitude: 1.12759
Value Function Update Magnitude: 0.90580
Collected Steps per Second: 13,029.72408
Overall Steps per Second: 7,190.55321
Timestep Collection Time: 3.83738
Timestep Consumption Time: 3.11619
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.95357
Cumulative Model Updates: 151,751
Cumulative Timesteps: 1,209,275,080
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1209275080...
Checkpoint 1209275080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50689
Policy Entropy: 4.32714
Value Function Loss: 0.00284
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03560
Policy Update Magnitude: 1.09372
Value Function Update Magnitude: 0.89870
Collected Steps per Second: 12,930.16329
Overall Steps per Second: 7,209.33948
Timestep Collection Time: 3.86755
Timestep Consumption Time: 3.06901
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.93656
Cumulative Model Updates: 151,760
Cumulative Timesteps: 1,209,325,088
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42427
Policy Entropy: 4.32829
Value Function Loss: 0.00287
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03505
Policy Update Magnitude: 1.07742
Value Function Update Magnitude: 0.88419
Collected Steps per Second: 12,990.60491
Overall Steps per Second: 7,273.42691
Timestep Collection Time: 3.85063
Timestep Consumption Time: 3.02673
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.87736
Cumulative Model Updates: 151,769
Cumulative Timesteps: 1,209,375,110
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1209375110...
Checkpoint 1209375110 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.80202
Policy Entropy: 4.32862
Value Function Loss: 0.00287
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03473
Policy Update Magnitude: 1.08381
Value Function Update Magnitude: 0.91092
Collected Steps per Second: 12,990.01528
Overall Steps per Second: 7,196.38470
Timestep Collection Time: 3.85204
Timestep Consumption Time: 3.10118
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.95321
Cumulative Model Updates: 151,778
Cumulative Timesteps: 1,209,425,148
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05542
Policy Entropy: 4.32404
Value Function Loss: 0.00289
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03782
Policy Update Magnitude: 1.09858
Value Function Update Magnitude: 0.91584
Collected Steps per Second: 12,919.98208
Overall Steps per Second: 7,201.51361
Timestep Collection Time: 3.87106
Timestep Consumption Time: 3.07387
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.94493
Cumulative Model Updates: 151,787
Cumulative Timesteps: 1,209,475,162
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1209475162...
Checkpoint 1209475162 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.17453
Policy Entropy: 4.32428
Value Function Loss: 0.00296
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03654
Policy Update Magnitude: 1.10824
Value Function Update Magnitude: 0.89895
Collected Steps per Second: 12,776.09121
Overall Steps per Second: 7,222.97750
Timestep Collection Time: 3.91638
Timestep Consumption Time: 3.01096
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.92734
Cumulative Model Updates: 151,796
Cumulative Timesteps: 1,209,525,198
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.42437
Policy Entropy: 4.32660
Value Function Loss: 0.00297
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03622
Policy Update Magnitude: 1.10421
Value Function Update Magnitude: 0.86867
Collected Steps per Second: 13,023.38086
Overall Steps per Second: 7,129.10967
Timestep Collection Time: 3.84002
Timestep Consumption Time: 3.17488
PPO Batch Consumption Time: 0.23019
Total Iteration Time: 7.01490
Cumulative Model Updates: 151,805
Cumulative Timesteps: 1,209,575,208
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1209575208...
Checkpoint 1209575208 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12270
Policy Entropy: 4.32405
Value Function Loss: 0.00324
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03922
Policy Update Magnitude: 1.12192
Value Function Update Magnitude: 0.89219
Collected Steps per Second: 12,662.12943
Overall Steps per Second: 7,112.37574
Timestep Collection Time: 3.95036
Timestep Consumption Time: 3.08245
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 7.03281
Cumulative Model Updates: 151,814
Cumulative Timesteps: 1,209,625,228
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.43030
Policy Entropy: 4.32737
Value Function Loss: 0.00308
Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03877
Policy Update Magnitude: 1.11688
Value Function Update Magnitude: 0.89170
Collected Steps per Second: 12,903.53444
Overall Steps per Second: 7,263.19231
Timestep Collection Time: 3.87553
Timestep Consumption Time: 3.00960
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.88513
Cumulative Model Updates: 151,823
Cumulative Timesteps: 1,209,675,236
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1209675236...
Checkpoint 1209675236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06044
Policy Entropy: 4.32795
Value Function Loss: 0.00303
Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03937
Policy Update Magnitude: 1.10088
Value Function Update Magnitude: 0.89242
Collected Steps per Second: 12,869.02846
Overall Steps per Second: 7,136.92649
Timestep Collection Time: 3.88685
Timestep Consumption Time: 3.12177
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 7.00862
Cumulative Model Updates: 151,832
Cumulative Timesteps: 1,209,725,256
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60314
Policy Entropy: 4.33297
Value Function Loss: 0.00277
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03580
Policy Update Magnitude: 1.07729
Value Function Update Magnitude: 0.87748
Collected Steps per Second: 12,865.18302
Overall Steps per Second: 7,177.35301
Timestep Collection Time: 3.88724
Timestep Consumption Time: 3.08051
PPO Batch Consumption Time: 0.22940
Total Iteration Time: 6.96775
Cumulative Model Updates: 151,841
Cumulative Timesteps: 1,209,775,266
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1209775266...
Checkpoint 1209775266 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.60482
Policy Entropy: 4.33005
Value Function Loss: 0.00279
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 1.05962
Value Function Update Magnitude: 0.83318
Collected Steps per Second: 12,797.98803
Overall Steps per Second: 7,228.53636
Timestep Collection Time: 3.90686
Timestep Consumption Time: 3.01017
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.91703
Cumulative Model Updates: 151,850
Cumulative Timesteps: 1,209,825,266
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.56871
Policy Entropy: 4.32805
Value Function Loss: 0.00273
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03510
Policy Update Magnitude: 1.05603
Value Function Update Magnitude: 0.82131
Collected Steps per Second: 12,965.33415
Overall Steps per Second: 7,174.35272
Timestep Collection Time: 3.85875
Timestep Consumption Time: 3.11470
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.97345
Cumulative Model Updates: 151,859
Cumulative Timesteps: 1,209,875,296
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1209875296...
Checkpoint 1209875296 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25494
Policy Entropy: 4.32869
Value Function Loss: 0.00278
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 1.05067
Value Function Update Magnitude: 0.82385
Collected Steps per Second: 12,848.89056
Overall Steps per Second: 7,028.07003
Timestep Collection Time: 3.89403
Timestep Consumption Time: 3.22513
PPO Batch Consumption Time: 0.24182
Total Iteration Time: 7.11917
Cumulative Model Updates: 151,868
Cumulative Timesteps: 1,209,925,330
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27548
Policy Entropy: 4.32556
Value Function Loss: 0.00284
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03452
Policy Update Magnitude: 1.05344
Value Function Update Magnitude: 0.81983
Collected Steps per Second: 13,279.05265
Overall Steps per Second: 7,298.27341
Timestep Collection Time: 3.76593
Timestep Consumption Time: 3.08610
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.85203
Cumulative Model Updates: 151,877
Cumulative Timesteps: 1,209,975,338
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1209975338...
Checkpoint 1209975338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51547
Policy Entropy: 4.32634
Value Function Loss: 0.00302
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03619
Policy Update Magnitude: 1.07025
Value Function Update Magnitude: 0.82146
Collected Steps per Second: 12,926.51171
Overall Steps per Second: 7,150.85930
Timestep Collection Time: 3.86988
Timestep Consumption Time: 3.12565
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.99552
Cumulative Model Updates: 151,886
Cumulative Timesteps: 1,210,025,362
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.42645
Policy Entropy: 4.32204
Value Function Loss: 0.00304
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03802
Policy Update Magnitude: 1.06230
Value Function Update Magnitude: 0.81582
Collected Steps per Second: 12,931.43357
Overall Steps per Second: 7,197.98401
Timestep Collection Time: 3.86871
Timestep Consumption Time: 3.08157
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.95028
Cumulative Model Updates: 151,895
Cumulative Timesteps: 1,210,075,390
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1210075390...
Checkpoint 1210075390 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.98508
Policy Entropy: 4.32358
Value Function Loss: 0.00287
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03421
Policy Update Magnitude: 1.05015
Value Function Update Magnitude: 0.80480
Collected Steps per Second: 13,225.84962
Overall Steps per Second: 7,258.37986
Timestep Collection Time: 3.78153
Timestep Consumption Time: 3.10898
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.89052
Cumulative Model Updates: 151,904
Cumulative Timesteps: 1,210,125,404
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.59995
Policy Entropy: 4.32218
Value Function Loss: 0.00278
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03386
Policy Update Magnitude: 1.02006
Value Function Update Magnitude: 0.82470
Collected Steps per Second: 12,920.22365
Overall Steps per Second: 7,155.08526
Timestep Collection Time: 3.87191
Timestep Consumption Time: 3.11976
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.99167
Cumulative Model Updates: 151,913
Cumulative Timesteps: 1,210,175,430
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1210175430...
Checkpoint 1210175430 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.02520
Policy Entropy: 4.32267
Value Function Loss: 0.00276
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03320
Policy Update Magnitude: 1.03545
Value Function Update Magnitude: 0.85216
Collected Steps per Second: 12,939.69591
Overall Steps per Second: 7,199.37348
Timestep Collection Time: 3.86593
Timestep Consumption Time: 3.08245
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.94838
Cumulative Model Updates: 151,922
Cumulative Timesteps: 1,210,225,454
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.91936
Policy Entropy: 4.32352
Value Function Loss: 0.00270
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03490
Policy Update Magnitude: 1.02658
Value Function Update Magnitude: 0.82181
Collected Steps per Second: 13,047.50457
Overall Steps per Second: 7,161.50065
Timestep Collection Time: 3.83338
Timestep Consumption Time: 3.15063
PPO Batch Consumption Time: 0.23070
Total Iteration Time: 6.98401
Cumulative Model Updates: 151,931
Cumulative Timesteps: 1,210,275,470
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1210275470...
Checkpoint 1210275470 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77796
Policy Entropy: 4.32461
Value Function Loss: 0.00270
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03528
Policy Update Magnitude: 1.01371
Value Function Update Magnitude: 0.81273
Collected Steps per Second: 12,933.09130
Overall Steps per Second: 7,161.77901
Timestep Collection Time: 3.86667
Timestep Consumption Time: 3.11595
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.98262
Cumulative Model Updates: 151,940
Cumulative Timesteps: 1,210,325,478
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05979
Policy Entropy: 4.32548
Value Function Loss: 0.00267
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03411
Policy Update Magnitude: 1.01807
Value Function Update Magnitude: 0.82285
Collected Steps per Second: 12,950.45017
Overall Steps per Second: 7,175.87514
Timestep Collection Time: 3.86288
Timestep Consumption Time: 3.10854
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.97141
Cumulative Model Updates: 151,949
Cumulative Timesteps: 1,210,375,504
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1210375504...
Checkpoint 1210375504 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23980
Policy Entropy: 4.32924
Value Function Loss: 0.00278
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 1.02041
Value Function Update Magnitude: 0.80467
Collected Steps per Second: 13,223.95162
Overall Steps per Second: 7,263.39543
Timestep Collection Time: 3.78374
Timestep Consumption Time: 3.10505
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.88879
Cumulative Model Updates: 151,958
Cumulative Timesteps: 1,210,425,540
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.30328
Policy Entropy: 4.32521
Value Function Loss: 0.00278
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 1.02854
Value Function Update Magnitude: 0.79733
Collected Steps per Second: 13,075.60303
Overall Steps per Second: 7,189.02145
Timestep Collection Time: 3.82468
Timestep Consumption Time: 3.13176
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.95644
Cumulative Model Updates: 151,967
Cumulative Timesteps: 1,210,475,550
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1210475550...
Checkpoint 1210475550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.89193
Policy Entropy: 4.32645
Value Function Loss: 0.00275
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03656
Policy Update Magnitude: 1.02261
Value Function Update Magnitude: 0.78877
Collected Steps per Second: 12,866.02381
Overall Steps per Second: 7,188.52021
Timestep Collection Time: 3.88869
Timestep Consumption Time: 3.07129
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.95999
Cumulative Model Updates: 151,976
Cumulative Timesteps: 1,210,525,582
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70540
Policy Entropy: 4.32292
Value Function Loss: 0.00263
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03534
Policy Update Magnitude: 1.00032
Value Function Update Magnitude: 0.80307
Collected Steps per Second: 13,383.94685
Overall Steps per Second: 7,315.04612
Timestep Collection Time: 3.73911
Timestep Consumption Time: 3.10214
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.84124
Cumulative Model Updates: 151,985
Cumulative Timesteps: 1,210,575,626
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1210575626...
Checkpoint 1210575626 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02193
Policy Entropy: 4.32623
Value Function Loss: 0.00259
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 0.99336
Value Function Update Magnitude: 0.80270
Collected Steps per Second: 12,934.26797
Overall Steps per Second: 7,127.82155
Timestep Collection Time: 3.86833
Timestep Consumption Time: 3.15121
PPO Batch Consumption Time: 0.23015
Total Iteration Time: 7.01954
Cumulative Model Updates: 151,994
Cumulative Timesteps: 1,210,625,660
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.18704
Policy Entropy: 4.32790
Value Function Loss: 0.00254
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03218
Policy Update Magnitude: 0.99777
Value Function Update Magnitude: 0.80356
Collected Steps per Second: 12,868.40596
Overall Steps per Second: 7,184.06970
Timestep Collection Time: 3.88766
Timestep Consumption Time: 3.07608
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.96374
Cumulative Model Updates: 152,003
Cumulative Timesteps: 1,210,675,688
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1210675688...
Checkpoint 1210675688 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.43395
Policy Entropy: 4.32446
Value Function Loss: 0.00271
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03305
Policy Update Magnitude: 1.01320
Value Function Update Magnitude: 0.82489
Collected Steps per Second: 12,950.63558
Overall Steps per Second: 7,279.05164
Timestep Collection Time: 3.86236
Timestep Consumption Time: 3.00942
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.87177
Cumulative Model Updates: 152,012
Cumulative Timesteps: 1,210,725,708
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.64201
Policy Entropy: 4.32955
Value Function Loss: 0.00262
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03382
Policy Update Magnitude: 1.01451
Value Function Update Magnitude: 0.82804
Collected Steps per Second: 12,922.47998
Overall Steps per Second: 7,151.32109
Timestep Collection Time: 3.87046
Timestep Consumption Time: 3.12349
PPO Batch Consumption Time: 0.22936
Total Iteration Time: 6.99395
Cumulative Model Updates: 152,021
Cumulative Timesteps: 1,210,775,724
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1210775724...
Checkpoint 1210775724 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.96537
Policy Entropy: 4.32890
Value Function Loss: 0.00264
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 1.00335
Value Function Update Magnitude: 0.80085
Collected Steps per Second: 12,815.78996
Overall Steps per Second: 7,177.37345
Timestep Collection Time: 3.90409
Timestep Consumption Time: 3.06698
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 6.97107
Cumulative Model Updates: 152,030
Cumulative Timesteps: 1,210,825,758
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36537
Policy Entropy: 4.32982
Value Function Loss: 0.00264
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03262
Policy Update Magnitude: 1.01931
Value Function Update Magnitude: 0.79434
Collected Steps per Second: 12,859.06802
Overall Steps per Second: 7,250.68756
Timestep Collection Time: 3.88940
Timestep Consumption Time: 3.00843
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.89783
Cumulative Model Updates: 152,039
Cumulative Timesteps: 1,210,875,772
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1210875772...
Checkpoint 1210875772 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04359
Policy Entropy: 4.32303
Value Function Loss: 0.00283
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03514
Policy Update Magnitude: 1.06282
Value Function Update Magnitude: 0.79063
Collected Steps per Second: 13,160.00308
Overall Steps per Second: 7,226.68316
Timestep Collection Time: 3.80319
Timestep Consumption Time: 3.12253
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.92572
Cumulative Model Updates: 152,048
Cumulative Timesteps: 1,210,925,822
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.43137
Policy Entropy: 4.32653
Value Function Loss: 0.00277
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03574
Policy Update Magnitude: 1.05644
Value Function Update Magnitude: 0.81871
Collected Steps per Second: 13,021.25253
Overall Steps per Second: 7,166.49739
Timestep Collection Time: 3.84233
Timestep Consumption Time: 3.13904
PPO Batch Consumption Time: 0.22994
Total Iteration Time: 6.98137
Cumulative Model Updates: 152,057
Cumulative Timesteps: 1,210,975,854
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1210975854...
Checkpoint 1210975854 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.16320
Policy Entropy: 4.32800
Value Function Loss: 0.00278
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03658
Policy Update Magnitude: 1.04866
Value Function Update Magnitude: 0.81811
Collected Steps per Second: 12,850.23839
Overall Steps per Second: 7,257.64847
Timestep Collection Time: 3.89098
Timestep Consumption Time: 2.99831
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.88928
Cumulative Model Updates: 152,066
Cumulative Timesteps: 1,211,025,854
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05091
Policy Entropy: 4.33112
Value Function Loss: 0.00279
Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03819
Policy Update Magnitude: 1.04201
Value Function Update Magnitude: 0.83102
Collected Steps per Second: 13,139.28551
Overall Steps per Second: 7,239.33367
Timestep Collection Time: 3.80782
Timestep Consumption Time: 3.10332
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.91113
Cumulative Model Updates: 152,075
Cumulative Timesteps: 1,211,075,886
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1211075886...
Checkpoint 1211075886 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.53170
Policy Entropy: 4.32744
Value Function Loss: 0.00282
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03585
Policy Update Magnitude: 1.04503
Value Function Update Magnitude: 0.82093
Collected Steps per Second: 12,967.46411
Overall Steps per Second: 7,208.38777
Timestep Collection Time: 3.85580
Timestep Consumption Time: 3.08056
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.93636
Cumulative Model Updates: 152,084
Cumulative Timesteps: 1,211,125,886
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44995
Policy Entropy: 4.32956
Value Function Loss: 0.00282
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03386
Policy Update Magnitude: 1.03973
Value Function Update Magnitude: 0.79274
Collected Steps per Second: 12,913.81381
Overall Steps per Second: 7,283.10031
Timestep Collection Time: 3.87353
Timestep Consumption Time: 2.99470
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.86823
Cumulative Model Updates: 152,093
Cumulative Timesteps: 1,211,175,908
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1211175908...
Checkpoint 1211175908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43674
Policy Entropy: 4.32751
Value Function Loss: 0.00271
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 1.04851
Value Function Update Magnitude: 0.77115
Collected Steps per Second: 12,986.69202
Overall Steps per Second: 7,190.01859
Timestep Collection Time: 3.85194
Timestep Consumption Time: 3.10548
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.95742
Cumulative Model Updates: 152,102
Cumulative Timesteps: 1,211,225,932
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75158
Policy Entropy: 4.32773
Value Function Loss: 0.00264
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03469
Policy Update Magnitude: 1.04135
Value Function Update Magnitude: 0.77021
Collected Steps per Second: 12,873.74166
Overall Steps per Second: 7,172.08046
Timestep Collection Time: 3.88745
Timestep Consumption Time: 3.09044
PPO Batch Consumption Time: 0.22962
Total Iteration Time: 6.97789
Cumulative Model Updates: 152,111
Cumulative Timesteps: 1,211,275,978
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1211275978...
Checkpoint 1211275978 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.92147
Policy Entropy: 4.32854
Value Function Loss: 0.00260
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03524
Policy Update Magnitude: 1.01974
Value Function Update Magnitude: 0.78610
Collected Steps per Second: 13,234.00223
Overall Steps per Second: 7,114.29964
Timestep Collection Time: 3.78072
Timestep Consumption Time: 3.25216
PPO Batch Consumption Time: 0.24024
Total Iteration Time: 7.03288
Cumulative Model Updates: 152,120
Cumulative Timesteps: 1,211,326,012
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.36373
Policy Entropy: 4.33250
Value Function Loss: 0.00253
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03365
Policy Update Magnitude: 1.01137
Value Function Update Magnitude: 0.78500
Collected Steps per Second: 13,031.08348
Overall Steps per Second: 7,192.51509
Timestep Collection Time: 3.83836
Timestep Consumption Time: 3.11581
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.95417
Cumulative Model Updates: 152,129
Cumulative Timesteps: 1,211,376,030
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1211376030...
Checkpoint 1211376030 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.03145
Policy Entropy: 4.33095
Value Function Loss: 0.00258
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 1.01388
Value Function Update Magnitude: 0.79650
Collected Steps per Second: 13,121.07648
Overall Steps per Second: 7,252.90735
Timestep Collection Time: 3.81325
Timestep Consumption Time: 3.08522
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.89847
Cumulative Model Updates: 152,138
Cumulative Timesteps: 1,211,426,064
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03546
Policy Entropy: 4.33141
Value Function Loss: 0.00259
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 1.02358
Value Function Update Magnitude: 0.81074
Collected Steps per Second: 13,340.62025
Overall Steps per Second: 7,282.87915
Timestep Collection Time: 3.74900
Timestep Consumption Time: 3.11834
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.86734
Cumulative Model Updates: 152,147
Cumulative Timesteps: 1,211,476,078
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1211476078...
Checkpoint 1211476078 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.81360
Policy Entropy: 4.32940
Value Function Loss: 0.00268
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03469
Policy Update Magnitude: 1.04129
Value Function Update Magnitude: 0.80938
Collected Steps per Second: 12,907.36134
Overall Steps per Second: 7,174.76413
Timestep Collection Time: 3.87515
Timestep Consumption Time: 3.09623
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.97138
Cumulative Model Updates: 152,156
Cumulative Timesteps: 1,211,526,096
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.33139
Policy Entropy: 4.33217
Value Function Loss: 0.00274
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03298
Policy Update Magnitude: 1.04844
Value Function Update Magnitude: 0.82321
Collected Steps per Second: 12,997.92724
Overall Steps per Second: 7,222.70819
Timestep Collection Time: 3.84984
Timestep Consumption Time: 3.07830
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.92815
Cumulative Model Updates: 152,165
Cumulative Timesteps: 1,211,576,136
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1211576136...
Checkpoint 1211576136 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53995
Policy Entropy: 4.33544
Value Function Loss: 0.00278
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 1.04225
Value Function Update Magnitude: 0.81398
Collected Steps per Second: 13,186.32679
Overall Steps per Second: 7,249.14115
Timestep Collection Time: 3.79196
Timestep Consumption Time: 3.10569
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.89764
Cumulative Model Updates: 152,174
Cumulative Timesteps: 1,211,626,138
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.23008
Policy Entropy: 4.33616
Value Function Loss: 0.00283
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03358
Policy Update Magnitude: 1.03674
Value Function Update Magnitude: 0.82353
Collected Steps per Second: 12,995.77267
Overall Steps per Second: 7,061.48073
Timestep Collection Time: 3.84910
Timestep Consumption Time: 3.23469
PPO Batch Consumption Time: 0.23973
Total Iteration Time: 7.08378
Cumulative Model Updates: 152,183
Cumulative Timesteps: 1,211,676,160
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1211676160...
Checkpoint 1211676160 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.17597
Policy Entropy: 4.33422
Value Function Loss: 0.00287
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 1.05144
Value Function Update Magnitude: 0.81431
Collected Steps per Second: 12,844.74892
Overall Steps per Second: 7,179.01237
Timestep Collection Time: 3.89295
Timestep Consumption Time: 3.07235
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.96530
Cumulative Model Updates: 152,192
Cumulative Timesteps: 1,211,726,164
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.26513
Policy Entropy: 4.33547
Value Function Loss: 0.00291
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 1.04829
Value Function Update Magnitude: 0.83216
Collected Steps per Second: 13,053.22426
Overall Steps per Second: 7,323.62642
Timestep Collection Time: 3.83185
Timestep Consumption Time: 2.99783
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.82968
Cumulative Model Updates: 152,201
Cumulative Timesteps: 1,211,776,182
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1211776182...
Checkpoint 1211776182 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.87741
Policy Entropy: 4.33822
Value Function Loss: 0.00280
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03267
Policy Update Magnitude: 1.03031
Value Function Update Magnitude: 0.84666
Collected Steps per Second: 12,917.49106
Overall Steps per Second: 7,181.80146
Timestep Collection Time: 3.87180
Timestep Consumption Time: 3.09219
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.96399
Cumulative Model Updates: 152,210
Cumulative Timesteps: 1,211,826,196
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01154
Policy Entropy: 4.33901
Value Function Loss: 0.00271
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03283
Policy Update Magnitude: 1.02658
Value Function Update Magnitude: 0.79952
Collected Steps per Second: 13,016.83481
Overall Steps per Second: 7,221.35024
Timestep Collection Time: 3.84256
Timestep Consumption Time: 3.08384
PPO Batch Consumption Time: 0.22813
Total Iteration Time: 6.92641
Cumulative Model Updates: 152,219
Cumulative Timesteps: 1,211,876,214
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1211876214...
Checkpoint 1211876214 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.17909
Policy Entropy: 4.34176
Value Function Loss: 0.00261
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 1.00643
Value Function Update Magnitude: 0.77397
Collected Steps per Second: 12,858.76071
Overall Steps per Second: 7,255.03670
Timestep Collection Time: 3.88840
Timestep Consumption Time: 3.00336
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.89176
Cumulative Model Updates: 152,228
Cumulative Timesteps: 1,211,926,214
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27608
Policy Entropy: 4.34080
Value Function Loss: 0.00257
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03158
Policy Update Magnitude: 1.01202
Value Function Update Magnitude: 0.76802
Collected Steps per Second: 12,808.53419
Overall Steps per Second: 7,148.86917
Timestep Collection Time: 3.90396
Timestep Consumption Time: 3.09071
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.99467
Cumulative Model Updates: 152,237
Cumulative Timesteps: 1,211,976,218
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1211976218...
Checkpoint 1211976218 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.82013
Policy Entropy: 4.34270
Value Function Loss: 0.00259
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 1.03013
Value Function Update Magnitude: 0.77344
Collected Steps per Second: 12,856.46769
Overall Steps per Second: 7,153.49112
Timestep Collection Time: 3.89003
Timestep Consumption Time: 3.10125
PPO Batch Consumption Time: 0.22934
Total Iteration Time: 6.99127
Cumulative Model Updates: 152,246
Cumulative Timesteps: 1,212,026,230
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.98421
Policy Entropy: 4.34402
Value Function Loss: 0.00255
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03310
Policy Update Magnitude: 1.01992
Value Function Update Magnitude: 0.77596
Collected Steps per Second: 12,869.34151
Overall Steps per Second: 7,263.81259
Timestep Collection Time: 3.88769
Timestep Consumption Time: 3.00015
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.88784
Cumulative Model Updates: 152,255
Cumulative Timesteps: 1,212,076,262
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1212076262...
Checkpoint 1212076262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.45209
Policy Entropy: 4.34273
Value Function Loss: 0.00258
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03244
Policy Update Magnitude: 1.00470
Value Function Update Magnitude: 0.77844
Collected Steps per Second: 12,896.97943
Overall Steps per Second: 7,167.10787
Timestep Collection Time: 3.87982
Timestep Consumption Time: 3.10179
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.98162
Cumulative Model Updates: 152,264
Cumulative Timesteps: 1,212,126,300
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.14072
Policy Entropy: 4.34026
Value Function Loss: 0.00263
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03251
Policy Update Magnitude: 1.01540
Value Function Update Magnitude: 0.77694
Collected Steps per Second: 12,914.64203
Overall Steps per Second: 7,206.29278
Timestep Collection Time: 3.87281
Timestep Consumption Time: 3.06779
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.94060
Cumulative Model Updates: 152,273
Cumulative Timesteps: 1,212,176,316
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1212176316...
Checkpoint 1212176316 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.46107
Policy Entropy: 4.33801
Value Function Loss: 0.00275
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03362
Policy Update Magnitude: 1.04007
Value Function Update Magnitude: 0.79975
Collected Steps per Second: 12,924.70745
Overall Steps per Second: 7,252.13633
Timestep Collection Time: 3.86887
Timestep Consumption Time: 3.02620
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.89507
Cumulative Model Updates: 152,282
Cumulative Timesteps: 1,212,226,320
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.57758
Policy Entropy: 4.33787
Value Function Loss: 0.00287
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 1.06210
Value Function Update Magnitude: 0.82547
Collected Steps per Second: 12,984.58115
Overall Steps per Second: 7,179.80279
Timestep Collection Time: 3.85365
Timestep Consumption Time: 3.11562
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.96927
Cumulative Model Updates: 152,291
Cumulative Timesteps: 1,212,276,358
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1212276358...
Checkpoint 1212276358 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.26916
Policy Entropy: 4.33678
Value Function Loss: 0.00279
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03359
Policy Update Magnitude: 1.05569
Value Function Update Magnitude: 0.82678
Collected Steps per Second: 12,826.50943
Overall Steps per Second: 7,187.68905
Timestep Collection Time: 3.89942
Timestep Consumption Time: 3.05914
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.95856
Cumulative Model Updates: 152,300
Cumulative Timesteps: 1,212,326,374
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.71576
Policy Entropy: 4.33861
Value Function Loss: 0.00276
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 1.04996
Value Function Update Magnitude: 0.81545
Collected Steps per Second: 12,864.00915
Overall Steps per Second: 7,190.41736
Timestep Collection Time: 3.88883
Timestep Consumption Time: 3.06848
PPO Batch Consumption Time: 0.22935
Total Iteration Time: 6.95732
Cumulative Model Updates: 152,309
Cumulative Timesteps: 1,212,376,400
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1212376400...
Checkpoint 1212376400 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.94459
Policy Entropy: 4.33935
Value Function Loss: 0.00267
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03194
Policy Update Magnitude: 1.03805
Value Function Update Magnitude: 0.81888
Collected Steps per Second: 13,075.14230
Overall Steps per Second: 7,208.51756
Timestep Collection Time: 3.82711
Timestep Consumption Time: 3.11468
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.94179
Cumulative Model Updates: 152,318
Cumulative Timesteps: 1,212,426,440
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.50576
Policy Entropy: 4.34112
Value Function Loss: 0.00258
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 1.02348
Value Function Update Magnitude: 0.82902
Collected Steps per Second: 12,939.52394
Overall Steps per Second: 7,214.20732
Timestep Collection Time: 3.86722
Timestep Consumption Time: 3.06909
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.93631
Cumulative Model Updates: 152,327
Cumulative Timesteps: 1,212,476,480
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1212476480...
Checkpoint 1212476480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.35658
Policy Entropy: 4.34034
Value Function Loss: 0.00259
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03084
Policy Update Magnitude: 1.01689
Value Function Update Magnitude: 0.80080
Collected Steps per Second: 12,919.71506
Overall Steps per Second: 7,292.86870
Timestep Collection Time: 3.87067
Timestep Consumption Time: 2.98644
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.85711
Cumulative Model Updates: 152,336
Cumulative Timesteps: 1,212,526,488
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.81068
Policy Entropy: 4.34204
Value Function Loss: 0.00267
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 1.03064
Value Function Update Magnitude: 0.80021
Collected Steps per Second: 12,915.72473
Overall Steps per Second: 7,156.16485
Timestep Collection Time: 3.87202
Timestep Consumption Time: 3.11636
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.98838
Cumulative Model Updates: 152,345
Cumulative Timesteps: 1,212,576,498
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1212576498...
Checkpoint 1212576498 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.96869
Policy Entropy: 4.34121
Value Function Loss: 0.00269
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03309
Policy Update Magnitude: 1.03081
Value Function Update Magnitude: 0.83011
Collected Steps per Second: 12,824.28073
Overall Steps per Second: 7,152.13756
Timestep Collection Time: 3.89932
Timestep Consumption Time: 3.09243
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.99176
Cumulative Model Updates: 152,354
Cumulative Timesteps: 1,212,626,504
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.14061
Policy Entropy: 4.33993
Value Function Loss: 0.00261
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 1.01398
Value Function Update Magnitude: 0.82944
Collected Steps per Second: 12,934.17147
Overall Steps per Second: 7,265.84716
Timestep Collection Time: 3.86697
Timestep Consumption Time: 3.01675
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.88371
Cumulative Model Updates: 152,363
Cumulative Timesteps: 1,212,676,520
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1212676520...
Checkpoint 1212676520 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.71254
Policy Entropy: 4.33990
Value Function Loss: 0.00261
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03393
Policy Update Magnitude: 1.01824
Value Function Update Magnitude: 0.82293
Collected Steps per Second: 12,906.51856
Overall Steps per Second: 7,109.18917
Timestep Collection Time: 3.87479
Timestep Consumption Time: 3.15977
PPO Batch Consumption Time: 0.23088
Total Iteration Time: 7.03456
Cumulative Model Updates: 152,372
Cumulative Timesteps: 1,212,726,530
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47566
Policy Entropy: 4.33837
Value Function Loss: 0.00267
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03401
Policy Update Magnitude: 1.02405
Value Function Update Magnitude: 0.79364
Collected Steps per Second: 12,964.03827
Overall Steps per Second: 7,173.33575
Timestep Collection Time: 3.85867
Timestep Consumption Time: 3.11493
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.97360
Cumulative Model Updates: 152,381
Cumulative Timesteps: 1,212,776,554
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1212776554...
Checkpoint 1212776554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.58776
Policy Entropy: 4.33950
Value Function Loss: 0.00269
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03473
Policy Update Magnitude: 1.05115
Value Function Update Magnitude: 0.80557
Collected Steps per Second: 12,981.82371
Overall Steps per Second: 7,279.90267
Timestep Collection Time: 3.85585
Timestep Consumption Time: 3.02006
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.87592
Cumulative Model Updates: 152,390
Cumulative Timesteps: 1,212,826,610
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.67707
Policy Entropy: 4.33837
Value Function Loss: 0.00262
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 1.04734
Value Function Update Magnitude: 0.83524
Collected Steps per Second: 13,062.00062
Overall Steps per Second: 7,199.28682
Timestep Collection Time: 3.82851
Timestep Consumption Time: 3.11773
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.94624
Cumulative Model Updates: 152,399
Cumulative Timesteps: 1,212,876,618
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1212876618...
Checkpoint 1212876618 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.96940
Policy Entropy: 4.33751
Value Function Loss: 0.00270
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03368
Policy Update Magnitude: 1.05455
Value Function Update Magnitude: 0.81431
Collected Steps per Second: 13,035.49734
Overall Steps per Second: 7,241.97722
Timestep Collection Time: 3.83583
Timestep Consumption Time: 3.06863
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.90447
Cumulative Model Updates: 152,408
Cumulative Timesteps: 1,212,926,620
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.34336
Policy Entropy: 4.33249
Value Function Loss: 0.00282
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03659
Policy Update Magnitude: 1.09001
Value Function Update Magnitude: 0.79658
Collected Steps per Second: 12,779.55435
Overall Steps per Second: 7,227.61741
Timestep Collection Time: 3.91375
Timestep Consumption Time: 3.00637
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.92012
Cumulative Model Updates: 152,417
Cumulative Timesteps: 1,212,976,636
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1212976636...
Checkpoint 1212976636 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.05345
Policy Entropy: 4.33511
Value Function Loss: 0.00284
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03542
Policy Update Magnitude: 1.07346
Value Function Update Magnitude: 0.81619
Collected Steps per Second: 12,847.88563
Overall Steps per Second: 7,163.19828
Timestep Collection Time: 3.89185
Timestep Consumption Time: 3.08855
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.98040
Cumulative Model Updates: 152,426
Cumulative Timesteps: 1,213,026,638
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.80859
Policy Entropy: 4.33449
Value Function Loss: 0.00280
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03288
Policy Update Magnitude: 1.06455
Value Function Update Magnitude: 0.86415
Collected Steps per Second: 12,961.34790
Overall Steps per Second: 7,030.77282
Timestep Collection Time: 3.85824
Timestep Consumption Time: 3.25449
PPO Batch Consumption Time: 0.24140
Total Iteration Time: 7.11273
Cumulative Model Updates: 152,435
Cumulative Timesteps: 1,213,076,646
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1213076646...
Checkpoint 1213076646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.31182
Policy Entropy: 4.33461
Value Function Loss: 0.00276
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 1.06310
Value Function Update Magnitude: 0.85803
Collected Steps per Second: 12,956.74804
Overall Steps per Second: 7,286.38668
Timestep Collection Time: 3.85899
Timestep Consumption Time: 3.00312
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.86211
Cumulative Model Updates: 152,444
Cumulative Timesteps: 1,213,126,646
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18415
Policy Entropy: 4.33118
Value Function Loss: 0.00280
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03412
Policy Update Magnitude: 1.06864
Value Function Update Magnitude: 0.85763
Collected Steps per Second: 12,964.58660
Overall Steps per Second: 7,180.63148
Timestep Collection Time: 3.85897
Timestep Consumption Time: 3.10838
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.96735
Cumulative Model Updates: 152,453
Cumulative Timesteps: 1,213,176,676
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1213176676...
Checkpoint 1213176676 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04247
Policy Entropy: 4.33409
Value Function Loss: 0.00271
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03346
Policy Update Magnitude: 1.06372
Value Function Update Magnitude: 0.84325
Collected Steps per Second: 12,965.71066
Overall Steps per Second: 7,184.61233
Timestep Collection Time: 3.85879
Timestep Consumption Time: 3.10498
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.96377
Cumulative Model Updates: 152,462
Cumulative Timesteps: 1,213,226,708
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61215
Policy Entropy: 4.33264
Value Function Loss: 0.00273
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03290
Policy Update Magnitude: 1.04818
Value Function Update Magnitude: 0.79783
Collected Steps per Second: 12,977.47001
Overall Steps per Second: 7,283.39603
Timestep Collection Time: 3.85638
Timestep Consumption Time: 3.01487
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.87125
Cumulative Model Updates: 152,471
Cumulative Timesteps: 1,213,276,754
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1213276754...
Checkpoint 1213276754 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.31928
Policy Entropy: 4.33186
Value Function Loss: 0.00277
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03256
Policy Update Magnitude: 1.06536
Value Function Update Magnitude: 0.79150
Collected Steps per Second: 13,034.55965
Overall Steps per Second: 7,195.24335
Timestep Collection Time: 3.83672
Timestep Consumption Time: 3.11370
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.95043
Cumulative Model Updates: 152,480
Cumulative Timesteps: 1,213,326,764
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.69546
Policy Entropy: 4.33046
Value Function Loss: 0.00295
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03514
Policy Update Magnitude: 1.06774
Value Function Update Magnitude: 0.84463
Collected Steps per Second: 12,894.36355
Overall Steps per Second: 7,160.92116
Timestep Collection Time: 3.88061
Timestep Consumption Time: 3.10704
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.98765
Cumulative Model Updates: 152,489
Cumulative Timesteps: 1,213,376,802
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1213376802...
Checkpoint 1213376802 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.70206
Policy Entropy: 4.33535
Value Function Loss: 0.00285
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03464
Policy Update Magnitude: 1.05213
Value Function Update Magnitude: 0.87073
Collected Steps per Second: 12,874.48081
Overall Steps per Second: 7,190.91730
Timestep Collection Time: 3.88785
Timestep Consumption Time: 3.07288
PPO Batch Consumption Time: 0.22950
Total Iteration Time: 6.96073
Cumulative Model Updates: 152,498
Cumulative Timesteps: 1,213,426,856
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.44088
Policy Entropy: 4.33283
Value Function Loss: 0.00291
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03475
Policy Update Magnitude: 1.07272
Value Function Update Magnitude: 0.86169
Collected Steps per Second: 12,952.90431
Overall Steps per Second: 7,160.04973
Timestep Collection Time: 3.86168
Timestep Consumption Time: 3.12430
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.98598
Cumulative Model Updates: 152,507
Cumulative Timesteps: 1,213,476,876
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1213476876...
Checkpoint 1213476876 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.51039
Policy Entropy: 4.33575
Value Function Loss: 0.00277
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 1.06694
Value Function Update Magnitude: 0.83961
Collected Steps per Second: 12,914.40862
Overall Steps per Second: 7,161.26319
Timestep Collection Time: 3.87195
Timestep Consumption Time: 3.11061
PPO Batch Consumption Time: 0.22935
Total Iteration Time: 6.98257
Cumulative Model Updates: 152,516
Cumulative Timesteps: 1,213,526,880
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.10052
Policy Entropy: 4.33232
Value Function Loss: 0.00288
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 1.06549
Value Function Update Magnitude: 0.84577
Collected Steps per Second: 12,956.56589
Overall Steps per Second: 7,272.99170
Timestep Collection Time: 3.85966
Timestep Consumption Time: 3.01619
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.87585
Cumulative Model Updates: 152,525
Cumulative Timesteps: 1,213,576,888
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1213576888...
Checkpoint 1213576888 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.14790
Policy Entropy: 4.33631
Value Function Loss: 0.00274
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03378
Policy Update Magnitude: 1.06109
Value Function Update Magnitude: 0.86229
Collected Steps per Second: 12,979.84587
Overall Steps per Second: 7,202.96662
Timestep Collection Time: 3.85382
Timestep Consumption Time: 3.09082
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.94464
Cumulative Model Updates: 152,534
Cumulative Timesteps: 1,213,626,910
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.76997
Policy Entropy: 4.33642
Value Function Loss: 0.00271
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03497
Policy Update Magnitude: 1.02836
Value Function Update Magnitude: 0.83949
Collected Steps per Second: 12,933.22170
Overall Steps per Second: 7,164.14231
Timestep Collection Time: 3.86849
Timestep Consumption Time: 3.11518
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.98367
Cumulative Model Updates: 152,543
Cumulative Timesteps: 1,213,676,942
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1213676942...
Checkpoint 1213676942 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42288
Policy Entropy: 4.33660
Value Function Loss: 0.00267
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03308
Policy Update Magnitude: 1.02743
Value Function Update Magnitude: 0.81317
Collected Steps per Second: 12,965.91225
Overall Steps per Second: 7,286.94690
Timestep Collection Time: 3.85812
Timestep Consumption Time: 3.00676
PPO Batch Consumption Time: 0.22940
Total Iteration Time: 6.86488
Cumulative Model Updates: 152,552
Cumulative Timesteps: 1,213,726,966
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.40280
Policy Entropy: 4.33376
Value Function Loss: 0.00267
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03228
Policy Update Magnitude: 1.04128
Value Function Update Magnitude: 0.79573
Collected Steps per Second: 12,958.87402
Overall Steps per Second: 7,007.80180
Timestep Collection Time: 3.86191
Timestep Consumption Time: 3.27956
PPO Batch Consumption Time: 0.24095
Total Iteration Time: 7.14147
Cumulative Model Updates: 152,561
Cumulative Timesteps: 1,213,777,012
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1213777012...
Checkpoint 1213777012 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.62286
Policy Entropy: 4.33461
Value Function Loss: 0.00267
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03414
Policy Update Magnitude: 1.04611
Value Function Update Magnitude: 0.78879
Collected Steps per Second: 12,654.97757
Overall Steps per Second: 7,111.81233
Timestep Collection Time: 3.95370
Timestep Consumption Time: 3.08164
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 7.03534
Cumulative Model Updates: 152,570
Cumulative Timesteps: 1,213,827,046
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.76619
Policy Entropy: 4.33841
Value Function Loss: 0.00268
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03515
Policy Update Magnitude: 1.03455
Value Function Update Magnitude: 0.79143
Collected Steps per Second: 12,909.65313
Overall Steps per Second: 7,295.15476
Timestep Collection Time: 3.87338
Timestep Consumption Time: 2.98103
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.85441
Cumulative Model Updates: 152,579
Cumulative Timesteps: 1,213,877,050
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1213877050...
Checkpoint 1213877050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99582
Policy Entropy: 4.34232
Value Function Loss: 0.00274
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03208
Policy Update Magnitude: 1.04751
Value Function Update Magnitude: 0.80190
Collected Steps per Second: 13,015.17478
Overall Steps per Second: 7,196.25666
Timestep Collection Time: 3.84167
Timestep Consumption Time: 3.10639
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.94806
Cumulative Model Updates: 152,588
Cumulative Timesteps: 1,213,927,050
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.07819
Policy Entropy: 4.33592
Value Function Loss: 0.00278
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03228
Policy Update Magnitude: 1.06595
Value Function Update Magnitude: 0.83021
Collected Steps per Second: 13,075.63679
Overall Steps per Second: 7,249.19861
Timestep Collection Time: 3.82651
Timestep Consumption Time: 3.07550
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.90200
Cumulative Model Updates: 152,597
Cumulative Timesteps: 1,213,977,084
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1213977084...
Checkpoint 1213977084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.00230
Policy Entropy: 4.33796
Value Function Loss: 0.00275
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03342
Policy Update Magnitude: 1.05017
Value Function Update Magnitude: 0.84767
Collected Steps per Second: 12,933.89850
Overall Steps per Second: 7,293.75317
Timestep Collection Time: 3.86890
Timestep Consumption Time: 2.99176
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.86067
Cumulative Model Updates: 152,606
Cumulative Timesteps: 1,214,027,124
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46631
Policy Entropy: 4.33563
Value Function Loss: 0.00286
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 1.05942
Value Function Update Magnitude: 0.81313
Collected Steps per Second: 13,032.85892
Overall Steps per Second: 7,220.06221
Timestep Collection Time: 3.83676
Timestep Consumption Time: 3.08894
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.92570
Cumulative Model Updates: 152,615
Cumulative Timesteps: 1,214,077,128
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1214077128...
Checkpoint 1214077128 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.66091
Policy Entropy: 4.33758
Value Function Loss: 0.00281
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 1.06004
Value Function Update Magnitude: 0.81708
Collected Steps per Second: 12,725.03608
Overall Steps per Second: 7,064.38031
Timestep Collection Time: 3.93162
Timestep Consumption Time: 3.15039
PPO Batch Consumption Time: 0.23342
Total Iteration Time: 7.08201
Cumulative Model Updates: 152,624
Cumulative Timesteps: 1,214,127,158
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.31937
Policy Entropy: 4.33652
Value Function Loss: 0.00280
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03571
Policy Update Magnitude: 1.03977
Value Function Update Magnitude: 0.80923
Collected Steps per Second: 12,926.76603
Overall Steps per Second: 7,284.08493
Timestep Collection Time: 3.87011
Timestep Consumption Time: 2.99801
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.86812
Cumulative Model Updates: 152,633
Cumulative Timesteps: 1,214,177,186
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1214177186...
Checkpoint 1214177186 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.69297
Policy Entropy: 4.33839
Value Function Loss: 0.00266
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03206
Policy Update Magnitude: 1.01913
Value Function Update Magnitude: 0.80507
Collected Steps per Second: 12,832.39024
Overall Steps per Second: 7,136.02481
Timestep Collection Time: 3.89686
Timestep Consumption Time: 3.11069
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 7.00754
Cumulative Model Updates: 152,642
Cumulative Timesteps: 1,214,227,192
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.26777
Policy Entropy: 4.34013
Value Function Loss: 0.00270
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 1.02698
Value Function Update Magnitude: 0.78651
Collected Steps per Second: 12,905.28792
Overall Steps per Second: 7,160.36194
Timestep Collection Time: 3.87702
Timestep Consumption Time: 3.11062
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.98764
Cumulative Model Updates: 152,651
Cumulative Timesteps: 1,214,277,226
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1214277226...
Checkpoint 1214277226 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.66930
Policy Entropy: 4.33774
Value Function Loss: 0.00276
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 1.05687
Value Function Update Magnitude: 0.79291
Collected Steps per Second: 12,887.69227
Overall Steps per Second: 7,253.60860
Timestep Collection Time: 3.88246
Timestep Consumption Time: 3.01562
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.89808
Cumulative Model Updates: 152,660
Cumulative Timesteps: 1,214,327,262
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.85220
Policy Entropy: 4.33915
Value Function Loss: 0.00283
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03544
Policy Update Magnitude: 1.06677
Value Function Update Magnitude: 0.80003
Collected Steps per Second: 13,020.83910
Overall Steps per Second: 7,187.81837
Timestep Collection Time: 3.84123
Timestep Consumption Time: 3.11721
PPO Batch Consumption Time: 0.22892
Total Iteration Time: 6.95844
Cumulative Model Updates: 152,669
Cumulative Timesteps: 1,214,377,278
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1214377278...
Checkpoint 1214377278 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.49843
Policy Entropy: 4.33987
Value Function Loss: 0.00276
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 1.05797
Value Function Update Magnitude: 0.81404
Collected Steps per Second: 12,936.79834
Overall Steps per Second: 7,172.19092
Timestep Collection Time: 3.86587
Timestep Consumption Time: 3.10717
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 6.97304
Cumulative Model Updates: 152,678
Cumulative Timesteps: 1,214,427,290
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23469
Policy Entropy: 4.34169
Value Function Loss: 0.00279
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 1.05449
Value Function Update Magnitude: 0.77744
Collected Steps per Second: 13,034.47812
Overall Steps per Second: 7,235.91261
Timestep Collection Time: 3.84028
Timestep Consumption Time: 3.07744
PPO Batch Consumption Time: 0.23019
Total Iteration Time: 6.91772
Cumulative Model Updates: 152,687
Cumulative Timesteps: 1,214,477,346
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1214477346...
Checkpoint 1214477346 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21639
Policy Entropy: 4.33912
Value Function Loss: 0.00278
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03422
Policy Update Magnitude: 1.04537
Value Function Update Magnitude: 0.79300
Collected Steps per Second: 13,012.41693
Overall Steps per Second: 7,185.81420
Timestep Collection Time: 3.84341
Timestep Consumption Time: 3.11642
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 6.95982
Cumulative Model Updates: 152,696
Cumulative Timesteps: 1,214,527,358
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84342
Policy Entropy: 4.33466
Value Function Loss: 0.00287
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03252
Policy Update Magnitude: 1.05649
Value Function Update Magnitude: 0.81384
Collected Steps per Second: 12,979.72952
Overall Steps per Second: 7,222.16307
Timestep Collection Time: 3.85324
Timestep Consumption Time: 3.07183
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.92507
Cumulative Model Updates: 152,705
Cumulative Timesteps: 1,214,577,372
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1214577372...
Checkpoint 1214577372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89866
Policy Entropy: 4.33833
Value Function Loss: 0.00279
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03273
Policy Update Magnitude: 1.05672
Value Function Update Magnitude: 0.80920
Collected Steps per Second: 12,776.95481
Overall Steps per Second: 7,221.77461
Timestep Collection Time: 3.91517
Timestep Consumption Time: 3.01166
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.92683
Cumulative Model Updates: 152,714
Cumulative Timesteps: 1,214,627,396
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.37177
Policy Entropy: 4.33622
Value Function Loss: 0.00283
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03522
Policy Update Magnitude: 1.05258
Value Function Update Magnitude: 0.80765
Collected Steps per Second: 13,083.36577
Overall Steps per Second: 7,206.53136
Timestep Collection Time: 3.82333
Timestep Consumption Time: 3.11788
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.94120
Cumulative Model Updates: 152,723
Cumulative Timesteps: 1,214,677,418
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1214677418...
Checkpoint 1214677418 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22118
Policy Entropy: 4.33857
Value Function Loss: 0.00289
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03280
Policy Update Magnitude: 1.06571
Value Function Update Magnitude: 0.82731
Collected Steps per Second: 12,888.20552
Overall Steps per Second: 7,163.01805
Timestep Collection Time: 3.88060
Timestep Consumption Time: 3.10165
PPO Batch Consumption Time: 0.22789
Total Iteration Time: 6.98225
Cumulative Model Updates: 152,732
Cumulative Timesteps: 1,214,727,432
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.89550
Policy Entropy: 4.33790
Value Function Loss: 0.00278
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03364
Policy Update Magnitude: 1.04929
Value Function Update Magnitude: 0.85100
Collected Steps per Second: 12,938.83560
Overall Steps per Second: 7,273.22303
Timestep Collection Time: 3.86588
Timestep Consumption Time: 3.01140
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.87728
Cumulative Model Updates: 152,741
Cumulative Timesteps: 1,214,777,452
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1214777452...
Checkpoint 1214777452 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.88533
Policy Entropy: 4.33887
Value Function Loss: 0.00281
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03520
Policy Update Magnitude: 1.04905
Value Function Update Magnitude: 0.81307
Collected Steps per Second: 12,738.50176
Overall Steps per Second: 7,052.22417
Timestep Collection Time: 3.92589
Timestep Consumption Time: 3.16549
PPO Batch Consumption Time: 0.22961
Total Iteration Time: 7.09138
Cumulative Model Updates: 152,750
Cumulative Timesteps: 1,214,827,462
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.46505
Policy Entropy: 4.34148
Value Function Loss: 0.00274
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03449
Policy Update Magnitude: 1.04476
Value Function Update Magnitude: 0.77977
Collected Steps per Second: 13,018.85472
Overall Steps per Second: 7,204.53456
Timestep Collection Time: 3.84120
Timestep Consumption Time: 3.09999
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.94118
Cumulative Model Updates: 152,759
Cumulative Timesteps: 1,214,877,470
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1214877470...
Checkpoint 1214877470 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.22688
Policy Entropy: 4.34040
Value Function Loss: 0.00281
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 1.04112
Value Function Update Magnitude: 0.77612
Collected Steps per Second: 13,014.60237
Overall Steps per Second: 7,296.86190
Timestep Collection Time: 3.84338
Timestep Consumption Time: 3.01163
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.85500
Cumulative Model Updates: 152,768
Cumulative Timesteps: 1,214,927,490
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.14127
Policy Entropy: 4.33836
Value Function Loss: 0.00271
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03555
Policy Update Magnitude: 1.04506
Value Function Update Magnitude: 0.76752
Collected Steps per Second: 13,070.91770
Overall Steps per Second: 7,201.49171
Timestep Collection Time: 3.82773
Timestep Consumption Time: 3.11972
PPO Batch Consumption Time: 0.22946
Total Iteration Time: 6.94745
Cumulative Model Updates: 152,777
Cumulative Timesteps: 1,214,977,522
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1214977522...
Checkpoint 1214977522 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.29967
Policy Entropy: 4.33684
Value Function Loss: 0.00269
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03556
Policy Update Magnitude: 1.03190
Value Function Update Magnitude: 0.75605
Collected Steps per Second: 12,856.96561
Overall Steps per Second: 7,144.43994
Timestep Collection Time: 3.88894
Timestep Consumption Time: 3.10951
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.99845
Cumulative Model Updates: 152,786
Cumulative Timesteps: 1,215,027,522
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.59919
Policy Entropy: 4.33748
Value Function Loss: 0.00270
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 1.02996
Value Function Update Magnitude: 0.76329
Collected Steps per Second: 12,958.77641
Overall Steps per Second: 7,280.80641
Timestep Collection Time: 3.86024
Timestep Consumption Time: 3.01043
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.87067
Cumulative Model Updates: 152,795
Cumulative Timesteps: 1,215,077,546
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1215077546...
Checkpoint 1215077546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28974
Policy Entropy: 4.33769
Value Function Loss: 0.00274
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03196
Policy Update Magnitude: 1.03977
Value Function Update Magnitude: 0.79094
Collected Steps per Second: 12,933.00423
Overall Steps per Second: 7,180.42506
Timestep Collection Time: 3.86623
Timestep Consumption Time: 3.09742
PPO Batch Consumption Time: 0.22823
Total Iteration Time: 6.96365
Cumulative Model Updates: 152,804
Cumulative Timesteps: 1,215,127,548
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81755
Policy Entropy: 4.33647
Value Function Loss: 0.00270
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03359
Policy Update Magnitude: 1.03562
Value Function Update Magnitude: 0.82543
Collected Steps per Second: 13,003.32017
Overall Steps per Second: 7,126.52815
Timestep Collection Time: 3.84748
Timestep Consumption Time: 3.17277
PPO Batch Consumption Time: 0.23122
Total Iteration Time: 7.02025
Cumulative Model Updates: 152,813
Cumulative Timesteps: 1,215,177,578
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1215177578...
Checkpoint 1215177578 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53693
Policy Entropy: 4.33774
Value Function Loss: 0.00257
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 1.00604
Value Function Update Magnitude: 0.79757
Collected Steps per Second: 12,990.46449
Overall Steps per Second: 7,292.51960
Timestep Collection Time: 3.85113
Timestep Consumption Time: 3.00905
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.86018
Cumulative Model Updates: 152,822
Cumulative Timesteps: 1,215,227,606
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.74740
Policy Entropy: 4.33731
Value Function Loss: 0.00260
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03231
Policy Update Magnitude: 0.99178
Value Function Update Magnitude: 0.78343
Collected Steps per Second: 13,083.31935
Overall Steps per Second: 7,204.24467
Timestep Collection Time: 3.82227
Timestep Consumption Time: 3.11919
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.94146
Cumulative Model Updates: 152,831
Cumulative Timesteps: 1,215,277,614
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1215277614...
Checkpoint 1215277614 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.00854
Policy Entropy: 4.33629
Value Function Loss: 0.00255
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03071
Policy Update Magnitude: 0.99008
Value Function Update Magnitude: 0.82270
Collected Steps per Second: 12,942.80366
Overall Steps per Second: 7,177.10134
Timestep Collection Time: 3.86361
Timestep Consumption Time: 3.10382
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.96744
Cumulative Model Updates: 152,840
Cumulative Timesteps: 1,215,327,620
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.63427
Policy Entropy: 4.33662
Value Function Loss: 0.00248
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03160
Policy Update Magnitude: 0.97866
Value Function Update Magnitude: 0.82049
Collected Steps per Second: 12,877.36577
Overall Steps per Second: 7,171.76424
Timestep Collection Time: 3.88294
Timestep Consumption Time: 3.08913
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.97206
Cumulative Model Updates: 152,849
Cumulative Timesteps: 1,215,377,622
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1215377622...
Checkpoint 1215377622 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28942
Policy Entropy: 4.33411
Value Function Loss: 0.00255
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03086
Policy Update Magnitude: 0.98852
Value Function Update Magnitude: 0.79267
Collected Steps per Second: 13,124.06912
Overall Steps per Second: 7,223.73554
Timestep Collection Time: 3.81193
Timestep Consumption Time: 3.11358
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.92550
Cumulative Model Updates: 152,858
Cumulative Timesteps: 1,215,427,650
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65301
Policy Entropy: 4.33070
Value Function Loss: 0.00270
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03351
Policy Update Magnitude: 1.00893
Value Function Update Magnitude: 0.81803
Collected Steps per Second: 13,023.83240
Overall Steps per Second: 7,202.44600
Timestep Collection Time: 3.83973
Timestep Consumption Time: 3.10347
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.94320
Cumulative Model Updates: 152,867
Cumulative Timesteps: 1,215,477,658
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1215477658...
Checkpoint 1215477658 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19726
Policy Entropy: 4.32647
Value Function Loss: 0.00283
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03586
Policy Update Magnitude: 1.03054
Value Function Update Magnitude: 0.83670
Collected Steps per Second: 12,953.68382
Overall Steps per Second: 7,157.31756
Timestep Collection Time: 3.86207
Timestep Consumption Time: 3.12770
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.98977
Cumulative Model Updates: 152,876
Cumulative Timesteps: 1,215,527,686
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77175
Policy Entropy: 4.33016
Value Function Loss: 0.00277
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03649
Policy Update Magnitude: 1.04904
Value Function Update Magnitude: 0.80575
Collected Steps per Second: 13,156.90022
Overall Steps per Second: 7,252.08899
Timestep Collection Time: 3.80242
Timestep Consumption Time: 3.09601
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.89843
Cumulative Model Updates: 152,885
Cumulative Timesteps: 1,215,577,714
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1215577714...
Checkpoint 1215577714 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.57262
Policy Entropy: 4.33202
Value Function Loss: 0.00269
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03627
Policy Update Magnitude: 1.02810
Value Function Update Magnitude: 0.77908
Collected Steps per Second: 12,940.68740
Overall Steps per Second: 7,155.91776
Timestep Collection Time: 3.86595
Timestep Consumption Time: 3.12519
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.99114
Cumulative Model Updates: 152,894
Cumulative Timesteps: 1,215,627,742
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68877
Policy Entropy: 4.33683
Value Function Loss: 0.00260
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03483
Policy Update Magnitude: 1.01649
Value Function Update Magnitude: 0.75805
Collected Steps per Second: 13,079.17098
Overall Steps per Second: 7,238.90570
Timestep Collection Time: 3.82425
Timestep Consumption Time: 3.08536
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.90961
Cumulative Model Updates: 152,903
Cumulative Timesteps: 1,215,677,760
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1215677760...
Checkpoint 1215677760 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.34285
Policy Entropy: 4.33760
Value Function Loss: 0.00265
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03426
Policy Update Magnitude: 1.00831
Value Function Update Magnitude: 0.76663
Collected Steps per Second: 13,345.73490
Overall Steps per Second: 7,304.94159
Timestep Collection Time: 3.74652
Timestep Consumption Time: 3.09817
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.84468
Cumulative Model Updates: 152,912
Cumulative Timesteps: 1,215,727,760
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.02970
Policy Entropy: 4.34136
Value Function Loss: 0.00263
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03210
Policy Update Magnitude: 1.01936
Value Function Update Magnitude: 0.80252
Collected Steps per Second: 12,928.95439
Overall Steps per Second: 7,175.18332
Timestep Collection Time: 3.87023
Timestep Consumption Time: 3.10353
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.97376
Cumulative Model Updates: 152,921
Cumulative Timesteps: 1,215,777,798
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1215777798...
Checkpoint 1215777798 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.80773
Policy Entropy: 4.34090
Value Function Loss: 0.00267
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 1.03627
Value Function Update Magnitude: 0.79221
Collected Steps per Second: 12,721.40455
Overall Steps per Second: 7,133.25285
Timestep Collection Time: 3.93227
Timestep Consumption Time: 3.08052
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 7.01279
Cumulative Model Updates: 152,930
Cumulative Timesteps: 1,215,827,822
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61316
Policy Entropy: 4.34216
Value Function Loss: 0.00273
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 1.03288
Value Function Update Magnitude: 0.79718
Collected Steps per Second: 13,166.90625
Overall Steps per Second: 7,203.04065
Timestep Collection Time: 3.79953
Timestep Consumption Time: 3.14587
PPO Batch Consumption Time: 0.22977
Total Iteration Time: 6.94540
Cumulative Model Updates: 152,939
Cumulative Timesteps: 1,215,877,850
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1215877850...
Checkpoint 1215877850 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 20.17388
Policy Entropy: 4.34254
Value Function Loss: 0.00265
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03144
Policy Update Magnitude: 1.02528
Value Function Update Magnitude: 0.78543
Collected Steps per Second: 12,997.28930
Overall Steps per Second: 7,178.33859
Timestep Collection Time: 3.84834
Timestep Consumption Time: 3.11957
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.96791
Cumulative Model Updates: 152,948
Cumulative Timesteps: 1,215,927,868
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.59631
Policy Entropy: 4.34911
Value Function Loss: 0.00257
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03197
Policy Update Magnitude: 0.99423
Value Function Update Magnitude: 0.76467
Collected Steps per Second: 12,910.60898
Overall Steps per Second: 7,207.27804
Timestep Collection Time: 3.87402
Timestep Consumption Time: 3.06563
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.93965
Cumulative Model Updates: 152,957
Cumulative Timesteps: 1,215,977,884
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1215977884...
Checkpoint 1215977884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.12216
Policy Entropy: 4.34684
Value Function Loss: 0.00252
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 0.99805
Value Function Update Magnitude: 0.77458
Collected Steps per Second: 13,206.84659
Overall Steps per Second: 7,256.66978
Timestep Collection Time: 3.78879
Timestep Consumption Time: 3.10666
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.89545
Cumulative Model Updates: 152,966
Cumulative Timesteps: 1,216,027,922
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74292
Policy Entropy: 4.34341
Value Function Loss: 0.00270
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03047
Policy Update Magnitude: 1.03519
Value Function Update Magnitude: 0.81210
Collected Steps per Second: 12,966.30356
Overall Steps per Second: 7,187.46042
Timestep Collection Time: 3.85677
Timestep Consumption Time: 3.10091
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.95767
Cumulative Model Updates: 152,975
Cumulative Timesteps: 1,216,077,930
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1216077930...
Checkpoint 1216077930 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85073
Policy Entropy: 4.33792
Value Function Loss: 0.00279
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03524
Policy Update Magnitude: 1.06106
Value Function Update Magnitude: 0.81448
Collected Steps per Second: 12,965.96115
Overall Steps per Second: 7,220.12188
Timestep Collection Time: 3.85826
Timestep Consumption Time: 3.07044
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.92869
Cumulative Model Updates: 152,984
Cumulative Timesteps: 1,216,127,956
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.13156
Policy Entropy: 4.33784
Value Function Loss: 0.00285
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03722
Policy Update Magnitude: 1.06129
Value Function Update Magnitude: 0.80767
Collected Steps per Second: 12,943.03080
Overall Steps per Second: 7,291.30657
Timestep Collection Time: 3.86556
Timestep Consumption Time: 2.99632
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.86187
Cumulative Model Updates: 152,993
Cumulative Timesteps: 1,216,177,988
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1216177988...
Checkpoint 1216177988 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.09047
Policy Entropy: 4.33726
Value Function Loss: 0.00268
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03605
Policy Update Magnitude: 1.04237
Value Function Update Magnitude: 0.77701
Collected Steps per Second: 12,794.30030
Overall Steps per Second: 7,018.54178
Timestep Collection Time: 3.90971
Timestep Consumption Time: 3.21741
PPO Batch Consumption Time: 0.23667
Total Iteration Time: 7.12712
Cumulative Model Updates: 153,002
Cumulative Timesteps: 1,216,228,010
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.32050
Policy Entropy: 4.33497
Value Function Loss: 0.00261
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03454
Policy Update Magnitude: 1.01970
Value Function Update Magnitude: 0.74959
Collected Steps per Second: 13,000.61846
Overall Steps per Second: 7,208.91942
Timestep Collection Time: 3.84843
Timestep Consumption Time: 3.09186
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.94029
Cumulative Model Updates: 153,011
Cumulative Timesteps: 1,216,278,042
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1216278042...
Checkpoint 1216278042 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.26367
Policy Entropy: 4.33260
Value Function Loss: 0.00257
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03350
Policy Update Magnitude: 1.00946
Value Function Update Magnitude: 0.76507
Collected Steps per Second: 13,230.58429
Overall Steps per Second: 7,261.83776
Timestep Collection Time: 3.78124
Timestep Consumption Time: 3.10793
PPO Batch Consumption Time: 0.22911
Total Iteration Time: 6.88917
Cumulative Model Updates: 153,020
Cumulative Timesteps: 1,216,328,070
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.37979
Policy Entropy: 4.33476
Value Function Loss: 0.00258
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03373
Policy Update Magnitude: 1.02438
Value Function Update Magnitude: 0.79628
Collected Steps per Second: 12,985.70544
Overall Steps per Second: 7,193.34498
Timestep Collection Time: 3.85177
Timestep Consumption Time: 3.10160
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.95337
Cumulative Model Updates: 153,029
Cumulative Timesteps: 1,216,378,088
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1216378088...
Checkpoint 1216378088 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.31902
Policy Entropy: 4.33804
Value Function Loss: 0.00250
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03392
Policy Update Magnitude: 1.01479
Value Function Update Magnitude: 0.79966
Collected Steps per Second: 12,906.98423
Overall Steps per Second: 7,202.02444
Timestep Collection Time: 3.87775
Timestep Consumption Time: 3.07169
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.94943
Cumulative Model Updates: 153,038
Cumulative Timesteps: 1,216,428,138
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.02469
Policy Entropy: 4.34032
Value Function Loss: 0.00255
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03172
Policy Update Magnitude: 1.00319
Value Function Update Magnitude: 0.80172
Collected Steps per Second: 13,186.87532
Overall Steps per Second: 7,247.49986
Timestep Collection Time: 3.79165
Timestep Consumption Time: 3.10728
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.89893
Cumulative Model Updates: 153,047
Cumulative Timesteps: 1,216,478,138
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1216478138...
Checkpoint 1216478138 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31294
Policy Entropy: 4.33936
Value Function Loss: 0.00257
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03322
Policy Update Magnitude: 0.99957
Value Function Update Magnitude: 0.79780
Collected Steps per Second: 12,922.56577
Overall Steps per Second: 7,167.17106
Timestep Collection Time: 3.87384
Timestep Consumption Time: 3.11078
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.98462
Cumulative Model Updates: 153,056
Cumulative Timesteps: 1,216,528,198
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95387
Policy Entropy: 4.33750
Value Function Loss: 0.00262
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 0.99920
Value Function Update Magnitude: 0.80024
Collected Steps per Second: 12,995.92786
Overall Steps per Second: 7,263.90841
Timestep Collection Time: 3.84736
Timestep Consumption Time: 3.03599
PPO Batch Consumption Time: 0.23233
Total Iteration Time: 6.88335
Cumulative Model Updates: 153,065
Cumulative Timesteps: 1,216,578,198
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1216578198...
Checkpoint 1216578198 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49187
Policy Entropy: 4.34027
Value Function Loss: 0.00261
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 1.00772
Value Function Update Magnitude: 0.79199
Collected Steps per Second: 12,927.52843
Overall Steps per Second: 7,182.09219
Timestep Collection Time: 3.86880
Timestep Consumption Time: 3.09491
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.96371
Cumulative Model Updates: 153,074
Cumulative Timesteps: 1,216,628,212
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.72106
Policy Entropy: 4.33720
Value Function Loss: 0.00266
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03224
Policy Update Magnitude: 1.03784
Value Function Update Magnitude: 0.82468
Collected Steps per Second: 12,987.27090
Overall Steps per Second: 7,177.69447
Timestep Collection Time: 3.85208
Timestep Consumption Time: 3.11785
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.96993
Cumulative Model Updates: 153,083
Cumulative Timesteps: 1,216,678,240
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1216678240...
Checkpoint 1216678240 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51919
Policy Entropy: 4.33318
Value Function Loss: 0.00263
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03503
Policy Update Magnitude: 1.04537
Value Function Update Magnitude: 0.85145
Collected Steps per Second: 13,028.52936
Overall Steps per Second: 7,307.47857
Timestep Collection Time: 3.83957
Timestep Consumption Time: 3.00602
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.84559
Cumulative Model Updates: 153,092
Cumulative Timesteps: 1,216,728,264
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.94844
Policy Entropy: 4.33030
Value Function Loss: 0.00265
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 1.04782
Value Function Update Magnitude: 0.84996
Collected Steps per Second: 13,028.30038
Overall Steps per Second: 7,193.14050
Timestep Collection Time: 3.83857
Timestep Consumption Time: 3.11389
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.95246
Cumulative Model Updates: 153,101
Cumulative Timesteps: 1,216,778,274
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1216778274...
Checkpoint 1216778274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.50667
Policy Entropy: 4.33374
Value Function Loss: 0.00266
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03400
Policy Update Magnitude: 1.05597
Value Function Update Magnitude: 0.83549
Collected Steps per Second: 13,062.12944
Overall Steps per Second: 7,205.07394
Timestep Collection Time: 3.82908
Timestep Consumption Time: 3.11269
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.94177
Cumulative Model Updates: 153,110
Cumulative Timesteps: 1,216,828,290
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.25510
Policy Entropy: 4.33129
Value Function Loss: 0.00267
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 1.03942
Value Function Update Magnitude: 0.83283
Collected Steps per Second: 12,919.78015
Overall Steps per Second: 7,273.53826
Timestep Collection Time: 3.87081
Timestep Consumption Time: 3.00480
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.87561
Cumulative Model Updates: 153,119
Cumulative Timesteps: 1,216,878,300
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1216878300...
Checkpoint 1216878300 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35615
Policy Entropy: 4.32906
Value Function Loss: 0.00267
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03295
Policy Update Magnitude: 1.03083
Value Function Update Magnitude: 0.83961
Collected Steps per Second: 12,970.20494
Overall Steps per Second: 7,098.52195
Timestep Collection Time: 3.85576
Timestep Consumption Time: 3.18937
PPO Batch Consumption Time: 0.23529
Total Iteration Time: 7.04513
Cumulative Model Updates: 153,128
Cumulative Timesteps: 1,216,928,310
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.65336
Policy Entropy: 4.32928
Value Function Loss: 0.00264
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03516
Policy Update Magnitude: 1.04364
Value Function Update Magnitude: 0.82727
Collected Steps per Second: 12,675.83223
Overall Steps per Second: 7,146.95805
Timestep Collection Time: 3.94925
Timestep Consumption Time: 3.05513
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 7.00438
Cumulative Model Updates: 153,137
Cumulative Timesteps: 1,216,978,370
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
Saving checkpoint 1216978370...
Checkpoint 1216978370 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.50461
Policy Entropy: 4.33276
Value Function Loss: 0.00265
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03298
Policy Update Magnitude: 1.02869
Value Function Update Magnitude: 0.83123
Collected Steps per Second: 12,833.70072
Overall Steps per Second: 7,264.39224
Timestep Collection Time: 3.89849
Timestep Consumption Time: 2.98881
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.88729
Cumulative Model Updates: 153,146
Cumulative Timesteps: 1,217,028,402
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44048
Policy Entropy: 4.33187
Value Function Loss: 0.00275
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03446
Policy Update Magnitude: 1.04091
Value Function Update Magnitude: 0.83103
Collected Steps per Second: 12,983.11473
Overall Steps per Second: 7,188.82081
Timestep Collection Time: 3.85254
Timestep Consumption Time: 3.10521
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.95775
Cumulative Model Updates: 153,155
Cumulative Timesteps: 1,217,078,420
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1217078420...
Checkpoint 1217078420 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.47366
Policy Entropy: 4.32912
Value Function Loss: 0.00277
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03640
Policy Update Magnitude: 1.04841
Value Function Update Magnitude: 0.83382
Collected Steps per Second: 13,015.95736
Overall Steps per Second: 7,244.17094
Timestep Collection Time: 3.84405
Timestep Consumption Time: 3.06274
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.90679
Cumulative Model Updates: 153,164
Cumulative Timesteps: 1,217,128,454
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.29995
Policy Entropy: 4.33153
Value Function Loss: 0.00281
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03473
Policy Update Magnitude: 1.03268
Value Function Update Magnitude: 0.83522
Collected Steps per Second: 13,032.03492
Overall Steps per Second: 7,311.99528
Timestep Collection Time: 3.83793
Timestep Consumption Time: 3.00234
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.84027
Cumulative Model Updates: 153,173
Cumulative Timesteps: 1,217,178,470
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1217178470...
Checkpoint 1217178470 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27087
Policy Entropy: 4.33394
Value Function Loss: 0.00276
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03321
Policy Update Magnitude: 1.03334
Value Function Update Magnitude: 0.84114
Collected Steps per Second: 12,930.17262
Overall Steps per Second: 7,183.56254
Timestep Collection Time: 3.87095
Timestep Consumption Time: 3.09663
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.96757
Cumulative Model Updates: 153,182
Cumulative Timesteps: 1,217,228,522
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.76545
Policy Entropy: 4.33584
Value Function Loss: 0.00264
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03352
Policy Update Magnitude: 1.01866
Value Function Update Magnitude: 0.82147
Collected Steps per Second: 12,811.48145
Overall Steps per Second: 7,119.26781
Timestep Collection Time: 3.90306
Timestep Consumption Time: 3.12069
PPO Batch Consumption Time: 0.22970
Total Iteration Time: 7.02376
Cumulative Model Updates: 153,191
Cumulative Timesteps: 1,217,278,526
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1217278526...
Checkpoint 1217278526 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.40019
Policy Entropy: 4.33588
Value Function Loss: 0.00270
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 1.02538
Value Function Update Magnitude: 0.80597
Collected Steps per Second: 12,840.25145
Overall Steps per Second: 7,250.25473
Timestep Collection Time: 3.89572
Timestep Consumption Time: 3.00363
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.89934
Cumulative Model Updates: 153,200
Cumulative Timesteps: 1,217,328,548
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.96386
Policy Entropy: 4.33734
Value Function Loss: 0.00254
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03278
Policy Update Magnitude: 1.01942
Value Function Update Magnitude: 0.80810
Collected Steps per Second: 12,964.52173
Overall Steps per Second: 7,167.94372
Timestep Collection Time: 3.85668
Timestep Consumption Time: 3.11882
PPO Batch Consumption Time: 0.22930
Total Iteration Time: 6.97550
Cumulative Model Updates: 153,209
Cumulative Timesteps: 1,217,378,548
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1217378548...
Checkpoint 1217378548 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.02687
Policy Entropy: 4.33556
Value Function Loss: 0.00266
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 1.01522
Value Function Update Magnitude: 0.80724
Collected Steps per Second: 12,818.18774
Overall Steps per Second: 7,176.42429
Timestep Collection Time: 3.90336
Timestep Consumption Time: 3.06864
PPO Batch Consumption Time: 0.22922
Total Iteration Time: 6.97200
Cumulative Model Updates: 153,218
Cumulative Timesteps: 1,217,428,582
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.35151
Policy Entropy: 4.33486
Value Function Loss: 0.00269
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03296
Policy Update Magnitude: 1.04651
Value Function Update Magnitude: 0.81643
Collected Steps per Second: 12,865.15905
Overall Steps per Second: 7,265.13711
Timestep Collection Time: 3.88740
Timestep Consumption Time: 2.99644
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.88383
Cumulative Model Updates: 153,227
Cumulative Timesteps: 1,217,478,594
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1217478594...
Checkpoint 1217478594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04751
Policy Entropy: 4.33368
Value Function Loss: 0.00283
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 1.06485
Value Function Update Magnitude: 0.85695
Collected Steps per Second: 12,897.71989
Overall Steps per Second: 7,176.48560
Timestep Collection Time: 3.87712
Timestep Consumption Time: 3.09092
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.96803
Cumulative Model Updates: 153,236
Cumulative Timesteps: 1,217,528,600
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.95403
Policy Entropy: 4.33572
Value Function Loss: 0.00279
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03465
Policy Update Magnitude: 1.05453
Value Function Update Magnitude: 0.86835
Collected Steps per Second: 12,883.40038
Overall Steps per Second: 7,158.15484
Timestep Collection Time: 3.88143
Timestep Consumption Time: 3.10445
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.98588
Cumulative Model Updates: 153,245
Cumulative Timesteps: 1,217,578,606
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1217578606...
Checkpoint 1217578606 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.76761
Policy Entropy: 4.33925
Value Function Loss: 0.00267
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03393
Policy Update Magnitude: 1.03274
Value Function Update Magnitude: 0.84177
Collected Steps per Second: 12,814.22859
Overall Steps per Second: 7,077.18768
Timestep Collection Time: 3.90457
Timestep Consumption Time: 3.16519
PPO Batch Consumption Time: 0.24101
Total Iteration Time: 7.06976
Cumulative Model Updates: 153,254
Cumulative Timesteps: 1,217,628,640
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.84492
Policy Entropy: 4.34218
Value Function Loss: 0.00263
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03374
Policy Update Magnitude: 1.03341
Value Function Update Magnitude: 0.86608
Collected Steps per Second: 13,147.72330
Overall Steps per Second: 7,242.30470
Timestep Collection Time: 3.80309
Timestep Consumption Time: 3.10106
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.90416
Cumulative Model Updates: 153,263
Cumulative Timesteps: 1,217,678,642
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1217678642...
Checkpoint 1217678642 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.32573
Policy Entropy: 4.34006
Value Function Loss: 0.00265
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 1.04983
Value Function Update Magnitude: 0.84178
Collected Steps per Second: 13,012.32518
Overall Steps per Second: 7,189.18215
Timestep Collection Time: 3.84343
Timestep Consumption Time: 3.11313
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.95656
Cumulative Model Updates: 153,272
Cumulative Timesteps: 1,217,728,654
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.50604
Policy Entropy: 4.33694
Value Function Loss: 0.00274
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03336
Policy Update Magnitude: 1.05305
Value Function Update Magnitude: 0.82272
Collected Steps per Second: 12,918.43051
Overall Steps per Second: 7,268.50551
Timestep Collection Time: 3.87121
Timestep Consumption Time: 3.00916
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.88037
Cumulative Model Updates: 153,281
Cumulative Timesteps: 1,217,778,664
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1217778664...
Checkpoint 1217778664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.15279
Policy Entropy: 4.33683
Value Function Loss: 0.00273
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03461
Policy Update Magnitude: 1.05644
Value Function Update Magnitude: 0.82688
Collected Steps per Second: 13,064.00466
Overall Steps per Second: 7,187.34772
Timestep Collection Time: 3.82792
Timestep Consumption Time: 3.12986
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.95778
Cumulative Model Updates: 153,290
Cumulative Timesteps: 1,217,828,672
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99593
Policy Entropy: 4.33092
Value Function Loss: 0.00278
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03457
Policy Update Magnitude: 1.05229
Value Function Update Magnitude: 0.85235
Collected Steps per Second: 13,075.91096
Overall Steps per Second: 7,234.53725
Timestep Collection Time: 3.82566
Timestep Consumption Time: 3.08895
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.91461
Cumulative Model Updates: 153,299
Cumulative Timesteps: 1,217,878,696
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1217878696...
Checkpoint 1217878696 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.40845
Policy Entropy: 4.33492
Value Function Loss: 0.00270
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 1.05310
Value Function Update Magnitude: 0.83439
Collected Steps per Second: 12,959.45529
Overall Steps per Second: 7,295.84035
Timestep Collection Time: 3.85958
Timestep Consumption Time: 2.99611
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.85569
Cumulative Model Updates: 153,308
Cumulative Timesteps: 1,217,928,714
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97114
Policy Entropy: 4.33560
Value Function Loss: 0.00261
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03258
Policy Update Magnitude: 1.01853
Value Function Update Magnitude: 0.79228
Collected Steps per Second: 12,981.71312
Overall Steps per Second: 7,033.42487
Timestep Collection Time: 3.85234
Timestep Consumption Time: 3.25799
PPO Batch Consumption Time: 0.24109
Total Iteration Time: 7.11033
Cumulative Model Updates: 153,317
Cumulative Timesteps: 1,217,978,724
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1217978724...
Checkpoint 1217978724 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.15060
Policy Entropy: 4.34251
Value Function Loss: 0.00253
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03135
Policy Update Magnitude: 1.01082
Value Function Update Magnitude: 0.77450
Collected Steps per Second: 12,974.09519
Overall Steps per Second: 7,183.81784
Timestep Collection Time: 3.85414
Timestep Consumption Time: 3.10650
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.96064
Cumulative Model Updates: 153,326
Cumulative Timesteps: 1,218,028,728
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52241
Policy Entropy: 4.34266
Value Function Loss: 0.00253
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 1.01477
Value Function Update Magnitude: 0.80797
Collected Steps per Second: 12,822.95376
Overall Steps per Second: 7,247.33739
Timestep Collection Time: 3.90035
Timestep Consumption Time: 3.00067
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.90102
Cumulative Model Updates: 153,335
Cumulative Timesteps: 1,218,078,742
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1218078742...
Checkpoint 1218078742 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36755
Policy Entropy: 4.34040
Value Function Loss: 0.00252
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03132
Policy Update Magnitude: 1.00471
Value Function Update Magnitude: 0.81061
Collected Steps per Second: 12,922.26235
Overall Steps per Second: 7,162.73323
Timestep Collection Time: 3.87208
Timestep Consumption Time: 3.11352
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.98560
Cumulative Model Updates: 153,344
Cumulative Timesteps: 1,218,128,778
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11082
Policy Entropy: 4.33277
Value Function Loss: 0.00261
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03038
Policy Update Magnitude: 1.00731
Value Function Update Magnitude: 0.81539
Collected Steps per Second: 13,000.03460
Overall Steps per Second: 7,179.55121
Timestep Collection Time: 3.85014
Timestep Consumption Time: 3.12132
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.97147
Cumulative Model Updates: 153,353
Cumulative Timesteps: 1,218,178,830
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1218178830...
Checkpoint 1218178830 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01703
Policy Entropy: 4.33136
Value Function Loss: 0.00261
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03216
Policy Update Magnitude: 1.03731
Value Function Update Magnitude: 0.84684
Collected Steps per Second: 12,703.77287
Overall Steps per Second: 7,193.45323
Timestep Collection Time: 3.93899
Timestep Consumption Time: 3.01734
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.95633
Cumulative Model Updates: 153,362
Cumulative Timesteps: 1,218,228,870
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.67419
Policy Entropy: 4.33096
Value Function Loss: 0.00257
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03493
Policy Update Magnitude: 1.03150
Value Function Update Magnitude: 0.83655
Collected Steps per Second: 13,039.22900
Overall Steps per Second: 7,195.07916
Timestep Collection Time: 3.83872
Timestep Consumption Time: 3.11798
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.95670
Cumulative Model Updates: 153,371
Cumulative Timesteps: 1,218,278,924
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1218278924...
Checkpoint 1218278924 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.38090
Policy Entropy: 4.33372
Value Function Loss: 0.00253
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 1.01563
Value Function Update Magnitude: 0.80965
Collected Steps per Second: 12,977.22288
Overall Steps per Second: 7,181.46953
Timestep Collection Time: 3.85321
Timestep Consumption Time: 3.10971
PPO Batch Consumption Time: 0.22968
Total Iteration Time: 6.96292
Cumulative Model Updates: 153,380
Cumulative Timesteps: 1,218,328,928
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.84063
Policy Entropy: 4.33774
Value Function Loss: 0.00242
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 0.99485
Value Function Update Magnitude: 0.80448
Collected Steps per Second: 12,864.61054
Overall Steps per Second: 7,247.84813
Timestep Collection Time: 3.88912
Timestep Consumption Time: 3.01390
PPO Batch Consumption Time: 0.23054
Total Iteration Time: 6.90301
Cumulative Model Updates: 153,389
Cumulative Timesteps: 1,218,378,960
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1218378960...
Checkpoint 1218378960 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.72766
Policy Entropy: 4.34033
Value Function Loss: 0.00246
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03067
Policy Update Magnitude: 0.99701
Value Function Update Magnitude: 0.79624
Collected Steps per Second: 12,942.52174
Overall Steps per Second: 7,170.47606
Timestep Collection Time: 3.86602
Timestep Consumption Time: 3.11204
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.97806
Cumulative Model Updates: 153,398
Cumulative Timesteps: 1,218,428,996
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.68404
Policy Entropy: 4.34495
Value Function Loss: 0.00247
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03024
Policy Update Magnitude: 1.00505
Value Function Update Magnitude: 0.79558
Collected Steps per Second: 12,905.16478
Overall Steps per Second: 7,175.04308
Timestep Collection Time: 3.87767
Timestep Consumption Time: 3.09678
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.97445
Cumulative Model Updates: 153,407
Cumulative Timesteps: 1,218,479,038
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1218479038...
Checkpoint 1218479038 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.26923
Policy Entropy: 4.33848
Value Function Loss: 0.00252
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 1.00737
Value Function Update Magnitude: 0.79146
Collected Steps per Second: 12,873.41157
Overall Steps per Second: 7,250.27668
Timestep Collection Time: 3.88444
Timestep Consumption Time: 3.01268
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.89712
Cumulative Model Updates: 153,416
Cumulative Timesteps: 1,218,529,044
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.23746
Policy Entropy: 4.33891
Value Function Loss: 0.00252
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03162
Policy Update Magnitude: 0.99931
Value Function Update Magnitude: 0.80090
Collected Steps per Second: 12,907.95725
Overall Steps per Second: 7,179.29490
Timestep Collection Time: 3.87606
Timestep Consumption Time: 3.09287
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.96893
Cumulative Model Updates: 153,425
Cumulative Timesteps: 1,218,579,076
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1218579076...
Checkpoint 1218579076 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.84871
Policy Entropy: 4.33422
Value Function Loss: 0.00269
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03382
Policy Update Magnitude: 1.01643
Value Function Update Magnitude: 0.83345
Collected Steps per Second: 12,871.54289
Overall Steps per Second: 7,132.59959
Timestep Collection Time: 3.88702
Timestep Consumption Time: 3.12753
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 7.01455
Cumulative Model Updates: 153,434
Cumulative Timesteps: 1,218,629,108
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.26427
Policy Entropy: 4.33591
Value Function Loss: 0.00265
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 1.03760
Value Function Update Magnitude: 0.86086
Collected Steps per Second: 12,908.42195
Overall Steps per Second: 7,095.98446
Timestep Collection Time: 3.87483
Timestep Consumption Time: 3.17394
PPO Batch Consumption Time: 0.24070
Total Iteration Time: 7.04878
Cumulative Model Updates: 153,443
Cumulative Timesteps: 1,218,679,126
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1218679126...
Checkpoint 1218679126 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01669
Policy Entropy: 4.33190
Value Function Loss: 0.00271
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 1.04210
Value Function Update Magnitude: 0.87933
Collected Steps per Second: 13,004.19936
Overall Steps per Second: 7,184.08593
Timestep Collection Time: 3.84630
Timestep Consumption Time: 3.11604
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.96233
Cumulative Model Updates: 153,452
Cumulative Timesteps: 1,218,729,144
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.75314
Policy Entropy: 4.32930
Value Function Loss: 0.00277
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03470
Policy Update Magnitude: 1.07039
Value Function Update Magnitude: 0.87309
Collected Steps per Second: 12,921.90647
Overall Steps per Second: 7,174.72293
Timestep Collection Time: 3.86986
Timestep Consumption Time: 3.09988
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.96975
Cumulative Model Updates: 153,461
Cumulative Timesteps: 1,218,779,150
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1218779150...
Checkpoint 1218779150 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60754
Policy Entropy: 4.32956
Value Function Loss: 0.00279
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03558
Policy Update Magnitude: 1.06884
Value Function Update Magnitude: 0.85594
Collected Steps per Second: 12,893.56988
Overall Steps per Second: 7,272.42159
Timestep Collection Time: 3.87821
Timestep Consumption Time: 2.99763
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.87584
Cumulative Model Updates: 153,470
Cumulative Timesteps: 1,218,829,154
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.70723
Policy Entropy: 4.32948
Value Function Loss: 0.00282
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03436
Policy Update Magnitude: 1.04509
Value Function Update Magnitude: 0.85813
Collected Steps per Second: 13,127.71511
Overall Steps per Second: 7,226.05545
Timestep Collection Time: 3.81270
Timestep Consumption Time: 3.11390
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.92660
Cumulative Model Updates: 153,479
Cumulative Timesteps: 1,218,879,206
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1218879206...
Checkpoint 1218879206 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.87811
Policy Entropy: 4.33118
Value Function Loss: 0.00277
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 1.04876
Value Function Update Magnitude: 0.85683
Collected Steps per Second: 12,910.57501
Overall Steps per Second: 7,176.26989
Timestep Collection Time: 3.87543
Timestep Consumption Time: 3.09672
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.97215
Cumulative Model Updates: 153,488
Cumulative Timesteps: 1,218,929,240
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.68228
Policy Entropy: 4.33023
Value Function Loss: 0.00266
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 1.02025
Value Function Update Magnitude: 0.83618
Collected Steps per Second: 12,895.43083
Overall Steps per Second: 7,271.55876
Timestep Collection Time: 3.87843
Timestep Consumption Time: 2.99960
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.87803
Cumulative Model Updates: 153,497
Cumulative Timesteps: 1,218,979,254
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1218979254...
Checkpoint 1218979254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.08803
Policy Entropy: 4.33080
Value Function Loss: 0.00267
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03218
Policy Update Magnitude: 1.00779
Value Function Update Magnitude: 0.82236
Collected Steps per Second: 12,967.84598
Overall Steps per Second: 7,120.44970
Timestep Collection Time: 3.85816
Timestep Consumption Time: 3.16836
PPO Batch Consumption Time: 0.23161
Total Iteration Time: 7.02652
Cumulative Model Updates: 153,506
Cumulative Timesteps: 1,219,029,286
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.15793
Policy Entropy: 4.32875
Value Function Loss: 0.00272
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 1.01483
Value Function Update Magnitude: 0.83011
Collected Steps per Second: 13,084.07030
Overall Steps per Second: 7,240.57291
Timestep Collection Time: 3.82358
Timestep Consumption Time: 3.08582
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.90940
Cumulative Model Updates: 153,515
Cumulative Timesteps: 1,219,079,314
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1219079314...
Checkpoint 1219079314 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.14162
Policy Entropy: 4.32813
Value Function Loss: 0.00283
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03659
Policy Update Magnitude: 1.02617
Value Function Update Magnitude: 0.83335
Collected Steps per Second: 12,859.09662
Overall Steps per Second: 7,247.75993
Timestep Collection Time: 3.89110
Timestep Consumption Time: 3.01255
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.90365
Cumulative Model Updates: 153,524
Cumulative Timesteps: 1,219,129,350
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.15282
Policy Entropy: 4.32604
Value Function Loss: 0.00288
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03585
Policy Update Magnitude: 1.03927
Value Function Update Magnitude: 0.84085
Collected Steps per Second: 13,062.42824
Overall Steps per Second: 7,211.96322
Timestep Collection Time: 3.82884
Timestep Consumption Time: 3.10602
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.93487
Cumulative Model Updates: 153,533
Cumulative Timesteps: 1,219,179,364
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1219179364...
Checkpoint 1219179364 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31175
Policy Entropy: 4.32806
Value Function Loss: 0.00272
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03501
Policy Update Magnitude: 1.02543
Value Function Update Magnitude: 0.84494
Collected Steps per Second: 12,935.64944
Overall Steps per Second: 7,209.74922
Timestep Collection Time: 3.86683
Timestep Consumption Time: 3.07099
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.93783
Cumulative Model Updates: 153,542
Cumulative Timesteps: 1,219,229,384
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.69524
Policy Entropy: 4.33229
Value Function Loss: 0.00275
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03619
Policy Update Magnitude: 1.02077
Value Function Update Magnitude: 0.80981
Collected Steps per Second: 13,022.52518
Overall Steps per Second: 7,309.55118
Timestep Collection Time: 3.84196
Timestep Consumption Time: 3.00278
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.84474
Cumulative Model Updates: 153,551
Cumulative Timesteps: 1,219,279,416
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1219279416...
Checkpoint 1219279416 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.26837
Policy Entropy: 4.33785
Value Function Loss: 0.00266
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 1.02412
Value Function Update Magnitude: 0.79434
Collected Steps per Second: 12,678.76361
Overall Steps per Second: 7,093.37985
Timestep Collection Time: 3.94613
Timestep Consumption Time: 3.10721
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 7.05334
Cumulative Model Updates: 153,560
Cumulative Timesteps: 1,219,329,448
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75324
Policy Entropy: 4.33460
Value Function Loss: 0.00281
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03389
Policy Update Magnitude: 1.02832
Value Function Update Magnitude: 0.81032
Collected Steps per Second: 12,978.50551
Overall Steps per Second: 7,132.14224
Timestep Collection Time: 3.85345
Timestep Consumption Time: 3.15875
PPO Batch Consumption Time: 0.22992
Total Iteration Time: 7.01220
Cumulative Model Updates: 153,569
Cumulative Timesteps: 1,219,379,460
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1219379460...
Checkpoint 1219379460 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77167
Policy Entropy: 4.33110
Value Function Loss: 0.00284
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03397
Policy Update Magnitude: 1.03795
Value Function Update Magnitude: 0.82693
Collected Steps per Second: 12,780.01552
Overall Steps per Second: 7,221.67005
Timestep Collection Time: 3.91283
Timestep Consumption Time: 3.01161
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.92444
Cumulative Model Updates: 153,578
Cumulative Timesteps: 1,219,429,466
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46086
Policy Entropy: 4.32999
Value Function Loss: 0.00280
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03596
Policy Update Magnitude: 1.04563
Value Function Update Magnitude: 0.81924
Collected Steps per Second: 12,872.73964
Overall Steps per Second: 7,154.36319
Timestep Collection Time: 3.88728
Timestep Consumption Time: 3.10705
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.99433
Cumulative Model Updates: 153,587
Cumulative Timesteps: 1,219,479,506
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1219479506...
Checkpoint 1219479506 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75283
Policy Entropy: 4.33370
Value Function Loss: 0.00276
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03350
Policy Update Magnitude: 1.04165
Value Function Update Magnitude: 0.80265
Collected Steps per Second: 12,947.47809
Overall Steps per Second: 7,176.27607
Timestep Collection Time: 3.86438
Timestep Consumption Time: 3.10776
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.97214
Cumulative Model Updates: 153,596
Cumulative Timesteps: 1,219,529,540
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.15713
Policy Entropy: 4.33339
Value Function Loss: 0.00275
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03322
Policy Update Magnitude: 1.04284
Value Function Update Magnitude: 0.79069
Collected Steps per Second: 13,069.05178
Overall Steps per Second: 7,307.77792
Timestep Collection Time: 3.82828
Timestep Consumption Time: 3.01812
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.84640
Cumulative Model Updates: 153,605
Cumulative Timesteps: 1,219,579,572
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1219579572...
Checkpoint 1219579572 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68321
Policy Entropy: 4.33569
Value Function Loss: 0.00264
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03470
Policy Update Magnitude: 1.01767
Value Function Update Magnitude: 0.77009
Collected Steps per Second: 12,948.40510
Overall Steps per Second: 7,186.01009
Timestep Collection Time: 3.86426
Timestep Consumption Time: 3.09871
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.96297
Cumulative Model Updates: 153,614
Cumulative Timesteps: 1,219,629,608
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.70372
Policy Entropy: 4.33546
Value Function Loss: 0.00274
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03436
Policy Update Magnitude: 0.99700
Value Function Update Magnitude: 0.76226
Collected Steps per Second: 12,838.67069
Overall Steps per Second: 7,154.55739
Timestep Collection Time: 3.89667
Timestep Consumption Time: 3.09580
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.99247
Cumulative Model Updates: 153,623
Cumulative Timesteps: 1,219,679,636
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1219679636...
Checkpoint 1219679636 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23507
Policy Entropy: 4.33903
Value Function Loss: 0.00259
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 0.99453
Value Function Update Magnitude: 0.77115
Collected Steps per Second: 12,805.62383
Overall Steps per Second: 7,112.02673
Timestep Collection Time: 3.90703
Timestep Consumption Time: 3.12781
PPO Batch Consumption Time: 0.23919
Total Iteration Time: 7.03484
Cumulative Model Updates: 153,632
Cumulative Timesteps: 1,219,729,668
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.89386
Policy Entropy: 4.33558
Value Function Loss: 0.00267
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 0.98398
Value Function Update Magnitude: 0.80133
Collected Steps per Second: 13,063.38456
Overall Steps per Second: 7,223.72218
Timestep Collection Time: 3.83147
Timestep Consumption Time: 3.09737
PPO Batch Consumption Time: 0.22783
Total Iteration Time: 6.92884
Cumulative Model Updates: 153,641
Cumulative Timesteps: 1,219,779,720
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1219779720...
Checkpoint 1219779720 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.67461
Policy Entropy: 4.33514
Value Function Loss: 0.00266
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03235
Policy Update Magnitude: 1.00348
Value Function Update Magnitude: 0.81390
Collected Steps per Second: 12,858.66809
Overall Steps per Second: 7,169.37762
Timestep Collection Time: 3.89092
Timestep Consumption Time: 3.08765
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.97857
Cumulative Model Updates: 153,650
Cumulative Timesteps: 1,219,829,752
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11413
Policy Entropy: 4.33411
Value Function Loss: 0.00272
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03464
Policy Update Magnitude: 1.03302
Value Function Update Magnitude: 0.82615
Collected Steps per Second: 13,014.38066
Overall Steps per Second: 7,300.87633
Timestep Collection Time: 3.84329
Timestep Consumption Time: 3.00767
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.85096
Cumulative Model Updates: 153,659
Cumulative Timesteps: 1,219,879,770
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1219879770...
Checkpoint 1219879770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 20.46240
Policy Entropy: 4.33712
Value Function Loss: 0.00272
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03492
Policy Update Magnitude: 1.03143
Value Function Update Magnitude: 0.82052
Collected Steps per Second: 12,874.43489
Overall Steps per Second: 7,166.11102
Timestep Collection Time: 3.88631
Timestep Consumption Time: 3.09572
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.98203
Cumulative Model Updates: 153,668
Cumulative Timesteps: 1,219,929,804
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95227
Policy Entropy: 4.33663
Value Function Loss: 0.00276
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03464
Policy Update Magnitude: 1.02512
Value Function Update Magnitude: 0.79388
Collected Steps per Second: 13,016.53045
Overall Steps per Second: 7,204.11444
Timestep Collection Time: 3.84281
Timestep Consumption Time: 3.10045
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.94325
Cumulative Model Updates: 153,677
Cumulative Timesteps: 1,219,979,824
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1219979824...
Checkpoint 1219979824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.16131
Policy Entropy: 4.33608
Value Function Loss: 0.00279
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03324
Policy Update Magnitude: 1.03539
Value Function Update Magnitude: 0.81016
Collected Steps per Second: 12,998.00213
Overall Steps per Second: 7,282.36532
Timestep Collection Time: 3.84890
Timestep Consumption Time: 3.02085
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.86975
Cumulative Model Updates: 153,686
Cumulative Timesteps: 1,220,029,852
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.62757
Policy Entropy: 4.33390
Value Function Loss: 0.00277
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03432
Policy Update Magnitude: 1.03088
Value Function Update Magnitude: 0.83329
Collected Steps per Second: 12,978.16559
Overall Steps per Second: 7,152.67778
Timestep Collection Time: 3.85571
Timestep Consumption Time: 3.14027
PPO Batch Consumption Time: 0.23255
Total Iteration Time: 6.99598
Cumulative Model Updates: 153,695
Cumulative Timesteps: 1,220,079,892
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1220079892...
Checkpoint 1220079892 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.11321
Policy Entropy: 4.33638
Value Function Loss: 0.00269
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 1.02612
Value Function Update Magnitude: 0.82620
Collected Steps per Second: 12,899.43817
Overall Steps per Second: 7,162.34352
Timestep Collection Time: 3.87815
Timestep Consumption Time: 3.10643
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.98459
Cumulative Model Updates: 153,704
Cumulative Timesteps: 1,220,129,918
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02721
Policy Entropy: 4.33730
Value Function Loss: 0.00266
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 1.00692
Value Function Update Magnitude: 0.79969
Collected Steps per Second: 12,901.18757
Overall Steps per Second: 7,269.89382
Timestep Collection Time: 3.87685
Timestep Consumption Time: 3.00303
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.87988
Cumulative Model Updates: 153,713
Cumulative Timesteps: 1,220,179,934
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1220179934...
Checkpoint 1220179934 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68457
Policy Entropy: 4.33491
Value Function Loss: 0.00263
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.99101
Value Function Update Magnitude: 0.79542
Collected Steps per Second: 13,030.98131
Overall Steps per Second: 7,151.80711
Timestep Collection Time: 3.84069
Timestep Consumption Time: 3.15726
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.99795
Cumulative Model Updates: 153,722
Cumulative Timesteps: 1,220,229,982
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.66121
Policy Entropy: 4.33208
Value Function Loss: 0.00267
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03206
Policy Update Magnitude: 0.99781
Value Function Update Magnitude: 0.81464
Collected Steps per Second: 12,940.72894
Overall Steps per Second: 7,165.92689
Timestep Collection Time: 3.86748
Timestep Consumption Time: 3.11668
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.98416
Cumulative Model Updates: 153,731
Cumulative Timesteps: 1,220,280,030
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1220280030...
Checkpoint 1220280030 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04728
Policy Entropy: 4.33406
Value Function Loss: 0.00271
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03494
Policy Update Magnitude: 1.01880
Value Function Update Magnitude: 0.81008
Collected Steps per Second: 12,869.95790
Overall Steps per Second: 7,259.08247
Timestep Collection Time: 3.88642
Timestep Consumption Time: 3.00399
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.89040
Cumulative Model Updates: 153,740
Cumulative Timesteps: 1,220,330,048
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.88578
Policy Entropy: 4.33234
Value Function Loss: 0.00276
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03343
Policy Update Magnitude: 1.02950
Value Function Update Magnitude: 0.81265
Collected Steps per Second: 12,903.00953
Overall Steps per Second: 7,178.71001
Timestep Collection Time: 3.87801
Timestep Consumption Time: 3.09232
PPO Batch Consumption Time: 0.22907
Total Iteration Time: 6.97033
Cumulative Model Updates: 153,749
Cumulative Timesteps: 1,220,380,086
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1220380086...
Checkpoint 1220380086 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.62289
Policy Entropy: 4.33145
Value Function Loss: 0.00283
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03586
Policy Update Magnitude: 1.04533
Value Function Update Magnitude: 0.82503
Collected Steps per Second: 13,027.13725
Overall Steps per Second: 7,047.21446
Timestep Collection Time: 3.83814
Timestep Consumption Time: 3.25686
PPO Batch Consumption Time: 0.24062
Total Iteration Time: 7.09500
Cumulative Model Updates: 153,758
Cumulative Timesteps: 1,220,430,086
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.91999
Policy Entropy: 4.32831
Value Function Loss: 0.00283
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03547
Policy Update Magnitude: 1.05914
Value Function Update Magnitude: 0.83447
Collected Steps per Second: 13,003.45483
Overall Steps per Second: 7,266.06301
Timestep Collection Time: 3.84575
Timestep Consumption Time: 3.03666
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.88241
Cumulative Model Updates: 153,767
Cumulative Timesteps: 1,220,480,094
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1220480094...
Checkpoint 1220480094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24755
Policy Entropy: 4.33139
Value Function Loss: 0.00284
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03626
Policy Update Magnitude: 1.05190
Value Function Update Magnitude: 0.80447
Collected Steps per Second: 12,914.19762
Overall Steps per Second: 7,165.22206
Timestep Collection Time: 3.87233
Timestep Consumption Time: 3.10694
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.97927
Cumulative Model Updates: 153,776
Cumulative Timesteps: 1,220,530,102
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.45454
Policy Entropy: 4.33715
Value Function Loss: 0.00274
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03409
Policy Update Magnitude: 1.02922
Value Function Update Magnitude: 0.79550
Collected Steps per Second: 12,757.06844
Overall Steps per Second: 7,120.40411
Timestep Collection Time: 3.92175
Timestep Consumption Time: 3.10454
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 7.02629
Cumulative Model Updates: 153,785
Cumulative Timesteps: 1,220,580,132
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1220580132...
Checkpoint 1220580132 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.69763
Policy Entropy: 4.34003
Value Function Loss: 0.00273
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 1.02553
Value Function Update Magnitude: 0.80060
Collected Steps per Second: 12,687.90383
Overall Steps per Second: 7,126.34281
Timestep Collection Time: 3.94092
Timestep Consumption Time: 3.07558
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 7.01650
Cumulative Model Updates: 153,794
Cumulative Timesteps: 1,220,630,134
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.10553
Policy Entropy: 4.33441
Value Function Loss: 0.00278
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 1.03078
Value Function Update Magnitude: 0.81457
Collected Steps per Second: 13,279.64520
Overall Steps per Second: 7,285.63745
Timestep Collection Time: 3.76667
Timestep Consumption Time: 3.09890
PPO Batch Consumption Time: 0.22867
Total Iteration Time: 6.86556
Cumulative Model Updates: 153,803
Cumulative Timesteps: 1,220,680,154
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1220680154...
Checkpoint 1220680154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.28058
Policy Entropy: 4.33266
Value Function Loss: 0.00272
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03256
Policy Update Magnitude: 1.02417
Value Function Update Magnitude: 0.83412
Collected Steps per Second: 12,918.83815
Overall Steps per Second: 7,170.93174
Timestep Collection Time: 3.87419
Timestep Consumption Time: 3.10538
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.97957
Cumulative Model Updates: 153,812
Cumulative Timesteps: 1,220,730,204
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.72847
Policy Entropy: 4.33208
Value Function Loss: 0.00279
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 1.01471
Value Function Update Magnitude: 0.83713
Collected Steps per Second: 12,898.74447
Overall Steps per Second: 7,128.85769
Timestep Collection Time: 3.87759
Timestep Consumption Time: 3.13840
PPO Batch Consumption Time: 0.23022
Total Iteration Time: 7.01599
Cumulative Model Updates: 153,821
Cumulative Timesteps: 1,220,780,220
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1220780220...
Checkpoint 1220780220 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.32253
Policy Entropy: 4.32810
Value Function Loss: 0.00295
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03496
Policy Update Magnitude: 1.04338
Value Function Update Magnitude: 0.86488
Collected Steps per Second: 13,268.90231
Overall Steps per Second: 7,295.99113
Timestep Collection Time: 3.77077
Timestep Consumption Time: 3.08697
PPO Batch Consumption Time: 0.22821
Total Iteration Time: 6.85774
Cumulative Model Updates: 153,830
Cumulative Timesteps: 1,220,830,254
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.33732
Policy Entropy: 4.32476
Value Function Loss: 0.00308
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03556
Policy Update Magnitude: 1.06781
Value Function Update Magnitude: 0.91620
Collected Steps per Second: 12,956.83490
Overall Steps per Second: 7,187.87229
Timestep Collection Time: 3.86020
Timestep Consumption Time: 3.09819
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.95839
Cumulative Model Updates: 153,839
Cumulative Timesteps: 1,220,880,270
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1220880270...
Checkpoint 1220880270 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30028
Policy Entropy: 4.32246
Value Function Loss: 0.00294
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03443
Policy Update Magnitude: 1.06009
Value Function Update Magnitude: 0.93650
Collected Steps per Second: 12,864.63563
Overall Steps per Second: 7,155.16699
Timestep Collection Time: 3.88740
Timestep Consumption Time: 3.10195
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.98935
Cumulative Model Updates: 153,848
Cumulative Timesteps: 1,220,930,280
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51026
Policy Entropy: 4.32517
Value Function Loss: 0.00272
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03353
Policy Update Magnitude: 1.04934
Value Function Update Magnitude: 0.88609
Collected Steps per Second: 13,322.25099
Overall Steps per Second: 7,298.63205
Timestep Collection Time: 3.75432
Timestep Consumption Time: 3.09847
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.85279
Cumulative Model Updates: 153,857
Cumulative Timesteps: 1,220,980,296
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1220980296...
Checkpoint 1220980296 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.57858
Policy Entropy: 4.32914
Value Function Loss: 0.00258
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03349
Policy Update Magnitude: 1.00912
Value Function Update Magnitude: 0.83625
Collected Steps per Second: 12,847.52741
Overall Steps per Second: 7,129.32066
Timestep Collection Time: 3.89258
Timestep Consumption Time: 3.12212
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 7.01469
Cumulative Model Updates: 153,866
Cumulative Timesteps: 1,221,030,306
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.54705
Policy Entropy: 4.33085
Value Function Loss: 0.00259
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03158
Policy Update Magnitude: 1.00604
Value Function Update Magnitude: 0.82210
Collected Steps per Second: 13,025.98719
Overall Steps per Second: 7,223.56290
Timestep Collection Time: 3.84017
Timestep Consumption Time: 3.08467
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.92484
Cumulative Model Updates: 153,875
Cumulative Timesteps: 1,221,080,328
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1221080328...
Checkpoint 1221080328 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.40283
Policy Entropy: 4.32997
Value Function Loss: 0.00268
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03136
Policy Update Magnitude: 1.01656
Value Function Update Magnitude: 0.82519
Collected Steps per Second: 13,131.18459
Overall Steps per Second: 7,160.57998
Timestep Collection Time: 3.80971
Timestep Consumption Time: 3.17660
PPO Batch Consumption Time: 0.22987
Total Iteration Time: 6.98631
Cumulative Model Updates: 153,884
Cumulative Timesteps: 1,221,130,354
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.18621
Policy Entropy: 4.33164
Value Function Loss: 0.00269
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03238
Policy Update Magnitude: 1.02153
Value Function Update Magnitude: 0.82013
Collected Steps per Second: 12,961.70098
Overall Steps per Second: 7,179.02094
Timestep Collection Time: 3.85767
Timestep Consumption Time: 3.10734
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.96502
Cumulative Model Updates: 153,893
Cumulative Timesteps: 1,221,180,356
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1221180356...
Checkpoint 1221180356 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.99627
Policy Entropy: 4.33128
Value Function Loss: 0.00278
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03380
Policy Update Magnitude: 1.02961
Value Function Update Magnitude: 0.82314
Collected Steps per Second: 12,851.23620
Overall Steps per Second: 7,259.64806
Timestep Collection Time: 3.89130
Timestep Consumption Time: 2.99719
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.88849
Cumulative Model Updates: 153,902
Cumulative Timesteps: 1,221,230,364
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.59683
Policy Entropy: 4.33255
Value Function Loss: 0.00288
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 1.05634
Value Function Update Magnitude: 0.85545
Collected Steps per Second: 12,850.69251
Overall Steps per Second: 7,134.45122
Timestep Collection Time: 3.89131
Timestep Consumption Time: 3.11778
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 7.00909
Cumulative Model Updates: 153,911
Cumulative Timesteps: 1,221,280,370
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1221280370...
Checkpoint 1221280370 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.73108
Policy Entropy: 4.33022
Value Function Loss: 0.00293
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03507
Policy Update Magnitude: 1.07230
Value Function Update Magnitude: 0.84799
Collected Steps per Second: 12,938.51205
Overall Steps per Second: 7,201.15097
Timestep Collection Time: 3.86443
Timestep Consumption Time: 3.07890
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.94333
Cumulative Model Updates: 153,920
Cumulative Timesteps: 1,221,330,370
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86472
Policy Entropy: 4.32879
Value Function Loss: 0.00291
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03488
Policy Update Magnitude: 1.06808
Value Function Update Magnitude: 0.83749
Collected Steps per Second: 12,897.40653
Overall Steps per Second: 7,284.72467
Timestep Collection Time: 3.87876
Timestep Consumption Time: 2.98848
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.86725
Cumulative Model Updates: 153,929
Cumulative Timesteps: 1,221,380,396
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1221380396...
Checkpoint 1221380396 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.09821
Policy Entropy: 4.32744
Value Function Loss: 0.00285
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03435
Policy Update Magnitude: 1.05991
Value Function Update Magnitude: 0.84741
Collected Steps per Second: 12,997.76313
Overall Steps per Second: 7,162.03985
Timestep Collection Time: 3.84712
Timestep Consumption Time: 3.13469
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.98181
Cumulative Model Updates: 153,938
Cumulative Timesteps: 1,221,430,400
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97229
Policy Entropy: 4.32617
Value Function Loss: 0.00277
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03421
Policy Update Magnitude: 1.04841
Value Function Update Magnitude: 0.85018
Collected Steps per Second: 12,930.48386
Overall Steps per Second: 7,130.01319
Timestep Collection Time: 3.86869
Timestep Consumption Time: 3.14729
PPO Batch Consumption Time: 0.23138
Total Iteration Time: 7.01598
Cumulative Model Updates: 153,947
Cumulative Timesteps: 1,221,480,424
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1221480424...
Checkpoint 1221480424 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.57520
Policy Entropy: 4.32807
Value Function Loss: 0.00265
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03288
Policy Update Magnitude: 1.01832
Value Function Update Magnitude: 0.83483
Collected Steps per Second: 12,961.43812
Overall Steps per Second: 7,283.00909
Timestep Collection Time: 3.86037
Timestep Consumption Time: 3.00986
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.87024
Cumulative Model Updates: 153,956
Cumulative Timesteps: 1,221,530,460
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.63529
Policy Entropy: 4.33226
Value Function Loss: 0.00259
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03260
Policy Update Magnitude: 1.00757
Value Function Update Magnitude: 0.81231
Collected Steps per Second: 13,004.90547
Overall Steps per Second: 7,182.60115
Timestep Collection Time: 3.84563
Timestep Consumption Time: 3.11731
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.96294
Cumulative Model Updates: 153,965
Cumulative Timesteps: 1,221,580,472
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1221580472...
Checkpoint 1221580472 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.20601
Policy Entropy: 4.33674
Value Function Loss: 0.00247
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03205
Policy Update Magnitude: 0.99784
Value Function Update Magnitude: 0.81158
Collected Steps per Second: 12,930.29811
Overall Steps per Second: 7,218.58150
Timestep Collection Time: 3.86859
Timestep Consumption Time: 3.06103
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.92962
Cumulative Model Updates: 153,974
Cumulative Timesteps: 1,221,630,494
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16862
Policy Entropy: 4.33900
Value Function Loss: 0.00253
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 0.98732
Value Function Update Magnitude: 0.81775
Collected Steps per Second: 12,931.23126
Overall Steps per Second: 7,280.97883
Timestep Collection Time: 3.86846
Timestep Consumption Time: 3.00204
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.87050
Cumulative Model Updates: 153,983
Cumulative Timesteps: 1,221,680,518
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1221680518...
Checkpoint 1221680518 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.14617
Policy Entropy: 4.33727
Value Function Loss: 0.00263
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03108
Policy Update Magnitude: 1.01134
Value Function Update Magnitude: 0.83619
Collected Steps per Second: 13,013.06396
Overall Steps per Second: 7,196.38096
Timestep Collection Time: 3.84506
Timestep Consumption Time: 3.10788
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.95294
Cumulative Model Updates: 153,992
Cumulative Timesteps: 1,221,730,554
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.12288
Policy Entropy: 4.33072
Value Function Loss: 0.00290
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03480
Policy Update Magnitude: 1.03684
Value Function Update Magnitude: 0.85291
Collected Steps per Second: 13,002.47445
Overall Steps per Second: 7,222.50799
Timestep Collection Time: 3.84542
Timestep Consumption Time: 3.07738
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.92280
Cumulative Model Updates: 154,001
Cumulative Timesteps: 1,221,780,554
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1221780554...
Checkpoint 1221780554 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.44066
Policy Entropy: 4.32816
Value Function Loss: 0.00292
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03463
Policy Update Magnitude: 1.03810
Value Function Update Magnitude: 0.88224
Collected Steps per Second: 12,801.91551
Overall Steps per Second: 7,149.64626
Timestep Collection Time: 3.90848
Timestep Consumption Time: 3.08991
PPO Batch Consumption Time: 0.22957
Total Iteration Time: 6.99839
Cumulative Model Updates: 154,010
Cumulative Timesteps: 1,221,830,590
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.63619
Policy Entropy: 4.32924
Value Function Loss: 0.00283
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03224
Policy Update Magnitude: 1.01158
Value Function Update Magnitude: 0.87183
Collected Steps per Second: 13,133.40285
Overall Steps per Second: 7,242.59995
Timestep Collection Time: 3.80846
Timestep Consumption Time: 3.09763
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.90608
Cumulative Model Updates: 154,019
Cumulative Timesteps: 1,221,880,608
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1221880608...
Checkpoint 1221880608 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50488
Policy Entropy: 4.33462
Value Function Loss: 0.00261
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 0.98344
Value Function Update Magnitude: 0.85724
Collected Steps per Second: 12,741.92376
Overall Steps per Second: 7,157.46275
Timestep Collection Time: 3.92672
Timestep Consumption Time: 3.06374
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.99047
Cumulative Model Updates: 154,028
Cumulative Timesteps: 1,221,930,642
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27344
Policy Entropy: 4.33534
Value Function Loss: 0.00258
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02902
Policy Update Magnitude: 0.97942
Value Function Update Magnitude: 0.84612
Collected Steps per Second: 12,940.91387
Overall Steps per Second: 7,278.22476
Timestep Collection Time: 3.86541
Timestep Consumption Time: 3.00742
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.87283
Cumulative Model Updates: 154,037
Cumulative Timesteps: 1,221,980,664
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1221980664...
Checkpoint 1221980664 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.20628
Policy Entropy: 4.33806
Value Function Loss: 0.00250
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03017
Policy Update Magnitude: 0.98081
Value Function Update Magnitude: 0.84536
Collected Steps per Second: 12,904.99959
Overall Steps per Second: 7,165.38499
Timestep Collection Time: 3.87509
Timestep Consumption Time: 3.10402
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.97911
Cumulative Model Updates: 154,046
Cumulative Timesteps: 1,222,030,672
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.35770
Policy Entropy: 4.33937
Value Function Loss: 0.00256
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02976
Policy Update Magnitude: 0.98519
Value Function Update Magnitude: 0.84491
Collected Steps per Second: 12,990.96635
Overall Steps per Second: 7,243.99337
Timestep Collection Time: 3.84975
Timestep Consumption Time: 3.05417
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.90393
Cumulative Model Updates: 154,055
Cumulative Timesteps: 1,222,080,684
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1222080684...
Checkpoint 1222080684 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.79307
Policy Entropy: 4.33785
Value Function Loss: 0.00255
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.99281
Value Function Update Magnitude: 0.83782
Collected Steps per Second: 12,850.76095
Overall Steps per Second: 7,250.80022
Timestep Collection Time: 3.89378
Timestep Consumption Time: 3.00725
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.90103
Cumulative Model Updates: 154,064
Cumulative Timesteps: 1,222,130,722
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.79627
Policy Entropy: 4.33495
Value Function Loss: 0.00261
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03134
Policy Update Magnitude: 0.98841
Value Function Update Magnitude: 0.78841
Collected Steps per Second: 13,028.62681
Overall Steps per Second: 7,136.80383
Timestep Collection Time: 3.83985
Timestep Consumption Time: 3.17001
PPO Batch Consumption Time: 0.23004
Total Iteration Time: 7.00986
Cumulative Model Updates: 154,073
Cumulative Timesteps: 1,222,180,750
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1222180750...
Checkpoint 1222180750 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.44644
Policy Entropy: 4.33568
Value Function Loss: 0.00262
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03074
Policy Update Magnitude: 0.98412
Value Function Update Magnitude: 0.79483
Collected Steps per Second: 13,111.98273
Overall Steps per Second: 7,276.48254
Timestep Collection Time: 3.81559
Timestep Consumption Time: 3.05998
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.87557
Cumulative Model Updates: 154,082
Cumulative Timesteps: 1,222,230,780
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11044
Policy Entropy: 4.34166
Value Function Loss: 0.00256
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 0.98688
Value Function Update Magnitude: 0.82062
Collected Steps per Second: 12,973.31616
Overall Steps per Second: 7,289.12802
Timestep Collection Time: 3.85453
Timestep Consumption Time: 3.00583
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.86035
Cumulative Model Updates: 154,091
Cumulative Timesteps: 1,222,280,786
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1222280786...
Checkpoint 1222280786 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83861
Policy Entropy: 4.34405
Value Function Loss: 0.00262
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03006
Policy Update Magnitude: 0.99595
Value Function Update Magnitude: 0.85290
Collected Steps per Second: 12,951.09576
Overall Steps per Second: 7,182.41927
Timestep Collection Time: 3.86129
Timestep Consumption Time: 3.10126
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.96256
Cumulative Model Updates: 154,100
Cumulative Timesteps: 1,222,330,794
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.49662
Policy Entropy: 4.34322
Value Function Loss: 0.00265
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 1.01126
Value Function Update Magnitude: 0.87288
Collected Steps per Second: 12,826.04213
Overall Steps per Second: 7,137.77025
Timestep Collection Time: 3.90066
Timestep Consumption Time: 3.10853
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 7.00919
Cumulative Model Updates: 154,109
Cumulative Timesteps: 1,222,380,824
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1222380824...
Checkpoint 1222380824 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28983
Policy Entropy: 4.33793
Value Function Loss: 0.00267
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03086
Policy Update Magnitude: 1.01719
Value Function Update Magnitude: 0.84078
Collected Steps per Second: 12,946.57390
Overall Steps per Second: 7,268.75214
Timestep Collection Time: 3.86295
Timestep Consumption Time: 3.01746
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.88041
Cumulative Model Updates: 154,118
Cumulative Timesteps: 1,222,430,836
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77458
Policy Entropy: 4.33845
Value Function Loss: 0.00263
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03351
Policy Update Magnitude: 1.02289
Value Function Update Magnitude: 0.85558
Collected Steps per Second: 12,999.35255
Overall Steps per Second: 7,201.15975
Timestep Collection Time: 3.84804
Timestep Consumption Time: 3.09834
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.94638
Cumulative Model Updates: 154,127
Cumulative Timesteps: 1,222,480,858
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1222480858...
Checkpoint 1222480858 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.54471
Policy Entropy: 4.33944
Value Function Loss: 0.00258
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03524
Policy Update Magnitude: 1.01072
Value Function Update Magnitude: 0.83903
Collected Steps per Second: 12,970.43172
Overall Steps per Second: 7,116.12066
Timestep Collection Time: 3.85492
Timestep Consumption Time: 3.17138
PPO Batch Consumption Time: 0.22985
Total Iteration Time: 7.02630
Cumulative Model Updates: 154,136
Cumulative Timesteps: 1,222,530,858
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.74077
Policy Entropy: 4.33909
Value Function Loss: 0.00274
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03225
Policy Update Magnitude: 1.03110
Value Function Update Magnitude: 0.82726
Collected Steps per Second: 12,918.70863
Overall Steps per Second: 7,263.32028
Timestep Collection Time: 3.87376
Timestep Consumption Time: 3.01620
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.88996
Cumulative Model Updates: 154,145
Cumulative Timesteps: 1,222,580,902
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1222580902...
Checkpoint 1222580902 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.15550
Policy Entropy: 4.34000
Value Function Loss: 0.00271
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03222
Policy Update Magnitude: 1.04266
Value Function Update Magnitude: 0.81569
Collected Steps per Second: 12,900.13069
Overall Steps per Second: 7,158.03136
Timestep Collection Time: 3.87624
Timestep Consumption Time: 3.10948
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.98572
Cumulative Model Updates: 154,154
Cumulative Timesteps: 1,222,630,906
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.90177
Policy Entropy: 4.34074
Value Function Loss: 0.00263
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 1.01923
Value Function Update Magnitude: 0.79191
Collected Steps per Second: 12,943.21089
Overall Steps per Second: 7,140.48126
Timestep Collection Time: 3.86612
Timestep Consumption Time: 3.14181
PPO Batch Consumption Time: 0.22952
Total Iteration Time: 7.00793
Cumulative Model Updates: 154,163
Cumulative Timesteps: 1,222,680,946
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1222680946...
Checkpoint 1222680946 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.71745
Policy Entropy: 4.34374
Value Function Loss: 0.00245
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02979
Policy Update Magnitude: 0.98741
Value Function Update Magnitude: 0.77728
Collected Steps per Second: 12,846.76079
Overall Steps per Second: 7,259.42048
Timestep Collection Time: 3.89437
Timestep Consumption Time: 2.99737
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.89173
Cumulative Model Updates: 154,172
Cumulative Timesteps: 1,222,730,976
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.73847
Policy Entropy: 4.34367
Value Function Loss: 0.00251
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 0.99646
Value Function Update Magnitude: 0.75919
Collected Steps per Second: 12,917.60768
Overall Steps per Second: 7,172.80749
Timestep Collection Time: 3.87208
Timestep Consumption Time: 3.10120
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.97328
Cumulative Model Updates: 154,181
Cumulative Timesteps: 1,222,780,994
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1222780994...
Checkpoint 1222780994 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.96982
Policy Entropy: 4.34353
Value Function Loss: 0.00258
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03115
Policy Update Magnitude: 1.00763
Value Function Update Magnitude: 0.76087
Collected Steps per Second: 12,791.81357
Overall Steps per Second: 7,118.28438
Timestep Collection Time: 3.90938
Timestep Consumption Time: 3.11591
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 7.02529
Cumulative Model Updates: 154,190
Cumulative Timesteps: 1,222,831,002
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.80660
Policy Entropy: 4.34299
Value Function Loss: 0.00263
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.99516
Value Function Update Magnitude: 0.81359
Collected Steps per Second: 12,956.90456
Overall Steps per Second: 7,128.27406
Timestep Collection Time: 3.85926
Timestep Consumption Time: 3.15563
PPO Batch Consumption Time: 0.24027
Total Iteration Time: 7.01488
Cumulative Model Updates: 154,199
Cumulative Timesteps: 1,222,881,006
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1222881006...
Checkpoint 1222881006 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.34159
Policy Entropy: 4.34383
Value Function Loss: 0.00259
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03026
Policy Update Magnitude: 0.99843
Value Function Update Magnitude: 0.83676
Collected Steps per Second: 13,132.41679
Overall Steps per Second: 7,223.30663
Timestep Collection Time: 3.81057
Timestep Consumption Time: 3.11728
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.92785
Cumulative Model Updates: 154,208
Cumulative Timesteps: 1,222,931,048
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.96819
Policy Entropy: 4.33795
Value Function Loss: 0.00270
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 1.00865
Value Function Update Magnitude: 0.83773
Collected Steps per Second: 13,063.98088
Overall Steps per Second: 7,243.57060
Timestep Collection Time: 3.83145
Timestep Consumption Time: 3.07868
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.91013
Cumulative Model Updates: 154,217
Cumulative Timesteps: 1,222,981,102
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1222981102...
Checkpoint 1222981102 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53628
Policy Entropy: 4.33359
Value Function Loss: 0.00273
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03398
Policy Update Magnitude: 1.03258
Value Function Update Magnitude: 0.87088
Collected Steps per Second: 12,909.07057
Overall Steps per Second: 7,274.67546
Timestep Collection Time: 3.87356
Timestep Consumption Time: 3.00015
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.87371
Cumulative Model Updates: 154,226
Cumulative Timesteps: 1,223,031,106
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.69589
Policy Entropy: 4.32791
Value Function Loss: 0.00273
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03556
Policy Update Magnitude: 1.03304
Value Function Update Magnitude: 0.88622
Collected Steps per Second: 13,108.44062
Overall Steps per Second: 7,228.59446
Timestep Collection Time: 3.81510
Timestep Consumption Time: 3.10326
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.91836
Cumulative Model Updates: 154,235
Cumulative Timesteps: 1,223,081,116
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1223081116...
Checkpoint 1223081116 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.53367
Policy Entropy: 4.32716
Value Function Loss: 0.00274
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03406
Policy Update Magnitude: 1.03484
Value Function Update Magnitude: 0.88878
Collected Steps per Second: 12,766.35465
Overall Steps per Second: 7,174.16646
Timestep Collection Time: 3.91780
Timestep Consumption Time: 3.05388
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.97168
Cumulative Model Updates: 154,244
Cumulative Timesteps: 1,223,131,132
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.34168
Policy Entropy: 4.33042
Value Function Loss: 0.00265
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03258
Policy Update Magnitude: 1.01957
Value Function Update Magnitude: 0.87924
Collected Steps per Second: 12,937.60535
Overall Steps per Second: 7,280.74019
Timestep Collection Time: 3.86640
Timestep Consumption Time: 3.00405
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.87046
Cumulative Model Updates: 154,253
Cumulative Timesteps: 1,223,181,154
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1223181154...
Checkpoint 1223181154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21227
Policy Entropy: 4.33464
Value Function Loss: 0.00261
Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 1.00619
Value Function Update Magnitude: 0.85714
Collected Steps per Second: 12,805.25768
Overall Steps per Second: 7,021.58682
Timestep Collection Time: 3.90511
Timestep Consumption Time: 3.21664
PPO Batch Consumption Time: 0.23759
Total Iteration Time: 7.12175
Cumulative Model Updates: 154,262
Cumulative Timesteps: 1,223,231,160
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.61394
Policy Entropy: 4.33452
Value Function Loss: 0.00254
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02863
Policy Update Magnitude: 0.99976
Value Function Update Magnitude: 0.85250
Collected Steps per Second: 13,031.59864
Overall Steps per Second: 7,224.25455
Timestep Collection Time: 3.83913
Timestep Consumption Time: 3.08615
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.92528
Cumulative Model Updates: 154,271
Cumulative Timesteps: 1,223,281,190
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1223281190...
Checkpoint 1223281190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.62866
Policy Entropy: 4.33082
Value Function Loss: 0.00246
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03166
Policy Update Magnitude: 0.97892
Value Function Update Magnitude: 0.85620
Collected Steps per Second: 12,854.70314
Overall Steps per Second: 7,217.55714
Timestep Collection Time: 3.89243
Timestep Consumption Time: 3.04011
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.93254
Cumulative Model Updates: 154,280
Cumulative Timesteps: 1,223,331,226
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74878
Policy Entropy: 4.33286
Value Function Loss: 0.00234
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03017
Policy Update Magnitude: 0.95797
Value Function Update Magnitude: 0.86327
Collected Steps per Second: 12,962.50997
Overall Steps per Second: 7,180.03521
Timestep Collection Time: 3.85990
Timestep Consumption Time: 3.10859
PPO Batch Consumption Time: 0.22933
Total Iteration Time: 6.96849
Cumulative Model Updates: 154,289
Cumulative Timesteps: 1,223,381,260
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1223381260...
Checkpoint 1223381260 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.93203
Policy Entropy: 4.33624
Value Function Loss: 0.00226
Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02932
Policy Update Magnitude: 0.95356
Value Function Update Magnitude: 0.83071
Collected Steps per Second: 12,946.73630
Overall Steps per Second: 7,189.96190
Timestep Collection Time: 3.86321
Timestep Consumption Time: 3.09315
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.95637
Cumulative Model Updates: 154,298
Cumulative Timesteps: 1,223,431,276
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.22981
Policy Entropy: 4.33776
Value Function Loss: 0.00238
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02934
Policy Update Magnitude: 0.97105
Value Function Update Magnitude: 0.78778
Collected Steps per Second: 12,804.25662
Overall Steps per Second: 7,249.22612
Timestep Collection Time: 3.90604
Timestep Consumption Time: 2.99317
PPO Batch Consumption Time: 0.22899
Total Iteration Time: 6.89922
Cumulative Model Updates: 154,307
Cumulative Timesteps: 1,223,481,290
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1223481290...
Checkpoint 1223481290 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07888
Policy Entropy: 4.33318
Value Function Loss: 0.00258
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03297
Policy Update Magnitude: 0.99218
Value Function Update Magnitude: 0.78530
Collected Steps per Second: 13,008.88192
Overall Steps per Second: 7,186.78568
Timestep Collection Time: 3.84445
Timestep Consumption Time: 3.11443
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.95888
Cumulative Model Updates: 154,316
Cumulative Timesteps: 1,223,531,302
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44975
Policy Entropy: 4.33335
Value Function Loss: 0.00265
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 1.00696
Value Function Update Magnitude: 0.79321
Collected Steps per Second: 12,945.64336
Overall Steps per Second: 7,169.65599
Timestep Collection Time: 3.86462
Timestep Consumption Time: 3.11340
PPO Batch Consumption Time: 0.23009
Total Iteration Time: 6.97802
Cumulative Model Updates: 154,325
Cumulative Timesteps: 1,223,581,332
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1223581332...
Checkpoint 1223581332 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89940
Policy Entropy: 4.33114
Value Function Loss: 0.00261
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03128
Policy Update Magnitude: 1.00759
Value Function Update Magnitude: 0.79804
Collected Steps per Second: 12,982.09654
Overall Steps per Second: 7,294.36557
Timestep Collection Time: 3.85269
Timestep Consumption Time: 3.00411
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.85680
Cumulative Model Updates: 154,334
Cumulative Timesteps: 1,223,631,348
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03457
Policy Entropy: 4.33354
Value Function Loss: 0.00263
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02935
Policy Update Magnitude: 1.00780
Value Function Update Magnitude: 0.79521
Collected Steps per Second: 13,069.93410
Overall Steps per Second: 7,218.24093
Timestep Collection Time: 3.82695
Timestep Consumption Time: 3.10244
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.92939
Cumulative Model Updates: 154,343
Cumulative Timesteps: 1,223,681,366
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1223681366...
Checkpoint 1223681366 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.37329
Policy Entropy: 4.32821
Value Function Loss: 0.00272
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03186
Policy Update Magnitude: 1.01823
Value Function Update Magnitude: 0.80237
Collected Steps per Second: 12,892.94115
Overall Steps per Second: 7,183.08372
Timestep Collection Time: 3.88088
Timestep Consumption Time: 3.08493
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.96581
Cumulative Model Updates: 154,352
Cumulative Timesteps: 1,223,731,402
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.48131
Policy Entropy: 4.32899
Value Function Loss: 0.00274
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 1.01765
Value Function Update Magnitude: 0.83215
Collected Steps per Second: 13,256.36551
Overall Steps per Second: 7,286.11665
Timestep Collection Time: 3.77223
Timestep Consumption Time: 3.09096
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.86319
Cumulative Model Updates: 154,361
Cumulative Timesteps: 1,223,781,408
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1223781408...
Checkpoint 1223781408 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.78525
Policy Entropy: 4.33126
Value Function Loss: 0.00266
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03300
Policy Update Magnitude: 1.01559
Value Function Update Magnitude: 0.83346
Collected Steps per Second: 12,951.51611
Overall Steps per Second: 7,141.60847
Timestep Collection Time: 3.86271
Timestep Consumption Time: 3.14243
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 7.00514
Cumulative Model Updates: 154,370
Cumulative Timesteps: 1,223,831,436
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.33958
Policy Entropy: 4.33328
Value Function Loss: 0.00273
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02996
Policy Update Magnitude: 1.02882
Value Function Update Magnitude: 0.84794
Collected Steps per Second: 13,011.31114
Overall Steps per Second: 7,212.52133
Timestep Collection Time: 3.84327
Timestep Consumption Time: 3.08995
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.93322
Cumulative Model Updates: 154,379
Cumulative Timesteps: 1,223,881,442
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1223881442...
Checkpoint 1223881442 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.57740
Policy Entropy: 4.33302
Value Function Loss: 0.00267
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03104
Policy Update Magnitude: 1.02874
Value Function Update Magnitude: 0.86521
Collected Steps per Second: 12,954.38931
Overall Steps per Second: 7,125.88729
Timestep Collection Time: 3.86278
Timestep Consumption Time: 3.15950
PPO Batch Consumption Time: 0.24023
Total Iteration Time: 7.02228
Cumulative Model Updates: 154,388
Cumulative Timesteps: 1,223,931,482
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.21729
Policy Entropy: 4.33542
Value Function Loss: 0.00265
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03217
Policy Update Magnitude: 1.02367
Value Function Update Magnitude: 0.82808
Collected Steps per Second: 12,973.51152
Overall Steps per Second: 7,183.49404
Timestep Collection Time: 3.85663
Timestep Consumption Time: 3.10851
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.96513
Cumulative Model Updates: 154,397
Cumulative Timesteps: 1,223,981,516
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1223981516...
Checkpoint 1223981516 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.35051
Policy Entropy: 4.33639
Value Function Loss: 0.00262
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03068
Policy Update Magnitude: 1.02153
Value Function Update Magnitude: 0.81419
Collected Steps per Second: 13,021.58416
Overall Steps per Second: 7,246.24901
Timestep Collection Time: 3.84300
Timestep Consumption Time: 3.06291
PPO Batch Consumption Time: 0.22918
Total Iteration Time: 6.90592
Cumulative Model Updates: 154,406
Cumulative Timesteps: 1,224,031,558
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10841
Policy Entropy: 4.33194
Value Function Loss: 0.00265
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03305
Policy Update Magnitude: 1.01128
Value Function Update Magnitude: 0.79152
Collected Steps per Second: 12,932.05788
Overall Steps per Second: 7,285.15080
Timestep Collection Time: 3.86729
Timestep Consumption Time: 2.99763
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.86492
Cumulative Model Updates: 154,415
Cumulative Timesteps: 1,224,081,570
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1224081570...
Checkpoint 1224081570 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35686
Policy Entropy: 4.32762
Value Function Loss: 0.00272
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03506
Policy Update Magnitude: 1.02730
Value Function Update Magnitude: 0.78873
Collected Steps per Second: 13,064.93164
Overall Steps per Second: 7,222.90264
Timestep Collection Time: 3.82933
Timestep Consumption Time: 3.09724
PPO Batch Consumption Time: 0.22914
Total Iteration Time: 6.92658
Cumulative Model Updates: 154,424
Cumulative Timesteps: 1,224,131,600
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.48052
Policy Entropy: 4.32469
Value Function Loss: 0.00276
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 1.03394
Value Function Update Magnitude: 0.82865
Collected Steps per Second: 13,185.60757
Overall Steps per Second: 7,276.79770
Timestep Collection Time: 3.79323
Timestep Consumption Time: 3.08013
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.87335
Cumulative Model Updates: 154,433
Cumulative Timesteps: 1,224,181,616
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1224181616...
Checkpoint 1224181616 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.24210
Policy Entropy: 4.32644
Value Function Loss: 0.00271
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 1.02279
Value Function Update Magnitude: 0.85630
Collected Steps per Second: 12,939.54375
Overall Steps per Second: 7,267.09843
Timestep Collection Time: 3.86845
Timestep Consumption Time: 3.01958
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.88803
Cumulative Model Updates: 154,442
Cumulative Timesteps: 1,224,231,672
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.25516
Policy Entropy: 4.32289
Value Function Loss: 0.00277
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 1.02534
Value Function Update Magnitude: 0.86545
Collected Steps per Second: 13,116.41955
Overall Steps per Second: 7,175.35845
Timestep Collection Time: 3.81446
Timestep Consumption Time: 3.15830
PPO Batch Consumption Time: 0.23015
Total Iteration Time: 6.97275
Cumulative Model Updates: 154,451
Cumulative Timesteps: 1,224,281,704
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1224281704...
Checkpoint 1224281704 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.35534
Policy Entropy: 4.32656
Value Function Loss: 0.00280
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03559
Policy Update Magnitude: 1.03728
Value Function Update Magnitude: 0.86454
Collected Steps per Second: 12,911.21389
Overall Steps per Second: 7,196.58229
Timestep Collection Time: 3.87400
Timestep Consumption Time: 3.07625
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.95024
Cumulative Model Updates: 154,460
Cumulative Timesteps: 1,224,331,722
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40344
Policy Entropy: 4.32717
Value Function Loss: 0.00291
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03600
Policy Update Magnitude: 1.03879
Value Function Update Magnitude: 0.87445
Collected Steps per Second: 13,263.59266
Overall Steps per Second: 7,266.27524
Timestep Collection Time: 3.76972
Timestep Consumption Time: 3.11139
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.88110
Cumulative Model Updates: 154,469
Cumulative Timesteps: 1,224,381,722
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1224381722...
Checkpoint 1224381722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.66499
Policy Entropy: 4.33112
Value Function Loss: 0.00270
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03246
Policy Update Magnitude: 1.00803
Value Function Update Magnitude: 0.86058
Collected Steps per Second: 12,969.77222
Overall Steps per Second: 7,183.18062
Timestep Collection Time: 3.85774
Timestep Consumption Time: 3.10770
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.96544
Cumulative Model Updates: 154,478
Cumulative Timesteps: 1,224,431,756
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.13490
Policy Entropy: 4.33514
Value Function Loss: 0.00257
Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.99174
Value Function Update Magnitude: 0.84406
Collected Steps per Second: 12,944.39693
Overall Steps per Second: 7,189.71356
Timestep Collection Time: 3.86437
Timestep Consumption Time: 3.09307
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.95744
Cumulative Model Updates: 154,487
Cumulative Timesteps: 1,224,481,778
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1224481778...
Checkpoint 1224481778 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.16229
Policy Entropy: 4.33725
Value Function Loss: 0.00257
Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.98649
Value Function Update Magnitude: 0.80951
Collected Steps per Second: 13,206.06833
Overall Steps per Second: 7,263.66905
Timestep Collection Time: 3.78674
Timestep Consumption Time: 3.09793
PPO Batch Consumption Time: 0.22942
Total Iteration Time: 6.88467
Cumulative Model Updates: 154,496
Cumulative Timesteps: 1,224,531,786
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.61018
Policy Entropy: 4.34104
Value Function Loss: 0.00264
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02911
Policy Update Magnitude: 0.98678
Value Function Update Magnitude: 0.83258
Collected Steps per Second: 13,004.07662
Overall Steps per Second: 7,216.13121
Timestep Collection Time: 3.84664
Timestep Consumption Time: 3.08533
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.93197
Cumulative Model Updates: 154,505
Cumulative Timesteps: 1,224,581,808
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1224581808...
Checkpoint 1224581808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95102
Policy Entropy: 4.34115
Value Function Loss: 0.00263
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03009
Policy Update Magnitude: 0.99743
Value Function Update Magnitude: 0.85144
Collected Steps per Second: 12,938.18825
Overall Steps per Second: 7,150.09341
Timestep Collection Time: 3.86793
Timestep Consumption Time: 3.13114
PPO Batch Consumption Time: 0.22958
Total Iteration Time: 6.99907
Cumulative Model Updates: 154,514
Cumulative Timesteps: 1,224,631,852
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.47954
Policy Entropy: 4.33629
Value Function Loss: 0.00273
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 1.01669
Value Function Update Magnitude: 0.83386
Collected Steps per Second: 12,691.05846
Overall Steps per Second: 7,210.04745
Timestep Collection Time: 3.94356
Timestep Consumption Time: 2.99786
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.94142
Cumulative Model Updates: 154,523
Cumulative Timesteps: 1,224,681,900
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1224681900...
Checkpoint 1224681900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.20968
Policy Entropy: 4.33741
Value Function Loss: 0.00276
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03173
Policy Update Magnitude: 1.03746
Value Function Update Magnitude: 0.84552
Collected Steps per Second: 12,895.86412
Overall Steps per Second: 7,175.15491
Timestep Collection Time: 3.87814
Timestep Consumption Time: 3.09202
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.97016
Cumulative Model Updates: 154,532
Cumulative Timesteps: 1,224,731,912
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.37524
Policy Entropy: 4.33707
Value Function Loss: 0.00294
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03183
Policy Update Magnitude: 1.05131
Value Function Update Magnitude: 0.87135
Collected Steps per Second: 12,939.47156
Overall Steps per Second: 7,222.13095
Timestep Collection Time: 3.86523
Timestep Consumption Time: 3.05988
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.92510
Cumulative Model Updates: 154,541
Cumulative Timesteps: 1,224,781,926
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1224781926...
Checkpoint 1224781926 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.15407
Policy Entropy: 4.34201
Value Function Loss: 0.00278
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03206
Policy Update Magnitude: 1.04941
Value Function Update Magnitude: 0.86718
Collected Steps per Second: 12,941.36806
Overall Steps per Second: 7,264.51935
Timestep Collection Time: 3.86621
Timestep Consumption Time: 3.02124
PPO Batch Consumption Time: 0.22939
Total Iteration Time: 6.88745
Cumulative Model Updates: 154,550
Cumulative Timesteps: 1,224,831,960
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28888
Policy Entropy: 4.34335
Value Function Loss: 0.00274
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 1.03298
Value Function Update Magnitude: 0.85643
Collected Steps per Second: 12,994.54020
Overall Steps per Second: 7,177.86913
Timestep Collection Time: 3.84992
Timestep Consumption Time: 3.11983
PPO Batch Consumption Time: 0.22962
Total Iteration Time: 6.96976
Cumulative Model Updates: 154,559
Cumulative Timesteps: 1,224,881,988
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1224881988...
Checkpoint 1224881988 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.54130
Policy Entropy: 4.34536
Value Function Loss: 0.00267
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 1.02574
Value Function Update Magnitude: 0.84404
Collected Steps per Second: 12,918.28353
Overall Steps per Second: 7,185.40227
Timestep Collection Time: 3.87250
Timestep Consumption Time: 3.08968
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.96217
Cumulative Model Updates: 154,568
Cumulative Timesteps: 1,224,932,014
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.82766
Policy Entropy: 4.34006
Value Function Loss: 0.00267
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 1.01570
Value Function Update Magnitude: 0.84269
Collected Steps per Second: 12,877.17175
Overall Steps per Second: 7,196.65321
Timestep Collection Time: 3.88408
Timestep Consumption Time: 3.06581
PPO Batch Consumption Time: 0.22992
Total Iteration Time: 6.94990
Cumulative Model Updates: 154,577
Cumulative Timesteps: 1,224,982,030
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1224982030...
Checkpoint 1224982030 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41770
Policy Entropy: 4.33539
Value Function Loss: 0.00272
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 1.01891
Value Function Update Magnitude: 0.82269
Collected Steps per Second: 12,948.79898
Overall Steps per Second: 7,187.90164
Timestep Collection Time: 3.86399
Timestep Consumption Time: 3.09688
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.96086
Cumulative Model Updates: 154,586
Cumulative Timesteps: 1,225,032,064
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25727
Policy Entropy: 4.32896
Value Function Loss: 0.00284
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03239
Policy Update Magnitude: 1.03680
Value Function Update Magnitude: 0.81203
Collected Steps per Second: 12,986.14211
Overall Steps per Second: 7,219.81137
Timestep Collection Time: 3.85041
Timestep Consumption Time: 3.07525
PPO Batch Consumption Time: 0.22931
Total Iteration Time: 6.92567
Cumulative Model Updates: 154,595
Cumulative Timesteps: 1,225,082,066
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1225082066...
Checkpoint 1225082066 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90390
Policy Entropy: 4.33187
Value Function Loss: 0.00286
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 1.05870
Value Function Update Magnitude: 0.82099
Collected Steps per Second: 12,948.12171
Overall Steps per Second: 7,275.36313
Timestep Collection Time: 3.86218
Timestep Consumption Time: 3.01143
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.87361
Cumulative Model Updates: 154,604
Cumulative Timesteps: 1,225,132,074
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.92579
Policy Entropy: 4.33057
Value Function Loss: 0.00288
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03640
Policy Update Magnitude: 1.04378
Value Function Update Magnitude: 0.79435
Collected Steps per Second: 13,049.48988
Overall Steps per Second: 7,202.94742
Timestep Collection Time: 3.83157
Timestep Consumption Time: 3.11004
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.94160
Cumulative Model Updates: 154,613
Cumulative Timesteps: 1,225,182,074
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1225182074...
Checkpoint 1225182074 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.42494
Policy Entropy: 4.32905
Value Function Loss: 0.00292
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 1.05399
Value Function Update Magnitude: 0.81233
Collected Steps per Second: 12,907.32169
Overall Steps per Second: 7,227.03232
Timestep Collection Time: 3.87485
Timestep Consumption Time: 3.04555
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.92041
Cumulative Model Updates: 154,622
Cumulative Timesteps: 1,225,232,088
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.03608
Policy Entropy: 4.33065
Value Function Loss: 0.00282
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03482
Policy Update Magnitude: 1.03947
Value Function Update Magnitude: 0.83084
Collected Steps per Second: 12,898.93760
Overall Steps per Second: 7,265.12129
Timestep Collection Time: 3.87830
Timestep Consumption Time: 3.00747
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.88578
Cumulative Model Updates: 154,631
Cumulative Timesteps: 1,225,282,114
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1225282114...
Checkpoint 1225282114 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.08933
Policy Entropy: 4.33251
Value Function Loss: 0.00284
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03201
Policy Update Magnitude: 1.00927
Value Function Update Magnitude: 0.85262
Collected Steps per Second: 12,831.57415
Overall Steps per Second: 7,100.40931
Timestep Collection Time: 3.89820
Timestep Consumption Time: 3.14647
PPO Batch Consumption Time: 0.23015
Total Iteration Time: 7.04466
Cumulative Model Updates: 154,640
Cumulative Timesteps: 1,225,332,134
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.00349
Policy Entropy: 4.34019
Value Function Loss: 0.00271
Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02924
Policy Update Magnitude: 1.01238
Value Function Update Magnitude: 0.87010
Collected Steps per Second: 13,034.16717
Overall Steps per Second: 7,239.74822
Timestep Collection Time: 3.83745
Timestep Consumption Time: 3.07135
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.90880
Cumulative Model Updates: 154,649
Cumulative Timesteps: 1,225,382,152
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1225382152...
Checkpoint 1225382152 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.85164
Policy Entropy: 4.33701
Value Function Loss: 0.00281
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03114
Policy Update Magnitude: 1.02422
Value Function Update Magnitude: 0.87890
Collected Steps per Second: 12,840.57869
Overall Steps per Second: 7,246.74545
Timestep Collection Time: 3.89391
Timestep Consumption Time: 3.00574
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.89965
Cumulative Model Updates: 154,658
Cumulative Timesteps: 1,225,432,152
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.32076
Policy Entropy: 4.33643
Value Function Loss: 0.00280
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03156
Policy Update Magnitude: 1.02365
Value Function Update Magnitude: 0.87999
Collected Steps per Second: 13,026.63527
Overall Steps per Second: 7,196.73157
Timestep Collection Time: 3.83829
Timestep Consumption Time: 3.10931
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.94760
Cumulative Model Updates: 154,667
Cumulative Timesteps: 1,225,482,152
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1225482152...
Checkpoint 1225482152 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32302
Policy Entropy: 4.33657
Value Function Loss: 0.00278
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 1.01395
Value Function Update Magnitude: 0.87864
Collected Steps per Second: 12,970.80855
Overall Steps per Second: 7,223.51353
Timestep Collection Time: 3.85496
Timestep Consumption Time: 3.06715
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.92212
Cumulative Model Updates: 154,676
Cumulative Timesteps: 1,225,532,154
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.60582
Policy Entropy: 4.33736
Value Function Loss: 0.00288
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03321
Policy Update Magnitude: 1.02465
Value Function Update Magnitude: 0.87440
Collected Steps per Second: 13,028.54855
Overall Steps per Second: 7,302.21037
Timestep Collection Time: 3.84049
Timestep Consumption Time: 3.01168
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.85217
Cumulative Model Updates: 154,685
Cumulative Timesteps: 1,225,582,190
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1225582190...
Checkpoint 1225582190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90212
Policy Entropy: 4.34154
Value Function Loss: 0.00279
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03070
Policy Update Magnitude: 1.03943
Value Function Update Magnitude: 0.91208
Collected Steps per Second: 13,047.67088
Overall Steps per Second: 7,171.04005
Timestep Collection Time: 3.83271
Timestep Consumption Time: 3.14089
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.97360
Cumulative Model Updates: 154,694
Cumulative Timesteps: 1,225,632,198
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.37117
Policy Entropy: 4.34084
Value Function Loss: 0.00279
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 1.02691
Value Function Update Magnitude: 0.87408
Collected Steps per Second: 12,856.61534
Overall Steps per Second: 6,996.73982
Timestep Collection Time: 3.88967
Timestep Consumption Time: 3.25766
PPO Batch Consumption Time: 0.24113
Total Iteration Time: 7.14733
Cumulative Model Updates: 154,703
Cumulative Timesteps: 1,225,682,206
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1225682206...
Checkpoint 1225682206 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.55764
Policy Entropy: 4.33816
Value Function Loss: 0.00269
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03132
Policy Update Magnitude: 1.02189
Value Function Update Magnitude: 0.84906
Collected Steps per Second: 12,966.86161
Overall Steps per Second: 7,280.60590
Timestep Collection Time: 3.85614
Timestep Consumption Time: 3.01170
PPO Batch Consumption Time: 0.22930
Total Iteration Time: 6.86784
Cumulative Model Updates: 154,712
Cumulative Timesteps: 1,225,732,208
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12008
Policy Entropy: 4.33316
Value Function Loss: 0.00274
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03247
Policy Update Magnitude: 1.03103
Value Function Update Magnitude: 0.84714
Collected Steps per Second: 13,078.34438
Overall Steps per Second: 7,203.65732
Timestep Collection Time: 3.82633
Timestep Consumption Time: 3.12042
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.94675
Cumulative Model Updates: 154,721
Cumulative Timesteps: 1,225,782,250
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1225782250...
Checkpoint 1225782250 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.35834
Policy Entropy: 4.32849
Value Function Loss: 0.00270
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03311
Policy Update Magnitude: 1.01554
Value Function Update Magnitude: 0.82762
Collected Steps per Second: 13,002.27398
Overall Steps per Second: 7,249.40783
Timestep Collection Time: 3.84717
Timestep Consumption Time: 3.05298
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.90015
Cumulative Model Updates: 154,730
Cumulative Timesteps: 1,225,832,272
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.37944
Policy Entropy: 4.32709
Value Function Loss: 0.00264
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03393
Policy Update Magnitude: 1.00362
Value Function Update Magnitude: 0.82394
Collected Steps per Second: 13,020.20778
Overall Steps per Second: 7,312.43192
Timestep Collection Time: 3.84034
Timestep Consumption Time: 2.99761
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.83794
Cumulative Model Updates: 154,739
Cumulative Timesteps: 1,225,882,274
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1225882274...
Checkpoint 1225882274 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49182
Policy Entropy: 4.32810
Value Function Loss: 0.00261
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 0.99466
Value Function Update Magnitude: 0.86079
Collected Steps per Second: 13,070.47960
Overall Steps per Second: 7,217.02193
Timestep Collection Time: 3.82603
Timestep Consumption Time: 3.10315
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.92917
Cumulative Model Updates: 154,748
Cumulative Timesteps: 1,225,932,282
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.83991
Policy Entropy: 4.32855
Value Function Loss: 0.00251
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02989
Policy Update Magnitude: 0.97898
Value Function Update Magnitude: 0.86271
Collected Steps per Second: 13,079.96302
Overall Steps per Second: 7,256.26387
Timestep Collection Time: 3.82600
Timestep Consumption Time: 3.07066
PPO Batch Consumption Time: 0.22797
Total Iteration Time: 6.89666
Cumulative Model Updates: 154,757
Cumulative Timesteps: 1,225,982,326
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1225982326...
Checkpoint 1225982326 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.47900
Policy Entropy: 4.32892
Value Function Loss: 0.00253
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.97392
Value Function Update Magnitude: 0.86193
Collected Steps per Second: 12,782.90126
Overall Steps per Second: 7,179.51013
Timestep Collection Time: 3.91492
Timestep Consumption Time: 3.05547
PPO Batch Consumption Time: 0.23026
Total Iteration Time: 6.97039
Cumulative Model Updates: 154,766
Cumulative Timesteps: 1,226,032,370
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.85772
Policy Entropy: 4.33271
Value Function Loss: 0.00250
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02948
Policy Update Magnitude: 0.97788
Value Function Update Magnitude: 0.83158
Collected Steps per Second: 13,071.14513
Overall Steps per Second: 7,216.05574
Timestep Collection Time: 3.82767
Timestep Consumption Time: 3.10576
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.93343
Cumulative Model Updates: 154,775
Cumulative Timesteps: 1,226,082,402
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1226082402...
Checkpoint 1226082402 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12297
Policy Entropy: 4.33257
Value Function Loss: 0.00266
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03053
Policy Update Magnitude: 1.00451
Value Function Update Magnitude: 0.78866
Collected Steps per Second: 13,067.29505
Overall Steps per Second: 7,221.36765
Timestep Collection Time: 3.82635
Timestep Consumption Time: 3.09755
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.92390
Cumulative Model Updates: 154,784
Cumulative Timesteps: 1,226,132,402
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.95968
Policy Entropy: 4.32987
Value Function Loss: 0.00275
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03304
Policy Update Magnitude: 1.02294
Value Function Update Magnitude: 0.81392
Collected Steps per Second: 13,108.70003
Overall Steps per Second: 7,335.61826
Timestep Collection Time: 3.81762
Timestep Consumption Time: 3.00444
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.82206
Cumulative Model Updates: 154,793
Cumulative Timesteps: 1,226,182,446
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
Saving checkpoint 1226182446...
Checkpoint 1226182446 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71324
Policy Entropy: 4.32930
Value Function Loss: 0.00283
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03433
Policy Update Magnitude: 1.04055
Value Function Update Magnitude: 0.86390
Collected Steps per Second: 13,099.24806
Overall Steps per Second: 7,226.17017
Timestep Collection Time: 3.82007
Timestep Consumption Time: 3.10476
PPO Batch Consumption Time: 0.22880
Total Iteration Time: 6.92483
Cumulative Model Updates: 154,802
Cumulative Timesteps: 1,226,232,486
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.04747
Policy Entropy: 4.33336
Value Function Loss: 0.00272
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03212
Policy Update Magnitude: 1.03678
Value Function Update Magnitude: 0.87199
Collected Steps per Second: 13,010.39627
Overall Steps per Second: 7,225.78430
Timestep Collection Time: 3.84385
Timestep Consumption Time: 3.07720
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.92105
Cumulative Model Updates: 154,811
Cumulative Timesteps: 1,226,282,496
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1226282496...
Checkpoint 1226282496 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56410
Policy Entropy: 4.33261
Value Function Loss: 0.00279
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 1.04036
Value Function Update Magnitude: 0.88656
Collected Steps per Second: 12,885.07812
Overall Steps per Second: 7,283.11226
Timestep Collection Time: 3.88170
Timestep Consumption Time: 2.98569
PPO Batch Consumption Time: 0.22912
Total Iteration Time: 6.86739
Cumulative Model Updates: 154,820
Cumulative Timesteps: 1,226,332,512
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.49448
Policy Entropy: 4.33073
Value Function Loss: 0.00282
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03257
Policy Update Magnitude: 1.05036
Value Function Update Magnitude: 0.89586
Collected Steps per Second: 12,998.25338
Overall Steps per Second: 7,085.48469
Timestep Collection Time: 3.84698
Timestep Consumption Time: 3.21027
PPO Batch Consumption Time: 0.23747
Total Iteration Time: 7.05724
Cumulative Model Updates: 154,829
Cumulative Timesteps: 1,226,382,516
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1226382516...
Checkpoint 1226382516 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.07121
Policy Entropy: 4.33080
Value Function Loss: 0.00283
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03460
Policy Update Magnitude: 1.04754
Value Function Update Magnitude: 0.87307
Collected Steps per Second: 12,866.15377
Overall Steps per Second: 7,176.92549
Timestep Collection Time: 3.88725
Timestep Consumption Time: 3.08147
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.96872
Cumulative Model Updates: 154,838
Cumulative Timesteps: 1,226,432,530
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95708
Policy Entropy: 4.33304
Value Function Loss: 0.00274
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03361
Policy Update Magnitude: 1.03854
Value Function Update Magnitude: 0.84950
Collected Steps per Second: 13,037.23017
Overall Steps per Second: 7,298.14771
Timestep Collection Time: 3.83609
Timestep Consumption Time: 3.01661
PPO Batch Consumption Time: 0.22941
Total Iteration Time: 6.85270
Cumulative Model Updates: 154,847
Cumulative Timesteps: 1,226,482,542
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1226482542...
Checkpoint 1226482542 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.47163
Policy Entropy: 4.33487
Value Function Loss: 0.00269
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03361
Policy Update Magnitude: 1.02980
Value Function Update Magnitude: 0.84337
Collected Steps per Second: 12,969.82683
Overall Steps per Second: 7,175.43082
Timestep Collection Time: 3.85556
Timestep Consumption Time: 3.11349
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.96906
Cumulative Model Updates: 154,856
Cumulative Timesteps: 1,226,532,548
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56447
Policy Entropy: 4.33189
Value Function Loss: 0.00271
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03216
Policy Update Magnitude: 1.03120
Value Function Update Magnitude: 0.84470
Collected Steps per Second: 12,979.89248
Overall Steps per Second: 7,239.93106
Timestep Collection Time: 3.85242
Timestep Consumption Time: 3.05428
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.90670
Cumulative Model Updates: 154,865
Cumulative Timesteps: 1,226,582,552
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1226582552...
Checkpoint 1226582552 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57265
Policy Entropy: 4.33659
Value Function Loss: 0.00273
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03218
Policy Update Magnitude: 1.03046
Value Function Update Magnitude: 0.82793
Collected Steps per Second: 12,861.46348
Overall Steps per Second: 7,259.47913
Timestep Collection Time: 3.88883
Timestep Consumption Time: 3.00092
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.88975
Cumulative Model Updates: 154,874
Cumulative Timesteps: 1,226,632,568
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29516
Policy Entropy: 4.33689
Value Function Loss: 0.00278
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03248
Policy Update Magnitude: 1.03184
Value Function Update Magnitude: 0.81732
Collected Steps per Second: 13,027.35800
Overall Steps per Second: 7,210.47531
Timestep Collection Time: 3.84299
Timestep Consumption Time: 3.10024
PPO Batch Consumption Time: 0.22904
Total Iteration Time: 6.94323
Cumulative Model Updates: 154,883
Cumulative Timesteps: 1,226,682,632
Timesteps Collected: 50,064
--------END ITERATION REPORT--------
Saving checkpoint 1226682632...
Checkpoint 1226682632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.60641
Policy Entropy: 4.33562
Value Function Loss: 0.00276
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 1.02368
Value Function Update Magnitude: 0.83761
Collected Steps per Second: 12,779.30126
Overall Steps per Second: 7,025.49523
Timestep Collection Time: 3.91336
Timestep Consumption Time: 3.20500
PPO Batch Consumption Time: 0.23801
Total Iteration Time: 7.11836
Cumulative Model Updates: 154,892
Cumulative Timesteps: 1,226,732,642
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05145
Policy Entropy: 4.33140
Value Function Loss: 0.00267
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03243
Policy Update Magnitude: 1.02855
Value Function Update Magnitude: 0.84000
Collected Steps per Second: 12,956.50341
Overall Steps per Second: 7,289.63300
Timestep Collection Time: 3.86138
Timestep Consumption Time: 3.00179
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.86317
Cumulative Model Updates: 154,901
Cumulative Timesteps: 1,226,782,672
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1226782672...
Checkpoint 1226782672 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22641
Policy Entropy: 4.33147
Value Function Loss: 0.00265
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03286
Policy Update Magnitude: 1.02921
Value Function Update Magnitude: 0.83547
Collected Steps per Second: 12,968.11865
Overall Steps per Second: 7,186.66529
Timestep Collection Time: 3.85823
Timestep Consumption Time: 3.10383
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.96206
Cumulative Model Updates: 154,910
Cumulative Timesteps: 1,226,832,706
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.34764
Policy Entropy: 4.33253
Value Function Loss: 0.00251
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03288
Policy Update Magnitude: 1.02604
Value Function Update Magnitude: 0.81218
Collected Steps per Second: 12,989.35771
Overall Steps per Second: 7,209.77603
Timestep Collection Time: 3.85115
Timestep Consumption Time: 3.08720
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.93836
Cumulative Model Updates: 154,919
Cumulative Timesteps: 1,226,882,730
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1226882730...
Checkpoint 1226882730 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.24017
Policy Entropy: 4.32854
Value Function Loss: 0.00265
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03228
Policy Update Magnitude: 1.03450
Value Function Update Magnitude: 0.81303
Collected Steps per Second: 12,920.53987
Overall Steps per Second: 7,281.14725
Timestep Collection Time: 3.87058
Timestep Consumption Time: 2.99784
PPO Batch Consumption Time: 0.22915
Total Iteration Time: 6.86842
Cumulative Model Updates: 154,928
Cumulative Timesteps: 1,226,932,740
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.71990
Policy Entropy: 4.32630
Value Function Loss: 0.00267
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03300
Policy Update Magnitude: 1.05346
Value Function Update Magnitude: 0.83981
Collected Steps per Second: 12,890.02120
Overall Steps per Second: 7,159.49411
Timestep Collection Time: 3.88037
Timestep Consumption Time: 3.10588
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.98625
Cumulative Model Updates: 154,937
Cumulative Timesteps: 1,226,982,758
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1226982758...
Checkpoint 1226982758 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.84727
Policy Entropy: 4.32327
Value Function Loss: 0.00274
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03621
Policy Update Magnitude: 1.05837
Value Function Update Magnitude: 0.86568
Collected Steps per Second: 12,930.91894
Overall Steps per Second: 7,213.63806
Timestep Collection Time: 3.86871
Timestep Consumption Time: 3.06621
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.93492
Cumulative Model Updates: 154,946
Cumulative Timesteps: 1,227,032,784
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.74589
Policy Entropy: 4.32952
Value Function Loss: 0.00264
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03437
Policy Update Magnitude: 1.05775
Value Function Update Magnitude: 0.87997
Collected Steps per Second: 12,926.95032
Overall Steps per Second: 7,244.99209
Timestep Collection Time: 3.86882
Timestep Consumption Time: 3.03416
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.90298
Cumulative Model Updates: 154,955
Cumulative Timesteps: 1,227,082,796
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1227082796...
Checkpoint 1227082796 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.14413
Policy Entropy: 4.33170
Value Function Loss: 0.00265
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03374
Policy Update Magnitude: 1.06130
Value Function Update Magnitude: 0.87844
Collected Steps per Second: 12,922.69455
Overall Steps per Second: 7,134.28055
Timestep Collection Time: 3.87102
Timestep Consumption Time: 3.14076
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 7.01178
Cumulative Model Updates: 154,964
Cumulative Timesteps: 1,227,132,820
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64564
Policy Entropy: 4.33141
Value Function Loss: 0.00262
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03373
Policy Update Magnitude: 1.05144
Value Function Update Magnitude: 0.87891
Collected Steps per Second: 12,947.42182
Overall Steps per Second: 7,201.25157
Timestep Collection Time: 3.86332
Timestep Consumption Time: 3.08270
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.94601
Cumulative Model Updates: 154,973
Cumulative Timesteps: 1,227,182,840
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1227182840...
Checkpoint 1227182840 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.40554
Policy Entropy: 4.33179
Value Function Loss: 0.00277
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 1.06749
Value Function Update Magnitude: 0.88468
Collected Steps per Second: 12,951.17901
Overall Steps per Second: 7,276.45521
Timestep Collection Time: 3.86081
Timestep Consumption Time: 3.01095
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.87175
Cumulative Model Updates: 154,982
Cumulative Timesteps: 1,227,232,842
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.28177
Policy Entropy: 4.32908
Value Function Loss: 0.00277
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03354
Policy Update Magnitude: 1.09373
Value Function Update Magnitude: 0.88995
Collected Steps per Second: 12,988.05996
Overall Steps per Second: 7,192.33629
Timestep Collection Time: 3.85154
Timestep Consumption Time: 3.10364
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.95518
Cumulative Model Updates: 154,991
Cumulative Timesteps: 1,227,282,866
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1227282866...
Checkpoint 1227282866 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25208
Policy Entropy: 4.32850
Value Function Loss: 0.00282
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03562
Policy Update Magnitude: 1.08717
Value Function Update Magnitude: 0.87574
Collected Steps per Second: 12,906.52736
Overall Steps per Second: 7,183.43066
Timestep Collection Time: 3.87618
Timestep Consumption Time: 3.08818
PPO Batch Consumption Time: 0.22917
Total Iteration Time: 6.96436
Cumulative Model Updates: 155,000
Cumulative Timesteps: 1,227,332,894
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23541
Policy Entropy: 4.33014
Value Function Loss: 0.00286
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 1.09369
Value Function Update Magnitude: 0.84335
Collected Steps per Second: 12,999.03210
Overall Steps per Second: 7,273.29130
Timestep Collection Time: 3.84690
Timestep Consumption Time: 3.02839
PPO Batch Consumption Time: 0.22943
Total Iteration Time: 6.87529
Cumulative Model Updates: 155,009
Cumulative Timesteps: 1,227,382,900
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1227382900...
Checkpoint 1227382900 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35711
Policy Entropy: 4.32375
Value Function Loss: 0.00291
Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03794
Policy Update Magnitude: 1.10138
Value Function Update Magnitude: 0.83698
Collected Steps per Second: 12,989.99302
Overall Steps per Second: 7,033.92681
Timestep Collection Time: 3.84942
Timestep Consumption Time: 3.25955
PPO Batch Consumption Time: 0.23997
Total Iteration Time: 7.10897
Cumulative Model Updates: 155,018
Cumulative Timesteps: 1,227,432,904
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.21884
Policy Entropy: 4.32555
Value Function Loss: 0.00288
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03634
Policy Update Magnitude: 1.09639
Value Function Update Magnitude: 0.84545
Collected Steps per Second: 12,831.62046
Overall Steps per Second: 7,171.03932
Timestep Collection Time: 3.89787
Timestep Consumption Time: 3.07685
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.97472
Cumulative Model Updates: 155,027
Cumulative Timesteps: 1,227,482,920
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1227482920...
Checkpoint 1227482920 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.25136
Policy Entropy: 4.32361
Value Function Loss: 0.00287
Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03701
Policy Update Magnitude: 1.09128
Value Function Update Magnitude: 0.83428
Collected Steps per Second: 12,776.03072
Overall Steps per Second: 7,236.47938
Timestep Collection Time: 3.91514
Timestep Consumption Time: 2.99706
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.91220
Cumulative Model Updates: 155,036
Cumulative Timesteps: 1,227,532,940
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11831
Policy Entropy: 4.32632
Value Function Loss: 0.00291
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03808
Policy Update Magnitude: 1.09231
Value Function Update Magnitude: 0.82426
Collected Steps per Second: 12,993.26475
Overall Steps per Second: 7,184.00406
Timestep Collection Time: 3.85138
Timestep Consumption Time: 3.11437
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.96575
Cumulative Model Updates: 155,045
Cumulative Timesteps: 1,227,582,982
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1227582982...
Checkpoint 1227582982 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.98499
Policy Entropy: 4.32781
Value Function Loss: 0.00294
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03698
Policy Update Magnitude: 1.07973
Value Function Update Magnitude: 0.83222
Collected Steps per Second: 12,857.58670
Overall Steps per Second: 7,179.17758
Timestep Collection Time: 3.89202
Timestep Consumption Time: 3.07842
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.97044
Cumulative Model Updates: 155,054
Cumulative Timesteps: 1,227,633,024
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.83351
Policy Entropy: 4.33181
Value Function Loss: 0.00289
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03741
Policy Update Magnitude: 1.07593
Value Function Update Magnitude: 0.84948
Collected Steps per Second: 13,244.81007
Overall Steps per Second: 7,249.72271
Timestep Collection Time: 3.77672
Timestep Consumption Time: 3.12313
PPO Batch Consumption Time: 0.23019
Total Iteration Time: 6.89985
Cumulative Model Updates: 155,063
Cumulative Timesteps: 1,227,683,046
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1227683046...
Checkpoint 1227683046 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.59096
Policy Entropy: 4.33007
Value Function Loss: 0.00290
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03939
Policy Update Magnitude: 1.08483
Value Function Update Magnitude: 0.85917
Collected Steps per Second: 12,857.61429
Overall Steps per Second: 7,123.93058
Timestep Collection Time: 3.88906
Timestep Consumption Time: 3.13010
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 7.01916
Cumulative Model Updates: 155,072
Cumulative Timesteps: 1,227,733,050
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.85886
Policy Entropy: 4.32975
Value Function Loss: 0.00282
Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03662
Policy Update Magnitude: 1.08461
Value Function Update Magnitude: 0.86432
Collected Steps per Second: 12,954.96215
Overall Steps per Second: 7,144.23964
Timestep Collection Time: 3.86014
Timestep Consumption Time: 3.13962
PPO Batch Consumption Time: 0.22972
Total Iteration Time: 6.99977
Cumulative Model Updates: 155,081
Cumulative Timesteps: 1,227,783,058
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1227783058...
Checkpoint 1227783058 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.34372
Policy Entropy: 4.32878
Value Function Loss: 0.00279
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 1.07702
Value Function Update Magnitude: 0.85387
Collected Steps per Second: 13,171.14705
Overall Steps per Second: 7,256.44664
Timestep Collection Time: 3.79785
Timestep Consumption Time: 3.09561
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.89346
Cumulative Model Updates: 155,090
Cumulative Timesteps: 1,227,833,080
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97275
Policy Entropy: 4.33006
Value Function Loss: 0.00272
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03398
Policy Update Magnitude: 1.07487
Value Function Update Magnitude: 0.84977
Collected Steps per Second: 13,175.13233
Overall Steps per Second: 7,241.80589
Timestep Collection Time: 3.79548
Timestep Consumption Time: 3.10970
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.90518
Cumulative Model Updates: 155,099
Cumulative Timesteps: 1,227,883,086
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1227883086...
Checkpoint 1227883086 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.84873
Policy Entropy: 4.33167
Value Function Loss: 0.00264
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 1.05791
Value Function Update Magnitude: 0.83687
Collected Steps per Second: 12,921.18942
Overall Steps per Second: 7,197.68300
Timestep Collection Time: 3.87162
Timestep Consumption Time: 3.07867
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.95029
Cumulative Model Updates: 155,108
Cumulative Timesteps: 1,227,933,112
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.46525
Policy Entropy: 4.33339
Value Function Loss: 0.00259
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 1.04341
Value Function Update Magnitude: 0.82897
Collected Steps per Second: 12,908.21814
Overall Steps per Second: 7,277.61750
Timestep Collection Time: 3.87536
Timestep Consumption Time: 2.99832
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.87368
Cumulative Model Updates: 155,117
Cumulative Timesteps: 1,227,983,136
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1227983136...
Checkpoint 1227983136 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.09168
Policy Entropy: 4.33519
Value Function Loss: 0.00263
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03155
Policy Update Magnitude: 1.04327
Value Function Update Magnitude: 0.85643
Collected Steps per Second: 13,089.02612
Overall Steps per Second: 7,225.24603
Timestep Collection Time: 3.82274
Timestep Consumption Time: 3.10242
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.92516
Cumulative Model Updates: 155,126
Cumulative Timesteps: 1,228,033,172
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.34549
Policy Entropy: 4.33367
Value Function Loss: 0.00271
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03294
Policy Update Magnitude: 1.07107
Value Function Update Magnitude: 0.84854
Collected Steps per Second: 13,063.47054
Overall Steps per Second: 7,255.44540
Timestep Collection Time: 3.82946
Timestep Consumption Time: 3.06550
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.89496
Cumulative Model Updates: 155,135
Cumulative Timesteps: 1,228,083,198
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1228083198...
Checkpoint 1228083198 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.11190
Policy Entropy: 4.32877
Value Function Loss: 0.00282
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03548
Policy Update Magnitude: 1.08960
Value Function Update Magnitude: 0.86358
Collected Steps per Second: 13,017.75194
Overall Steps per Second: 7,165.46875
Timestep Collection Time: 3.84321
Timestep Consumption Time: 3.13888
PPO Batch Consumption Time: 0.23961
Total Iteration Time: 6.98210
Cumulative Model Updates: 155,144
Cumulative Timesteps: 1,228,133,228
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.48987
Policy Entropy: 4.32381
Value Function Loss: 0.00283
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03829
Policy Update Magnitude: 1.08275
Value Function Update Magnitude: 0.84607
Collected Steps per Second: 12,970.86698
Overall Steps per Second: 7,181.87034
Timestep Collection Time: 3.85741
Timestep Consumption Time: 3.10930
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.96671
Cumulative Model Updates: 155,153
Cumulative Timesteps: 1,228,183,262
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1228183262...
Checkpoint 1228183262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66523
Policy Entropy: 4.32638
Value Function Loss: 0.00278
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03617
Policy Update Magnitude: 1.07520
Value Function Update Magnitude: 0.83036
Collected Steps per Second: 12,818.97391
Overall Steps per Second: 7,133.88147
Timestep Collection Time: 3.90218
Timestep Consumption Time: 3.10971
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 7.01189
Cumulative Model Updates: 155,162
Cumulative Timesteps: 1,228,233,284
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.57686
Policy Entropy: 4.33157
Value Function Loss: 0.00265
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03489
Policy Update Magnitude: 1.05064
Value Function Update Magnitude: 0.80519
Collected Steps per Second: 12,893.24972
Overall Steps per Second: 7,266.14166
Timestep Collection Time: 3.87986
Timestep Consumption Time: 3.00467
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.88453
Cumulative Model Updates: 155,171
Cumulative Timesteps: 1,228,283,308
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1228283308...
Checkpoint 1228283308 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22564
Policy Entropy: 4.33126
Value Function Loss: 0.00281
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03446
Policy Update Magnitude: 1.07588
Value Function Update Magnitude: 0.81290
Collected Steps per Second: 13,055.67495
Overall Steps per Second: 7,136.57252
Timestep Collection Time: 3.82991
Timestep Consumption Time: 3.17654
PPO Batch Consumption Time: 0.22963
Total Iteration Time: 7.00644
Cumulative Model Updates: 155,180
Cumulative Timesteps: 1,228,333,310
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.98538
Policy Entropy: 4.32780
Value Function Loss: 0.00290
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03710
Policy Update Magnitude: 1.10959
Value Function Update Magnitude: 0.85141
Collected Steps per Second: 12,990.81028
Overall Steps per Second: 7,207.15239
Timestep Collection Time: 3.85134
Timestep Consumption Time: 3.09065
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.94199
Cumulative Model Updates: 155,189
Cumulative Timesteps: 1,228,383,342
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1228383342...
Checkpoint 1228383342 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.92503
Policy Entropy: 4.32067
Value Function Loss: 0.00308
Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03792
Policy Update Magnitude: 1.12159
Value Function Update Magnitude: 0.87499
Collected Steps per Second: 13,295.53211
Overall Steps per Second: 7,296.37392
Timestep Collection Time: 3.76111
Timestep Consumption Time: 3.09243
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.85354
Cumulative Model Updates: 155,198
Cumulative Timesteps: 1,228,433,348
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54145
Policy Entropy: 4.31837
Value Function Loss: 0.00300
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03891
Policy Update Magnitude: 1.11694
Value Function Update Magnitude: 0.86197
Collected Steps per Second: 12,897.12758
Overall Steps per Second: 7,073.20518
Timestep Collection Time: 3.87823
Timestep Consumption Time: 3.19325
PPO Batch Consumption Time: 0.23678
Total Iteration Time: 7.07148
Cumulative Model Updates: 155,207
Cumulative Timesteps: 1,228,483,366
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1228483366...
Checkpoint 1228483366 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36836
Policy Entropy: 4.32001
Value Function Loss: 0.00284
Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03828
Policy Update Magnitude: 1.08629
Value Function Update Magnitude: 0.84018
Collected Steps per Second: 13,111.56345
Overall Steps per Second: 7,269.01020
Timestep Collection Time: 3.81648
Timestep Consumption Time: 3.06754
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.88402
Cumulative Model Updates: 155,216
Cumulative Timesteps: 1,228,533,406
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36327
Policy Entropy: 4.32357
Value Function Loss: 0.00288
Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03660
Policy Update Magnitude: 1.07299
Value Function Update Magnitude: 0.81037
Collected Steps per Second: 13,240.78269
Overall Steps per Second: 7,271.56811
Timestep Collection Time: 3.77742
Timestep Consumption Time: 3.10088
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.87830
Cumulative Model Updates: 155,225
Cumulative Timesteps: 1,228,583,422
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1228583422...
Checkpoint 1228583422 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.88332
Policy Entropy: 4.32499
Value Function Loss: 0.00278
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03703
Policy Update Magnitude: 1.06711
Value Function Update Magnitude: 0.79639
Collected Steps per Second: 12,981.96243
Overall Steps per Second: 7,190.72292
Timestep Collection Time: 3.85196
Timestep Consumption Time: 3.10228
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.95424
Cumulative Model Updates: 155,234
Cumulative Timesteps: 1,228,633,428
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.41195
Policy Entropy: 4.32299
Value Function Loss: 0.00303
Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04100
Policy Update Magnitude: 1.07508
Value Function Update Magnitude: 0.82058
Collected Steps per Second: 12,826.07085
Overall Steps per Second: 7,168.07165
Timestep Collection Time: 3.90034
Timestep Consumption Time: 3.07867
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.97900
Cumulative Model Updates: 155,243
Cumulative Timesteps: 1,228,683,454
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1228683454...
Checkpoint 1228683454 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12123
Policy Entropy: 4.32278
Value Function Loss: 0.00280
Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.03934
Policy Update Magnitude: 1.08461
Value Function Update Magnitude: 0.82160
Collected Steps per Second: 13,326.08743
Overall Steps per Second: 7,301.61055
Timestep Collection Time: 3.75219
Timestep Consumption Time: 3.09589
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.84808
Cumulative Model Updates: 155,252
Cumulative Timesteps: 1,228,733,456
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.59381
Policy Entropy: 4.32206
Value Function Loss: 0.00295
Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04069
Policy Update Magnitude: 1.07432
Value Function Update Magnitude: 0.82550
Collected Steps per Second: 13,103.43301
Overall Steps per Second: 7,226.05329
Timestep Collection Time: 3.81763
Timestep Consumption Time: 3.10510
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.92273
Cumulative Model Updates: 155,261
Cumulative Timesteps: 1,228,783,480
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1228783480...
Checkpoint 1228783480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01066
Policy Entropy: 4.32944
Value Function Loss: 0.00281
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03732
Policy Update Magnitude: 1.07120
Value Function Update Magnitude: 0.83651
Collected Steps per Second: 12,829.09732
Overall Steps per Second: 7,003.54865
Timestep Collection Time: 3.89895
Timestep Consumption Time: 3.24314
PPO Batch Consumption Time: 0.24026
Total Iteration Time: 7.14209
Cumulative Model Updates: 155,270
Cumulative Timesteps: 1,228,833,500
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.70798
Policy Entropy: 4.33083
Value Function Loss: 0.00280
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03515
Policy Update Magnitude: 1.05962
Value Function Update Magnitude: 0.83118
Collected Steps per Second: 13,223.74131
Overall Steps per Second: 7,273.67153
Timestep Collection Time: 3.78108
Timestep Consumption Time: 3.09303
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.87411
Cumulative Model Updates: 155,279
Cumulative Timesteps: 1,228,883,500
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1228883500...
Checkpoint 1228883500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04069
Policy Entropy: 4.33479
Value Function Loss: 0.00269
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 1.02411
Value Function Update Magnitude: 0.82680
Collected Steps per Second: 12,990.02588
Overall Steps per Second: 7,188.67955
Timestep Collection Time: 3.84926
Timestep Consumption Time: 3.10640
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.95566
Cumulative Model Updates: 155,288
Cumulative Timesteps: 1,228,933,502
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.09918
Policy Entropy: 4.33553
Value Function Loss: 0.00269
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03228
Policy Update Magnitude: 1.01820
Value Function Update Magnitude: 0.82657
Collected Steps per Second: 13,048.31925
Overall Steps per Second: 7,235.70670
Timestep Collection Time: 3.83482
Timestep Consumption Time: 3.08060
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.91543
Cumulative Model Updates: 155,297
Cumulative Timesteps: 1,228,983,540
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1228983540...
Checkpoint 1228983540 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.82447
Policy Entropy: 4.33823
Value Function Loss: 0.00273
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03300
Policy Update Magnitude: 1.02942
Value Function Update Magnitude: 0.83589
Collected Steps per Second: 12,966.44461
Overall Steps per Second: 7,199.23786
Timestep Collection Time: 3.85796
Timestep Consumption Time: 3.09056
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.94851
Cumulative Model Updates: 155,306
Cumulative Timesteps: 1,229,033,564
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.70209
Policy Entropy: 4.33682
Value Function Loss: 0.00263
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 1.01712
Value Function Update Magnitude: 0.85721
Collected Steps per Second: 12,978.78239
Overall Steps per Second: 7,184.66782
Timestep Collection Time: 3.85290
Timestep Consumption Time: 3.10720
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.96010
Cumulative Model Updates: 155,315
Cumulative Timesteps: 1,229,083,570
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1229083570...
Checkpoint 1229083570 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.57121
Policy Entropy: 4.33458
Value Function Loss: 0.00267
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 1.01842
Value Function Update Magnitude: 0.83955
Collected Steps per Second: 12,828.05363
Overall Steps per Second: 7,179.59249
Timestep Collection Time: 3.89895
Timestep Consumption Time: 3.06746
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.96641
Cumulative Model Updates: 155,324
Cumulative Timesteps: 1,229,133,586
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.24897
Policy Entropy: 4.33465
Value Function Loss: 0.00261
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03044
Policy Update Magnitude: 1.03870
Value Function Update Magnitude: 0.79055
Collected Steps per Second: 13,228.52397
Overall Steps per Second: 7,209.60981
Timestep Collection Time: 3.78213
Timestep Consumption Time: 3.15750
PPO Batch Consumption Time: 0.23005
Total Iteration Time: 6.93963
Cumulative Model Updates: 155,333
Cumulative Timesteps: 1,229,183,618
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1229183618...
Checkpoint 1229183618 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.19341
Policy Entropy: 4.33207
Value Function Loss: 0.00278
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03330
Policy Update Magnitude: 1.04761
Value Function Update Magnitude: 0.82013
Collected Steps per Second: 13,012.09832
Overall Steps per Second: 7,188.04150
Timestep Collection Time: 3.84304
Timestep Consumption Time: 3.11379
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.95683
Cumulative Model Updates: 155,342
Cumulative Timesteps: 1,229,233,624
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.10552
Policy Entropy: 4.33964
Value Function Loss: 0.00267
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 1.04503
Value Function Update Magnitude: 0.84139
Collected Steps per Second: 12,819.80147
Overall Steps per Second: 7,173.26013
Timestep Collection Time: 3.90193
Timestep Consumption Time: 3.07147
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.97340
Cumulative Model Updates: 155,351
Cumulative Timesteps: 1,229,283,646
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1229283646...
Checkpoint 1229283646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05079
Policy Entropy: 4.34085
Value Function Loss: 0.00265
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03114
Policy Update Magnitude: 1.04033
Value Function Update Magnitude: 0.83592
Collected Steps per Second: 13,221.25657
Overall Steps per Second: 7,278.81288
Timestep Collection Time: 3.78285
Timestep Consumption Time: 3.08833
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.87118
Cumulative Model Updates: 155,360
Cumulative Timesteps: 1,229,333,660
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.30403
Policy Entropy: 4.34331
Value Function Loss: 0.00258
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 1.03316
Value Function Update Magnitude: 0.81491
Collected Steps per Second: 13,016.81222
Overall Steps per Second: 7,194.94388
Timestep Collection Time: 3.84364
Timestep Consumption Time: 3.11013
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.95377
Cumulative Model Updates: 155,369
Cumulative Timesteps: 1,229,383,692
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1229383692...
Checkpoint 1229383692 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.94542
Policy Entropy: 4.34096
Value Function Loss: 0.00258
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03280
Policy Update Magnitude: 1.02901
Value Function Update Magnitude: 0.81015
Collected Steps per Second: 12,789.19715
Overall Steps per Second: 7,177.69040
Timestep Collection Time: 3.91002
Timestep Consumption Time: 3.05685
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.96686
Cumulative Model Updates: 155,378
Cumulative Timesteps: 1,229,433,698
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53095
Policy Entropy: 4.33722
Value Function Loss: 0.00268
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 1.03305
Value Function Update Magnitude: 0.82610
Collected Steps per Second: 12,913.73946
Overall Steps per Second: 7,274.92434
Timestep Collection Time: 3.87355
Timestep Consumption Time: 3.00240
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.87595
Cumulative Model Updates: 155,387
Cumulative Timesteps: 1,229,483,720
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1229483720...
Checkpoint 1229483720 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.00593
Policy Entropy: 4.34275
Value Function Loss: 0.00253
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 1.01987
Value Function Update Magnitude: 0.83054
Collected Steps per Second: 12,941.62519
Overall Steps per Second: 7,130.25543
Timestep Collection Time: 3.86350
Timestep Consumption Time: 3.14887
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 7.01237
Cumulative Model Updates: 155,396
Cumulative Timesteps: 1,229,533,720
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12830
Policy Entropy: 4.34473
Value Function Loss: 0.00248
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03105
Policy Update Magnitude: 1.00279
Value Function Update Magnitude: 0.80593
Collected Steps per Second: 12,914.52198
Overall Steps per Second: 7,206.19300
Timestep Collection Time: 3.87285
Timestep Consumption Time: 3.06785
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.94070
Cumulative Model Updates: 155,405
Cumulative Timesteps: 1,229,583,736
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1229583736...
Checkpoint 1229583736 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25515
Policy Entropy: 4.34637
Value Function Loss: 0.00249
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03077
Policy Update Magnitude: 1.01677
Value Function Update Magnitude: 0.78038
Collected Steps per Second: 12,985.40733
Overall Steps per Second: 7,303.70124
Timestep Collection Time: 3.85325
Timestep Consumption Time: 2.99752
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.85077
Cumulative Model Updates: 155,414
Cumulative Timesteps: 1,229,633,772
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.32757
Policy Entropy: 4.34120
Value Function Loss: 0.00256
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03395
Policy Update Magnitude: 1.03383
Value Function Update Magnitude: 0.80505
Collected Steps per Second: 12,966.59570
Overall Steps per Second: 7,190.77587
Timestep Collection Time: 3.85884
Timestep Consumption Time: 3.09952
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.95836
Cumulative Model Updates: 155,423
Cumulative Timesteps: 1,229,683,808
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1229683808...
Checkpoint 1229683808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.88317
Policy Entropy: 4.33691
Value Function Loss: 0.00254
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03244
Policy Update Magnitude: 1.04503
Value Function Update Magnitude: 0.81785
Collected Steps per Second: 12,889.93615
Overall Steps per Second: 7,182.06265
Timestep Collection Time: 3.88194
Timestep Consumption Time: 3.08514
PPO Batch Consumption Time: 0.22901
Total Iteration Time: 6.96708
Cumulative Model Updates: 155,432
Cumulative Timesteps: 1,229,733,846
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99372
Policy Entropy: 4.33828
Value Function Loss: 0.00248
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03130
Policy Update Magnitude: 1.04331
Value Function Update Magnitude: 0.81564
Collected Steps per Second: 12,983.28742
Overall Steps per Second: 7,275.59723
Timestep Collection Time: 3.85403
Timestep Consumption Time: 3.02348
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.87751
Cumulative Model Updates: 155,441
Cumulative Timesteps: 1,229,783,884
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1229783884...
Checkpoint 1229783884 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.89079
Policy Entropy: 4.33698
Value Function Loss: 0.00258
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03349
Policy Update Magnitude: 1.05004
Value Function Update Magnitude: 0.80858
Collected Steps per Second: 13,021.24539
Overall Steps per Second: 7,196.41914
Timestep Collection Time: 3.84249
Timestep Consumption Time: 3.11013
PPO Batch Consumption Time: 0.22927
Total Iteration Time: 6.95262
Cumulative Model Updates: 155,450
Cumulative Timesteps: 1,229,833,918
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.89246
Policy Entropy: 4.34389
Value Function Loss: 0.00256
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 1.04225
Value Function Update Magnitude: 0.82714
Collected Steps per Second: 13,030.69798
Overall Steps per Second: 7,077.22268
Timestep Collection Time: 3.83709
Timestep Consumption Time: 3.22783
PPO Batch Consumption Time: 0.24046
Total Iteration Time: 7.06492
Cumulative Model Updates: 155,459
Cumulative Timesteps: 1,229,883,918
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1229883918...
Checkpoint 1229883918 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06430
Policy Entropy: 4.34426
Value Function Loss: 0.00267
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03293
Policy Update Magnitude: 1.05121
Value Function Update Magnitude: 0.83726
Collected Steps per Second: 12,996.24169
Overall Steps per Second: 7,309.03349
Timestep Collection Time: 3.84880
Timestep Consumption Time: 2.99478
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.84359
Cumulative Model Updates: 155,468
Cumulative Timesteps: 1,229,933,938
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70650
Policy Entropy: 4.34909
Value Function Loss: 0.00262
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 1.05710
Value Function Update Magnitude: 0.85632
Collected Steps per Second: 13,130.62329
Overall Steps per Second: 7,238.25908
Timestep Collection Time: 3.80835
Timestep Consumption Time: 3.10022
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.90857
Cumulative Model Updates: 155,477
Cumulative Timesteps: 1,229,983,944
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1229983944...
Checkpoint 1229983944 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11468
Policy Entropy: 4.34201
Value Function Loss: 0.00270
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03373
Policy Update Magnitude: 1.04904
Value Function Update Magnitude: 0.86321
Collected Steps per Second: 12,827.07482
Overall Steps per Second: 7,190.10612
Timestep Collection Time: 3.89832
Timestep Consumption Time: 3.05624
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.95456
Cumulative Model Updates: 155,486
Cumulative Timesteps: 1,230,033,948
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.93806
Policy Entropy: 4.33938
Value Function Loss: 0.00262
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 1.05270
Value Function Update Magnitude: 0.83298
Collected Steps per Second: 12,924.79417
Overall Steps per Second: 7,284.30159
Timestep Collection Time: 3.86869
Timestep Consumption Time: 2.99566
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.86435
Cumulative Model Updates: 155,495
Cumulative Timesteps: 1,230,083,950
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1230083950...
Checkpoint 1230083950 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.13827
Policy Entropy: 4.33670
Value Function Loss: 0.00259
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03559
Policy Update Magnitude: 1.05732
Value Function Update Magnitude: 0.80213
Collected Steps per Second: 12,897.96895
Overall Steps per Second: 7,174.58587
Timestep Collection Time: 3.87844
Timestep Consumption Time: 3.09395
PPO Batch Consumption Time: 0.22878
Total Iteration Time: 6.97239
Cumulative Model Updates: 155,504
Cumulative Timesteps: 1,230,133,974
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.81312
Policy Entropy: 4.33877
Value Function Loss: 0.00270
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03353
Policy Update Magnitude: 1.06658
Value Function Update Magnitude: 0.80196
Collected Steps per Second: 12,842.60074
Overall Steps per Second: 7,204.70696
Timestep Collection Time: 3.89423
Timestep Consumption Time: 3.04735
PPO Batch Consumption Time: 0.22808
Total Iteration Time: 6.94157
Cumulative Model Updates: 155,513
Cumulative Timesteps: 1,230,183,986
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1230183986...
Checkpoint 1230183986 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43796
Policy Entropy: 4.33406
Value Function Loss: 0.00277
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03524
Policy Update Magnitude: 1.07177
Value Function Update Magnitude: 0.84290
Collected Steps per Second: 12,862.60217
Overall Steps per Second: 7,177.40123
Timestep Collection Time: 3.88895
Timestep Consumption Time: 3.08043
PPO Batch Consumption Time: 0.23034
Total Iteration Time: 6.96937
Cumulative Model Updates: 155,522
Cumulative Timesteps: 1,230,234,008
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.37039
Policy Entropy: 4.32943
Value Function Loss: 0.00277
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03598
Policy Update Magnitude: 1.07692
Value Function Update Magnitude: 0.83348
Collected Steps per Second: 13,138.83441
Overall Steps per Second: 7,228.25736
Timestep Collection Time: 3.80917
Timestep Consumption Time: 3.11477
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 6.92394
Cumulative Model Updates: 155,531
Cumulative Timesteps: 1,230,284,056
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1230284056...
Checkpoint 1230284056 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21982
Policy Entropy: 4.33083
Value Function Loss: 0.00280
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03684
Policy Update Magnitude: 1.07920
Value Function Update Magnitude: 0.84757
Collected Steps per Second: 12,602.44717
Overall Steps per Second: 7,031.86984
Timestep Collection Time: 3.96844
Timestep Consumption Time: 3.14376
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 7.11219
Cumulative Model Updates: 155,540
Cumulative Timesteps: 1,230,334,068
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.00096
Policy Entropy: 4.33026
Value Function Loss: 0.00280
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03635
Policy Update Magnitude: 1.07980
Value Function Update Magnitude: 0.84656
Collected Steps per Second: 12,779.04500
Overall Steps per Second: 7,200.63777
Timestep Collection Time: 3.91657
Timestep Consumption Time: 3.03421
PPO Batch Consumption Time: 0.22885
Total Iteration Time: 6.95077
Cumulative Model Updates: 155,549
Cumulative Timesteps: 1,230,384,118
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1230384118...
Checkpoint 1230384118 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.09801
Policy Entropy: 4.33077
Value Function Loss: 0.00293
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03559
Policy Update Magnitude: 1.08397
Value Function Update Magnitude: 0.83244
Collected Steps per Second: 13,039.56778
Overall Steps per Second: 7,213.43427
Timestep Collection Time: 3.83540
Timestep Consumption Time: 3.09777
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.93317
Cumulative Model Updates: 155,558
Cumulative Timesteps: 1,230,434,130
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.53714
Policy Entropy: 4.32829
Value Function Loss: 0.00283
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03752
Policy Update Magnitude: 1.06716
Value Function Update Magnitude: 0.82165
Collected Steps per Second: 12,978.65773
Overall Steps per Second: 7,195.14455
Timestep Collection Time: 3.85433
Timestep Consumption Time: 3.09814
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.95247
Cumulative Model Updates: 155,567
Cumulative Timesteps: 1,230,484,154
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1230484154...
Checkpoint 1230484154 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.70656
Policy Entropy: 4.33258
Value Function Loss: 0.00290
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03635
Policy Update Magnitude: 1.06768
Value Function Update Magnitude: 0.82092
Collected Steps per Second: 12,893.12482
Overall Steps per Second: 7,259.46270
Timestep Collection Time: 3.87928
Timestep Consumption Time: 3.01049
PPO Batch Consumption Time: 0.22921
Total Iteration Time: 6.88977
Cumulative Model Updates: 155,576
Cumulative Timesteps: 1,230,534,170
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.86068
Policy Entropy: 4.33670
Value Function Loss: 0.00273
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03746
Policy Update Magnitude: 1.05241
Value Function Update Magnitude: 0.81779
Collected Steps per Second: 12,909.73060
Overall Steps per Second: 7,011.31143
Timestep Collection Time: 3.87367
Timestep Consumption Time: 3.25881
PPO Batch Consumption Time: 0.24149
Total Iteration Time: 7.13247
Cumulative Model Updates: 155,585
Cumulative Timesteps: 1,230,584,178
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1230584178...
Checkpoint 1230584178 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.94001
Policy Entropy: 4.33597
Value Function Loss: 0.00287
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03668
Policy Update Magnitude: 1.04131
Value Function Update Magnitude: 0.83816
Collected Steps per Second: 12,903.07708
Overall Steps per Second: 7,188.16153
Timestep Collection Time: 3.87799
Timestep Consumption Time: 3.08318
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.96117
Cumulative Model Updates: 155,594
Cumulative Timesteps: 1,230,634,216
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.18148
Policy Entropy: 4.33814
Value Function Loss: 0.00278
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03573
Policy Update Magnitude: 1.04466
Value Function Update Magnitude: 0.86925
Collected Steps per Second: 12,939.34782
Overall Steps per Second: 7,290.26875
Timestep Collection Time: 3.86650
Timestep Consumption Time: 2.99607
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.86257
Cumulative Model Updates: 155,603
Cumulative Timesteps: 1,230,684,246
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1230684246...
Checkpoint 1230684246 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.79977
Policy Entropy: 4.33505
Value Function Loss: 0.00265
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03565
Policy Update Magnitude: 1.03260
Value Function Update Magnitude: 0.84575
Collected Steps per Second: 12,927.19199
Overall Steps per Second: 7,158.96780
Timestep Collection Time: 3.87029
Timestep Consumption Time: 3.11843
PPO Batch Consumption Time: 0.23001
Total Iteration Time: 6.98872
Cumulative Model Updates: 155,612
Cumulative Timesteps: 1,230,734,278
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.79913
Policy Entropy: 4.33485
Value Function Loss: 0.00258
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 1.03142
Value Function Update Magnitude: 0.83632
Collected Steps per Second: 13,075.05790
Overall Steps per Second: 7,259.89287
Timestep Collection Time: 3.82591
Timestep Consumption Time: 3.06455
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.89046
Cumulative Model Updates: 155,621
Cumulative Timesteps: 1,230,784,302
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1230784302...
Checkpoint 1230784302 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82566
Policy Entropy: 4.33131
Value Function Loss: 0.00251
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03322
Policy Update Magnitude: 1.02081
Value Function Update Magnitude: 0.82856
Collected Steps per Second: 12,971.51274
Overall Steps per Second: 7,258.10487
Timestep Collection Time: 3.85691
Timestep Consumption Time: 3.03607
PPO Batch Consumption Time: 0.22916
Total Iteration Time: 6.89298
Cumulative Model Updates: 155,630
Cumulative Timesteps: 1,230,834,332
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.76341
Policy Entropy: 4.32961
Value Function Loss: 0.00268
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03545
Policy Update Magnitude: 1.01641
Value Function Update Magnitude: 0.82187
Collected Steps per Second: 12,999.76879
Overall Steps per Second: 7,215.93143
Timestep Collection Time: 3.84668
Timestep Consumption Time: 3.08326
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.92994
Cumulative Model Updates: 155,639
Cumulative Timesteps: 1,230,884,338
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1230884338...
Checkpoint 1230884338 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.73827
Policy Entropy: 4.33266
Value Function Loss: 0.00262
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03269
Policy Update Magnitude: 1.02473
Value Function Update Magnitude: 0.81108
Collected Steps per Second: 12,916.31374
Overall Steps per Second: 7,139.88150
Timestep Collection Time: 3.87247
Timestep Consumption Time: 3.13297
PPO Batch Consumption Time: 0.23389
Total Iteration Time: 7.00544
Cumulative Model Updates: 155,648
Cumulative Timesteps: 1,230,934,356
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.55568
Policy Entropy: 4.33165
Value Function Loss: 0.00275
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03352
Policy Update Magnitude: 1.03768
Value Function Update Magnitude: 0.80929
Collected Steps per Second: 13,033.93164
Overall Steps per Second: 7,320.39521
Timestep Collection Time: 3.83906
Timestep Consumption Time: 2.99637
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.83542
Cumulative Model Updates: 155,657
Cumulative Timesteps: 1,230,984,394
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1230984394...
Checkpoint 1230984394 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.13988
Policy Entropy: 4.33486
Value Function Loss: 0.00268
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03456
Policy Update Magnitude: 1.03484
Value Function Update Magnitude: 0.80370
Collected Steps per Second: 13,016.03553
Overall Steps per Second: 7,220.77068
Timestep Collection Time: 3.84372
Timestep Consumption Time: 3.08490
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.92862
Cumulative Model Updates: 155,666
Cumulative Timesteps: 1,231,034,424
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.74948
Policy Entropy: 4.33512
Value Function Loss: 0.00260
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03558
Policy Update Magnitude: 1.02339
Value Function Update Magnitude: 0.79438
Collected Steps per Second: 13,041.43658
Overall Steps per Second: 7,253.45515
Timestep Collection Time: 3.83700
Timestep Consumption Time: 3.06178
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.89878
Cumulative Model Updates: 155,675
Cumulative Timesteps: 1,231,084,464
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1231084464...
Checkpoint 1231084464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.31864
Policy Entropy: 4.33946
Value Function Loss: 0.00243
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 0.99709
Value Function Update Magnitude: 0.77457
Collected Steps per Second: 12,812.49676
Overall Steps per Second: 7,245.02205
Timestep Collection Time: 3.90322
Timestep Consumption Time: 2.99945
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.90267
Cumulative Model Updates: 155,684
Cumulative Timesteps: 1,231,134,474
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25240
Policy Entropy: 4.33717
Value Function Loss: 0.00246
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03110
Policy Update Magnitude: 0.99813
Value Function Update Magnitude: 0.77829
Collected Steps per Second: 13,006.87700
Overall Steps per Second: 7,201.33256
Timestep Collection Time: 3.84458
Timestep Consumption Time: 3.09941
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.94399
Cumulative Model Updates: 155,693
Cumulative Timesteps: 1,231,184,480
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1231184480...
Checkpoint 1231184480 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.08473
Policy Entropy: 4.33862
Value Function Loss: 0.00260
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03022
Policy Update Magnitude: 1.01280
Value Function Update Magnitude: 0.77173
Collected Steps per Second: 12,901.02425
Overall Steps per Second: 7,204.08539
Timestep Collection Time: 3.87644
Timestep Consumption Time: 3.06546
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.94189
Cumulative Model Updates: 155,702
Cumulative Timesteps: 1,231,234,490
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.72030
Policy Entropy: 4.33735
Value Function Loss: 0.00263
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 1.01504
Value Function Update Magnitude: 0.79587
Collected Steps per Second: 12,963.72772
Overall Steps per Second: 7,123.81289
Timestep Collection Time: 3.85769
Timestep Consumption Time: 3.16243
PPO Batch Consumption Time: 0.24074
Total Iteration Time: 7.02012
Cumulative Model Updates: 155,711
Cumulative Timesteps: 1,231,284,500
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1231284500...
Checkpoint 1231284500 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.88877
Policy Entropy: 4.34077
Value Function Loss: 0.00266
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03174
Policy Update Magnitude: 1.00575
Value Function Update Magnitude: 0.80920
Collected Steps per Second: 12,998.76488
Overall Steps per Second: 7,194.03893
Timestep Collection Time: 3.84652
Timestep Consumption Time: 3.10368
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.95020
Cumulative Model Updates: 155,720
Cumulative Timesteps: 1,231,334,500
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.50376
Policy Entropy: 4.33842
Value Function Loss: 0.00269
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03117
Policy Update Magnitude: 1.01668
Value Function Update Magnitude: 0.79983
Collected Steps per Second: 12,982.33777
Overall Steps per Second: 7,197.53071
Timestep Collection Time: 3.85370
Timestep Consumption Time: 3.09730
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.95099
Cumulative Model Updates: 155,729
Cumulative Timesteps: 1,231,384,530
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1231384530...
Checkpoint 1231384530 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.83692
Policy Entropy: 4.34106
Value Function Loss: 0.00260
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03070
Policy Update Magnitude: 1.00278
Value Function Update Magnitude: 0.78857
Collected Steps per Second: 13,004.21161
Overall Steps per Second: 7,313.45573
Timestep Collection Time: 3.84537
Timestep Consumption Time: 2.99216
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.83753
Cumulative Model Updates: 155,738
Cumulative Timesteps: 1,231,434,536
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.62452
Policy Entropy: 4.34197
Value Function Loss: 0.00253
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.97974
Value Function Update Magnitude: 0.75702
Collected Steps per Second: 12,879.00098
Overall Steps per Second: 7,184.54289
Timestep Collection Time: 3.88415
Timestep Consumption Time: 3.07857
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.96273
Cumulative Model Updates: 155,747
Cumulative Timesteps: 1,231,484,560
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1231484560...
Checkpoint 1231484560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.92537
Policy Entropy: 4.33703
Value Function Loss: 0.00250
Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02828
Policy Update Magnitude: 0.99140
Value Function Update Magnitude: 0.73736
Collected Steps per Second: 12,975.44495
Overall Steps per Second: 7,183.42115
Timestep Collection Time: 3.85467
Timestep Consumption Time: 3.10803
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.96270
Cumulative Model Updates: 155,756
Cumulative Timesteps: 1,231,534,576
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.57995
Policy Entropy: 4.33417
Value Function Loss: 0.00259
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03190
Policy Update Magnitude: 1.01689
Value Function Update Magnitude: 0.74414
Collected Steps per Second: 12,897.84094
Overall Steps per Second: 7,279.39587
Timestep Collection Time: 3.87801
Timestep Consumption Time: 2.99316
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.87117
Cumulative Model Updates: 155,765
Cumulative Timesteps: 1,231,584,594
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1231584594...
Checkpoint 1231584594 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.08405
Policy Entropy: 4.33315
Value Function Loss: 0.00265
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 1.02458
Value Function Update Magnitude: 0.76925
Collected Steps per Second: 12,980.41076
Overall Steps per Second: 7,098.99041
Timestep Collection Time: 3.85427
Timestep Consumption Time: 3.19321
PPO Batch Consumption Time: 0.23425
Total Iteration Time: 7.04748
Cumulative Model Updates: 155,774
Cumulative Timesteps: 1,231,634,624
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54227
Policy Entropy: 4.33694
Value Function Loss: 0.00265
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03231
Policy Update Magnitude: 1.02290
Value Function Update Magnitude: 0.77671
Collected Steps per Second: 13,146.33508
Overall Steps per Second: 7,214.88678
Timestep Collection Time: 3.80395
Timestep Consumption Time: 3.12727
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.93122
Cumulative Model Updates: 155,783
Cumulative Timesteps: 1,231,684,632
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1231684632...
Checkpoint 1231684632 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.14439
Policy Entropy: 4.33705
Value Function Loss: 0.00261
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03125
Policy Update Magnitude: 1.02058
Value Function Update Magnitude: 0.79855
Collected Steps per Second: 12,905.07244
Overall Steps per Second: 7,204.54318
Timestep Collection Time: 3.87522
Timestep Consumption Time: 3.06623
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.94145
Cumulative Model Updates: 155,792
Cumulative Timesteps: 1,231,734,642
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19002
Policy Entropy: 4.33661
Value Function Loss: 0.00267
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03043
Policy Update Magnitude: 1.01580
Value Function Update Magnitude: 0.79428
Collected Steps per Second: 13,333.25868
Overall Steps per Second: 7,293.78273
Timestep Collection Time: 3.75062
Timestep Consumption Time: 3.10563
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.85625
Cumulative Model Updates: 155,801
Cumulative Timesteps: 1,231,784,650
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1231784650...
Checkpoint 1231784650 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22168
Policy Entropy: 4.33339
Value Function Loss: 0.00274
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 1.02048
Value Function Update Magnitude: 0.80019
Collected Steps per Second: 12,972.16343
Overall Steps per Second: 7,190.50219
Timestep Collection Time: 3.85564
Timestep Consumption Time: 3.10020
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.95584
Cumulative Model Updates: 155,810
Cumulative Timesteps: 1,231,834,666
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27107
Policy Entropy: 4.33275
Value Function Loss: 0.00273
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03563
Policy Update Magnitude: 1.01193
Value Function Update Magnitude: 0.81998
Collected Steps per Second: 13,029.31087
Overall Steps per Second: 7,310.77213
Timestep Collection Time: 3.83888
Timestep Consumption Time: 3.00280
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.84168
Cumulative Model Updates: 155,819
Cumulative Timesteps: 1,231,884,684
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1231884684...
Checkpoint 1231884684 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51059
Policy Entropy: 4.33753
Value Function Loss: 0.00265
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 1.00884
Value Function Update Magnitude: 0.80465
Collected Steps per Second: 12,888.72358
Overall Steps per Second: 7,145.29175
Timestep Collection Time: 3.87936
Timestep Consumption Time: 3.11825
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.99761
Cumulative Model Updates: 155,828
Cumulative Timesteps: 1,231,934,684
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41817
Policy Entropy: 4.34119
Value Function Loss: 0.00253
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 0.99197
Value Function Update Magnitude: 0.79078
Collected Steps per Second: 12,966.38134
Overall Steps per Second: 7,136.21743
Timestep Collection Time: 3.85721
Timestep Consumption Time: 3.15127
PPO Batch Consumption Time: 0.23375
Total Iteration Time: 7.00847
Cumulative Model Updates: 155,837
Cumulative Timesteps: 1,231,984,698
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1231984698...
Checkpoint 1231984698 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.92181
Policy Entropy: 4.34432
Value Function Loss: 0.00249
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03067
Policy Update Magnitude: 0.99792
Value Function Update Magnitude: 0.75626
Collected Steps per Second: 12,807.35921
Overall Steps per Second: 7,240.89487
Timestep Collection Time: 3.90650
Timestep Consumption Time: 3.00314
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.90964
Cumulative Model Updates: 155,846
Cumulative Timesteps: 1,232,034,730
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.51508
Policy Entropy: 4.34348
Value Function Loss: 0.00256
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03024
Policy Update Magnitude: 1.00677
Value Function Update Magnitude: 0.76786
Collected Steps per Second: 13,030.93748
Overall Steps per Second: 7,191.31309
Timestep Collection Time: 3.83764
Timestep Consumption Time: 3.11631
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.95395
Cumulative Model Updates: 155,855
Cumulative Timesteps: 1,232,084,738
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1232084738...
Checkpoint 1232084738 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.04232
Policy Entropy: 4.34306
Value Function Loss: 0.00271
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03214
Policy Update Magnitude: 1.01579
Value Function Update Magnitude: 0.80274
Collected Steps per Second: 12,747.58818
Overall Steps per Second: 7,120.45795
Timestep Collection Time: 3.92608
Timestep Consumption Time: 3.10269
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 7.02876
Cumulative Model Updates: 155,864
Cumulative Timesteps: 1,232,134,786
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.17951
Policy Entropy: 4.33666
Value Function Loss: 0.00289
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03290
Policy Update Magnitude: 1.04291
Value Function Update Magnitude: 0.84299
Collected Steps per Second: 12,946.98976
Overall Steps per Second: 7,200.77952
Timestep Collection Time: 3.86360
Timestep Consumption Time: 3.08315
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.94675
Cumulative Model Updates: 155,873
Cumulative Timesteps: 1,232,184,808
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1232184808...
Checkpoint 1232184808 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41123
Policy Entropy: 4.33754
Value Function Loss: 0.00284
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03514
Policy Update Magnitude: 1.03773
Value Function Update Magnitude: 0.81600
Collected Steps per Second: 13,141.82679
Overall Steps per Second: 7,240.15446
Timestep Collection Time: 3.80784
Timestep Consumption Time: 3.10389
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.91173
Cumulative Model Updates: 155,882
Cumulative Timesteps: 1,232,234,850
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69851
Policy Entropy: 4.33472
Value Function Loss: 0.00278
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03504
Policy Update Magnitude: 1.02416
Value Function Update Magnitude: 0.78416
Collected Steps per Second: 13,037.30020
Overall Steps per Second: 7,207.36134
Timestep Collection Time: 3.83622
Timestep Consumption Time: 3.10307
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.93929
Cumulative Model Updates: 155,891
Cumulative Timesteps: 1,232,284,864
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1232284864...
Checkpoint 1232284864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84572
Policy Entropy: 4.33942
Value Function Loss: 0.00259
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 1.01593
Value Function Update Magnitude: 0.79323
Collected Steps per Second: 12,921.29494
Overall Steps per Second: 7,125.96221
Timestep Collection Time: 3.87422
Timestep Consumption Time: 3.15079
PPO Batch Consumption Time: 0.23111
Total Iteration Time: 7.02502
Cumulative Model Updates: 155,900
Cumulative Timesteps: 1,232,334,924
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.05440
Policy Entropy: 4.33281
Value Function Loss: 0.00259
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 0.99621
Value Function Update Magnitude: 0.78846
Collected Steps per Second: 13,344.91229
Overall Steps per Second: 7,303.28068
Timestep Collection Time: 3.74944
Timestep Consumption Time: 3.10172
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.85117
Cumulative Model Updates: 155,909
Cumulative Timesteps: 1,232,384,960
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1232384960...
Checkpoint 1232384960 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31379
Policy Entropy: 4.33094
Value Function Loss: 0.00259
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03133
Policy Update Magnitude: 1.01153
Value Function Update Magnitude: 0.79833
Collected Steps per Second: 12,925.71556
Overall Steps per Second: 7,174.87441
Timestep Collection Time: 3.86981
Timestep Consumption Time: 3.10175
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.97155
Cumulative Model Updates: 155,918
Cumulative Timesteps: 1,232,434,980
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40816
Policy Entropy: 4.32665
Value Function Loss: 0.00272
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03327
Policy Update Magnitude: 1.02820
Value Function Update Magnitude: 0.82763
Collected Steps per Second: 12,937.03264
Overall Steps per Second: 7,226.95424
Timestep Collection Time: 3.86534
Timestep Consumption Time: 3.05404
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.91937
Cumulative Model Updates: 155,927
Cumulative Timesteps: 1,232,484,986
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1232484986...
Checkpoint 1232484986 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.01986
Policy Entropy: 4.33250
Value Function Loss: 0.00272
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03358
Policy Update Magnitude: 1.01998
Value Function Update Magnitude: 0.85381
Collected Steps per Second: 12,692.81228
Overall Steps per Second: 7,214.89665
Timestep Collection Time: 3.94302
Timestep Consumption Time: 2.99374
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.93676
Cumulative Model Updates: 155,936
Cumulative Timesteps: 1,232,535,034
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60995
Policy Entropy: 4.33062
Value Function Loss: 0.00283
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03445
Policy Update Magnitude: 1.03588
Value Function Update Magnitude: 0.84862
Collected Steps per Second: 12,927.26919
Overall Steps per Second: 7,185.81079
Timestep Collection Time: 3.87042
Timestep Consumption Time: 3.09247
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.96289
Cumulative Model Updates: 155,945
Cumulative Timesteps: 1,232,585,068
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1232585068...
Checkpoint 1232585068 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.16700
Policy Entropy: 4.32922
Value Function Loss: 0.00284
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03536
Policy Update Magnitude: 1.04641
Value Function Update Magnitude: 0.83005
Collected Steps per Second: 12,924.23753
Overall Steps per Second: 7,207.89714
Timestep Collection Time: 3.87071
Timestep Consumption Time: 3.06973
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.94044
Cumulative Model Updates: 155,954
Cumulative Timesteps: 1,232,635,094
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36287
Policy Entropy: 4.32828
Value Function Loss: 0.00283
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03581
Policy Update Magnitude: 1.05727
Value Function Update Magnitude: 0.80925
Collected Steps per Second: 12,963.71904
Overall Steps per Second: 7,134.23705
Timestep Collection Time: 3.85692
Timestep Consumption Time: 3.15154
PPO Batch Consumption Time: 0.24021
Total Iteration Time: 7.00846
Cumulative Model Updates: 155,963
Cumulative Timesteps: 1,232,685,094
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1232685094...
Checkpoint 1232685094 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.68973
Policy Entropy: 4.32652
Value Function Loss: 0.00275
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03530
Policy Update Magnitude: 1.04993
Value Function Update Magnitude: 0.80667
Collected Steps per Second: 12,903.27642
Overall Steps per Second: 7,146.60467
Timestep Collection Time: 3.87514
Timestep Consumption Time: 3.12147
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.99661
Cumulative Model Updates: 155,972
Cumulative Timesteps: 1,232,735,096
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.73914
Policy Entropy: 4.33477
Value Function Loss: 0.00262
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03486
Policy Update Magnitude: 1.03248
Value Function Update Magnitude: 0.78568
Collected Steps per Second: 12,901.97673
Overall Steps per Second: 7,180.23078
Timestep Collection Time: 3.87693
Timestep Consumption Time: 3.08942
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.96635
Cumulative Model Updates: 155,981
Cumulative Timesteps: 1,232,785,116
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1232785116...
Checkpoint 1232785116 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.21439
Policy Entropy: 4.33023
Value Function Loss: 0.00270
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03525
Policy Update Magnitude: 1.04286
Value Function Update Magnitude: 0.80579
Collected Steps per Second: 12,970.55384
Overall Steps per Second: 7,300.93942
Timestep Collection Time: 3.85504
Timestep Consumption Time: 2.99367
PPO Batch Consumption Time: 0.22877
Total Iteration Time: 6.84871
Cumulative Model Updates: 155,990
Cumulative Timesteps: 1,232,835,118
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.60500
Policy Entropy: 4.33525
Value Function Loss: 0.00262
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03468
Policy Update Magnitude: 1.03967
Value Function Update Magnitude: 0.83655
Collected Steps per Second: 13,089.48288
Overall Steps per Second: 7,212.69227
Timestep Collection Time: 3.82276
Timestep Consumption Time: 3.11473
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.93749
Cumulative Model Updates: 155,999
Cumulative Timesteps: 1,232,885,156
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1232885156...
Checkpoint 1232885156 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.62361
Policy Entropy: 4.33083
Value Function Loss: 0.00267
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03489
Policy Update Magnitude: 1.02545
Value Function Update Magnitude: 0.80879
Collected Steps per Second: 12,883.55534
Overall Steps per Second: 7,200.19659
Timestep Collection Time: 3.88216
Timestep Consumption Time: 3.06432
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.94648
Cumulative Model Updates: 156,008
Cumulative Timesteps: 1,232,935,172
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.66134
Policy Entropy: 4.33469
Value Function Loss: 0.00266
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03256
Policy Update Magnitude: 1.03381
Value Function Update Magnitude: 0.80952
Collected Steps per Second: 12,834.66096
Overall Steps per Second: 7,256.22401
Timestep Collection Time: 3.89804
Timestep Consumption Time: 2.99673
PPO Batch Consumption Time: 0.22859
Total Iteration Time: 6.89477
Cumulative Model Updates: 156,017
Cumulative Timesteps: 1,232,985,202
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1232985202...
Checkpoint 1232985202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76359
Policy Entropy: 4.33549
Value Function Loss: 0.00276
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03441
Policy Update Magnitude: 1.04143
Value Function Update Magnitude: 0.83403
Collected Steps per Second: 12,861.89167
Overall Steps per Second: 7,010.03396
Timestep Collection Time: 3.89150
Timestep Consumption Time: 3.24855
PPO Batch Consumption Time: 0.23992
Total Iteration Time: 7.14005
Cumulative Model Updates: 156,026
Cumulative Timesteps: 1,233,035,254
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.35771
Policy Entropy: 4.33813
Value Function Loss: 0.00270
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 1.03625
Value Function Update Magnitude: 0.83242
Collected Steps per Second: 12,954.32562
Overall Steps per Second: 7,234.46095
Timestep Collection Time: 3.86404
Timestep Consumption Time: 3.05507
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.91911
Cumulative Model Updates: 156,035
Cumulative Timesteps: 1,233,085,310
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1233085310...
Checkpoint 1233085310 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.72462
Policy Entropy: 4.33346
Value Function Loss: 0.00274
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03297
Policy Update Magnitude: 1.03206
Value Function Update Magnitude: 0.83651
Collected Steps per Second: 12,922.12530
Overall Steps per Second: 7,291.76197
Timestep Collection Time: 3.87134
Timestep Consumption Time: 2.98927
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.86062
Cumulative Model Updates: 156,044
Cumulative Timesteps: 1,233,135,336
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.92296
Policy Entropy: 4.33317
Value Function Loss: 0.00275
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03231
Policy Update Magnitude: 1.03356
Value Function Update Magnitude: 0.84725
Collected Steps per Second: 12,948.24594
Overall Steps per Second: 7,184.20129
Timestep Collection Time: 3.86431
Timestep Consumption Time: 3.10042
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.96473
Cumulative Model Updates: 156,053
Cumulative Timesteps: 1,233,185,372
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1233185372...
Checkpoint 1233185372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.62750
Policy Entropy: 4.32985
Value Function Loss: 0.00282
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03496
Policy Update Magnitude: 1.03765
Value Function Update Magnitude: 0.85432
Collected Steps per Second: 13,013.27852
Overall Steps per Second: 7,222.25291
Timestep Collection Time: 3.84361
Timestep Consumption Time: 3.08193
PPO Batch Consumption Time: 0.22822
Total Iteration Time: 6.92554
Cumulative Model Updates: 156,062
Cumulative Timesteps: 1,233,235,390
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.66341
Policy Entropy: 4.32613
Value Function Loss: 0.00295
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03522
Policy Update Magnitude: 1.05186
Value Function Update Magnitude: 0.80477
Collected Steps per Second: 13,371.14990
Overall Steps per Second: 7,290.72275
Timestep Collection Time: 3.73984
Timestep Consumption Time: 3.11901
PPO Batch Consumption Time: 0.22811
Total Iteration Time: 6.85885
Cumulative Model Updates: 156,071
Cumulative Timesteps: 1,233,285,396
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1233285396...
Checkpoint 1233285396 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.34417
Policy Entropy: 4.32456
Value Function Loss: 0.00301
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03596
Policy Update Magnitude: 1.06822
Value Function Update Magnitude: 0.83941
Collected Steps per Second: 12,883.15892
Overall Steps per Second: 7,169.38393
Timestep Collection Time: 3.88507
Timestep Consumption Time: 3.09628
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.98135
Cumulative Model Updates: 156,080
Cumulative Timesteps: 1,233,335,448
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.25741
Policy Entropy: 4.32994
Value Function Loss: 0.00301
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03502
Policy Update Magnitude: 1.05500
Value Function Update Magnitude: 0.87288
Collected Steps per Second: 12,849.33322
Overall Steps per Second: 7,086.19221
Timestep Collection Time: 3.89405
Timestep Consumption Time: 3.16700
PPO Batch Consumption Time: 0.23754
Total Iteration Time: 7.06106
Cumulative Model Updates: 156,089
Cumulative Timesteps: 1,233,385,484
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1233385484...
Checkpoint 1233385484 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.46653
Policy Entropy: 4.33680
Value Function Loss: 0.00278
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 1.05539
Value Function Update Magnitude: 0.86069
Collected Steps per Second: 13,244.18550
Overall Steps per Second: 7,284.10720
Timestep Collection Time: 3.77841
Timestep Consumption Time: 3.09161
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.87003
Cumulative Model Updates: 156,098
Cumulative Timesteps: 1,233,435,526
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.08102
Policy Entropy: 4.34106
Value Function Loss: 0.00278
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03450
Policy Update Magnitude: 1.03771
Value Function Update Magnitude: 0.87626
Collected Steps per Second: 13,094.95096
Overall Steps per Second: 7,218.63696
Timestep Collection Time: 3.82056
Timestep Consumption Time: 3.11011
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.93067
Cumulative Model Updates: 156,107
Cumulative Timesteps: 1,233,485,556
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1233485556...
Checkpoint 1233485556 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03087
Policy Entropy: 4.33994
Value Function Loss: 0.00275
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03301
Policy Update Magnitude: 1.02880
Value Function Update Magnitude: 0.89006
Collected Steps per Second: 12,938.43550
Overall Steps per Second: 7,219.06524
Timestep Collection Time: 3.86492
Timestep Consumption Time: 3.06202
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.92694
Cumulative Model Updates: 156,116
Cumulative Timesteps: 1,233,535,562
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51425
Policy Entropy: 4.33955
Value Function Loss: 0.00280
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03198
Policy Update Magnitude: 1.02987
Value Function Update Magnitude: 0.88753
Collected Steps per Second: 13,238.45500
Overall Steps per Second: 7,275.45151
Timestep Collection Time: 3.77733
Timestep Consumption Time: 3.09592
PPO Batch Consumption Time: 0.22942
Total Iteration Time: 6.87325
Cumulative Model Updates: 156,125
Cumulative Timesteps: 1,233,585,568
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1233585568...
Checkpoint 1233585568 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.06030
Policy Entropy: 4.34190
Value Function Loss: 0.00273
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03320
Policy Update Magnitude: 1.01554
Value Function Update Magnitude: 0.86460
Collected Steps per Second: 12,960.60576
Overall Steps per Second: 7,176.09486
Timestep Collection Time: 3.86263
Timestep Consumption Time: 3.11359
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.97622
Cumulative Model Updates: 156,134
Cumulative Timesteps: 1,233,635,630
Timesteps Collected: 50,062
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.63985
Policy Entropy: 4.34019
Value Function Loss: 0.00274
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03386
Policy Update Magnitude: 1.02290
Value Function Update Magnitude: 0.85146
Collected Steps per Second: 12,990.05509
Overall Steps per Second: 7,192.73660
Timestep Collection Time: 3.84987
Timestep Consumption Time: 3.10298
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.95285
Cumulative Model Updates: 156,143
Cumulative Timesteps: 1,233,685,640
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1233685640...
Checkpoint 1233685640 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35060
Policy Entropy: 4.33953
Value Function Loss: 0.00265
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03356
Policy Update Magnitude: 1.01733
Value Function Update Magnitude: 0.86216
Collected Steps per Second: 12,935.70355
Overall Steps per Second: 7,220.95165
Timestep Collection Time: 3.86790
Timestep Consumption Time: 3.06110
PPO Batch Consumption Time: 0.23036
Total Iteration Time: 6.92900
Cumulative Model Updates: 156,152
Cumulative Timesteps: 1,233,735,674
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.66170
Policy Entropy: 4.33275
Value Function Loss: 0.00274
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03518
Policy Update Magnitude: 1.01132
Value Function Update Magnitude: 0.84142
Collected Steps per Second: 13,114.58589
Overall Steps per Second: 7,209.79899
Timestep Collection Time: 3.81255
Timestep Consumption Time: 3.12246
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.93501
Cumulative Model Updates: 156,161
Cumulative Timesteps: 1,233,785,674
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1233785674...
Checkpoint 1233785674 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.07175
Policy Entropy: 4.33251
Value Function Loss: 0.00268
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 1.02343
Value Function Update Magnitude: 0.83363
Collected Steps per Second: 12,957.29986
Overall Steps per Second: 7,217.91306
Timestep Collection Time: 3.86099
Timestep Consumption Time: 3.07010
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.93109
Cumulative Model Updates: 156,170
Cumulative Timesteps: 1,233,835,702
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.56641
Policy Entropy: 4.33074
Value Function Loss: 0.00277
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03444
Policy Update Magnitude: 1.02621
Value Function Update Magnitude: 0.83678
Collected Steps per Second: 12,854.93067
Overall Steps per Second: 7,251.61080
Timestep Collection Time: 3.89065
Timestep Consumption Time: 3.00630
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.89695
Cumulative Model Updates: 156,179
Cumulative Timesteps: 1,233,885,716
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1233885716...
Checkpoint 1233885716 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.58098
Policy Entropy: 4.33346
Value Function Loss: 0.00280
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 1.02780
Value Function Update Magnitude: 0.84852
Collected Steps per Second: 12,829.41713
Overall Steps per Second: 7,118.80480
Timestep Collection Time: 3.90088
Timestep Consumption Time: 3.12923
PPO Batch Consumption Time: 0.22913
Total Iteration Time: 7.03011
Cumulative Model Updates: 156,188
Cumulative Timesteps: 1,233,935,762
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.23284
Policy Entropy: 4.33462
Value Function Loss: 0.00280
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03184
Policy Update Magnitude: 1.02836
Value Function Update Magnitude: 0.84137
Collected Steps per Second: 13,000.89962
Overall Steps per Second: 7,243.22890
Timestep Collection Time: 3.85020
Timestep Consumption Time: 3.06054
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.91073
Cumulative Model Updates: 156,197
Cumulative Timesteps: 1,233,985,818
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1233985818...
Checkpoint 1233985818 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.22955
Policy Entropy: 4.33790
Value Function Loss: 0.00273
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 1.02693
Value Function Update Magnitude: 0.83157
Collected Steps per Second: 12,927.53434
Overall Steps per Second: 7,273.10874
Timestep Collection Time: 3.87003
Timestep Consumption Time: 3.00873
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.87876
Cumulative Model Updates: 156,206
Cumulative Timesteps: 1,234,035,848
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41516
Policy Entropy: 4.33670
Value Function Loss: 0.00270
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03412
Policy Update Magnitude: 1.02599
Value Function Update Magnitude: 0.83373
Collected Steps per Second: 13,058.40693
Overall Steps per Second: 7,167.97749
Timestep Collection Time: 3.83033
Timestep Consumption Time: 3.14765
PPO Batch Consumption Time: 0.23027
Total Iteration Time: 6.97798
Cumulative Model Updates: 156,215
Cumulative Timesteps: 1,234,085,866
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1234085866...
Checkpoint 1234085866 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.33758
Policy Entropy: 4.33859
Value Function Loss: 0.00267
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03106
Policy Update Magnitude: 1.01459
Value Function Update Magnitude: 0.80428
Collected Steps per Second: 12,959.03398
Overall Steps per Second: 7,220.83085
Timestep Collection Time: 3.86171
Timestep Consumption Time: 3.06880
PPO Batch Consumption Time: 0.22896
Total Iteration Time: 6.93050
Cumulative Model Updates: 156,224
Cumulative Timesteps: 1,234,135,910
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02241
Policy Entropy: 4.34099
Value Function Loss: 0.00268
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03328
Policy Update Magnitude: 1.02086
Value Function Update Magnitude: 0.80349
Collected Steps per Second: 12,806.19631
Overall Steps per Second: 7,223.51246
Timestep Collection Time: 3.90467
Timestep Consumption Time: 3.01772
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.92239
Cumulative Model Updates: 156,233
Cumulative Timesteps: 1,234,185,914
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1234185914...
Checkpoint 1234185914 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.13811
Policy Entropy: 4.33631
Value Function Loss: 0.00266
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 1.02493
Value Function Update Magnitude: 0.84468
Collected Steps per Second: 13,080.83861
Overall Steps per Second: 7,208.44067
Timestep Collection Time: 3.82238
Timestep Consumption Time: 3.11393
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.93631
Cumulative Model Updates: 156,242
Cumulative Timesteps: 1,234,235,914
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.57331
Policy Entropy: 4.33783
Value Function Loss: 0.00275
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 1.03585
Value Function Update Magnitude: 0.87828
Collected Steps per Second: 13,007.21745
Overall Steps per Second: 7,193.77880
Timestep Collection Time: 3.84556
Timestep Consumption Time: 3.10767
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.95323
Cumulative Model Updates: 156,251
Cumulative Timesteps: 1,234,285,934
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1234285934...
Checkpoint 1234285934 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.35358
Policy Entropy: 4.33959
Value Function Loss: 0.00280
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03508
Policy Update Magnitude: 1.05233
Value Function Update Magnitude: 0.86131
Collected Steps per Second: 11,797.87552
Overall Steps per Second: 6,894.02259
Timestep Collection Time: 4.23992
Timestep Consumption Time: 3.01594
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 7.25585
Cumulative Model Updates: 156,260
Cumulative Timesteps: 1,234,335,956
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03369
Policy Entropy: 4.33870
Value Function Loss: 0.00296
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03290
Policy Update Magnitude: 1.06141
Value Function Update Magnitude: 0.84709
Collected Steps per Second: 13,087.97266
Overall Steps per Second: 7,212.45994
Timestep Collection Time: 3.82183
Timestep Consumption Time: 3.11339
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.93522
Cumulative Model Updates: 156,269
Cumulative Timesteps: 1,234,385,976
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1234385976...
Checkpoint 1234385976 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.40661
Policy Entropy: 4.33795
Value Function Loss: 0.00287
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 1.06522
Value Function Update Magnitude: 0.83828
Collected Steps per Second: 12,821.97802
Overall Steps per Second: 6,985.76889
Timestep Collection Time: 3.90252
Timestep Consumption Time: 3.26033
PPO Batch Consumption Time: 0.24111
Total Iteration Time: 7.16285
Cumulative Model Updates: 156,278
Cumulative Timesteps: 1,234,436,014
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.37100
Policy Entropy: 4.33719
Value Function Loss: 0.00287
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 1.07081
Value Function Update Magnitude: 0.86531
Collected Steps per Second: 12,984.77675
Overall Steps per Second: 7,304.15942
Timestep Collection Time: 3.85097
Timestep Consumption Time: 2.99499
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.84596
Cumulative Model Updates: 156,287
Cumulative Timesteps: 1,234,486,018
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1234486018...
Checkpoint 1234486018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.33535
Policy Entropy: 4.34070
Value Function Loss: 0.00266
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03214
Policy Update Magnitude: 1.05597
Value Function Update Magnitude: 0.86765
Collected Steps per Second: 12,986.86932
Overall Steps per Second: 7,114.25209
Timestep Collection Time: 3.85081
Timestep Consumption Time: 3.17874
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 7.02955
Cumulative Model Updates: 156,296
Cumulative Timesteps: 1,234,536,028
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01406
Policy Entropy: 4.33655
Value Function Loss: 0.00271
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03536
Policy Update Magnitude: 1.04498
Value Function Update Magnitude: 0.85729
Collected Steps per Second: 12,929.49215
Overall Steps per Second: 7,162.81286
Timestep Collection Time: 3.87038
Timestep Consumption Time: 3.11599
PPO Batch Consumption Time: 0.22920
Total Iteration Time: 6.98636
Cumulative Model Updates: 156,305
Cumulative Timesteps: 1,234,586,070
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1234586070...
Checkpoint 1234586070 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.94918
Policy Entropy: 4.33201
Value Function Loss: 0.00273
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03473
Policy Update Magnitude: 1.04612
Value Function Update Magnitude: 0.86216
Collected Steps per Second: 12,928.17973
Overall Steps per Second: 7,274.65866
Timestep Collection Time: 3.86969
Timestep Consumption Time: 3.00734
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.87702
Cumulative Model Updates: 156,314
Cumulative Timesteps: 1,234,636,098
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54869
Policy Entropy: 4.33226
Value Function Loss: 0.00274
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03469
Policy Update Magnitude: 1.04382
Value Function Update Magnitude: 0.86283
Collected Steps per Second: 13,001.21846
Overall Steps per Second: 7,182.02313
Timestep Collection Time: 3.84779
Timestep Consumption Time: 3.11765
PPO Batch Consumption Time: 0.22879
Total Iteration Time: 6.96545
Cumulative Model Updates: 156,323
Cumulative Timesteps: 1,234,686,124
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1234686124...
Checkpoint 1234686124 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75505
Policy Entropy: 4.33458
Value Function Loss: 0.00265
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03393
Policy Update Magnitude: 1.04592
Value Function Update Magnitude: 0.84766
Collected Steps per Second: 12,935.89150
Overall Steps per Second: 7,194.96468
Timestep Collection Time: 3.86599
Timestep Consumption Time: 3.08471
PPO Batch Consumption Time: 0.22906
Total Iteration Time: 6.95069
Cumulative Model Updates: 156,332
Cumulative Timesteps: 1,234,736,134
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66805
Policy Entropy: 4.33506
Value Function Loss: 0.00256
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03408
Policy Update Magnitude: 1.02524
Value Function Update Magnitude: 0.83121
Collected Steps per Second: 12,829.24489
Overall Steps per Second: 7,178.11826
Timestep Collection Time: 3.90015
Timestep Consumption Time: 3.07048
PPO Batch Consumption Time: 0.23406
Total Iteration Time: 6.97063
Cumulative Model Updates: 156,341
Cumulative Timesteps: 1,234,786,170
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1234786170...
Checkpoint 1234786170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03778
Policy Entropy: 4.33449
Value Function Loss: 0.00264
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 1.03747
Value Function Update Magnitude: 0.83831
Collected Steps per Second: 12,920.33568
Overall Steps per Second: 7,183.25212
Timestep Collection Time: 3.87265
Timestep Consumption Time: 3.09299
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.96565
Cumulative Model Updates: 156,350
Cumulative Timesteps: 1,234,836,206
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42641
Policy Entropy: 4.33531
Value Function Loss: 0.00266
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 1.05121
Value Function Update Magnitude: 0.85609
Collected Steps per Second: 13,032.73200
Overall Steps per Second: 7,236.94409
Timestep Collection Time: 3.83895
Timestep Consumption Time: 3.07447
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.91342
Cumulative Model Updates: 156,359
Cumulative Timesteps: 1,234,886,238
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1234886238...
Checkpoint 1234886238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.09856
Policy Entropy: 4.33581
Value Function Loss: 0.00268
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 1.04398
Value Function Update Magnitude: 0.88435
Collected Steps per Second: 13,038.17626
Overall Steps per Second: 7,302.61149
Timestep Collection Time: 3.83719
Timestep Consumption Time: 3.01378
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.85097
Cumulative Model Updates: 156,368
Cumulative Timesteps: 1,234,936,268
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.86794
Policy Entropy: 4.33686
Value Function Loss: 0.00262
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03324
Policy Update Magnitude: 1.03498
Value Function Update Magnitude: 0.89400
Collected Steps per Second: 12,959.39811
Overall Steps per Second: 7,178.82838
Timestep Collection Time: 3.85944
Timestep Consumption Time: 3.10772
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.96715
Cumulative Model Updates: 156,377
Cumulative Timesteps: 1,234,986,284
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1234986284...
Checkpoint 1234986284 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.63807
Policy Entropy: 4.33803
Value Function Loss: 0.00260
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 1.03543
Value Function Update Magnitude: 0.86586
Collected Steps per Second: 12,988.72358
Overall Steps per Second: 7,223.89664
Timestep Collection Time: 3.85072
Timestep Consumption Time: 3.07296
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.92369
Cumulative Model Updates: 156,386
Cumulative Timesteps: 1,235,036,300
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.41465
Policy Entropy: 4.33835
Value Function Loss: 0.00259
Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03153
Policy Update Magnitude: 1.03005
Value Function Update Magnitude: 0.86056
Collected Steps per Second: 12,944.42141
Overall Steps per Second: 7,291.22021
Timestep Collection Time: 3.86684
Timestep Consumption Time: 2.99813
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.86497
Cumulative Model Updates: 156,395
Cumulative Timesteps: 1,235,086,354
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1235086354...
Checkpoint 1235086354 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.63012
Policy Entropy: 4.33679
Value Function Loss: 0.00261
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03073
Policy Update Magnitude: 1.03807
Value Function Update Magnitude: 0.83574
Collected Steps per Second: 12,959.21210
Overall Steps per Second: 7,080.11334
Timestep Collection Time: 3.86104
Timestep Consumption Time: 3.20608
PPO Batch Consumption Time: 0.23758
Total Iteration Time: 7.06712
Cumulative Model Updates: 156,404
Cumulative Timesteps: 1,235,136,390
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.17211
Policy Entropy: 4.33300
Value Function Loss: 0.00270
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 1.04352
Value Function Update Magnitude: 0.82814
Collected Steps per Second: 13,201.47302
Overall Steps per Second: 7,302.94341
Timestep Collection Time: 3.79064
Timestep Consumption Time: 3.06167
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.85231
Cumulative Model Updates: 156,413
Cumulative Timesteps: 1,235,186,432
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1235186432...
Checkpoint 1235186432 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.21266
Policy Entropy: 4.33684
Value Function Loss: 0.00269
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03245
Policy Update Magnitude: 1.04055
Value Function Update Magnitude: 0.84418
Collected Steps per Second: 12,899.09824
Overall Steps per Second: 7,263.21157
Timestep Collection Time: 3.87857
Timestep Consumption Time: 3.00957
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.88814
Cumulative Model Updates: 156,422
Cumulative Timesteps: 1,235,236,462
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.84545
Policy Entropy: 4.33784
Value Function Loss: 0.00268
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 1.04610
Value Function Update Magnitude: 0.85240
Collected Steps per Second: 12,992.39667
Overall Steps per Second: 7,185.48915
Timestep Collection Time: 3.85195
Timestep Consumption Time: 3.11293
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.96487
Cumulative Model Updates: 156,431
Cumulative Timesteps: 1,235,286,508
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1235286508...
Checkpoint 1235286508 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.71905
Policy Entropy: 4.33587
Value Function Loss: 0.00275
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03400
Policy Update Magnitude: 1.05543
Value Function Update Magnitude: 0.85479
Collected Steps per Second: 12,826.74453
Overall Steps per Second: 7,193.99494
Timestep Collection Time: 3.89982
Timestep Consumption Time: 3.05348
PPO Batch Consumption Time: 0.22873
Total Iteration Time: 6.95330
Cumulative Model Updates: 156,440
Cumulative Timesteps: 1,235,336,530
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.33614
Policy Entropy: 4.33010
Value Function Loss: 0.00278
Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03557
Policy Update Magnitude: 1.06902
Value Function Update Magnitude: 0.86463
Collected Steps per Second: 12,850.31987
Overall Steps per Second: 7,268.27066
Timestep Collection Time: 3.89329
Timestep Consumption Time: 2.99005
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.88334
Cumulative Model Updates: 156,449
Cumulative Timesteps: 1,235,386,560
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1235386560...
Checkpoint 1235386560 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.10764
Policy Entropy: 4.32793
Value Function Loss: 0.00268
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03467
Policy Update Magnitude: 1.06233
Value Function Update Magnitude: 0.84727
Collected Steps per Second: 12,886.29525
Overall Steps per Second: 7,170.71949
Timestep Collection Time: 3.88273
Timestep Consumption Time: 3.09481
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.97754
Cumulative Model Updates: 156,458
Cumulative Timesteps: 1,235,436,594
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32473
Policy Entropy: 4.33157
Value Function Loss: 0.00262
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03400
Policy Update Magnitude: 1.04245
Value Function Update Magnitude: 0.82753
Collected Steps per Second: 12,974.36922
Overall Steps per Second: 7,159.05556
Timestep Collection Time: 3.85591
Timestep Consumption Time: 3.13216
PPO Batch Consumption Time: 0.23443
Total Iteration Time: 6.98807
Cumulative Model Updates: 156,467
Cumulative Timesteps: 1,235,486,622
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1235486622...
Checkpoint 1235486622 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.46961
Policy Entropy: 4.33017
Value Function Loss: 0.00270
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 1.05220
Value Function Update Magnitude: 0.85970
Collected Steps per Second: 13,017.97776
Overall Steps per Second: 7,311.97378
Timestep Collection Time: 3.84391
Timestep Consumption Time: 2.99965
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.84357
Cumulative Model Updates: 156,476
Cumulative Timesteps: 1,235,536,662
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46490
Policy Entropy: 4.33225
Value Function Loss: 0.00279
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03418
Policy Update Magnitude: 1.05362
Value Function Update Magnitude: 0.85941
Collected Steps per Second: 12,909.88418
Overall Steps per Second: 7,155.65534
Timestep Collection Time: 3.87347
Timestep Consumption Time: 3.11485
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.98832
Cumulative Model Updates: 156,485
Cumulative Timesteps: 1,235,586,668
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1235586668...
Checkpoint 1235586668 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.20977
Policy Entropy: 4.33358
Value Function Loss: 0.00275
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03460
Policy Update Magnitude: 1.03951
Value Function Update Magnitude: 0.85208
Collected Steps per Second: 12,876.10783
Overall Steps per Second: 7,192.16950
Timestep Collection Time: 3.88658
Timestep Consumption Time: 3.07154
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.95812
Cumulative Model Updates: 156,494
Cumulative Timesteps: 1,235,636,712
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.00567
Policy Entropy: 4.33970
Value Function Loss: 0.00261
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03189
Policy Update Magnitude: 1.02227
Value Function Update Magnitude: 0.82549
Collected Steps per Second: 12,894.14096
Overall Steps per Second: 7,258.97726
Timestep Collection Time: 3.88083
Timestep Consumption Time: 3.01270
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.89353
Cumulative Model Updates: 156,503
Cumulative Timesteps: 1,235,686,752
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1235686752...
Checkpoint 1235686752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 22.01388
Policy Entropy: 4.34049
Value Function Loss: 0.00261
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03172
Policy Update Magnitude: 1.02944
Value Function Update Magnitude: 0.82250
Collected Steps per Second: 13,059.22584
Overall Steps per Second: 7,186.33065
Timestep Collection Time: 3.83131
Timestep Consumption Time: 3.13107
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.96238
Cumulative Model Updates: 156,512
Cumulative Timesteps: 1,235,736,786
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.80720
Policy Entropy: 4.33693
Value Function Loss: 0.00263
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 1.03550
Value Function Update Magnitude: 0.84899
Collected Steps per Second: 12,903.19451
Overall Steps per Second: 7,172.40219
Timestep Collection Time: 3.87594
Timestep Consumption Time: 3.09690
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.97284
Cumulative Model Updates: 156,521
Cumulative Timesteps: 1,235,786,798
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1235786798...
Checkpoint 1235786798 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.95472
Policy Entropy: 4.33653
Value Function Loss: 0.00257
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03480
Policy Update Magnitude: 1.02887
Value Function Update Magnitude: 0.82860
Collected Steps per Second: 12,904.77509
Overall Steps per Second: 7,199.58995
Timestep Collection Time: 3.87608
Timestep Consumption Time: 3.07153
PPO Batch Consumption Time: 0.23178
Total Iteration Time: 6.94762
Cumulative Model Updates: 156,530
Cumulative Timesteps: 1,235,836,818
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.30110
Policy Entropy: 4.33462
Value Function Loss: 0.00263
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03399
Policy Update Magnitude: 1.03018
Value Function Update Magnitude: 0.84132
Collected Steps per Second: 12,823.23344
Overall Steps per Second: 7,155.16035
Timestep Collection Time: 3.90182
Timestep Consumption Time: 3.09089
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.99272
Cumulative Model Updates: 156,539
Cumulative Timesteps: 1,235,886,852
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1235886852...
Checkpoint 1235886852 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51455
Policy Entropy: 4.33874
Value Function Loss: 0.00259
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03391
Policy Update Magnitude: 1.03384
Value Function Update Magnitude: 0.84033
Collected Steps per Second: 12,901.72747
Overall Steps per Second: 7,170.37544
Timestep Collection Time: 3.87871
Timestep Consumption Time: 3.10029
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.97899
Cumulative Model Updates: 156,548
Cumulative Timesteps: 1,235,936,894
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.59864
Policy Entropy: 4.33493
Value Function Loss: 0.00269
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03373
Policy Update Magnitude: 1.02410
Value Function Update Magnitude: 0.85553
Collected Steps per Second: 12,829.22100
Overall Steps per Second: 7,243.48490
Timestep Collection Time: 3.89922
Timestep Consumption Time: 3.00684
PPO Batch Consumption Time: 0.22928
Total Iteration Time: 6.90607
Cumulative Model Updates: 156,557
Cumulative Timesteps: 1,235,986,918
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1235986918...
Checkpoint 1235986918 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.88621
Policy Entropy: 4.33651
Value Function Loss: 0.00271
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 1.04006
Value Function Update Magnitude: 0.84247
Collected Steps per Second: 13,041.35768
Overall Steps per Second: 7,198.03105
Timestep Collection Time: 3.83672
Timestep Consumption Time: 3.11463
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.95135
Cumulative Model Updates: 156,566
Cumulative Timesteps: 1,236,036,954
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95051
Policy Entropy: 4.33106
Value Function Loss: 0.00286
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03470
Policy Update Magnitude: 1.07223
Value Function Update Magnitude: 0.85459
Collected Steps per Second: 13,015.00497
Overall Steps per Second: 7,194.52882
Timestep Collection Time: 3.84233
Timestep Consumption Time: 3.10850
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.95084
Cumulative Model Updates: 156,575
Cumulative Timesteps: 1,236,086,962
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1236086962...
Checkpoint 1236086962 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66292
Policy Entropy: 4.33097
Value Function Loss: 0.00277
Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03476
Policy Update Magnitude: 1.07852
Value Function Update Magnitude: 0.84336
Collected Steps per Second: 13,023.98246
Overall Steps per Second: 7,299.38905
Timestep Collection Time: 3.84076
Timestep Consumption Time: 3.01214
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.85290
Cumulative Model Updates: 156,584
Cumulative Timesteps: 1,236,136,984
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.94893
Policy Entropy: 4.32971
Value Function Loss: 0.00274
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03564
Policy Update Magnitude: 1.04401
Value Function Update Magnitude: 0.83049
Collected Steps per Second: 13,092.96402
Overall Steps per Second: 7,177.52550
Timestep Collection Time: 3.81946
Timestep Consumption Time: 3.14785
PPO Batch Consumption Time: 0.23246
Total Iteration Time: 6.96730
Cumulative Model Updates: 156,593
Cumulative Timesteps: 1,236,186,992
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1236186992...
Checkpoint 1236186992 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.70311
Policy Entropy: 4.34061
Value Function Loss: 0.00254
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03534
Policy Update Magnitude: 1.01296
Value Function Update Magnitude: 0.79499
Collected Steps per Second: 12,896.55928
Overall Steps per Second: 7,182.04556
Timestep Collection Time: 3.88150
Timestep Consumption Time: 3.08838
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.96988
Cumulative Model Updates: 156,602
Cumulative Timesteps: 1,236,237,050
Timesteps Collected: 50,058
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01551
Policy Entropy: 4.33956
Value Function Loss: 0.00265
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03394
Policy Update Magnitude: 1.00900
Value Function Update Magnitude: 0.80186
Collected Steps per Second: 12,903.54009
Overall Steps per Second: 7,267.70230
Timestep Collection Time: 3.87568
Timestep Consumption Time: 3.00545
PPO Batch Consumption Time: 0.22809
Total Iteration Time: 6.88113
Cumulative Model Updates: 156,611
Cumulative Timesteps: 1,236,287,060
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1236287060...
Checkpoint 1236287060 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05630
Policy Entropy: 4.33542
Value Function Loss: 0.00274
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 1.05128
Value Function Update Magnitude: 0.82418
Collected Steps per Second: 13,072.46904
Overall Steps per Second: 7,220.26486
Timestep Collection Time: 3.82621
Timestep Consumption Time: 3.10124
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.92745
Cumulative Model Updates: 156,620
Cumulative Timesteps: 1,236,337,078
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85699
Policy Entropy: 4.33218
Value Function Loss: 0.00285
Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03853
Policy Update Magnitude: 1.05513
Value Function Update Magnitude: 0.85807
Collected Steps per Second: 13,003.20254
Overall Steps per Second: 7,232.75642
Timestep Collection Time: 3.84551
Timestep Consumption Time: 3.06803
PPO Batch Consumption Time: 0.22838
Total Iteration Time: 6.91355
Cumulative Model Updates: 156,629
Cumulative Timesteps: 1,236,387,082
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1236387082...
Checkpoint 1236387082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.08208
Policy Entropy: 4.33387
Value Function Loss: 0.00281
Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03744
Policy Update Magnitude: 1.04767
Value Function Update Magnitude: 0.82984
Collected Steps per Second: 12,734.65208
Overall Steps per Second: 7,226.39013
Timestep Collection Time: 3.92739
Timestep Consumption Time: 2.99363
PPO Batch Consumption Time: 0.22790
Total Iteration Time: 6.92102
Cumulative Model Updates: 156,638
Cumulative Timesteps: 1,236,437,096
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.14296
Policy Entropy: 4.33732
Value Function Loss: 0.00271
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03577
Policy Update Magnitude: 1.02391
Value Function Update Magnitude: 0.82948
Collected Steps per Second: 12,933.25366
Overall Steps per Second: 7,176.11315
Timestep Collection Time: 3.86910
Timestep Consumption Time: 3.10404
PPO Batch Consumption Time: 0.22793
Total Iteration Time: 6.97313
Cumulative Model Updates: 156,647
Cumulative Timesteps: 1,236,487,136
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1236487136...
Checkpoint 1236487136 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51370
Policy Entropy: 4.33902
Value Function Loss: 0.00262
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03390
Policy Update Magnitude: 1.01337
Value Function Update Magnitude: 0.84239
Collected Steps per Second: 12,776.31104
Overall Steps per Second: 7,045.54230
Timestep Collection Time: 3.91349
Timestep Consumption Time: 3.18319
PPO Batch Consumption Time: 0.23017
Total Iteration Time: 7.09669
Cumulative Model Updates: 156,656
Cumulative Timesteps: 1,236,537,136
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.08563
Policy Entropy: 4.34404
Value Function Loss: 0.00257
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03280
Policy Update Magnitude: 1.00461
Value Function Update Magnitude: 0.81164
Collected Steps per Second: 12,921.98311
Overall Steps per Second: 7,214.92471
Timestep Collection Time: 3.87201
Timestep Consumption Time: 3.06279
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.93479
Cumulative Model Updates: 156,665
Cumulative Timesteps: 1,236,587,170
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1236587170...
Checkpoint 1236587170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56790
Policy Entropy: 4.34504
Value Function Loss: 0.00253
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03393
Policy Update Magnitude: 1.00615
Value Function Update Magnitude: 0.84806
Collected Steps per Second: 13,240.97308
Overall Steps per Second: 7,283.90296
Timestep Collection Time: 3.77676
Timestep Consumption Time: 3.08879
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.86555
Cumulative Model Updates: 156,674
Cumulative Timesteps: 1,236,637,178
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95751
Policy Entropy: 4.34361
Value Function Loss: 0.00255
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 1.00242
Value Function Update Magnitude: 0.86642
Collected Steps per Second: 13,022.33044
Overall Steps per Second: 7,209.97770
Timestep Collection Time: 3.83987
Timestep Consumption Time: 3.09552
PPO Batch Consumption Time: 0.22786
Total Iteration Time: 6.93539
Cumulative Model Updates: 156,683
Cumulative Timesteps: 1,236,687,182
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1236687182...
Checkpoint 1236687182 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.48485
Policy Entropy: 4.33799
Value Function Loss: 0.00248
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03312
Policy Update Magnitude: 1.01499
Value Function Update Magnitude: 0.83652
Collected Steps per Second: 13,023.25136
Overall Steps per Second: 7,235.07235
Timestep Collection Time: 3.84159
Timestep Consumption Time: 3.07334
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.91493
Cumulative Model Updates: 156,692
Cumulative Timesteps: 1,236,737,212
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54566
Policy Entropy: 4.33796
Value Function Loss: 0.00256
Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03649
Policy Update Magnitude: 1.00607
Value Function Update Magnitude: 0.80798
Collected Steps per Second: 12,961.68055
Overall Steps per Second: 7,294.30645
Timestep Collection Time: 3.86076
Timestep Consumption Time: 2.99965
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.86042
Cumulative Model Updates: 156,701
Cumulative Timesteps: 1,236,787,254
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1236787254...
Checkpoint 1236787254 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57613
Policy Entropy: 4.33672
Value Function Loss: 0.00263
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03399
Policy Update Magnitude: 1.02367
Value Function Update Magnitude: 0.82747
Collected Steps per Second: 12,828.29061
Overall Steps per Second: 7,161.00454
Timestep Collection Time: 3.89966
Timestep Consumption Time: 3.08623
PPO Batch Consumption Time: 0.22855
Total Iteration Time: 6.98589
Cumulative Model Updates: 156,710
Cumulative Timesteps: 1,236,837,280
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.92579
Policy Entropy: 4.34149
Value Function Loss: 0.00257
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03163
Policy Update Magnitude: 1.00691
Value Function Update Magnitude: 0.82350
Collected Steps per Second: 12,813.08419
Overall Steps per Second: 7,041.94057
Timestep Collection Time: 3.90554
Timestep Consumption Time: 3.20074
PPO Batch Consumption Time: 0.23956
Total Iteration Time: 7.10628
Cumulative Model Updates: 156,719
Cumulative Timesteps: 1,236,887,322
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1236887322...
Checkpoint 1236887322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99602
Policy Entropy: 4.34138
Value Function Loss: 0.00253
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03066
Policy Update Magnitude: 0.98621
Value Function Update Magnitude: 0.82095
Collected Steps per Second: 12,981.79012
Overall Steps per Second: 7,251.70763
Timestep Collection Time: 3.85294
Timestep Consumption Time: 3.04447
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.89741
Cumulative Model Updates: 156,728
Cumulative Timesteps: 1,236,937,340
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54578
Policy Entropy: 4.34185
Value Function Loss: 0.00267
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03008
Policy Update Magnitude: 1.02415
Value Function Update Magnitude: 0.83943
Collected Steps per Second: 12,971.51621
Overall Steps per Second: 7,198.65379
Timestep Collection Time: 3.85660
Timestep Consumption Time: 3.09275
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.94935
Cumulative Model Updates: 156,737
Cumulative Timesteps: 1,236,987,366
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1236987366...
Checkpoint 1236987366 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.90371
Policy Entropy: 4.33984
Value Function Loss: 0.00263
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03345
Policy Update Magnitude: 1.03881
Value Function Update Magnitude: 0.84300
Collected Steps per Second: 13,044.02988
Overall Steps per Second: 7,245.83599
Timestep Collection Time: 3.83532
Timestep Consumption Time: 3.06906
PPO Batch Consumption Time: 0.22908
Total Iteration Time: 6.90438
Cumulative Model Updates: 156,746
Cumulative Timesteps: 1,237,037,394
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74004
Policy Entropy: 4.33933
Value Function Loss: 0.00262
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03465
Policy Update Magnitude: 1.00899
Value Function Update Magnitude: 0.85083
Collected Steps per Second: 12,988.55790
Overall Steps per Second: 7,315.41525
Timestep Collection Time: 3.85262
Timestep Consumption Time: 2.98773
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.84035
Cumulative Model Updates: 156,755
Cumulative Timesteps: 1,237,087,434
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1237087434...
Checkpoint 1237087434 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99883
Policy Entropy: 4.34349
Value Function Loss: 0.00240
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03215
Policy Update Magnitude: 0.99388
Value Function Update Magnitude: 0.83960
Collected Steps per Second: 13,102.58250
Overall Steps per Second: 7,229.02724
Timestep Collection Time: 3.81894
Timestep Consumption Time: 3.10287
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.92182
Cumulative Model Updates: 156,764
Cumulative Timesteps: 1,237,137,472
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50767
Policy Entropy: 4.34511
Value Function Loss: 0.00238
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03099
Policy Update Magnitude: 0.99279
Value Function Update Magnitude: 0.80526
Collected Steps per Second: 12,992.94708
Overall Steps per Second: 7,183.62857
Timestep Collection Time: 3.84855
Timestep Consumption Time: 3.11228
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.96083
Cumulative Model Updates: 156,773
Cumulative Timesteps: 1,237,187,476
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1237187476...
Checkpoint 1237187476 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56580
Policy Entropy: 4.34822
Value Function Loss: 0.00239
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03234
Policy Update Magnitude: 0.98170
Value Function Update Magnitude: 0.79857
Collected Steps per Second: 12,655.65022
Overall Steps per Second: 7,043.03800
Timestep Collection Time: 3.95270
Timestep Consumption Time: 3.14992
PPO Batch Consumption Time: 0.24139
Total Iteration Time: 7.10262
Cumulative Model Updates: 156,782
Cumulative Timesteps: 1,237,237,500
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.40208
Policy Entropy: 4.34302
Value Function Loss: 0.00255
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03306
Policy Update Magnitude: 1.00686
Value Function Update Magnitude: 0.80106
Collected Steps per Second: 12,918.40789
Overall Steps per Second: 7,170.13377
Timestep Collection Time: 3.87401
Timestep Consumption Time: 3.10578
PPO Batch Consumption Time: 0.22799
Total Iteration Time: 6.97979
Cumulative Model Updates: 156,791
Cumulative Timesteps: 1,237,287,546
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
Saving checkpoint 1237287546...
Checkpoint 1237287546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.80763
Policy Entropy: 4.33737
Value Function Loss: 0.00259
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03498
Policy Update Magnitude: 1.03689
Value Function Update Magnitude: 0.79247
Collected Steps per Second: 12,929.55838
Overall Steps per Second: 7,158.42599
Timestep Collection Time: 3.86912
Timestep Consumption Time: 3.11929
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.98841
Cumulative Model Updates: 156,800
Cumulative Timesteps: 1,237,337,572
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 18.48569
Policy Entropy: 4.33188
Value Function Loss: 0.00268
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03616
Policy Update Magnitude: 1.03868
Value Function Update Magnitude: 0.81673
Collected Steps per Second: 12,901.92139
Overall Steps per Second: 7,279.76934
Timestep Collection Time: 3.87865
Timestep Consumption Time: 2.99547
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.87412
Cumulative Model Updates: 156,809
Cumulative Timesteps: 1,237,387,614
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1237387614...
Checkpoint 1237387614 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.59098
Policy Entropy: 4.33590
Value Function Loss: 0.00269
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 1.03559
Value Function Update Magnitude: 0.82410
Collected Steps per Second: 12,982.70071
Overall Steps per Second: 7,167.78486
Timestep Collection Time: 3.85128
Timestep Consumption Time: 3.12438
PPO Batch Consumption Time: 0.22826
Total Iteration Time: 6.97566
Cumulative Model Updates: 156,818
Cumulative Timesteps: 1,237,437,614
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.03054
Policy Entropy: 4.33797
Value Function Loss: 0.00265
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03250
Policy Update Magnitude: 1.03060
Value Function Update Magnitude: 0.81366
Collected Steps per Second: 12,983.99488
Overall Steps per Second: 7,194.21957
Timestep Collection Time: 3.85336
Timestep Consumption Time: 3.10111
PPO Batch Consumption Time: 0.22887
Total Iteration Time: 6.95447
Cumulative Model Updates: 156,827
Cumulative Timesteps: 1,237,487,646
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
Saving checkpoint 1237487646...
Checkpoint 1237487646 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.13899
Policy Entropy: 4.33927
Value Function Loss: 0.00260
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03188
Policy Update Magnitude: 1.01394
Value Function Update Magnitude: 0.79199
Collected Steps per Second: 12,931.93694
Overall Steps per Second: 7,278.40213
Timestep Collection Time: 3.86825
Timestep Consumption Time: 3.00468
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.87294
Cumulative Model Updates: 156,836
Cumulative Timesteps: 1,237,537,670
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74420
Policy Entropy: 4.34134
Value Function Loss: 0.00264
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03287
Policy Update Magnitude: 1.02558
Value Function Update Magnitude: 0.80785
Collected Steps per Second: 13,029.48418
Overall Steps per Second: 7,160.47929
Timestep Collection Time: 3.84175
Timestep Consumption Time: 3.14885
PPO Batch Consumption Time: 0.22958
Total Iteration Time: 6.99059
Cumulative Model Updates: 156,845
Cumulative Timesteps: 1,237,587,726
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
Saving checkpoint 1237587726...
Checkpoint 1237587726 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49604
Policy Entropy: 4.33871
Value Function Loss: 0.00266
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03364
Policy Update Magnitude: 1.02603
Value Function Update Magnitude: 0.82503
Collected Steps per Second: 12,924.78696
Overall Steps per Second: 7,169.58403
Timestep Collection Time: 3.86885
Timestep Consumption Time: 3.10562
PPO Batch Consumption Time: 0.22872
Total Iteration Time: 6.97446
Cumulative Model Updates: 156,854
Cumulative Timesteps: 1,237,637,730
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28589
Policy Entropy: 4.33748
Value Function Loss: 0.00262
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03381
Policy Update Magnitude: 1.02446
Value Function Update Magnitude: 0.83695
Collected Steps per Second: 12,841.10780
Overall Steps per Second: 7,275.83177
Timestep Collection Time: 3.89670
Timestep Consumption Time: 2.98059
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.87729
Cumulative Model Updates: 156,863
Cumulative Timesteps: 1,237,687,768
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1237687768...
Checkpoint 1237687768 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.15058
Policy Entropy: 4.33864
Value Function Loss: 0.00249
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03550
Policy Update Magnitude: 1.02192
Value Function Update Magnitude: 0.81294
Collected Steps per Second: 12,876.14432
Overall Steps per Second: 7,159.46962
Timestep Collection Time: 3.88486
Timestep Consumption Time: 3.10197
PPO Batch Consumption Time: 0.22817
Total Iteration Time: 6.98683
Cumulative Model Updates: 156,872
Cumulative Timesteps: 1,237,737,790
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.98772
Policy Entropy: 4.34181
Value Function Loss: 0.00256
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03386
Policy Update Magnitude: 1.01878
Value Function Update Magnitude: 0.76519
Collected Steps per Second: 12,948.69278
Overall Steps per Second: 7,186.92592
Timestep Collection Time: 3.86155
Timestep Consumption Time: 3.09581
PPO Batch Consumption Time: 0.22804
Total Iteration Time: 6.95736
Cumulative Model Updates: 156,881
Cumulative Timesteps: 1,237,787,792
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1237787792...
Checkpoint 1237787792 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99125
Policy Entropy: 4.34427
Value Function Loss: 0.00269
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03196
Policy Update Magnitude: 1.04063
Value Function Update Magnitude: 0.79795
Collected Steps per Second: 12,870.34966
Overall Steps per Second: 7,172.68621
Timestep Collection Time: 3.88630
Timestep Consumption Time: 3.08710
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.97340
Cumulative Model Updates: 156,890
Cumulative Timesteps: 1,237,837,810
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86021
Policy Entropy: 4.34086
Value Function Loss: 0.00279
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03306
Policy Update Magnitude: 1.05037
Value Function Update Magnitude: 0.84502
Collected Steps per Second: 13,159.16145
Overall Steps per Second: 7,248.72406
Timestep Collection Time: 3.80283
Timestep Consumption Time: 3.10073
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.90356
Cumulative Model Updates: 156,899
Cumulative Timesteps: 1,237,887,852
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1237887852...
Checkpoint 1237887852 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95885
Policy Entropy: 4.33485
Value Function Loss: 0.00280
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03418
Policy Update Magnitude: 1.06325
Value Function Update Magnitude: 0.84244
Collected Steps per Second: 12,791.64292
Overall Steps per Second: 7,050.93914
Timestep Collection Time: 3.90927
Timestep Consumption Time: 3.18283
PPO Batch Consumption Time: 0.23417
Total Iteration Time: 7.09210
Cumulative Model Updates: 156,908
Cumulative Timesteps: 1,237,937,858
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.42887
Policy Entropy: 4.33716
Value Function Loss: 0.00277
Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03632
Policy Update Magnitude: 1.07021
Value Function Update Magnitude: 0.83589
Collected Steps per Second: 12,863.77022
Overall Steps per Second: 7,191.60204
Timestep Collection Time: 3.88782
Timestep Consumption Time: 3.06640
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.95422
Cumulative Model Updates: 156,917
Cumulative Timesteps: 1,237,987,870
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1237987870...
Checkpoint 1237987870 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.57299
Policy Entropy: 4.33405
Value Function Loss: 0.00284
Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03671
Policy Update Magnitude: 1.06535
Value Function Update Magnitude: 0.85258
Collected Steps per Second: 13,086.95486
Overall Steps per Second: 7,337.19978
Timestep Collection Time: 3.82320
Timestep Consumption Time: 2.99603
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.81922
Cumulative Model Updates: 156,926
Cumulative Timesteps: 1,238,037,904
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.75698
Policy Entropy: 4.33739
Value Function Loss: 0.00265
Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03656
Policy Update Magnitude: 1.05214
Value Function Update Magnitude: 0.87289
Collected Steps per Second: 12,808.88328
Overall Steps per Second: 7,137.55885
Timestep Collection Time: 3.90385
Timestep Consumption Time: 3.10190
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 7.00576
Cumulative Model Updates: 156,935
Cumulative Timesteps: 1,238,087,908
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1238087908...
Checkpoint 1238087908 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38167
Policy Entropy: 4.33884
Value Function Loss: 0.00251
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03440
Policy Update Magnitude: 1.02536
Value Function Update Magnitude: 0.86358
Collected Steps per Second: 12,981.97739
Overall Steps per Second: 7,229.07723
Timestep Collection Time: 3.85180
Timestep Consumption Time: 3.06526
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.91707
Cumulative Model Updates: 156,944
Cumulative Timesteps: 1,238,137,912
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.04802
Policy Entropy: 4.34036
Value Function Loss: 0.00245
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03201
Policy Update Magnitude: 1.01081
Value Function Update Magnitude: 0.84980
Collected Steps per Second: 13,006.58023
Overall Steps per Second: 7,323.29305
Timestep Collection Time: 3.84575
Timestep Consumption Time: 2.98451
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.83026
Cumulative Model Updates: 156,953
Cumulative Timesteps: 1,238,187,932
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1238187932...
Checkpoint 1238187932 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.99004
Policy Entropy: 4.33678
Value Function Loss: 0.00260
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03218
Policy Update Magnitude: 1.03319
Value Function Update Magnitude: 0.83252
Collected Steps per Second: 12,966.36426
Overall Steps per Second: 7,196.66488
Timestep Collection Time: 3.85659
Timestep Consumption Time: 3.09190
PPO Batch Consumption Time: 0.22871
Total Iteration Time: 6.94850
Cumulative Model Updates: 156,962
Cumulative Timesteps: 1,238,237,938
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03906
Policy Entropy: 4.33452
Value Function Loss: 0.00268
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03226
Policy Update Magnitude: 1.03917
Value Function Update Magnitude: 0.83866
Collected Steps per Second: 13,007.23172
Overall Steps per Second: 7,167.44976
Timestep Collection Time: 3.84586
Timestep Consumption Time: 3.13347
PPO Batch Consumption Time: 0.23281
Total Iteration Time: 6.97933
Cumulative Model Updates: 156,971
Cumulative Timesteps: 1,238,287,962
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1238287962...
Checkpoint 1238287962 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.79009
Policy Entropy: 4.33737
Value Function Loss: 0.00260
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03335
Policy Update Magnitude: 1.02584
Value Function Update Magnitude: 0.85137
Collected Steps per Second: 13,253.88595
Overall Steps per Second: 7,278.58573
Timestep Collection Time: 3.77519
Timestep Consumption Time: 3.09922
PPO Batch Consumption Time: 0.22841
Total Iteration Time: 6.87441
Cumulative Model Updates: 156,980
Cumulative Timesteps: 1,238,337,998
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.91152
Policy Entropy: 4.33751
Value Function Loss: 0.00259
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03289
Policy Update Magnitude: 1.03045
Value Function Update Magnitude: 0.83689
Collected Steps per Second: 12,911.17464
Overall Steps per Second: 7,185.75672
Timestep Collection Time: 3.87478
Timestep Consumption Time: 3.08732
PPO Batch Consumption Time: 0.22801
Total Iteration Time: 6.96211
Cumulative Model Updates: 156,989
Cumulative Timesteps: 1,238,388,026
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1238388026...
Checkpoint 1238388026 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.74047
Policy Entropy: 4.34132
Value Function Loss: 0.00254
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03361
Policy Update Magnitude: 1.03204
Value Function Update Magnitude: 0.83776
Collected Steps per Second: 12,634.11336
Overall Steps per Second: 7,128.23725
Timestep Collection Time: 3.95865
Timestep Consumption Time: 3.05767
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 7.01632
Cumulative Model Updates: 156,998
Cumulative Timesteps: 1,238,438,040
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.69687
Policy Entropy: 4.33926
Value Function Loss: 0.00261
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 1.02458
Value Function Update Magnitude: 0.86033
Collected Steps per Second: 13,042.85406
Overall Steps per Second: 7,337.89079
Timestep Collection Time: 3.83658
Timestep Consumption Time: 2.98281
PPO Batch Consumption Time: 0.22840
Total Iteration Time: 6.81940
Cumulative Model Updates: 157,007
Cumulative Timesteps: 1,238,488,080
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1238488080...
Checkpoint 1238488080 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.56400
Policy Entropy: 4.34159
Value Function Loss: 0.00257
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03166
Policy Update Magnitude: 1.01850
Value Function Update Magnitude: 0.83254
Collected Steps per Second: 12,874.07529
Overall Steps per Second: 7,166.78028
Timestep Collection Time: 3.88595
Timestep Consumption Time: 3.09459
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.98054
Cumulative Model Updates: 157,016
Cumulative Timesteps: 1,238,538,108
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.89244
Policy Entropy: 4.34131
Value Function Loss: 0.00262
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03319
Policy Update Magnitude: 1.02018
Value Function Update Magnitude: 0.83496
Collected Steps per Second: 13,028.71204
Overall Steps per Second: 7,225.83756
Timestep Collection Time: 3.84029
Timestep Consumption Time: 3.08403
PPO Batch Consumption Time: 0.22803
Total Iteration Time: 6.92432
Cumulative Model Updates: 157,025
Cumulative Timesteps: 1,238,588,142
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1238588142...
Checkpoint 1238588142 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61230
Policy Entropy: 4.34104
Value Function Loss: 0.00252
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03145
Policy Update Magnitude: 1.01724
Value Function Update Magnitude: 0.82382
Collected Steps per Second: 12,938.15264
Overall Steps per Second: 7,240.13039
Timestep Collection Time: 3.86748
Timestep Consumption Time: 3.04373
PPO Batch Consumption Time: 0.22975
Total Iteration Time: 6.91120
Cumulative Model Updates: 157,034
Cumulative Timesteps: 1,238,638,180
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29580
Policy Entropy: 4.33941
Value Function Loss: 0.00260
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 1.03339
Value Function Update Magnitude: 0.81492
Collected Steps per Second: 13,030.72006
Overall Steps per Second: 7,216.30282
Timestep Collection Time: 3.83893
Timestep Consumption Time: 3.09315
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.93208
Cumulative Model Updates: 157,043
Cumulative Timesteps: 1,238,688,204
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1238688204...
Checkpoint 1238688204 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.74493
Policy Entropy: 4.33787
Value Function Loss: 0.00257
Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 1.03376
Value Function Update Magnitude: 0.83161
Collected Steps per Second: 12,868.91291
Overall Steps per Second: 7,189.50515
Timestep Collection Time: 3.88689
Timestep Consumption Time: 3.07048
PPO Batch Consumption Time: 0.22839
Total Iteration Time: 6.95736
Cumulative Model Updates: 157,052
Cumulative Timesteps: 1,238,738,224
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.25376
Policy Entropy: 4.34045
Value Function Loss: 0.00258
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03428
Policy Update Magnitude: 1.03566
Value Function Update Magnitude: 0.85307
Collected Steps per Second: 12,900.93812
Overall Steps per Second: 7,289.97535
Timestep Collection Time: 3.87770
Timestep Consumption Time: 2.98460
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.86230
Cumulative Model Updates: 157,061
Cumulative Timesteps: 1,238,788,250
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1238788250...
Checkpoint 1238788250 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.11680
Policy Entropy: 4.34060
Value Function Loss: 0.00259
Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03500
Policy Update Magnitude: 1.04044
Value Function Update Magnitude: 0.87506
Collected Steps per Second: 12,863.58189
Overall Steps per Second: 7,149.09053
Timestep Collection Time: 3.88803
Timestep Consumption Time: 3.10782
PPO Batch Consumption Time: 0.22902
Total Iteration Time: 6.99585
Cumulative Model Updates: 157,070
Cumulative Timesteps: 1,238,838,264
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.99371
Policy Entropy: 4.33545
Value Function Loss: 0.00272
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 1.05669
Value Function Update Magnitude: 0.85498
Collected Steps per Second: 13,077.07932
Overall Steps per Second: 7,246.99618
Timestep Collection Time: 3.82532
Timestep Consumption Time: 3.07740
PPO Batch Consumption Time: 0.22844
Total Iteration Time: 6.90272
Cumulative Model Updates: 157,079
Cumulative Timesteps: 1,238,888,288
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1238888288...
Checkpoint 1238888288 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.03963
Policy Entropy: 4.33812
Value Function Loss: 0.00267
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 1.03164
Value Function Update Magnitude: 0.84268
Collected Steps per Second: 12,831.62527
Overall Steps per Second: 7,252.94935
Timestep Collection Time: 3.89849
Timestep Consumption Time: 2.99856
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.89706
Cumulative Model Updates: 157,088
Cumulative Timesteps: 1,238,938,312
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.04823
Policy Entropy: 4.34048
Value Function Loss: 0.00265
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03440
Policy Update Magnitude: 1.01834
Value Function Update Magnitude: 0.83734
Collected Steps per Second: 12,932.52515
Overall Steps per Second: 7,080.55507
Timestep Collection Time: 3.86947
Timestep Consumption Time: 3.19806
PPO Batch Consumption Time: 0.23697
Total Iteration Time: 7.06752
Cumulative Model Updates: 157,097
Cumulative Timesteps: 1,238,988,354
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1238988354...
Checkpoint 1238988354 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27829
Policy Entropy: 4.34398
Value Function Loss: 0.00245
Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03010
Policy Update Magnitude: 1.00971
Value Function Update Magnitude: 0.84397
Collected Steps per Second: 13,068.55582
Overall Steps per Second: 7,255.54030
Timestep Collection Time: 3.82613
Timestep Consumption Time: 3.06543
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.89156
Cumulative Model Updates: 157,106
Cumulative Timesteps: 1,239,038,356
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.48995
Policy Entropy: 4.33970
Value Function Loss: 0.00245
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03084
Policy Update Magnitude: 0.99585
Value Function Update Magnitude: 0.80374
Collected Steps per Second: 13,036.68200
Overall Steps per Second: 7,319.32420
Timestep Collection Time: 3.83855
Timestep Consumption Time: 2.99842
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.83697
Cumulative Model Updates: 157,115
Cumulative Timesteps: 1,239,088,398
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1239088398...
Checkpoint 1239088398 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.79216
Policy Entropy: 4.34016
Value Function Loss: 0.00253
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 1.01031
Value Function Update Magnitude: 0.79303
Collected Steps per Second: 13,213.46092
Overall Steps per Second: 7,268.28671
Timestep Collection Time: 3.78584
Timestep Consumption Time: 3.09667
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.88250
Cumulative Model Updates: 157,124
Cumulative Timesteps: 1,239,138,422
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.91259
Policy Entropy: 4.33534
Value Function Loss: 0.00260
Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03126
Policy Update Magnitude: 1.02556
Value Function Update Magnitude: 0.82184
Collected Steps per Second: 13,090.06863
Overall Steps per Second: 7,233.22671
Timestep Collection Time: 3.82061
Timestep Consumption Time: 3.09360
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.91420
Cumulative Model Updates: 157,133
Cumulative Timesteps: 1,239,188,434
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1239188434...
Checkpoint 1239188434 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06045
Policy Entropy: 4.33609
Value Function Loss: 0.00273
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03285
Policy Update Magnitude: 1.04105
Value Function Update Magnitude: 0.83727
Collected Steps per Second: 12,898.88554
Overall Steps per Second: 7,270.59703
Timestep Collection Time: 3.87816
Timestep Consumption Time: 3.00215
PPO Batch Consumption Time: 0.22815
Total Iteration Time: 6.88032
Cumulative Model Updates: 157,142
Cumulative Timesteps: 1,239,238,458
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.97875
Policy Entropy: 4.33552
Value Function Loss: 0.00280
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03500
Policy Update Magnitude: 1.05587
Value Function Update Magnitude: 0.83942
Collected Steps per Second: 13,222.25161
Overall Steps per Second: 7,271.64557
Timestep Collection Time: 3.78150
Timestep Consumption Time: 3.09452
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.87602
Cumulative Model Updates: 157,151
Cumulative Timesteps: 1,239,288,458
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1239288458...
Checkpoint 1239288458 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10700
Policy Entropy: 4.33835
Value Function Loss: 0.00285
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03350
Policy Update Magnitude: 1.05476
Value Function Update Magnitude: 0.83679
Collected Steps per Second: 13,026.35507
Overall Steps per Second: 7,185.67735
Timestep Collection Time: 3.83853
Timestep Consumption Time: 3.12004
PPO Batch Consumption Time: 0.23049
Total Iteration Time: 6.95856
Cumulative Model Updates: 157,160
Cumulative Timesteps: 1,239,338,460
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.05064
Policy Entropy: 4.34055
Value Function Loss: 0.00272
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03164
Policy Update Magnitude: 1.03656
Value Function Update Magnitude: 0.83844
Collected Steps per Second: 13,021.90661
Overall Steps per Second: 7,298.51527
Timestep Collection Time: 3.84337
Timestep Consumption Time: 3.01392
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 6.85729
Cumulative Model Updates: 157,169
Cumulative Timesteps: 1,239,388,508
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1239388508...
Checkpoint 1239388508 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82639
Policy Entropy: 4.33843
Value Function Loss: 0.00263
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03114
Policy Update Magnitude: 1.02838
Value Function Update Magnitude: 0.81903
Collected Steps per Second: 13,020.90550
Overall Steps per Second: 7,225.05732
Timestep Collection Time: 3.84290
Timestep Consumption Time: 3.08272
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.92562
Cumulative Model Updates: 157,178
Cumulative Timesteps: 1,239,438,546
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.25270
Policy Entropy: 4.33578
Value Function Loss: 0.00260
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03202
Policy Update Magnitude: 1.02360
Value Function Update Magnitude: 0.81545
Collected Steps per Second: 13,130.09580
Overall Steps per Second: 7,284.30945
Timestep Collection Time: 3.81063
Timestep Consumption Time: 3.05810
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.86874
Cumulative Model Updates: 157,187
Cumulative Timesteps: 1,239,488,580
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1239488580...
Checkpoint 1239488580 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.43257
Policy Entropy: 4.33326
Value Function Loss: 0.00271
Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03260
Policy Update Magnitude: 1.04829
Value Function Update Magnitude: 0.80946
Collected Steps per Second: 13,076.89019
Overall Steps per Second: 7,312.08599
Timestep Collection Time: 3.82675
Timestep Consumption Time: 3.01699
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.84374
Cumulative Model Updates: 157,196
Cumulative Timesteps: 1,239,538,622
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.38782
Policy Entropy: 4.33490
Value Function Loss: 0.00281
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 1.06432
Value Function Update Magnitude: 0.80934
Collected Steps per Second: 13,060.00550
Overall Steps per Second: 7,214.12053
Timestep Collection Time: 3.83001
Timestep Consumption Time: 3.10361
PPO Batch Consumption Time: 0.22893
Total Iteration Time: 6.93362
Cumulative Model Updates: 157,205
Cumulative Timesteps: 1,239,588,642
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1239588642...
Checkpoint 1239588642 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.44144
Policy Entropy: 4.33831
Value Function Loss: 0.00266
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03414
Policy Update Magnitude: 1.04123
Value Function Update Magnitude: 0.81452
Collected Steps per Second: 13,032.20921
Overall Steps per Second: 7,208.86395
Timestep Collection Time: 3.83910
Timestep Consumption Time: 3.10124
PPO Batch Consumption Time: 0.22883
Total Iteration Time: 6.94034
Cumulative Model Updates: 157,214
Cumulative Timesteps: 1,239,638,674
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.84103
Policy Entropy: 4.34059
Value Function Loss: 0.00259
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03191
Policy Update Magnitude: 1.02917
Value Function Update Magnitude: 0.80546
Collected Steps per Second: 13,125.15895
Overall Steps per Second: 7,275.66283
Timestep Collection Time: 3.81222
Timestep Consumption Time: 3.06495
PPO Batch Consumption Time: 0.23397
Total Iteration Time: 6.87717
Cumulative Model Updates: 157,223
Cumulative Timesteps: 1,239,688,710
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
Saving checkpoint 1239688710...
Checkpoint 1239688710 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43666
Policy Entropy: 4.34300
Value Function Loss: 0.00260
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03045
Policy Update Magnitude: 1.03426
Value Function Update Magnitude: 0.77345
Collected Steps per Second: 13,076.24404
Overall Steps per Second: 7,214.08139
Timestep Collection Time: 3.82602
Timestep Consumption Time: 3.10903
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.93505
Cumulative Model Updates: 157,232
Cumulative Timesteps: 1,239,738,740
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69330
Policy Entropy: 4.33739
Value Function Loss: 0.00268
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03473
Policy Update Magnitude: 1.04918
Value Function Update Magnitude: 0.81036
Collected Steps per Second: 13,081.88314
Overall Steps per Second: 7,247.02369
Timestep Collection Time: 3.82208
Timestep Consumption Time: 3.07730
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.89938
Cumulative Model Updates: 157,241
Cumulative Timesteps: 1,239,788,740
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1239788740...
Checkpoint 1239788740 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19914
Policy Entropy: 4.33682
Value Function Loss: 0.00262
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03446
Policy Update Magnitude: 1.03956
Value Function Update Magnitude: 0.82481
Collected Steps per Second: 12,821.73796
Overall Steps per Second: 7,250.62019
Timestep Collection Time: 3.90119
Timestep Consumption Time: 2.99753
PPO Batch Consumption Time: 0.22870
Total Iteration Time: 6.89872
Cumulative Model Updates: 157,250
Cumulative Timesteps: 1,239,838,760
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.96517
Policy Entropy: 4.33641
Value Function Loss: 0.00249
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03203
Policy Update Magnitude: 1.01929
Value Function Update Magnitude: 0.80779
Collected Steps per Second: 13,094.15994
Overall Steps per Second: 7,219.49117
Timestep Collection Time: 3.82155
Timestep Consumption Time: 3.10969
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.93124
Cumulative Model Updates: 157,259
Cumulative Timesteps: 1,239,888,800
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1239888800...
Checkpoint 1239888800 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.47990
Policy Entropy: 4.33744
Value Function Loss: 0.00254
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03072
Policy Update Magnitude: 1.01281
Value Function Update Magnitude: 0.78924
Collected Steps per Second: 12,883.13120
Overall Steps per Second: 7,177.34033
Timestep Collection Time: 3.88151
Timestep Consumption Time: 3.08570
PPO Batch Consumption Time: 0.22800
Total Iteration Time: 6.96720
Cumulative Model Updates: 157,268
Cumulative Timesteps: 1,239,938,806
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.60480
Policy Entropy: 4.33897
Value Function Loss: 0.00272
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03165
Policy Update Magnitude: 1.03829
Value Function Update Magnitude: 0.80609
Collected Steps per Second: 13,025.53534
Overall Steps per Second: 7,317.07067
Timestep Collection Time: 3.83923
Timestep Consumption Time: 2.99520
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.83443
Cumulative Model Updates: 157,277
Cumulative Timesteps: 1,239,988,814
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1239988814...
Checkpoint 1239988814 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05404
Policy Entropy: 4.33951
Value Function Loss: 0.00274
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03339
Policy Update Magnitude: 1.04838
Value Function Update Magnitude: 0.83873
Collected Steps per Second: 13,117.77881
Overall Steps per Second: 7,183.42896
Timestep Collection Time: 3.81254
Timestep Consumption Time: 3.14960
PPO Batch Consumption Time: 0.23022
Total Iteration Time: 6.96213
Cumulative Model Updates: 157,286
Cumulative Timesteps: 1,240,038,826
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.04137
Policy Entropy: 4.34106
Value Function Loss: 0.00269
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 1.04460
Value Function Update Magnitude: 0.83257
Collected Steps per Second: 13,029.06889
Overall Steps per Second: 7,199.15827
Timestep Collection Time: 3.83911
Timestep Consumption Time: 3.10893
PPO Batch Consumption Time: 0.22827
Total Iteration Time: 6.94803
Cumulative Model Updates: 157,295
Cumulative Timesteps: 1,240,088,846
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1240088846...
Checkpoint 1240088846 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.95605
Policy Entropy: 4.34069
Value Function Loss: 0.00258
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 1.03996
Value Function Update Magnitude: 0.83417
Collected Steps per Second: 12,920.61029
Overall Steps per Second: 7,281.69847
Timestep Collection Time: 3.87242
Timestep Consumption Time: 2.99878
PPO Batch Consumption Time: 0.22807
Total Iteration Time: 6.87120
Cumulative Model Updates: 157,304
Cumulative Timesteps: 1,240,138,880
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.45595
Policy Entropy: 4.33807
Value Function Loss: 0.00267
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 1.03907
Value Function Update Magnitude: 0.81806
Collected Steps per Second: 13,186.68393
Overall Steps per Second: 7,269.30993
Timestep Collection Time: 3.79186
Timestep Consumption Time: 3.08665
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.87851
Cumulative Model Updates: 157,313
Cumulative Timesteps: 1,240,188,882
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1240188882...
Checkpoint 1240188882 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.91374
Policy Entropy: 4.33853
Value Function Loss: 0.00260
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 1.04813
Value Function Update Magnitude: 0.81059
Collected Steps per Second: 13,114.50403
Overall Steps per Second: 7,213.69163
Timestep Collection Time: 3.81273
Timestep Consumption Time: 3.11882
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.93154
Cumulative Model Updates: 157,322
Cumulative Timesteps: 1,240,238,884
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.07159
Policy Entropy: 4.33517
Value Function Loss: 0.00267
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 1.03976
Value Function Update Magnitude: 0.81233
Collected Steps per Second: 13,049.14840
Overall Steps per Second: 7,310.50626
Timestep Collection Time: 3.83243
Timestep Consumption Time: 3.00841
PPO Batch Consumption Time: 0.22894
Total Iteration Time: 6.84084
Cumulative Model Updates: 157,331
Cumulative Timesteps: 1,240,288,894
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1240288894...
Checkpoint 1240288894 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97291
Policy Entropy: 4.33769
Value Function Loss: 0.00265
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 1.03419
Value Function Update Magnitude: 0.82620
Collected Steps per Second: 13,090.56078
Overall Steps per Second: 7,216.84781
Timestep Collection Time: 3.82184
Timestep Consumption Time: 3.11055
PPO Batch Consumption Time: 0.22805
Total Iteration Time: 6.93239
Cumulative Model Updates: 157,340
Cumulative Timesteps: 1,240,338,924
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.32226
Policy Entropy: 4.33681
Value Function Loss: 0.00269
Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03451
Policy Update Magnitude: 1.03703
Value Function Update Magnitude: 0.84187
Collected Steps per Second: 12,931.88975
Overall Steps per Second: 7,117.81185
Timestep Collection Time: 3.86904
Timestep Consumption Time: 3.16037
PPO Batch Consumption Time: 0.23051
Total Iteration Time: 7.02941
Cumulative Model Updates: 157,349
Cumulative Timesteps: 1,240,388,958
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1240388958...
Checkpoint 1240388958 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.65068
Policy Entropy: 4.33839
Value Function Loss: 0.00256
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03392
Policy Update Magnitude: 1.01066
Value Function Update Magnitude: 0.81874
Collected Steps per Second: 13,048.16700
Overall Steps per Second: 7,305.54930
Timestep Collection Time: 3.83380
Timestep Consumption Time: 3.01360
PPO Batch Consumption Time: 0.22903
Total Iteration Time: 6.84740
Cumulative Model Updates: 157,358
Cumulative Timesteps: 1,240,438,982
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.33805
Policy Entropy: 4.33534
Value Function Loss: 0.00261
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03172
Policy Update Magnitude: 1.01465
Value Function Update Magnitude: 0.83917
Collected Steps per Second: 13,099.36578
Overall Steps per Second: 7,218.15728
Timestep Collection Time: 3.81835
Timestep Consumption Time: 3.11112
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.92947
Cumulative Model Updates: 157,367
Cumulative Timesteps: 1,240,489,000
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1240489000...
Checkpoint 1240489000 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.64447
Policy Entropy: 4.33354
Value Function Loss: 0.00269
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03330
Policy Update Magnitude: 1.03752
Value Function Update Magnitude: 0.85638
Collected Steps per Second: 13,080.29901
Overall Steps per Second: 7,220.19816
Timestep Collection Time: 3.82392
Timestep Consumption Time: 3.10359
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.92751
Cumulative Model Updates: 157,376
Cumulative Timesteps: 1,240,539,018
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.31153
Policy Entropy: 4.33119
Value Function Loss: 0.00282
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03438
Policy Update Magnitude: 1.06313
Value Function Update Magnitude: 0.88189
Collected Steps per Second: 13,125.56087
Overall Steps per Second: 7,331.11205
Timestep Collection Time: 3.80951
Timestep Consumption Time: 3.01101
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.82052
Cumulative Model Updates: 157,385
Cumulative Timesteps: 1,240,589,020
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1240589020...
Checkpoint 1240589020 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.04915
Policy Entropy: 4.32859
Value Function Loss: 0.00275
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03602
Policy Update Magnitude: 1.04430
Value Function Update Magnitude: 0.88252
Collected Steps per Second: 13,157.55635
Overall Steps per Second: 7,234.59720
Timestep Collection Time: 3.80283
Timestep Consumption Time: 3.11338
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.91621
Cumulative Model Updates: 157,394
Cumulative Timesteps: 1,240,639,056
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.42728
Policy Entropy: 4.32886
Value Function Loss: 0.00265
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03418
Policy Update Magnitude: 1.02597
Value Function Update Magnitude: 0.83915
Collected Steps per Second: 13,192.20269
Overall Steps per Second: 7,277.36411
Timestep Collection Time: 3.79239
Timestep Consumption Time: 3.08235
PPO Batch Consumption Time: 0.22905
Total Iteration Time: 6.87474
Cumulative Model Updates: 157,403
Cumulative Timesteps: 1,240,689,086
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1240689086...
Checkpoint 1240689086 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60436
Policy Entropy: 4.32971
Value Function Loss: 0.00268
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03358
Policy Update Magnitude: 1.03682
Value Function Update Magnitude: 0.80751
Collected Steps per Second: 13,078.66729
Overall Steps per Second: 7,199.11216
Timestep Collection Time: 3.82455
Timestep Consumption Time: 3.12353
PPO Batch Consumption Time: 0.23751
Total Iteration Time: 6.94808
Cumulative Model Updates: 157,412
Cumulative Timesteps: 1,240,739,106
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31525
Policy Entropy: 4.33841
Value Function Loss: 0.00259
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03246
Policy Update Magnitude: 1.01429
Value Function Update Magnitude: 0.81678
Collected Steps per Second: 13,122.94751
Overall Steps per Second: 7,229.00292
Timestep Collection Time: 3.81210
Timestep Consumption Time: 3.10808
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.92018
Cumulative Model Updates: 157,421
Cumulative Timesteps: 1,240,789,132
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1240789132...
Checkpoint 1240789132 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.33648
Policy Entropy: 4.33741
Value Function Loss: 0.00266
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03092
Policy Update Magnitude: 1.01012
Value Function Update Magnitude: 0.80852
Collected Steps per Second: 12,956.64579
Overall Steps per Second: 7,167.83859
Timestep Collection Time: 3.85964
Timestep Consumption Time: 3.11708
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.97672
Cumulative Model Updates: 157,430
Cumulative Timesteps: 1,240,839,140
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.89946
Policy Entropy: 4.33813
Value Function Loss: 0.00260
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03150
Policy Update Magnitude: 1.01525
Value Function Update Magnitude: 0.80963
Collected Steps per Second: 12,952.53012
Overall Steps per Second: 7,289.95139
Timestep Collection Time: 3.86087
Timestep Consumption Time: 2.99899
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 6.85985
Cumulative Model Updates: 157,439
Cumulative Timesteps: 1,240,889,148
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1240889148...
Checkpoint 1240889148 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.83826
Policy Entropy: 4.33469
Value Function Loss: 0.00267
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03494
Policy Update Magnitude: 1.00196
Value Function Update Magnitude: 0.81232
Collected Steps per Second: 13,078.95391
Overall Steps per Second: 7,228.19494
Timestep Collection Time: 3.82370
Timestep Consumption Time: 3.09504
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.91874
Cumulative Model Updates: 157,448
Cumulative Timesteps: 1,240,939,158
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.46353
Policy Entropy: 4.33136
Value Function Loss: 0.00276
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 1.02304
Value Function Update Magnitude: 0.84534
Collected Steps per Second: 13,160.11106
Overall Steps per Second: 7,248.44322
Timestep Collection Time: 3.80134
Timestep Consumption Time: 3.10028
PPO Batch Consumption Time: 0.22810
Total Iteration Time: 6.90162
Cumulative Model Updates: 157,457
Cumulative Timesteps: 1,240,989,184
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1240989184...
Checkpoint 1240989184 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.99647
Policy Entropy: 4.32867
Value Function Loss: 0.00288
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03601
Policy Update Magnitude: 1.04149
Value Function Update Magnitude: 0.85654
Collected Steps per Second: 12,923.02718
Overall Steps per Second: 7,206.89217
Timestep Collection Time: 3.86953
Timestep Consumption Time: 3.06911
PPO Batch Consumption Time: 0.22900
Total Iteration Time: 6.93864
Cumulative Model Updates: 157,466
Cumulative Timesteps: 1,241,039,190
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.29521
Policy Entropy: 4.32595
Value Function Loss: 0.00305
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03694
Policy Update Magnitude: 1.05187
Value Function Update Magnitude: 0.88061
Collected Steps per Second: 13,199.93575
Overall Steps per Second: 7,212.58629
Timestep Collection Time: 3.78956
Timestep Consumption Time: 3.14581
PPO Batch Consumption Time: 0.23285
Total Iteration Time: 6.93538
Cumulative Model Updates: 157,475
Cumulative Timesteps: 1,241,089,212
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1241089212...
Checkpoint 1241089212 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.72381
Policy Entropy: 4.33380
Value Function Loss: 0.00285
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 1.02486
Value Function Update Magnitude: 0.88283
Collected Steps per Second: 12,925.66411
Overall Steps per Second: 7,176.75152
Timestep Collection Time: 3.87230
Timestep Consumption Time: 3.10189
PPO Batch Consumption Time: 0.22956
Total Iteration Time: 6.97419
Cumulative Model Updates: 157,484
Cumulative Timesteps: 1,241,139,264
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.98498
Policy Entropy: 4.33637
Value Function Loss: 0.00278
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03262
Policy Update Magnitude: 1.01574
Value Function Update Magnitude: 0.90582
Collected Steps per Second: 12,950.25170
Overall Steps per Second: 7,201.83819
Timestep Collection Time: 3.86417
Timestep Consumption Time: 3.08433
PPO Batch Consumption Time: 0.22835
Total Iteration Time: 6.94850
Cumulative Model Updates: 157,493
Cumulative Timesteps: 1,241,189,306
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
Saving checkpoint 1241189306...
Checkpoint 1241189306 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05618
Policy Entropy: 4.33720
Value Function Loss: 0.00269
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 1.00157
Value Function Update Magnitude: 0.89396
Collected Steps per Second: 13,008.28184
Overall Steps per Second: 7,196.76328
Timestep Collection Time: 3.84447
Timestep Consumption Time: 3.10448
PPO Batch Consumption Time: 0.22897
Total Iteration Time: 6.94896
Cumulative Model Updates: 157,502
Cumulative Timesteps: 1,241,239,316
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.84647
Policy Entropy: 4.33482
Value Function Loss: 0.00267
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03524
Policy Update Magnitude: 0.99364
Value Function Update Magnitude: 0.86133
Collected Steps per Second: 13,006.99046
Overall Steps per Second: 7,181.67200
Timestep Collection Time: 3.84439
Timestep Consumption Time: 3.11833
PPO Batch Consumption Time: 0.22884
Total Iteration Time: 6.96272
Cumulative Model Updates: 157,511
Cumulative Timesteps: 1,241,289,320
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1241289320...
Checkpoint 1241289320 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.23463
Policy Entropy: 4.33389
Value Function Loss: 0.00264
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03495
Policy Update Magnitude: 0.98674
Value Function Update Magnitude: 0.83087
Collected Steps per Second: 12,818.07448
Overall Steps per Second: 7,171.21294
Timestep Collection Time: 3.90293
Timestep Consumption Time: 3.07330
PPO Batch Consumption Time: 0.22865
Total Iteration Time: 6.97623
Cumulative Model Updates: 157,520
Cumulative Timesteps: 1,241,339,348
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.43487
Policy Entropy: 4.33258
Value Function Loss: 0.00265
Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03548
Policy Update Magnitude: 0.98764
Value Function Update Magnitude: 0.83870
Collected Steps per Second: 13,278.07510
Overall Steps per Second: 7,268.29146
Timestep Collection Time: 3.76651
Timestep Consumption Time: 3.11434
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.88085
Cumulative Model Updates: 157,529
Cumulative Timesteps: 1,241,389,360
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1241389360...
Checkpoint 1241389360 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.75315
Policy Entropy: 4.33367
Value Function Loss: 0.00267
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 0.99478
Value Function Update Magnitude: 0.85832
Collected Steps per Second: 12,971.33606
Overall Steps per Second: 7,142.92969
Timestep Collection Time: 3.85512
Timestep Consumption Time: 3.14565
PPO Batch Consumption Time: 0.23375
Total Iteration Time: 7.00077
Cumulative Model Updates: 157,538
Cumulative Timesteps: 1,241,439,366
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.87776
Policy Entropy: 4.33250
Value Function Loss: 0.00280
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 1.00619
Value Function Update Magnitude: 0.85073
Collected Steps per Second: 12,880.89020
Overall Steps per Second: 7,262.61776
Timestep Collection Time: 3.88219
Timestep Consumption Time: 3.00321
PPO Batch Consumption Time: 0.22818
Total Iteration Time: 6.88540
Cumulative Model Updates: 157,547
Cumulative Timesteps: 1,241,489,372
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1241489372...
Checkpoint 1241489372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.48585
Policy Entropy: 4.33345
Value Function Loss: 0.00277
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03368
Policy Update Magnitude: 1.02206
Value Function Update Magnitude: 0.82411
Collected Steps per Second: 13,022.05705
Overall Steps per Second: 7,208.49695
Timestep Collection Time: 3.84225
Timestep Consumption Time: 3.09873
PPO Batch Consumption Time: 0.22830
Total Iteration Time: 6.94098
Cumulative Model Updates: 157,556
Cumulative Timesteps: 1,241,539,406
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13720
Policy Entropy: 4.33375
Value Function Loss: 0.00268
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03328
Policy Update Magnitude: 1.00719
Value Function Update Magnitude: 0.82711
Collected Steps per Second: 12,936.97320
Overall Steps per Second: 7,168.62876
Timestep Collection Time: 3.86752
Timestep Consumption Time: 3.11206
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.97958
Cumulative Model Updates: 157,565
Cumulative Timesteps: 1,241,589,440
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1241589440...
Checkpoint 1241589440 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.32060
Policy Entropy: 4.34224
Value Function Loss: 0.00266
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03171
Policy Update Magnitude: 0.99001
Value Function Update Magnitude: 0.82935
Collected Steps per Second: 12,678.09084
Overall Steps per Second: 7,111.87859
Timestep Collection Time: 3.94602
Timestep Consumption Time: 3.08841
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 7.03443
Cumulative Model Updates: 157,574
Cumulative Timesteps: 1,241,639,468
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.41208
Policy Entropy: 4.34545
Value Function Loss: 0.00257
Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03023
Policy Update Magnitude: 0.96945
Value Function Update Magnitude: 0.83000
Collected Steps per Second: 13,263.05088
Overall Steps per Second: 7,301.28482
Timestep Collection Time: 3.77244
Timestep Consumption Time: 3.08033
PPO Batch Consumption Time: 0.22824
Total Iteration Time: 6.85277
Cumulative Model Updates: 157,583
Cumulative Timesteps: 1,241,689,502
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1241689502...
Checkpoint 1241689502 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.09211
Policy Entropy: 4.34263
Value Function Loss: 0.00264
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 0.99297
Value Function Update Magnitude: 0.84255
Collected Steps per Second: 13,021.07941
Overall Steps per Second: 7,191.24886
Timestep Collection Time: 3.84146
Timestep Consumption Time: 3.11421
PPO Batch Consumption Time: 0.22881
Total Iteration Time: 6.95568
Cumulative Model Updates: 157,592
Cumulative Timesteps: 1,241,739,522
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.81992
Policy Entropy: 4.34235
Value Function Loss: 0.00267
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03310
Policy Update Magnitude: 1.01060
Value Function Update Magnitude: 0.85750
Collected Steps per Second: 12,829.77159
Overall Steps per Second: 7,104.02796
Timestep Collection Time: 3.89984
Timestep Consumption Time: 3.14321
PPO Batch Consumption Time: 0.23091
Total Iteration Time: 7.04305
Cumulative Model Updates: 157,601
Cumulative Timesteps: 1,241,789,556
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1241789556...
Checkpoint 1241789556 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.48496
Policy Entropy: 4.34106
Value Function Loss: 0.00276
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 1.03188
Value Function Update Magnitude: 0.87004
Collected Steps per Second: 13,173.94955
Overall Steps per Second: 7,246.55878
Timestep Collection Time: 3.79825
Timestep Consumption Time: 3.10682
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.90507
Cumulative Model Updates: 157,610
Cumulative Timesteps: 1,241,839,594
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50067
Policy Entropy: 4.34230
Value Function Loss: 0.00280
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03269
Policy Update Magnitude: 1.02461
Value Function Update Magnitude: 0.86155
Collected Steps per Second: 13,057.91058
Overall Steps per Second: 7,213.30819
Timestep Collection Time: 3.83216
Timestep Consumption Time: 3.10502
PPO Batch Consumption Time: 0.22889
Total Iteration Time: 6.93718
Cumulative Model Updates: 157,619
Cumulative Timesteps: 1,241,889,634
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1241889634...
Checkpoint 1241889634 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.41388
Policy Entropy: 4.34321
Value Function Loss: 0.00276
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03374
Policy Update Magnitude: 1.01251
Value Function Update Magnitude: 0.82829
Collected Steps per Second: 12,873.20954
Overall Steps per Second: 7,199.46373
Timestep Collection Time: 3.88637
Timestep Consumption Time: 3.06276
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.94913
Cumulative Model Updates: 157,628
Cumulative Timesteps: 1,241,939,664
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.81249
Policy Entropy: 4.34271
Value Function Loss: 0.00286
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03350
Policy Update Magnitude: 1.02169
Value Function Update Magnitude: 0.85454
Collected Steps per Second: 12,950.60774
Overall Steps per Second: 7,290.00975
Timestep Collection Time: 3.86376
Timestep Consumption Time: 3.00016
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.86391
Cumulative Model Updates: 157,637
Cumulative Timesteps: 1,241,989,702
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1241989702...
Checkpoint 1241989702 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.10304
Policy Entropy: 4.34289
Value Function Loss: 0.00279
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03386
Policy Update Magnitude: 1.01258
Value Function Update Magnitude: 0.84436
Collected Steps per Second: 12,755.87681
Overall Steps per Second: 7,124.15855
Timestep Collection Time: 3.92149
Timestep Consumption Time: 3.09997
PPO Batch Consumption Time: 0.22909
Total Iteration Time: 7.02146
Cumulative Model Updates: 157,646
Cumulative Timesteps: 1,242,039,724
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.11929
Policy Entropy: 4.33927
Value Function Loss: 0.00283
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 1.02627
Value Function Update Magnitude: 0.84762
Collected Steps per Second: 13,059.61956
Overall Steps per Second: 7,252.73041
Timestep Collection Time: 3.83227
Timestep Consumption Time: 3.06830
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.90057
Cumulative Model Updates: 157,655
Cumulative Timesteps: 1,242,089,772
Timesteps Collected: 50,048
--------END ITERATION REPORT--------
Saving checkpoint 1242089772...
Checkpoint 1242089772 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44860
Policy Entropy: 4.33576
Value Function Loss: 0.00279
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 1.04566
Value Function Update Magnitude: 0.85388
Collected Steps per Second: 12,942.21075
Overall Steps per Second: 7,228.96411
Timestep Collection Time: 3.86425
Timestep Consumption Time: 3.05403
PPO Batch Consumption Time: 0.22951
Total Iteration Time: 6.91828
Cumulative Model Updates: 157,664
Cumulative Timesteps: 1,242,139,784
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.72577
Policy Entropy: 4.33302
Value Function Loss: 0.00281
Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03419
Policy Update Magnitude: 1.04208
Value Function Update Magnitude: 0.88419
Collected Steps per Second: 13,051.64183
Overall Steps per Second: 7,215.04511
Timestep Collection Time: 3.83155
Timestep Consumption Time: 3.09952
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.93107
Cumulative Model Updates: 157,673
Cumulative Timesteps: 1,242,189,792
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1242189792...
Checkpoint 1242189792 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.59125
Policy Entropy: 4.33459
Value Function Loss: 0.00273
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03280
Policy Update Magnitude: 1.04994
Value Function Update Magnitude: 0.92074
Collected Steps per Second: 12,985.34060
Overall Steps per Second: 7,221.97493
Timestep Collection Time: 3.85250
Timestep Consumption Time: 3.07442
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.92691
Cumulative Model Updates: 157,682
Cumulative Timesteps: 1,242,239,818
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.70443
Policy Entropy: 4.33939
Value Function Loss: 0.00256
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03256
Policy Update Magnitude: 1.01488
Value Function Update Magnitude: 0.91581
Collected Steps per Second: 12,942.08189
Overall Steps per Second: 7,288.64270
Timestep Collection Time: 3.86352
Timestep Consumption Time: 2.99674
PPO Batch Consumption Time: 0.22843
Total Iteration Time: 6.86026
Cumulative Model Updates: 157,691
Cumulative Timesteps: 1,242,289,820
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1242289820...
Checkpoint 1242289820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.86850
Policy Entropy: 4.34074
Value Function Loss: 0.00253
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 1.01115
Value Function Update Magnitude: 0.86772
Collected Steps per Second: 12,918.01280
Overall Steps per Second: 7,160.81646
Timestep Collection Time: 3.87149
Timestep Consumption Time: 3.11263
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.98412
Cumulative Model Updates: 157,700
Cumulative Timesteps: 1,242,339,832
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.71314
Policy Entropy: 4.33874
Value Function Loss: 0.00256
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03293
Policy Update Magnitude: 1.01352
Value Function Update Magnitude: 0.85195
Collected Steps per Second: 13,003.45994
Overall Steps per Second: 7,239.62879
Timestep Collection Time: 3.84605
Timestep Consumption Time: 3.06204
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.90809
Cumulative Model Updates: 157,709
Cumulative Timesteps: 1,242,389,844
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1242389844...
Checkpoint 1242389844 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.07892
Policy Entropy: 4.34069
Value Function Loss: 0.00264
Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03522
Policy Update Magnitude: 1.02109
Value Function Update Magnitude: 0.83511
Collected Steps per Second: 12,760.22765
Overall Steps per Second: 7,237.79078
Timestep Collection Time: 3.91890
Timestep Consumption Time: 2.99012
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 6.90901
Cumulative Model Updates: 157,718
Cumulative Timesteps: 1,242,439,850
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12645
Policy Entropy: 4.34234
Value Function Loss: 0.00267
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03420
Policy Update Magnitude: 1.01578
Value Function Update Magnitude: 0.84199
Collected Steps per Second: 12,880.33530
Overall Steps per Second: 7,013.33265
Timestep Collection Time: 3.88328
Timestep Consumption Time: 3.24856
PPO Batch Consumption Time: 0.23939
Total Iteration Time: 7.13184
Cumulative Model Updates: 157,727
Cumulative Timesteps: 1,242,489,868
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1242489868...
Checkpoint 1242489868 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.69329
Policy Entropy: 4.34356
Value Function Loss: 0.00261
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03423
Policy Update Magnitude: 1.02339
Value Function Update Magnitude: 0.86577
Collected Steps per Second: 12,846.16811
Overall Steps per Second: 7,151.71106
Timestep Collection Time: 3.89688
Timestep Consumption Time: 3.10284
PPO Batch Consumption Time: 0.22785
Total Iteration Time: 6.99972
Cumulative Model Updates: 157,736
Cumulative Timesteps: 1,242,539,928
Timesteps Collected: 50,060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.00328
Policy Entropy: 4.34135
Value Function Loss: 0.00264
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03320
Policy Update Magnitude: 1.03550
Value Function Update Magnitude: 0.87586
Collected Steps per Second: 12,825.62853
Overall Steps per Second: 7,184.73912
Timestep Collection Time: 3.90000
Timestep Consumption Time: 3.06197
PPO Batch Consumption Time: 0.22828
Total Iteration Time: 6.96198
Cumulative Model Updates: 157,745
Cumulative Timesteps: 1,242,589,948
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1242589948...
Checkpoint 1242589948 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.19076
Policy Entropy: 4.34059
Value Function Loss: 0.00268
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 1.02184
Value Function Update Magnitude: 0.87140
Collected Steps per Second: 13,118.91490
Overall Steps per Second: 7,250.81848
Timestep Collection Time: 3.81358
Timestep Consumption Time: 3.08633
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.89991
Cumulative Model Updates: 157,754
Cumulative Timesteps: 1,242,639,978
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.15846
Policy Entropy: 4.34007
Value Function Loss: 0.00279
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03304
Policy Update Magnitude: 1.02675
Value Function Update Magnitude: 0.86425
Collected Steps per Second: 12,953.67302
Overall Steps per Second: 7,168.75896
Timestep Collection Time: 3.86300
Timestep Consumption Time: 3.11729
PPO Batch Consumption Time: 0.22831
Total Iteration Time: 6.98029
Cumulative Model Updates: 157,763
Cumulative Timesteps: 1,242,690,018
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1242690018...
Checkpoint 1242690018 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.03028
Policy Entropy: 4.33760
Value Function Loss: 0.00285
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03330
Policy Update Magnitude: 1.05735
Value Function Update Magnitude: 0.87311
Collected Steps per Second: 12,828.64888
Overall Steps per Second: 7,177.33273
Timestep Collection Time: 3.90033
Timestep Consumption Time: 3.07106
PPO Batch Consumption Time: 0.22848
Total Iteration Time: 6.97139
Cumulative Model Updates: 157,772
Cumulative Timesteps: 1,242,740,054
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.20828
Policy Entropy: 4.33279
Value Function Loss: 0.00277
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03579
Policy Update Magnitude: 1.04997
Value Function Update Magnitude: 0.86789
Collected Steps per Second: 13,196.76082
Overall Steps per Second: 7,261.99699
Timestep Collection Time: 3.78987
Timestep Consumption Time: 3.09722
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.88709
Cumulative Model Updates: 157,781
Cumulative Timesteps: 1,242,790,068
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 1242790068...
Checkpoint 1242790068 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.65797
Policy Entropy: 4.33293
Value Function Loss: 0.00273
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 1.03376
Value Function Update Magnitude: 0.85983
Collected Steps per Second: 12,699.81864
Overall Steps per Second: 6,964.29427
Timestep Collection Time: 3.93974
Timestep Consumption Time: 3.24462
PPO Batch Consumption Time: 0.23794
Total Iteration Time: 7.18436
Cumulative Model Updates: 157,790
Cumulative Timesteps: 1,242,840,102
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66022
Policy Entropy: 4.33353
Value Function Loss: 0.00265
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03364
Policy Update Magnitude: 1.01517
Value Function Update Magnitude: 0.84866
Collected Steps per Second: 12,948.85361
Overall Steps per Second: 7,199.29397
Timestep Collection Time: 3.86196
Timestep Consumption Time: 3.08427
PPO Batch Consumption Time: 0.22929
Total Iteration Time: 6.94624
Cumulative Model Updates: 157,799
Cumulative Timesteps: 1,242,890,110
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1242890110...
Checkpoint 1242890110 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42735
Policy Entropy: 4.33508
Value Function Loss: 0.00268
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 1.00016
Value Function Update Magnitude: 0.86352
Collected Steps per Second: 13,432.16737
Overall Steps per Second: 7,330.68029
Timestep Collection Time: 3.72479
Timestep Consumption Time: 3.10022
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.82501
Cumulative Model Updates: 157,808
Cumulative Timesteps: 1,242,940,142
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.94927
Policy Entropy: 4.33768
Value Function Loss: 0.00266
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.99317
Value Function Update Magnitude: 0.87488
Collected Steps per Second: 12,885.90856
Overall Steps per Second: 7,163.82509
Timestep Collection Time: 3.88067
Timestep Consumption Time: 3.09968
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.98035
Cumulative Model Updates: 157,817
Cumulative Timesteps: 1,242,990,148
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1242990148...
Checkpoint 1242990148 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.13826
Policy Entropy: 4.33763
Value Function Loss: 0.00257
Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 0.98371
Value Function Update Magnitude: 0.85981
Collected Steps per Second: 13,045.54244
Overall Steps per Second: 7,238.91696
Timestep Collection Time: 3.83457
Timestep Consumption Time: 3.07586
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.91043
Cumulative Model Updates: 157,826
Cumulative Timesteps: 1,243,040,172
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.99392
Policy Entropy: 4.33807
Value Function Loss: 0.00252
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03066
Policy Update Magnitude: 0.98015
Value Function Update Magnitude: 0.81958
Collected Steps per Second: 13,225.95690
Overall Steps per Second: 7,273.46245
Timestep Collection Time: 3.78044
Timestep Consumption Time: 3.09386
PPO Batch Consumption Time: 0.22802
Total Iteration Time: 6.87431
Cumulative Model Updates: 157,835
Cumulative Timesteps: 1,243,090,172
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1243090172...
Checkpoint 1243090172 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36958
Policy Entropy: 4.33572
Value Function Loss: 0.00251
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.99498
Value Function Update Magnitude: 0.80189
Collected Steps per Second: 12,892.41594
Overall Steps per Second: 7,156.26605
Timestep Collection Time: 3.87949
Timestep Consumption Time: 3.10963
PPO Batch Consumption Time: 0.22837
Total Iteration Time: 6.98912
Cumulative Model Updates: 157,844
Cumulative Timesteps: 1,243,140,188
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.85886
Policy Entropy: 4.33613
Value Function Loss: 0.00266
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 0.98962
Value Function Update Magnitude: 0.82351
Collected Steps per Second: 13,038.20906
Overall Steps per Second: 7,076.80521
Timestep Collection Time: 3.83872
Timestep Consumption Time: 3.23368
PPO Batch Consumption Time: 0.24165
Total Iteration Time: 7.07240
Cumulative Model Updates: 157,853
Cumulative Timesteps: 1,243,190,238
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1243190238...
Checkpoint 1243190238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.40913
Policy Entropy: 4.33850
Value Function Loss: 0.00256
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03420
Policy Update Magnitude: 0.99603
Value Function Update Magnitude: 0.82954
Collected Steps per Second: 12,838.99589
Overall Steps per Second: 7,244.83893
Timestep Collection Time: 3.89657
Timestep Consumption Time: 3.00876
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.90533
Cumulative Model Updates: 157,862
Cumulative Timesteps: 1,243,240,266
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.52938
Policy Entropy: 4.34179
Value Function Loss: 0.00250
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03138
Policy Update Magnitude: 0.97419
Value Function Update Magnitude: 0.83478
Collected Steps per Second: 13,193.37375
Overall Steps per Second: 7,254.42220
Timestep Collection Time: 3.79175
Timestep Consumption Time: 3.10418
PPO Batch Consumption Time: 0.22868
Total Iteration Time: 6.89593
Cumulative Model Updates: 157,871
Cumulative Timesteps: 1,243,290,292
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1243290292...
Checkpoint 1243290292 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.31353
Policy Entropy: 4.34068
Value Function Loss: 0.00245
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03042
Policy Update Magnitude: 0.98031
Value Function Update Magnitude: 0.85084
Collected Steps per Second: 13,025.45219
Overall Steps per Second: 7,192.34390
Timestep Collection Time: 3.83956
Timestep Consumption Time: 3.11395
PPO Batch Consumption Time: 0.22816
Total Iteration Time: 6.95351
Cumulative Model Updates: 157,880
Cumulative Timesteps: 1,243,340,304
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.74980
Policy Entropy: 4.34074
Value Function Loss: 0.00256
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03234
Policy Update Magnitude: 0.99351
Value Function Update Magnitude: 0.85736
Collected Steps per Second: 12,918.13968
Overall Steps per Second: 7,282.25446
Timestep Collection Time: 3.87238
Timestep Consumption Time: 2.99692
PPO Batch Consumption Time: 0.22847
Total Iteration Time: 6.86930
Cumulative Model Updates: 157,889
Cumulative Timesteps: 1,243,390,328
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 1243390328...
Checkpoint 1243390328 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.51637
Policy Entropy: 4.34047
Value Function Loss: 0.00265
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 0.99787
Value Function Update Magnitude: 0.85832
Collected Steps per Second: 12,999.08651
Overall Steps per Second: 7,187.96349
Timestep Collection Time: 3.84689
Timestep Consumption Time: 3.11002
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.95691
Cumulative Model Updates: 157,898
Cumulative Timesteps: 1,243,440,334
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.29866
Policy Entropy: 4.34269
Value Function Loss: 0.00260
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03234
Policy Update Magnitude: 0.98753
Value Function Update Magnitude: 0.84012
Collected Steps per Second: 12,968.50937
Overall Steps per Second: 7,223.04485
Timestep Collection Time: 3.85842
Timestep Consumption Time: 3.06913
PPO Batch Consumption Time: 0.22851
Total Iteration Time: 6.92755
Cumulative Model Updates: 157,907
Cumulative Timesteps: 1,243,490,372
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1243490372...
Checkpoint 1243490372 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.66954
Policy Entropy: 4.33660
Value Function Loss: 0.00261
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03085
Policy Update Magnitude: 0.98950
Value Function Update Magnitude: 0.81803
Collected Steps per Second: 12,968.39953
Overall Steps per Second: 7,214.38928
Timestep Collection Time: 3.85568
Timestep Consumption Time: 3.07519
PPO Batch Consumption Time: 0.23303
Total Iteration Time: 6.93087
Cumulative Model Updates: 157,916
Cumulative Timesteps: 1,243,540,374
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.07858
Policy Entropy: 4.33446
Value Function Loss: 0.00260
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03396
Policy Update Magnitude: 0.98817
Value Function Update Magnitude: 0.81266
Collected Steps per Second: 12,942.97909
Overall Steps per Second: 7,172.16379
Timestep Collection Time: 3.86464
Timestep Consumption Time: 3.10954
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.97419
Cumulative Model Updates: 157,925
Cumulative Timesteps: 1,243,590,394
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1243590394...
Checkpoint 1243590394 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56613
Policy Entropy: 4.33447
Value Function Loss: 0.00250
Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 0.98247
Value Function Update Magnitude: 0.81742
Collected Steps per Second: 12,798.50112
Overall Steps per Second: 7,178.80456
Timestep Collection Time: 3.90905
Timestep Consumption Time: 3.06008
PPO Batch Consumption Time: 0.22891
Total Iteration Time: 6.96913
Cumulative Model Updates: 157,934
Cumulative Timesteps: 1,243,640,424
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25679
Policy Entropy: 4.33918
Value Function Loss: 0.00252
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03312
Policy Update Magnitude: 0.97184
Value Function Update Magnitude: 0.80612
Collected Steps per Second: 12,941.75126
Overall Steps per Second: 7,295.96118
Timestep Collection Time: 3.86640
Timestep Consumption Time: 2.99191
PPO Batch Consumption Time: 0.22798
Total Iteration Time: 6.85831
Cumulative Model Updates: 157,943
Cumulative Timesteps: 1,243,690,462
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1243690462...
Checkpoint 1243690462 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76933
Policy Entropy: 4.33692
Value Function Loss: 0.00261
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03136
Policy Update Magnitude: 0.97895
Value Function Update Magnitude: 0.81101
Collected Steps per Second: 12,911.53118
Overall Steps per Second: 7,139.42880
Timestep Collection Time: 3.87437
Timestep Consumption Time: 3.13236
PPO Batch Consumption Time: 0.22882
Total Iteration Time: 7.00672
Cumulative Model Updates: 157,952
Cumulative Timesteps: 1,243,740,486
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53370
Policy Entropy: 4.33654
Value Function Loss: 0.00260
Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 0.98225
Value Function Update Magnitude: 0.81809
Collected Steps per Second: 13,023.78809
Overall Steps per Second: 7,240.69680
Timestep Collection Time: 3.83959
Timestep Consumption Time: 3.06665
PPO Batch Consumption Time: 0.22806
Total Iteration Time: 6.90624
Cumulative Model Updates: 157,961
Cumulative Timesteps: 1,243,790,492
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1243790492...
Checkpoint 1243790492 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.92130
Policy Entropy: 4.34155
Value Function Loss: 0.00245
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03192
Policy Update Magnitude: 0.96401
Value Function Update Magnitude: 0.82567
Collected Steps per Second: 12,946.10229
Overall Steps per Second: 7,289.86391
Timestep Collection Time: 3.86217
Timestep Consumption Time: 2.99667
PPO Batch Consumption Time: 0.22820
Total Iteration Time: 6.85884
Cumulative Model Updates: 157,970
Cumulative Timesteps: 1,243,840,492
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 19.24605
Policy Entropy: 4.34576
Value Function Loss: 0.00235
Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 0.94478
Value Function Update Magnitude: 0.81689
Collected Steps per Second: 13,011.51847
Overall Steps per Second: 7,146.40365
Timestep Collection Time: 3.84690
Timestep Consumption Time: 3.15718
PPO Batch Consumption Time: 0.22979
Total Iteration Time: 7.00408
Cumulative Model Updates: 157,979
Cumulative Timesteps: 1,243,890,546
Timesteps Collected: 50,054
--------END ITERATION REPORT--------
Saving checkpoint 1243890546...
Checkpoint 1243890546 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22057
Policy Entropy: 4.34162
Value Function Loss: 0.00240
Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02883
Policy Update Magnitude: 0.94329
Value Function Update Magnitude: 0.80136
Collected Steps per Second: 13,020.28575
Overall Steps per Second: 7,212.07098
Timestep Collection Time: 3.84262
Timestep Consumption Time: 3.09464
PPO Batch Consumption Time: 0.22876
Total Iteration Time: 6.93726
Cumulative Model Updates: 157,988
Cumulative Timesteps: 1,243,940,578
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.59365
Policy Entropy: 4.33908
Value Function Loss: 0.00241
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03022
Policy Update Magnitude: 0.95400
Value Function Update Magnitude: 0.80104
Collected Steps per Second: 13,042.11065
Overall Steps per Second: 7,299.25665
Timestep Collection Time: 3.83404
Timestep Consumption Time: 3.01652
PPO Batch Consumption Time: 0.22918
Total Iteration Time: 6.85056
Cumulative Model Updates: 157,997
Cumulative Timesteps: 1,243,990,582
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1243990582...
Checkpoint 1243990582 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.30627
Policy Entropy: 4.33705
Value Function Loss: 0.00240
Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02951
Policy Update Magnitude: 0.93271
Value Function Update Magnitude: 0.79710
Collected Steps per Second: 12,834.19322
Overall Steps per Second: 7,165.72557
Timestep Collection Time: 3.89927
Timestep Consumption Time: 3.08453
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.98380
Cumulative Model Updates: 158,006
Cumulative Timesteps: 1,244,040,626
Timesteps Collected: 50,044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.40736
Policy Entropy: 4.33632
Value Function Loss: 0.00237
Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02937
Policy Update Magnitude: 0.94663
Value Function Update Magnitude: 0.80463
Collected Steps per Second: 12,996.76180
Overall Steps per Second: 7,235.01804
Timestep Collection Time: 3.84942
Timestep Consumption Time: 3.06556
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.91498
Cumulative Model Updates: 158,015
Cumulative Timesteps: 1,244,090,656
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1244090656...
Checkpoint 1244090656 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.04321
Policy Entropy: 4.33424
Value Function Loss: 0.00245
Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02996
Policy Update Magnitude: 0.96984
Value Function Update Magnitude: 0.81024
Collected Steps per Second: 12,888.47831
Overall Steps per Second: 7,253.14823
Timestep Collection Time: 3.88099
Timestep Consumption Time: 3.01533
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.89632
Cumulative Model Updates: 158,024
Cumulative Timesteps: 1,244,140,676
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.17712
Policy Entropy: 4.33510
Value Function Loss: 0.00252
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03331
Policy Update Magnitude: 0.97640
Value Function Update Magnitude: 0.81366
Collected Steps per Second: 12,749.30245
Overall Steps per Second: 7,105.80799
Timestep Collection Time: 3.92445
Timestep Consumption Time: 3.11683
PPO Batch Consumption Time: 0.22875
Total Iteration Time: 7.04128
Cumulative Model Updates: 158,033
Cumulative Timesteps: 1,244,190,710
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
Saving checkpoint 1244190710...
Checkpoint 1244190710 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03435
Policy Entropy: 4.34008
Value Function Loss: 0.00255
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03400
Policy Update Magnitude: 0.97028
Value Function Update Magnitude: 0.80957
Collected Steps per Second: 12,782.04581
Overall Steps per Second: 7,075.87415
Timestep Collection Time: 3.91471
Timestep Consumption Time: 3.15693
PPO Batch Consumption Time: 0.22973
Total Iteration Time: 7.07164
Cumulative Model Updates: 158,042
Cumulative Timesteps: 1,244,240,748
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.73746
Policy Entropy: 4.33680
Value Function Loss: 0.00260
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03192
Policy Update Magnitude: 0.97378
Value Function Update Magnitude: 0.80595
Collected Steps per Second: 13,074.43730
Overall Steps per Second: 7,318.12390
Timestep Collection Time: 3.82456
Timestep Consumption Time: 3.00834
PPO Batch Consumption Time: 0.22812
Total Iteration Time: 6.83290
Cumulative Model Updates: 158,051
Cumulative Timesteps: 1,244,290,752
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1244290752...
Checkpoint 1244290752 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43041
Policy Entropy: 4.33997
Value Function Loss: 0.00263
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03194
Policy Update Magnitude: 0.96551
Value Function Update Magnitude: 0.78875
Collected Steps per Second: 12,972.22990
Overall Steps per Second: 7,176.73122
Timestep Collection Time: 3.85716
Timestep Consumption Time: 3.11481
PPO Batch Consumption Time: 0.22814
Total Iteration Time: 6.97198
Cumulative Model Updates: 158,060
Cumulative Timesteps: 1,244,340,788
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16802
Policy Entropy: 4.33848
Value Function Loss: 0.00267
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03236
Policy Update Magnitude: 0.98267
Value Function Update Magnitude: 0.81348
Collected Steps per Second: 13,084.22311
Overall Steps per Second: 7,235.05729
Timestep Collection Time: 3.82231
Timestep Consumption Time: 3.09014
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.91245
Cumulative Model Updates: 158,069
Cumulative Timesteps: 1,244,390,800
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1244390800...
Checkpoint 1244390800 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.63209
Policy Entropy: 4.34356
Value Function Loss: 0.00255
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03045
Policy Update Magnitude: 0.97053
Value Function Update Magnitude: 0.81071
Collected Steps per Second: 12,850.17279
Overall Steps per Second: 7,257.50953
Timestep Collection Time: 3.89427
Timestep Consumption Time: 3.00094
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.89520
Cumulative Model Updates: 158,078
Cumulative Timesteps: 1,244,440,842
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.43643
Policy Entropy: 4.34344
Value Function Loss: 0.00245
Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03194
Policy Update Magnitude: 0.95856
Value Function Update Magnitude: 0.78552
Collected Steps per Second: 13,028.54935
Overall Steps per Second: 7,211.67809
Timestep Collection Time: 3.83941
Timestep Consumption Time: 3.09684
PPO Batch Consumption Time: 0.22863
Total Iteration Time: 6.93625
Cumulative Model Updates: 158,087
Cumulative Timesteps: 1,244,490,864
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1244490864...
Checkpoint 1244490864 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.30707
Policy Entropy: 4.34585
Value Function Loss: 0.00246
Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03306
Policy Update Magnitude: 0.95597
Value Function Update Magnitude: 0.80914
Collected Steps per Second: 12,998.29595
Overall Steps per Second: 7,231.86162
Timestep Collection Time: 3.84835
Timestep Consumption Time: 3.06854
PPO Batch Consumption Time: 0.22834
Total Iteration Time: 6.91689
Cumulative Model Updates: 158,096
Cumulative Timesteps: 1,244,540,886
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.63233
Policy Entropy: 4.34208
Value Function Loss: 0.00255
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03147
Policy Update Magnitude: 0.97328
Value Function Update Magnitude: 0.82335
Collected Steps per Second: 12,913.72298
Overall Steps per Second: 7,113.80155
Timestep Collection Time: 3.87262
Timestep Consumption Time: 3.15737
PPO Batch Consumption Time: 0.24165
Total Iteration Time: 7.03000
Cumulative Model Updates: 158,105
Cumulative Timesteps: 1,244,590,896
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1244590896...
Checkpoint 1244590896 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.09457
Policy Entropy: 4.34215
Value Function Loss: 0.00262
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03264
Policy Update Magnitude: 1.00275
Value Function Update Magnitude: 0.84946
Collected Steps per Second: 12,832.95003
Overall Steps per Second: 7,146.87444
Timestep Collection Time: 3.89856
Timestep Consumption Time: 3.10170
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 7.00026
Cumulative Model Updates: 158,114
Cumulative Timesteps: 1,244,640,926
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.50040
Policy Entropy: 4.34126
Value Function Loss: 0.00268
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03356
Policy Update Magnitude: 1.02282
Value Function Update Magnitude: 0.82103
Collected Steps per Second: 13,011.60380
Overall Steps per Second: 7,245.70116
Timestep Collection Time: 3.84564
Timestep Consumption Time: 3.06024
PPO Batch Consumption Time: 0.22791
Total Iteration Time: 6.90589
Cumulative Model Updates: 158,123
Cumulative Timesteps: 1,244,690,964
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
Saving checkpoint 1244690964...
Checkpoint 1244690964 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.84520
Policy Entropy: 4.33884
Value Function Loss: 0.00275
Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03260
Policy Update Magnitude: 1.02815
Value Function Update Magnitude: 0.84192
Collected Steps per Second: 12,934.39200
Overall Steps per Second: 7,276.37700
Timestep Collection Time: 3.86767
Timestep Consumption Time: 3.00745
PPO Batch Consumption Time: 0.22842
Total Iteration Time: 6.87512
Cumulative Model Updates: 158,132
Cumulative Timesteps: 1,244,740,990
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.38545
Policy Entropy: 4.33226
Value Function Loss: 0.00290
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03414
Policy Update Magnitude: 1.04332
Value Function Update Magnitude: 0.87252
Collected Steps per Second: 13,150.34319
Overall Steps per Second: 7,235.26080
Timestep Collection Time: 3.80264
Timestep Consumption Time: 3.10879
PPO Batch Consumption Time: 0.22910
Total Iteration Time: 6.91143
Cumulative Model Updates: 158,141
Cumulative Timesteps: 1,244,790,996
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1244790996...
Checkpoint 1244790996 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24909
Policy Entropy: 4.33323
Value Function Loss: 0.00284
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03373
Policy Update Magnitude: 1.05264
Value Function Update Magnitude: 0.85893
Collected Steps per Second: 13,041.67142
Overall Steps per Second: 7,200.07495
Timestep Collection Time: 3.83662
Timestep Consumption Time: 3.11275
PPO Batch Consumption Time: 0.22864
Total Iteration Time: 6.94937
Cumulative Model Updates: 158,150
Cumulative Timesteps: 1,244,841,032
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.58228
Policy Entropy: 4.33318
Value Function Loss: 0.00288
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03557
Policy Update Magnitude: 1.04854
Value Function Update Magnitude: 0.82011
Collected Steps per Second: 12,825.13394
Overall Steps per Second: 7,235.25259
Timestep Collection Time: 3.90265
Timestep Consumption Time: 3.01515
PPO Batch Consumption Time: 0.22866
Total Iteration Time: 6.91780
Cumulative Model Updates: 158,159
Cumulative Timesteps: 1,244,891,084
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
Saving checkpoint 1244891084...
Checkpoint 1244891084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67069
Policy Entropy: 4.33834
Value Function Loss: 0.00265
Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03446
Policy Update Magnitude: 1.03026
Value Function Update Magnitude: 0.79483
Collected Steps per Second: 12,933.73244
Overall Steps per Second: 7,168.15802
Timestep Collection Time: 3.86772
Timestep Consumption Time: 3.11093
PPO Batch Consumption Time: 0.22924
Total Iteration Time: 6.97864
Cumulative Model Updates: 158,168
Cumulative Timesteps: 1,244,941,108
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.64162
Policy Entropy: 4.33824
Value Function Loss: 0.00257
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 1.00319
Value Function Update Magnitude: 0.79986
Collected Steps per Second: 13,063.03376
Overall Steps per Second: 7,199.86108
Timestep Collection Time: 3.82790
Timestep Consumption Time: 3.11723
PPO Batch Consumption Time: 0.22895
Total Iteration Time: 6.94513
Cumulative Model Updates: 158,177
Cumulative Timesteps: 1,244,991,112
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1244991112...
Checkpoint 1244991112 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24562
Policy Entropy: 4.33868
Value Function Loss: 0.00256
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03090
Policy Update Magnitude: 0.99756
Value Function Update Magnitude: 0.81901
Collected Steps per Second: 12,880.77988
Overall Steps per Second: 7,271.58048
Timestep Collection Time: 3.88299
Timestep Consumption Time: 2.99529
PPO Batch Consumption Time: 0.22886
Total Iteration Time: 6.87828
Cumulative Model Updates: 158,186
Cumulative Timesteps: 1,245,041,128
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.49253
Policy Entropy: 4.33543
Value Function Loss: 0.00266
Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03183
Policy Update Magnitude: 1.01891
Value Function Update Magnitude: 0.82853
Collected Steps per Second: 13,137.27337
Overall Steps per Second: 7,231.55746
Timestep Collection Time: 3.80596
Timestep Consumption Time: 3.10818
PPO Batch Consumption Time: 0.22833
Total Iteration Time: 6.91414
Cumulative Model Updates: 158,195
Cumulative Timesteps: 1,245,091,128
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 1245091128...
Checkpoint 1245091128 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.38429
Policy Entropy: 4.33620
Value Function Loss: 0.00279
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03224
Policy Update Magnitude: 1.04234
Value Function Update Magnitude: 0.83959
Collected Steps per Second: 12,982.31549
Overall Steps per Second: 7,200.99640
Timestep Collection Time: 3.85201
Timestep Consumption Time: 3.09259
PPO Batch Consumption Time: 0.22856
Total Iteration Time: 6.94459
Cumulative Model Updates: 158,204
Cumulative Timesteps: 1,245,141,136
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.27861
Policy Entropy: 4.33443
Value Function Loss: 0.00270
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03231
Policy Update Magnitude: 1.02023
Value Function Update Magnitude: 0.86457
Collected Steps per Second: 12,989.04369
Overall Steps per Second: 7,299.37287
Timestep Collection Time: 3.85063
Timestep Consumption Time: 3.00147
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.85210
Cumulative Model Updates: 158,213
Cumulative Timesteps: 1,245,191,152
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
Saving checkpoint 1245191152...
Checkpoint 1245191152 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 16.58940
Policy Entropy: 4.33459
Value Function Loss: 0.00264
Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03220
Policy Update Magnitude: 1.00936
Value Function Update Magnitude: 0.87204
Collected Steps per Second: 12,925.25820
Overall Steps per Second: 7,157.79655
Timestep Collection Time: 3.87195
Timestep Consumption Time: 3.11986
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.99182
Cumulative Model Updates: 158,222
Cumulative Timesteps: 1,245,241,198
Timesteps Collected: 50,046
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.86964
Policy Entropy: 4.33303
Value Function Loss: 0.00259
Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03097
Policy Update Magnitude: 1.01604
Value Function Update Magnitude: 0.86907
Collected Steps per Second: 12,866.96168
Overall Steps per Second: 7,012.75038
Timestep Collection Time: 3.88903
Timestep Consumption Time: 3.24654
PPO Batch Consumption Time: 0.23952
Total Iteration Time: 7.13557
Cumulative Model Updates: 158,231
Cumulative Timesteps: 1,245,291,238
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 1245291238...
Checkpoint 1245291238 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.72893
Policy Entropy: 4.33245
Value Function Loss: 0.00269
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 1.02250
Value Function Update Magnitude: 0.88044
Collected Steps per Second: 12,927.64522
Overall Steps per Second: 7,267.84357
Timestep Collection Time: 3.87201
Timestep Consumption Time: 3.01531
PPO Batch Consumption Time: 0.22825
Total Iteration Time: 6.88732
Cumulative Model Updates: 158,240
Cumulative Timesteps: 1,245,341,294
Timesteps Collected: 50,056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.34835
Policy Entropy: 4.32809
Value Function Loss: 0.00277
Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 1.04432
Value Function Update Magnitude: 0.87436
Collected Steps per Second: 13,064.45439
Overall Steps per Second: 7,193.94490
Timestep Collection Time: 3.82932
Timestep Consumption Time: 3.12486
PPO Batch Consumption Time: 0.22852
Total Iteration Time: 6.95418
Cumulative Model Updates: 158,249
Cumulative Timesteps: 1,245,391,322
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 1245391322...
Checkpoint 1245391322 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07961
Policy Entropy: 4.33051
Value Function Loss: 0.00283
Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03662
Policy Update Magnitude: 1.03884
Value Function Update Magnitude: 0.88864
Collected Steps per Second: 12,988.62359
Overall Steps per Second: 7,204.31142
Timestep Collection Time: 3.85029
Timestep Consumption Time: 3.09138
PPO Batch Consumption Time: 0.22888
Total Iteration Time: 6.94168
Cumulative Model Updates: 158,258
Cumulative Timesteps: 1,245,441,332
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.64039
Policy Entropy: 4.33243
Value Function Loss: 0.00271
Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03498
Policy Update Magnitude: 1.01729
Value Function Update Magnitude: 0.89178
Collected Steps per Second: 12,714.10636
Overall Steps per Second: 7,204.44596
Timestep Collection Time: 3.93421
Timestep Consumption Time: 3.00872
PPO Batch Consumption Time: 0.22869
Total Iteration Time: 6.94293
Cumulative Model Updates: 158,267
Cumulative Timesteps: 1,245,491,352
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1245491352...
Checkpoint 1245491352 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.22529
Policy Entropy: 4.33214
Value Function Loss: 0.00275
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 1.01340
Value Function Update Magnitude: 0.87768
Collected Steps per Second: 12,957.12286
Overall Steps per Second: 7,192.54654
Timestep Collection Time: 3.85981
Timestep Consumption Time: 3.09350
PPO Batch Consumption Time: 0.22829
Total Iteration Time: 6.95331
Cumulative Model Updates: 158,276
Cumulative Timesteps: 1,245,541,364
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.00776
Policy Entropy: 4.33015
Value Function Loss: 0.00266
Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03422
Policy Update Magnitude: 1.00526
Value Function Update Magnitude: 0.89154
Collected Steps per Second: 12,939.20526
Overall Steps per Second: 7,170.92307
Timestep Collection Time: 3.86654
Timestep Consumption Time: 3.11024
PPO Batch Consumption Time: 0.22861
Total Iteration Time: 6.97679
Cumulative Model Updates: 158,285
Cumulative Timesteps: 1,245,591,394
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1245591394...
Checkpoint 1245591394 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.17522
Policy Entropy: 4.33040
Value Function Loss: 0.00265
Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03480
Policy Update Magnitude: 0.99200
Value Function Update Magnitude: 0.85313
Collected Steps per Second: 12,792.16952
Overall Steps per Second: 7,120.67155
Timestep Collection Time: 3.90989
Timestep Consumption Time: 3.11416
PPO Batch Consumption Time: 0.23996
Total Iteration Time: 7.02406
Cumulative Model Updates: 158,294
Cumulative Timesteps: 1,245,641,410
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44328
Policy Entropy: 4.33335
Value Function Loss: 0.00257
Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03412
Policy Update Magnitude: 0.99542
Value Function Update Magnitude: 0.85882
Collected Steps per Second: 12,923.00407
Overall Steps per Second: 7,168.31504
Timestep Collection Time: 3.87294
Timestep Consumption Time: 3.10918
PPO Batch Consumption Time: 0.22862
Total Iteration Time: 6.98211
Cumulative Model Updates: 158,303
Cumulative Timesteps: 1,245,691,460
Timesteps Collected: 50,050
--------END ITERATION REPORT--------
Saving checkpoint 1245691460...
Checkpoint 1245691460 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.38703
Policy Entropy: 4.33707
Value Function Loss: 0.00261
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03180
Policy Update Magnitude: 0.99086
Value Function Update Magnitude: 0.87019
Collected Steps per Second: 12,998.07037
Overall Steps per Second: 7,181.12663
Timestep Collection Time: 3.84934
Timestep Consumption Time: 3.11809
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 6.96743
Cumulative Model Updates: 158,312
Cumulative Timesteps: 1,245,741,494
Timesteps Collected: 50,034
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.81562
Policy Entropy: 4.33717
Value Function Loss: 0.00263
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 0.99981
Value Function Update Magnitude: 0.84498
Collected Steps per Second: 12,934.08771
Overall Steps per Second: 7,289.60271
Timestep Collection Time: 3.86730
Timestep Consumption Time: 2.99453
PPO Batch Consumption Time: 0.22836
Total Iteration Time: 6.86183
Cumulative Model Updates: 158,321
Cumulative Timesteps: 1,245,791,514
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
Saving checkpoint 1245791514...
Checkpoint 1245791514 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.85697
Policy Entropy: 4.33621
Value Function Loss: 0.00267
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 1.01250
Value Function Update Magnitude: 0.86683
Collected Steps per Second: 12,967.50757
Overall Steps per Second: 7,166.13113
Timestep Collection Time: 3.85687
Timestep Consumption Time: 3.12235
PPO Batch Consumption Time: 0.22890
Total Iteration Time: 6.97922
Cumulative Model Updates: 158,330
Cumulative Timesteps: 1,245,841,528
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.98920
Policy Entropy: 4.33268
Value Function Loss: 0.00263
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03379
Policy Update Magnitude: 1.02343
Value Function Update Magnitude: 0.87755
Collected Steps per Second: 12,938.54301
Overall Steps per Second: 7,160.75104
Timestep Collection Time: 3.86612
Timestep Consumption Time: 3.11946
PPO Batch Consumption Time: 0.22845
Total Iteration Time: 6.98558
Cumulative Model Updates: 158,339
Cumulative Timesteps: 1,245,891,550
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 1245891550...
Checkpoint 1245891550 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.66937
Policy Entropy: 4.33382
Value Function Loss: 0.00263
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03379
Policy Update Magnitude: 1.01200
Value Function Update Magnitude: 0.85464
Collected Steps per Second: 12,848.93360
Overall Steps per Second: 7,204.41156
Timestep Collection Time: 3.89386
Timestep Consumption Time: 3.05077
PPO Batch Consumption Time: 0.22860
Total Iteration Time: 6.94463
Cumulative Model Updates: 158,348
Cumulative Timesteps: 1,245,941,582
Timesteps Collected: 50,032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.30778
Policy Entropy: 4.33576
Value Function Loss: 0.00253
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03296
Policy Update Magnitude: 0.98989
Value Function Update Magnitude: 0.84140
Collected Steps per Second: 13,067.11152
Overall Steps per Second: 7,174.30980
Timestep Collection Time: 3.82655
Timestep Consumption Time: 3.14304
PPO Batch Consumption Time: 0.23312
Total Iteration Time: 6.96959
Cumulative Model Updates: 158,357
Cumulative Timesteps: 1,245,991,584
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1245991584...
Checkpoint 1245991584 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.01897
Policy Entropy: 4.33531
Value Function Loss: 0.00253
Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03110
Policy Update Magnitude: 0.99818
Value Function Update Magnitude: 0.83568
Collected Steps per Second: 12,767.57914
Overall Steps per Second: 7,145.60402
Timestep Collection Time: 3.92024
Timestep Consumption Time: 3.08434
PPO Batch Consumption Time: 0.22853
Total Iteration Time: 7.00459
Cumulative Model Updates: 158,366
Cumulative Timesteps: 1,246,041,636
Timesteps Collected: 50,052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.99027
Policy Entropy: 4.33604
Value Function Loss: 0.00255
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03294
Policy Update Magnitude: 1.00618
Value Function Update Magnitude: 0.83754
Collected Steps per Second: 12,910.72049
Overall Steps per Second: 7,166.80929
Timestep Collection Time: 3.87337
Timestep Consumption Time: 3.10435
PPO Batch Consumption Time: 0.22858
Total Iteration Time: 6.97772
Cumulative Model Updates: 158,375
Cumulative Timesteps: 1,246,091,644
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1246091644...
Checkpoint 1246091644 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 17.92311
Policy Entropy: 4.33737
Value Function Loss: 0.00259
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03154
Policy Update Magnitude: 1.01239
Value Function Update Magnitude: 0.84158
Collected Steps per Second: 13,143.54197
Overall Steps per Second: 7,230.49115
Timestep Collection Time: 3.80506
Timestep Consumption Time: 3.11176
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.91682
Cumulative Model Updates: 158,384
Cumulative Timesteps: 1,246,141,656
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.21710
Policy Entropy: 4.33622
Value Function Loss: 0.00270
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03116
Policy Update Magnitude: 1.01347
Value Function Update Magnitude: 0.85696
Collected Steps per Second: 13,014.59975
Overall Steps per Second: 7,195.84026
Timestep Collection Time: 3.84322
Timestep Consumption Time: 3.10774
PPO Batch Consumption Time: 0.22850
Total Iteration Time: 6.95096
Cumulative Model Updates: 158,393
Cumulative Timesteps: 1,246,191,674
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 1246191674...
Checkpoint 1246191674 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61844
Policy Entropy: 4.33340
Value Function Loss: 0.00274
Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03362
Policy Update Magnitude: 1.02109
Value Function Update Magnitude: 0.87438
Collected Steps per Second: 12,975.48807
Overall Steps per Second: 7,235.39831
Timestep Collection Time: 3.85512
Timestep Consumption Time: 3.05840
PPO Batch Consumption Time: 0.22857
Total Iteration Time: 6.91351
Cumulative Model Updates: 158,402
Cumulative Timesteps: 1,246,241,696
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77798
Policy Entropy: 4.33078
Value Function Loss: 0.00278
Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03497
Policy Update Magnitude: 1.03152
Value Function Update Magnitude: 0.89280
Collected Steps per Second: 13,299.79097
Overall Steps per Second: 7,275.52745
Timestep Collection Time: 3.76141
Timestep Consumption Time: 3.11452
PPO Batch Consumption Time: 0.22874
Total Iteration Time: 6.87593
Cumulative Model Updates: 158,411
Cumulative Timesteps: 1,246,291,722
Timesteps Collected: 50,026
--------END ITERATION REPORT--------
Saving checkpoint 1246291722...
Checkpoint 1246291722 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.26524
Policy Entropy: 4.33027
Value Function Loss: 0.00260
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 1.01369
Value Function Update Magnitude: 0.90870
Collected Steps per Second: 12,771.21738
Overall Steps per Second: 7,078.49949
Timestep Collection Time: 3.91834
Timestep Consumption Time: 3.15124
PPO Batch Consumption Time: 0.23375
Total Iteration Time: 7.06958
Cumulative Model Updates: 158,420
Cumulative Timesteps: 1,246,341,764
Timesteps Collected: 50,042
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.43026
Policy Entropy: 4.33060
Value Function Loss: 0.00258
Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 1.01902
Value Function Update Magnitude: 0.87622
Collected Steps per Second: 12,866.41005
Overall Steps per Second: 7,203.48541
Timestep Collection Time: 3.88655
Timestep Consumption Time: 3.05536
PPO Batch Consumption Time: 0.22846
Total Iteration Time: 6.94192
Cumulative Model Updates: 158,429
Cumulative Timesteps: 1,246,391,770
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1246391770...
Checkpoint 1246391770 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61417
Policy Entropy: 4.32934
Value Function Loss: 0.00269
Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03427
Policy Update Magnitude: 1.02602
Value Function Update Magnitude: 0.87668
Collected Steps per Second: 13,104.98699
Overall Steps per Second: 7,232.27644
Timestep Collection Time: 3.81595
Timestep Consumption Time: 3.09861
PPO Batch Consumption Time: 0.22854
Total Iteration Time: 6.91456
Cumulative Model Updates: 158,438
Cumulative Timesteps: 1,246,441,778
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 11.38149
Policy Entropy: 4.33147
Value Function Loss: 0.00262
Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03368
Policy Update Magnitude: 1.02400
Value Function Update Magnitude: 0.89493
Collected Steps per Second: 13,067.62940
Overall Steps per Second: 7,232.82955
Timestep Collection Time: 3.82655
Timestep Consumption Time: 3.08692
PPO Batch Consumption Time: 0.22849
Total Iteration Time: 6.91348
Cumulative Model Updates: 158,447
Cumulative Timesteps: 1,246,491,782
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1246491782...
Checkpoint 1246491782 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89334
Policy Entropy: 4.33403
Value Function Loss: 0.00258
Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03096
Policy Update Magnitude: 1.01166
Value Function Update Magnitude: 0.85876
Collected Steps per Second: 12,919.01765
Overall Steps per Second: 7,208.81584
Timestep Collection Time: 3.87305
Timestep Consumption Time: 3.06790
PPO Batch Consumption Time: 0.22832
Total Iteration Time: 6.94095
Cumulative Model Updates: 158,456
Cumulative Timesteps: 1,246,541,818
Timesteps Collected: 50,036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.20437
Policy Entropy: 4.33826
Value Function Loss: 0.00240
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03205
Policy Update Magnitude: 0.99709
Value Function Update Magnitude: 0.85010
Collected Steps per Second: 13,136.56423
Overall Steps per Second: 7,217.34000
Timestep Collection Time: 3.80632
Timestep Consumption Time: 3.12171
PPO Batch Consumption Time: 0.23061
Total Iteration Time: 6.92804
Cumulative Model Updates: 158,465
Cumulative Timesteps: 1,246,591,820
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 1246591820...
Checkpoint 1246591820 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38970
Policy Entropy: 4.34263
Value Function Loss: 0.00244
Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 0.97804
Value Function Update Magnitude: 0.83821
Collected Steps per Second: 10,589.01188
Overall Steps per Second: 6,332.22311
Timestep Collection Time: 4.72263
Timestep Consumption Time: 3.17475
PPO Batch Consumption Time: 0.23175
Total Iteration Time: 7.89738
Cumulative Model Updates: 158,474
Cumulative Timesteps: 1,246,641,828
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 15.24175
Policy Entropy: 4.34269
Value Function Loss: 0.00254
Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03327
Policy Update Magnitude: 0.99774
Value Function Update Magnitude: 0.81554
Collected Steps per Second: 11,589.86579
Overall Steps per Second: 6,634.35865
Timestep Collection Time: 4.31463
Timestep Consumption Time: 3.22280
PPO Batch Consumption Time: 0.24102
Total Iteration Time: 7.53743
Cumulative Model Updates: 158,483
Cumulative Timesteps: 1,246,691,834
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1246691834...
Checkpoint 1246691834 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 14.59120
Policy Entropy: 4.34213
Value Function Loss: 0.00262
Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 1.00995
Value Function Update Magnitude: 0.81184
Collected Steps per Second: 11,622.97899
Overall Steps per Second: 6,697.48212
Timestep Collection Time: 4.30337
Timestep Consumption Time: 3.16481
PPO Batch Consumption Time: 0.22967
Total Iteration Time: 7.46818
Cumulative Model Updates: 158,492
Cumulative Timesteps: 1,246,741,852
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 13.31777
Policy Entropy: 4.33341
Value Function Loss: 0.00280
Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03453
Policy Update Magnitude: 1.03244
Value Function Update Magnitude: 0.83716
Collected Steps per Second: 11,812.40299
Overall Steps per Second: 6,782.40029
Timestep Collection Time: 4.23538
Timestep Consumption Time: 3.14107
PPO Batch Consumption Time: 0.22898
Total Iteration Time: 7.37644
Cumulative Model Updates: 158,501
Cumulative Timesteps: 1,246,791,882
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
Saving checkpoint 1246791882...
Checkpoint 1246791882 saved!